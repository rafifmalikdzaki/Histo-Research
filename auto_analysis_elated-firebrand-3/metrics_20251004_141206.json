{
  "batch_metrics": [
    {
      "batch_idx": 0,
      "phase": "val",
      "loss": 0.3895999789237976,
      "timestamp": 1759561871.0865848,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3895999789237976,
      "ssim": 0.00040854327380657196,
      "attention_bam_384_mean_attention": 0.027279892936348915,
      "attention_bam_384_std_attention": 0.25250741839408875,
      "attention_bam_384_max_attention": 0.98193359375,
      "attention_bam_384_min_attention": -0.7830810546875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": -0.3201067576437744,
      "attention_bam_384_attention_skewness": -0.013473773464475442,
      "attention_bam_384_attention_sparsity": 0.607330322265625,
      "attention_bam_384_attention_concentration_10": 1.7005794433075048,
      "attention_bam_384_attention_concentration_20": 2.782090788188882,
      "attention_bam_384_attention_center_y": 0.48433865387215447,
      "attention_bam_384_attention_center_x": 0.4841889192949348,
      "attention_bam_384_attention_center_distance": 0.031472783022741015,
      "attention_bam_384_attention_spatial_variance": 170.47589944698439,
      "attention_bam_384_attention_spatial_std": 13.05664196671504,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 16.841797090485656,
      "attention_bam_384_peak_intensity_mean": 0.45934778451919556,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": -0.023056861013174057,
      "attention_bam_16_std_attention": 0.2135583460330963,
      "attention_bam_16_max_attention": 0.42156982421875,
      "attention_bam_16_min_attention": -0.7479248046875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.618020875036284,
      "attention_bam_16_attention_skewness": -0.8164942125515078,
      "attention_bam_16_attention_sparsity": 0.769775390625,
      "attention_bam_16_attention_concentration_10": -1.383140427327069,
      "attention_bam_16_attention_concentration_20": -2.230925605625802,
      "attention_bam_16_attention_center_y": 0.4698477388378518,
      "attention_bam_16_attention_center_x": 0.46838565310888425,
      "attention_bam_16_attention_center_distance": 0.06178391024437011,
      "attention_bam_16_attention_spatial_variance": 42.4473040781802,
      "attention_bam_16_attention_spatial_std": 6.515159558919505,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 7.2631093237814905,
      "attention_bam_16_peak_intensity_mean": 0.6194080114364624,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 1,
      "phase": "val",
      "loss": 0.3948638141155243,
      "timestamp": 1759561873.0108893,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3948638141155243,
      "ssim": 0.0006062970496714115,
      "attention_bam_384_mean_attention": 0.027856267988681793,
      "attention_bam_384_std_attention": 0.25301969051361084,
      "attention_bam_384_max_attention": 0.922119140625,
      "attention_bam_384_min_attention": -0.75048828125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": -0.3489305636883069,
      "attention_bam_384_attention_skewness": -0.018300669019679246,
      "attention_bam_384_attention_sparsity": 0.5998662312825521,
      "attention_bam_384_attention_concentration_10": 1.6659078680650583,
      "attention_bam_384_attention_concentration_20": 2.728711446569341,
      "attention_bam_384_attention_center_y": 0.4848240448428333,
      "attention_bam_384_attention_center_x": 0.484328580432118,
      "attention_bam_384_attention_center_distance": 0.030851353493969384,
      "attention_bam_384_attention_spatial_variance": 170.36773816970666,
      "attention_bam_384_attention_spatial_std": 13.052499307401117,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 15.967948666447814,
      "attention_bam_384_peak_intensity_mean": 0.46574026346206665,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": -0.023064471781253815,
      "attention_bam_16_std_attention": 0.20926405489444733,
      "attention_bam_16_max_attention": 0.412109375,
      "attention_bam_16_min_attention": -0.696044921875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.6857240283563524,
      "attention_bam_16_attention_skewness": -0.835637469842628,
      "attention_bam_16_attention_sparsity": 0.8115234375,
      "attention_bam_16_attention_concentration_10": -1.3610803962210327,
      "attention_bam_16_attention_concentration_20": -2.1846442490685716,
      "attention_bam_16_attention_center_y": 0.46929735998565686,
      "attention_bam_16_attention_center_x": 0.46821391087525055,
      "attention_bam_16_attention_center_distance": 0.06249812102290531,
      "attention_bam_16_attention_spatial_variance": 42.46409940421988,
      "attention_bam_16_attention_spatial_std": 6.516448373479213,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 8.775735827210816,
      "attention_bam_16_peak_intensity_mean": 0.6077205538749695,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 0,
      "phase": "train",
      "loss": 0.674382209777832,
      "timestamp": 1759561874.1838658,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.674382209777832,
      "ssim": 0.03018847294151783,
      "attention_bam_384_mean_attention": 0.23461361229419708,
      "attention_bam_384_std_attention": 0.6595689654350281,
      "attention_bam_384_max_attention": 7.37109375,
      "attention_bam_384_min_attention": -1.6923828125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 4.286768198118034,
      "attention_bam_384_attention_skewness": 1.1116628967717006,
      "attention_bam_384_attention_sparsity": 0.44769541422526044,
      "attention_bam_384_attention_concentration_10": 0.6542075235698351,
      "attention_bam_384_attention_concentration_20": 1.0145116776148941,
      "attention_bam_384_attention_center_y": 0.48272383779368117,
      "attention_bam_384_attention_center_x": 0.48078391599871945,
      "attention_bam_384_attention_center_distance": 0.036543772791634684,
      "attention_bam_384_attention_spatial_variance": 171.31305243638997,
      "attention_bam_384_attention_spatial_std": 13.088661216350202,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 15.21052423792029,
      "attention_bam_384_peak_intensity_mean": 0.21384508907794952,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2457546889781952,
      "attention_bam_16_std_attention": 0.6227905750274658,
      "attention_bam_16_max_attention": 2.90234375,
      "attention_bam_16_min_attention": -1.152099609375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5525255646052725,
      "attention_bam_16_attention_skewness": 0.6018279438076105,
      "attention_bam_16_attention_sparsity": 0.436279296875,
      "attention_bam_16_attention_concentration_10": 0.6002472787573981,
      "attention_bam_16_attention_concentration_20": 0.9610750289827383,
      "attention_bam_16_attention_center_y": 0.469531449824565,
      "attention_bam_16_attention_center_x": 0.460236103148496,
      "attention_bam_16_attention_center_distance": 0.07084490161768944,
      "attention_bam_16_attention_spatial_variance": 42.944681043519246,
      "attention_bam_16_attention_spatial_std": 6.553219135930008,
      "attention_bam_16_num_attention_peaks": 13,
      "attention_bam_16_peak_separation_mean": 10.095097223127974,
      "attention_bam_16_peak_intensity_mean": 0.35803619027137756,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 1,
      "phase": "train",
      "loss": 0.6144739985466003,
      "timestamp": 1759561886.2873745,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.6144739985466003,
      "ssim": 0.03929352015256882,
      "attention_bam_384_mean_attention": 0.24507178366184235,
      "attention_bam_384_std_attention": 0.6470795273780823,
      "attention_bam_384_max_attention": 7.384765625,
      "attention_bam_384_min_attention": -1.6845703125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.7057730060244056,
      "attention_bam_384_attention_skewness": 1.0353455572980284,
      "attention_bam_384_attention_sparsity": 0.44038645426432294,
      "attention_bam_384_attention_concentration_10": 0.6204706544463922,
      "attention_bam_384_attention_concentration_20": 0.9697935940451372,
      "attention_bam_384_attention_center_y": 0.48430625478923683,
      "attention_bam_384_attention_center_x": 0.48379328161105617,
      "attention_bam_384_attention_center_distance": 0.031904587747810874,
      "attention_bam_384_attention_spatial_variance": 172.113608661504,
      "attention_bam_384_attention_spatial_std": 13.119207623233349,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 19.315131767412286,
      "attention_bam_384_peak_intensity_mean": 0.21474553644657135,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23714670538902283,
      "attention_bam_16_std_attention": 0.6517515182495117,
      "attention_bam_16_max_attention": 3.302001953125,
      "attention_bam_16_min_attention": -1.2509765625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.7928361656069498,
      "attention_bam_16_attention_skewness": 0.9776529900174382,
      "attention_bam_16_attention_sparsity": 0.466552734375,
      "attention_bam_16_attention_concentration_10": 0.666880369182622,
      "attention_bam_16_attention_concentration_20": 1.0304665903238543,
      "attention_bam_16_attention_center_y": 0.4728299145913402,
      "attention_bam_16_attention_center_x": 0.47218787968920545,
      "attention_bam_16_attention_center_distance": 0.05498595415732964,
      "attention_bam_16_attention_spatial_variance": 43.05681063107941,
      "attention_bam_16_attention_spatial_std": 6.561768864496783,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.587395801406776,
      "attention_bam_16_peak_intensity_mean": 0.3330957591533661,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 2,
      "phase": "train",
      "loss": 0.5141948461532593,
      "timestamp": 1759561886.4587305,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.5141948461532593,
      "ssim": 0.04283855855464935,
      "attention_bam_384_mean_attention": 0.23788386583328247,
      "attention_bam_384_std_attention": 0.5025405883789062,
      "attention_bam_384_max_attention": 7.2119140625,
      "attention_bam_384_min_attention": -1.535400390625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.795895592311523,
      "attention_bam_384_attention_skewness": 0.701906506714188,
      "attention_bam_384_attention_sparsity": 0.39693959554036456,
      "attention_bam_384_attention_concentration_10": 0.4888951779937266,
      "attention_bam_384_attention_concentration_20": 0.795247959026689,
      "attention_bam_384_attention_center_y": 0.47962442315965287,
      "attention_bam_384_attention_center_x": 0.47967508068354775,
      "attention_bam_384_attention_center_distance": 0.04070052768201376,
      "attention_bam_384_attention_spatial_variance": 171.36987671465798,
      "attention_bam_384_attention_spatial_std": 13.090831780855561,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 16.123279626589877,
      "attention_bam_384_peak_intensity_mean": 0.203139066696167,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23465333878993988,
      "attention_bam_16_std_attention": 0.4644710123538971,
      "attention_bam_16_max_attention": 2.8439788818359375,
      "attention_bam_16_min_attention": -0.978271484375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8573802166599522,
      "attention_bam_16_attention_skewness": 0.44645333734208276,
      "attention_bam_16_attention_sparsity": 0.391845703125,
      "attention_bam_16_attention_concentration_10": 0.4695503088445131,
      "attention_bam_16_attention_concentration_20": 0.764658034797842,
      "attention_bam_16_attention_center_y": 0.46304302485440896,
      "attention_bam_16_attention_center_x": 0.4677005391776773,
      "attention_bam_16_attention_center_distance": 0.06941286885476775,
      "attention_bam_16_attention_spatial_variance": 42.682484573959094,
      "attention_bam_16_attention_spatial_std": 6.533183341523418,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.371553826958499,
      "attention_bam_16_peak_intensity_mean": 0.3213530480861664,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 3,
      "phase": "train",
      "loss": 0.4800562858581543,
      "timestamp": 1759561886.625876,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.4800562858581543,
      "ssim": 0.02482813224196434,
      "attention_bam_384_mean_attention": 0.23525206744670868,
      "attention_bam_384_std_attention": 0.5401883125305176,
      "attention_bam_384_max_attention": 5.5439453125,
      "attention_bam_384_min_attention": -1.42724609375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5079595689825673,
      "attention_bam_384_attention_skewness": 0.5590058152284704,
      "attention_bam_384_attention_sparsity": 0.42616017659505206,
      "attention_bam_384_attention_concentration_10": 0.5328799394355668,
      "attention_bam_384_attention_concentration_20": 0.8720827550979479,
      "attention_bam_384_attention_center_y": 0.4796270104540608,
      "attention_bam_384_attention_center_x": 0.48751961199998234,
      "attention_bam_384_attention_center_distance": 0.03378812772764813,
      "attention_bam_384_attention_spatial_variance": 170.85260805560662,
      "attention_bam_384_attention_spatial_std": 13.071059943845665,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 17.68275091263935,
      "attention_bam_384_peak_intensity_mean": 0.23828202486038208,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2231074571609497,
      "attention_bam_16_std_attention": 0.4671613574028015,
      "attention_bam_16_max_attention": 2.10675048828125,
      "attention_bam_16_min_attention": -1.017333984375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.14705186277783966,
      "attention_bam_16_attention_skewness": 0.40073627972728615,
      "attention_bam_16_attention_sparsity": 0.4208984375,
      "attention_bam_16_attention_concentration_10": 0.4941993608489805,
      "attention_bam_16_attention_concentration_20": 0.8147345317536079,
      "attention_bam_16_attention_center_y": 0.47289023563955745,
      "attention_bam_16_attention_center_x": 0.4672763886824233,
      "attention_bam_16_attention_center_distance": 0.060096157303816906,
      "attention_bam_16_attention_spatial_variance": 42.00355966331507,
      "attention_bam_16_attention_spatial_std": 6.481015326576158,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.631948299588975,
      "attention_bam_16_peak_intensity_mean": 0.4099538028240204,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 4,
      "phase": "train",
      "loss": 0.4695420265197754,
      "timestamp": 1759561886.7964306,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.4695420265197754,
      "ssim": 0.013416453264653683,
      "attention_bam_384_mean_attention": 0.24061687290668488,
      "attention_bam_384_std_attention": 0.5737588405609131,
      "attention_bam_384_max_attention": 5.45703125,
      "attention_bam_384_min_attention": -1.559326171875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.867155187951676,
      "attention_bam_384_attention_skewness": 0.7504933481379583,
      "attention_bam_384_attention_sparsity": 0.4301249186197917,
      "attention_bam_384_attention_concentration_10": 0.5644004976117932,
      "attention_bam_384_attention_concentration_20": 0.8979211179850428,
      "attention_bam_384_attention_center_y": 0.4818129469000245,
      "attention_bam_384_attention_center_x": 0.48235960723415977,
      "attention_bam_384_attention_center_distance": 0.03583161613420293,
      "attention_bam_384_attention_spatial_variance": 168.69745399233875,
      "attention_bam_384_attention_spatial_std": 12.988358402521035,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 13.917834979235522,
      "attention_bam_384_peak_intensity_mean": 0.2596208155155182,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24608412384986877,
      "attention_bam_16_std_attention": 0.5414301753044128,
      "attention_bam_16_max_attention": 4.2208251953125,
      "attention_bam_16_min_attention": -1.28076171875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.252109324031718,
      "attention_bam_16_attention_skewness": 1.0396536944166843,
      "attention_bam_16_attention_sparsity": 0.426025390625,
      "attention_bam_16_attention_concentration_10": 0.5339119264522136,
      "attention_bam_16_attention_concentration_20": 0.8408373987604678,
      "attention_bam_16_attention_center_y": 0.4765246746911699,
      "attention_bam_16_attention_center_x": 0.4689797949325313,
      "attention_bam_16_attention_center_distance": 0.0550153436921594,
      "attention_bam_16_attention_spatial_variance": 41.60606606801984,
      "attention_bam_16_attention_spatial_std": 6.450276433457704,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.263764654601964,
      "attention_bam_16_peak_intensity_mean": 0.2825165092945099,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 5,
      "phase": "train",
      "loss": 0.45334145426750183,
      "timestamp": 1759561886.964522,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.45334145426750183,
      "ssim": 0.0006481515010818839,
      "attention_bam_384_mean_attention": 0.23825156688690186,
      "attention_bam_384_std_attention": 0.5795870423316956,
      "attention_bam_384_max_attention": 5.154296875,
      "attention_bam_384_min_attention": -1.2939453125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.21181178454695,
      "attention_bam_384_attention_skewness": 0.6765672392983002,
      "attention_bam_384_attention_sparsity": 0.433319091796875,
      "attention_bam_384_attention_concentration_10": 0.5792252472856618,
      "attention_bam_384_attention_concentration_20": 0.9204517764693186,
      "attention_bam_384_attention_center_y": 0.4890084740976202,
      "attention_bam_384_attention_center_x": 0.4852378459580533,
      "attention_bam_384_attention_center_distance": 0.02602824748694575,
      "attention_bam_384_attention_spatial_variance": 169.49214312562054,
      "attention_bam_384_attention_spatial_std": 13.018914821352068,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 15.943614546826382,
      "attention_bam_384_peak_intensity_mean": 0.23916293680667877,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22865775227546692,
      "attention_bam_16_std_attention": 0.5442461371421814,
      "attention_bam_16_max_attention": 3.38934326171875,
      "attention_bam_16_min_attention": -0.9951171875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.480605941100677,
      "attention_bam_16_attention_skewness": 0.9339807570108357,
      "attention_bam_16_attention_sparsity": 0.423095703125,
      "attention_bam_16_attention_concentration_10": 0.5703094605191307,
      "attention_bam_16_attention_concentration_20": 0.8915840260701801,
      "attention_bam_16_attention_center_y": 0.47432327301586513,
      "attention_bam_16_attention_center_x": 0.4718586965532351,
      "attention_bam_16_attention_center_distance": 0.05387443305132226,
      "attention_bam_16_attention_spatial_variance": 41.767421490534254,
      "attention_bam_16_attention_spatial_std": 6.462771966465648,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 7.9374453949347235,
      "attention_bam_16_peak_intensity_mean": 0.2822211980819702,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 6,
      "phase": "train",
      "loss": 0.4858403205871582,
      "timestamp": 1759561887.136022,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.4858403205871582,
      "ssim": 0.0030935481190681458,
      "attention_bam_384_mean_attention": 0.239176943898201,
      "attention_bam_384_std_attention": 0.5839954018592834,
      "attention_bam_384_max_attention": 5.7822265625,
      "attention_bam_384_min_attention": -1.3358154296875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7911144873548648,
      "attention_bam_384_attention_skewness": 0.5868238725319901,
      "attention_bam_384_attention_sparsity": 0.43982187906901044,
      "attention_bam_384_attention_concentration_10": 0.5747936771119917,
      "attention_bam_384_attention_concentration_20": 0.9257709435901649,
      "attention_bam_384_attention_center_y": 0.4892179356511552,
      "attention_bam_384_attention_center_x": 0.48577622731973974,
      "attention_bam_384_attention_center_distance": 0.02524157764016935,
      "attention_bam_384_attention_spatial_variance": 171.01781698989254,
      "attention_bam_384_attention_spatial_std": 13.077378062512857,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 18.426053848297446,
      "attention_bam_384_peak_intensity_mean": 0.22272942960262299,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23707067966461182,
      "attention_bam_16_std_attention": 0.5264033675193787,
      "attention_bam_16_max_attention": 2.66021728515625,
      "attention_bam_16_min_attention": -1.11883544921875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.613426195190788,
      "attention_bam_16_attention_skewness": 0.6182504270224477,
      "attention_bam_16_attention_sparsity": 0.43017578125,
      "attention_bam_16_attention_concentration_10": 0.5409360569926689,
      "attention_bam_16_attention_concentration_20": 0.8591459943703753,
      "attention_bam_16_attention_center_y": 0.479302486716333,
      "attention_bam_16_attention_center_x": 0.4714061726132226,
      "attention_bam_16_attention_center_distance": 0.04991981612050254,
      "attention_bam_16_attention_spatial_variance": 42.177045671452255,
      "attention_bam_16_attention_spatial_std": 6.494385703933226,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 7.928983251355613,
      "attention_bam_16_peak_intensity_mean": 0.367025226354599,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 7,
      "phase": "train",
      "loss": 0.4560016989707947,
      "timestamp": 1759561887.3043792,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.4560016989707947,
      "ssim": 0.002819655928760767,
      "attention_bam_384_mean_attention": 0.232966348528862,
      "attention_bam_384_std_attention": 0.6516706943511963,
      "attention_bam_384_max_attention": 5.85888671875,
      "attention_bam_384_min_attention": -1.4969482421875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1122782481201305,
      "attention_bam_384_attention_skewness": 0.7272043230720782,
      "attention_bam_384_attention_sparsity": 0.45753224690755206,
      "attention_bam_384_attention_concentration_10": 0.6560878012003808,
      "attention_bam_384_attention_concentration_20": 1.034536969599685,
      "attention_bam_384_attention_center_y": 0.47840616145127973,
      "attention_bam_384_attention_center_x": 0.48878241626533986,
      "attention_bam_384_attention_center_distance": 0.034413022189639465,
      "attention_bam_384_attention_spatial_variance": 171.65104658316136,
      "attention_bam_384_attention_spatial_std": 13.101566569809938,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 18.419209632304916,
      "attention_bam_384_peak_intensity_mean": 0.23894982039928436,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22480495274066925,
      "attention_bam_16_std_attention": 0.6070523858070374,
      "attention_bam_16_max_attention": 3.418914794921875,
      "attention_bam_16_min_attention": -1.285400390625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.9005046331571092,
      "attention_bam_16_attention_skewness": 0.7159868201185197,
      "attention_bam_16_attention_sparsity": 0.462646484375,
      "attention_bam_16_attention_concentration_10": 0.63551933014498,
      "attention_bam_16_attention_concentration_20": 1.0070298391058048,
      "attention_bam_16_attention_center_y": 0.46922082166700074,
      "attention_bam_16_attention_center_x": 0.4725121492172216,
      "attention_bam_16_attention_center_distance": 0.05835991363103377,
      "attention_bam_16_attention_spatial_variance": 42.43074090568345,
      "attention_bam_16_attention_spatial_std": 6.513888309272999,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 8.992868689348464,
      "attention_bam_16_peak_intensity_mean": 0.3321414589881897,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 8,
      "phase": "train",
      "loss": 0.4709603190422058,
      "timestamp": 1759561887.4727755,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.4709603190422058,
      "ssim": 0.002096948679536581,
      "attention_bam_384_mean_attention": 0.24090266227722168,
      "attention_bam_384_std_attention": 0.5347017645835876,
      "attention_bam_384_max_attention": 6.17578125,
      "attention_bam_384_min_attention": -1.2586669921875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.0151457347433865,
      "attention_bam_384_attention_skewness": 0.6977032458782128,
      "attention_bam_384_attention_sparsity": 0.42211151123046875,
      "attention_bam_384_attention_concentration_10": 0.5297907353285553,
      "attention_bam_384_attention_concentration_20": 0.8521156404751321,
      "attention_bam_384_attention_center_y": 0.48831487380111066,
      "attention_bam_384_attention_center_x": 0.48565524395911286,
      "attention_bam_384_attention_center_distance": 0.026165404646461637,
      "attention_bam_384_attention_spatial_variance": 169.94338579828192,
      "attention_bam_384_attention_spatial_std": 13.03623357409194,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 15.558328156855547,
      "attention_bam_384_peak_intensity_mean": 0.20002229511737823,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23067566752433777,
      "attention_bam_16_std_attention": 0.48392632603645325,
      "attention_bam_16_max_attention": 3.1092529296875,
      "attention_bam_16_min_attention": -1.02569580078125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.6400896152557625,
      "attention_bam_16_attention_skewness": 0.7410729468412586,
      "attention_bam_16_attention_sparsity": 0.417724609375,
      "attention_bam_16_attention_concentration_10": 0.5113211676505286,
      "attention_bam_16_attention_concentration_20": 0.8138757816096951,
      "attention_bam_16_attention_center_y": 0.4809635201054975,
      "attention_bam_16_attention_center_x": 0.467113892898642,
      "attention_bam_16_attention_center_distance": 0.05373794947810692,
      "attention_bam_16_attention_spatial_variance": 42.665321303001676,
      "attention_bam_16_attention_spatial_std": 6.531869663656929,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.112248662552393,
      "attention_bam_16_peak_intensity_mean": 0.3068339228630066,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 9,
      "phase": "train",
      "loss": 0.44120165705680847,
      "timestamp": 1759561887.6396368,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.44120165705680847,
      "ssim": 0.0015531770186498761,
      "attention_bam_384_mean_attention": 0.2386624813079834,
      "attention_bam_384_std_attention": 0.6243621706962585,
      "attention_bam_384_max_attention": 5.7490234375,
      "attention_bam_384_min_attention": -1.3917236328125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7929839887477388,
      "attention_bam_384_attention_skewness": 0.5370521673129613,
      "attention_bam_384_attention_sparsity": 0.4377237955729167,
      "attention_bam_384_attention_concentration_10": 0.5989521053295174,
      "attention_bam_384_attention_concentration_20": 0.9687488033074465,
      "attention_bam_384_attention_center_y": 0.48184348954467254,
      "attention_bam_384_attention_center_x": 0.48396136784914057,
      "attention_bam_384_attention_center_distance": 0.03426066529374457,
      "attention_bam_384_attention_spatial_variance": 168.049396206901,
      "attention_bam_384_attention_spatial_std": 12.963386756820187,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 14.95450373565302,
      "attention_bam_384_peak_intensity_mean": 0.23023447394371033,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23995989561080933,
      "attention_bam_16_std_attention": 0.5747243762016296,
      "attention_bam_16_max_attention": 2.5950927734375,
      "attention_bam_16_min_attention": -1.1875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5440129785350609,
      "attention_bam_16_attention_skewness": 0.43301634536227973,
      "attention_bam_16_attention_sparsity": 0.413818359375,
      "attention_bam_16_attention_concentration_10": 0.5563420129659812,
      "attention_bam_16_attention_concentration_20": 0.9065293891223881,
      "attention_bam_16_attention_center_y": 0.4700431452491051,
      "attention_bam_16_attention_center_x": 0.4678168088250252,
      "attention_bam_16_attention_center_distance": 0.06217991541922825,
      "attention_bam_16_attention_spatial_variance": 42.200369005721384,
      "attention_bam_16_attention_spatial_std": 6.496181109368902,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.990187135814832,
      "attention_bam_16_peak_intensity_mean": 0.3892548978328705,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 10,
      "phase": "train",
      "loss": 0.4198513925075531,
      "timestamp": 1759561887.914069,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.4198513925075531,
      "ssim": 0.001457405393011868,
      "attention_bam_384_mean_attention": 0.2305784970521927,
      "attention_bam_384_std_attention": 0.5653135180473328,
      "attention_bam_384_max_attention": 5.724609375,
      "attention_bam_384_min_attention": -1.414794921875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5957995737240376,
      "attention_bam_384_attention_skewness": 0.741398018974984,
      "attention_bam_384_attention_sparsity": 0.43711598714192706,
      "attention_bam_384_attention_concentration_10": 0.5813972224643826,
      "attention_bam_384_attention_concentration_20": 0.9228012555537802,
      "attention_bam_384_attention_center_y": 0.4766546812227461,
      "attention_bam_384_attention_center_x": 0.47673215211139575,
      "attention_bam_384_attention_center_distance": 0.04661323104396063,
      "attention_bam_384_attention_spatial_variance": 170.7517006975137,
      "attention_bam_384_attention_spatial_std": 13.067199420591763,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 21.36602736143575,
      "attention_bam_384_peak_intensity_mean": 0.23476500809192657,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21765072643756866,
      "attention_bam_16_std_attention": 0.49605050683021545,
      "attention_bam_16_max_attention": 3.25384521484375,
      "attention_bam_16_min_attention": -1.009033203125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.114381506721597,
      "attention_bam_16_attention_skewness": 0.8242034441314291,
      "attention_bam_16_attention_sparsity": 0.432373046875,
      "attention_bam_16_attention_concentration_10": 0.5352786295545557,
      "attention_bam_16_attention_concentration_20": 0.8647701370812099,
      "attention_bam_16_attention_center_y": 0.4647428056750229,
      "attention_bam_16_attention_center_x": 0.46682177341139336,
      "attention_bam_16_attention_center_distance": 0.06846699162712089,
      "attention_bam_16_attention_spatial_variance": 41.92946109243847,
      "attention_bam_16_attention_spatial_std": 6.475296216578704,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.241694519456756,
      "attention_bam_16_peak_intensity_mean": 0.29687198996543884,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 11,
      "phase": "train",
      "loss": 0.5250172019004822,
      "timestamp": 1759561888.0843654,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.5250172019004822,
      "ssim": 0.0006150297704152763,
      "attention_bam_384_mean_attention": 0.23817576467990875,
      "attention_bam_384_std_attention": 0.6111212968826294,
      "attention_bam_384_max_attention": 5.970703125,
      "attention_bam_384_min_attention": -1.396728515625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.3031715253746032,
      "attention_bam_384_attention_skewness": 0.586484136260003,
      "attention_bam_384_attention_sparsity": 0.4292653401692708,
      "attention_bam_384_attention_concentration_10": 0.5982743759289552,
      "attention_bam_384_attention_concentration_20": 0.9585861567850703,
      "attention_bam_384_attention_center_y": 0.484743055607845,
      "attention_bam_384_attention_center_x": 0.4864963751157407,
      "attention_bam_384_attention_center_distance": 0.02881396318454295,
      "attention_bam_384_attention_spatial_variance": 169.68303378929812,
      "attention_bam_384_attention_spatial_std": 13.026244039987048,
      "attention_bam_384_num_attention_peaks": 20,
      "attention_bam_384_peak_separation_mean": 16.41047690734079,
      "attention_bam_384_peak_intensity_mean": 0.22255556285381317,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2470933347940445,
      "attention_bam_16_std_attention": 0.577705442905426,
      "attention_bam_16_max_attention": 3.7723388671875,
      "attention_bam_16_min_attention": -1.208740234375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7828309586074256,
      "attention_bam_16_attention_skewness": 0.4356238081947762,
      "attention_bam_16_attention_sparsity": 0.41064453125,
      "attention_bam_16_attention_concentration_10": 0.5384639738827508,
      "attention_bam_16_attention_concentration_20": 0.8768400580947684,
      "attention_bam_16_attention_center_y": 0.46900830276961736,
      "attention_bam_16_attention_center_x": 0.4625636864302809,
      "attention_bam_16_attention_center_distance": 0.06873082090168925,
      "attention_bam_16_attention_spatial_variance": 41.817843673040684,
      "attention_bam_16_attention_spatial_std": 6.466671761659214,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 6.808357026090837,
      "attention_bam_16_peak_intensity_mean": 0.2987084686756134,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 12,
      "phase": "train",
      "loss": 0.5536743402481079,
      "timestamp": 1759561888.2541296,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.5536743402481079,
      "ssim": 0.004162087105214596,
      "attention_bam_384_mean_attention": 0.24686604738235474,
      "attention_bam_384_std_attention": 0.41523653268814087,
      "attention_bam_384_max_attention": 6.2802734375,
      "attention_bam_384_min_attention": -1.354736328125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.839608499877526,
      "attention_bam_384_attention_skewness": 0.40975244281098694,
      "attention_bam_384_attention_sparsity": 0.337982177734375,
      "attention_bam_384_attention_concentration_10": 0.40365290629705286,
      "attention_bam_384_attention_concentration_20": 0.6605103751053127,
      "attention_bam_384_attention_center_y": 0.4845542781308059,
      "attention_bam_384_attention_center_x": 0.48389494299004193,
      "attention_bam_384_attention_center_distance": 0.031557667383838736,
      "attention_bam_384_attention_spatial_variance": 168.5681863574323,
      "attention_bam_384_attention_spatial_std": 12.983381160446315,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 17.49570255895203,
      "attention_bam_384_peak_intensity_mean": 0.20963945984840393,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24113669991493225,
      "attention_bam_16_std_attention": 0.3448593020439148,
      "attention_bam_16_max_attention": 2.744873046875,
      "attention_bam_16_min_attention": -0.902099609375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.4757646303591372,
      "attention_bam_16_attention_skewness": 0.17112444103071991,
      "attention_bam_16_attention_sparsity": 0.330322265625,
      "attention_bam_16_attention_concentration_10": 0.34678042392592845,
      "attention_bam_16_attention_concentration_20": 0.5869969306119315,
      "attention_bam_16_attention_center_y": 0.4777158104868729,
      "attention_bam_16_attention_center_x": 0.4688785632380198,
      "attention_bam_16_attention_center_distance": 0.05413185621031107,
      "attention_bam_16_attention_spatial_variance": 41.89478802771091,
      "attention_bam_16_attention_spatial_std": 6.472618328598629,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 8.19335436855237,
      "attention_bam_16_peak_intensity_mean": 0.31903308629989624,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 13,
      "phase": "train",
      "loss": 0.4588035047054291,
      "timestamp": 1759561888.4239938,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.4588035047054291,
      "ssim": 0.0010963589884340763,
      "attention_bam_384_mean_attention": 0.22783994674682617,
      "attention_bam_384_std_attention": 0.626022458076477,
      "attention_bam_384_max_attention": 4.6790771484375,
      "attention_bam_384_min_attention": -1.2996826171875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.3489393612556198,
      "attention_bam_384_attention_skewness": 0.9959727565562077,
      "attention_bam_384_attention_sparsity": 0.4560190836588542,
      "attention_bam_384_attention_concentration_10": 0.64931768397106,
      "attention_bam_384_attention_concentration_20": 1.0114700947715736,
      "attention_bam_384_attention_center_y": 0.48366931938053054,
      "attention_bam_384_attention_center_x": 0.47977235624793335,
      "attention_bam_384_attention_center_distance": 0.036765437608048034,
      "attention_bam_384_attention_spatial_variance": 168.00197995581308,
      "attention_bam_384_attention_spatial_std": 12.961557775044367,
      "attention_bam_384_num_attention_peaks": 2,
      "attention_bam_384_peak_separation_mean": 22.846279163767978,
      "attention_bam_384_peak_intensity_mean": 0.257546067237854,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22542516887187958,
      "attention_bam_16_std_attention": 0.5221493244171143,
      "attention_bam_16_max_attention": 3.439208984375,
      "attention_bam_16_min_attention": -1.1553955078125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.0125144458828235,
      "attention_bam_16_attention_skewness": 0.7766793692075744,
      "attention_bam_16_attention_sparsity": 0.4208984375,
      "attention_bam_16_attention_concentration_10": 0.5416607862949514,
      "attention_bam_16_attention_concentration_20": 0.865156308873474,
      "attention_bam_16_attention_center_y": 0.4737184370756668,
      "attention_bam_16_attention_center_x": 0.4697026267099578,
      "attention_bam_16_attention_center_distance": 0.05672127251784547,
      "attention_bam_16_attention_spatial_variance": 42.33413834811927,
      "attention_bam_16_attention_spatial_std": 6.506468961588864,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.209120502519376,
      "attention_bam_16_peak_intensity_mean": 0.30324259400367737,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 14,
      "phase": "train",
      "loss": 0.4143281579017639,
      "timestamp": 1759561888.5909503,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.4143281579017639,
      "ssim": 0.0005208884831517935,
      "attention_bam_384_mean_attention": 0.22821541130542755,
      "attention_bam_384_std_attention": 0.4802074432373047,
      "attention_bam_384_max_attention": 4.38232421875,
      "attention_bam_384_min_attention": -1.2034912109375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9001149091319003,
      "attention_bam_384_attention_skewness": 0.5166115888283378,
      "attention_bam_384_attention_sparsity": 0.41150156656901044,
      "attention_bam_384_attention_concentration_10": 0.501384978728809,
      "attention_bam_384_attention_concentration_20": 0.8138220676904019,
      "attention_bam_384_attention_center_y": 0.48084136165847663,
      "attention_bam_384_attention_center_x": 0.48806759186745363,
      "attention_bam_384_attention_center_distance": 0.0319197677605257,
      "attention_bam_384_attention_spatial_variance": 167.40873600883845,
      "attention_bam_384_attention_spatial_std": 12.93865278956192,
      "attention_bam_384_num_attention_peaks": 4,
      "attention_bam_384_peak_separation_mean": 15.48193666506358,
      "attention_bam_384_peak_intensity_mean": 0.25933170318603516,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23241965472698212,
      "attention_bam_16_std_attention": 0.4000910520553589,
      "attention_bam_16_max_attention": 2.1201171875,
      "attention_bam_16_min_attention": -1.0460205078125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8525213203925515,
      "attention_bam_16_attention_skewness": 0.413773414564646,
      "attention_bam_16_attention_sparsity": 0.369873046875,
      "attention_bam_16_attention_concentration_10": 0.4195136387585194,
      "attention_bam_16_attention_concentration_20": 0.6876138930349529,
      "attention_bam_16_attention_center_y": 0.4685943500284337,
      "attention_bam_16_attention_center_x": 0.46921808163789347,
      "attention_bam_16_attention_center_distance": 0.06219069622038226,
      "attention_bam_16_attention_spatial_variance": 41.730401808850125,
      "attention_bam_16_attention_spatial_std": 6.459907260081225,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 7.673835057945997,
      "attention_bam_16_peak_intensity_mean": 0.40526553988456726,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 15,
      "phase": "train",
      "loss": 0.420686811208725,
      "timestamp": 1759561888.7581387,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.420686811208725,
      "ssim": 0.0008906464790925384,
      "attention_bam_384_mean_attention": 0.2300127148628235,
      "attention_bam_384_std_attention": 0.6279935836791992,
      "attention_bam_384_max_attention": 4.27099609375,
      "attention_bam_384_min_attention": -1.257568359375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8425287749431076,
      "attention_bam_384_attention_skewness": 0.659565534934107,
      "attention_bam_384_attention_sparsity": 0.44695790608723956,
      "attention_bam_384_attention_concentration_10": 0.6318923022610067,
      "attention_bam_384_attention_concentration_20": 1.0063567862916474,
      "attention_bam_384_attention_center_y": 0.48057429874770324,
      "attention_bam_384_attention_center_x": 0.481355456716505,
      "attention_bam_384_attention_center_distance": 0.03807825792742107,
      "attention_bam_384_attention_spatial_variance": 167.666654237019,
      "attention_bam_384_attention_spatial_std": 12.94861591974289,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 15.320562050298847,
      "attention_bam_384_peak_intensity_mean": 0.271147757768631,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2325185239315033,
      "attention_bam_16_std_attention": 0.5843653678894043,
      "attention_bam_16_max_attention": 3.4407958984375,
      "attention_bam_16_min_attention": -1.2890625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.2047561706211969,
      "attention_bam_16_attention_skewness": 0.6538982284589429,
      "attention_bam_16_attention_sparsity": 0.427490234375,
      "attention_bam_16_attention_concentration_10": 0.5856363993551964,
      "attention_bam_16_attention_concentration_20": 0.9281680901545155,
      "attention_bam_16_attention_center_y": 0.4661793758436179,
      "attention_bam_16_attention_center_x": 0.47393724864508396,
      "attention_bam_16_attention_center_distance": 0.06038379959087426,
      "attention_bam_16_attention_spatial_variance": 42.319042264650946,
      "attention_bam_16_attention_spatial_std": 6.505308775504123,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.168482576159423,
      "attention_bam_16_peak_intensity_mean": 0.32268139719963074,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 16,
      "phase": "train",
      "loss": 0.3505541682243347,
      "timestamp": 1759561888.9253416,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3505541682243347,
      "ssim": 0.0010726412292569876,
      "attention_bam_384_mean_attention": 0.2351071834564209,
      "attention_bam_384_std_attention": 0.455392062664032,
      "attention_bam_384_max_attention": 4.07421875,
      "attention_bam_384_min_attention": -1.24267578125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5462567093505264,
      "attention_bam_384_attention_skewness": 0.44866465830705426,
      "attention_bam_384_attention_sparsity": 0.4034474690755208,
      "attention_bam_384_attention_concentration_10": 0.46343519306307024,
      "attention_bam_384_attention_concentration_20": 0.7623251844872623,
      "attention_bam_384_attention_center_y": 0.48713005886629623,
      "attention_bam_384_attention_center_x": 0.484401139680375,
      "attention_bam_384_attention_center_distance": 0.028599294678581532,
      "attention_bam_384_attention_spatial_variance": 170.93288231648125,
      "attention_bam_384_attention_spatial_std": 13.074130269982827,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 16.022186149912294,
      "attention_bam_384_peak_intensity_mean": 0.2815971076488495,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.244666188955307,
      "attention_bam_16_std_attention": 0.3875468075275421,
      "attention_bam_16_max_attention": 2.07183837890625,
      "attention_bam_16_min_attention": -0.79248046875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.3464903812522411,
      "attention_bam_16_attention_skewness": 0.22619211349933385,
      "attention_bam_16_attention_sparsity": 0.3525390625,
      "attention_bam_16_attention_concentration_10": 0.38806432928725937,
      "attention_bam_16_attention_concentration_20": 0.644089536251884,
      "attention_bam_16_attention_center_y": 0.4713572486753919,
      "attention_bam_16_attention_center_x": 0.472921716458883,
      "attention_bam_16_attention_center_distance": 0.05574299315566876,
      "attention_bam_16_attention_spatial_variance": 41.77901038640821,
      "attention_bam_16_attention_spatial_std": 6.463668492923211,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.727620205271657,
      "attention_bam_16_peak_intensity_mean": 0.36544889211654663,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 17,
      "phase": "train",
      "loss": 0.4083728790283203,
      "timestamp": 1759561889.0909243,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.4083728790283203,
      "ssim": 1.1694035492837429e-05,
      "attention_bam_384_mean_attention": 0.22309525310993195,
      "attention_bam_384_std_attention": 0.533692479133606,
      "attention_bam_384_max_attention": 4.45916748046875,
      "attention_bam_384_min_attention": -1.23388671875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.544587836649698,
      "attention_bam_384_attention_skewness": 0.9223814421822987,
      "attention_bam_384_attention_sparsity": 0.4303334554036458,
      "attention_bam_384_attention_concentration_10": 0.5756671801104222,
      "attention_bam_384_attention_concentration_20": 0.9012274917104631,
      "attention_bam_384_attention_center_y": 0.4871925056094225,
      "attention_bam_384_attention_center_x": 0.48787690603049955,
      "attention_bam_384_attention_center_distance": 0.024939980752118153,
      "attention_bam_384_attention_spatial_variance": 169.89145948336247,
      "attention_bam_384_attention_spatial_std": 13.034241807000608,
      "attention_bam_384_num_attention_peaks": 4,
      "attention_bam_384_peak_separation_mean": 21.5188925645129,
      "attention_bam_384_peak_intensity_mean": 0.2576117515563965,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22663649916648865,
      "attention_bam_16_std_attention": 0.4754912555217743,
      "attention_bam_16_max_attention": 3.227783203125,
      "attention_bam_16_min_attention": -0.994415283203125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.336989919326272,
      "attention_bam_16_attention_skewness": 0.9930143084424898,
      "attention_bam_16_attention_sparsity": 0.405029296875,
      "attention_bam_16_attention_concentration_10": 0.5120107620812525,
      "attention_bam_16_attention_concentration_20": 0.7991007880740658,
      "attention_bam_16_attention_center_y": 0.4649648203398738,
      "attention_bam_16_attention_center_x": 0.47049237868549704,
      "attention_bam_16_attention_center_distance": 0.06477906343036197,
      "attention_bam_16_attention_spatial_variance": 42.449067240468494,
      "attention_bam_16_attention_spatial_std": 6.515294869802018,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 9.288172455643172,
      "attention_bam_16_peak_intensity_mean": 0.2939288020133972,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 18,
      "phase": "train",
      "loss": 0.362771600484848,
      "timestamp": 1759561889.2585177,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.362771600484848,
      "ssim": 0.0003558550961315632,
      "attention_bam_384_mean_attention": 0.21454019844532013,
      "attention_bam_384_std_attention": 0.5622808933258057,
      "attention_bam_384_max_attention": 6.0714111328125,
      "attention_bam_384_min_attention": -1.218994140625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 9.624103586640981,
      "attention_bam_384_attention_skewness": 2.011180050539433,
      "attention_bam_384_attention_sparsity": 0.4417215983072917,
      "attention_bam_384_attention_concentration_10": 0.6194161561939159,
      "attention_bam_384_attention_concentration_20": 0.930453719808872,
      "attention_bam_384_attention_center_y": 0.4727514052663248,
      "attention_bam_384_attention_center_x": 0.4845249699190062,
      "attention_bam_384_attention_center_distance": 0.044316192773471305,
      "attention_bam_384_attention_spatial_variance": 169.7437119860774,
      "attention_bam_384_attention_spatial_std": 13.028572906733777,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 17.25412183415587,
      "attention_bam_384_peak_intensity_mean": 0.20034489035606384,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22808365523815155,
      "attention_bam_16_std_attention": 0.5082948207855225,
      "attention_bam_16_max_attention": 5.1500701904296875,
      "attention_bam_16_min_attention": -0.81005859375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 14.895160387256233,
      "attention_bam_16_attention_skewness": 2.413582381570918,
      "attention_bam_16_attention_sparsity": 0.40673828125,
      "attention_bam_16_attention_concentration_10": 0.5215594944162077,
      "attention_bam_16_attention_concentration_20": 0.8003257453397133,
      "attention_bam_16_attention_center_y": 0.47447201254776483,
      "attention_bam_16_attention_center_x": 0.46844265790913553,
      "attention_bam_16_attention_center_distance": 0.05740285677910677,
      "attention_bam_16_attention_spatial_variance": 42.29586167616812,
      "attention_bam_16_attention_spatial_std": 6.50352686441504,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.90656132229367,
      "attention_bam_16_peak_intensity_mean": 0.17587736248970032,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 19,
      "phase": "train",
      "loss": 0.4095955789089203,
      "timestamp": 1759561889.4316,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.4095955789089203,
      "ssim": 0.0005955170490778983,
      "attention_bam_384_mean_attention": 0.2163437008857727,
      "attention_bam_384_std_attention": 0.599531352519989,
      "attention_bam_384_max_attention": 5.4759521484375,
      "attention_bam_384_min_attention": -1.235107421875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 4.816899004628956,
      "attention_bam_384_attention_skewness": 1.4445015911829824,
      "attention_bam_384_attention_sparsity": 0.45451609293619794,
      "attention_bam_384_attention_concentration_10": 0.6596809513509958,
      "attention_bam_384_attention_concentration_20": 0.9969606761357951,
      "attention_bam_384_attention_center_y": 0.4740247236460018,
      "attention_bam_384_attention_center_x": 0.49540775478208643,
      "attention_bam_384_attention_center_distance": 0.03730425439029786,
      "attention_bam_384_attention_spatial_variance": 171.93835588715177,
      "attention_bam_384_attention_spatial_std": 13.112526678224597,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 16.605063569294263,
      "attention_bam_384_peak_intensity_mean": 0.21976801753044128,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2095968872308731,
      "attention_bam_16_std_attention": 0.49391278624534607,
      "attention_bam_16_max_attention": 3.6187820434570312,
      "attention_bam_16_min_attention": -0.901611328125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 5.448974488045083,
      "attention_bam_16_attention_skewness": 1.3101961236473323,
      "attention_bam_16_attention_sparsity": 0.433837890625,
      "attention_bam_16_attention_concentration_10": 0.5432608248776158,
      "attention_bam_16_attention_concentration_20": 0.8573518949290105,
      "attention_bam_16_attention_center_y": 0.47299707770967764,
      "attention_bam_16_attention_center_x": 0.47502680919905305,
      "attention_bam_16_attention_center_distance": 0.05201572975548242,
      "attention_bam_16_attention_spatial_variance": 42.619450655576706,
      "attention_bam_16_attention_spatial_std": 6.528357424006187,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.784318936344002,
      "attention_bam_16_peak_intensity_mean": 0.2528820335865021,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 20,
      "phase": "train",
      "loss": 0.493151992559433,
      "timestamp": 1759561889.7458375,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.493151992559433,
      "ssim": -0.0018198546022176743,
      "attention_bam_384_mean_attention": 0.24042940139770508,
      "attention_bam_384_std_attention": 0.6084676384925842,
      "attention_bam_384_max_attention": 4.34765625,
      "attention_bam_384_min_attention": -1.3076171875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.16138050116226088,
      "attention_bam_384_attention_skewness": 0.42101307847527825,
      "attention_bam_384_attention_sparsity": 0.4270375569661458,
      "attention_bam_384_attention_concentration_10": 0.5723852114598201,
      "attention_bam_384_attention_concentration_20": 0.9349130268646572,
      "attention_bam_384_attention_center_y": 0.4836135107520447,
      "attention_bam_384_attention_center_x": 0.47951705801639877,
      "attention_bam_384_attention_center_distance": 0.03709630553510496,
      "attention_bam_384_attention_spatial_variance": 167.19952736979624,
      "attention_bam_384_attention_spatial_std": 12.930565624511413,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 12.8653225085155,
      "attention_bam_384_peak_intensity_mean": 0.27862653136253357,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2676053047180176,
      "attention_bam_16_std_attention": 0.5482960939407349,
      "attention_bam_16_max_attention": 2.42578125,
      "attention_bam_16_min_attention": -1.079833984375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.05154328961484156,
      "attention_bam_16_attention_skewness": 0.38190537906592514,
      "attention_bam_16_attention_sparsity": 0.402587890625,
      "attention_bam_16_attention_concentration_10": 0.48320333868046667,
      "attention_bam_16_attention_concentration_20": 0.804043758645858,
      "attention_bam_16_attention_center_y": 0.4768061572428521,
      "attention_bam_16_attention_center_x": 0.4732510514696106,
      "attention_bam_16_attention_center_distance": 0.05006916394997471,
      "attention_bam_16_attention_spatial_variance": 42.37891650020156,
      "attention_bam_16_attention_spatial_std": 6.509909100763355,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.285930568174674,
      "attention_bam_16_peak_intensity_mean": 0.3930264413356781,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 21,
      "phase": "train",
      "loss": 0.37550705671310425,
      "timestamp": 1759561889.9269798,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.37550705671310425,
      "ssim": -0.0015474576503038406,
      "attention_bam_384_mean_attention": 0.21498708426952362,
      "attention_bam_384_std_attention": 0.6306966543197632,
      "attention_bam_384_max_attention": 5.6865234375,
      "attention_bam_384_min_attention": -1.2279052734375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5450835734580313,
      "attention_bam_384_attention_skewness": 0.7984837175018211,
      "attention_bam_384_attention_sparsity": 0.4607035319010417,
      "attention_bam_384_attention_concentration_10": 0.6710911373747965,
      "attention_bam_384_attention_concentration_20": 1.0679750965143728,
      "attention_bam_384_attention_center_y": 0.477049012430863,
      "attention_bam_384_attention_center_x": 0.48302031511971283,
      "attention_bam_384_attention_center_distance": 0.04037468338036928,
      "attention_bam_384_attention_spatial_variance": 169.6455831707751,
      "attention_bam_384_attention_spatial_std": 13.024806454253941,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 12.779439230244682,
      "attention_bam_384_peak_intensity_mean": 0.21195895969867706,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23376663029193878,
      "attention_bam_16_std_attention": 0.6153234243392944,
      "attention_bam_16_max_attention": 4.660003662109375,
      "attention_bam_16_min_attention": -1.257080078125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.2462003097303684,
      "attention_bam_16_attention_skewness": 0.9283255458015099,
      "attention_bam_16_attention_sparsity": 0.436279296875,
      "attention_bam_16_attention_concentration_10": 0.5944671828955764,
      "attention_bam_16_attention_concentration_20": 0.9517723088517221,
      "attention_bam_16_attention_center_y": 0.46629612195496745,
      "attention_bam_16_attention_center_x": 0.47810845098852217,
      "attention_bam_16_attention_center_distance": 0.05683645508643838,
      "attention_bam_16_attention_spatial_variance": 42.47954361440215,
      "attention_bam_16_attention_spatial_std": 6.517633283209646,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.377149398234952,
      "attention_bam_16_peak_intensity_mean": 0.2566264569759369,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 22,
      "phase": "train",
      "loss": 0.39059171080589294,
      "timestamp": 1759561890.0942419,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.39059171080589294,
      "ssim": 0.0008436451898887753,
      "attention_bam_384_mean_attention": 0.21690350770950317,
      "attention_bam_384_std_attention": 0.5047915577888489,
      "attention_bam_384_max_attention": 4.642425537109375,
      "attention_bam_384_min_attention": -1.227783203125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8064602109677121,
      "attention_bam_384_attention_skewness": 0.7335254661819224,
      "attention_bam_384_attention_sparsity": 0.42979685465494794,
      "attention_bam_384_attention_concentration_10": 0.5447007912623865,
      "attention_bam_384_attention_concentration_20": 0.8723040372126731,
      "attention_bam_384_attention_center_y": 0.47484425496644833,
      "attention_bam_384_attention_center_x": 0.48571724554841456,
      "attention_bam_384_attention_center_distance": 0.04090986636295316,
      "attention_bam_384_attention_spatial_variance": 171.65163257500538,
      "attention_bam_384_attention_spatial_std": 13.101588933217428,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 17.417528545987125,
      "attention_bam_384_peak_intensity_mean": 0.2568003535270691,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22295132279396057,
      "attention_bam_16_std_attention": 0.43865546584129333,
      "attention_bam_16_max_attention": 3.1556568145751953,
      "attention_bam_16_min_attention": -0.821044921875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.5064170268410706,
      "attention_bam_16_attention_skewness": 0.6850451824271553,
      "attention_bam_16_attention_sparsity": 0.385986328125,
      "attention_bam_16_attention_concentration_10": 0.4566023548925038,
      "attention_bam_16_attention_concentration_20": 0.7368764624458392,
      "attention_bam_16_attention_center_y": 0.4649586440922867,
      "attention_bam_16_attention_center_x": 0.47570097177294784,
      "attention_bam_16_attention_center_distance": 0.06030488200187627,
      "attention_bam_16_attention_spatial_variance": 42.95384011839228,
      "attention_bam_16_attention_spatial_std": 6.553917921243161,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 11.299776698468884,
      "attention_bam_16_peak_intensity_mean": 0.2690442204475403,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 23,
      "phase": "train",
      "loss": 0.3740243911743164,
      "timestamp": 1759561890.2651184,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3740243911743164,
      "ssim": 0.0014891541795805097,
      "attention_bam_384_mean_attention": 0.21272824704647064,
      "attention_bam_384_std_attention": 0.550478994846344,
      "attention_bam_384_max_attention": 5.05908203125,
      "attention_bam_384_min_attention": -1.253662109375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.344609290716928,
      "attention_bam_384_attention_skewness": 0.695600789077516,
      "attention_bam_384_attention_sparsity": 0.44581858317057294,
      "attention_bam_384_attention_concentration_10": 0.5988490387049281,
      "attention_bam_384_attention_concentration_20": 0.954789420678747,
      "attention_bam_384_attention_center_y": 0.48457475265779465,
      "attention_bam_384_attention_center_x": 0.4819133408857201,
      "attention_bam_384_attention_center_distance": 0.03361742088514163,
      "attention_bam_384_attention_spatial_variance": 171.0680720111025,
      "attention_bam_384_attention_spatial_std": 13.079299370038996,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 18.3462513524135,
      "attention_bam_384_peak_intensity_mean": 0.238263338804245,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22741693258285522,
      "attention_bam_16_std_attention": 0.5175738334655762,
      "attention_bam_16_max_attention": 4.1513671875,
      "attention_bam_16_min_attention": -1.0225830078125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.459043747144129,
      "attention_bam_16_attention_skewness": 1.0663455455627393,
      "attention_bam_16_attention_sparsity": 0.43115234375,
      "attention_bam_16_attention_concentration_10": 0.5508532081442705,
      "attention_bam_16_attention_concentration_20": 0.8654633444219817,
      "attention_bam_16_attention_center_y": 0.47431623740126744,
      "attention_bam_16_attention_center_x": 0.47314121366145917,
      "attention_bam_16_attention_center_distance": 0.05255568598748267,
      "attention_bam_16_attention_spatial_variance": 41.514125448744316,
      "attention_bam_16_attention_spatial_std": 6.443145617533746,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.131964401194235,
      "attention_bam_16_peak_intensity_mean": 0.2452806532382965,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 24,
      "phase": "train",
      "loss": 0.37603089213371277,
      "timestamp": 1759561890.4359252,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.37603089213371277,
      "ssim": -0.0019465561490505934,
      "attention_bam_384_mean_attention": 0.222737655043602,
      "attention_bam_384_std_attention": 0.4529288411140442,
      "attention_bam_384_max_attention": 4.96875,
      "attention_bam_384_min_attention": -1.265869140625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6597297297541345,
      "attention_bam_384_attention_skewness": 0.29879303043638605,
      "attention_bam_384_attention_sparsity": 0.40086110432942706,
      "attention_bam_384_attention_concentration_10": 0.4714717646530431,
      "attention_bam_384_attention_concentration_20": 0.779340335122806,
      "attention_bam_384_attention_center_y": 0.48234248182939116,
      "attention_bam_384_attention_center_x": 0.48408438635598156,
      "attention_bam_384_attention_center_distance": 0.0336182898319069,
      "attention_bam_384_attention_spatial_variance": 169.91156419366018,
      "attention_bam_384_attention_spatial_std": 13.03501301087422,
      "attention_bam_384_num_attention_peaks": 18,
      "attention_bam_384_peak_separation_mean": 16.136634286712233,
      "attention_bam_384_peak_intensity_mean": 0.24085932970046997,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23865093290805817,
      "attention_bam_16_std_attention": 0.4183272421360016,
      "attention_bam_16_max_attention": 2.42681884765625,
      "attention_bam_16_min_attention": -0.87060546875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.9065327943389447,
      "attention_bam_16_attention_skewness": 0.4126014536596339,
      "attention_bam_16_attention_sparsity": 0.382568359375,
      "attention_bam_16_attention_concentration_10": 0.42591763539009875,
      "attention_bam_16_attention_concentration_20": 0.7018853438573897,
      "attention_bam_16_attention_center_y": 0.4676718857566496,
      "attention_bam_16_attention_center_x": 0.46962146201673066,
      "attention_bam_16_attention_center_distance": 0.06273695148048004,
      "attention_bam_16_attention_spatial_variance": 41.46609177086312,
      "attention_bam_16_attention_spatial_std": 6.439417036569624,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 7.507787008539353,
      "attention_bam_16_peak_intensity_mean": 0.35090506076812744,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 25,
      "phase": "train",
      "loss": 0.3457426428794861,
      "timestamp": 1759561890.603324,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3457426428794861,
      "ssim": 0.0035340702161192894,
      "attention_bam_384_mean_attention": 0.21932904422283173,
      "attention_bam_384_std_attention": 0.578107476234436,
      "attention_bam_384_max_attention": 5.23291015625,
      "attention_bam_384_min_attention": -1.275390625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.4148345908673363,
      "attention_bam_384_attention_skewness": 1.1537459588359111,
      "attention_bam_384_attention_sparsity": 0.4630991617838542,
      "attention_bam_384_attention_concentration_10": 0.6496714614619592,
      "attention_bam_384_attention_concentration_20": 0.9848550509855014,
      "attention_bam_384_attention_center_y": 0.47465331838298613,
      "attention_bam_384_attention_center_x": 0.47490849117382355,
      "attention_bam_384_attention_center_distance": 0.05043883591377499,
      "attention_bam_384_attention_spatial_variance": 170.5667521486199,
      "attention_bam_384_attention_spatial_std": 13.060120678945502,
      "attention_bam_384_num_attention_peaks": 1,
      "attention_bam_384_peak_separation_mean": 0.0,
      "attention_bam_384_peak_intensity_mean": 0.2439144402742386,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22107093036174774,
      "attention_bam_16_std_attention": 0.5019516944885254,
      "attention_bam_16_max_attention": 3.0308837890625,
      "attention_bam_16_min_attention": -0.7967529296875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 4.215520083571065,
      "attention_bam_16_attention_skewness": 1.3570790287848808,
      "attention_bam_16_attention_sparsity": 0.454345703125,
      "attention_bam_16_attention_concentration_10": 0.5419073594731247,
      "attention_bam_16_attention_concentration_20": 0.8461263243951258,
      "attention_bam_16_attention_center_y": 0.47958557734606394,
      "attention_bam_16_attention_center_x": 0.47219890377590223,
      "attention_bam_16_attention_center_distance": 0.04877806071493783,
      "attention_bam_16_attention_spatial_variance": 42.21963562881199,
      "attention_bam_16_attention_spatial_std": 6.497663859327596,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 12.387782164371371,
      "attention_bam_16_peak_intensity_mean": 0.2724291980266571,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 26,
      "phase": "train",
      "loss": 0.4012865424156189,
      "timestamp": 1759561890.7716005,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.4012865424156189,
      "ssim": 0.0038994671776890755,
      "attention_bam_384_mean_attention": 0.21551842987537384,
      "attention_bam_384_std_attention": 0.49021756649017334,
      "attention_bam_384_max_attention": 4.328369140625,
      "attention_bam_384_min_attention": -1.15625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8517687149369841,
      "attention_bam_384_attention_skewness": 0.772410318619924,
      "attention_bam_384_attention_sparsity": 0.42986806233723956,
      "attention_bam_384_attention_concentration_10": 0.540644032790104,
      "attention_bam_384_attention_concentration_20": 0.8626493653131282,
      "attention_bam_384_attention_center_y": 0.4895707694488865,
      "attention_bam_384_attention_center_x": 0.49360174113056,
      "attention_bam_384_attention_center_distance": 0.01730355838829961,
      "attention_bam_384_attention_spatial_variance": 169.4586957578079,
      "attention_bam_384_attention_spatial_std": 13.01763018977755,
      "attention_bam_384_num_attention_peaks": 4,
      "attention_bam_384_peak_separation_mean": 13.754672309644404,
      "attention_bam_384_peak_intensity_mean": 0.2554244101047516,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21872954070568085,
      "attention_bam_16_std_attention": 0.4299331307411194,
      "attention_bam_16_max_attention": 2.939208984375,
      "attention_bam_16_min_attention": -0.8587646484375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.720072183149707,
      "attention_bam_16_attention_skewness": 0.8037452648170491,
      "attention_bam_16_attention_sparsity": 0.396484375,
      "attention_bam_16_attention_concentration_10": 0.4664711587650134,
      "attention_bam_16_attention_concentration_20": 0.7516209721886545,
      "attention_bam_16_attention_center_y": 0.4763052430899522,
      "attention_bam_16_attention_center_x": 0.4686749655591199,
      "attention_bam_16_attention_center_distance": 0.055546364196922576,
      "attention_bam_16_attention_spatial_variance": 42.29286765203727,
      "attention_bam_16_attention_spatial_std": 6.503296675689744,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.553848148201208,
      "attention_bam_16_peak_intensity_mean": 0.2868809700012207,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 27,
      "phase": "train",
      "loss": 0.402923047542572,
      "timestamp": 1759561890.9527428,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.402923047542572,
      "ssim": 0.004224345553666353,
      "attention_bam_384_mean_attention": 0.21660566329956055,
      "attention_bam_384_std_attention": 0.542765736579895,
      "attention_bam_384_max_attention": 3.9393310546875,
      "attention_bam_384_min_attention": -1.1630859375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.249210069833854,
      "attention_bam_384_attention_skewness": 0.902268242999902,
      "attention_bam_384_attention_sparsity": 0.43240102132161456,
      "attention_bam_384_attention_concentration_10": 0.5914638162118233,
      "attention_bam_384_attention_concentration_20": 0.917480545068191,
      "attention_bam_384_attention_center_y": 0.49454370868645703,
      "attention_bam_384_attention_center_x": 0.47533073470303994,
      "attention_bam_384_attention_center_distance": 0.03573076448076762,
      "attention_bam_384_attention_spatial_variance": 169.75581583276917,
      "attention_bam_384_attention_spatial_std": 13.029037410061004,
      "attention_bam_384_num_attention_peaks": 4,
      "attention_bam_384_peak_separation_mean": 12.703063658551827,
      "attention_bam_384_peak_intensity_mean": 0.26719096302986145,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2233433574438095,
      "attention_bam_16_std_attention": 0.47626420855522156,
      "attention_bam_16_max_attention": 2.919830322265625,
      "attention_bam_16_min_attention": -1.0098876953125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.9457916009380973,
      "attention_bam_16_attention_skewness": 0.7923427038304958,
      "attention_bam_16_attention_sparsity": 0.384033203125,
      "attention_bam_16_attention_concentration_10": 0.49052045128740807,
      "attention_bam_16_attention_concentration_20": 0.7732673023488029,
      "attention_bam_16_attention_center_y": 0.47797721826505124,
      "attention_bam_16_attention_center_x": 0.4730229399386866,
      "attention_bam_16_attention_center_distance": 0.04924966365158046,
      "attention_bam_16_attention_spatial_variance": 43.12364312525277,
      "attention_bam_16_attention_spatial_std": 6.566859456791562,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.239006317153017,
      "attention_bam_16_peak_intensity_mean": 0.3198828101158142,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 28,
      "phase": "train",
      "loss": 0.43928083777427673,
      "timestamp": 1759561891.1203306,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.43928083777427673,
      "ssim": 0.003647006582468748,
      "attention_bam_384_mean_attention": 0.2057025283575058,
      "attention_bam_384_std_attention": 0.5642521381378174,
      "attention_bam_384_max_attention": 4.2353515625,
      "attention_bam_384_min_attention": -1.385986328125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.821343804418524,
      "attention_bam_384_attention_skewness": 0.6739921996929042,
      "attention_bam_384_attention_sparsity": 0.4618326822916667,
      "attention_bam_384_attention_concentration_10": 0.6398801759468876,
      "attention_bam_384_attention_concentration_20": 1.0193764393291074,
      "attention_bam_384_attention_center_y": 0.4786039435572992,
      "attention_bam_384_attention_center_x": 0.4863800039753374,
      "attention_bam_384_attention_center_distance": 0.03586908203484063,
      "attention_bam_384_attention_spatial_variance": 170.58838052919077,
      "attention_bam_384_attention_spatial_std": 13.060948684119035,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 14.94895332394235,
      "attention_bam_384_peak_intensity_mean": 0.28559285402297974,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2503933608531952,
      "attention_bam_16_std_attention": 0.53554767370224,
      "attention_bam_16_max_attention": 2.9635238647460938,
      "attention_bam_16_min_attention": -1.2357177734375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.4695447381143172,
      "attention_bam_16_attention_skewness": 0.7718020537937061,
      "attention_bam_16_attention_sparsity": 0.41015625,
      "attention_bam_16_attention_concentration_10": 0.5200995452475157,
      "attention_bam_16_attention_concentration_20": 0.8255898998789627,
      "attention_bam_16_attention_center_y": 0.46996080961821085,
      "attention_bam_16_attention_center_x": 0.47749857217331615,
      "attention_bam_16_attention_center_distance": 0.05307856842517205,
      "attention_bam_16_attention_spatial_variance": 42.5621381585891,
      "attention_bam_16_attention_spatial_std": 6.523966443705018,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 9.024988241016132,
      "attention_bam_16_peak_intensity_mean": 0.35665878653526306,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 29,
      "phase": "train",
      "loss": 0.3707438111305237,
      "timestamp": 1759561891.292717,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3707438111305237,
      "ssim": 0.0031733594369143248,
      "attention_bam_384_mean_attention": 0.21745924651622772,
      "attention_bam_384_std_attention": 0.5478830337524414,
      "attention_bam_384_max_attention": 4.58154296875,
      "attention_bam_384_min_attention": -1.232421875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2074555436790382,
      "attention_bam_384_attention_skewness": 0.7384297766507006,
      "attention_bam_384_attention_sparsity": 0.44663747151692706,
      "attention_bam_384_attention_concentration_10": 0.5928736760491371,
      "attention_bam_384_attention_concentration_20": 0.9404427486243407,
      "attention_bam_384_attention_center_y": 0.4835030176167239,
      "attention_bam_384_attention_center_x": 0.4875655409313446,
      "attention_bam_384_attention_center_distance": 0.029215276828542625,
      "attention_bam_384_attention_spatial_variance": 166.6684114176571,
      "attention_bam_384_attention_spatial_std": 12.9100120610965,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 12.184244043545121,
      "attention_bam_384_peak_intensity_mean": 0.2522590160369873,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24974606931209564,
      "attention_bam_16_std_attention": 0.4644300639629364,
      "attention_bam_16_max_attention": 2.5527725219726562,
      "attention_bam_16_min_attention": -1.0343017578125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.9956650448106874,
      "attention_bam_16_attention_skewness": 0.5012949684117372,
      "attention_bam_16_attention_sparsity": 0.36767578125,
      "attention_bam_16_attention_concentration_10": 0.44547088559200687,
      "attention_bam_16_attention_concentration_20": 0.7196303141155803,
      "attention_bam_16_attention_center_y": 0.47464906488366754,
      "attention_bam_16_attention_center_x": 0.4760736800419561,
      "attention_bam_16_attention_center_distance": 0.04929784372580991,
      "attention_bam_16_attention_spatial_variance": 41.852809079244594,
      "attention_bam_16_attention_spatial_std": 6.4693747054290025,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 7.7512002420991974,
      "attention_bam_16_peak_intensity_mean": 0.36312732100486755,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 30,
      "phase": "train",
      "loss": 0.29498815536499023,
      "timestamp": 1759561891.5520668,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.29498815536499023,
      "ssim": 0.001561687677167356,
      "attention_bam_384_mean_attention": 0.21818973124027252,
      "attention_bam_384_std_attention": 0.5406831502914429,
      "attention_bam_384_max_attention": 4.485260009765625,
      "attention_bam_384_min_attention": -1.2236328125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.024312811342207,
      "attention_bam_384_attention_skewness": 0.7878073868877925,
      "attention_bam_384_attention_sparsity": 0.4372100830078125,
      "attention_bam_384_attention_concentration_10": 0.5696563939277686,
      "attention_bam_384_attention_concentration_20": 0.912620543225356,
      "attention_bam_384_attention_center_y": 0.4792098542573517,
      "attention_bam_384_attention_center_x": 0.4827863385513594,
      "attention_bam_384_attention_center_distance": 0.03817172515014153,
      "attention_bam_384_attention_spatial_variance": 168.7219232238291,
      "attention_bam_384_attention_spatial_std": 12.989300336193212,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 14.58877010186176,
      "attention_bam_384_peak_intensity_mean": 0.2549682557582855,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.26247477531433105,
      "attention_bam_16_std_attention": 0.49406519532203674,
      "attention_bam_16_max_attention": 3.674560546875,
      "attention_bam_16_min_attention": -1.06103515625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.3677880309501536,
      "attention_bam_16_attention_skewness": 0.885740890636933,
      "attention_bam_16_attention_sparsity": 0.37353515625,
      "attention_bam_16_attention_concentration_10": 0.44912572587985,
      "attention_bam_16_attention_concentration_20": 0.7215145303907187,
      "attention_bam_16_attention_center_y": 0.46810112677951055,
      "attention_bam_16_attention_center_x": 0.46976446633589397,
      "attention_bam_16_attention_center_distance": 0.06215666671709717,
      "attention_bam_16_attention_spatial_variance": 41.93253862216568,
      "attention_bam_16_attention_spatial_std": 6.475533848430234,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.179951337611845,
      "attention_bam_16_peak_intensity_mean": 0.2819732427597046,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 31,
      "phase": "train",
      "loss": 0.34274134039878845,
      "timestamp": 1759561891.7190928,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.34274134039878845,
      "ssim": 0.0063679707236588,
      "attention_bam_384_mean_attention": 0.2044781893491745,
      "attention_bam_384_std_attention": 0.47136953473091125,
      "attention_bam_384_max_attention": 4.49755859375,
      "attention_bam_384_min_attention": -1.23974609375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.33011030812241726,
      "attention_bam_384_attention_skewness": 0.33641028840130516,
      "attention_bam_384_attention_sparsity": 0.4245096842447917,
      "attention_bam_384_attention_concentration_10": 0.5269357203904153,
      "attention_bam_384_attention_concentration_20": 0.8634982826977186,
      "attention_bam_384_attention_center_y": 0.4772295171100849,
      "attention_bam_384_attention_center_x": 0.4877041012356181,
      "attention_bam_384_attention_center_distance": 0.03659737743237474,
      "attention_bam_384_attention_spatial_variance": 171.82695940054057,
      "attention_bam_384_attention_spatial_std": 13.108278277506187,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 17.70077711137111,
      "attention_bam_384_peak_intensity_mean": 0.2534187436103821,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2310323417186737,
      "attention_bam_16_std_attention": 0.4396107494831085,
      "attention_bam_16_max_attention": 2.3121337890625,
      "attention_bam_16_min_attention": -0.8807373046875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6442235305109403,
      "attention_bam_16_attention_skewness": 0.37688969813301393,
      "attention_bam_16_attention_sparsity": 0.384521484375,
      "attention_bam_16_attention_concentration_10": 0.4541403884985843,
      "attention_bam_16_attention_concentration_20": 0.7390579837100163,
      "attention_bam_16_attention_center_y": 0.4687174124500691,
      "attention_bam_16_attention_center_x": 0.4785663738282205,
      "attention_bam_16_attention_center_distance": 0.0536283621732136,
      "attention_bam_16_attention_spatial_variance": 42.123625014818145,
      "attention_bam_16_attention_spatial_std": 6.490271567108587,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.05434849822776,
      "attention_bam_16_peak_intensity_mean": 0.35422274470329285,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 32,
      "phase": "train",
      "loss": 0.377725213766098,
      "timestamp": 1759561891.920866,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.377725213766098,
      "ssim": 0.00831372570246458,
      "attention_bam_384_mean_attention": 0.2170126587152481,
      "attention_bam_384_std_attention": 0.5399659276008606,
      "attention_bam_384_max_attention": 4.89495849609375,
      "attention_bam_384_min_attention": -1.3572998046875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.6527846622980373,
      "attention_bam_384_attention_skewness": 1.1062424757178917,
      "attention_bam_384_attention_sparsity": 0.43566131591796875,
      "attention_bam_384_attention_concentration_10": 0.5908860111666808,
      "attention_bam_384_attention_concentration_20": 0.9176829153850043,
      "attention_bam_384_attention_center_y": 0.4797135912695591,
      "attention_bam_384_attention_center_x": 0.48989204835794375,
      "attention_bam_384_attention_center_distance": 0.032053363804027075,
      "attention_bam_384_attention_spatial_variance": 170.58328130314896,
      "attention_bam_384_attention_spatial_std": 13.060753473791202,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 15.503899825451072,
      "attention_bam_384_peak_intensity_mean": 0.25646573305130005,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23467044532299042,
      "attention_bam_16_std_attention": 0.4914420247077942,
      "attention_bam_16_max_attention": 4.4869384765625,
      "attention_bam_16_min_attention": -0.9874267578125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 8.06269703597677,
      "attention_bam_16_attention_skewness": 1.6904480538850455,
      "attention_bam_16_attention_sparsity": 0.40234375,
      "attention_bam_16_attention_concentration_10": 0.5111300674482321,
      "attention_bam_16_attention_concentration_20": 0.7846283704865652,
      "attention_bam_16_attention_center_y": 0.46867966448940135,
      "attention_bam_16_attention_center_x": 0.473442085175437,
      "attention_bam_16_attention_center_distance": 0.05807385395038303,
      "attention_bam_16_attention_spatial_variance": 41.90060343056128,
      "attention_bam_16_attention_spatial_std": 6.473067544106216,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.054390390018678,
      "attention_bam_16_peak_intensity_mean": 0.2269664704799652,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 33,
      "phase": "train",
      "loss": 0.36529776453971863,
      "timestamp": 1759561892.09107,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.36529776453971863,
      "ssim": 0.006355466786772013,
      "attention_bam_384_mean_attention": 0.21562041342258453,
      "attention_bam_384_std_attention": 0.5712029337882996,
      "attention_bam_384_max_attention": 3.83349609375,
      "attention_bam_384_min_attention": -1.269287109375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.38269849285083835,
      "attention_bam_384_attention_skewness": 0.4609247513435478,
      "attention_bam_384_attention_sparsity": 0.44192250569661456,
      "attention_bam_384_attention_concentration_10": 0.5962912245999792,
      "attention_bam_384_attention_concentration_20": 0.9710147798701296,
      "attention_bam_384_attention_center_y": 0.4833559279217812,
      "attention_bam_384_attention_center_x": 0.48801228499150306,
      "attention_bam_384_attention_center_distance": 0.02900794534157442,
      "attention_bam_384_attention_spatial_variance": 169.6058686541659,
      "attention_bam_384_attention_spatial_std": 13.023281792780416,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 16.820290241221368,
      "attention_bam_384_peak_intensity_mean": 0.29167091846466064,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.25534123182296753,
      "attention_bam_16_std_attention": 0.559786319732666,
      "attention_bam_16_max_attention": 2.69183349609375,
      "attention_bam_16_min_attention": -1.205322265625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6691407795578108,
      "attention_bam_16_attention_skewness": 0.496923253826016,
      "attention_bam_16_attention_sparsity": 0.413818359375,
      "attention_bam_16_attention_concentration_10": 0.5132333391253043,
      "attention_bam_16_attention_concentration_20": 0.8312521373477186,
      "attention_bam_16_attention_center_y": 0.4571274630447008,
      "attention_bam_16_attention_center_x": 0.47630272726252404,
      "attention_bam_16_attention_center_distance": 0.06927647739569061,
      "attention_bam_16_attention_spatial_variance": 42.03614925269509,
      "attention_bam_16_attention_spatial_std": 6.483529073945384,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 7.364917966145997,
      "attention_bam_16_peak_intensity_mean": 0.3690265119075775,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 34,
      "phase": "train",
      "loss": 0.3206520080566406,
      "timestamp": 1759561892.258163,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3206520080566406,
      "ssim": 0.0042001595720648766,
      "attention_bam_384_mean_attention": 0.20136402547359467,
      "attention_bam_384_std_attention": 0.5212732553482056,
      "attention_bam_384_max_attention": 3.9140625,
      "attention_bam_384_min_attention": -1.2252197265625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.10464381903344222,
      "attention_bam_384_attention_skewness": 0.36161095213515243,
      "attention_bam_384_attention_sparsity": 0.43433888753255206,
      "attention_bam_384_attention_concentration_10": 0.5769869569588091,
      "attention_bam_384_attention_concentration_20": 0.946078449268123,
      "attention_bam_384_attention_center_y": 0.4821873266196471,
      "attention_bam_384_attention_center_x": 0.48665139298155985,
      "attention_bam_384_attention_center_distance": 0.031479410486471404,
      "attention_bam_384_attention_spatial_variance": 169.5142987498533,
      "attention_bam_384_attention_spatial_std": 13.019765694890722,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 16.76740745741446,
      "attention_bam_384_peak_intensity_mean": 0.2808375656604767,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.25376883149147034,
      "attention_bam_16_std_attention": 0.4990917444229126,
      "attention_bam_16_max_attention": 3.0465087890625,
      "attention_bam_16_min_attention": -0.90576171875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6922083314573007,
      "attention_bam_16_attention_skewness": 0.5307534886530596,
      "attention_bam_16_attention_sparsity": 0.39697265625,
      "attention_bam_16_attention_concentration_10": 0.46908480717673257,
      "attention_bam_16_attention_concentration_20": 0.7737909698602103,
      "attention_bam_16_attention_center_y": 0.4778080741686284,
      "attention_bam_16_attention_center_x": 0.4790521679795775,
      "attention_bam_16_attention_center_distance": 0.04315769313716698,
      "attention_bam_16_attention_spatial_variance": 41.71373772665156,
      "attention_bam_16_attention_spatial_std": 6.458617323131287,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.223289623779307,
      "attention_bam_16_peak_intensity_mean": 0.2977506220340729,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 35,
      "phase": "train",
      "loss": 0.26291152834892273,
      "timestamp": 1759561892.4267561,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.26291152834892273,
      "ssim": 0.009922063909471035,
      "attention_bam_384_mean_attention": 0.21041877567768097,
      "attention_bam_384_std_attention": 0.5056754946708679,
      "attention_bam_384_max_attention": 3.5439453125,
      "attention_bam_384_min_attention": -1.228759765625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.735541976210182,
      "attention_bam_384_attention_skewness": 0.5432131894005443,
      "attention_bam_384_attention_sparsity": 0.43667856852213544,
      "attention_bam_384_attention_concentration_10": 0.5540159482958191,
      "attention_bam_384_attention_concentration_20": 0.8993494684592714,
      "attention_bam_384_attention_center_y": 0.4810781780863097,
      "attention_bam_384_attention_center_x": 0.48612929449607273,
      "attention_bam_384_attention_center_distance": 0.03317926508258097,
      "attention_bam_384_attention_spatial_variance": 170.24509660405084,
      "attention_bam_384_attention_spatial_std": 13.047800450805907,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 15.211052311671292,
      "attention_bam_384_peak_intensity_mean": 0.30795878171920776,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21474532783031464,
      "attention_bam_16_std_attention": 0.4744444489479065,
      "attention_bam_16_max_attention": 3.2972640991210938,
      "attention_bam_16_min_attention": -0.98828125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.2481975021604663,
      "attention_bam_16_attention_skewness": 0.8409192080387388,
      "attention_bam_16_attention_sparsity": 0.425048828125,
      "attention_bam_16_attention_concentration_10": 0.5249944921691035,
      "attention_bam_16_attention_concentration_20": 0.8387875776681429,
      "attention_bam_16_attention_center_y": 0.46923899149949894,
      "attention_bam_16_attention_center_x": 0.46923996454393835,
      "attention_bam_16_attention_center_distance": 0.06152104396425776,
      "attention_bam_16_attention_spatial_variance": 42.06022705478866,
      "attention_bam_16_attention_spatial_std": 6.4853856519707955,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 8.890056420796975,
      "attention_bam_16_peak_intensity_mean": 0.2855604887008667,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 36,
      "phase": "train",
      "loss": 0.37697935104370117,
      "timestamp": 1759561892.5974956,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.37697935104370117,
      "ssim": 0.00878603383898735,
      "attention_bam_384_mean_attention": 0.2099037915468216,
      "attention_bam_384_std_attention": 0.5548276901245117,
      "attention_bam_384_max_attention": 4.859130859375,
      "attention_bam_384_min_attention": -1.1533203125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 4.957280268283276,
      "attention_bam_384_attention_skewness": 1.4127912883547542,
      "attention_bam_384_attention_sparsity": 0.44617462158203125,
      "attention_bam_384_attention_concentration_10": 0.6273365790789112,
      "attention_bam_384_attention_concentration_20": 0.9522493744321978,
      "attention_bam_384_attention_center_y": 0.4833444925213585,
      "attention_bam_384_attention_center_x": 0.48243434414811864,
      "attention_bam_384_attention_center_distance": 0.03423326437480994,
      "attention_bam_384_attention_spatial_variance": 164.15266475440745,
      "attention_bam_384_attention_spatial_std": 12.812207645617029,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 14.134200565366907,
      "attention_bam_384_peak_intensity_mean": 0.23279781639575958,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21014413237571716,
      "attention_bam_16_std_attention": 0.502081036567688,
      "attention_bam_16_max_attention": 3.7984619140625,
      "attention_bam_16_min_attention": -0.82098388671875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 7.916623408832368,
      "attention_bam_16_attention_skewness": 1.7700650649354714,
      "attention_bam_16_attention_sparsity": 0.419677734375,
      "attention_bam_16_attention_concentration_10": 0.5553326090126083,
      "attention_bam_16_attention_concentration_20": 0.8453605571779863,
      "attention_bam_16_attention_center_y": 0.4719951717012494,
      "attention_bam_16_attention_center_x": 0.4696386409326529,
      "attention_bam_16_attention_center_distance": 0.058413740377737895,
      "attention_bam_16_attention_spatial_variance": 41.62552954269211,
      "attention_bam_16_attention_spatial_std": 6.451784988876497,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.063203071756314,
      "attention_bam_16_peak_intensity_mean": 0.22483202815055847,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 37,
      "phase": "train",
      "loss": 0.38056159019470215,
      "timestamp": 1759561892.774695,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.38056159019470215,
      "ssim": 0.011205531656742096,
      "attention_bam_384_mean_attention": 0.2068842500448227,
      "attention_bam_384_std_attention": 0.5677648186683655,
      "attention_bam_384_max_attention": 4.763671875,
      "attention_bam_384_min_attention": -1.284912109375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.6716491447345199,
      "attention_bam_384_attention_skewness": 0.8166567852236954,
      "attention_bam_384_attention_sparsity": 0.4462432861328125,
      "attention_bam_384_attention_concentration_10": 0.6414785612933261,
      "attention_bam_384_attention_concentration_20": 1.0023848475316466,
      "attention_bam_384_attention_center_y": 0.47842303029917094,
      "attention_bam_384_attention_center_x": 0.4848434722599771,
      "attention_bam_384_attention_center_distance": 0.03729037287570558,
      "attention_bam_384_attention_spatial_variance": 167.46909033406624,
      "attention_bam_384_attention_spatial_std": 12.940984905874291,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 16.196759011341413,
      "attention_bam_384_peak_intensity_mean": 0.24596118927001953,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2555862069129944,
      "attention_bam_16_std_attention": 0.5238634943962097,
      "attention_bam_16_max_attention": 3.70782470703125,
      "attention_bam_16_min_attention": -1.079345703125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 4.501042393436651,
      "attention_bam_16_attention_skewness": 1.2095806246323746,
      "attention_bam_16_attention_sparsity": 0.38232421875,
      "attention_bam_16_attention_concentration_10": 0.49671900233316146,
      "attention_bam_16_attention_concentration_20": 0.7734279767418148,
      "attention_bam_16_attention_center_y": 0.4729873190460294,
      "attention_bam_16_attention_center_x": 0.4736729637305009,
      "attention_bam_16_attention_center_distance": 0.05334412378240975,
      "attention_bam_16_attention_spatial_variance": 42.341966982872705,
      "attention_bam_16_attention_spatial_std": 6.507070537720696,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 10.027407879040803,
      "attention_bam_16_peak_intensity_mean": 0.280418336391449,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 38,
      "phase": "train",
      "loss": 0.3243849575519562,
      "timestamp": 1759561892.9519446,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3243849575519562,
      "ssim": 0.01421327330172062,
      "attention_bam_384_mean_attention": 0.20235000550746918,
      "attention_bam_384_std_attention": 0.5802842378616333,
      "attention_bam_384_max_attention": 4.87481689453125,
      "attention_bam_384_min_attention": -1.55712890625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.470079113901943,
      "attention_bam_384_attention_skewness": 1.0325577894793132,
      "attention_bam_384_attention_sparsity": 0.4690450032552083,
      "attention_bam_384_attention_concentration_10": 0.6786476535328093,
      "attention_bam_384_attention_concentration_20": 1.0480335573018718,
      "attention_bam_384_attention_center_y": 0.48797806589544523,
      "attention_bam_384_attention_center_x": 0.48615512292843993,
      "attention_bam_384_attention_center_distance": 0.02593096684432984,
      "attention_bam_384_attention_spatial_variance": 170.72216583809387,
      "attention_bam_384_attention_spatial_std": 13.06606925735869,
      "attention_bam_384_num_attention_peaks": 3,
      "attention_bam_384_peak_separation_mean": 20.174527379615466,
      "attention_bam_384_peak_intensity_mean": 0.27549228072166443,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23087292909622192,
      "attention_bam_16_std_attention": 0.5010107755661011,
      "attention_bam_16_max_attention": 3.952392578125,
      "attention_bam_16_min_attention": -1.1334228515625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 5.535319216778733,
      "attention_bam_16_attention_skewness": 1.3963715883245083,
      "attention_bam_16_attention_sparsity": 0.40771484375,
      "attention_bam_16_attention_concentration_10": 0.52437616256976,
      "attention_bam_16_attention_concentration_20": 0.8072516300172419,
      "attention_bam_16_attention_center_y": 0.47445797842694315,
      "attention_bam_16_attention_center_x": 0.476538638334049,
      "attention_bam_16_attention_center_distance": 0.04904753525426238,
      "attention_bam_16_attention_spatial_variance": 42.021504286589014,
      "attention_bam_16_attention_spatial_std": 6.482399577825253,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 7.873731559528384,
      "attention_bam_16_peak_intensity_mean": 0.2738911509513855,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 39,
      "phase": "train",
      "loss": 0.28543227910995483,
      "timestamp": 1759561893.1350648,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.28543227910995483,
      "ssim": 0.012873800471425056,
      "attention_bam_384_mean_attention": 0.20928359031677246,
      "attention_bam_384_std_attention": 0.5525324940681458,
      "attention_bam_384_max_attention": 3.8701171875,
      "attention_bam_384_min_attention": -1.085205078125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.529704801689041,
      "attention_bam_384_attention_skewness": 0.822020825176353,
      "attention_bam_384_attention_sparsity": 0.4538472493489583,
      "attention_bam_384_attention_concentration_10": 0.6089235690630032,
      "attention_bam_384_attention_concentration_20": 0.9654320066437727,
      "attention_bam_384_attention_center_y": 0.4807025613649719,
      "attention_bam_384_attention_center_x": 0.4854983069526688,
      "attention_bam_384_attention_center_distance": 0.03413766949021822,
      "attention_bam_384_attention_spatial_variance": 165.60559976302608,
      "attention_bam_384_attention_spatial_std": 12.868783927124818,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 13.226573504681806,
      "attention_bam_384_peak_intensity_mean": 0.2627199590206146,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22136399149894714,
      "attention_bam_16_std_attention": 0.5179586410522461,
      "attention_bam_16_max_attention": 3.7078857421875,
      "attention_bam_16_min_attention": -0.7835693359375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 4.227990447527364,
      "attention_bam_16_attention_skewness": 1.2216865459577142,
      "attention_bam_16_attention_sparsity": 0.4306640625,
      "attention_bam_16_attention_concentration_10": 0.5403357722467963,
      "attention_bam_16_attention_concentration_20": 0.8618293605378375,
      "attention_bam_16_attention_center_y": 0.4780762790593959,
      "attention_bam_16_attention_center_x": 0.47488602940126307,
      "attention_bam_16_attention_center_distance": 0.04714575397881987,
      "attention_bam_16_attention_spatial_variance": 41.07386266117738,
      "attention_bam_16_attention_spatial_std": 6.4088893469287935,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.044927065112576,
      "attention_bam_16_peak_intensity_mean": 0.22676727175712585,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 40,
      "phase": "train",
      "loss": 0.3111514151096344,
      "timestamp": 1759561893.4320738,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3111514151096344,
      "ssim": 0.016293345019221306,
      "attention_bam_384_mean_attention": 0.20637619495391846,
      "attention_bam_384_std_attention": 0.6428527235984802,
      "attention_bam_384_max_attention": 5.73388671875,
      "attention_bam_384_min_attention": -1.369873046875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 7.2782291003422,
      "attention_bam_384_attention_skewness": 1.829870958744409,
      "attention_bam_384_attention_sparsity": 0.46249135335286456,
      "attention_bam_384_attention_concentration_10": 0.7325788413375722,
      "attention_bam_384_attention_concentration_20": 1.0746074949162334,
      "attention_bam_384_attention_center_y": 0.4901794521142899,
      "attention_bam_384_attention_center_x": 0.477955041440164,
      "attention_bam_384_attention_center_distance": 0.03412985082535263,
      "attention_bam_384_attention_spatial_variance": 166.31785782477598,
      "attention_bam_384_attention_spatial_std": 12.896428103346135,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 12.815147123707238,
      "attention_bam_384_peak_intensity_mean": 0.22350656986236572,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23247374594211578,
      "attention_bam_16_std_attention": 0.6016060709953308,
      "attention_bam_16_max_attention": 5.371551513671875,
      "attention_bam_16_min_attention": -1.14501953125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 13.427360846551657,
      "attention_bam_16_attention_skewness": 2.4822164809429803,
      "attention_bam_16_attention_sparsity": 0.4052734375,
      "attention_bam_16_attention_concentration_10": 0.5851167443871328,
      "attention_bam_16_attention_concentration_20": 0.8689713108302928,
      "attention_bam_16_attention_center_y": 0.4758694948245887,
      "attention_bam_16_attention_center_x": 0.47013358977878617,
      "attention_bam_16_attention_center_distance": 0.054300713430347834,
      "attention_bam_16_attention_spatial_variance": 41.83541636749105,
      "attention_bam_16_attention_spatial_std": 6.468030331367583,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.263169871660528,
      "attention_bam_16_peak_intensity_mean": 0.21234066784381866,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 41,
      "phase": "train",
      "loss": 0.3168369233608246,
      "timestamp": 1759561893.6209302,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3168369233608246,
      "ssim": 0.013067459687590599,
      "attention_bam_384_mean_attention": 0.20445863902568817,
      "attention_bam_384_std_attention": 0.5789698958396912,
      "attention_bam_384_max_attention": 5.15625,
      "attention_bam_384_min_attention": -1.17431640625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 4.947036920977459,
      "attention_bam_384_attention_skewness": 1.5330234332409374,
      "attention_bam_384_attention_sparsity": 0.4588826497395833,
      "attention_bam_384_attention_concentration_10": 0.6893948345793517,
      "attention_bam_384_attention_concentration_20": 1.0182502910382243,
      "attention_bam_384_attention_center_y": 0.48284172561420813,
      "attention_bam_384_attention_center_x": 0.48982428704889835,
      "attention_bam_384_attention_center_distance": 0.02821175336491297,
      "attention_bam_384_attention_spatial_variance": 172.0055467080783,
      "attention_bam_384_attention_spatial_std": 13.11508851316217,
      "attention_bam_384_num_attention_peaks": 2,
      "attention_bam_384_peak_separation_mean": 26.588231703507848,
      "attention_bam_384_peak_intensity_mean": 0.22405794262886047,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20459800958633423,
      "attention_bam_16_std_attention": 0.5090613961219788,
      "attention_bam_16_max_attention": 3.62103271484375,
      "attention_bam_16_min_attention": -0.8507080078125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 6.0332561418184,
      "attention_bam_16_attention_skewness": 1.6222343924799938,
      "attention_bam_16_attention_sparsity": 0.437255859375,
      "attention_bam_16_attention_concentration_10": 0.5871813079576905,
      "attention_bam_16_attention_concentration_20": 0.8970078672380315,
      "attention_bam_16_attention_center_y": 0.4704993194228227,
      "attention_bam_16_attention_center_x": 0.4631800243931751,
      "attention_bam_16_attention_center_distance": 0.06672332063385072,
      "attention_bam_16_attention_spatial_variance": 42.94831711701396,
      "attention_bam_16_attention_spatial_std": 6.553496556572984,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.104977246871831,
      "attention_bam_16_peak_intensity_mean": 0.23802369832992554,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 42,
      "phase": "train",
      "loss": 0.3130760192871094,
      "timestamp": 1759561893.790868,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3130760192871094,
      "ssim": 0.011615973897278309,
      "attention_bam_384_mean_attention": 0.20067328214645386,
      "attention_bam_384_std_attention": 0.5250174403190613,
      "attention_bam_384_max_attention": 3.76220703125,
      "attention_bam_384_min_attention": -1.1907958984375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7340714786051077,
      "attention_bam_384_attention_skewness": 0.513211748682458,
      "attention_bam_384_attention_sparsity": 0.43742116292317706,
      "attention_bam_384_attention_concentration_10": 0.5909351254531704,
      "attention_bam_384_attention_concentration_20": 0.9539750482587432,
      "attention_bam_384_attention_center_y": 0.48125876628448977,
      "attention_bam_384_attention_center_x": 0.48355715544996886,
      "attention_bam_384_attention_center_distance": 0.03525906913336954,
      "attention_bam_384_attention_spatial_variance": 168.01492184934827,
      "attention_bam_384_attention_spatial_std": 12.962057006870022,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 15.88730496386554,
      "attention_bam_384_peak_intensity_mean": 0.2883421778678894,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2438998818397522,
      "attention_bam_16_std_attention": 0.4829942584037781,
      "attention_bam_16_max_attention": 3.17138671875,
      "attention_bam_16_min_attention": -1.083251953125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.4720564659346937,
      "attention_bam_16_attention_skewness": 0.5658762231239325,
      "attention_bam_16_attention_sparsity": 0.385498046875,
      "attention_bam_16_attention_concentration_10": 0.4691523819461582,
      "attention_bam_16_attention_concentration_20": 0.7624176403364478,
      "attention_bam_16_attention_center_y": 0.46762497110245727,
      "attention_bam_16_attention_center_x": 0.4699809338924944,
      "attention_bam_16_attention_center_distance": 0.062438559017381524,
      "attention_bam_16_attention_spatial_variance": 41.78741524084673,
      "attention_bam_16_attention_spatial_std": 6.46431862154448,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 7.681206167481298,
      "attention_bam_16_peak_intensity_mean": 0.3187369406223297,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 43,
      "phase": "train",
      "loss": 0.3270752429962158,
      "timestamp": 1759561893.9631045,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3270752429962158,
      "ssim": 0.015082726255059242,
      "attention_bam_384_mean_attention": 0.20002351701259613,
      "attention_bam_384_std_attention": 0.5080283880233765,
      "attention_bam_384_max_attention": 4.6240234375,
      "attention_bam_384_min_attention": -1.21484375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9114297966540268,
      "attention_bam_384_attention_skewness": 0.616122632587998,
      "attention_bam_384_attention_sparsity": 0.4474080403645833,
      "attention_bam_384_attention_concentration_10": 0.5901665585134327,
      "attention_bam_384_attention_concentration_20": 0.9433428096888271,
      "attention_bam_384_attention_center_y": 0.4779606355790335,
      "attention_bam_384_attention_center_x": 0.48060673473831506,
      "attention_bam_384_attention_center_distance": 0.04151704039524589,
      "attention_bam_384_attention_spatial_variance": 169.66646903547388,
      "attention_bam_384_attention_spatial_std": 13.025608202132977,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 14.878031639106638,
      "attention_bam_384_peak_intensity_mean": 0.24390487372875214,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2298351228237152,
      "attention_bam_16_std_attention": 0.42409834265708923,
      "attention_bam_16_max_attention": 2.64715576171875,
      "attention_bam_16_min_attention": -0.89642333984375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.4284349681300617,
      "attention_bam_16_attention_skewness": 0.5705934185132594,
      "attention_bam_16_attention_sparsity": 0.373291015625,
      "attention_bam_16_attention_concentration_10": 0.4474131634251131,
      "attention_bam_16_attention_concentration_20": 0.7187578246619346,
      "attention_bam_16_attention_center_y": 0.4723258297132091,
      "attention_bam_16_attention_center_x": 0.46993995974279607,
      "attention_bam_16_attention_center_distance": 0.05778348762972035,
      "attention_bam_16_attention_spatial_variance": 42.39090055874452,
      "attention_bam_16_attention_spatial_std": 6.510829483156852,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.028713153135449,
      "attention_bam_16_peak_intensity_mean": 0.32116371393203735,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 44,
      "phase": "train",
      "loss": 0.3815705180168152,
      "timestamp": 1759561894.133959,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3815705180168152,
      "ssim": 0.015793247148394585,
      "attention_bam_384_mean_attention": 0.2170644998550415,
      "attention_bam_384_std_attention": 0.43143969774246216,
      "attention_bam_384_max_attention": 3.9658203125,
      "attention_bam_384_min_attention": -1.121826171875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.06567493569330773,
      "attention_bam_384_attention_skewness": 0.11487026773021629,
      "attention_bam_384_attention_sparsity": 0.39072418212890625,
      "attention_bam_384_attention_concentration_10": 0.4480229403286221,
      "attention_bam_384_attention_concentration_20": 0.7586064218054703,
      "attention_bam_384_attention_center_y": 0.47590906461638116,
      "attention_bam_384_attention_center_x": 0.4817846351640035,
      "attention_bam_384_attention_center_distance": 0.042712356145877886,
      "attention_bam_384_attention_spatial_variance": 166.46919308714314,
      "attention_bam_384_attention_spatial_std": 12.902294101714746,
      "attention_bam_384_num_attention_peaks": 23,
      "attention_bam_384_peak_separation_mean": 10.781713183503149,
      "attention_bam_384_peak_intensity_mean": 0.27438947558403015,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23258009552955627,
      "attention_bam_16_std_attention": 0.3604208528995514,
      "attention_bam_16_max_attention": 1.5630569458007812,
      "attention_bam_16_min_attention": -0.8240966796875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.3027682619074641,
      "attention_bam_16_attention_skewness": 0.06707449633287875,
      "attention_bam_16_attention_sparsity": 0.34423828125,
      "attention_bam_16_attention_concentration_10": 0.37621905581714365,
      "attention_bam_16_attention_concentration_20": 0.6341691468756265,
      "attention_bam_16_attention_center_y": 0.47250191906890787,
      "attention_bam_16_attention_center_x": 0.4769457856008097,
      "attention_bam_16_attention_center_distance": 0.05074724143156407,
      "attention_bam_16_attention_spatial_variance": 42.14399648705044,
      "attention_bam_16_attention_spatial_std": 6.491840762607354,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 7.978377235156172,
      "attention_bam_16_peak_intensity_mean": 0.4477721154689789,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 45,
      "phase": "train",
      "loss": 0.3710777759552002,
      "timestamp": 1759561894.3009844,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3710777759552002,
      "ssim": 0.012795074842870235,
      "attention_bam_384_mean_attention": 0.21014732122421265,
      "attention_bam_384_std_attention": 0.543440580368042,
      "attention_bam_384_max_attention": 4.0693359375,
      "attention_bam_384_min_attention": -1.2578125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.066208699144485,
      "attention_bam_384_attention_skewness": 0.6333924271008873,
      "attention_bam_384_attention_sparsity": 0.44072214762369794,
      "attention_bam_384_attention_concentration_10": 0.5984146257641167,
      "attention_bam_384_attention_concentration_20": 0.9554840423061546,
      "attention_bam_384_attention_center_y": 0.48774481544209125,
      "attention_bam_384_attention_center_x": 0.4800967632128613,
      "attention_bam_384_attention_center_distance": 0.03305535911628599,
      "attention_bam_384_attention_spatial_variance": 167.50193331194308,
      "attention_bam_384_attention_spatial_std": 12.942253795685783,
      "attention_bam_384_num_attention_peaks": 4,
      "attention_bam_384_peak_separation_mean": 14.452962508697409,
      "attention_bam_384_peak_intensity_mean": 0.28147900104522705,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23214489221572876,
      "attention_bam_16_std_attention": 0.4933653473854065,
      "attention_bam_16_max_attention": 2.9013671875,
      "attention_bam_16_min_attention": -1.1346435546875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.047012742337145,
      "attention_bam_16_attention_skewness": 0.6850543231411442,
      "attention_bam_16_attention_sparsity": 0.39501953125,
      "attention_bam_16_attention_concentration_10": 0.49966358515885734,
      "attention_bam_16_attention_concentration_20": 0.7899004941190362,
      "attention_bam_16_attention_center_y": 0.46863617056308143,
      "attention_bam_16_attention_center_x": 0.4672060187224952,
      "attention_bam_16_attention_center_distance": 0.0641737486045105,
      "attention_bam_16_attention_spatial_variance": 41.981558684576655,
      "attention_bam_16_attention_spatial_std": 6.479317763821794,
      "attention_bam_16_num_attention_peaks": 11,
      "attention_bam_16_peak_separation_mean": 9.014316624801284,
      "attention_bam_16_peak_intensity_mean": 0.3415186107158661,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 46,
      "phase": "train",
      "loss": 0.29428496956825256,
      "timestamp": 1759561894.4696956,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.29428496956825256,
      "ssim": 0.013562352396547794,
      "attention_bam_384_mean_attention": 0.19148056209087372,
      "attention_bam_384_std_attention": 0.4997089207172394,
      "attention_bam_384_max_attention": 3.94189453125,
      "attention_bam_384_min_attention": -1.1983642578125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5254973610560163,
      "attention_bam_384_attention_skewness": 0.45978001628693177,
      "attention_bam_384_attention_sparsity": 0.43939208984375,
      "attention_bam_384_attention_concentration_10": 0.5849224158217323,
      "attention_bam_384_attention_concentration_20": 0.9488535031581514,
      "attention_bam_384_attention_center_y": 0.48814660671614035,
      "attention_bam_384_attention_center_x": 0.4774895883661772,
      "attention_bam_384_attention_center_distance": 0.0359783702873266,
      "attention_bam_384_attention_spatial_variance": 168.08812931997545,
      "attention_bam_384_attention_spatial_std": 12.964880613410038,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 12.405668047510675,
      "attention_bam_384_peak_intensity_mean": 0.270896852016449,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23772552609443665,
      "attention_bam_16_std_attention": 0.4881671667098999,
      "attention_bam_16_max_attention": 2.814117431640625,
      "attention_bam_16_min_attention": -1.0760498046875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.1203859620683314,
      "attention_bam_16_attention_skewness": 0.5493021311557776,
      "attention_bam_16_attention_sparsity": 0.38818359375,
      "attention_bam_16_attention_concentration_10": 0.4856690291541492,
      "attention_bam_16_attention_concentration_20": 0.7860214912142245,
      "attention_bam_16_attention_center_y": 0.4653387861003348,
      "attention_bam_16_attention_center_x": 0.4774995254046299,
      "attention_bam_16_attention_center_distance": 0.05844092925365301,
      "attention_bam_16_attention_spatial_variance": 41.90886837891773,
      "attention_bam_16_attention_spatial_std": 6.473705923110636,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.379682375238426,
      "attention_bam_16_peak_intensity_mean": 0.3408536911010742,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 47,
      "phase": "train",
      "loss": 0.23610316216945648,
      "timestamp": 1759561894.6349547,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.23610316216945648,
      "ssim": 0.023053178563714027,
      "attention_bam_384_mean_attention": 0.17686361074447632,
      "attention_bam_384_std_attention": 0.5187351107597351,
      "attention_bam_384_max_attention": 4.77001953125,
      "attention_bam_384_min_attention": -1.1484375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 4.450997403428944,
      "attention_bam_384_attention_skewness": 1.2677251857083767,
      "attention_bam_384_attention_sparsity": 0.47073109944661456,
      "attention_bam_384_attention_concentration_10": 0.6777827992131437,
      "attention_bam_384_attention_concentration_20": 1.0448302973867825,
      "attention_bam_384_attention_center_y": 0.48835945479809184,
      "attention_bam_384_attention_center_x": 0.47803143707055046,
      "attention_bam_384_attention_center_distance": 0.035160206193446925,
      "attention_bam_384_attention_spatial_variance": 166.8684989024319,
      "attention_bam_384_attention_spatial_std": 12.917759051106035,
      "attention_bam_384_num_attention_peaks": 4,
      "attention_bam_384_peak_separation_mean": 12.407358254736204,
      "attention_bam_384_peak_intensity_mean": 0.22989797592163086,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20484760403633118,
      "attention_bam_16_std_attention": 0.4886791706085205,
      "attention_bam_16_max_attention": 4.937713623046875,
      "attention_bam_16_min_attention": -0.9791259765625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 14.421090344833829,
      "attention_bam_16_attention_skewness": 2.4090435367291376,
      "attention_bam_16_attention_sparsity": 0.434814453125,
      "attention_bam_16_attention_concentration_10": 0.562995732180975,
      "attention_bam_16_attention_concentration_20": 0.8553840849125054,
      "attention_bam_16_attention_center_y": 0.46463494138699274,
      "attention_bam_16_attention_center_x": 0.46825133212428804,
      "attention_bam_16_attention_center_distance": 0.06721108959961448,
      "attention_bam_16_attention_spatial_variance": 41.728599450144586,
      "attention_bam_16_attention_spatial_std": 6.459767755124373,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.044344975736264,
      "attention_bam_16_peak_intensity_mean": 0.2027854025363922,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 48,
      "phase": "train",
      "loss": 0.3098300099372864,
      "timestamp": 1759561894.8018718,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3098300099372864,
      "ssim": 0.018703561276197433,
      "attention_bam_384_mean_attention": 0.20540744066238403,
      "attention_bam_384_std_attention": 0.5026587247848511,
      "attention_bam_384_max_attention": 4.30224609375,
      "attention_bam_384_min_attention": -1.23974609375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.08439773207812884,
      "attention_bam_384_attention_skewness": 0.31763046977569426,
      "attention_bam_384_attention_sparsity": 0.4340769449869792,
      "attention_bam_384_attention_concentration_10": 0.5511240272398734,
      "attention_bam_384_attention_concentration_20": 0.9094440728557528,
      "attention_bam_384_attention_center_y": 0.4830106658042467,
      "attention_bam_384_attention_center_x": 0.48461887034388446,
      "attention_bam_384_attention_center_distance": 0.03241038802338627,
      "attention_bam_384_attention_spatial_variance": 169.16124095214835,
      "attention_bam_384_attention_spatial_std": 13.00620009657503,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 14.2080556944813,
      "attention_bam_384_peak_intensity_mean": 0.26263749599456787,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24457034468650818,
      "attention_bam_16_std_attention": 0.47045955061912537,
      "attention_bam_16_max_attention": 2.78387451171875,
      "attention_bam_16_min_attention": -1.00115966796875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5942419093785891,
      "attention_bam_16_attention_skewness": 0.4486847103782806,
      "attention_bam_16_attention_sparsity": 0.37939453125,
      "attention_bam_16_attention_concentration_10": 0.46216114482603676,
      "attention_bam_16_attention_concentration_20": 0.7563028404884083,
      "attention_bam_16_attention_center_y": 0.464652248459176,
      "attention_bam_16_attention_center_x": 0.46943194603583194,
      "attention_bam_16_attention_center_distance": 0.06608887141036854,
      "attention_bam_16_attention_spatial_variance": 42.31841824969467,
      "attention_bam_16_attention_spatial_std": 6.505260813349045,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.742705661071488,
      "attention_bam_16_peak_intensity_mean": 0.33778491616249084,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 49,
      "phase": "train",
      "loss": 0.26980265974998474,
      "timestamp": 1759561894.968279,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.26980265974998474,
      "ssim": 0.031933754682540894,
      "attention_bam_384_mean_attention": 0.20950239896774292,
      "attention_bam_384_std_attention": 0.5180281400680542,
      "attention_bam_384_max_attention": 4.1453857421875,
      "attention_bam_384_min_attention": -1.278564453125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.0464347717561733,
      "attention_bam_384_attention_skewness": 0.7697306347554864,
      "attention_bam_384_attention_sparsity": 0.43368275960286456,
      "attention_bam_384_attention_concentration_10": 0.569887471322933,
      "attention_bam_384_attention_concentration_20": 0.9074754938568883,
      "attention_bam_384_attention_center_y": 0.4778418028820801,
      "attention_bam_384_attention_center_x": 0.48011637888432407,
      "attention_bam_384_attention_center_distance": 0.042103303627823475,
      "attention_bam_384_attention_spatial_variance": 169.47868841323032,
      "attention_bam_384_attention_spatial_std": 13.018398074003972,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 16.135788618302463,
      "attention_bam_384_peak_intensity_mean": 0.27694377303123474,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22860297560691833,
      "attention_bam_16_std_attention": 0.5432708263397217,
      "attention_bam_16_max_attention": 3.8021240234375,
      "attention_bam_16_min_attention": -0.941741943359375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.872168221169235,
      "attention_bam_16_attention_skewness": 1.0714173882094578,
      "attention_bam_16_attention_sparsity": 0.41162109375,
      "attention_bam_16_attention_concentration_10": 0.5468772304949141,
      "attention_bam_16_attention_concentration_20": 0.8603701149863862,
      "attention_bam_16_attention_center_y": 0.4752872959657386,
      "attention_bam_16_attention_center_x": 0.47329673072208606,
      "attention_bam_16_attention_center_distance": 0.051454491170621494,
      "attention_bam_16_attention_spatial_variance": 43.40952091255824,
      "attention_bam_16_attention_spatial_std": 6.588590206755786,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 10.314217634753092,
      "attention_bam_16_peak_intensity_mean": 0.2520168423652649,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 50,
      "phase": "train",
      "loss": 0.3179776966571808,
      "timestamp": 1759561895.2573755,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3179776966571808,
      "ssim": 0.024813691154122353,
      "attention_bam_384_mean_attention": 0.19781000912189484,
      "attention_bam_384_std_attention": 0.543398380279541,
      "attention_bam_384_max_attention": 4.99853515625,
      "attention_bam_384_min_attention": -1.328857421875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.791729662855703,
      "attention_bam_384_attention_skewness": 0.9483397491663681,
      "attention_bam_384_attention_sparsity": 0.44573720296223956,
      "attention_bam_384_attention_concentration_10": 0.6383328257719267,
      "attention_bam_384_attention_concentration_20": 0.9909619264723161,
      "attention_bam_384_attention_center_y": 0.48292078954490175,
      "attention_bam_384_attention_center_x": 0.4799466866861676,
      "attention_bam_384_attention_center_distance": 0.03725143768050478,
      "attention_bam_384_attention_spatial_variance": 167.55787866393803,
      "attention_bam_384_attention_spatial_std": 12.944414960280671,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 16.53875685595516,
      "attention_bam_384_peak_intensity_mean": 0.24577821791172028,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21372327208518982,
      "attention_bam_16_std_attention": 0.48502853512763977,
      "attention_bam_16_max_attention": 4.48223876953125,
      "attention_bam_16_min_attention": -1.1007080078125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 9.071704571323174,
      "attention_bam_16_attention_skewness": 1.5553178009878923,
      "attention_bam_16_attention_sparsity": 0.393798828125,
      "attention_bam_16_attention_concentration_10": 0.5247576715830745,
      "attention_bam_16_attention_concentration_20": 0.807380270658989,
      "attention_bam_16_attention_center_y": 0.46704956690623994,
      "attention_bam_16_attention_center_x": 0.46791493579862814,
      "attention_bam_16_attention_center_distance": 0.0650412543832376,
      "attention_bam_16_attention_spatial_variance": 42.08159545160792,
      "attention_bam_16_attention_spatial_std": 6.487032869625983,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 10.060642915583694,
      "attention_bam_16_peak_intensity_mean": 0.24246802926063538,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 51,
      "phase": "train",
      "loss": 0.34341341257095337,
      "timestamp": 1759561895.4952629,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.34341341257095337,
      "ssim": 0.021573074162006378,
      "attention_bam_384_mean_attention": 0.1927391141653061,
      "attention_bam_384_std_attention": 0.5332438945770264,
      "attention_bam_384_max_attention": 5.1669921875,
      "attention_bam_384_min_attention": -1.3182373046875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2928407392633385,
      "attention_bam_384_attention_skewness": 0.601050559222626,
      "attention_bam_384_attention_sparsity": 0.4448750813802083,
      "attention_bam_384_attention_concentration_10": 0.6228651285857147,
      "attention_bam_384_attention_concentration_20": 0.998073473150801,
      "attention_bam_384_attention_center_y": 0.4805465633010315,
      "attention_bam_384_attention_center_x": 0.4875215865540173,
      "attention_bam_384_attention_center_distance": 0.03268476714096816,
      "attention_bam_384_attention_spatial_variance": 171.7731027896837,
      "attention_bam_384_attention_spatial_std": 13.106223818845903,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 18.0893683962962,
      "attention_bam_384_peak_intensity_mean": 0.2360241860151291,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22769713401794434,
      "attention_bam_16_std_attention": 0.5143418908119202,
      "attention_bam_16_max_attention": 4.0484619140625,
      "attention_bam_16_min_attention": -1.1505126953125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.104471567178149,
      "attention_bam_16_attention_skewness": 0.9139364283888322,
      "attention_bam_16_attention_sparsity": 0.421142578125,
      "attention_bam_16_attention_concentration_10": 0.5291189500598219,
      "attention_bam_16_attention_concentration_20": 0.847785896469663,
      "attention_bam_16_attention_center_y": 0.4785021284341648,
      "attention_bam_16_attention_center_x": 0.4679353236975062,
      "attention_bam_16_attention_center_distance": 0.05459490723950092,
      "attention_bam_16_attention_spatial_variance": 42.241048370896046,
      "attention_bam_16_attention_spatial_std": 6.499311376668766,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.04128336651877,
      "attention_bam_16_peak_intensity_mean": 0.26757797598838806,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 52,
      "phase": "train",
      "loss": 0.28550463914871216,
      "timestamp": 1759561895.6756823,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.28550463914871216,
      "ssim": 0.029550574719905853,
      "attention_bam_384_mean_attention": 0.19877557456493378,
      "attention_bam_384_std_attention": 0.48330503702163696,
      "attention_bam_384_max_attention": 4.7171630859375,
      "attention_bam_384_min_attention": -1.25732421875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 4.881121208173555,
      "attention_bam_384_attention_skewness": 1.1156902241840683,
      "attention_bam_384_attention_sparsity": 0.42879486083984375,
      "attention_bam_384_attention_concentration_10": 0.5548290693715106,
      "attention_bam_384_attention_concentration_20": 0.8761796203424029,
      "attention_bam_384_attention_center_y": 0.4866167428032836,
      "attention_bam_384_attention_center_x": 0.48576994647097843,
      "attention_bam_384_attention_center_distance": 0.027626291703096186,
      "attention_bam_384_attention_spatial_variance": 166.56140114728473,
      "attention_bam_384_attention_spatial_std": 12.905866927381698,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 15.398975497143795,
      "attention_bam_384_peak_intensity_mean": 0.24863596260547638,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21523723006248474,
      "attention_bam_16_std_attention": 0.46818679571151733,
      "attention_bam_16_max_attention": 4.89813232421875,
      "attention_bam_16_min_attention": -0.8036766052246094,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 11.638033551919088,
      "attention_bam_16_attention_skewness": 1.8303630260160422,
      "attention_bam_16_attention_sparsity": 0.401611328125,
      "attention_bam_16_attention_concentration_10": 0.4897389812387065,
      "attention_bam_16_attention_concentration_20": 0.7777305773819129,
      "attention_bam_16_attention_center_y": 0.46472613590377043,
      "attention_bam_16_attention_center_x": 0.47681358838442156,
      "attention_bam_16_attention_center_distance": 0.05969682021492105,
      "attention_bam_16_attention_spatial_variance": 42.88695408164949,
      "attention_bam_16_attention_spatial_std": 6.548813181153474,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.889438493710148,
      "attention_bam_16_peak_intensity_mean": 0.18517246842384338,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 53,
      "phase": "train",
      "loss": 0.28366100788116455,
      "timestamp": 1759561895.8531492,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.28366100788116455,
      "ssim": 0.027410278096795082,
      "attention_bam_384_mean_attention": 0.1886613816022873,
      "attention_bam_384_std_attention": 0.5426255464553833,
      "attention_bam_384_max_attention": 3.8895263671875,
      "attention_bam_384_min_attention": -1.234130859375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.808497734773908,
      "attention_bam_384_attention_skewness": 0.533571978189605,
      "attention_bam_384_attention_sparsity": 0.45601654052734375,
      "attention_bam_384_attention_concentration_10": 0.6363287016627198,
      "attention_bam_384_attention_concentration_20": 1.031431379334246,
      "attention_bam_384_attention_center_y": 0.4880816901648093,
      "attention_bam_384_attention_center_x": 0.48405265680389603,
      "attention_bam_384_attention_center_distance": 0.028155420946664147,
      "attention_bam_384_attention_spatial_variance": 167.28846077392018,
      "attention_bam_384_attention_spatial_std": 12.934004050328737,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 14.688594786551903,
      "attention_bam_384_peak_intensity_mean": 0.2853670120239258,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22603605687618256,
      "attention_bam_16_std_attention": 0.5109683871269226,
      "attention_bam_16_max_attention": 4.29833984375,
      "attention_bam_16_min_attention": -1.00946044921875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 4.700405714740637,
      "attention_bam_16_attention_skewness": 1.1301953727573204,
      "attention_bam_16_attention_sparsity": 0.40673828125,
      "attention_bam_16_attention_concentration_10": 0.5309830435297648,
      "attention_bam_16_attention_concentration_20": 0.8403677679084747,
      "attention_bam_16_attention_center_y": 0.4669805985827391,
      "attention_bam_16_attention_center_x": 0.4712147512079511,
      "attention_bam_16_attention_center_distance": 0.06194951844807777,
      "attention_bam_16_attention_spatial_variance": 41.58461836658298,
      "attention_bam_16_attention_spatial_std": 6.4486136778832535,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.886687842471892,
      "attention_bam_16_peak_intensity_mean": 0.23462624847888947,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 54,
      "phase": "train",
      "loss": 0.3018132448196411,
      "timestamp": 1759561896.0230954,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3018132448196411,
      "ssim": 0.02841363102197647,
      "attention_bam_384_mean_attention": 0.1934506744146347,
      "attention_bam_384_std_attention": 0.6049466729164124,
      "attention_bam_384_max_attention": 6.48480224609375,
      "attention_bam_384_min_attention": -1.32861328125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 9.616331818313785,
      "attention_bam_384_attention_skewness": 1.7560472595907037,
      "attention_bam_384_attention_sparsity": 0.46102142333984375,
      "attention_bam_384_attention_concentration_10": 0.6930677475539804,
      "attention_bam_384_attention_concentration_20": 1.0673144500527576,
      "attention_bam_384_attention_center_y": 0.47606921112669665,
      "attention_bam_384_attention_center_x": 0.4803605953674274,
      "attention_bam_384_attention_center_distance": 0.043781020326633155,
      "attention_bam_384_attention_spatial_variance": 172.64699390254063,
      "attention_bam_384_attention_spatial_std": 13.139520307170297,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 20.933291705935822,
      "attention_bam_384_peak_intensity_mean": 0.20082202553749084,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22474230825901031,
      "attention_bam_16_std_attention": 0.6224356889724731,
      "attention_bam_16_max_attention": 8.320465087890625,
      "attention_bam_16_min_attention": -1.2979736328125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 18.97067354440745,
      "attention_bam_16_attention_skewness": 2.32888687502016,
      "attention_bam_16_attention_sparsity": 0.43212890625,
      "attention_bam_16_attention_concentration_10": 0.6024733392627039,
      "attention_bam_16_attention_concentration_20": 0.9348552641518856,
      "attention_bam_16_attention_center_y": 0.4750714950325382,
      "attention_bam_16_attention_center_x": 0.4733798338958367,
      "attention_bam_16_attention_center_distance": 0.051576421033763316,
      "attention_bam_16_attention_spatial_variance": 42.712399643311024,
      "attention_bam_16_attention_spatial_std": 6.535472411640265,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.057796649798641,
      "attention_bam_16_peak_intensity_mean": 0.15957677364349365,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 55,
      "phase": "train",
      "loss": 0.2516891360282898,
      "timestamp": 1759561896.1905243,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.2516891360282898,
      "ssim": 0.026414263993501663,
      "attention_bam_384_mean_attention": 0.18564654886722565,
      "attention_bam_384_std_attention": 0.4422983229160309,
      "attention_bam_384_max_attention": 4.32470703125,
      "attention_bam_384_min_attention": -1.1888427734375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.41718127415575657,
      "attention_bam_384_attention_skewness": 0.24872570097734503,
      "attention_bam_384_attention_sparsity": 0.4206797281901042,
      "attention_bam_384_attention_concentration_10": 0.5275518341008387,
      "attention_bam_384_attention_concentration_20": 0.871901573829301,
      "attention_bam_384_attention_center_y": 0.4895570153021939,
      "attention_bam_384_attention_center_x": 0.4828145505586215,
      "attention_bam_384_attention_center_distance": 0.028439254628094202,
      "attention_bam_384_attention_spatial_variance": 171.47091981976308,
      "attention_bam_384_attention_spatial_std": 13.09469052019799,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 19.463378742492804,
      "attention_bam_384_peak_intensity_mean": 0.25350847840309143,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23757833242416382,
      "attention_bam_16_std_attention": 0.40704143047332764,
      "attention_bam_16_max_attention": 2.478424072265625,
      "attention_bam_16_min_attention": -1.0604248046875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.2799263945820325,
      "attention_bam_16_attention_skewness": 0.49314473095030326,
      "attention_bam_16_attention_sparsity": 0.35693359375,
      "attention_bam_16_attention_concentration_10": 0.42538811154776623,
      "attention_bam_16_attention_concentration_20": 0.6916552535201358,
      "attention_bam_16_attention_center_y": 0.4722935826179994,
      "attention_bam_16_attention_center_x": 0.4727256141347534,
      "attention_bam_16_attention_center_distance": 0.054982500642877054,
      "attention_bam_16_attention_spatial_variance": 42.40809668801668,
      "attention_bam_16_attention_spatial_std": 6.512149928250783,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.071112395324596,
      "attention_bam_16_peak_intensity_mean": 0.37235909700393677,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 56,
      "phase": "train",
      "loss": 0.2977958917617798,
      "timestamp": 1759561896.3577018,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.2977958917617798,
      "ssim": 0.03110702708363533,
      "attention_bam_384_mean_attention": 0.1978563815355301,
      "attention_bam_384_std_attention": 0.45167824625968933,
      "attention_bam_384_max_attention": 4.728515625,
      "attention_bam_384_min_attention": -1.1588134765625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.37262018204400515,
      "attention_bam_384_attention_skewness": 0.28867198666815286,
      "attention_bam_384_attention_sparsity": 0.4237467447916667,
      "attention_bam_384_attention_concentration_10": 0.5132146728231218,
      "attention_bam_384_attention_concentration_20": 0.846260226754328,
      "attention_bam_384_attention_center_y": 0.48453622480236075,
      "attention_bam_384_attention_center_x": 0.48012764465180596,
      "attention_bam_384_attention_center_distance": 0.035610078642092854,
      "attention_bam_384_attention_spatial_variance": 169.0708231536015,
      "attention_bam_384_attention_spatial_std": 13.002723682121431,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 16.289734199342355,
      "attention_bam_384_peak_intensity_mean": 0.23231996595859528,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2463318556547165,
      "attention_bam_16_std_attention": 0.403676837682724,
      "attention_bam_16_max_attention": 2.9744873046875,
      "attention_bam_16_min_attention": -0.8299560546875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.0896035256243533,
      "attention_bam_16_attention_skewness": 0.5755025254042107,
      "attention_bam_16_attention_sparsity": 0.34228515625,
      "attention_bam_16_attention_concentration_10": 0.40295175424321056,
      "attention_bam_16_attention_concentration_20": 0.6519745175242143,
      "attention_bam_16_attention_center_y": 0.46937752459155113,
      "attention_bam_16_attention_center_x": 0.4716150809226072,
      "attention_bam_16_attention_center_distance": 0.05904980323711831,
      "attention_bam_16_attention_spatial_variance": 41.95163530903499,
      "attention_bam_16_attention_spatial_std": 6.477008206651817,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 8.534031410436562,
      "attention_bam_16_peak_intensity_mean": 0.2853168249130249,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 57,
      "phase": "train",
      "loss": 0.21936550736427307,
      "timestamp": 1759561896.5251825,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.21936550736427307,
      "ssim": 0.03744059056043625,
      "attention_bam_384_mean_attention": 0.1858268827199936,
      "attention_bam_384_std_attention": 0.5090001225471497,
      "attention_bam_384_max_attention": 4.6103515625,
      "attention_bam_384_min_attention": -1.15576171875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9994639025338663,
      "attention_bam_384_attention_skewness": 0.5612203994485699,
      "attention_bam_384_attention_sparsity": 0.45328013102213544,
      "attention_bam_384_attention_concentration_10": 0.6096249823451024,
      "attention_bam_384_attention_concentration_20": 0.9902608507475359,
      "attention_bam_384_attention_center_y": 0.4852770599615158,
      "attention_bam_384_attention_center_x": 0.49242736568174994,
      "attention_bam_384_attention_center_distance": 0.02341408780605125,
      "attention_bam_384_attention_spatial_variance": 171.59618966886524,
      "attention_bam_384_attention_spatial_std": 13.099472877519355,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 18.502376104015156,
      "attention_bam_384_peak_intensity_mean": 0.23330900073051453,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22627981007099152,
      "attention_bam_16_std_attention": 0.49935439229011536,
      "attention_bam_16_max_attention": 3.9670791625976562,
      "attention_bam_16_min_attention": -0.9364013671875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 4.472463211052026,
      "attention_bam_16_attention_skewness": 1.1500186786489868,
      "attention_bam_16_attention_sparsity": 0.420166015625,
      "attention_bam_16_attention_concentration_10": 0.5213221189454902,
      "attention_bam_16_attention_concentration_20": 0.8276377128676851,
      "attention_bam_16_attention_center_y": 0.47681454721661104,
      "attention_bam_16_attention_center_x": 0.47624686997839394,
      "attention_bam_16_attention_center_distance": 0.04694201543594143,
      "attention_bam_16_attention_spatial_variance": 43.39277494225124,
      "attention_bam_16_attention_spatial_std": 6.587319253099188,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 10.182917154358373,
      "attention_bam_16_peak_intensity_mean": 0.24408094584941864,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 58,
      "phase": "train",
      "loss": 0.23050940036773682,
      "timestamp": 1759561896.6983156,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.23050940036773682,
      "ssim": 0.03559616953134537,
      "attention_bam_384_mean_attention": 0.18527013063430786,
      "attention_bam_384_std_attention": 0.48376187682151794,
      "attention_bam_384_max_attention": 4.515869140625,
      "attention_bam_384_min_attention": -1.3739013671875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.374086764441712,
      "attention_bam_384_attention_skewness": 0.7278906630574989,
      "attention_bam_384_attention_sparsity": 0.43592580159505206,
      "attention_bam_384_attention_concentration_10": 0.5817537271776823,
      "attention_bam_384_attention_concentration_20": 0.9327387350345119,
      "attention_bam_384_attention_center_y": 0.47893917114902107,
      "attention_bam_384_attention_center_x": 0.48913464176210636,
      "attention_bam_384_attention_center_distance": 0.03351460939733565,
      "attention_bam_384_attention_spatial_variance": 166.88800991032497,
      "attention_bam_384_attention_spatial_std": 12.918514229985002,
      "attention_bam_384_num_attention_peaks": 2,
      "attention_bam_384_peak_separation_mean": 16.688884087370308,
      "attention_bam_384_peak_intensity_mean": 0.27017003297805786,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20919552445411682,
      "attention_bam_16_std_attention": 0.4394896626472473,
      "attention_bam_16_max_attention": 3.6439208984375,
      "attention_bam_16_min_attention": -1.2073974609375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 5.731333234811428,
      "attention_bam_16_attention_skewness": 1.1872336493509137,
      "attention_bam_16_attention_sparsity": 0.409423828125,
      "attention_bam_16_attention_concentration_10": 0.4866846158687842,
      "attention_bam_16_attention_concentration_20": 0.7719422512000268,
      "attention_bam_16_attention_center_y": 0.47332376997943804,
      "attention_bam_16_attention_center_x": 0.47322013828365556,
      "attention_bam_16_attention_center_distance": 0.05345619218867842,
      "attention_bam_16_attention_spatial_variance": 41.66989844580347,
      "attention_bam_16_attention_spatial_std": 6.455222571360609,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 10.600798850840372,
      "attention_bam_16_peak_intensity_mean": 0.29066959023475647,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 59,
      "phase": "train",
      "loss": 0.2731233835220337,
      "timestamp": 1759561896.8705013,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.2731233835220337,
      "ssim": 0.02806875668466091,
      "attention_bam_384_mean_attention": 0.20186330378055573,
      "attention_bam_384_std_attention": 0.4568077325820923,
      "attention_bam_384_max_attention": 4.21337890625,
      "attention_bam_384_min_attention": -1.170166015625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.3931620848001489,
      "attention_bam_384_attention_skewness": 0.3487112999483815,
      "attention_bam_384_attention_sparsity": 0.4234670003255208,
      "attention_bam_384_attention_concentration_10": 0.5059586443575335,
      "attention_bam_384_attention_concentration_20": 0.842341025144004,
      "attention_bam_384_attention_center_y": 0.4773846456922936,
      "attention_bam_384_attention_center_x": 0.48151803204134896,
      "attention_bam_384_attention_center_distance": 0.04130465809294873,
      "attention_bam_384_attention_spatial_variance": 168.77957179721412,
      "attention_bam_384_attention_spatial_std": 12.99151922591096,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 10.63091887324903,
      "attention_bam_384_peak_intensity_mean": 0.2602928578853607,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2314862608909607,
      "attention_bam_16_std_attention": 0.43973013758659363,
      "attention_bam_16_max_attention": 3.57647705078125,
      "attention_bam_16_min_attention": -0.9163818359375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.2744306562317,
      "attention_bam_16_attention_skewness": 0.9043556842154847,
      "attention_bam_16_attention_sparsity": 0.3974609375,
      "attention_bam_16_attention_concentration_10": 0.44964627757369785,
      "attention_bam_16_attention_concentration_20": 0.7287393834917909,
      "attention_bam_16_attention_center_y": 0.46774312808702034,
      "attention_bam_16_attention_center_x": 0.4734329282016619,
      "attention_bam_16_attention_center_distance": 0.05909847865298103,
      "attention_bam_16_attention_spatial_variance": 42.83621925806621,
      "attention_bam_16_attention_spatial_std": 6.5449384457049105,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.909198907463537,
      "attention_bam_16_peak_intensity_mean": 0.2613445520401001,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 60,
      "phase": "train",
      "loss": 0.2889419198036194,
      "timestamp": 1759561897.1477654,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.2889419198036194,
      "ssim": 0.04596628248691559,
      "attention_bam_384_mean_attention": 0.19856120645999908,
      "attention_bam_384_std_attention": 0.5066681504249573,
      "attention_bam_384_max_attention": 4.5076904296875,
      "attention_bam_384_min_attention": -1.39501953125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5034051669654485,
      "attention_bam_384_attention_skewness": 0.619498818928519,
      "attention_bam_384_attention_sparsity": 0.4430084228515625,
      "attention_bam_384_attention_concentration_10": 0.5719565999823361,
      "attention_bam_384_attention_concentration_20": 0.9280096794917879,
      "attention_bam_384_attention_center_y": 0.4862607202298221,
      "attention_bam_384_attention_center_x": 0.48911530534044906,
      "attention_bam_384_attention_center_distance": 0.024788884058580644,
      "attention_bam_384_attention_spatial_variance": 168.71950519777192,
      "attention_bam_384_attention_spatial_std": 12.989207258249902,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 9.438956126072714,
      "attention_bam_384_peak_intensity_mean": 0.27743417024612427,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22565136849880219,
      "attention_bam_16_std_attention": 0.4771805703639984,
      "attention_bam_16_max_attention": 4.162353515625,
      "attention_bam_16_min_attention": -1.228515625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.8000382325163278,
      "attention_bam_16_attention_skewness": 0.8950617118184987,
      "attention_bam_16_attention_sparsity": 0.406494140625,
      "attention_bam_16_attention_concentration_10": 0.48737787180219805,
      "attention_bam_16_attention_concentration_20": 0.7871505685599512,
      "attention_bam_16_attention_center_y": 0.4676257523365438,
      "attention_bam_16_attention_center_x": 0.46419815124700253,
      "attention_bam_16_attention_center_distance": 0.06826220456310074,
      "attention_bam_16_attention_spatial_variance": 41.945784406791674,
      "attention_bam_16_attention_spatial_std": 6.4765565238629454,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.060514312864601,
      "attention_bam_16_peak_intensity_mean": 0.27478766441345215,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 61,
      "phase": "train",
      "loss": 0.2865070700645447,
      "timestamp": 1759561897.3361166,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.2865070700645447,
      "ssim": 0.04808909446001053,
      "attention_bam_384_mean_attention": 0.18424542248249054,
      "attention_bam_384_std_attention": 0.517902135848999,
      "attention_bam_384_max_attention": 4.92529296875,
      "attention_bam_384_min_attention": -1.2493896484375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.334618182412206,
      "attention_bam_384_attention_skewness": 0.856885798903948,
      "attention_bam_384_attention_sparsity": 0.4578094482421875,
      "attention_bam_384_attention_concentration_10": 0.6443734191301178,
      "attention_bam_384_attention_concentration_20": 1.0145139159674645,
      "attention_bam_384_attention_center_y": 0.4793384263924519,
      "attention_bam_384_attention_center_x": 0.49014413141576085,
      "attention_bam_384_attention_center_distance": 0.032374025683869496,
      "attention_bam_384_attention_spatial_variance": 170.85597627749934,
      "attention_bam_384_attention_spatial_std": 13.071188785932952,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 18.47132152657398,
      "attention_bam_384_peak_intensity_mean": 0.23197484016418457,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21553188562393188,
      "attention_bam_16_std_attention": 0.47501593828201294,
      "attention_bam_16_max_attention": 4.89349365234375,
      "attention_bam_16_min_attention": -1.183837890625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 10.178256092744299,
      "attention_bam_16_attention_skewness": 1.7166216436069301,
      "attention_bam_16_attention_sparsity": 0.411376953125,
      "attention_bam_16_attention_concentration_10": 0.5194823735949619,
      "attention_bam_16_attention_concentration_20": 0.8110332478251063,
      "attention_bam_16_attention_center_y": 0.4670550904097451,
      "attention_bam_16_attention_center_x": 0.476566862212517,
      "attention_bam_16_attention_center_distance": 0.05717480239541253,
      "attention_bam_16_attention_spatial_variance": 42.75008639843482,
      "attention_bam_16_attention_spatial_std": 6.538355022361115,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.267771975914918,
      "attention_bam_16_peak_intensity_mean": 0.23369376361370087,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 62,
      "phase": "train",
      "loss": 0.25887250900268555,
      "timestamp": 1759561897.5049508,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.25887250900268555,
      "ssim": 0.03922828286886215,
      "attention_bam_384_mean_attention": 0.1839427798986435,
      "attention_bam_384_std_attention": 0.5153570175170898,
      "attention_bam_384_max_attention": 3.80859375,
      "attention_bam_384_min_attention": -1.192138671875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5954796652567032,
      "attention_bam_384_attention_skewness": 0.5605486050004038,
      "attention_bam_384_attention_sparsity": 0.45415496826171875,
      "attention_bam_384_attention_concentration_10": 0.6300293158141103,
      "attention_bam_384_attention_concentration_20": 1.0143697283568316,
      "attention_bam_384_attention_center_y": 0.4871256390348798,
      "attention_bam_384_attention_center_x": 0.4802458909005981,
      "attention_bam_384_attention_center_distance": 0.033345884200940985,
      "attention_bam_384_attention_spatial_variance": 169.11958182287685,
      "attention_bam_384_attention_spatial_std": 13.004598487568805,
      "attention_bam_384_num_attention_peaks": 2,
      "attention_bam_384_peak_separation_mean": 20.32958584083657,
      "attention_bam_384_peak_intensity_mean": 0.27656039595603943,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23444530367851257,
      "attention_bam_16_std_attention": 0.5147183537483215,
      "attention_bam_16_max_attention": 3.37164306640625,
      "attention_bam_16_min_attention": -0.8446044921875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.4598853350349605,
      "attention_bam_16_attention_skewness": 1.1456443712103845,
      "attention_bam_16_attention_sparsity": 0.42236328125,
      "attention_bam_16_attention_concentration_10": 0.5273270969816871,
      "attention_bam_16_attention_concentration_20": 0.8268540002626603,
      "attention_bam_16_attention_center_y": 0.4664857790478972,
      "attention_bam_16_attention_center_x": 0.4763894431855561,
      "attention_bam_16_attention_center_distance": 0.05797691608070321,
      "attention_bam_16_attention_spatial_variance": 41.31589719144642,
      "attention_bam_16_attention_spatial_std": 6.4277443315245835,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.882219612520858,
      "attention_bam_16_peak_intensity_mean": 0.26051512360572815,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 63,
      "phase": "train",
      "loss": 0.2851073443889618,
      "timestamp": 1759561897.6939855,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.2851073443889618,
      "ssim": 0.020429354161024094,
      "attention_bam_384_mean_attention": 0.2100030779838562,
      "attention_bam_384_std_attention": 0.46403035521507263,
      "attention_bam_384_max_attention": 4.00634765625,
      "attention_bam_384_min_attention": -1.30517578125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.694653049050304,
      "attention_bam_384_attention_skewness": 0.4677545043885484,
      "attention_bam_384_attention_sparsity": 0.43015797932942706,
      "attention_bam_384_attention_concentration_10": 0.5119461567913478,
      "attention_bam_384_attention_concentration_20": 0.8409495126728426,
      "attention_bam_384_attention_center_y": 0.48319537350552993,
      "attention_bam_384_attention_center_x": 0.48316260622212953,
      "attention_bam_384_attention_center_distance": 0.03364203622998217,
      "attention_bam_384_attention_spatial_variance": 169.51790663496087,
      "attention_bam_384_attention_spatial_std": 13.019904248302323,
      "attention_bam_384_num_attention_peaks": 19,
      "attention_bam_384_peak_separation_mean": 16.17585649945904,
      "attention_bam_384_peak_intensity_mean": 0.28673362731933594,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2648122310638428,
      "attention_bam_16_std_attention": 0.4258951246738434,
      "attention_bam_16_max_attention": 4.21630859375,
      "attention_bam_16_min_attention": -0.9898681640625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 7.264275418648401,
      "attention_bam_16_attention_skewness": 1.204089212085271,
      "attention_bam_16_attention_sparsity": 0.349609375,
      "attention_bam_16_attention_concentration_10": 0.3904302894167046,
      "attention_bam_16_attention_concentration_20": 0.6361706279657889,
      "attention_bam_16_attention_center_y": 0.4735572938272561,
      "attention_bam_16_attention_center_x": 0.4803822844703542,
      "attention_bam_16_attention_center_distance": 0.04656332188193138,
      "attention_bam_16_attention_spatial_variance": 42.11979166689643,
      "attention_bam_16_attention_spatial_std": 6.489976245480135,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 7.907197596990333,
      "attention_bam_16_peak_intensity_mean": 0.24419815838336945,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 64,
      "phase": "train",
      "loss": 0.2794792652130127,
      "timestamp": 1759561897.8651667,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.2794792652130127,
      "ssim": 0.044352225959300995,
      "attention_bam_384_mean_attention": 0.1925942301750183,
      "attention_bam_384_std_attention": 0.4793716371059418,
      "attention_bam_384_max_attention": 3.9755859375,
      "attention_bam_384_min_attention": -1.1749267578125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6131824610292305,
      "attention_bam_384_attention_skewness": 0.4897330529795727,
      "attention_bam_384_attention_sparsity": 0.44355010986328125,
      "attention_bam_384_attention_concentration_10": 0.5729866710818822,
      "attention_bam_384_attention_concentration_20": 0.9273597951633801,
      "attention_bam_384_attention_center_y": 0.4864874103141027,
      "attention_bam_384_attention_center_x": 0.48237534354145994,
      "attention_bam_384_attention_center_distance": 0.031407597657285916,
      "attention_bam_384_attention_spatial_variance": 173.32840184786198,
      "attention_bam_384_attention_spatial_std": 13.165424484150217,
      "attention_bam_384_num_attention_peaks": 3,
      "attention_bam_384_peak_separation_mean": 26.592365482226523,
      "attention_bam_384_peak_intensity_mean": 0.271841436624527,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2303624153137207,
      "attention_bam_16_std_attention": 0.4457898437976837,
      "attention_bam_16_max_attention": 4.064399719238281,
      "attention_bam_16_min_attention": -0.953369140625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.860342337131997,
      "attention_bam_16_attention_skewness": 0.9272152958621364,
      "attention_bam_16_attention_sparsity": 0.390625,
      "attention_bam_16_attention_concentration_10": 0.4696882665209327,
      "attention_bam_16_attention_concentration_20": 0.7543706207680269,
      "attention_bam_16_attention_center_y": 0.4642806859899439,
      "attention_bam_16_attention_center_x": 0.4760792079009134,
      "attention_bam_16_attention_center_distance": 0.060795948680758584,
      "attention_bam_16_attention_spatial_variance": 42.05107894696461,
      "attention_bam_16_attention_spatial_std": 6.484680327276327,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.16826318165583,
      "attention_bam_16_peak_intensity_mean": 0.23950158059597015,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 65,
      "phase": "train",
      "loss": 0.21714279055595398,
      "timestamp": 1759561898.0321255,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.21714279055595398,
      "ssim": 0.04991630092263222,
      "attention_bam_384_mean_attention": 0.20178121328353882,
      "attention_bam_384_std_attention": 0.5155739188194275,
      "attention_bam_384_max_attention": 4.072509765625,
      "attention_bam_384_min_attention": -1.140625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1732335901507396,
      "attention_bam_384_attention_skewness": 0.56287075888559,
      "attention_bam_384_attention_sparsity": 0.4378712972005208,
      "attention_bam_384_attention_concentration_10": 0.5674531096502912,
      "attention_bam_384_attention_concentration_20": 0.9273862367405781,
      "attention_bam_384_attention_center_y": 0.48055669405592094,
      "attention_bam_384_attention_center_x": 0.48290092904870474,
      "attention_bam_384_attention_center_distance": 0.03661749236177948,
      "attention_bam_384_attention_spatial_variance": 169.23990252730397,
      "attention_bam_384_attention_spatial_std": 13.00922374806829,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 16.336963068192688,
      "attention_bam_384_peak_intensity_mean": 0.264900267124176,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23389364778995514,
      "attention_bam_16_std_attention": 0.5180310606956482,
      "attention_bam_16_max_attention": 4.7000732421875,
      "attention_bam_16_min_attention": -0.8133544921875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 4.749148599672142,
      "attention_bam_16_attention_skewness": 1.121914853977987,
      "attention_bam_16_attention_sparsity": 0.425537109375,
      "attention_bam_16_attention_concentration_10": 0.503839462666828,
      "attention_bam_16_attention_concentration_20": 0.8189375648513296,
      "attention_bam_16_attention_center_y": 0.47714176191182295,
      "attention_bam_16_attention_center_x": 0.4633677342690863,
      "attention_bam_16_attention_center_distance": 0.061064260268606604,
      "attention_bam_16_attention_spatial_variance": 42.363145313586635,
      "attention_bam_16_attention_spatial_std": 6.508697666475732,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.117413213024964,
      "attention_bam_16_peak_intensity_mean": 0.1949911266565323,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 66,
      "phase": "train",
      "loss": 0.23329941928386688,
      "timestamp": 1759561898.2021565,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.23329941928386688,
      "ssim": 0.037602394819259644,
      "attention_bam_384_mean_attention": 0.17472340166568756,
      "attention_bam_384_std_attention": 0.4710453450679779,
      "attention_bam_384_max_attention": 5.04150390625,
      "attention_bam_384_min_attention": -1.18603515625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.3262826869124842,
      "attention_bam_384_attention_skewness": 0.6240342399133533,
      "attention_bam_384_attention_sparsity": 0.43914794921875,
      "attention_bam_384_attention_concentration_10": 0.6053102886849498,
      "attention_bam_384_attention_concentration_20": 0.9632101778949231,
      "attention_bam_384_attention_center_y": 0.4778793609443882,
      "attention_bam_384_attention_center_x": 0.4938636171259986,
      "attention_bam_384_attention_center_distance": 0.03246468441260428,
      "attention_bam_384_attention_spatial_variance": 170.58824130539548,
      "attention_bam_384_attention_spatial_std": 13.06094335434449,
      "attention_bam_384_num_attention_peaks": 3,
      "attention_bam_384_peak_separation_mean": 16.83139395228454,
      "attention_bam_384_peak_intensity_mean": 0.21745885908603668,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2154495120048523,
      "attention_bam_16_std_attention": 0.43196386098861694,
      "attention_bam_16_max_attention": 3.247314453125,
      "attention_bam_16_min_attention": -0.859130859375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.7314053516513184,
      "attention_bam_16_attention_skewness": 0.7968368540969181,
      "attention_bam_16_attention_sparsity": 0.389892578125,
      "attention_bam_16_attention_concentration_10": 0.4752808230247171,
      "attention_bam_16_attention_concentration_20": 0.7656431077615795,
      "attention_bam_16_attention_center_y": 0.47138609449880753,
      "attention_bam_16_attention_center_x": 0.4750334672327685,
      "attention_bam_16_attention_center_distance": 0.05370443829793616,
      "attention_bam_16_attention_spatial_variance": 42.34774772324424,
      "attention_bam_16_attention_spatial_std": 6.507514711719386,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 7.573963794724229,
      "attention_bam_16_peak_intensity_mean": 0.26624858379364014,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 67,
      "phase": "train",
      "loss": 0.2632102370262146,
      "timestamp": 1759561898.3731844,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.2632102370262146,
      "ssim": 0.03638575226068497,
      "attention_bam_384_mean_attention": 0.18643729388713837,
      "attention_bam_384_std_attention": 0.46394243836402893,
      "attention_bam_384_max_attention": 4.26513671875,
      "attention_bam_384_min_attention": -1.1357421875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5468314946120696,
      "attention_bam_384_attention_skewness": 0.7406986215440196,
      "attention_bam_384_attention_sparsity": 0.43841298421223956,
      "attention_bam_384_attention_concentration_10": 0.5839081956618429,
      "attention_bam_384_attention_concentration_20": 0.9185173944252696,
      "attention_bam_384_attention_center_y": 0.4810922327674473,
      "attention_bam_384_attention_center_x": 0.4821688544163139,
      "attention_bam_384_attention_center_distance": 0.03675468445101936,
      "attention_bam_384_attention_spatial_variance": 168.5192773438198,
      "attention_bam_384_attention_spatial_std": 12.981497500050592,
      "attention_bam_384_num_attention_peaks": 2,
      "attention_bam_384_peak_separation_mean": 18.290303223862896,
      "attention_bam_384_peak_intensity_mean": 0.24860244989395142,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20987927913665771,
      "attention_bam_16_std_attention": 0.43032923340797424,
      "attention_bam_16_max_attention": 2.952056884765625,
      "attention_bam_16_min_attention": -0.72265625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 4.328335440580349,
      "attention_bam_16_attention_skewness": 1.2208508449148705,
      "attention_bam_16_attention_sparsity": 0.399169921875,
      "attention_bam_16_attention_concentration_10": 0.5005328454242737,
      "attention_bam_16_attention_concentration_20": 0.7713405127154189,
      "attention_bam_16_attention_center_y": 0.4684778456550656,
      "attention_bam_16_attention_center_x": 0.4684323430258489,
      "attention_bam_16_attention_center_distance": 0.06308982772814545,
      "attention_bam_16_attention_spatial_variance": 42.10465681736011,
      "attention_bam_16_attention_spatial_std": 6.488810123386267,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.90846109205564,
      "attention_bam_16_peak_intensity_mean": 0.26233893632888794,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 68,
      "phase": "train",
      "loss": 0.2571694850921631,
      "timestamp": 1759561898.5530639,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.2571694850921631,
      "ssim": 0.053891342133283615,
      "attention_bam_384_mean_attention": 0.18182696402072906,
      "attention_bam_384_std_attention": 0.5013434886932373,
      "attention_bam_384_max_attention": 4.136474609375,
      "attention_bam_384_min_attention": -1.212646484375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.9724838039394834,
      "attention_bam_384_attention_skewness": 1.0265701964806841,
      "attention_bam_384_attention_sparsity": 0.46272532145182294,
      "attention_bam_384_attention_concentration_10": 0.6426811949012454,
      "attention_bam_384_attention_concentration_20": 1.0004861417900135,
      "attention_bam_384_attention_center_y": 0.48183911784454103,
      "attention_bam_384_attention_center_x": 0.4880852869953453,
      "attention_bam_384_attention_center_distance": 0.03071735752462296,
      "attention_bam_384_attention_spatial_variance": 170.00690927088706,
      "attention_bam_384_attention_spatial_std": 13.038669766156634,
      "attention_bam_384_num_attention_peaks": 2,
      "attention_bam_384_peak_separation_mean": 23.66227881306486,
      "attention_bam_384_peak_intensity_mean": 0.2657957673072815,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.201073557138443,
      "attention_bam_16_std_attention": 0.4577004313468933,
      "attention_bam_16_max_attention": 3.988037109375,
      "attention_bam_16_min_attention": -0.96337890625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 7.524301713328981,
      "attention_bam_16_attention_skewness": 1.6298486705616273,
      "attention_bam_16_attention_sparsity": 0.435302734375,
      "attention_bam_16_attention_concentration_10": 0.5461210829959707,
      "attention_bam_16_attention_concentration_20": 0.8435747391777323,
      "attention_bam_16_attention_center_y": 0.4687374893001246,
      "attention_bam_16_attention_center_x": 0.47674950310953645,
      "attention_bam_16_attention_center_distance": 0.055098642105105976,
      "attention_bam_16_attention_spatial_variance": 42.10424717179754,
      "attention_bam_16_attention_spatial_std": 6.488778557771681,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.032101400256876,
      "attention_bam_16_peak_intensity_mean": 0.23792792856693268,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 69,
      "phase": "train",
      "loss": 0.18394526839256287,
      "timestamp": 1759561898.7484503,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.18394526839256287,
      "ssim": 0.05117392912507057,
      "attention_bam_384_mean_attention": 0.1873633712530136,
      "attention_bam_384_std_attention": 0.4916772246360779,
      "attention_bam_384_max_attention": 4.1722412109375,
      "attention_bam_384_min_attention": -1.19384765625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.9773910141848576,
      "attention_bam_384_attention_skewness": 0.9058657574892792,
      "attention_bam_384_attention_sparsity": 0.4408467610677083,
      "attention_bam_384_attention_concentration_10": 0.5943124651190295,
      "attention_bam_384_attention_concentration_20": 0.9454954117611218,
      "attention_bam_384_attention_center_y": 0.4837577291193181,
      "attention_bam_384_attention_center_x": 0.4966933049074629,
      "attention_bam_384_attention_center_distance": 0.023441228457419073,
      "attention_bam_384_attention_spatial_variance": 170.79711392261592,
      "attention_bam_384_attention_spatial_std": 13.068936985180391,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 17.06815339468497,
      "attention_bam_384_peak_intensity_mean": 0.26063933968544006,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20047637820243835,
      "attention_bam_16_std_attention": 0.4531845450401306,
      "attention_bam_16_max_attention": 4.338958740234375,
      "attention_bam_16_min_attention": -0.758056640625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 9.908300788354396,
      "attention_bam_16_attention_skewness": 1.7993330886961616,
      "attention_bam_16_attention_sparsity": 0.430908203125,
      "attention_bam_16_attention_concentration_10": 0.5225860953714127,
      "attention_bam_16_attention_concentration_20": 0.8272852266577178,
      "attention_bam_16_attention_center_y": 0.4654638928959029,
      "attention_bam_16_attention_center_x": 0.4727437324816658,
      "attention_bam_16_attention_center_distance": 0.06221972055444586,
      "attention_bam_16_attention_spatial_variance": 41.25698073967317,
      "attention_bam_16_attention_spatial_std": 6.423159716189001,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 7.34401506935491,
      "attention_bam_16_peak_intensity_mean": 0.1959642767906189,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 70,
      "phase": "train",
      "loss": 0.17453041672706604,
      "timestamp": 1759561899.1135461,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.17453041672706604,
      "ssim": 0.058838505297899246,
      "attention_bam_384_mean_attention": 0.1677233725786209,
      "attention_bam_384_std_attention": 0.523624062538147,
      "attention_bam_384_max_attention": 5.4053955078125,
      "attention_bam_384_min_attention": -1.342529296875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 8.26112325754609,
      "attention_bam_384_attention_skewness": 1.754364437818365,
      "attention_bam_384_attention_sparsity": 0.47412363688151044,
      "attention_bam_384_attention_concentration_10": 0.7159584206863001,
      "attention_bam_384_attention_concentration_20": 1.0789855805529749,
      "attention_bam_384_attention_center_y": 0.4897784075216617,
      "attention_bam_384_attention_center_x": 0.4931547321763385,
      "attention_bam_384_attention_center_distance": 0.017397623077356174,
      "attention_bam_384_attention_spatial_variance": 170.27329913937137,
      "attention_bam_384_attention_spatial_std": 13.048881145116288,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 16.553007939145854,
      "attention_bam_384_peak_intensity_mean": 0.22841131687164307,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1790696680545807,
      "attention_bam_16_std_attention": 0.464398056268692,
      "attention_bam_16_max_attention": 5.2740478515625,
      "attention_bam_16_min_attention": -0.845453143119812,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 16.991411266464937,
      "attention_bam_16_attention_skewness": 2.645561641234492,
      "attention_bam_16_attention_sparsity": 0.46923828125,
      "attention_bam_16_attention_concentration_10": 0.6068240155121964,
      "attention_bam_16_attention_concentration_20": 0.9134965476749279,
      "attention_bam_16_attention_center_y": 0.4610563459132345,
      "attention_bam_16_attention_center_x": 0.4810060745349776,
      "attention_bam_16_attention_center_distance": 0.06127605402113408,
      "attention_bam_16_attention_spatial_variance": 42.126425414641716,
      "attention_bam_16_attention_spatial_std": 6.490487301785723,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 8.951043817614467,
      "attention_bam_16_peak_intensity_mean": 0.17246055603027344,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 71,
      "phase": "train",
      "loss": 0.22047963738441467,
      "timestamp": 1759561899.3203456,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.22047963738441467,
      "ssim": 0.06570248305797577,
      "attention_bam_384_mean_attention": 0.18931008875370026,
      "attention_bam_384_std_attention": 0.5906841158866882,
      "attention_bam_384_max_attention": 4.74951171875,
      "attention_bam_384_min_attention": -1.2412109375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5269620130819117,
      "attention_bam_384_attention_skewness": 0.8268602133102708,
      "attention_bam_384_attention_sparsity": 0.46941375732421875,
      "attention_bam_384_attention_concentration_10": 0.7234592695497664,
      "attention_bam_384_attention_concentration_20": 1.1233257093690758,
      "attention_bam_384_attention_center_y": 0.48995338359217466,
      "attention_bam_384_attention_center_x": 0.4787417028040229,
      "attention_bam_384_attention_center_distance": 0.03325205861051232,
      "attention_bam_384_attention_spatial_variance": 168.72146991401377,
      "attention_bam_384_attention_spatial_std": 12.989282886826885,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 14.398865479587096,
      "attention_bam_384_peak_intensity_mean": 0.2400418519973755,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2078617513179779,
      "attention_bam_16_std_attention": 0.5552895665168762,
      "attention_bam_16_max_attention": 5.298309326171875,
      "attention_bam_16_min_attention": -1.166748046875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 7.24839226907905,
      "attention_bam_16_attention_skewness": 1.4576038177864046,
      "attention_bam_16_attention_sparsity": 0.44091796875,
      "attention_bam_16_attention_concentration_10": 0.6084254295069981,
      "attention_bam_16_attention_concentration_20": 0.9403494753701302,
      "attention_bam_16_attention_center_y": 0.46389420238186163,
      "attention_bam_16_attention_center_x": 0.4662424956356786,
      "attention_bam_16_attention_center_distance": 0.06990275706364013,
      "attention_bam_16_attention_spatial_variance": 42.163115588886086,
      "attention_bam_16_attention_spatial_std": 6.493313144218911,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.30955051588553,
      "attention_bam_16_peak_intensity_mean": 0.21718241274356842,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 72,
      "phase": "train",
      "loss": 0.22797761857509613,
      "timestamp": 1759561899.5045967,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.22797761857509613,
      "ssim": 0.05239962786436081,
      "attention_bam_384_mean_attention": 0.20450609922409058,
      "attention_bam_384_std_attention": 0.5456167459487915,
      "attention_bam_384_max_attention": 5.7646484375,
      "attention_bam_384_min_attention": -1.216552734375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8602028803302506,
      "attention_bam_384_attention_skewness": 0.7213449197624631,
      "attention_bam_384_attention_sparsity": 0.4440968831380208,
      "attention_bam_384_attention_concentration_10": 0.5959674167106268,
      "attention_bam_384_attention_concentration_20": 0.9637248304183078,
      "attention_bam_384_attention_center_y": 0.4814999940978002,
      "attention_bam_384_attention_center_x": 0.48389904438885806,
      "attention_bam_384_attention_center_distance": 0.03468403061852502,
      "attention_bam_384_attention_spatial_variance": 168.72499405087447,
      "attention_bam_384_attention_spatial_std": 12.989418541677471,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 16.11660544287671,
      "attention_bam_384_peak_intensity_mean": 0.2044840008020401,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22430342435836792,
      "attention_bam_16_std_attention": 0.5357726812362671,
      "attention_bam_16_max_attention": 4.5856170654296875,
      "attention_bam_16_min_attention": -0.905517578125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 4.535827497164308,
      "attention_bam_16_attention_skewness": 1.1474276213681953,
      "attention_bam_16_attention_sparsity": 0.443359375,
      "attention_bam_16_attention_concentration_10": 0.5526353394017794,
      "attention_bam_16_attention_concentration_20": 0.8859699903203616,
      "attention_bam_16_attention_center_y": 0.4772056899046325,
      "attention_bam_16_attention_center_x": 0.48516751516132656,
      "attention_bam_16_attention_center_distance": 0.03845993185675838,
      "attention_bam_16_attention_spatial_variance": 42.71002323521435,
      "attention_bam_16_attention_spatial_std": 6.535290600670666,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.840674058816074,
      "attention_bam_16_peak_intensity_mean": 0.2095799297094345,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 73,
      "phase": "train",
      "loss": 0.21875092387199402,
      "timestamp": 1759561899.68388,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.21875092387199402,
      "ssim": 0.05593167245388031,
      "attention_bam_384_mean_attention": 0.18527990579605103,
      "attention_bam_384_std_attention": 0.4937731921672821,
      "attention_bam_384_max_attention": 4.36376953125,
      "attention_bam_384_min_attention": -1.21142578125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.6741962549342704,
      "attention_bam_384_attention_skewness": 0.7243271206387273,
      "attention_bam_384_attention_sparsity": 0.45092519124348956,
      "attention_bam_384_attention_concentration_10": 0.6118212292970122,
      "attention_bam_384_attention_concentration_20": 0.9705304080458974,
      "attention_bam_384_attention_center_y": 0.48205319329737806,
      "attention_bam_384_attention_center_x": 0.483090014273315,
      "attention_bam_384_attention_center_distance": 0.03487220922448036,
      "attention_bam_384_attention_spatial_variance": 170.47521476147622,
      "attention_bam_384_attention_spatial_std": 13.056615746872396,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 20.027661468825663,
      "attention_bam_384_peak_intensity_mean": 0.2520119547843933,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21483340859413147,
      "attention_bam_16_std_attention": 0.47944217920303345,
      "attention_bam_16_max_attention": 4.167093276977539,
      "attention_bam_16_min_attention": -1.09765625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 4.041031551835918,
      "attention_bam_16_attention_skewness": 1.1507257278483898,
      "attention_bam_16_attention_sparsity": 0.44580078125,
      "attention_bam_16_attention_concentration_10": 0.5371562462787218,
      "attention_bam_16_attention_concentration_20": 0.8541715306300985,
      "attention_bam_16_attention_center_y": 0.47598320394345767,
      "attention_bam_16_attention_center_x": 0.47117101614021684,
      "attention_bam_16_attention_center_distance": 0.0530644288240095,
      "attention_bam_16_attention_spatial_variance": 42.75199899733128,
      "attention_bam_16_attention_spatial_std": 6.538501280670616,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 9.484974593799029,
      "attention_bam_16_peak_intensity_mean": 0.2566923201084137,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 74,
      "phase": "train",
      "loss": 0.2370455265045166,
      "timestamp": 1759561899.8547325,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.2370455265045166,
      "ssim": 0.06998513638973236,
      "attention_bam_384_mean_attention": 0.17225563526153564,
      "attention_bam_384_std_attention": 0.5498421788215637,
      "attention_bam_384_max_attention": 4.98046875,
      "attention_bam_384_min_attention": -1.22021484375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.2219525311345256,
      "attention_bam_384_attention_skewness": 1.2288861834457774,
      "attention_bam_384_attention_sparsity": 0.48403676350911456,
      "attention_bam_384_attention_concentration_10": 0.753305685987402,
      "attention_bam_384_attention_concentration_20": 1.133955946486013,
      "attention_bam_384_attention_center_y": 0.4678507265121213,
      "attention_bam_384_attention_center_x": 0.49133964962186993,
      "attention_bam_384_attention_center_distance": 0.047086674430679404,
      "attention_bam_384_attention_spatial_variance": 172.55985060511523,
      "attention_bam_384_attention_spatial_std": 13.136203812559975,
      "attention_bam_384_num_attention_peaks": 2,
      "attention_bam_384_peak_separation_mean": 21.81790001915113,
      "attention_bam_384_peak_intensity_mean": 0.2444012314081192,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20285984873771667,
      "attention_bam_16_std_attention": 0.5080795288085938,
      "attention_bam_16_max_attention": 3.9051513671875,
      "attention_bam_16_min_attention": -0.8709716796875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 6.207982335257876,
      "attention_bam_16_attention_skewness": 1.5113929243727255,
      "attention_bam_16_attention_sparsity": 0.437744140625,
      "attention_bam_16_attention_concentration_10": 0.5884612949213921,
      "attention_bam_16_attention_concentration_20": 0.8993266632739545,
      "attention_bam_16_attention_center_y": 0.46692451215703623,
      "attention_bam_16_attention_center_x": 0.478847152596236,
      "attention_bam_16_attention_center_distance": 0.055523523831561145,
      "attention_bam_16_attention_spatial_variance": 42.38582431121599,
      "attention_bam_16_attention_spatial_std": 6.510439640394187,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 10.109347177225816,
      "attention_bam_16_peak_intensity_mean": 0.23852553963661194,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 75,
      "phase": "train",
      "loss": 0.23623055219650269,
      "timestamp": 1759561900.038176,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.23623055219650269,
      "ssim": 0.09072452783584595,
      "attention_bam_384_mean_attention": 0.1841244250535965,
      "attention_bam_384_std_attention": 0.48409122228622437,
      "attention_bam_384_max_attention": 5.4453125,
      "attention_bam_384_min_attention": -1.293701171875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.34732613121981837,
      "attention_bam_384_attention_skewness": 0.27099193692956985,
      "attention_bam_384_attention_sparsity": 0.43189748128255206,
      "attention_bam_384_attention_concentration_10": 0.5695831551976783,
      "attention_bam_384_attention_concentration_20": 0.9417761575502035,
      "attention_bam_384_attention_center_y": 0.47695503354449215,
      "attention_bam_384_attention_center_x": 0.4861171594721384,
      "attention_bam_384_attention_center_distance": 0.03804743723452392,
      "attention_bam_384_attention_spatial_variance": 168.02301762947357,
      "attention_bam_384_attention_spatial_std": 12.962369290738232,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 7.723304571237251,
      "attention_bam_384_peak_intensity_mean": 0.21881002187728882,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22444604337215424,
      "attention_bam_16_std_attention": 0.4566630423069,
      "attention_bam_16_max_attention": 2.31756591796875,
      "attention_bam_16_min_attention": -1.005126953125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.822215376968523,
      "attention_bam_16_attention_skewness": 0.4197797099176877,
      "attention_bam_16_attention_sparsity": 0.388916015625,
      "attention_bam_16_attention_concentration_10": 0.4738332125300471,
      "attention_bam_16_attention_concentration_20": 0.7776973784629433,
      "attention_bam_16_attention_center_y": 0.4771046755773896,
      "attention_bam_16_attention_center_x": 0.4701804898742792,
      "attention_bam_16_attention_center_distance": 0.053167641748615206,
      "attention_bam_16_attention_spatial_variance": 41.736179646281464,
      "attention_bam_16_attention_spatial_std": 6.4603544520623215,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.669767731309689,
      "attention_bam_16_peak_intensity_mean": 0.38045644760131836,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 76,
      "phase": "train",
      "loss": 0.18074417114257812,
      "timestamp": 1759561900.205854,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.18074417114257812,
      "ssim": 0.08040137588977814,
      "attention_bam_384_mean_attention": 0.1865512728691101,
      "attention_bam_384_std_attention": 0.5171400308609009,
      "attention_bam_384_max_attention": 4.290283203125,
      "attention_bam_384_min_attention": -1.1552734375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.2398576941645496,
      "attention_bam_384_attention_skewness": 0.8592424136985344,
      "attention_bam_384_attention_sparsity": 0.45742543538411456,
      "attention_bam_384_attention_concentration_10": 0.6399800712140106,
      "attention_bam_384_attention_concentration_20": 1.0073401663336552,
      "attention_bam_384_attention_center_y": 0.4796441251205463,
      "attention_bam_384_attention_center_x": 0.4855596466210261,
      "attention_bam_384_attention_center_distance": 0.035295479818742134,
      "attention_bam_384_attention_spatial_variance": 170.03818431055137,
      "attention_bam_384_attention_spatial_std": 13.039869029654836,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 18.45523286032405,
      "attention_bam_384_peak_intensity_mean": 0.24978022277355194,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.217772975564003,
      "attention_bam_16_std_attention": 0.4715286195278168,
      "attention_bam_16_max_attention": 4.26385498046875,
      "attention_bam_16_min_attention": -1.0169677734375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 6.37953645790318,
      "attention_bam_16_attention_skewness": 1.4011307465856166,
      "attention_bam_16_attention_sparsity": 0.4169921875,
      "attention_bam_16_attention_concentration_10": 0.5260477661265942,
      "attention_bam_16_attention_concentration_20": 0.8138128188651764,
      "attention_bam_16_attention_center_y": 0.4638717122269454,
      "attention_bam_16_attention_center_x": 0.4712660020954658,
      "attention_bam_16_attention_center_distance": 0.06528239905197145,
      "attention_bam_16_attention_spatial_variance": 42.28749421575013,
      "attention_bam_16_attention_spatial_std": 6.502883530846153,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.394629195500599,
      "attention_bam_16_peak_intensity_mean": 0.2365097999572754,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 77,
      "phase": "train",
      "loss": 0.19181376695632935,
      "timestamp": 1759561900.3847234,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.19181376695632935,
      "ssim": 0.08428648114204407,
      "attention_bam_384_mean_attention": 0.19792009890079498,
      "attention_bam_384_std_attention": 0.4931405484676361,
      "attention_bam_384_max_attention": 4.671875,
      "attention_bam_384_min_attention": -1.314697265625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.874290330490986,
      "attention_bam_384_attention_skewness": 0.7862393269806988,
      "attention_bam_384_attention_sparsity": 0.4311625162760417,
      "attention_bam_384_attention_concentration_10": 0.5576309936761736,
      "attention_bam_384_attention_concentration_20": 0.8977681898922167,
      "attention_bam_384_attention_center_y": 0.4836664143471049,
      "attention_bam_384_attention_center_x": 0.4855629524319992,
      "attention_bam_384_attention_center_distance": 0.030829024076709875,
      "attention_bam_384_attention_spatial_variance": 167.11268064338373,
      "attention_bam_384_attention_spatial_std": 12.927206993135977,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 14.659563848901149,
      "attention_bam_384_peak_intensity_mean": 0.25589868426322937,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21893008053302765,
      "attention_bam_16_std_attention": 0.4644608795642853,
      "attention_bam_16_max_attention": 4.146728515625,
      "attention_bam_16_min_attention": -1.077880859375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 7.972302642190879,
      "attention_bam_16_attention_skewness": 1.5032474201090442,
      "attention_bam_16_attention_sparsity": 0.421875,
      "attention_bam_16_attention_concentration_10": 0.49757173031109864,
      "attention_bam_16_attention_concentration_20": 0.7899133067511486,
      "attention_bam_16_attention_center_y": 0.4700471125830379,
      "attention_bam_16_attention_center_x": 0.470975589477028,
      "attention_bam_16_attention_center_distance": 0.05898460597171461,
      "attention_bam_16_attention_spatial_variance": 41.7198119882335,
      "attention_bam_16_attention_spatial_std": 6.459087550748442,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.550810691236476,
      "attention_bam_16_peak_intensity_mean": 0.24938097596168518,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 78,
      "phase": "train",
      "loss": 0.22506855428218842,
      "timestamp": 1759561900.5594182,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.22506855428218842,
      "ssim": 0.0856553465127945,
      "attention_bam_384_mean_attention": 0.19222591817378998,
      "attention_bam_384_std_attention": 0.5536720752716064,
      "attention_bam_384_max_attention": 4.842983245849609,
      "attention_bam_384_min_attention": -1.192626953125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.520542817445981,
      "attention_bam_384_attention_skewness": 0.8479400948443694,
      "attention_bam_384_attention_sparsity": 0.45648193359375,
      "attention_bam_384_attention_concentration_10": 0.6453689578974835,
      "attention_bam_384_attention_concentration_20": 1.0297829044136615,
      "attention_bam_384_attention_center_y": 0.4820469479200373,
      "attention_bam_384_attention_center_x": 0.4797002940715786,
      "attention_bam_384_attention_center_distance": 0.03832466933363519,
      "attention_bam_384_attention_spatial_variance": 167.93510185778788,
      "attention_bam_384_attention_spatial_std": 12.958977654807029,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 16.897837273376688,
      "attention_bam_384_peak_intensity_mean": 0.23289412260055542,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20762044191360474,
      "attention_bam_16_std_attention": 0.5092981457710266,
      "attention_bam_16_max_attention": 5.586090087890625,
      "attention_bam_16_min_attention": -1.0518798828125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 10.408496581763968,
      "attention_bam_16_attention_skewness": 1.739814304098536,
      "attention_bam_16_attention_sparsity": 0.440673828125,
      "attention_bam_16_attention_concentration_10": 0.5626099354768478,
      "attention_bam_16_attention_concentration_20": 0.8971201963094273,
      "attention_bam_16_attention_center_y": 0.4773130873024192,
      "attention_bam_16_attention_center_x": 0.46634894005734284,
      "attention_bam_16_attention_center_distance": 0.05739494477760139,
      "attention_bam_16_attention_spatial_variance": 41.96688206897633,
      "attention_bam_16_attention_spatial_std": 6.478185090669788,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.903292868570892,
      "attention_bam_16_peak_intensity_mean": 0.19190476834774017,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 79,
      "phase": "train",
      "loss": 0.2196781039237976,
      "timestamp": 1759561900.7386208,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.2196781039237976,
      "ssim": 0.10288958251476288,
      "attention_bam_384_mean_attention": 0.2041345238685608,
      "attention_bam_384_std_attention": 0.5376307964324951,
      "attention_bam_384_max_attention": 5.2421875,
      "attention_bam_384_min_attention": -1.267822265625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.074868744437948,
      "attention_bam_384_attention_skewness": 0.5953230284780431,
      "attention_bam_384_attention_sparsity": 0.43744150797526044,
      "attention_bam_384_attention_concentration_10": 0.604420275699971,
      "attention_bam_384_attention_concentration_20": 0.9659122596324606,
      "attention_bam_384_attention_center_y": 0.47660604205869805,
      "attention_bam_384_attention_center_x": 0.48582657784884636,
      "attention_bam_384_attention_center_distance": 0.038682377476939464,
      "attention_bam_384_attention_spatial_variance": 167.91577741181382,
      "attention_bam_384_attention_spatial_std": 12.958232032642949,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 13.72587509955839,
      "attention_bam_384_peak_intensity_mean": 0.23136362433433533,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21525312960147858,
      "attention_bam_16_std_attention": 0.5026288628578186,
      "attention_bam_16_max_attention": 3.8111572265625,
      "attention_bam_16_min_attention": -1.02001953125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.3368898300927192,
      "attention_bam_16_attention_skewness": 0.9671691466928823,
      "attention_bam_16_attention_sparsity": 0.42724609375,
      "attention_bam_16_attention_concentration_10": 0.5500073275894873,
      "attention_bam_16_attention_concentration_20": 0.8703426760253185,
      "attention_bam_16_attention_center_y": 0.46503248598466146,
      "attention_bam_16_attention_center_x": 0.47749628740143213,
      "attention_bam_16_attention_center_distance": 0.058807212434051646,
      "attention_bam_16_attention_spatial_variance": 42.71460383962128,
      "attention_bam_16_attention_spatial_std": 6.535641042745637,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.837471515376219,
      "attention_bam_16_peak_intensity_mean": 0.2567446231842041,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 80,
      "phase": "train",
      "loss": 0.24085359275341034,
      "timestamp": 1759561901.0190184,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.24085359275341034,
      "ssim": 0.10932691395282745,
      "attention_bam_384_mean_attention": 0.19547085464000702,
      "attention_bam_384_std_attention": 0.4963949918746948,
      "attention_bam_384_max_attention": 4.9775390625,
      "attention_bam_384_min_attention": -1.1541748046875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.33350408908145956,
      "attention_bam_384_attention_skewness": 0.3943418993835501,
      "attention_bam_384_attention_sparsity": 0.44006601969401044,
      "attention_bam_384_attention_concentration_10": 0.5710823540890685,
      "attention_bam_384_attention_concentration_20": 0.9328263726612037,
      "attention_bam_384_attention_center_y": 0.4785361526619485,
      "attention_bam_384_attention_center_x": 0.4925357005574551,
      "attention_bam_384_attention_center_distance": 0.032137595078635145,
      "attention_bam_384_attention_spatial_variance": 168.64658310645407,
      "attention_bam_384_attention_spatial_std": 12.986399928635112,
      "attention_bam_384_num_attention_peaks": 4,
      "attention_bam_384_peak_separation_mean": 13.069984547002798,
      "attention_bam_384_peak_intensity_mean": 0.22447997331619263,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2230057418346405,
      "attention_bam_16_std_attention": 0.43484923243522644,
      "attention_bam_16_max_attention": 2.5921287536621094,
      "attention_bam_16_min_attention": -0.91448974609375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.3572892172512478,
      "attention_bam_16_attention_skewness": 0.4916150814759376,
      "attention_bam_16_attention_sparsity": 0.377197265625,
      "attention_bam_16_attention_concentration_10": 0.45610892454508667,
      "attention_bam_16_attention_concentration_20": 0.7443666040217962,
      "attention_bam_16_attention_center_y": 0.47297163583177904,
      "attention_bam_16_attention_center_x": 0.4710867184475109,
      "attention_bam_16_attention_center_distance": 0.05597339224566398,
      "attention_bam_16_attention_spatial_variance": 41.585998699871155,
      "attention_bam_16_attention_spatial_std": 6.4487207025790125,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.27813502346197,
      "attention_bam_16_peak_intensity_mean": 0.32467204332351685,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 81,
      "phase": "train",
      "loss": 0.2699161469936371,
      "timestamp": 1759561901.226654,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.2699161469936371,
      "ssim": 0.09278438985347748,
      "attention_bam_384_mean_attention": 0.19579870998859406,
      "attention_bam_384_std_attention": 0.5353970527648926,
      "attention_bam_384_max_attention": 5.27587890625,
      "attention_bam_384_min_attention": -1.160888671875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6847430781410089,
      "attention_bam_384_attention_skewness": 0.5664707517991914,
      "attention_bam_384_attention_sparsity": 0.4561818440755208,
      "attention_bam_384_attention_concentration_10": 0.6191489853951637,
      "attention_bam_384_attention_concentration_20": 0.9999385075725713,
      "attention_bam_384_attention_center_y": 0.46894646076859126,
      "attention_bam_384_attention_center_x": 0.49077141823065995,
      "attention_bam_384_attention_center_distance": 0.04581460510077627,
      "attention_bam_384_attention_spatial_variance": 170.11143389329357,
      "attention_bam_384_attention_spatial_std": 13.042677405091853,
      "attention_bam_384_num_attention_peaks": 4,
      "attention_bam_384_peak_separation_mean": 16.338409306170288,
      "attention_bam_384_peak_intensity_mean": 0.2166723906993866,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21136614680290222,
      "attention_bam_16_std_attention": 0.4952723979949951,
      "attention_bam_16_max_attention": 2.90313720703125,
      "attention_bam_16_min_attention": -0.9520263671875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.8058859211224512,
      "attention_bam_16_attention_skewness": 0.8117660833866186,
      "attention_bam_16_attention_sparsity": 0.439697265625,
      "attention_bam_16_attention_concentration_10": 0.5475146113219796,
      "attention_bam_16_attention_concentration_20": 0.8847359329511693,
      "attention_bam_16_attention_center_y": 0.4668718534853057,
      "attention_bam_16_attention_center_x": 0.4600688899298177,
      "attention_bam_16_attention_center_distance": 0.07337530433239874,
      "attention_bam_16_attention_spatial_variance": 42.17443995038004,
      "attention_bam_16_attention_spatial_std": 6.494185087474797,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 7.916281876988782,
      "attention_bam_16_peak_intensity_mean": 0.31040191650390625,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 82,
      "phase": "train",
      "loss": 0.18737101554870605,
      "timestamp": 1759561901.4025521,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.18737101554870605,
      "ssim": 0.08125748485326767,
      "attention_bam_384_mean_attention": 0.1927531212568283,
      "attention_bam_384_std_attention": 0.5996799468994141,
      "attention_bam_384_max_attention": 6.214111328125,
      "attention_bam_384_min_attention": -1.42919921875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 7.308137937849477,
      "attention_bam_384_attention_skewness": 1.5510250579377647,
      "attention_bam_384_attention_sparsity": 0.46570587158203125,
      "attention_bam_384_attention_concentration_10": 0.7022683516975996,
      "attention_bam_384_attention_concentration_20": 1.0795946475532154,
      "attention_bam_384_attention_center_y": 0.489168716999879,
      "attention_bam_384_attention_center_x": 0.48491371376199094,
      "attention_bam_384_attention_center_distance": 0.02626452831801292,
      "attention_bam_384_attention_spatial_variance": 169.75633720259592,
      "attention_bam_384_attention_spatial_std": 13.02905741804049,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 18.620353467533402,
      "attention_bam_384_peak_intensity_mean": 0.21357284486293793,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2126471996307373,
      "attention_bam_16_std_attention": 0.562800407409668,
      "attention_bam_16_max_attention": 5.75384521484375,
      "attention_bam_16_min_attention": -1.259521484375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 10.854435498681486,
      "attention_bam_16_attention_skewness": 1.7676608975508876,
      "attention_bam_16_attention_sparsity": 0.434814453125,
      "attention_bam_16_attention_concentration_10": 0.5852466260428577,
      "attention_bam_16_attention_concentration_20": 0.9060679812925808,
      "attention_bam_16_attention_center_y": 0.46875431569837483,
      "attention_bam_16_attention_center_x": 0.47113452695451047,
      "attention_bam_16_attention_center_distance": 0.06015826329967826,
      "attention_bam_16_attention_spatial_variance": 42.269843327877794,
      "attention_bam_16_attention_spatial_std": 6.501526230653676,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.232924714456619,
      "attention_bam_16_peak_intensity_mean": 0.21205776929855347,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 83,
      "phase": "train",
      "loss": 0.20391565561294556,
      "timestamp": 1759561901.5703876,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.20391565561294556,
      "ssim": 0.09559334814548492,
      "attention_bam_384_mean_attention": 0.2000114470720291,
      "attention_bam_384_std_attention": 0.5718159079551697,
      "attention_bam_384_max_attention": 5.09375,
      "attention_bam_384_min_attention": -1.36376953125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.7046401248878595,
      "attention_bam_384_attention_skewness": 0.7792449560395964,
      "attention_bam_384_attention_sparsity": 0.45567576090494794,
      "attention_bam_384_attention_concentration_10": 0.6580909268447682,
      "attention_bam_384_attention_concentration_20": 1.0366213809882274,
      "attention_bam_384_attention_center_y": 0.4876570177349041,
      "attention_bam_384_attention_center_x": 0.48317657185571705,
      "attention_bam_384_attention_center_distance": 0.029508539297034793,
      "attention_bam_384_attention_spatial_variance": 168.10513032363184,
      "attention_bam_384_attention_spatial_std": 12.965536252837051,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 13.383156113084679,
      "attention_bam_384_peak_intensity_mean": 0.24365663528442383,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21335193514823914,
      "attention_bam_16_std_attention": 0.5185651183128357,
      "attention_bam_16_max_attention": 4.189697265625,
      "attention_bam_16_min_attention": -1.16064453125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 4.339868695033553,
      "attention_bam_16_attention_skewness": 1.039107237779164,
      "attention_bam_16_attention_sparsity": 0.408447265625,
      "attention_bam_16_attention_concentration_10": 0.5599583134391021,
      "attention_bam_16_attention_concentration_20": 0.8703449397105536,
      "attention_bam_16_attention_center_y": 0.47380459983969514,
      "attention_bam_16_attention_center_x": 0.4740127527230035,
      "attention_bam_16_attention_center_distance": 0.052183062589201495,
      "attention_bam_16_attention_spatial_variance": 41.53506631119785,
      "attention_bam_16_attention_spatial_std": 6.4447704622583615,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.742842131777476,
      "attention_bam_16_peak_intensity_mean": 0.2567293047904968,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 84,
      "phase": "train",
      "loss": 0.1987510621547699,
      "timestamp": 1759561901.7402253,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.1987510621547699,
      "ssim": 0.08437713235616684,
      "attention_bam_384_mean_attention": 0.18745505809783936,
      "attention_bam_384_std_attention": 0.5232647061347961,
      "attention_bam_384_max_attention": 4.9140625,
      "attention_bam_384_min_attention": -1.0869140625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.719608809822202,
      "attention_bam_384_attention_skewness": 1.1051833076273831,
      "attention_bam_384_attention_sparsity": 0.4777984619140625,
      "attention_bam_384_attention_concentration_10": 0.6618380628900963,
      "attention_bam_384_attention_concentration_20": 1.025266557582425,
      "attention_bam_384_attention_center_y": 0.49090685248872235,
      "attention_bam_384_attention_center_x": 0.4823181799148849,
      "attention_bam_384_attention_center_distance": 0.028118751507996746,
      "attention_bam_384_attention_spatial_variance": 169.13531352824864,
      "attention_bam_384_attention_spatial_std": 13.00520332514062,
      "attention_bam_384_num_attention_peaks": 3,
      "attention_bam_384_peak_separation_mean": 20.00355257766106,
      "attention_bam_384_peak_intensity_mean": 0.2157999724149704,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.211500346660614,
      "attention_bam_16_std_attention": 0.4799724519252777,
      "attention_bam_16_max_attention": 4.4376373291015625,
      "attention_bam_16_min_attention": -0.84112548828125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 8.722332200950298,
      "attention_bam_16_attention_skewness": 1.8685859681295212,
      "attention_bam_16_attention_sparsity": 0.427734375,
      "attention_bam_16_attention_concentration_10": 0.5545884651187382,
      "attention_bam_16_attention_concentration_20": 0.8418806911324827,
      "attention_bam_16_attention_center_y": 0.48398660251050174,
      "attention_bam_16_attention_center_x": 0.47025977540196806,
      "attention_bam_16_attention_center_distance": 0.04776839662994883,
      "attention_bam_16_attention_spatial_variance": 42.06522674547203,
      "attention_bam_16_attention_spatial_std": 6.485771098757034,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.052249655689192,
      "attention_bam_16_peak_intensity_mean": 0.2050231248140335,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 85,
      "phase": "train",
      "loss": 0.22740857303142548,
      "timestamp": 1759561901.9113472,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.22740857303142548,
      "ssim": 0.10188329219818115,
      "attention_bam_384_mean_attention": 0.19295306503772736,
      "attention_bam_384_std_attention": 0.5240312218666077,
      "attention_bam_384_max_attention": 5.0771484375,
      "attention_bam_384_min_attention": -1.0810546875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.04079988939997392,
      "attention_bam_384_attention_skewness": 0.3978093118063948,
      "attention_bam_384_attention_sparsity": 0.4465891520182292,
      "attention_bam_384_attention_concentration_10": 0.614947095476834,
      "attention_bam_384_attention_concentration_20": 0.9997278525183806,
      "attention_bam_384_attention_center_y": 0.48130526808953894,
      "attention_bam_384_attention_center_x": 0.4758737820468084,
      "attention_bam_384_attention_center_distance": 0.04316404508219578,
      "attention_bam_384_attention_spatial_variance": 169.07062056542372,
      "attention_bam_384_attention_spatial_std": 13.002715891898266,
      "attention_bam_384_num_attention_peaks": 2,
      "attention_bam_384_peak_separation_mean": 17.415031167456842,
      "attention_bam_384_peak_intensity_mean": 0.21024559438228607,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24036285281181335,
      "attention_bam_16_std_attention": 0.4986724555492401,
      "attention_bam_16_max_attention": 2.633270263671875,
      "attention_bam_16_min_attention": -0.8925704956054688,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7065772370468011,
      "attention_bam_16_attention_skewness": 0.5642181433168882,
      "attention_bam_16_attention_sparsity": 0.386474609375,
      "attention_bam_16_attention_concentration_10": 0.5005235740638309,
      "attention_bam_16_attention_concentration_20": 0.8043530390028253,
      "attention_bam_16_attention_center_y": 0.4673183264903562,
      "attention_bam_16_attention_center_x": 0.4772514868327357,
      "attention_bam_16_attention_center_distance": 0.056313171367134866,
      "attention_bam_16_attention_spatial_variance": 41.938558053864874,
      "attention_bam_16_attention_spatial_std": 6.475998614411902,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.355277518560085,
      "attention_bam_16_peak_intensity_mean": 0.3245202600955963,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 86,
      "phase": "train",
      "loss": 0.14706648886203766,
      "timestamp": 1759561902.1012151,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.14706648886203766,
      "ssim": 0.12164124101400375,
      "attention_bam_384_mean_attention": 0.188595250248909,
      "attention_bam_384_std_attention": 0.5539929270744324,
      "attention_bam_384_max_attention": 5.22412109375,
      "attention_bam_384_min_attention": -1.197265625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.021993483086109,
      "attention_bam_384_attention_skewness": 0.6844491334374238,
      "attention_bam_384_attention_sparsity": 0.46493784586588544,
      "attention_bam_384_attention_concentration_10": 0.667911235515817,
      "attention_bam_384_attention_concentration_20": 1.059265236807336,
      "attention_bam_384_attention_center_y": 0.4814507649187297,
      "attention_bam_384_attention_center_x": 0.4828070228958538,
      "attention_bam_384_attention_center_distance": 0.03576793490834842,
      "attention_bam_384_attention_spatial_variance": 170.22062903546805,
      "attention_bam_384_attention_spatial_std": 13.046862804347567,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 17.580363577101288,
      "attention_bam_384_peak_intensity_mean": 0.21650587022304535,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22349879145622253,
      "attention_bam_16_std_attention": 0.5362013578414917,
      "attention_bam_16_max_attention": 4.1895751953125,
      "attention_bam_16_min_attention": -1.2276611328125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.8288743685952475,
      "attention_bam_16_attention_skewness": 0.8333583044272724,
      "attention_bam_16_attention_sparsity": 0.42529296875,
      "attention_bam_16_attention_concentration_10": 0.5508349695747813,
      "attention_bam_16_attention_concentration_20": 0.8796651720880657,
      "attention_bam_16_attention_center_y": 0.46984456703096744,
      "attention_bam_16_attention_center_x": 0.46816395843333103,
      "attention_bam_16_attention_center_distance": 0.062014251268309124,
      "attention_bam_16_attention_spatial_variance": 42.603215852385304,
      "attention_bam_16_attention_spatial_std": 6.527113899142967,
      "attention_bam_16_num_attention_peaks": 16,
      "attention_bam_16_peak_separation_mean": 8.99701645937495,
      "attention_bam_16_peak_intensity_mean": 0.271987646818161,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 87,
      "phase": "train",
      "loss": 0.1583968997001648,
      "timestamp": 1759561902.2690167,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.1583968997001648,
      "ssim": 0.10555540025234222,
      "attention_bam_384_mean_attention": 0.18988072872161865,
      "attention_bam_384_std_attention": 0.6089776754379272,
      "attention_bam_384_max_attention": 5.548828125,
      "attention_bam_384_min_attention": -1.2635498046875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 4.691124115566997,
      "attention_bam_384_attention_skewness": 1.3350094643000734,
      "attention_bam_384_attention_sparsity": 0.46821339925130206,
      "attention_bam_384_attention_concentration_10": 0.7389662666460592,
      "attention_bam_384_attention_concentration_20": 1.12604758182722,
      "attention_bam_384_attention_center_y": 0.48639801559462004,
      "attention_bam_384_attention_center_x": 0.49183164122857387,
      "attention_bam_384_attention_center_distance": 0.022438184631691303,
      "attention_bam_384_attention_spatial_variance": 169.70813138689118,
      "attention_bam_384_attention_spatial_std": 13.027207351803808,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 17.7994695073506,
      "attention_bam_384_peak_intensity_mean": 0.21693654358386993,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21132829785346985,
      "attention_bam_16_std_attention": 0.5610806941986084,
      "attention_bam_16_max_attention": 5.33172607421875,
      "attention_bam_16_min_attention": -0.96875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 8.231150895349765,
      "attention_bam_16_attention_skewness": 1.6331674275885717,
      "attention_bam_16_attention_sparsity": 0.415283203125,
      "attention_bam_16_attention_concentration_10": 0.6041663229141424,
      "attention_bam_16_attention_concentration_20": 0.9255464073301046,
      "attention_bam_16_attention_center_y": 0.47121309669853634,
      "attention_bam_16_attention_center_x": 0.4667682591191629,
      "attention_bam_16_attention_center_distance": 0.0621777195409886,
      "attention_bam_16_attention_spatial_variance": 42.15073152728798,
      "attention_bam_16_attention_spatial_std": 6.492359473048914,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.887525825938875,
      "attention_bam_16_peak_intensity_mean": 0.1882127821445465,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 88,
      "phase": "train",
      "loss": 0.16586697101593018,
      "timestamp": 1759561902.4350188,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.16586697101593018,
      "ssim": 0.11295664310455322,
      "attention_bam_384_mean_attention": 0.18622201681137085,
      "attention_bam_384_std_attention": 0.4561105966567993,
      "attention_bam_384_max_attention": 4.92041015625,
      "attention_bam_384_min_attention": -1.125732421875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.3243812505121464,
      "attention_bam_384_attention_skewness": 0.23032123312198835,
      "attention_bam_384_attention_sparsity": 0.42537180582682294,
      "attention_bam_384_attention_concentration_10": 0.5328012439317428,
      "attention_bam_384_attention_concentration_20": 0.8885667887317291,
      "attention_bam_384_attention_center_y": 0.4799120243302125,
      "attention_bam_384_attention_center_x": 0.4715082401941686,
      "attention_bam_384_attention_center_distance": 0.049301260497945976,
      "attention_bam_384_attention_spatial_variance": 167.24935949896707,
      "attention_bam_384_attention_spatial_std": 12.932492393153264,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 9.088051078983037,
      "attention_bam_384_peak_intensity_mean": 0.22339417040348053,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.228728786110878,
      "attention_bam_16_std_attention": 0.41314417123794556,
      "attention_bam_16_max_attention": 2.0085296630859375,
      "attention_bam_16_min_attention": -0.9202961921691895,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6608982138167674,
      "attention_bam_16_attention_skewness": 0.21405775173308816,
      "attention_bam_16_attention_sparsity": 0.36328125,
      "attention_bam_16_attention_concentration_10": 0.4172400698365189,
      "attention_bam_16_attention_concentration_20": 0.69587951682313,
      "attention_bam_16_attention_center_y": 0.4772763514738062,
      "attention_bam_16_attention_center_x": 0.46855340907330373,
      "attention_bam_16_attention_center_distance": 0.0548680650880449,
      "attention_bam_16_attention_spatial_variance": 42.095118939477544,
      "attention_bam_16_attention_spatial_std": 6.48807513361841,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 10.565147810203673,
      "attention_bam_16_peak_intensity_mean": 0.3996369242668152,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 89,
      "phase": "train",
      "loss": 0.18185412883758545,
      "timestamp": 1759561902.599224,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.18185412883758545,
      "ssim": 0.10733895003795624,
      "attention_bam_384_mean_attention": 0.2027606964111328,
      "attention_bam_384_std_attention": 0.5472707152366638,
      "attention_bam_384_max_attention": 4.70751953125,
      "attention_bam_384_min_attention": -1.306640625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.8379245744803407,
      "attention_bam_384_attention_skewness": 0.9854232252947501,
      "attention_bam_384_attention_sparsity": 0.4525044759114583,
      "attention_bam_384_attention_concentration_10": 0.6285631555429342,
      "attention_bam_384_attention_concentration_20": 0.9814036459556958,
      "attention_bam_384_attention_center_y": 0.4796482553548875,
      "attention_bam_384_attention_center_x": 0.4804994461120349,
      "attention_bam_384_attention_center_distance": 0.03986138763358089,
      "attention_bam_384_attention_spatial_variance": 168.96665965912464,
      "attention_bam_384_attention_spatial_std": 12.998717615946761,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 14.893740309157291,
      "attention_bam_384_peak_intensity_mean": 0.2516474723815918,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2130499929189682,
      "attention_bam_16_std_attention": 0.5238876938819885,
      "attention_bam_16_max_attention": 4.529266357421875,
      "attention_bam_16_min_attention": -1.075225830078125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 7.355277315425017,
      "attention_bam_16_attention_skewness": 1.5215677546498652,
      "attention_bam_16_attention_sparsity": 0.442626953125,
      "attention_bam_16_attention_concentration_10": 0.5654967080642701,
      "attention_bam_16_attention_concentration_20": 0.8891168223697126,
      "attention_bam_16_attention_center_y": 0.4666822588725161,
      "attention_bam_16_attention_center_x": 0.4730708284755876,
      "attention_bam_16_attention_center_distance": 0.06058468705587668,
      "attention_bam_16_attention_spatial_variance": 43.4202959439562,
      "attention_bam_16_attention_spatial_std": 6.589407859888186,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.705501814940336,
      "attention_bam_16_peak_intensity_mean": 0.2356429100036621,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 90,
      "phase": "train",
      "loss": 0.13874921202659607,
      "timestamp": 1759561902.8442574,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.13874921202659607,
      "ssim": 0.13995569944381714,
      "attention_bam_384_mean_attention": 0.1922656148672104,
      "attention_bam_384_std_attention": 0.5627776384353638,
      "attention_bam_384_max_attention": 5.07611083984375,
      "attention_bam_384_min_attention": -1.31103515625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.809640443417665,
      "attention_bam_384_attention_skewness": 1.1745862810196166,
      "attention_bam_384_attention_sparsity": 0.45914459228515625,
      "attention_bam_384_attention_concentration_10": 0.6733390719996795,
      "attention_bam_384_attention_concentration_20": 1.0356579927032141,
      "attention_bam_384_attention_center_y": 0.47904274705810884,
      "attention_bam_384_attention_center_x": 0.4739084067274235,
      "attention_bam_384_attention_center_distance": 0.04732816688552313,
      "attention_bam_384_attention_spatial_variance": 169.940326977049,
      "attention_bam_384_attention_spatial_std": 13.036116253587531,
      "attention_bam_384_num_attention_peaks": 2,
      "attention_bam_384_peak_separation_mean": 17.230730813843763,
      "attention_bam_384_peak_intensity_mean": 0.24153977632522583,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1997050940990448,
      "attention_bam_16_std_attention": 0.49749311804771423,
      "attention_bam_16_max_attention": 4.11639404296875,
      "attention_bam_16_min_attention": -0.989013671875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 6.590712007238679,
      "attention_bam_16_attention_skewness": 1.4916093629194096,
      "attention_bam_16_attention_sparsity": 0.426513671875,
      "attention_bam_16_attention_concentration_10": 0.575131387275835,
      "attention_bam_16_attention_concentration_20": 0.8855519280547393,
      "attention_bam_16_attention_center_y": 0.463791314058431,
      "attention_bam_16_attention_center_x": 0.4630131615850031,
      "attention_bam_16_attention_center_distance": 0.07319966056686693,
      "attention_bam_16_attention_spatial_variance": 42.573816039974886,
      "attention_bam_16_attention_spatial_std": 6.524861380901121,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.78776662089805,
      "attention_bam_16_peak_intensity_mean": 0.23547951877117157,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 91,
      "phase": "train",
      "loss": 0.14156502485275269,
      "timestamp": 1759561903.010997,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.14156502485275269,
      "ssim": 0.09426036477088928,
      "attention_bam_384_mean_attention": 0.188145712018013,
      "attention_bam_384_std_attention": 0.5058722496032715,
      "attention_bam_384_max_attention": 4.00244140625,
      "attention_bam_384_min_attention": -1.2718505859375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.425761585768033,
      "attention_bam_384_attention_skewness": 1.0386741673036375,
      "attention_bam_384_attention_sparsity": 0.444610595703125,
      "attention_bam_384_attention_concentration_10": 0.6228071073965301,
      "attention_bam_384_attention_concentration_20": 0.9628122754675624,
      "attention_bam_384_attention_center_y": 0.4897256606001481,
      "attention_bam_384_attention_center_x": 0.4877254167547837,
      "attention_bam_384_attention_center_distance": 0.02263746646367891,
      "attention_bam_384_attention_spatial_variance": 169.51436125112454,
      "attention_bam_384_attention_spatial_std": 13.019768095136124,
      "attention_bam_384_num_attention_peaks": 3,
      "attention_bam_384_peak_separation_mean": 19.82608022879381,
      "attention_bam_384_peak_intensity_mean": 0.2766718864440918,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21156767010688782,
      "attention_bam_16_std_attention": 0.46928292512893677,
      "attention_bam_16_max_attention": 3.9979248046875,
      "attention_bam_16_min_attention": -0.97705078125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 5.64967430542659,
      "attention_bam_16_attention_skewness": 1.2478526288518377,
      "attention_bam_16_attention_sparsity": 0.396240234375,
      "attention_bam_16_attention_concentration_10": 0.5123395679324253,
      "attention_bam_16_attention_concentration_20": 0.8001217207941496,
      "attention_bam_16_attention_center_y": 0.4707328198637529,
      "attention_bam_16_attention_center_x": 0.46773956504057124,
      "attention_bam_16_attention_center_distance": 0.0616003814419857,
      "attention_bam_16_attention_spatial_variance": 42.16463256057023,
      "attention_bam_16_attention_spatial_std": 6.49342995346606,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.661506825164595,
      "attention_bam_16_peak_intensity_mean": 0.24131953716278076,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 92,
      "phase": "train",
      "loss": 0.16147130727767944,
      "timestamp": 1759561903.1779346,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.16147130727767944,
      "ssim": 0.0958770141005516,
      "attention_bam_384_mean_attention": 0.19261057674884796,
      "attention_bam_384_std_attention": 0.48934388160705566,
      "attention_bam_384_max_attention": 4.646484375,
      "attention_bam_384_min_attention": -1.1697998046875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.496221223260748,
      "attention_bam_384_attention_skewness": 0.8544138670830701,
      "attention_bam_384_attention_sparsity": 0.4453531901041667,
      "attention_bam_384_attention_concentration_10": 0.5851390822419741,
      "attention_bam_384_attention_concentration_20": 0.9285723274694867,
      "attention_bam_384_attention_center_y": 0.4803397131345871,
      "attention_bam_384_attention_center_x": 0.4776132131512994,
      "attention_bam_384_attention_center_distance": 0.0421353795530426,
      "attention_bam_384_attention_spatial_variance": 170.5090514170842,
      "attention_bam_384_attention_spatial_std": 13.057911449274123,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 17.722379812974733,
      "attention_bam_384_peak_intensity_mean": 0.23687508702278137,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22655239701271057,
      "attention_bam_16_std_attention": 0.45379820466041565,
      "attention_bam_16_max_attention": 3.99560546875,
      "attention_bam_16_min_attention": -0.9123382568359375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 7.024147251148525,
      "attention_bam_16_attention_skewness": 1.3290304970212363,
      "attention_bam_16_attention_sparsity": 0.39794921875,
      "attention_bam_16_attention_concentration_10": 0.46406421236892925,
      "attention_bam_16_attention_concentration_20": 0.7435539593836448,
      "attention_bam_16_attention_center_y": 0.46661472061255016,
      "attention_bam_16_attention_center_x": 0.4611662878214681,
      "attention_bam_16_attention_center_distance": 0.07242422359049681,
      "attention_bam_16_attention_spatial_variance": 42.22878507980044,
      "attention_bam_16_attention_spatial_std": 6.498367878152209,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.746122059983081,
      "attention_bam_16_peak_intensity_mean": 0.23901736736297607,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 93,
      "phase": "train",
      "loss": 0.15045908093452454,
      "timestamp": 1759561903.3436866,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.15045908093452454,
      "ssim": 0.1551298201084137,
      "attention_bam_384_mean_attention": 0.1910717487335205,
      "attention_bam_384_std_attention": 0.52438884973526,
      "attention_bam_384_max_attention": 4.87890625,
      "attention_bam_384_min_attention": -1.1644287109375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.7436441385916588,
      "attention_bam_384_attention_skewness": 0.7942439167861157,
      "attention_bam_384_attention_sparsity": 0.4479878743489583,
      "attention_bam_384_attention_concentration_10": 0.6296080589324933,
      "attention_bam_384_attention_concentration_20": 0.9925724938326358,
      "attention_bam_384_attention_center_y": 0.4711937442810914,
      "attention_bam_384_attention_center_x": 0.4829933597640808,
      "attention_bam_384_attention_center_distance": 0.047308058101282066,
      "attention_bam_384_attention_spatial_variance": 171.38026020854286,
      "attention_bam_384_attention_spatial_std": 13.091228368970684,
      "attention_bam_384_num_attention_peaks": 2,
      "attention_bam_384_peak_separation_mean": 16.392004376485914,
      "attention_bam_384_peak_intensity_mean": 0.23350980877876282,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21549735963344574,
      "attention_bam_16_std_attention": 0.5039222836494446,
      "attention_bam_16_max_attention": 3.746337890625,
      "attention_bam_16_min_attention": -1.0442533493041992,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 4.9385136703817825,
      "attention_bam_16_attention_skewness": 1.161566632780631,
      "attention_bam_16_attention_sparsity": 0.4150390625,
      "attention_bam_16_attention_concentration_10": 0.5388085618427355,
      "attention_bam_16_attention_concentration_20": 0.8530584368372998,
      "attention_bam_16_attention_center_y": 0.46606951594303103,
      "attention_bam_16_attention_center_x": 0.46377482792185637,
      "attention_bam_16_attention_center_distance": 0.07019317403325401,
      "attention_bam_16_attention_spatial_variance": 42.639362598064935,
      "attention_bam_16_attention_spatial_std": 6.529882280567157,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.716811054124273,
      "attention_bam_16_peak_intensity_mean": 0.2673168480396271,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 94,
      "phase": "train",
      "loss": 0.17910772562026978,
      "timestamp": 1759561903.5102246,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.17910772562026978,
      "ssim": 0.10712851583957672,
      "attention_bam_384_mean_attention": 0.18436022102832794,
      "attention_bam_384_std_attention": 0.578262209892273,
      "attention_bam_384_max_attention": 4.553466796875,
      "attention_bam_384_min_attention": -1.19403076171875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 5.467554804696979,
      "attention_bam_384_attention_skewness": 1.5496835403544218,
      "attention_bam_384_attention_sparsity": 0.48300425211588544,
      "attention_bam_384_attention_concentration_10": 0.7384661360291095,
      "attention_bam_384_attention_concentration_20": 1.1072384400559128,
      "attention_bam_384_attention_center_y": 0.47645800779626907,
      "attention_bam_384_attention_center_x": 0.4944421397654739,
      "attention_bam_384_attention_center_distance": 0.034208630703582814,
      "attention_bam_384_attention_spatial_variance": 169.27012750437248,
      "attention_bam_384_attention_spatial_std": 13.010385371093836,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 15.548609923691666,
      "attention_bam_384_peak_intensity_mean": 0.23972482979297638,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19859227538108826,
      "attention_bam_16_std_attention": 0.5362984538078308,
      "attention_bam_16_max_attention": 5.151123046875,
      "attention_bam_16_min_attention": -0.99029541015625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 13.856082277031444,
      "attention_bam_16_attention_skewness": 2.413007268902504,
      "attention_bam_16_attention_sparsity": 0.43994140625,
      "attention_bam_16_attention_concentration_10": 0.6173483200049683,
      "attention_bam_16_attention_concentration_20": 0.9167595961920724,
      "attention_bam_16_attention_center_y": 0.4649726702051093,
      "attention_bam_16_attention_center_x": 0.4763951353883602,
      "attention_bam_16_attention_center_distance": 0.05973447021433911,
      "attention_bam_16_attention_spatial_variance": 42.65841837691089,
      "attention_bam_16_attention_spatial_std": 6.531341238743455,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.524645211276683,
      "attention_bam_16_peak_intensity_mean": 0.1967005729675293,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 95,
      "phase": "train",
      "loss": 0.12295129150152206,
      "timestamp": 1759561903.6819947,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.12295129150152206,
      "ssim": 0.10622473806142807,
      "attention_bam_384_mean_attention": 0.18050207197666168,
      "attention_bam_384_std_attention": 0.5242693424224854,
      "attention_bam_384_max_attention": 4.4267578125,
      "attention_bam_384_min_attention": -1.177978515625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.137655567627088,
      "attention_bam_384_attention_skewness": 1.1380370792592225,
      "attention_bam_384_attention_sparsity": 0.48095957438151044,
      "attention_bam_384_attention_concentration_10": 0.6814500812164896,
      "attention_bam_384_attention_concentration_20": 1.0569253581216802,
      "attention_bam_384_attention_center_y": 0.48218313086624687,
      "attention_bam_384_attention_center_x": 0.475223883386738,
      "attention_bam_384_attention_center_distance": 0.04315777520130626,
      "attention_bam_384_attention_spatial_variance": 168.46837127171239,
      "attention_bam_384_attention_spatial_std": 12.979536635477878,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 14.1901024126885,
      "attention_bam_384_peak_intensity_mean": 0.24448910355567932,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20331373810768127,
      "attention_bam_16_std_attention": 0.47736719250679016,
      "attention_bam_16_max_attention": 4.0518951416015625,
      "attention_bam_16_min_attention": -0.8876953125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 7.953924237772416,
      "attention_bam_16_attention_skewness": 1.6272919381823472,
      "attention_bam_16_attention_sparsity": 0.441162109375,
      "attention_bam_16_attention_concentration_10": 0.5493722439595735,
      "attention_bam_16_attention_concentration_20": 0.8574401901253472,
      "attention_bam_16_attention_center_y": 0.4693797758379406,
      "attention_bam_16_attention_center_x": 0.46403872174552563,
      "attention_bam_16_attention_center_distance": 0.06679538399366376,
      "attention_bam_16_attention_spatial_variance": 42.524847212041635,
      "attention_bam_16_attention_spatial_std": 6.521107820918286,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.701723268608047,
      "attention_bam_16_peak_intensity_mean": 0.2278095781803131,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 96,
      "phase": "train",
      "loss": 0.14567965269088745,
      "timestamp": 1759561903.8609488,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.14567965269088745,
      "ssim": 0.1361365020275116,
      "attention_bam_384_mean_attention": 0.17992150783538818,
      "attention_bam_384_std_attention": 0.5566271543502808,
      "attention_bam_384_max_attention": 4.25079345703125,
      "attention_bam_384_min_attention": -1.217529296875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.0820124369608353,
      "attention_bam_384_attention_skewness": 0.8810804790969962,
      "attention_bam_384_attention_sparsity": 0.4722340901692708,
      "attention_bam_384_attention_concentration_10": 0.7041501053584209,
      "attention_bam_384_attention_concentration_20": 1.1061027992612187,
      "attention_bam_384_attention_center_y": 0.49198179062134156,
      "attention_bam_384_attention_center_x": 0.48270298547021573,
      "attention_bam_384_attention_center_distance": 0.02696213616476166,
      "attention_bam_384_attention_spatial_variance": 169.9395955592502,
      "attention_bam_384_attention_spatial_std": 13.036088200041076,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 16.498522871081956,
      "attention_bam_384_peak_intensity_mean": 0.25535982847213745,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22320185601711273,
      "attention_bam_16_std_attention": 0.5515015721321106,
      "attention_bam_16_max_attention": 4.8648681640625,
      "attention_bam_16_min_attention": -1.0980224609375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 7.604897779343185,
      "attention_bam_16_attention_skewness": 1.607992058947449,
      "attention_bam_16_attention_sparsity": 0.42333984375,
      "attention_bam_16_attention_concentration_10": 0.5781492978390409,
      "attention_bam_16_attention_concentration_20": 0.8865298695267813,
      "attention_bam_16_attention_center_y": 0.4731382282331778,
      "attention_bam_16_attention_center_x": 0.47034386140692036,
      "attention_bam_16_attention_center_distance": 0.056586947942167606,
      "attention_bam_16_attention_spatial_variance": 42.449055944672615,
      "attention_bam_16_attention_spatial_std": 6.5152940029343736,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.540254608965085,
      "attention_bam_16_peak_intensity_mean": 0.22320567071437836,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 97,
      "phase": "train",
      "loss": 0.1360432207584381,
      "timestamp": 1759561904.0307786,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.1360432207584381,
      "ssim": 0.10203294456005096,
      "attention_bam_384_mean_attention": 0.17942959070205688,
      "attention_bam_384_std_attention": 0.5271511673927307,
      "attention_bam_384_max_attention": 4.45654296875,
      "attention_bam_384_min_attention": -1.22998046875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.4947742220543674,
      "attention_bam_384_attention_skewness": 1.0166954159207289,
      "attention_bam_384_attention_sparsity": 0.48068491617838544,
      "attention_bam_384_attention_concentration_10": 0.6827948041558609,
      "attention_bam_384_attention_concentration_20": 1.0669655487266934,
      "attention_bam_384_attention_center_y": 0.48691269782250907,
      "attention_bam_384_attention_center_x": 0.47826712247447506,
      "attention_bam_384_attention_center_distance": 0.03587744260184736,
      "attention_bam_384_attention_spatial_variance": 171.36948082761722,
      "attention_bam_384_attention_spatial_std": 13.090816660071946,
      "attention_bam_384_num_attention_peaks": 2,
      "attention_bam_384_peak_separation_mean": 21.983981784632615,
      "attention_bam_384_peak_intensity_mean": 0.2540919780731201,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21118207275867462,
      "attention_bam_16_std_attention": 0.5025805234909058,
      "attention_bam_16_max_attention": 3.9902114868164062,
      "attention_bam_16_min_attention": -0.8153076171875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 6.1512113376520094,
      "attention_bam_16_attention_skewness": 1.4498838658652362,
      "attention_bam_16_attention_sparsity": 0.432861328125,
      "attention_bam_16_attention_concentration_10": 0.555017083099094,
      "attention_bam_16_attention_concentration_20": 0.8674089090865132,
      "attention_bam_16_attention_center_y": 0.47485579763722435,
      "attention_bam_16_attention_center_x": 0.4737303437870166,
      "attention_bam_16_attention_center_distance": 0.051426175241963086,
      "attention_bam_16_attention_spatial_variance": 43.45131146994162,
      "attention_bam_16_attention_spatial_std": 6.591760877788395,
      "attention_bam_16_num_attention_peaks": 12,
      "attention_bam_16_peak_separation_mean": 9.566137158178005,
      "attention_bam_16_peak_intensity_mean": 0.21867746114730835,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 98,
      "phase": "train",
      "loss": 0.1303795874118805,
      "timestamp": 1759561904.2013063,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.1303795874118805,
      "ssim": 0.15254449844360352,
      "attention_bam_384_mean_attention": 0.19012810289859772,
      "attention_bam_384_std_attention": 0.48719146847724915,
      "attention_bam_384_max_attention": 4.697265625,
      "attention_bam_384_min_attention": -1.248046875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8900189717380984,
      "attention_bam_384_attention_skewness": 0.7851618280241225,
      "attention_bam_384_attention_sparsity": 0.44641367594401044,
      "attention_bam_384_attention_concentration_10": 0.5958909284440616,
      "attention_bam_384_attention_concentration_20": 0.9455703931494982,
      "attention_bam_384_attention_center_y": 0.46832792697322384,
      "attention_bam_384_attention_center_x": 0.4849398925693549,
      "attention_bam_384_attention_center_distance": 0.049596916146793124,
      "attention_bam_384_attention_spatial_variance": 171.83026160290504,
      "attention_bam_384_attention_spatial_std": 13.108404235562201,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 15.165180780249553,
      "attention_bam_384_peak_intensity_mean": 0.2527591288089752,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21566063165664673,
      "attention_bam_16_std_attention": 0.4503113031387329,
      "attention_bam_16_max_attention": 4.020263671875,
      "attention_bam_16_min_attention": -0.917236328125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 6.038392229546391,
      "attention_bam_16_attention_skewness": 1.1907800903411334,
      "attention_bam_16_attention_sparsity": 0.39794921875,
      "attention_bam_16_attention_concentration_10": 0.48642544534900123,
      "attention_bam_16_attention_concentration_20": 0.7787698113745155,
      "attention_bam_16_attention_center_y": 0.4635798594630689,
      "attention_bam_16_attention_center_x": 0.4755053928266395,
      "attention_bam_16_attention_center_distance": 0.06207112722203545,
      "attention_bam_16_attention_spatial_variance": 42.99631030259441,
      "attention_bam_16_attention_spatial_std": 6.557157181476925,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.659430743942576,
      "attention_bam_16_peak_intensity_mean": 0.23366442322731018,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 99,
      "phase": "train",
      "loss": 0.15005993843078613,
      "timestamp": 1759561904.3843362,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.15005993843078613,
      "ssim": 0.168793722987175,
      "attention_bam_384_mean_attention": 0.18936489522457123,
      "attention_bam_384_std_attention": 0.51832115650177,
      "attention_bam_384_max_attention": 4.8017578125,
      "attention_bam_384_min_attention": -1.1796875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6069481753594741,
      "attention_bam_384_attention_skewness": 0.5380144376405568,
      "attention_bam_384_attention_sparsity": 0.4567921956380208,
      "attention_bam_384_attention_concentration_10": 0.6191268388456387,
      "attention_bam_384_attention_concentration_20": 1.0006885917149206,
      "attention_bam_384_attention_center_y": 0.48623193024307954,
      "attention_bam_384_attention_center_x": 0.4910414604174496,
      "attention_bam_384_attention_center_distance": 0.023229945169265895,
      "attention_bam_384_attention_spatial_variance": 169.76967790659307,
      "attention_bam_384_attention_spatial_std": 13.029569367657286,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 16.49855392568788,
      "attention_bam_384_peak_intensity_mean": 0.23163890838623047,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22293442487716675,
      "attention_bam_16_std_attention": 0.48274075984954834,
      "attention_bam_16_max_attention": 3.1402587890625,
      "attention_bam_16_min_attention": -1.07958984375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.545218410894031,
      "attention_bam_16_attention_skewness": 0.899243563018928,
      "attention_bam_16_attention_sparsity": 0.422119140625,
      "attention_bam_16_attention_concentration_10": 0.5162137564615483,
      "attention_bam_16_attention_concentration_20": 0.8231415058760688,
      "attention_bam_16_attention_center_y": 0.4697690100375449,
      "attention_bam_16_attention_center_x": 0.4715881169118333,
      "attention_bam_16_attention_center_distance": 0.05867108069101361,
      "attention_bam_16_attention_spatial_variance": 42.34578193071809,
      "attention_bam_16_attention_spatial_std": 6.50736366977581,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.151068585993677,
      "attention_bam_16_peak_intensity_mean": 0.31063324213027954,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 100,
      "phase": "train",
      "loss": 0.10103954374790192,
      "timestamp": 1759561904.6642666,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.10103954374790192,
      "ssim": 0.15977373719215393,
      "attention_bam_384_mean_attention": 0.18264003098011017,
      "attention_bam_384_std_attention": 0.5202842950820923,
      "attention_bam_384_max_attention": 4.37841796875,
      "attention_bam_384_min_attention": -1.2021484375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.2117852454836493,
      "attention_bam_384_attention_skewness": 0.8252412800768748,
      "attention_bam_384_attention_sparsity": 0.4589131673177083,
      "attention_bam_384_attention_concentration_10": 0.6555074237095248,
      "attention_bam_384_attention_concentration_20": 1.0277430456364762,
      "attention_bam_384_attention_center_y": 0.48644096813204374,
      "attention_bam_384_attention_center_x": 0.4834957548926432,
      "attention_bam_384_attention_center_distance": 0.03020719953123642,
      "attention_bam_384_attention_spatial_variance": 170.51306940318446,
      "attention_bam_384_attention_spatial_std": 13.058065300923582,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 16.998937726268654,
      "attention_bam_384_peak_intensity_mean": 0.24826422333717346,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21988123655319214,
      "attention_bam_16_std_attention": 0.5257718563079834,
      "attention_bam_16_max_attention": 4.6151123046875,
      "attention_bam_16_min_attention": -1.1630859375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 6.443374340947475,
      "attention_bam_16_attention_skewness": 1.397602610021133,
      "attention_bam_16_attention_sparsity": 0.424560546875,
      "attention_bam_16_attention_concentration_10": 0.5636283391484439,
      "attention_bam_16_attention_concentration_20": 0.8693579145443111,
      "attention_bam_16_attention_center_y": 0.4765286719956962,
      "attention_bam_16_attention_center_x": 0.47214766201580805,
      "attention_bam_16_attention_center_distance": 0.05151030905500912,
      "attention_bam_16_attention_spatial_variance": 42.99917251768331,
      "attention_bam_16_attention_spatial_std": 6.557375429063317,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 8.62334537376987,
      "attention_bam_16_peak_intensity_mean": 0.24230842292308807,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 101,
      "phase": "train",
      "loss": 0.11776690185070038,
      "timestamp": 1759561906.1273992,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.11776690185070038,
      "ssim": 0.20584365725517273,
      "attention_bam_384_mean_attention": 0.18050970137119293,
      "attention_bam_384_std_attention": 0.5034061670303345,
      "attention_bam_384_max_attention": 4.40185546875,
      "attention_bam_384_min_attention": -1.2955322265625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.1452111674890153,
      "attention_bam_384_attention_skewness": 1.0063173156651517,
      "attention_bam_384_attention_sparsity": 0.4599609375,
      "attention_bam_384_attention_concentration_10": 0.6435546078516038,
      "attention_bam_384_attention_concentration_20": 1.003754285332368,
      "attention_bam_384_attention_center_y": 0.49137942201542373,
      "attention_bam_384_attention_center_x": 0.48887836819780567,
      "attention_bam_384_attention_center_distance": 0.019900002951343573,
      "attention_bam_384_attention_spatial_variance": 168.5787150617915,
      "attention_bam_384_attention_spatial_std": 12.983786622622521,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 18.073175680377283,
      "attention_bam_384_peak_intensity_mean": 0.26256850361824036,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20072773098945618,
      "attention_bam_16_std_attention": 0.4587841331958771,
      "attention_bam_16_max_attention": 4.06158447265625,
      "attention_bam_16_min_attention": -1.1419677734375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 8.162382662039331,
      "attention_bam_16_attention_skewness": 1.5367300887950168,
      "attention_bam_16_attention_sparsity": 0.41015625,
      "attention_bam_16_attention_concentration_10": 0.5294128476671257,
      "attention_bam_16_attention_concentration_20": 0.8230654736396606,
      "attention_bam_16_attention_center_y": 0.4746190568084579,
      "attention_bam_16_attention_center_x": 0.4773581235235431,
      "attention_bam_16_attention_center_distance": 0.04810087000600756,
      "attention_bam_16_attention_spatial_variance": 42.39915814199003,
      "attention_bam_16_attention_spatial_std": 6.511463594460928,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.714432091110794,
      "attention_bam_16_peak_intensity_mean": 0.26051637530326843,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 102,
      "phase": "train",
      "loss": 0.1454375982284546,
      "timestamp": 1759561906.3234158,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.1454375982284546,
      "ssim": 0.11241239309310913,
      "attention_bam_384_mean_attention": 0.18058456480503082,
      "attention_bam_384_std_attention": 0.4911315143108368,
      "attention_bam_384_max_attention": 4.0947265625,
      "attention_bam_384_min_attention": -1.250732421875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.1893819662662546,
      "attention_bam_384_attention_skewness": 0.9381408184379263,
      "attention_bam_384_attention_sparsity": 0.4553629557291667,
      "attention_bam_384_attention_concentration_10": 0.6246620822105201,
      "attention_bam_384_attention_concentration_20": 0.9828152761558895,
      "attention_bam_384_attention_center_y": 0.4799503718892434,
      "attention_bam_384_attention_center_x": 0.49104939742345066,
      "attention_bam_384_attention_center_distance": 0.031051598150915623,
      "attention_bam_384_attention_spatial_variance": 172.31698799520692,
      "attention_bam_384_attention_spatial_std": 13.126956539701307,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 16.837160596802462,
      "attention_bam_384_peak_intensity_mean": 0.27116310596466064,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20955845713615417,
      "attention_bam_16_std_attention": 0.4810854196548462,
      "attention_bam_16_max_attention": 4.60662841796875,
      "attention_bam_16_min_attention": -0.904541015625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 9.395941412641845,
      "attention_bam_16_attention_skewness": 1.7486124024168044,
      "attention_bam_16_attention_sparsity": 0.42529296875,
      "attention_bam_16_attention_concentration_10": 0.5370286200191573,
      "attention_bam_16_attention_concentration_20": 0.833980387141742,
      "attention_bam_16_attention_center_y": 0.4698587955163232,
      "attention_bam_16_attention_center_x": 0.4730369046045649,
      "attention_bam_16_attention_center_distance": 0.057192669478354524,
      "attention_bam_16_attention_spatial_variance": 43.05788402832129,
      "attention_bam_16_attention_spatial_std": 6.5618506557465395,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 7.834192765002421,
      "attention_bam_16_peak_intensity_mean": 0.203753262758255,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 103,
      "phase": "train",
      "loss": 0.1280127763748169,
      "timestamp": 1759561906.5349517,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.1280127763748169,
      "ssim": 0.2000066041946411,
      "attention_bam_384_mean_attention": 0.17855091392993927,
      "attention_bam_384_std_attention": 0.48046591877937317,
      "attention_bam_384_max_attention": 4.65771484375,
      "attention_bam_384_min_attention": -1.21875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 4.044634523611839,
      "attention_bam_384_attention_skewness": 1.1739463150460392,
      "attention_bam_384_attention_sparsity": 0.46148681640625,
      "attention_bam_384_attention_concentration_10": 0.6316147573507779,
      "attention_bam_384_attention_concentration_20": 0.9738822503587782,
      "attention_bam_384_attention_center_y": 0.4835599408807035,
      "attention_bam_384_attention_center_x": 0.4793187808226273,
      "attention_bam_384_attention_center_distance": 0.03736277212703825,
      "attention_bam_384_attention_spatial_variance": 171.00916354085473,
      "attention_bam_384_attention_spatial_std": 13.077047202669826,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 16.298147833362034,
      "attention_bam_384_peak_intensity_mean": 0.2374824732542038,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2102889120578766,
      "attention_bam_16_std_attention": 0.4479650855064392,
      "attention_bam_16_max_attention": 4.3929443359375,
      "attention_bam_16_min_attention": -0.9486083984375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 9.923191302143483,
      "attention_bam_16_attention_skewness": 1.8747726629667039,
      "attention_bam_16_attention_sparsity": 0.414794921875,
      "attention_bam_16_attention_concentration_10": 0.5117389501968967,
      "attention_bam_16_attention_concentration_20": 0.786988184015381,
      "attention_bam_16_attention_center_y": 0.4729397242423739,
      "attention_bam_16_attention_center_x": 0.4650148337950687,
      "attention_bam_16_attention_center_distance": 0.06254950644833952,
      "attention_bam_16_attention_spatial_variance": 42.82846144016987,
      "attention_bam_16_attention_spatial_std": 6.544345761049753,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 8.753501911344578,
      "attention_bam_16_peak_intensity_mean": 0.21800649166107178,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 104,
      "phase": "train",
      "loss": 0.12305307388305664,
      "timestamp": 1759561906.708454,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.12305307388305664,
      "ssim": 0.1331726312637329,
      "attention_bam_384_mean_attention": 0.18155141174793243,
      "attention_bam_384_std_attention": 0.499362051486969,
      "attention_bam_384_max_attention": 4.76953125,
      "attention_bam_384_min_attention": -1.239990234375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.8107334891389257,
      "attention_bam_384_attention_skewness": 0.8640827540470601,
      "attention_bam_384_attention_sparsity": 0.45270538330078125,
      "attention_bam_384_attention_concentration_10": 0.62356658322547,
      "attention_bam_384_attention_concentration_20": 0.9898919672190399,
      "attention_bam_384_attention_center_y": 0.47781495694405474,
      "attention_bam_384_attention_center_x": 0.49578138029365354,
      "attention_bam_384_attention_center_distance": 0.03193658991254138,
      "attention_bam_384_attention_spatial_variance": 172.2279450394356,
      "attention_bam_384_attention_spatial_std": 13.123564494428928,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 15.304625544675655,
      "attention_bam_384_peak_intensity_mean": 0.23588262498378754,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21017372608184814,
      "attention_bam_16_std_attention": 0.4679473340511322,
      "attention_bam_16_max_attention": 2.7957801818847656,
      "attention_bam_16_min_attention": -0.940399169921875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.4636034923749826,
      "attention_bam_16_attention_skewness": 0.5814351133186334,
      "attention_bam_16_attention_sparsity": 0.410888671875,
      "attention_bam_16_attention_concentration_10": 0.5077511677048783,
      "attention_bam_16_attention_concentration_20": 0.8244487582608215,
      "attention_bam_16_attention_center_y": 0.46833224093768727,
      "attention_bam_16_attention_center_x": 0.47501901700159266,
      "attention_bam_16_attention_center_distance": 0.057042027937221976,
      "attention_bam_16_attention_spatial_variance": 42.494834933282654,
      "attention_bam_16_attention_spatial_std": 6.518806250632293,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 7.159865775852722,
      "attention_bam_16_peak_intensity_mean": 0.3087492287158966,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 105,
      "phase": "train",
      "loss": 0.11535134166479111,
      "timestamp": 1759561906.8811197,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.11535134166479111,
      "ssim": 0.17423835396766663,
      "attention_bam_384_mean_attention": 0.17543429136276245,
      "attention_bam_384_std_attention": 0.606335461139679,
      "attention_bam_384_max_attention": 5.173583984375,
      "attention_bam_384_min_attention": -1.2916259765625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 5.536482177423297,
      "attention_bam_384_attention_skewness": 1.477467469156263,
      "attention_bam_384_attention_sparsity": 0.48518625895182294,
      "attention_bam_384_attention_concentration_10": 0.7883987774714689,
      "attention_bam_384_attention_concentration_20": 1.1945625186792634,
      "attention_bam_384_attention_center_y": 0.4864494335686601,
      "attention_bam_384_attention_center_x": 0.49269255873214685,
      "attention_bam_384_attention_center_distance": 0.021772301141279433,
      "attention_bam_384_attention_spatial_variance": 168.68336216542286,
      "attention_bam_384_attention_spatial_std": 12.987815912054762,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 14.040496183515145,
      "attention_bam_384_peak_intensity_mean": 0.22907887399196625,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19139060378074646,
      "attention_bam_16_std_attention": 0.570317804813385,
      "attention_bam_16_max_attention": 5.0152587890625,
      "attention_bam_16_min_attention": -1.15771484375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 11.546151803166987,
      "attention_bam_16_attention_skewness": 2.133440397494345,
      "attention_bam_16_attention_sparsity": 0.45556640625,
      "attention_bam_16_attention_concentration_10": 0.6831281455246966,
      "attention_bam_16_attention_concentration_20": 1.0194932172900704,
      "attention_bam_16_attention_center_y": 0.46794640005545335,
      "attention_bam_16_attention_center_x": 0.4704314839918391,
      "attention_bam_16_attention_center_distance": 0.061672204571101695,
      "attention_bam_16_attention_spatial_variance": 42.46650752171455,
      "attention_bam_16_attention_spatial_std": 6.516633143097327,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.018540376813927,
      "attention_bam_16_peak_intensity_mean": 0.2177187204360962,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 106,
      "phase": "train",
      "loss": 0.08912257850170135,
      "timestamp": 1759561907.0536692,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.08912257850170135,
      "ssim": 0.17287753522396088,
      "attention_bam_384_mean_attention": 0.1813175529241562,
      "attention_bam_384_std_attention": 0.5438304543495178,
      "attention_bam_384_max_attention": 4.99853515625,
      "attention_bam_384_min_attention": -1.181640625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.027134235123177,
      "attention_bam_384_attention_skewness": 0.8173942737045109,
      "attention_bam_384_attention_sparsity": 0.4664052327473958,
      "attention_bam_384_attention_concentration_10": 0.6722236034998358,
      "attention_bam_384_attention_concentration_20": 1.0690857155441333,
      "attention_bam_384_attention_center_y": 0.4877326939693671,
      "attention_bam_384_attention_center_x": 0.4891107792482623,
      "attention_bam_384_attention_center_distance": 0.02319749666792854,
      "attention_bam_384_attention_spatial_variance": 169.3158277715662,
      "attention_bam_384_attention_spatial_std": 13.012141552087659,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 14.635756300653451,
      "attention_bam_384_peak_intensity_mean": 0.22243241965770721,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2319278120994568,
      "attention_bam_16_std_attention": 0.5420334935188293,
      "attention_bam_16_max_attention": 4.7008056640625,
      "attention_bam_16_min_attention": -0.97869873046875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 6.318983100782063,
      "attention_bam_16_attention_skewness": 1.375914394756656,
      "attention_bam_16_attention_sparsity": 0.416259765625,
      "attention_bam_16_attention_concentration_10": 0.5448011784775898,
      "attention_bam_16_attention_concentration_20": 0.8555480284035033,
      "attention_bam_16_attention_center_y": 0.47308382250545833,
      "attention_bam_16_attention_center_x": 0.47082787939886456,
      "attention_bam_16_attention_center_distance": 0.05613364822073944,
      "attention_bam_16_attention_spatial_variance": 43.179242417526645,
      "attention_bam_16_attention_spatial_std": 6.571091417529256,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 10.546119341996485,
      "attention_bam_16_peak_intensity_mean": 0.21899601817131042,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 107,
      "phase": "train",
      "loss": 0.10635988414287567,
      "timestamp": 1759561907.2595756,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.10635988414287567,
      "ssim": 0.17379187047481537,
      "attention_bam_384_mean_attention": 0.18491031229496002,
      "attention_bam_384_std_attention": 0.5299955606460571,
      "attention_bam_384_max_attention": 4.45166015625,
      "attention_bam_384_min_attention": -1.221435546875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.9054310340543203,
      "attention_bam_384_attention_skewness": 0.7814402752748932,
      "attention_bam_384_attention_sparsity": 0.46391550699869794,
      "attention_bam_384_attention_concentration_10": 0.6546279774199605,
      "attention_bam_384_attention_concentration_20": 1.033449480870972,
      "attention_bam_384_attention_center_y": 0.48006978383046356,
      "attention_bam_384_attention_center_x": 0.4847787576917485,
      "attention_bam_384_attention_center_distance": 0.03546546866942427,
      "attention_bam_384_attention_spatial_variance": 169.50874171695534,
      "attention_bam_384_attention_spatial_std": 13.01955228558015,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 18.943526136386634,
      "attention_bam_384_peak_intensity_mean": 0.24772436916828156,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20778919756412506,
      "attention_bam_16_std_attention": 0.512383222579956,
      "attention_bam_16_max_attention": 3.9003524780273438,
      "attention_bam_16_min_attention": -1.113037109375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 4.943569058967298,
      "attention_bam_16_attention_skewness": 1.2885045292060724,
      "attention_bam_16_attention_sparsity": 0.43310546875,
      "attention_bam_16_attention_concentration_10": 0.5834811753987542,
      "attention_bam_16_attention_concentration_20": 0.8998828713472106,
      "attention_bam_16_attention_center_y": 0.46896808496009396,
      "attention_bam_16_attention_center_x": 0.4719817321934683,
      "attention_bam_16_attention_center_distance": 0.0591270341201464,
      "attention_bam_16_attention_spatial_variance": 42.72647059401803,
      "attention_bam_16_attention_spatial_std": 6.5365488290089315,
      "attention_bam_16_num_attention_peaks": 11,
      "attention_bam_16_peak_separation_mean": 10.110958604482162,
      "attention_bam_16_peak_intensity_mean": 0.2713894546031952,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 108,
      "phase": "train",
      "loss": 0.09262785315513611,
      "timestamp": 1759561907.4662478,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.09262785315513611,
      "ssim": 0.21091581881046295,
      "attention_bam_384_mean_attention": 0.1813739389181137,
      "attention_bam_384_std_attention": 0.489701509475708,
      "attention_bam_384_max_attention": 4.458984375,
      "attention_bam_384_min_attention": -1.192626953125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9936077007518072,
      "attention_bam_384_attention_skewness": 0.5458660255303226,
      "attention_bam_384_attention_sparsity": 0.4476114908854167,
      "attention_bam_384_attention_concentration_10": 0.6099430497754119,
      "attention_bam_384_attention_concentration_20": 0.9778802344083848,
      "attention_bam_384_attention_center_y": 0.48453985128534477,
      "attention_bam_384_attention_center_x": 0.4839511355010729,
      "attention_bam_384_attention_center_distance": 0.03151451252944201,
      "attention_bam_384_attention_spatial_variance": 170.05758099429235,
      "attention_bam_384_attention_spatial_std": 13.040612753789308,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 15.342212601171642,
      "attention_bam_384_peak_intensity_mean": 0.24477991461753845,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22670121490955353,
      "attention_bam_16_std_attention": 0.48553311824798584,
      "attention_bam_16_max_attention": 3.805908203125,
      "attention_bam_16_min_attention": -0.96044921875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.693544907072061,
      "attention_bam_16_attention_skewness": 0.8242840081515728,
      "attention_bam_16_attention_sparsity": 0.40478515625,
      "attention_bam_16_attention_concentration_10": 0.5051105384770466,
      "attention_bam_16_attention_concentration_20": 0.8095380855316393,
      "attention_bam_16_attention_center_y": 0.4740033301407118,
      "attention_bam_16_attention_center_x": 0.4678791823212547,
      "attention_bam_16_attention_center_distance": 0.05843926372096113,
      "attention_bam_16_attention_spatial_variance": 42.55325260258473,
      "attention_bam_16_attention_spatial_std": 6.523285414772585,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.836035326588558,
      "attention_bam_16_peak_intensity_mean": 0.25706619024276733,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 109,
      "phase": "train",
      "loss": 0.11563043296337128,
      "timestamp": 1759561907.6700559,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.11563043296337128,
      "ssim": 0.1937595158815384,
      "attention_bam_384_mean_attention": 0.18991832435131073,
      "attention_bam_384_std_attention": 0.5399767160415649,
      "attention_bam_384_max_attention": 4.4267578125,
      "attention_bam_384_min_attention": -1.15966796875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.122309605698943,
      "attention_bam_384_attention_skewness": 0.650512778338863,
      "attention_bam_384_attention_sparsity": 0.45763397216796875,
      "attention_bam_384_attention_concentration_10": 0.6468603297741908,
      "attention_bam_384_attention_concentration_20": 1.030672455894901,
      "attention_bam_384_attention_center_y": 0.48406498822403454,
      "attention_bam_384_attention_center_x": 0.48213187569702554,
      "attention_bam_384_attention_center_distance": 0.033858365772928396,
      "attention_bam_384_attention_spatial_variance": 166.9506022794427,
      "attention_bam_384_attention_spatial_std": 12.9209365867743,
      "attention_bam_384_num_attention_peaks": 3,
      "attention_bam_384_peak_separation_mean": 14.157560452739787,
      "attention_bam_384_peak_intensity_mean": 0.24722565710544586,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22147752344608307,
      "attention_bam_16_std_attention": 0.5466269850730896,
      "attention_bam_16_max_attention": 4.4306640625,
      "attention_bam_16_min_attention": -1.01953125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.6582935129232466,
      "attention_bam_16_attention_skewness": 1.0227075363585216,
      "attention_bam_16_attention_sparsity": 0.43017578125,
      "attention_bam_16_attention_concentration_10": 0.573144709662355,
      "attention_bam_16_attention_concentration_20": 0.9030959547047562,
      "attention_bam_16_attention_center_y": 0.47621234917213967,
      "attention_bam_16_attention_center_x": 0.46791252351263296,
      "attention_bam_16_attention_center_distance": 0.05648820194050323,
      "attention_bam_16_attention_spatial_variance": 42.22499350977862,
      "attention_bam_16_attention_spatial_std": 6.498076139118302,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.04631910913693,
      "attention_bam_16_peak_intensity_mean": 0.2297336459159851,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 110,
      "phase": "train",
      "loss": 0.10997515916824341,
      "timestamp": 1759561907.9713986,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.10997515916824341,
      "ssim": 0.27916857600212097,
      "attention_bam_384_mean_attention": 0.18654532730579376,
      "attention_bam_384_std_attention": 0.5994794368743896,
      "attention_bam_384_max_attention": 4.824623107910156,
      "attention_bam_384_min_attention": -1.3056640625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.355179189571671,
      "attention_bam_384_attention_skewness": 0.972230872793165,
      "attention_bam_384_attention_sparsity": 0.4794921875,
      "attention_bam_384_attention_concentration_10": 0.7353600981729581,
      "attention_bam_384_attention_concentration_20": 1.148240295643723,
      "attention_bam_384_attention_center_y": 0.48411982226691275,
      "attention_bam_384_attention_center_x": 0.4832985234897933,
      "attention_bam_384_attention_center_distance": 0.0325920040026822,
      "attention_bam_384_attention_spatial_variance": 170.52528340176127,
      "attention_bam_384_attention_spatial_std": 13.058532972802162,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 20.983625454011495,
      "attention_bam_384_peak_intensity_mean": 0.24280652403831482,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20610958337783813,
      "attention_bam_16_std_attention": 0.5641427040100098,
      "attention_bam_16_max_attention": 4.548095703125,
      "attention_bam_16_min_attention": -1.029052734375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 5.838915518165955,
      "attention_bam_16_attention_skewness": 1.3440921402474364,
      "attention_bam_16_attention_sparsity": 0.446533203125,
      "attention_bam_16_attention_concentration_10": 0.6319725299199711,
      "attention_bam_16_attention_concentration_20": 0.9805432127925219,
      "attention_bam_16_attention_center_y": 0.47297781275993755,
      "attention_bam_16_attention_center_x": 0.47231240995713264,
      "attention_bam_16_attention_center_distance": 0.05471382358451804,
      "attention_bam_16_attention_spatial_variance": 43.11893859301503,
      "attention_bam_16_attention_spatial_std": 6.566501244423474,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.438026623875352,
      "attention_bam_16_peak_intensity_mean": 0.2251635640859604,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 111,
      "phase": "train",
      "loss": 0.08863697946071625,
      "timestamp": 1759561908.1499946,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.08863697946071625,
      "ssim": 0.21877238154411316,
      "attention_bam_384_mean_attention": 0.17653654515743256,
      "attention_bam_384_std_attention": 0.5516356825828552,
      "attention_bam_384_max_attention": 5.754150390625,
      "attention_bam_384_min_attention": -1.20947265625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 6.122118508305075,
      "attention_bam_384_attention_skewness": 1.4266475943857753,
      "attention_bam_384_attention_sparsity": 0.46810658772786456,
      "attention_bam_384_attention_concentration_10": 0.7090324268811494,
      "attention_bam_384_attention_concentration_20": 1.0885775783237743,
      "attention_bam_384_attention_center_y": 0.4885113205874025,
      "attention_bam_384_attention_center_x": 0.4791529830361499,
      "attention_bam_384_attention_center_distance": 0.03366267579787727,
      "attention_bam_384_attention_spatial_variance": 169.92133559607305,
      "attention_bam_384_attention_spatial_std": 13.03538781916645,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 15.664239049772654,
      "attention_bam_384_peak_intensity_mean": 0.20015233755111694,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20809003710746765,
      "attention_bam_16_std_attention": 0.5644471645355225,
      "attention_bam_16_max_attention": 6.4259033203125,
      "attention_bam_16_min_attention": -1.01171875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 17.557130579881655,
      "attention_bam_16_attention_skewness": 2.5664413698044477,
      "attention_bam_16_attention_sparsity": 0.4453125,
      "attention_bam_16_attention_concentration_10": 0.6137315941009662,
      "attention_bam_16_attention_concentration_20": 0.9329192220897162,
      "attention_bam_16_attention_center_y": 0.47255392981054867,
      "attention_bam_16_attention_center_x": 0.4670935081025306,
      "attention_bam_16_attention_center_distance": 0.060599075534904144,
      "attention_bam_16_attention_spatial_variance": 42.99434879949039,
      "attention_bam_16_attention_spatial_std": 6.55700761014431,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.628126471291319,
      "attention_bam_16_peak_intensity_mean": 0.16972030699253082,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 112,
      "phase": "train",
      "loss": 0.10330149531364441,
      "timestamp": 1759561908.335194,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.10330149531364441,
      "ssim": 0.2919008135795593,
      "attention_bam_384_mean_attention": 0.17843012511730194,
      "attention_bam_384_std_attention": 0.4955613911151886,
      "attention_bam_384_max_attention": 4.62890625,
      "attention_bam_384_min_attention": -1.19921875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6065913636113285,
      "attention_bam_384_attention_skewness": 0.47682167515170226,
      "attention_bam_384_attention_sparsity": 0.46106211344401044,
      "attention_bam_384_attention_concentration_10": 0.6236046438343104,
      "attention_bam_384_attention_concentration_20": 1.0112048283191306,
      "attention_bam_384_attention_center_y": 0.4844943756934253,
      "attention_bam_384_attention_center_x": 0.49339426868143277,
      "attention_bam_384_attention_center_distance": 0.02383527098187643,
      "attention_bam_384_attention_spatial_variance": 169.23504961634885,
      "attention_bam_384_attention_spatial_std": 13.00903722864797,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 14.479461118782021,
      "attention_bam_384_peak_intensity_mean": 0.2376524806022644,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2156534343957901,
      "attention_bam_16_std_attention": 0.4574211835861206,
      "attention_bam_16_max_attention": 3.680419921875,
      "attention_bam_16_min_attention": -0.95318603515625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.447149623709567,
      "attention_bam_16_attention_skewness": 0.7548155927286668,
      "attention_bam_16_attention_sparsity": 0.407470703125,
      "attention_bam_16_attention_concentration_10": 0.5067224483311054,
      "attention_bam_16_attention_concentration_20": 0.8021551165010803,
      "attention_bam_16_attention_center_y": 0.47044152787083293,
      "attention_bam_16_attention_center_x": 0.4723110050343724,
      "attention_bam_16_attention_center_distance": 0.05727798384750107,
      "attention_bam_16_attention_spatial_variance": 42.62878828247776,
      "attention_bam_16_attention_spatial_std": 6.529072543821041,
      "attention_bam_16_num_attention_peaks": 11,
      "attention_bam_16_peak_separation_mean": 7.831012754255349,
      "attention_bam_16_peak_intensity_mean": 0.2559208869934082,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 113,
      "phase": "train",
      "loss": 0.09636865556240082,
      "timestamp": 1759561908.5132396,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.09636865556240082,
      "ssim": 0.24300412833690643,
      "attention_bam_384_mean_attention": 0.18509410321712494,
      "attention_bam_384_std_attention": 0.4734802544116974,
      "attention_bam_384_max_attention": 5.1669921875,
      "attention_bam_384_min_attention": -1.1910400390625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 7.39304596767794,
      "attention_bam_384_attention_skewness": 1.4470105357414906,
      "attention_bam_384_attention_sparsity": 0.44632720947265625,
      "attention_bam_384_attention_concentration_10": 0.5861633382498357,
      "attention_bam_384_attention_concentration_20": 0.9143524896868043,
      "attention_bam_384_attention_center_y": 0.48743679587657984,
      "attention_bam_384_attention_center_x": 0.48465685198407016,
      "attention_bam_384_attention_center_distance": 0.028044474995458663,
      "attention_bam_384_attention_spatial_variance": 169.00383720017635,
      "attention_bam_384_attention_spatial_std": 13.000147583784438,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 15.143157194823374,
      "attention_bam_384_peak_intensity_mean": 0.21779614686965942,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20278038084506989,
      "attention_bam_16_std_attention": 0.45084163546562195,
      "attention_bam_16_max_attention": 5.5164794921875,
      "attention_bam_16_min_attention": -0.884033203125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 20.832848454767497,
      "attention_bam_16_attention_skewness": 2.67362188471408,
      "attention_bam_16_attention_sparsity": 0.4306640625,
      "attention_bam_16_attention_concentration_10": 0.5085501479507105,
      "attention_bam_16_attention_concentration_20": 0.7987582045970952,
      "attention_bam_16_attention_center_y": 0.4770098290589291,
      "attention_bam_16_attention_center_x": 0.4717622057860852,
      "attention_bam_16_attention_center_distance": 0.05149603833242053,
      "attention_bam_16_attention_spatial_variance": 42.485701530188294,
      "attention_bam_16_attention_spatial_std": 6.51810567037604,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 9.870393485818521,
      "attention_bam_16_peak_intensity_mean": 0.17026560008525848,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 114,
      "phase": "train",
      "loss": 0.07918417453765869,
      "timestamp": 1759561908.6925256,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.07918417453765869,
      "ssim": 0.25668302178382874,
      "attention_bam_384_mean_attention": 0.17921201884746552,
      "attention_bam_384_std_attention": 0.5715141296386719,
      "attention_bam_384_max_attention": 5.0263671875,
      "attention_bam_384_min_attention": -1.45654296875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.262175693182358,
      "attention_bam_384_attention_skewness": 1.065125112936599,
      "attention_bam_384_attention_sparsity": 0.4721628824869792,
      "attention_bam_384_attention_concentration_10": 0.7312681457146141,
      "attention_bam_384_attention_concentration_20": 1.131214997367921,
      "attention_bam_384_attention_center_y": 0.4718241677602977,
      "attention_bam_384_attention_center_x": 0.4947560088966111,
      "attention_bam_384_attention_center_distance": 0.040530900929840456,
      "attention_bam_384_attention_spatial_variance": 172.5255892210849,
      "attention_bam_384_attention_spatial_std": 13.134899665436539,
      "attention_bam_384_num_attention_peaks": 1,
      "attention_bam_384_peak_separation_mean": 0.0,
      "attention_bam_384_peak_intensity_mean": 0.26257795095443726,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19621503353118896,
      "attention_bam_16_std_attention": 0.5317891836166382,
      "attention_bam_16_max_attention": 4.411285400390625,
      "attention_bam_16_min_attention": -1.192626953125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 7.796709298972285,
      "attention_bam_16_attention_skewness": 1.614253876052558,
      "attention_bam_16_attention_sparsity": 0.4482421875,
      "attention_bam_16_attention_concentration_10": 0.6313689988991723,
      "attention_bam_16_attention_concentration_20": 0.9609737960026752,
      "attention_bam_16_attention_center_y": 0.46462134945058897,
      "attention_bam_16_attention_center_x": 0.4737520024833438,
      "attention_bam_16_attention_center_distance": 0.062299378621808586,
      "attention_bam_16_attention_spatial_variance": 42.61239729427393,
      "attention_bam_16_attention_spatial_std": 6.527817192161093,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.916953199277744,
      "attention_bam_16_peak_intensity_mean": 0.2514704167842865,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 115,
      "phase": "train",
      "loss": 0.07019073516130447,
      "timestamp": 1759561908.887717,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.07019073516130447,
      "ssim": 0.3006613850593567,
      "attention_bam_384_mean_attention": 0.18584956228733063,
      "attention_bam_384_std_attention": 0.5025925636291504,
      "attention_bam_384_max_attention": 4.2294921875,
      "attention_bam_384_min_attention": -1.2144775390625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.0808664328656343,
      "attention_bam_384_attention_skewness": 0.8700578679230966,
      "attention_bam_384_attention_sparsity": 0.4598134358723958,
      "attention_bam_384_attention_concentration_10": 0.6388669050999675,
      "attention_bam_384_attention_concentration_20": 0.996363632476052,
      "attention_bam_384_attention_center_y": 0.4749536010602192,
      "attention_bam_384_attention_center_x": 0.4838460035817002,
      "attention_bam_384_attention_center_distance": 0.04214910912778807,
      "attention_bam_384_attention_spatial_variance": 168.0223424522501,
      "attention_bam_384_attention_spatial_std": 12.96234324696928,
      "attention_bam_384_num_attention_peaks": 2,
      "attention_bam_384_peak_separation_mean": 11.98253641030369,
      "attention_bam_384_peak_intensity_mean": 0.26912498474121094,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2051219791173935,
      "attention_bam_16_std_attention": 0.46461740136146545,
      "attention_bam_16_max_attention": 3.8007049560546875,
      "attention_bam_16_min_attention": -0.8656005859375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 5.415790854238052,
      "attention_bam_16_attention_skewness": 1.3356472351055961,
      "attention_bam_16_attention_sparsity": 0.452880859375,
      "attention_bam_16_attention_concentration_10": 0.5523563868250584,
      "attention_bam_16_attention_concentration_20": 0.8584298735657793,
      "attention_bam_16_attention_center_y": 0.4725394613584501,
      "attention_bam_16_attention_center_x": 0.4799138914671019,
      "attention_bam_16_attention_center_distance": 0.04811513147606307,
      "attention_bam_16_attention_spatial_variance": 42.48589087034186,
      "attention_bam_16_attention_spatial_std": 6.518120194530158,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 8.854204028869317,
      "attention_bam_16_peak_intensity_mean": 0.23407241702079773,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 116,
      "phase": "train",
      "loss": 0.10667772591114044,
      "timestamp": 1759561909.0580888,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.10667772591114044,
      "ssim": 0.3092634081840515,
      "attention_bam_384_mean_attention": 0.17955684661865234,
      "attention_bam_384_std_attention": 0.5221760272979736,
      "attention_bam_384_max_attention": 5.38720703125,
      "attention_bam_384_min_attention": -1.241455078125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.3029307479007244,
      "attention_bam_384_attention_skewness": 0.6255095726996605,
      "attention_bam_384_attention_sparsity": 0.4485626220703125,
      "attention_bam_384_attention_concentration_10": 0.6509762993570675,
      "attention_bam_384_attention_concentration_20": 1.0378805080048172,
      "attention_bam_384_attention_center_y": 0.4855166450374826,
      "attention_bam_384_attention_center_x": 0.4805126249949868,
      "attention_bam_384_attention_center_distance": 0.03433730786058482,
      "attention_bam_384_attention_spatial_variance": 174.76127236466655,
      "attention_bam_384_attention_spatial_std": 13.219730419515617,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 20.30769006787914,
      "attention_bam_384_peak_intensity_mean": 0.22310508787631989,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21399754285812378,
      "attention_bam_16_std_attention": 0.49505388736724854,
      "attention_bam_16_max_attention": 3.54443359375,
      "attention_bam_16_min_attention": -0.9819183349609375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.9358052580408645,
      "attention_bam_16_attention_skewness": 0.8205031630023617,
      "attention_bam_16_attention_sparsity": 0.405517578125,
      "attention_bam_16_attention_concentration_10": 0.530533352100174,
      "attention_bam_16_attention_concentration_20": 0.8425625500734869,
      "attention_bam_16_attention_center_y": 0.46701265991351937,
      "attention_bam_16_attention_center_x": 0.47093388989174284,
      "attention_bam_16_attention_center_distance": 0.06217722031108275,
      "attention_bam_16_attention_spatial_variance": 42.503578448641285,
      "attention_bam_16_attention_spatial_std": 6.519476853907934,
      "attention_bam_16_num_attention_peaks": 12,
      "attention_bam_16_peak_separation_mean": 8.804551588972766,
      "attention_bam_16_peak_intensity_mean": 0.2666403353214264,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 117,
      "phase": "train",
      "loss": 0.06983973830938339,
      "timestamp": 1759561909.230442,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.06983973830938339,
      "ssim": 0.23956632614135742,
      "attention_bam_384_mean_attention": 0.18103010952472687,
      "attention_bam_384_std_attention": 0.5280696153640747,
      "attention_bam_384_max_attention": 4.453125,
      "attention_bam_384_min_attention": -1.2440185546875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.834568586047003,
      "attention_bam_384_attention_skewness": 0.9178236029579695,
      "attention_bam_384_attention_sparsity": 0.45683034261067706,
      "attention_bam_384_attention_concentration_10": 0.6646901995972526,
      "attention_bam_384_attention_concentration_20": 1.0369087829679222,
      "attention_bam_384_attention_center_y": 0.4827427619301743,
      "attention_bam_384_attention_center_x": 0.48181900300325786,
      "attention_bam_384_attention_center_distance": 0.03545027270964748,
      "attention_bam_384_attention_spatial_variance": 170.84661476670854,
      "attention_bam_384_attention_spatial_std": 13.070830683881898,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 15.227755096158392,
      "attention_bam_384_peak_intensity_mean": 0.2517412006855011,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21740072965621948,
      "attention_bam_16_std_attention": 0.5136628746986389,
      "attention_bam_16_max_attention": 4.8849639892578125,
      "attention_bam_16_min_attention": -1.1348876953125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 8.590969410909004,
      "attention_bam_16_attention_skewness": 1.4977222513292394,
      "attention_bam_16_attention_sparsity": 0.421630859375,
      "attention_bam_16_attention_concentration_10": 0.5383736513200159,
      "attention_bam_16_attention_concentration_20": 0.8469548955469965,
      "attention_bam_16_attention_center_y": 0.468189353797599,
      "attention_bam_16_attention_center_x": 0.4690693501997665,
      "attention_bam_16_attention_center_distance": 0.06274746702264584,
      "attention_bam_16_attention_spatial_variance": 43.18888052777031,
      "attention_bam_16_attention_spatial_std": 6.571824748710993,
      "attention_bam_16_num_attention_peaks": 13,
      "attention_bam_16_peak_separation_mean": 10.262159866670281,
      "attention_bam_16_peak_intensity_mean": 0.22832772135734558,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 118,
      "phase": "train",
      "loss": 0.09708430618047714,
      "timestamp": 1759561909.4030702,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.09708430618047714,
      "ssim": 0.29246020317077637,
      "attention_bam_384_mean_attention": 0.18924665451049805,
      "attention_bam_384_std_attention": 0.5339913368225098,
      "attention_bam_384_max_attention": 4.7255859375,
      "attention_bam_384_min_attention": -1.24365234375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6393147636900798,
      "attention_bam_384_attention_skewness": 0.4834601231055156,
      "attention_bam_384_attention_sparsity": 0.45134735107421875,
      "attention_bam_384_attention_concentration_10": 0.6325304227904045,
      "attention_bam_384_attention_concentration_20": 1.0200092471507578,
      "attention_bam_384_attention_center_y": 0.48044131128882145,
      "attention_bam_384_attention_center_x": 0.4872816546888475,
      "attention_bam_384_attention_center_distance": 0.03299389675544549,
      "attention_bam_384_attention_spatial_variance": 170.83175625392178,
      "attention_bam_384_attention_spatial_std": 13.07026228711275,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 17.22648696156057,
      "attention_bam_384_peak_intensity_mean": 0.23949572443962097,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23612216114997864,
      "attention_bam_16_std_attention": 0.5315461754798889,
      "attention_bam_16_max_attention": 4.328125,
      "attention_bam_16_min_attention": -1.0865478515625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.246419573836027,
      "attention_bam_16_attention_skewness": 0.7409681551735627,
      "attention_bam_16_attention_sparsity": 0.4111328125,
      "attention_bam_16_attention_concentration_10": 0.5324215301199723,
      "attention_bam_16_attention_concentration_20": 0.8492002658014707,
      "attention_bam_16_attention_center_y": 0.47245407369943565,
      "attention_bam_16_attention_center_x": 0.4751192311657424,
      "attention_bam_16_attention_center_distance": 0.05249439424433598,
      "attention_bam_16_attention_spatial_variance": 43.26130151078093,
      "attention_bam_16_attention_spatial_std": 6.577332400812729,
      "attention_bam_16_num_attention_peaks": 12,
      "attention_bam_16_peak_separation_mean": 9.466870100366473,
      "attention_bam_16_peak_intensity_mean": 0.24959821999073029,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 119,
      "phase": "train",
      "loss": 0.061078086495399475,
      "timestamp": 1759561909.626733,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.061078086495399475,
      "ssim": 0.2752864956855774,
      "attention_bam_384_mean_attention": 0.1722451001405716,
      "attention_bam_384_std_attention": 0.5548156499862671,
      "attention_bam_384_max_attention": 4.3916015625,
      "attention_bam_384_min_attention": -1.302490234375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8262765759030088,
      "attention_bam_384_attention_skewness": 0.6332225061183696,
      "attention_bam_384_attention_sparsity": 0.48312123616536456,
      "attention_bam_384_attention_concentration_10": 0.7240620436523804,
      "attention_bam_384_attention_concentration_20": 1.1606262500892237,
      "attention_bam_384_attention_center_y": 0.4836659300082318,
      "attention_bam_384_attention_center_x": 0.48471744998320154,
      "attention_bam_384_attention_center_distance": 0.0316341011413926,
      "attention_bam_384_attention_spatial_variance": 169.4278217385546,
      "attention_bam_384_attention_spatial_std": 13.016444281698233,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 14.479397473081255,
      "attention_bam_384_peak_intensity_mean": 0.25869014859199524,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21297401189804077,
      "attention_bam_16_std_attention": 0.5464403033256531,
      "attention_bam_16_max_attention": 4.52294921875,
      "attention_bam_16_min_attention": -1.0670166015625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.551006364240296,
      "attention_bam_16_attention_skewness": 0.9647590201473546,
      "attention_bam_16_attention_sparsity": 0.434814453125,
      "attention_bam_16_attention_concentration_10": 0.5864696408748505,
      "attention_bam_16_attention_concentration_20": 0.9341652834075785,
      "attention_bam_16_attention_center_y": 0.4674395251775744,
      "attention_bam_16_attention_center_x": 0.4705333325718812,
      "attention_bam_16_attention_center_distance": 0.06210425122294235,
      "attention_bam_16_attention_spatial_variance": 42.62613614555959,
      "attention_bam_16_attention_spatial_std": 6.52886943854444,
      "attention_bam_16_num_attention_peaks": 14,
      "attention_bam_16_peak_separation_mean": 8.142048439336625,
      "attention_bam_16_peak_intensity_mean": 0.2297056019306183,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 120,
      "phase": "train",
      "loss": 0.06452711671590805,
      "timestamp": 1759561909.9233682,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.06452711671590805,
      "ssim": 0.3009057641029358,
      "attention_bam_384_mean_attention": 0.1854703277349472,
      "attention_bam_384_std_attention": 0.522685706615448,
      "attention_bam_384_max_attention": 4.4306640625,
      "attention_bam_384_min_attention": -1.293701171875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7065629212069418,
      "attention_bam_384_attention_skewness": 0.5117806566854601,
      "attention_bam_384_attention_sparsity": 0.46052805582682294,
      "attention_bam_384_attention_concentration_10": 0.627725018899163,
      "attention_bam_384_attention_concentration_20": 1.0206476103388553,
      "attention_bam_384_attention_center_y": 0.4842505637298375,
      "attention_bam_384_attention_center_x": 0.48816032482454486,
      "attention_bam_384_attention_center_distance": 0.027864768116322054,
      "attention_bam_384_attention_spatial_variance": 170.56111857315713,
      "attention_bam_384_attention_spatial_std": 13.059904998626795,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 17.123964677945427,
      "attention_bam_384_peak_intensity_mean": 0.26037895679473877,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23022182285785675,
      "attention_bam_16_std_attention": 0.5135267376899719,
      "attention_bam_16_max_attention": 3.92950439453125,
      "attention_bam_16_min_attention": -1.224609375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.528446914069204,
      "attention_bam_16_attention_skewness": 0.6134630745625941,
      "attention_bam_16_attention_sparsity": 0.4189453125,
      "attention_bam_16_attention_concentration_10": 0.518909379813493,
      "attention_bam_16_attention_concentration_20": 0.8407434987459326,
      "attention_bam_16_attention_center_y": 0.47476333449385955,
      "attention_bam_16_attention_center_x": 0.4739316770770021,
      "attention_bam_16_attention_center_distance": 0.05131172859856732,
      "attention_bam_16_attention_spatial_variance": 42.658873633939166,
      "attention_bam_16_attention_spatial_std": 6.531376090376297,
      "attention_bam_16_num_attention_peaks": 11,
      "attention_bam_16_peak_separation_mean": 8.764252801682632,
      "attention_bam_16_peak_intensity_mean": 0.28640052676200867,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 121,
      "phase": "train",
      "loss": 0.05920290946960449,
      "timestamp": 1759561910.1134186,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.05920290946960449,
      "ssim": 0.41693612933158875,
      "attention_bam_384_mean_attention": 0.18050576746463776,
      "attention_bam_384_std_attention": 0.525225818157196,
      "attention_bam_384_max_attention": 5.36474609375,
      "attention_bam_384_min_attention": -1.156005859375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9640049986677433,
      "attention_bam_384_attention_skewness": 0.6232309201607136,
      "attention_bam_384_attention_sparsity": 0.458740234375,
      "attention_bam_384_attention_concentration_10": 0.6633475517692604,
      "attention_bam_384_attention_concentration_20": 1.0516200442632782,
      "attention_bam_384_attention_center_y": 0.4903004706296146,
      "attention_bam_384_attention_center_x": 0.49349437775697286,
      "attention_bam_384_attention_center_distance": 0.01651689987715237,
      "attention_bam_384_attention_spatial_variance": 169.00528518412472,
      "attention_bam_384_attention_spatial_std": 13.000203274723235,
      "attention_bam_384_num_attention_peaks": 2,
      "attention_bam_384_peak_separation_mean": 12.353199204550004,
      "attention_bam_384_peak_intensity_mean": 0.21189287304878235,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22216472029685974,
      "attention_bam_16_std_attention": 0.5292775630950928,
      "attention_bam_16_max_attention": 4.45068359375,
      "attention_bam_16_min_attention": -1.0701904296875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 5.04056551831844,
      "attention_bam_16_attention_skewness": 1.1859072231470806,
      "attention_bam_16_attention_sparsity": 0.421630859375,
      "attention_bam_16_attention_concentration_10": 0.5631798895950257,
      "attention_bam_16_attention_concentration_20": 0.8700405024391918,
      "attention_bam_16_attention_center_y": 0.4741964059411374,
      "attention_bam_16_attention_center_x": 0.47191540170197693,
      "attention_bam_16_attention_center_distance": 0.05393644645165068,
      "attention_bam_16_attention_spatial_variance": 42.278705179921744,
      "attention_bam_16_attention_spatial_std": 6.5022077158394245,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 7.223195480796315,
      "attention_bam_16_peak_intensity_mean": 0.23588895797729492,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 122,
      "phase": "train",
      "loss": 0.08046414703130722,
      "timestamp": 1759561910.2838688,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.08046414703130722,
      "ssim": 0.3410395681858063,
      "attention_bam_384_mean_attention": 0.18809865415096283,
      "attention_bam_384_std_attention": 0.5504299998283386,
      "attention_bam_384_max_attention": 5.087890625,
      "attention_bam_384_min_attention": -1.185302734375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.6568997272317967,
      "attention_bam_384_attention_skewness": 1.024266743948241,
      "attention_bam_384_attention_sparsity": 0.46800994873046875,
      "attention_bam_384_attention_concentration_10": 0.6882299258025236,
      "attention_bam_384_attention_concentration_20": 1.0603345299061713,
      "attention_bam_384_attention_center_y": 0.4758332484561489,
      "attention_bam_384_attention_center_x": 0.4820612037027387,
      "attention_bam_384_attention_center_distance": 0.04256365333889623,
      "attention_bam_384_attention_spatial_variance": 170.41839471927108,
      "attention_bam_384_attention_spatial_std": 13.054439655506899,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 19.43327483299165,
      "attention_bam_384_peak_intensity_mean": 0.21954964101314545,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21020039916038513,
      "attention_bam_16_std_attention": 0.5072348713874817,
      "attention_bam_16_max_attention": 3.6778411865234375,
      "attention_bam_16_min_attention": -1.0390625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 5.30806640818046,
      "attention_bam_16_attention_skewness": 1.346262555183524,
      "attention_bam_16_attention_sparsity": 0.4296875,
      "attention_bam_16_attention_concentration_10": 0.5758479006845627,
      "attention_bam_16_attention_concentration_20": 0.879952872144156,
      "attention_bam_16_attention_center_y": 0.4690109791419218,
      "attention_bam_16_attention_center_x": 0.4738097089566424,
      "attention_bam_16_attention_center_distance": 0.05738032343370303,
      "attention_bam_16_attention_spatial_variance": 42.60297414320192,
      "attention_bam_16_attention_spatial_std": 6.527095383338742,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.459602923718935,
      "attention_bam_16_peak_intensity_mean": 0.26450613141059875,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 123,
      "phase": "train",
      "loss": 0.05724833905696869,
      "timestamp": 1759561910.4681008,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.05724833905696869,
      "ssim": 0.24508541822433472,
      "attention_bam_384_mean_attention": 0.1862422078847885,
      "attention_bam_384_std_attention": 0.5080726742744446,
      "attention_bam_384_max_attention": 3.9649658203125,
      "attention_bam_384_min_attention": -1.117431640625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.948123109368015,
      "attention_bam_384_attention_skewness": 1.0692867288213495,
      "attention_bam_384_attention_sparsity": 0.4639638264973958,
      "attention_bam_384_attention_concentration_10": 0.6401076096901187,
      "attention_bam_384_attention_concentration_20": 0.9938885479293923,
      "attention_bam_384_attention_center_y": 0.4916482293115947,
      "attention_bam_384_attention_center_x": 0.48819824222018415,
      "attention_bam_384_attention_center_distance": 0.02044668972352982,
      "attention_bam_384_attention_spatial_variance": 168.17676675027982,
      "attention_bam_384_attention_spatial_std": 12.96829852950185,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 12.087564791085473,
      "attention_bam_384_peak_intensity_mean": 0.2608502507209778,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21186596155166626,
      "attention_bam_16_std_attention": 0.4877566397190094,
      "attention_bam_16_max_attention": 4.37548828125,
      "attention_bam_16_min_attention": -0.88330078125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 5.772050326055442,
      "attention_bam_16_attention_skewness": 1.3692211633344844,
      "attention_bam_16_attention_sparsity": 0.43017578125,
      "attention_bam_16_attention_concentration_10": 0.5467159639730941,
      "attention_bam_16_attention_concentration_20": 0.8485309975564201,
      "attention_bam_16_attention_center_y": 0.4730779230313785,
      "attention_bam_16_attention_center_x": 0.47440970961067186,
      "attention_bam_16_attention_center_distance": 0.052529252622029926,
      "attention_bam_16_attention_spatial_variance": 41.654155773992606,
      "attention_bam_16_attention_spatial_std": 6.454003081343594,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 7.515402832679971,
      "attention_bam_16_peak_intensity_mean": 0.21056881546974182,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 124,
      "phase": "train",
      "loss": 0.03971869498491287,
      "timestamp": 1759561910.6500335,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.03971869498491287,
      "ssim": 0.3779561519622803,
      "attention_bam_384_mean_attention": 0.1794337034225464,
      "attention_bam_384_std_attention": 0.4896141588687897,
      "attention_bam_384_max_attention": 4.1911468505859375,
      "attention_bam_384_min_attention": -1.128173828125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 4.256757242377533,
      "attention_bam_384_attention_skewness": 1.2014120631538054,
      "attention_bam_384_attention_sparsity": 0.4605560302734375,
      "attention_bam_384_attention_concentration_10": 0.6279850704125276,
      "attention_bam_384_attention_concentration_20": 0.9778372604994144,
      "attention_bam_384_attention_center_y": 0.49295320358452743,
      "attention_bam_384_attention_center_x": 0.4732863199503841,
      "attention_bam_384_attention_center_distance": 0.039071166901293405,
      "attention_bam_384_attention_spatial_variance": 170.28031720889763,
      "attention_bam_384_attention_spatial_std": 13.04915005695381,
      "attention_bam_384_num_attention_peaks": 3,
      "attention_bam_384_peak_separation_mean": 14.247091933208841,
      "attention_bam_384_peak_intensity_mean": 0.2421926110982895,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19680143892765045,
      "attention_bam_16_std_attention": 0.44750550389289856,
      "attention_bam_16_max_attention": 4.32281494140625,
      "attention_bam_16_min_attention": -0.71392822265625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 10.447366866050956,
      "attention_bam_16_attention_skewness": 1.859694067756061,
      "attention_bam_16_attention_sparsity": 0.436767578125,
      "attention_bam_16_attention_concentration_10": 0.5301973079457009,
      "attention_bam_16_attention_concentration_20": 0.8276264751314387,
      "attention_bam_16_attention_center_y": 0.4652395937765975,
      "attention_bam_16_attention_center_x": 0.4670904404382487,
      "attention_bam_16_attention_center_distance": 0.06769527238093385,
      "attention_bam_16_attention_spatial_variance": 42.32527333348062,
      "attention_bam_16_attention_spatial_std": 6.505787679711091,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.826109038828653,
      "attention_bam_16_peak_intensity_mean": 0.18058225512504578,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 125,
      "phase": "train",
      "loss": 0.06888748705387115,
      "timestamp": 1759561910.8211482,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.06888748705387115,
      "ssim": 0.39857596158981323,
      "attention_bam_384_mean_attention": 0.17904698848724365,
      "attention_bam_384_std_attention": 0.5111667513847351,
      "attention_bam_384_max_attention": 4.38128662109375,
      "attention_bam_384_min_attention": -1.255615234375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.549616611345515,
      "attention_bam_384_attention_skewness": 0.9249465669075884,
      "attention_bam_384_attention_sparsity": 0.4633585611979167,
      "attention_bam_384_attention_concentration_10": 0.6559794845161984,
      "attention_bam_384_attention_concentration_20": 1.027264132413941,
      "attention_bam_384_attention_center_y": 0.4897709634059319,
      "attention_bam_384_attention_center_x": 0.48177185962514374,
      "attention_bam_384_attention_center_distance": 0.02956005044543223,
      "attention_bam_384_attention_spatial_variance": 168.73669219002832,
      "attention_bam_384_attention_spatial_std": 12.989868828823035,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 18.826296198722762,
      "attention_bam_384_peak_intensity_mean": 0.25514882802963257,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2159917652606964,
      "attention_bam_16_std_attention": 0.510876476764679,
      "attention_bam_16_max_attention": 5.324435234069824,
      "attention_bam_16_min_attention": -0.95989990234375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 11.533717672965125,
      "attention_bam_16_attention_skewness": 1.9857844789819328,
      "attention_bam_16_attention_sparsity": 0.430419921875,
      "attention_bam_16_attention_concentration_10": 0.5604080231399146,
      "attention_bam_16_attention_concentration_20": 0.8522878500723466,
      "attention_bam_16_attention_center_y": 0.46908710577888346,
      "attention_bam_16_attention_center_x": 0.46779360557947613,
      "attention_bam_16_attention_center_distance": 0.06313254106554386,
      "attention_bam_16_attention_spatial_variance": 41.3622743827456,
      "attention_bam_16_attention_spatial_std": 6.4313508987416945,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 7.684598465123504,
      "attention_bam_16_peak_intensity_mean": 0.18910637497901917,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 126,
      "phase": "train",
      "loss": 0.07109232991933823,
      "timestamp": 1759561910.9940226,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.07109232991933823,
      "ssim": 0.3887612819671631,
      "attention_bam_384_mean_attention": 0.1858244389295578,
      "attention_bam_384_std_attention": 0.5506260395050049,
      "attention_bam_384_max_attention": 4.1337890625,
      "attention_bam_384_min_attention": -1.25732421875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.6595999072815708,
      "attention_bam_384_attention_skewness": 0.8650070468437722,
      "attention_bam_384_attention_sparsity": 0.47642771402994794,
      "attention_bam_384_attention_concentration_10": 0.686155236104409,
      "attention_bam_384_attention_concentration_20": 1.0769074667078615,
      "attention_bam_384_attention_center_y": 0.47488445944407337,
      "attention_bam_384_attention_center_x": 0.48034082077448154,
      "attention_bam_384_attention_center_distance": 0.04510595759403522,
      "attention_bam_384_attention_spatial_variance": 170.48458015912513,
      "attention_bam_384_attention_spatial_std": 13.056974387626145,
      "attention_bam_384_num_attention_peaks": 4,
      "attention_bam_384_peak_separation_mean": 15.473302783456871,
      "attention_bam_384_peak_intensity_mean": 0.271719366312027,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21409103274345398,
      "attention_bam_16_std_attention": 0.5258254408836365,
      "attention_bam_16_max_attention": 3.90826416015625,
      "attention_bam_16_min_attention": -1.03961181640625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 4.164230052708869,
      "attention_bam_16_attention_skewness": 1.1724902169617337,
      "attention_bam_16_attention_sparsity": 0.432373046875,
      "attention_bam_16_attention_concentration_10": 0.5831069296645799,
      "attention_bam_16_attention_concentration_20": 0.9008541277285826,
      "attention_bam_16_attention_center_y": 0.4630808635239642,
      "attention_bam_16_attention_center_x": 0.4660841169336783,
      "attention_bam_16_attention_center_distance": 0.0708986567193563,
      "attention_bam_16_attention_spatial_variance": 42.39826746646657,
      "attention_bam_16_attention_spatial_std": 6.511395201219671,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 6.969897957037497,
      "attention_bam_16_peak_intensity_mean": 0.2580031752586365,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 127,
      "phase": "train",
      "loss": 0.0627257451415062,
      "timestamp": 1759561911.1874244,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0627257451415062,
      "ssim": 0.38690438866615295,
      "attention_bam_384_mean_attention": 0.1891663521528244,
      "attention_bam_384_std_attention": 0.5437408089637756,
      "attention_bam_384_max_attention": 4.03515625,
      "attention_bam_384_min_attention": -1.123291015625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": -0.08953433095084096,
      "attention_bam_384_attention_skewness": 0.3623553197586009,
      "attention_bam_384_attention_sparsity": 0.4520060221354167,
      "attention_bam_384_attention_concentration_10": 0.6336665562446331,
      "attention_bam_384_attention_concentration_20": 1.0327229527317752,
      "attention_bam_384_attention_center_y": 0.48450644704896406,
      "attention_bam_384_attention_center_x": 0.48353154674876386,
      "attention_bam_384_attention_center_distance": 0.03197687087676668,
      "attention_bam_384_attention_spatial_variance": 169.0123882444516,
      "attention_bam_384_attention_spatial_std": 13.000476462209052,
      "attention_bam_384_num_attention_peaks": 4,
      "attention_bam_384_peak_separation_mean": 16.42351642498167,
      "attention_bam_384_peak_intensity_mean": 0.2578275203704834,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24096032977104187,
      "attention_bam_16_std_attention": 0.5579447150230408,
      "attention_bam_16_max_attention": 3.1036376953125,
      "attention_bam_16_min_attention": -1.140869140625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8382972081418996,
      "attention_bam_16_attention_skewness": 0.44771718165879854,
      "attention_bam_16_attention_sparsity": 0.4033203125,
      "attention_bam_16_attention_concentration_10": 0.5350048798460924,
      "attention_bam_16_attention_concentration_20": 0.8515856023330078,
      "attention_bam_16_attention_center_y": 0.46437005230555045,
      "attention_bam_16_attention_center_x": 0.4732690505028865,
      "attention_bam_16_attention_center_distance": 0.0629926477253726,
      "attention_bam_16_attention_spatial_variance": 42.30739785085961,
      "attention_bam_16_attention_spatial_std": 6.504413720763741,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.102773834420681,
      "attention_bam_16_peak_intensity_mean": 0.3248586058616638,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 128,
      "phase": "train",
      "loss": 0.05477133393287659,
      "timestamp": 1759561911.3667908,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.05477133393287659,
      "ssim": 0.4446650743484497,
      "attention_bam_384_mean_attention": 0.18084394931793213,
      "attention_bam_384_std_attention": 0.5401321649551392,
      "attention_bam_384_max_attention": 4.04296875,
      "attention_bam_384_min_attention": -1.1513671875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9413946040366636,
      "attention_bam_384_attention_skewness": 0.742475885787669,
      "attention_bam_384_attention_sparsity": 0.4791514078776042,
      "attention_bam_384_attention_concentration_10": 0.694113241517808,
      "attention_bam_384_attention_concentration_20": 1.0959006057232699,
      "attention_bam_384_attention_center_y": 0.4883578278350646,
      "attention_bam_384_attention_center_x": 0.48356419756737273,
      "attention_bam_384_attention_center_distance": 0.02848423333433263,
      "attention_bam_384_attention_spatial_variance": 167.8753108320984,
      "attention_bam_384_attention_spatial_std": 12.956670514916183,
      "attention_bam_384_num_attention_peaks": 3,
      "attention_bam_384_peak_separation_mean": 14.129314921339542,
      "attention_bam_384_peak_intensity_mean": 0.2673361301422119,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2153346985578537,
      "attention_bam_16_std_attention": 0.5156721472740173,
      "attention_bam_16_max_attention": 4.006591796875,
      "attention_bam_16_min_attention": -0.963134765625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.06036251794887,
      "attention_bam_16_attention_skewness": 1.033777873040729,
      "attention_bam_16_attention_sparsity": 0.439697265625,
      "attention_bam_16_attention_concentration_10": 0.5734006132577412,
      "attention_bam_16_attention_concentration_20": 0.8923766304024383,
      "attention_bam_16_attention_center_y": 0.4717357617651602,
      "attention_bam_16_attention_center_x": 0.4623647481217639,
      "attention_bam_16_attention_center_distance": 0.06656244206658966,
      "attention_bam_16_attention_spatial_variance": 42.12548888555088,
      "attention_bam_16_attention_spatial_std": 6.4904151550999325,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.656034882473602,
      "attention_bam_16_peak_intensity_mean": 0.24174053966999054,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 129,
      "phase": "train",
      "loss": 0.04034864157438278,
      "timestamp": 1759561911.546844,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.04034864157438278,
      "ssim": 0.424150288105011,
      "attention_bam_384_mean_attention": 0.18148183822631836,
      "attention_bam_384_std_attention": 0.5229253172874451,
      "attention_bam_384_max_attention": 4.333282470703125,
      "attention_bam_384_min_attention": -1.1826171875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.2676935275711916,
      "attention_bam_384_attention_skewness": 1.0991493815704583,
      "attention_bam_384_attention_sparsity": 0.46398162841796875,
      "attention_bam_384_attention_concentration_10": 0.6875951908633324,
      "attention_bam_384_attention_concentration_20": 1.040189812442652,
      "attention_bam_384_attention_center_y": 0.48814230689199123,
      "attention_bam_384_attention_center_x": 0.47451945583042515,
      "attention_bam_384_attention_center_distance": 0.03974576749847393,
      "attention_bam_384_attention_spatial_variance": 172.46719620943412,
      "attention_bam_384_attention_spatial_std": 13.132676658222959,
      "attention_bam_384_num_attention_peaks": 2,
      "attention_bam_384_peak_separation_mean": 24.802652298897957,
      "attention_bam_384_peak_intensity_mean": 0.2503061294555664,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21592110395431519,
      "attention_bam_16_std_attention": 0.5187445878982544,
      "attention_bam_16_max_attention": 4.13323974609375,
      "attention_bam_16_min_attention": -1.0511474609375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 5.9122831567366045,
      "attention_bam_16_attention_skewness": 1.4813523940059383,
      "attention_bam_16_attention_sparsity": 0.419189453125,
      "attention_bam_16_attention_concentration_10": 0.5867507187540194,
      "attention_bam_16_attention_concentration_20": 0.8792803697843055,
      "attention_bam_16_attention_center_y": 0.4763972659728146,
      "attention_bam_16_attention_center_x": 0.46304314457125384,
      "attention_bam_16_attention_center_distance": 0.06201448567454702,
      "attention_bam_16_attention_spatial_variance": 42.368887508685816,
      "attention_bam_16_attention_spatial_std": 6.509138768584198,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.913312830626785,
      "attention_bam_16_peak_intensity_mean": 0.246261328458786,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 130,
      "phase": "train",
      "loss": 0.04916904866695404,
      "timestamp": 1759561911.86525,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.04916904866695404,
      "ssim": 0.4311501383781433,
      "attention_bam_384_mean_attention": 0.18389277160167694,
      "attention_bam_384_std_attention": 0.5452150106430054,
      "attention_bam_384_max_attention": 5.61175537109375,
      "attention_bam_384_min_attention": -1.491455078125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.4303129848663243,
      "attention_bam_384_attention_skewness": 1.023142608002372,
      "attention_bam_384_attention_sparsity": 0.467376708984375,
      "attention_bam_384_attention_concentration_10": 0.6750021014244889,
      "attention_bam_384_attention_concentration_20": 1.0606489501627057,
      "attention_bam_384_attention_center_y": 0.4840719380470571,
      "attention_bam_384_attention_center_x": 0.4796895941144921,
      "attention_bam_384_attention_center_distance": 0.036502486074536385,
      "attention_bam_384_attention_spatial_variance": 169.2521672981091,
      "attention_bam_384_attention_spatial_std": 13.009695127023889,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 15.23270645770438,
      "attention_bam_384_peak_intensity_mean": 0.23731079697608948,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2249477654695511,
      "attention_bam_16_std_attention": 0.5180440545082092,
      "attention_bam_16_max_attention": 4.4033203125,
      "attention_bam_16_min_attention": -1.0841064453125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 6.724865130999449,
      "attention_bam_16_attention_skewness": 1.4606618059657386,
      "attention_bam_16_attention_sparsity": 0.410400390625,
      "attention_bam_16_attention_concentration_10": 0.5420588210491667,
      "attention_bam_16_attention_concentration_20": 0.8412765139045985,
      "attention_bam_16_attention_center_y": 0.46955105893264043,
      "attention_bam_16_attention_center_x": 0.4676274400801192,
      "attention_bam_16_attention_center_distance": 0.06285094506671812,
      "attention_bam_16_attention_spatial_variance": 42.18649380948671,
      "attention_bam_16_attention_spatial_std": 6.495113071339614,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 7.933339213874856,
      "attention_bam_16_peak_intensity_mean": 0.24066312611103058,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 131,
      "phase": "train",
      "loss": 0.044951923191547394,
      "timestamp": 1759561912.0353706,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.044951923191547394,
      "ssim": 0.38889747858047485,
      "attention_bam_384_mean_attention": 0.17755751311779022,
      "attention_bam_384_std_attention": 0.5249997973442078,
      "attention_bam_384_max_attention": 4.7861328125,
      "attention_bam_384_min_attention": -1.223388671875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2610082132184086,
      "attention_bam_384_attention_skewness": 0.6465504008316312,
      "attention_bam_384_attention_sparsity": 0.46322886149088544,
      "attention_bam_384_attention_concentration_10": 0.6702725215239191,
      "attention_bam_384_attention_concentration_20": 1.061713963066113,
      "attention_bam_384_attention_center_y": 0.4843804436516841,
      "attention_bam_384_attention_center_x": 0.48648243854951295,
      "attention_bam_384_attention_center_distance": 0.02921283991966236,
      "attention_bam_384_attention_spatial_variance": 169.98110389846565,
      "attention_bam_384_attention_spatial_std": 13.037680157852686,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 15.509168820040276,
      "attention_bam_384_peak_intensity_mean": 0.23436938226222992,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23015785217285156,
      "attention_bam_16_std_attention": 0.5312344431877136,
      "attention_bam_16_max_attention": 3.469482421875,
      "attention_bam_16_min_attention": -1.34228515625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.7185468989525745,
      "attention_bam_16_attention_skewness": 0.7683565028416055,
      "attention_bam_16_attention_sparsity": 0.406005859375,
      "attention_bam_16_attention_concentration_10": 0.5453987250188689,
      "attention_bam_16_attention_concentration_20": 0.8548408378407528,
      "attention_bam_16_attention_center_y": 0.4688497141034251,
      "attention_bam_16_attention_center_x": 0.4715877153757399,
      "attention_bam_16_attention_center_distance": 0.05962546819955917,
      "attention_bam_16_attention_spatial_variance": 42.33674413188694,
      "attention_bam_16_attention_spatial_std": 6.506669204123331,
      "attention_bam_16_num_attention_peaks": 11,
      "attention_bam_16_peak_separation_mean": 8.866964773516102,
      "attention_bam_16_peak_intensity_mean": 0.3313910663127899,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 132,
      "phase": "train",
      "loss": 0.04178889840841293,
      "timestamp": 1759561912.2060711,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.04178889840841293,
      "ssim": 0.49424687027931213,
      "attention_bam_384_mean_attention": 0.1814700961112976,
      "attention_bam_384_std_attention": 0.5531290769577026,
      "attention_bam_384_max_attention": 4.90625,
      "attention_bam_384_min_attention": -1.25732421875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.152204761155697,
      "attention_bam_384_attention_skewness": 0.6995868365934874,
      "attention_bam_384_attention_sparsity": 0.46893564860026044,
      "attention_bam_384_attention_concentration_10": 0.6873817906433118,
      "attention_bam_384_attention_concentration_20": 1.093728503346085,
      "attention_bam_384_attention_center_y": 0.47744908585529283,
      "attention_bam_384_attention_center_x": 0.49063215556084566,
      "attention_bam_384_attention_center_distance": 0.03453404807427443,
      "attention_bam_384_attention_spatial_variance": 170.63384683400884,
      "attention_bam_384_attention_spatial_std": 13.062689111894565,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 15.83111827864453,
      "attention_bam_384_peak_intensity_mean": 0.2342660129070282,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2244185209274292,
      "attention_bam_16_std_attention": 0.5555137991905212,
      "attention_bam_16_max_attention": 4.01885986328125,
      "attention_bam_16_min_attention": -1.094482421875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.5734592166471995,
      "attention_bam_16_attention_skewness": 0.7072372804466949,
      "attention_bam_16_attention_sparsity": 0.4365234375,
      "attention_bam_16_attention_concentration_10": 0.5635171327902389,
      "attention_bam_16_attention_concentration_20": 0.9006426890108383,
      "attention_bam_16_attention_center_y": 0.472117609930599,
      "attention_bam_16_attention_center_x": 0.4714794855513724,
      "attention_bam_16_attention_center_distance": 0.05640651416984756,
      "attention_bam_16_attention_spatial_variance": 42.93442529415426,
      "attention_bam_16_attention_spatial_std": 6.552436592150607,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 8.426294898268175,
      "attention_bam_16_peak_intensity_mean": 0.2602037787437439,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 133,
      "phase": "train",
      "loss": 0.05569625645875931,
      "timestamp": 1759561912.375974,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.05569625645875931,
      "ssim": 0.44785594940185547,
      "attention_bam_384_mean_attention": 0.18905235826969147,
      "attention_bam_384_std_attention": 0.5525863766670227,
      "attention_bam_384_max_attention": 4.59521484375,
      "attention_bam_384_min_attention": -1.272705078125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1873598187288028,
      "attention_bam_384_attention_skewness": 0.6776100346479188,
      "attention_bam_384_attention_sparsity": 0.4621632893880208,
      "attention_bam_384_attention_concentration_10": 0.6623523945654309,
      "attention_bam_384_attention_concentration_20": 1.0543737008445069,
      "attention_bam_384_attention_center_y": 0.4839968491637212,
      "attention_bam_384_attention_center_x": 0.4874638060302182,
      "attention_bam_384_attention_center_distance": 0.028749156368028737,
      "attention_bam_384_attention_spatial_variance": 172.05630450449638,
      "attention_bam_384_attention_spatial_std": 13.117023462070058,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 18.963925079761072,
      "attention_bam_384_peak_intensity_mean": 0.25188615918159485,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22887730598449707,
      "attention_bam_16_std_attention": 0.543291449546814,
      "attention_bam_16_max_attention": 3.22314453125,
      "attention_bam_16_min_attention": -1.0032958984375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.2747386720597422,
      "attention_bam_16_attention_skewness": 0.8437127844572625,
      "attention_bam_16_attention_sparsity": 0.429443359375,
      "attention_bam_16_attention_concentration_10": 0.5550823401653949,
      "attention_bam_16_attention_concentration_20": 0.8796493107582258,
      "attention_bam_16_attention_center_y": 0.47937789750794124,
      "attention_bam_16_attention_center_x": 0.476495602057367,
      "attention_bam_16_attention_center_distance": 0.04422053445716426,
      "attention_bam_16_attention_spatial_variance": 42.74490970447015,
      "attention_bam_16_attention_spatial_std": 6.537959139094566,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 8.698195419183625,
      "attention_bam_16_peak_intensity_mean": 0.2994210124015808,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 134,
      "phase": "train",
      "loss": 0.04079468548297882,
      "timestamp": 1759561912.543559,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.04079468548297882,
      "ssim": 0.46288707852363586,
      "attention_bam_384_mean_attention": 0.1762695461511612,
      "attention_bam_384_std_attention": 0.5088179111480713,
      "attention_bam_384_max_attention": 4.58837890625,
      "attention_bam_384_min_attention": -1.25341796875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.7011994993503263,
      "attention_bam_384_attention_skewness": 0.7355862592807012,
      "attention_bam_384_attention_sparsity": 0.45940399169921875,
      "attention_bam_384_attention_concentration_10": 0.659607253748438,
      "attention_bam_384_attention_concentration_20": 1.041234174678953,
      "attention_bam_384_attention_center_y": 0.48623364317945633,
      "attention_bam_384_attention_center_x": 0.4886964507049259,
      "attention_bam_384_attention_center_distance": 0.025190585812033008,
      "attention_bam_384_attention_spatial_variance": 169.5021335520071,
      "attention_bam_384_attention_spatial_std": 13.019298504604889,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 21.985551456234276,
      "attention_bam_384_peak_intensity_mean": 0.24275533854961395,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21801258623600006,
      "attention_bam_16_std_attention": 0.4985484778881073,
      "attention_bam_16_max_attention": 4.116455078125,
      "attention_bam_16_min_attention": -1.067626953125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 4.515832217183586,
      "attention_bam_16_attention_skewness": 1.1272648132935923,
      "attention_bam_16_attention_sparsity": 0.410400390625,
      "attention_bam_16_attention_concentration_10": 0.5428797510796092,
      "attention_bam_16_attention_concentration_20": 0.8413530101965324,
      "attention_bam_16_attention_center_y": 0.47281678036603886,
      "attention_bam_16_attention_center_x": 0.47632005768094315,
      "attention_bam_16_attention_center_distance": 0.05098366597062298,
      "attention_bam_16_attention_spatial_variance": 42.549576762118875,
      "attention_bam_16_attention_spatial_std": 6.5230036610536155,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.617881903481111,
      "attention_bam_16_peak_intensity_mean": 0.2534008324146271,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 135,
      "phase": "train",
      "loss": 0.036874011158943176,
      "timestamp": 1759561912.7120197,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.036874011158943176,
      "ssim": 0.3969454765319824,
      "attention_bam_384_mean_attention": 0.17923058569431305,
      "attention_bam_384_std_attention": 0.49872612953186035,
      "attention_bam_384_max_attention": 3.94677734375,
      "attention_bam_384_min_attention": -1.201904296875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.0218306664221917,
      "attention_bam_384_attention_skewness": 0.7475250139497426,
      "attention_bam_384_attention_sparsity": 0.452056884765625,
      "attention_bam_384_attention_concentration_10": 0.6346265828810654,
      "attention_bam_384_attention_concentration_20": 0.9969113081062697,
      "attention_bam_384_attention_center_y": 0.480354105509122,
      "attention_bam_384_attention_center_x": 0.48449336384517433,
      "attention_bam_384_attention_center_distance": 0.03539539334955489,
      "attention_bam_384_attention_spatial_variance": 168.89251952052825,
      "attention_bam_384_attention_spatial_std": 12.995865477932904,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 17.596674042870347,
      "attention_bam_384_peak_intensity_mean": 0.27095261216163635,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23050808906555176,
      "attention_bam_16_std_attention": 0.4908052682876587,
      "attention_bam_16_max_attention": 3.653564453125,
      "attention_bam_16_min_attention": -1.035888671875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.083561621776812,
      "attention_bam_16_attention_skewness": 0.7539420291149255,
      "attention_bam_16_attention_sparsity": 0.39306640625,
      "attention_bam_16_attention_concentration_10": 0.4969000531069471,
      "attention_bam_16_attention_concentration_20": 0.793516198957071,
      "attention_bam_16_attention_center_y": 0.47025119699404644,
      "attention_bam_16_attention_center_x": 0.47038302421984607,
      "attention_bam_16_attention_center_distance": 0.05936592515322668,
      "attention_bam_16_attention_spatial_variance": 42.900900316582536,
      "attention_bam_16_attention_spatial_std": 6.549877885623711,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 9.166959616986215,
      "attention_bam_16_peak_intensity_mean": 0.27174997329711914,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 136,
      "phase": "train",
      "loss": 0.035598572343587875,
      "timestamp": 1759561912.8825817,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.035598572343587875,
      "ssim": 0.49625149369239807,
      "attention_bam_384_mean_attention": 0.16684620082378387,
      "attention_bam_384_std_attention": 0.5464116930961609,
      "attention_bam_384_max_attention": 4.888671875,
      "attention_bam_384_min_attention": -1.1591796875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.779521409637848,
      "attention_bam_384_attention_skewness": 0.8097251449760788,
      "attention_bam_384_attention_sparsity": 0.4832102457682292,
      "attention_bam_384_attention_concentration_10": 0.7283659559751602,
      "attention_bam_384_attention_concentration_20": 1.1558665740055807,
      "attention_bam_384_attention_center_y": 0.49494986774081884,
      "attention_bam_384_attention_center_x": 0.4935643339568745,
      "attention_bam_384_attention_center_distance": 0.01156906506627575,
      "attention_bam_384_attention_spatial_variance": 172.32031014110626,
      "attention_bam_384_attention_spatial_std": 13.1270830781673,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 15.62760437015407,
      "attention_bam_384_peak_intensity_mean": 0.22632567584514618,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20190376043319702,
      "attention_bam_16_std_attention": 0.5519747138023376,
      "attention_bam_16_max_attention": 5.1209716796875,
      "attention_bam_16_min_attention": -0.93597412109375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 7.388489166259722,
      "attention_bam_16_attention_skewness": 1.5879209844552897,
      "attention_bam_16_attention_sparsity": 0.45556640625,
      "attention_bam_16_attention_concentration_10": 0.6362047043319108,
      "attention_bam_16_attention_concentration_20": 0.9750593599720083,
      "attention_bam_16_attention_center_y": 0.47851413559403133,
      "attention_bam_16_attention_center_x": 0.4781582872238034,
      "attention_bam_16_attention_center_distance": 0.043329038444662994,
      "attention_bam_16_attention_spatial_variance": 42.90540780125799,
      "attention_bam_16_attention_spatial_std": 6.5502219658007,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 8.439988267512533,
      "attention_bam_16_peak_intensity_mean": 0.19287553429603577,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 137,
      "phase": "train",
      "loss": 0.03337150812149048,
      "timestamp": 1759561913.0668914,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.03337150812149048,
      "ssim": 0.49835774302482605,
      "attention_bam_384_mean_attention": 0.17758001387119293,
      "attention_bam_384_std_attention": 0.5409618020057678,
      "attention_bam_384_max_attention": 4.39599609375,
      "attention_bam_384_min_attention": -1.203369140625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8450054385101589,
      "attention_bam_384_attention_skewness": 0.5943741762870082,
      "attention_bam_384_attention_sparsity": 0.4685465494791667,
      "attention_bam_384_attention_concentration_10": 0.6780329149088384,
      "attention_bam_384_attention_concentration_20": 1.0885193885135827,
      "attention_bam_384_attention_center_y": 0.4878034277732628,
      "attention_bam_384_attention_center_x": 0.4924866621172894,
      "attention_bam_384_attention_center_distance": 0.020258658406804294,
      "attention_bam_384_attention_spatial_variance": 169.15420095330416,
      "attention_bam_384_attention_spatial_std": 13.005929453649369,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 16.50308039027257,
      "attention_bam_384_peak_intensity_mean": 0.2482069581747055,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2311260849237442,
      "attention_bam_16_std_attention": 0.5505543947219849,
      "attention_bam_16_max_attention": 3.6259765625,
      "attention_bam_16_min_attention": -1.16143798828125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.132388204303589,
      "attention_bam_16_attention_skewness": 0.7495827818330052,
      "attention_bam_16_attention_sparsity": 0.4208984375,
      "attention_bam_16_attention_concentration_10": 0.5542376833758876,
      "attention_bam_16_attention_concentration_20": 0.8745955751870675,
      "attention_bam_16_attention_center_y": 0.4713824943168849,
      "attention_bam_16_attention_center_x": 0.47251779344754985,
      "attention_bam_16_attention_center_distance": 0.056111198677530665,
      "attention_bam_16_attention_spatial_variance": 42.25178671259831,
      "attention_bam_16_attention_spatial_std": 6.500137437977624,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 7.423561118028163,
      "attention_bam_16_peak_intensity_mean": 0.2950134873390198,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 138,
      "phase": "train",
      "loss": 0.04848387464880943,
      "timestamp": 1759561913.2440164,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.04848387464880943,
      "ssim": 0.4659731984138489,
      "attention_bam_384_mean_attention": 0.18260310590267181,
      "attention_bam_384_std_attention": 0.5318091511726379,
      "attention_bam_384_max_attention": 4.76953125,
      "attention_bam_384_min_attention": -1.384765625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8502931467459236,
      "attention_bam_384_attention_skewness": 0.6110762110684829,
      "attention_bam_384_attention_sparsity": 0.4591827392578125,
      "attention_bam_384_attention_concentration_10": 0.6586890138579161,
      "attention_bam_384_attention_concentration_20": 1.0481045272319574,
      "attention_bam_384_attention_center_y": 0.47499719710095034,
      "attention_bam_384_attention_center_x": 0.48062538664100896,
      "attention_bam_384_attention_center_distance": 0.04473289160381028,
      "attention_bam_384_attention_spatial_variance": 169.8304880931655,
      "attention_bam_384_attention_spatial_std": 13.031902704254875,
      "attention_bam_384_num_attention_peaks": 2,
      "attention_bam_384_peak_separation_mean": 10.92552820116414,
      "attention_bam_384_peak_intensity_mean": 0.25738435983657837,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2244918942451477,
      "attention_bam_16_std_attention": 0.5094320178031921,
      "attention_bam_16_max_attention": 3.5361785888671875,
      "attention_bam_16_min_attention": -1.233642578125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.4921340590154824,
      "attention_bam_16_attention_skewness": 0.8177050340441315,
      "attention_bam_16_attention_sparsity": 0.409423828125,
      "attention_bam_16_attention_concentration_10": 0.5323470089941732,
      "attention_bam_16_attention_concentration_20": 0.8399112774640898,
      "attention_bam_16_attention_center_y": 0.46756417587667193,
      "attention_bam_16_attention_center_x": 0.46780602932354043,
      "attention_bam_16_attention_center_distance": 0.06463024732238319,
      "attention_bam_16_attention_spatial_variance": 42.55777095078664,
      "attention_bam_16_attention_spatial_std": 6.523631730162781,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 8.605410043375858,
      "attention_bam_16_peak_intensity_mean": 0.3055068254470825,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 139,
      "phase": "train",
      "loss": 0.03824995458126068,
      "timestamp": 1759561913.4126832,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.03824995458126068,
      "ssim": 0.42666202783584595,
      "attention_bam_384_mean_attention": 0.1817028671503067,
      "attention_bam_384_std_attention": 0.5215965509414673,
      "attention_bam_384_max_attention": 4.2429046630859375,
      "attention_bam_384_min_attention": -1.2261962890625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.3297733533977985,
      "attention_bam_384_attention_skewness": 1.0343748912586845,
      "attention_bam_384_attention_sparsity": 0.4587249755859375,
      "attention_bam_384_attention_concentration_10": 0.663119566601933,
      "attention_bam_384_attention_concentration_20": 1.0268028589219051,
      "attention_bam_384_attention_center_y": 0.48666793174380435,
      "attention_bam_384_attention_center_x": 0.47853892963724604,
      "attention_bam_384_attention_center_distance": 0.035730143719356525,
      "attention_bam_384_attention_spatial_variance": 168.5171847162647,
      "attention_bam_384_attention_spatial_std": 12.98141689940912,
      "attention_bam_384_num_attention_peaks": 2,
      "attention_bam_384_peak_separation_mean": 12.052022631882815,
      "attention_bam_384_peak_intensity_mean": 0.2568405270576477,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23506370186805725,
      "attention_bam_16_std_attention": 0.554497241973877,
      "attention_bam_16_max_attention": 4.531829833984375,
      "attention_bam_16_min_attention": -1.1390380859375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 6.0563799391293,
      "attention_bam_16_attention_skewness": 1.353077575177071,
      "attention_bam_16_attention_sparsity": 0.402587890625,
      "attention_bam_16_attention_concentration_10": 0.5519016399329602,
      "attention_bam_16_attention_concentration_20": 0.8453437108506142,
      "attention_bam_16_attention_center_y": 0.4689639752927298,
      "attention_bam_16_attention_center_x": 0.4681646641237842,
      "attention_bam_16_attention_center_distance": 0.0628764413748386,
      "attention_bam_16_attention_spatial_variance": 42.797734638120225,
      "attention_bam_16_attention_spatial_std": 6.5419977558938545,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.57484140923025,
      "attention_bam_16_peak_intensity_mean": 0.2463383674621582,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 140,
      "phase": "train",
      "loss": 0.0468699149787426,
      "timestamp": 1759561913.659722,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0468699149787426,
      "ssim": 0.49514394998550415,
      "attention_bam_384_mean_attention": 0.1847207397222519,
      "attention_bam_384_std_attention": 0.5457533597946167,
      "attention_bam_384_max_attention": 4.879063129425049,
      "attention_bam_384_min_attention": -1.26416015625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 4.200822759800932,
      "attention_bam_384_attention_skewness": 1.1620115297862867,
      "attention_bam_384_attention_sparsity": 0.46771494547526044,
      "attention_bam_384_attention_concentration_10": 0.6808847924541449,
      "attention_bam_384_attention_concentration_20": 1.056006265905684,
      "attention_bam_384_attention_center_y": 0.4809883733392968,
      "attention_bam_384_attention_center_x": 0.4746904764932437,
      "attention_bam_384_attention_center_distance": 0.04476636970818633,
      "attention_bam_384_attention_spatial_variance": 170.41532079278198,
      "attention_bam_384_attention_spatial_std": 13.05432192006854,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 16.128398701947745,
      "attention_bam_384_peak_intensity_mean": 0.23506449162960052,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19556176662445068,
      "attention_bam_16_std_attention": 0.48839399218559265,
      "attention_bam_16_max_attention": 5.030517578125,
      "attention_bam_16_min_attention": -1.1290283203125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 10.049855463245532,
      "attention_bam_16_attention_skewness": 1.7827093500758497,
      "attention_bam_16_attention_sparsity": 0.4404296875,
      "attention_bam_16_attention_concentration_10": 0.5848963816247826,
      "attention_bam_16_attention_concentration_20": 0.8944742762878194,
      "attention_bam_16_attention_center_y": 0.4676379482615295,
      "attention_bam_16_attention_center_x": 0.46822694869724635,
      "attention_bam_16_attention_center_distance": 0.06413780759911984,
      "attention_bam_16_attention_spatial_variance": 42.740198788513894,
      "attention_bam_16_attention_spatial_std": 6.537598854970676,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 8.775368926248925,
      "attention_bam_16_peak_intensity_mean": 0.21695002913475037,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 141,
      "phase": "train",
      "loss": 0.031944021582603455,
      "timestamp": 1759561913.8831632,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.031944021582603455,
      "ssim": 0.5238027572631836,
      "attention_bam_384_mean_attention": 0.1693955510854721,
      "attention_bam_384_std_attention": 0.5486416220664978,
      "attention_bam_384_max_attention": 4.162353515625,
      "attention_bam_384_min_attention": -1.216064453125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.4454136053876665,
      "attention_bam_384_attention_skewness": 1.1929851838753205,
      "attention_bam_384_attention_sparsity": 0.48607635498046875,
      "attention_bam_384_attention_concentration_10": 0.7573595550621509,
      "attention_bam_384_attention_concentration_20": 1.1504590041913803,
      "attention_bam_384_attention_center_y": 0.4826981889715754,
      "attention_bam_384_attention_center_x": 0.4897086056614107,
      "attention_bam_384_attention_center_distance": 0.028469824807879036,
      "attention_bam_384_attention_spatial_variance": 167.84220354342034,
      "attention_bam_384_attention_spatial_std": 12.955392836321883,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 14.590665855617251,
      "attention_bam_384_peak_intensity_mean": 0.2584429979324341,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1910848617553711,
      "attention_bam_16_std_attention": 0.5184388160705566,
      "attention_bam_16_max_attention": 5.004974365234375,
      "attention_bam_16_min_attention": -1.1591796875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 9.57753856953616,
      "attention_bam_16_attention_skewness": 1.847458157024491,
      "attention_bam_16_attention_sparsity": 0.440185546875,
      "attention_bam_16_attention_concentration_10": 0.6189256386326868,
      "attention_bam_16_attention_concentration_20": 0.9400205310634663,
      "attention_bam_16_attention_center_y": 0.4706279822264462,
      "attention_bam_16_attention_center_x": 0.46912713237693343,
      "attention_bam_16_attention_center_distance": 0.0602635774471007,
      "attention_bam_16_attention_spatial_variance": 42.176408571551605,
      "attention_bam_16_attention_spatial_std": 6.4943366536969425,
      "attention_bam_16_num_attention_peaks": 12,
      "attention_bam_16_peak_separation_mean": 9.985364594839096,
      "attention_bam_16_peak_intensity_mean": 0.22073644399642944,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 142,
      "phase": "train",
      "loss": 0.024654781445860863,
      "timestamp": 1759561914.0613,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.024654781445860863,
      "ssim": 0.4797903299331665,
      "attention_bam_384_mean_attention": 0.17670322954654694,
      "attention_bam_384_std_attention": 0.4968250095844269,
      "attention_bam_384_max_attention": 4.1220703125,
      "attention_bam_384_min_attention": -1.131591796875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8727941945348894,
      "attention_bam_384_attention_skewness": 0.7752881211630487,
      "attention_bam_384_attention_sparsity": 0.4612528483072917,
      "attention_bam_384_attention_concentration_10": 0.6416786928819436,
      "attention_bam_384_attention_concentration_20": 1.0175673632031763,
      "attention_bam_384_attention_center_y": 0.48137626731085104,
      "attention_bam_384_attention_center_x": 0.4859881397602695,
      "attention_bam_384_attention_center_distance": 0.03295984364813086,
      "attention_bam_384_attention_spatial_variance": 169.31251081760539,
      "attention_bam_384_attention_spatial_std": 13.012014095350704,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 14.374614962865042,
      "attention_bam_384_peak_intensity_mean": 0.25246870517730713,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22087028622627258,
      "attention_bam_16_std_attention": 0.5230041742324829,
      "attention_bam_16_max_attention": 7.26416015625,
      "attention_bam_16_min_attention": -1.0875244140625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 13.243835358594445,
      "attention_bam_16_attention_skewness": 1.8069781939255416,
      "attention_bam_16_attention_sparsity": 0.41796875,
      "attention_bam_16_attention_concentration_10": 0.5491986630402984,
      "attention_bam_16_attention_concentration_20": 0.8475325848958364,
      "attention_bam_16_attention_center_y": 0.4686165089379324,
      "attention_bam_16_attention_center_x": 0.46718122260977596,
      "attention_bam_16_attention_center_distance": 0.06421830985991392,
      "attention_bam_16_attention_spatial_variance": 42.4866002610681,
      "attention_bam_16_attention_spatial_std": 6.518174611121437,
      "attention_bam_16_num_attention_peaks": 13,
      "attention_bam_16_peak_separation_mean": 7.920562510235396,
      "attention_bam_16_peak_intensity_mean": 0.15732550621032715,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 143,
      "phase": "train",
      "loss": 0.02353024110198021,
      "timestamp": 1759561914.2311022,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.02353024110198021,
      "ssim": 0.544529139995575,
      "attention_bam_384_mean_attention": 0.18061114847660065,
      "attention_bam_384_std_attention": 0.50077223777771,
      "attention_bam_384_max_attention": 4.09814453125,
      "attention_bam_384_min_attention": -1.235595703125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5920422319034717,
      "attention_bam_384_attention_skewness": 0.7721110849379185,
      "attention_bam_384_attention_sparsity": 0.4615427652994792,
      "attention_bam_384_attention_concentration_10": 0.643275855108184,
      "attention_bam_384_attention_concentration_20": 1.0104024473135627,
      "attention_bam_384_attention_center_y": 0.47819692009387,
      "attention_bam_384_attention_center_x": 0.47878088607837377,
      "attention_bam_384_attention_center_distance": 0.04302615690512091,
      "attention_bam_384_attention_spatial_variance": 169.6858441007022,
      "attention_bam_384_attention_spatial_std": 13.026351910673311,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 14.5009668236001,
      "attention_bam_384_peak_intensity_mean": 0.267411470413208,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2171362340450287,
      "attention_bam_16_std_attention": 0.48699796199798584,
      "attention_bam_16_max_attention": 4.78253173828125,
      "attention_bam_16_min_attention": -0.84765625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 6.287321948465857,
      "attention_bam_16_attention_skewness": 1.3523478900006773,
      "attention_bam_16_attention_sparsity": 0.41357421875,
      "attention_bam_16_attention_concentration_10": 0.5316518944864262,
      "attention_bam_16_attention_concentration_20": 0.8281797827294448,
      "attention_bam_16_attention_center_y": 0.4692028432669823,
      "attention_bam_16_attention_center_x": 0.47095886882868637,
      "attention_bam_16_attention_center_distance": 0.05986404868612715,
      "attention_bam_16_attention_spatial_variance": 42.52035189290791,
      "attention_bam_16_attention_spatial_std": 6.520763137310533,
      "attention_bam_16_num_attention_peaks": 12,
      "attention_bam_16_peak_separation_mean": 8.743313718682652,
      "attention_bam_16_peak_intensity_mean": 0.19239288568496704,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 144,
      "phase": "train",
      "loss": 0.05870107561349869,
      "timestamp": 1759561914.3993428,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.05870107561349869,
      "ssim": 0.483335018157959,
      "attention_bam_384_mean_attention": 0.19075055420398712,
      "attention_bam_384_std_attention": 0.3980247974395752,
      "attention_bam_384_max_attention": 5.4345703125,
      "attention_bam_384_min_attention": -1.260009765625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 4.4524447657363755,
      "attention_bam_384_attention_skewness": 0.6456918552354836,
      "attention_bam_384_attention_sparsity": 0.40851593017578125,
      "attention_bam_384_attention_concentration_10": 0.48436394296712876,
      "attention_bam_384_attention_concentration_20": 0.7832336193166394,
      "attention_bam_384_attention_center_y": 0.4808748256619096,
      "attention_bam_384_attention_center_x": 0.4825447696842559,
      "attention_bam_384_attention_center_distance": 0.036618502395319864,
      "attention_bam_384_attention_spatial_variance": 170.02090434762187,
      "attention_bam_384_attention_spatial_std": 13.039206430899922,
      "attention_bam_384_num_attention_peaks": 18,
      "attention_bam_384_peak_separation_mean": 15.873982640844439,
      "attention_bam_384_peak_intensity_mean": 0.21787364780902863,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2526082694530487,
      "attention_bam_16_std_attention": 0.35473814606666565,
      "attention_bam_16_max_attention": 2.642578125,
      "attention_bam_16_min_attention": -0.9638671875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.5740240132378673,
      "attention_bam_16_attention_skewness": 0.317561296490738,
      "attention_bam_16_attention_sparsity": 0.31689453125,
      "attention_bam_16_attention_concentration_10": 0.36706941743203353,
      "attention_bam_16_attention_concentration_20": 0.6063016752757872,
      "attention_bam_16_attention_center_y": 0.4660662512987393,
      "attention_bam_16_attention_center_x": 0.47516612882095766,
      "attention_bam_16_attention_center_distance": 0.05946798228723726,
      "attention_bam_16_attention_spatial_variance": 43.59949825400967,
      "attention_bam_16_attention_spatial_std": 6.602991613958757,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 12.114547544810545,
      "attention_bam_16_peak_intensity_mean": 0.343669593334198,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 145,
      "phase": "train",
      "loss": 0.021402757614850998,
      "timestamp": 1759561914.5771892,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.021402757614850998,
      "ssim": 0.554222047328949,
      "attention_bam_384_mean_attention": 0.1762102246284485,
      "attention_bam_384_std_attention": 0.52700275182724,
      "attention_bam_384_max_attention": 4.328369140625,
      "attention_bam_384_min_attention": -1.2161865234375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.8510807091626518,
      "attention_bam_384_attention_skewness": 1.0907244529328115,
      "attention_bam_384_attention_sparsity": 0.47461700439453125,
      "attention_bam_384_attention_concentration_10": 0.7110353862592194,
      "attention_bam_384_attention_concentration_20": 1.0773775838877249,
      "attention_bam_384_attention_center_y": 0.48956259620279824,
      "attention_bam_384_attention_center_x": 0.4851894301556831,
      "attention_bam_384_attention_center_distance": 0.025623909816389477,
      "attention_bam_384_attention_spatial_variance": 170.25363533607617,
      "attention_bam_384_attention_spatial_std": 13.048127656337371,
      "attention_bam_384_num_attention_peaks": 2,
      "attention_bam_384_peak_separation_mean": 23.400357541547688,
      "attention_bam_384_peak_intensity_mean": 0.2519640326499939,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19831284880638123,
      "attention_bam_16_std_attention": 0.48691537976264954,
      "attention_bam_16_max_attention": 3.819427490234375,
      "attention_bam_16_min_attention": -1.18743896484375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 4.735431213594176,
      "attention_bam_16_attention_skewness": 1.259646259933582,
      "attention_bam_16_attention_sparsity": 0.4345703125,
      "attention_bam_16_attention_concentration_10": 0.5919150470864986,
      "attention_bam_16_attention_concentration_20": 0.8944513865036727,
      "attention_bam_16_attention_center_y": 0.4710931325437147,
      "attention_bam_16_attention_center_x": 0.4688215592386578,
      "attention_bam_16_attention_center_distance": 0.06012823221156213,
      "attention_bam_16_attention_spatial_variance": 42.37212714071734,
      "attention_bam_16_attention_spatial_std": 6.509387616413493,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.076507049772484,
      "attention_bam_16_peak_intensity_mean": 0.27971699833869934,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 146,
      "phase": "train",
      "loss": 0.034220192581415176,
      "timestamp": 1759561914.7427294,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.034220192581415176,
      "ssim": 0.5526670217514038,
      "attention_bam_384_mean_attention": 0.18389493227005005,
      "attention_bam_384_std_attention": 0.5327873229980469,
      "attention_bam_384_max_attention": 3.908203125,
      "attention_bam_384_min_attention": -1.2236328125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9183906573161544,
      "attention_bam_384_attention_skewness": 0.6587116338261118,
      "attention_bam_384_attention_sparsity": 0.4645436604817708,
      "attention_bam_384_attention_concentration_10": 0.6672643501568645,
      "attention_bam_384_attention_concentration_20": 1.0560403900931312,
      "attention_bam_384_attention_center_y": 0.48636251003777814,
      "attention_bam_384_attention_center_x": 0.49009373211486107,
      "attention_bam_384_attention_center_distance": 0.02383758695345806,
      "attention_bam_384_attention_spatial_variance": 167.83536763726323,
      "attention_bam_384_attention_spatial_std": 12.955129008900808,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 12.408225464096695,
      "attention_bam_384_peak_intensity_mean": 0.282222718000412,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22327879071235657,
      "attention_bam_16_std_attention": 0.5426353216171265,
      "attention_bam_16_max_attention": 4.4188232421875,
      "attention_bam_16_min_attention": -1.001220703125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.3649286262936293,
      "attention_bam_16_attention_skewness": 0.9614735579743224,
      "attention_bam_16_attention_sparsity": 0.41650390625,
      "attention_bam_16_attention_concentration_10": 0.563504263812558,
      "attention_bam_16_attention_concentration_20": 0.8811964987057266,
      "attention_bam_16_attention_center_y": 0.4704737592768348,
      "attention_bam_16_attention_center_x": 0.46719546578062615,
      "attention_bam_16_attention_center_distance": 0.062416926495821104,
      "attention_bam_16_attention_spatial_variance": 42.72888676255926,
      "attention_bam_16_attention_spatial_std": 6.536733646291492,
      "attention_bam_16_num_attention_peaks": 12,
      "attention_bam_16_peak_separation_mean": 8.544578663576013,
      "attention_bam_16_peak_intensity_mean": 0.2302878051996231,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 147,
      "phase": "train",
      "loss": 0.019618453457951546,
      "timestamp": 1759561914.9110436,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.019618453457951546,
      "ssim": 0.5530368089675903,
      "attention_bam_384_mean_attention": 0.16870927810668945,
      "attention_bam_384_std_attention": 0.517133891582489,
      "attention_bam_384_max_attention": 4.31640625,
      "attention_bam_384_min_attention": -1.224853515625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.059507155709989,
      "attention_bam_384_attention_skewness": 1.0968869587352934,
      "attention_bam_384_attention_sparsity": 0.4745381673177083,
      "attention_bam_384_attention_concentration_10": 0.7185000711305488,
      "attention_bam_384_attention_concentration_20": 1.097687123089788,
      "attention_bam_384_attention_center_y": 0.49794774839315453,
      "attention_bam_384_attention_center_x": 0.4811485944635376,
      "attention_bam_384_attention_center_distance": 0.026817428189815876,
      "attention_bam_384_attention_spatial_variance": 173.0074767454201,
      "attention_bam_384_attention_spatial_std": 13.15323065810906,
      "attention_bam_384_num_attention_peaks": 2,
      "attention_bam_384_peak_separation_mean": 17.141629999362646,
      "attention_bam_384_peak_intensity_mean": 0.2702863812446594,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21813397109508514,
      "attention_bam_16_std_attention": 0.5292576551437378,
      "attention_bam_16_max_attention": 3.867401123046875,
      "attention_bam_16_min_attention": -1.0474853515625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 5.469380648084787,
      "attention_bam_16_attention_skewness": 1.427009995457906,
      "attention_bam_16_attention_sparsity": 0.414794921875,
      "attention_bam_16_attention_concentration_10": 0.5824426761750032,
      "attention_bam_16_attention_concentration_20": 0.8844921787136135,
      "attention_bam_16_attention_center_y": 0.47781318869556744,
      "attention_bam_16_attention_center_x": 0.4721209482284688,
      "attention_bam_16_attention_center_distance": 0.05038841381782551,
      "attention_bam_16_attention_spatial_variance": 42.604383663428244,
      "attention_bam_16_attention_spatial_std": 6.527203356984386,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.583730635356337,
      "attention_bam_16_peak_intensity_mean": 0.2618809640407562,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 148,
      "phase": "train",
      "loss": 0.024400226771831512,
      "timestamp": 1759561915.0791554,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.024400226771831512,
      "ssim": 0.5896843075752258,
      "attention_bam_384_mean_attention": 0.17813777923583984,
      "attention_bam_384_std_attention": 0.5667524337768555,
      "attention_bam_384_max_attention": 4.531982421875,
      "attention_bam_384_min_attention": -1.287841796875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.0709250867484403,
      "attention_bam_384_attention_skewness": 0.8640248970640723,
      "attention_bam_384_attention_sparsity": 0.4715677897135417,
      "attention_bam_384_attention_concentration_10": 0.7255274611730793,
      "attention_bam_384_attention_concentration_20": 1.1349707025497466,
      "attention_bam_384_attention_center_y": 0.48268982176630953,
      "attention_bam_384_attention_center_x": 0.4858548299362719,
      "attention_bam_384_attention_center_distance": 0.03161417740868553,
      "attention_bam_384_attention_spatial_variance": 168.58607957360638,
      "attention_bam_384_attention_spatial_std": 12.984070223685883,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 16.232342186038668,
      "attention_bam_384_peak_intensity_mean": 0.2520134747028351,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22386763989925385,
      "attention_bam_16_std_attention": 0.5758029222488403,
      "attention_bam_16_max_attention": 4.595267295837402,
      "attention_bam_16_min_attention": -1.18115234375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 6.050376688258275,
      "attention_bam_16_attention_skewness": 1.3071574865280253,
      "attention_bam_16_attention_sparsity": 0.424072265625,
      "attention_bam_16_attention_concentration_10": 0.5917361616597041,
      "attention_bam_16_attention_concentration_20": 0.9192583780127304,
      "attention_bam_16_attention_center_y": 0.47107624301033074,
      "attention_bam_16_attention_center_x": 0.46990819538164214,
      "attention_bam_16_attention_center_distance": 0.05902711959069094,
      "attention_bam_16_attention_spatial_variance": 42.66801946061581,
      "attention_bam_16_attention_spatial_std": 6.5320761983167195,
      "attention_bam_16_num_attention_peaks": 15,
      "attention_bam_16_peak_separation_mean": 9.204801177167608,
      "attention_bam_16_peak_intensity_mean": 0.24660514295101166,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 149,
      "phase": "train",
      "loss": 0.024442698806524277,
      "timestamp": 1759561915.2493143,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.024442698806524277,
      "ssim": 0.48882192373275757,
      "attention_bam_384_mean_attention": 0.1825742870569229,
      "attention_bam_384_std_attention": 0.4712684452533722,
      "attention_bam_384_max_attention": 4.74761962890625,
      "attention_bam_384_min_attention": -1.283203125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 5.781609687841145,
      "attention_bam_384_attention_skewness": 1.3134435623728238,
      "attention_bam_384_attention_sparsity": 0.45058441162109375,
      "attention_bam_384_attention_concentration_10": 0.6006236625017596,
      "attention_bam_384_attention_concentration_20": 0.9332567947489604,
      "attention_bam_384_attention_center_y": 0.4846109395794309,
      "attention_bam_384_attention_center_x": 0.48562214129252146,
      "attention_bam_384_attention_center_distance": 0.029784089767529998,
      "attention_bam_384_attention_spatial_variance": 167.1250771905589,
      "attention_bam_384_attention_spatial_std": 12.927686459322832,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 18.530763437310444,
      "attention_bam_384_peak_intensity_mean": 0.24693997204303741,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20315754413604736,
      "attention_bam_16_std_attention": 0.4663643538951874,
      "attention_bam_16_max_attention": 4.28863525390625,
      "attention_bam_16_min_attention": -0.8829345703125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 11.689442019324018,
      "attention_bam_16_attention_skewness": 1.9824525428656479,
      "attention_bam_16_attention_sparsity": 0.42138671875,
      "attention_bam_16_attention_concentration_10": 0.5235753801260744,
      "attention_bam_16_attention_concentration_20": 0.8154272011140066,
      "attention_bam_16_attention_center_y": 0.46995208255967436,
      "attention_bam_16_attention_center_x": 0.4768749023816589,
      "attention_bam_16_attention_center_distance": 0.05362177696343959,
      "attention_bam_16_attention_spatial_variance": 42.463930542440295,
      "attention_bam_16_attention_spatial_std": 6.516435416885546,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 10.81553025065766,
      "attention_bam_16_peak_intensity_mean": 0.2188338041305542,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 150,
      "phase": "train",
      "loss": 0.02975395694375038,
      "timestamp": 1759561915.4935043,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.02975395694375038,
      "ssim": 0.6000595092773438,
      "attention_bam_384_mean_attention": 0.18602465093135834,
      "attention_bam_384_std_attention": 0.5929553508758545,
      "attention_bam_384_max_attention": 6.0179443359375,
      "attention_bam_384_min_attention": -1.40576171875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 5.976617239804822,
      "attention_bam_384_attention_skewness": 1.3752706599361935,
      "attention_bam_384_attention_sparsity": 0.47311147054036456,
      "attention_bam_384_attention_concentration_10": 0.7261684300218373,
      "attention_bam_384_attention_concentration_20": 1.1157538662854651,
      "attention_bam_384_attention_center_y": 0.4843760094555751,
      "attention_bam_384_attention_center_x": 0.482286757439301,
      "attention_bam_384_attention_center_distance": 0.03340263590037283,
      "attention_bam_384_attention_spatial_variance": 168.3289954249224,
      "attention_bam_384_attention_spatial_std": 12.974166463589189,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 19.811121751344466,
      "attention_bam_384_peak_intensity_mean": 0.21603554487228394,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21107107400894165,
      "attention_bam_16_std_attention": 0.5809417366981506,
      "attention_bam_16_max_attention": 6.4505615234375,
      "attention_bam_16_min_attention": -1.192626953125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 13.313622296619275,
      "attention_bam_16_attention_skewness": 2.0834569024752487,
      "attention_bam_16_attention_sparsity": 0.455322265625,
      "attention_bam_16_attention_concentration_10": 0.6205052828289356,
      "attention_bam_16_attention_concentration_20": 0.9535747214452059,
      "attention_bam_16_attention_center_y": 0.4661896921530655,
      "attention_bam_16_attention_center_x": 0.4694464824730764,
      "attention_bam_16_attention_center_distance": 0.06444616900906536,
      "attention_bam_16_attention_spatial_variance": 42.70409105044149,
      "attention_bam_16_attention_spatial_std": 6.534836727144871,
      "attention_bam_16_num_attention_peaks": 16,
      "attention_bam_16_peak_separation_mean": 8.819005297710245,
      "attention_bam_16_peak_intensity_mean": 0.18496116995811462,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 151,
      "phase": "train",
      "loss": 0.02930482290685177,
      "timestamp": 1759561915.8592095,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.02930482290685177,
      "ssim": 0.5613878965377808,
      "attention_bam_384_mean_attention": 0.1747666746377945,
      "attention_bam_384_std_attention": 0.5233790874481201,
      "attention_bam_384_max_attention": 4.072662353515625,
      "attention_bam_384_min_attention": -1.34326171875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5914357723582393,
      "attention_bam_384_attention_skewness": 0.802398390614939,
      "attention_bam_384_attention_sparsity": 0.48166656494140625,
      "attention_bam_384_attention_concentration_10": 0.6881304003559588,
      "attention_bam_384_attention_concentration_20": 1.0909381734012564,
      "attention_bam_384_attention_center_y": 0.48218899794703635,
      "attention_bam_384_attention_center_x": 0.4843957941000445,
      "attention_bam_384_attention_center_distance": 0.03348799892196847,
      "attention_bam_384_attention_spatial_variance": 170.94276325968403,
      "attention_bam_384_attention_spatial_std": 13.074508145994786,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 20.645699270186817,
      "attention_bam_384_peak_intensity_mean": 0.28355687856674194,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20496010780334473,
      "attention_bam_16_std_attention": 0.5281815528869629,
      "attention_bam_16_max_attention": 4.92633056640625,
      "attention_bam_16_min_attention": -0.971923828125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.6479625304613466,
      "attention_bam_16_attention_skewness": 0.9442642988318812,
      "attention_bam_16_attention_sparsity": 0.44873046875,
      "attention_bam_16_attention_concentration_10": 0.5848737589572809,
      "attention_bam_16_attention_concentration_20": 0.9404155252224647,
      "attention_bam_16_attention_center_y": 0.46583065793012307,
      "attention_bam_16_attention_center_x": 0.46724879108140815,
      "attention_bam_16_attention_center_distance": 0.06693557534103238,
      "attention_bam_16_attention_spatial_variance": 43.90540234305161,
      "attention_bam_16_attention_spatial_std": 6.62611517731556,
      "attention_bam_16_num_attention_peaks": 18,
      "attention_bam_16_peak_separation_mean": 10.310721836561209,
      "attention_bam_16_peak_intensity_mean": 0.20690056681632996,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 152,
      "phase": "train",
      "loss": 0.019381288439035416,
      "timestamp": 1759561916.025163,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.019381288439035416,
      "ssim": 0.5664384365081787,
      "attention_bam_384_mean_attention": 0.18008466064929962,
      "attention_bam_384_std_attention": 0.5309715867042542,
      "attention_bam_384_max_attention": 5.21820068359375,
      "attention_bam_384_min_attention": -1.2000732421875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 6.145312512537572,
      "attention_bam_384_attention_skewness": 1.5739564969436224,
      "attention_bam_384_attention_sparsity": 0.47245534261067706,
      "attention_bam_384_attention_concentration_10": 0.6916191579880572,
      "attention_bam_384_attention_concentration_20": 1.0383590700661534,
      "attention_bam_384_attention_center_y": 0.47496966057077344,
      "attention_bam_384_attention_center_x": 0.4908014019593686,
      "attention_bam_384_attention_center_distance": 0.03771291815427178,
      "attention_bam_384_attention_spatial_variance": 170.45998432723636,
      "attention_bam_384_attention_spatial_std": 13.056032487981804,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 17.086703820519226,
      "attention_bam_384_peak_intensity_mean": 0.2162674218416214,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2051278054714203,
      "attention_bam_16_std_attention": 0.4864664077758789,
      "attention_bam_16_max_attention": 3.7359619140625,
      "attention_bam_16_min_attention": -0.944580078125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.439708899605554,
      "attention_bam_16_attention_skewness": 0.9575835441561393,
      "attention_bam_16_attention_sparsity": 0.44287109375,
      "attention_bam_16_attention_concentration_10": 0.5417282015909205,
      "attention_bam_16_attention_concentration_20": 0.8660780040771854,
      "attention_bam_16_attention_center_y": 0.4712743531384479,
      "attention_bam_16_attention_center_x": 0.46588912113809305,
      "attention_bam_16_attention_center_distance": 0.06306686680573703,
      "attention_bam_16_attention_spatial_variance": 42.787512731543586,
      "attention_bam_16_attention_spatial_std": 6.541216456557877,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 10.759680830521658,
      "attention_bam_16_peak_intensity_mean": 0.25051170587539673,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 153,
      "phase": "train",
      "loss": 0.021782752126455307,
      "timestamp": 1759561916.2148492,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.021782752126455307,
      "ssim": 0.6468113660812378,
      "attention_bam_384_mean_attention": 0.18368326127529144,
      "attention_bam_384_std_attention": 0.5593442320823669,
      "attention_bam_384_max_attention": 4.2138671875,
      "attention_bam_384_min_attention": -1.3087158203125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.6924713531368019,
      "attention_bam_384_attention_skewness": 0.8076872481693933,
      "attention_bam_384_attention_sparsity": 0.4773203531901042,
      "attention_bam_384_attention_concentration_10": 0.7019824380120738,
      "attention_bam_384_attention_concentration_20": 1.105235746447066,
      "attention_bam_384_attention_center_y": 0.4828941101916415,
      "attention_bam_384_attention_center_x": 0.4837457635031308,
      "attention_bam_384_attention_center_distance": 0.03337099549704373,
      "attention_bam_384_attention_spatial_variance": 169.7329486366952,
      "attention_bam_384_attention_spatial_std": 13.02815983309597,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 17.193731039922092,
      "attention_bam_384_peak_intensity_mean": 0.27199843525886536,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21687328815460205,
      "attention_bam_16_std_attention": 0.5505548119544983,
      "attention_bam_16_max_attention": 4.36968994140625,
      "attention_bam_16_min_attention": -1.2080078125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.9829075132152534,
      "attention_bam_16_attention_skewness": 1.1419997821270929,
      "attention_bam_16_attention_sparsity": 0.453125,
      "attention_bam_16_attention_concentration_10": 0.5986174361556674,
      "attention_bam_16_attention_concentration_20": 0.9398865750623198,
      "attention_bam_16_attention_center_y": 0.46467221915411805,
      "attention_bam_16_attention_center_x": 0.47066538082779263,
      "attention_bam_16_attention_center_distance": 0.06493954082795934,
      "attention_bam_16_attention_spatial_variance": 42.847329747153246,
      "attention_bam_16_attention_spatial_std": 6.545787175516268,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.57861056923685,
      "attention_bam_16_peak_intensity_mean": 0.25631341338157654,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 154,
      "phase": "train",
      "loss": 0.0184309259057045,
      "timestamp": 1759561916.3768528,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0184309259057045,
      "ssim": 0.564734697341919,
      "attention_bam_384_mean_attention": 0.17785675823688507,
      "attention_bam_384_std_attention": 0.5507581233978271,
      "attention_bam_384_max_attention": 4.5203857421875,
      "attention_bam_384_min_attention": -1.360107421875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.5586247715377306,
      "attention_bam_384_attention_skewness": 1.0687690258821507,
      "attention_bam_384_attention_sparsity": 0.4856618245442708,
      "attention_bam_384_attention_concentration_10": 0.7375225428917119,
      "attention_bam_384_attention_concentration_20": 1.1278148453319186,
      "attention_bam_384_attention_center_y": 0.48484351773738293,
      "attention_bam_384_attention_center_x": 0.4825992466352175,
      "attention_bam_384_attention_center_distance": 0.032634496234476,
      "attention_bam_384_attention_spatial_variance": 173.51432292441407,
      "attention_bam_384_attention_spatial_std": 13.172483551874873,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 19.725238775092997,
      "attention_bam_384_peak_intensity_mean": 0.26327747106552124,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20448514819145203,
      "attention_bam_16_std_attention": 0.5349142551422119,
      "attention_bam_16_max_attention": 4.712158203125,
      "attention_bam_16_min_attention": -1.0897216796875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 4.074154630229274,
      "attention_bam_16_attention_skewness": 1.175315092514183,
      "attention_bam_16_attention_sparsity": 0.463623046875,
      "attention_bam_16_attention_concentration_10": 0.6226085907096275,
      "attention_bam_16_attention_concentration_20": 0.9652016218772411,
      "attention_bam_16_attention_center_y": 0.46471393538048117,
      "attention_bam_16_attention_center_x": 0.4680071897662943,
      "attention_bam_16_attention_center_distance": 0.06735942789220768,
      "attention_bam_16_attention_spatial_variance": 43.88409235212103,
      "attention_bam_16_attention_spatial_std": 6.624506951624478,
      "attention_bam_16_num_attention_peaks": 11,
      "attention_bam_16_peak_separation_mean": 10.136045468862878,
      "attention_bam_16_peak_intensity_mean": 0.22894348204135895,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 155,
      "phase": "train",
      "loss": 0.015865063294768333,
      "timestamp": 1759561916.5580764,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.015865063294768333,
      "ssim": 0.5793660879135132,
      "attention_bam_384_mean_attention": 0.1846723109483719,
      "attention_bam_384_std_attention": 0.5143648386001587,
      "attention_bam_384_max_attention": 5.1952056884765625,
      "attention_bam_384_min_attention": -1.351806640625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 4.2337882980664965,
      "attention_bam_384_attention_skewness": 1.0631512177242233,
      "attention_bam_384_attention_sparsity": 0.4580637613932292,
      "attention_bam_384_attention_concentration_10": 0.6359829764012834,
      "attention_bam_384_attention_concentration_20": 1.0035514244319836,
      "attention_bam_384_attention_center_y": 0.4837400324383113,
      "attention_bam_384_attention_center_x": 0.48133936258618715,
      "attention_bam_384_attention_center_distance": 0.035003026549056016,
      "attention_bam_384_attention_spatial_variance": 170.81169156418653,
      "attention_bam_384_attention_spatial_std": 13.069494694294287,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 16.754360061713797,
      "attention_bam_384_peak_intensity_mean": 0.23471903800964355,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21794703602790833,
      "attention_bam_16_std_attention": 0.5365748405456543,
      "attention_bam_16_max_attention": 5.26092529296875,
      "attention_bam_16_min_attention": -0.89990234375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 8.020946063812554,
      "attention_bam_16_attention_skewness": 1.4450725262362476,
      "attention_bam_16_attention_sparsity": 0.43701171875,
      "attention_bam_16_attention_concentration_10": 0.5570951960183121,
      "attention_bam_16_attention_concentration_20": 0.8951376087350599,
      "attention_bam_16_attention_center_y": 0.4769425084823993,
      "attention_bam_16_attention_center_x": 0.46212257318527006,
      "attention_bam_16_attention_center_distance": 0.06271120118749843,
      "attention_bam_16_attention_spatial_variance": 43.276778212148415,
      "attention_bam_16_attention_spatial_std": 6.5785088137167085,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 8.183939692956578,
      "attention_bam_16_peak_intensity_mean": 0.18172800540924072,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 156,
      "phase": "train",
      "loss": 0.01948847621679306,
      "timestamp": 1759561916.718758,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.01948847621679306,
      "ssim": 0.6693168878555298,
      "attention_bam_384_mean_attention": 0.1802067756652832,
      "attention_bam_384_std_attention": 0.5644136071205139,
      "attention_bam_384_max_attention": 5.0333251953125,
      "attention_bam_384_min_attention": -1.33642578125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.2388801612955636,
      "attention_bam_384_attention_skewness": 0.8301758464614041,
      "attention_bam_384_attention_sparsity": 0.4718373616536458,
      "attention_bam_384_attention_concentration_10": 0.7031088066905408,
      "attention_bam_384_attention_concentration_20": 1.1159589790810085,
      "attention_bam_384_attention_center_y": 0.4836018221200231,
      "attention_bam_384_attention_center_x": 0.4858659818241587,
      "attention_bam_384_attention_center_distance": 0.030616031995618756,
      "attention_bam_384_attention_spatial_variance": 170.64957924620435,
      "attention_bam_384_attention_spatial_std": 13.063291286892609,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 18.505655094112292,
      "attention_bam_384_peak_intensity_mean": 0.24060392379760742,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2184910923242569,
      "attention_bam_16_std_attention": 0.5755861401557922,
      "attention_bam_16_max_attention": 4.5802001953125,
      "attention_bam_16_min_attention": -1.115966796875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 4.480983133164045,
      "attention_bam_16_attention_skewness": 0.9741048736020657,
      "attention_bam_16_attention_sparsity": 0.444091796875,
      "attention_bam_16_attention_concentration_10": 0.5802405002182706,
      "attention_bam_16_attention_concentration_20": 0.9443211950990219,
      "attention_bam_16_attention_center_y": 0.4708016461134533,
      "attention_bam_16_attention_center_x": 0.4672389007568338,
      "attention_bam_16_attention_center_distance": 0.06206179973711046,
      "attention_bam_16_attention_spatial_variance": 43.1163070687143,
      "attention_bam_16_attention_spatial_std": 6.5663008664478895,
      "attention_bam_16_num_attention_peaks": 15,
      "attention_bam_16_peak_separation_mean": 9.266962221491763,
      "attention_bam_16_peak_intensity_mean": 0.23872531950473785,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 157,
      "phase": "train",
      "loss": 0.018622037023305893,
      "timestamp": 1759561916.8837588,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.018622037023305893,
      "ssim": 0.7012475728988647,
      "attention_bam_384_mean_attention": 0.18302197754383087,
      "attention_bam_384_std_attention": 0.5390484929084778,
      "attention_bam_384_max_attention": 3.8372802734375,
      "attention_bam_384_min_attention": -1.30322265625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.6547240061134705,
      "attention_bam_384_attention_skewness": 1.1528174645675144,
      "attention_bam_384_attention_sparsity": 0.48158518473307294,
      "attention_bam_384_attention_concentration_10": 0.7138790385980116,
      "attention_bam_384_attention_concentration_20": 1.077872528251121,
      "attention_bam_384_attention_center_y": 0.48094398338748706,
      "attention_bam_384_attention_center_x": 0.474936586757093,
      "attention_bam_384_attention_center_distance": 0.04452654157962631,
      "attention_bam_384_attention_spatial_variance": 167.931052655444,
      "attention_bam_384_attention_spatial_std": 12.958821422314763,
      "attention_bam_384_num_attention_peaks": 3,
      "attention_bam_384_peak_separation_mean": 15.814806225555898,
      "attention_bam_384_peak_intensity_mean": 0.2916812598705292,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2035267949104309,
      "attention_bam_16_std_attention": 0.4948086738586426,
      "attention_bam_16_max_attention": 3.3021621704101562,
      "attention_bam_16_min_attention": -0.90777587890625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 4.206053570329929,
      "attention_bam_16_attention_skewness": 1.262799871984987,
      "attention_bam_16_attention_sparsity": 0.438232421875,
      "attention_bam_16_attention_concentration_10": 0.5831953357455478,
      "attention_bam_16_attention_concentration_20": 0.8970837983581903,
      "attention_bam_16_attention_center_y": 0.466226904615083,
      "attention_bam_16_attention_center_x": 0.46151338091147603,
      "attention_bam_16_attention_center_distance": 0.07241328359829902,
      "attention_bam_16_attention_spatial_variance": 42.551799439635275,
      "attention_bam_16_attention_spatial_std": 6.523174031070709,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 8.443557453878828,
      "attention_bam_16_peak_intensity_mean": 0.2691654562950134,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 158,
      "phase": "train",
      "loss": 0.017222285270690918,
      "timestamp": 1759561917.045458,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.017222285270690918,
      "ssim": 0.6853591799736023,
      "attention_bam_384_mean_attention": 0.18392151594161987,
      "attention_bam_384_std_attention": 0.5363050103187561,
      "attention_bam_384_max_attention": 3.95849609375,
      "attention_bam_384_min_attention": -1.26171875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0525914192919252,
      "attention_bam_384_attention_skewness": 0.6056221775371089,
      "attention_bam_384_attention_sparsity": 0.4601186116536458,
      "attention_bam_384_attention_concentration_10": 0.6535494534826682,
      "attention_bam_384_attention_concentration_20": 1.0513692611043095,
      "attention_bam_384_attention_center_y": 0.4791102827869069,
      "attention_bam_384_attention_center_x": 0.48465911902479064,
      "attention_bam_384_attention_center_distance": 0.03665304664931791,
      "attention_bam_384_attention_spatial_variance": 170.72444670228634,
      "attention_bam_384_attention_spatial_std": 13.066156539024258,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 18.250938558075486,
      "attention_bam_384_peak_intensity_mean": 0.2771978974342346,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22688543796539307,
      "attention_bam_16_std_attention": 0.562730073928833,
      "attention_bam_16_max_attention": 3.6877288818359375,
      "attention_bam_16_min_attention": -1.025634765625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.928055639334353,
      "attention_bam_16_attention_skewness": 0.7277639714822874,
      "attention_bam_16_attention_sparsity": 0.43359375,
      "attention_bam_16_attention_concentration_10": 0.5618976431344085,
      "attention_bam_16_attention_concentration_20": 0.9161283339530991,
      "attention_bam_16_attention_center_y": 0.4662936138040748,
      "attention_bam_16_attention_center_x": 0.4713637070449956,
      "attention_bam_16_attention_center_distance": 0.06254850509154783,
      "attention_bam_16_attention_spatial_variance": 43.8695253923313,
      "attention_bam_16_attention_spatial_std": 6.623407385351689,
      "attention_bam_16_num_attention_peaks": 14,
      "attention_bam_16_peak_separation_mean": 8.942713035087673,
      "attention_bam_16_peak_intensity_mean": 0.2685690224170685,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 159,
      "phase": "train",
      "loss": 0.0172390379011631,
      "timestamp": 1759561917.2098813,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0172390379011631,
      "ssim": 0.6576597690582275,
      "attention_bam_384_mean_attention": 0.17409121990203857,
      "attention_bam_384_std_attention": 0.4609720706939697,
      "attention_bam_384_max_attention": 3.212646484375,
      "attention_bam_384_min_attention": -1.170654296875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.419782649764394,
      "attention_bam_384_attention_skewness": 0.7478317489723658,
      "attention_bam_384_attention_sparsity": 0.46450551350911456,
      "attention_bam_384_attention_concentration_10": 0.6234757137909716,
      "attention_bam_384_attention_concentration_20": 0.9789495860559351,
      "attention_bam_384_attention_center_y": 0.48242541344795536,
      "attention_bam_384_attention_center_x": 0.48852904513854367,
      "attention_bam_384_attention_center_distance": 0.029679922436181554,
      "attention_bam_384_attention_spatial_variance": 168.3773774586849,
      "attention_bam_384_attention_spatial_std": 12.97603088231085,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 15.680818738217944,
      "attention_bam_384_peak_intensity_mean": 0.30741092562675476,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22768348455429077,
      "attention_bam_16_std_attention": 0.48880431056022644,
      "attention_bam_16_max_attention": 3.1502685546875,
      "attention_bam_16_min_attention": -1.056396484375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.503851808302529,
      "attention_bam_16_attention_skewness": 0.9139086416215985,
      "attention_bam_16_attention_sparsity": 0.41650390625,
      "attention_bam_16_attention_concentration_10": 0.5256467782435039,
      "attention_bam_16_attention_concentration_20": 0.8224866128431045,
      "attention_bam_16_attention_center_y": 0.4664623323244931,
      "attention_bam_16_attention_center_x": 0.47256834902779876,
      "attention_bam_16_attention_center_distance": 0.06127431155343013,
      "attention_bam_16_attention_spatial_variance": 42.297602534142335,
      "attention_bam_16_attention_spatial_std": 6.503660702569157,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 8.871573236021359,
      "attention_bam_16_peak_intensity_mean": 0.31019845604896545,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 160,
      "phase": "train",
      "loss": 0.015871092677116394,
      "timestamp": 1759561917.4784598,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.015871092677116394,
      "ssim": 0.6724368333816528,
      "attention_bam_384_mean_attention": 0.17057280242443085,
      "attention_bam_384_std_attention": 0.516645073890686,
      "attention_bam_384_max_attention": 3.3990936279296875,
      "attention_bam_384_min_attention": -1.1318359375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.062246820742744,
      "attention_bam_384_attention_skewness": 0.9870221238866319,
      "attention_bam_384_attention_sparsity": 0.48061879475911456,
      "attention_bam_384_attention_concentration_10": 0.7162388572905128,
      "attention_bam_384_attention_concentration_20": 1.097691727983194,
      "attention_bam_384_attention_center_y": 0.4941349761983813,
      "attention_bam_384_attention_center_x": 0.4797627390313434,
      "attention_bam_384_attention_center_distance": 0.029797491025489533,
      "attention_bam_384_attention_spatial_variance": 169.61725912093786,
      "attention_bam_384_attention_spatial_std": 13.023719097129586,
      "attention_bam_384_num_attention_peaks": 3,
      "attention_bam_384_peak_separation_mean": 22.32206818519195,
      "attention_bam_384_peak_intensity_mean": 0.2945099174976349,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21331572532653809,
      "attention_bam_16_std_attention": 0.5366588234901428,
      "attention_bam_16_max_attention": 3.91351318359375,
      "attention_bam_16_min_attention": -1.166748046875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 5.087208576725397,
      "attention_bam_16_attention_skewness": 1.3344649662934687,
      "attention_bam_16_attention_sparsity": 0.420166015625,
      "attention_bam_16_attention_concentration_10": 0.5894552123467399,
      "attention_bam_16_attention_concentration_20": 0.9026736705939198,
      "attention_bam_16_attention_center_y": 0.47482710478785,
      "attention_bam_16_attention_center_x": 0.45680919703085565,
      "attention_bam_16_attention_center_distance": 0.07069823356324162,
      "attention_bam_16_attention_spatial_variance": 41.94376854237731,
      "attention_bam_16_attention_spatial_std": 6.476400894198669,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.508969563095134,
      "attention_bam_16_peak_intensity_mean": 0.27094510197639465,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 161,
      "phase": "train",
      "loss": 0.029809731990098953,
      "timestamp": 1759561917.6619768,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.029809731990098953,
      "ssim": 0.6723382472991943,
      "attention_bam_384_mean_attention": 0.19300176203250885,
      "attention_bam_384_std_attention": 0.46259984374046326,
      "attention_bam_384_max_attention": 4.4697265625,
      "attention_bam_384_min_attention": -1.30078125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.6666052557367887,
      "attention_bam_384_attention_skewness": 0.6946591312813707,
      "attention_bam_384_attention_sparsity": 0.429595947265625,
      "attention_bam_384_attention_concentration_10": 0.5579346181121402,
      "attention_bam_384_attention_concentration_20": 0.875389858676404,
      "attention_bam_384_attention_center_y": 0.4794429079913057,
      "attention_bam_384_attention_center_x": 0.48108795856058095,
      "attention_bam_384_attention_center_distance": 0.039503400948784836,
      "attention_bam_384_attention_spatial_variance": 171.03497691680647,
      "attention_bam_384_attention_spatial_std": 13.078034138080787,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 17.584906105708537,
      "attention_bam_384_peak_intensity_mean": 0.2638721764087677,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2399379014968872,
      "attention_bam_16_std_attention": 0.49527209997177124,
      "attention_bam_16_max_attention": 3.321044921875,
      "attention_bam_16_min_attention": -1.34619140625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.040939216747028,
      "attention_bam_16_attention_skewness": 0.9245138685063898,
      "attention_bam_16_attention_sparsity": 0.410888671875,
      "attention_bam_16_attention_concentration_10": 0.5024600731785247,
      "attention_bam_16_attention_concentration_20": 0.7986653798586723,
      "attention_bam_16_attention_center_y": 0.4627229466065347,
      "attention_bam_16_attention_center_x": 0.4547100898792418,
      "attention_bam_16_attention_center_distance": 0.08295486325039204,
      "attention_bam_16_attention_spatial_variance": 43.94548548713058,
      "attention_bam_16_attention_spatial_std": 6.629139121117507,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 11.469509375108878,
      "attention_bam_16_peak_intensity_mean": 0.3542799651622772,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 162,
      "phase": "train",
      "loss": 0.023801572620868683,
      "timestamp": 1759561917.83022,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.023801572620868683,
      "ssim": 0.7696202397346497,
      "attention_bam_384_mean_attention": 0.17883585393428802,
      "attention_bam_384_std_attention": 0.47427675127983093,
      "attention_bam_384_max_attention": 3.0703125,
      "attention_bam_384_min_attention": -1.189697265625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.06130974209379669,
      "attention_bam_384_attention_skewness": 0.4260849912093204,
      "attention_bam_384_attention_sparsity": 0.46241505940755206,
      "attention_bam_384_attention_concentration_10": 0.6068646253686046,
      "attention_bam_384_attention_concentration_20": 0.9889254683563486,
      "attention_bam_384_attention_center_y": 0.4863661373729567,
      "attention_bam_384_attention_center_x": 0.48571557652458686,
      "attention_bam_384_attention_center_distance": 0.027925864862454026,
      "attention_bam_384_attention_spatial_variance": 166.78506504845825,
      "attention_bam_384_attention_spatial_std": 12.91452922287368,
      "attention_bam_384_num_attention_peaks": 2,
      "attention_bam_384_peak_separation_mean": 13.238685113892183,
      "attention_bam_384_peak_intensity_mean": 0.3306639790534973,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22636672854423523,
      "attention_bam_16_std_attention": 0.4583877921104431,
      "attention_bam_16_max_attention": 2.39776611328125,
      "attention_bam_16_min_attention": -0.929931640625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.43075656883079017,
      "attention_bam_16_attention_skewness": 0.4327970108049155,
      "attention_bam_16_attention_sparsity": 0.39697265625,
      "attention_bam_16_attention_concentration_10": 0.48697026451738584,
      "attention_bam_16_attention_concentration_20": 0.7853089950461718,
      "attention_bam_16_attention_center_y": 0.47365528412482283,
      "attention_bam_16_attention_center_x": 0.47634949471645094,
      "attention_bam_16_attention_center_distance": 0.050067763175740014,
      "attention_bam_16_attention_spatial_variance": 42.843744209403575,
      "attention_bam_16_attention_spatial_std": 6.545513288459781,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.39060198868527,
      "attention_bam_16_peak_intensity_mean": 0.3603288531303406,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 163,
      "phase": "train",
      "loss": 0.01624199002981186,
      "timestamp": 1759561917.994576,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.01624199002981186,
      "ssim": 0.7035906314849854,
      "attention_bam_384_mean_attention": 0.17556023597717285,
      "attention_bam_384_std_attention": 0.5189919471740723,
      "attention_bam_384_max_attention": 4.483642578125,
      "attention_bam_384_min_attention": -1.183837890625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.3474932955672028,
      "attention_bam_384_attention_skewness": 0.959174402805904,
      "attention_bam_384_attention_sparsity": 0.4787089029947917,
      "attention_bam_384_attention_concentration_10": 0.694544373871308,
      "attention_bam_384_attention_concentration_20": 1.0791027989744297,
      "attention_bam_384_attention_center_y": 0.4850458737142974,
      "attention_bam_384_attention_center_x": 0.4917606615029566,
      "attention_bam_384_attention_center_distance": 0.024145914430296574,
      "attention_bam_384_attention_spatial_variance": 169.143684564228,
      "attention_bam_384_attention_spatial_std": 13.005525155264896,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 16.39643327653457,
      "attention_bam_384_peak_intensity_mean": 0.2412732094526291,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20838938653469086,
      "attention_bam_16_std_attention": 0.5426278114318848,
      "attention_bam_16_max_attention": 5.237548828125,
      "attention_bam_16_min_attention": -1.072723388671875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 7.035611842891093,
      "attention_bam_16_attention_skewness": 1.5321205860155573,
      "attention_bam_16_attention_sparsity": 0.46533203125,
      "attention_bam_16_attention_concentration_10": 0.6223775498639077,
      "attention_bam_16_attention_concentration_20": 0.9622545947176372,
      "attention_bam_16_attention_center_y": 0.47814578921945405,
      "attention_bam_16_attention_center_x": 0.46845202050895807,
      "attention_bam_16_attention_center_distance": 0.054274884409047486,
      "attention_bam_16_attention_spatial_variance": 42.898791617505424,
      "attention_bam_16_attention_spatial_std": 6.549716911249327,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.226103932784769,
      "attention_bam_16_peak_intensity_mean": 0.20368090271949768,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 164,
      "phase": "train",
      "loss": 0.015728021040558815,
      "timestamp": 1759561918.1599464,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.015728021040558815,
      "ssim": 0.734546422958374,
      "attention_bam_384_mean_attention": 0.17593270540237427,
      "attention_bam_384_std_attention": 0.5519219040870667,
      "attention_bam_384_max_attention": 3.932098388671875,
      "attention_bam_384_min_attention": -1.302001953125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.1311173805352066,
      "attention_bam_384_attention_skewness": 1.0118529849330973,
      "attention_bam_384_attention_sparsity": 0.48597971598307294,
      "attention_bam_384_attention_concentration_10": 0.7457071910808915,
      "attention_bam_384_attention_concentration_20": 1.1382690401549662,
      "attention_bam_384_attention_center_y": 0.47910587934766014,
      "attention_bam_384_attention_center_x": 0.4948621081446841,
      "attention_bam_384_attention_center_distance": 0.030429006245733903,
      "attention_bam_384_attention_spatial_variance": 172.83465629126135,
      "attention_bam_384_attention_spatial_std": 13.14665951073737,
      "attention_bam_384_num_attention_peaks": 4,
      "attention_bam_384_peak_separation_mean": 18.794784527471922,
      "attention_bam_384_peak_intensity_mean": 0.2837727665901184,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20929878950119019,
      "attention_bam_16_std_attention": 0.5441798567771912,
      "attention_bam_16_max_attention": 4.94171142578125,
      "attention_bam_16_min_attention": -1.0457763671875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 5.3820133019695415,
      "attention_bam_16_attention_skewness": 1.4489623225680694,
      "attention_bam_16_attention_sparsity": 0.44970703125,
      "attention_bam_16_attention_concentration_10": 0.6269634689404237,
      "attention_bam_16_attention_concentration_20": 0.946036125795647,
      "attention_bam_16_attention_center_y": 0.46255678345344814,
      "attention_bam_16_attention_center_x": 0.47398125076775277,
      "attention_bam_16_attention_center_distance": 0.06448208707792483,
      "attention_bam_16_attention_spatial_variance": 43.24880253481512,
      "attention_bam_16_attention_spatial_std": 6.576382176760648,
      "attention_bam_16_num_attention_peaks": 14,
      "attention_bam_16_peak_separation_mean": 9.1509058651576,
      "attention_bam_16_peak_intensity_mean": 0.20994234085083008,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 165,
      "phase": "train",
      "loss": 0.016884807497262955,
      "timestamp": 1759561918.3288097,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.016884807497262955,
      "ssim": 0.6810047030448914,
      "attention_bam_384_mean_attention": 0.17364893853664398,
      "attention_bam_384_std_attention": 0.5004510879516602,
      "attention_bam_384_max_attention": 4.61285400390625,
      "attention_bam_384_min_attention": -1.196044921875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.3716252782920195,
      "attention_bam_384_attention_skewness": 1.0602357875133452,
      "attention_bam_384_attention_sparsity": 0.4668731689453125,
      "attention_bam_384_attention_concentration_10": 0.6683491156844239,
      "attention_bam_384_attention_concentration_20": 1.0349235363647402,
      "attention_bam_384_attention_center_y": 0.47648824584751964,
      "attention_bam_384_attention_center_x": 0.48483770055753617,
      "attention_bam_384_attention_center_distance": 0.03956508328588773,
      "attention_bam_384_attention_spatial_variance": 168.37722114946385,
      "attention_bam_384_attention_spatial_std": 12.976024859311261,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 15.452654219325325,
      "attention_bam_384_peak_intensity_mean": 0.23964770138263702,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18965964019298553,
      "attention_bam_16_std_attention": 0.4954451024532318,
      "attention_bam_16_max_attention": 4.921875,
      "attention_bam_16_min_attention": -0.8919677734375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 13.297985581486124,
      "attention_bam_16_attention_skewness": 2.096762550612575,
      "attention_bam_16_attention_sparsity": 0.44287109375,
      "attention_bam_16_attention_concentration_10": 0.5967232232438939,
      "attention_bam_16_attention_concentration_20": 0.9115120291671305,
      "attention_bam_16_attention_center_y": 0.46146009873393806,
      "attention_bam_16_attention_center_x": 0.4657738625722306,
      "attention_bam_16_attention_center_distance": 0.07289379222982381,
      "attention_bam_16_attention_spatial_variance": 42.522406988811355,
      "attention_bam_16_attention_spatial_std": 6.52092071634147,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.917497056794232,
      "attention_bam_16_peak_intensity_mean": 0.18627408146858215,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 166,
      "phase": "train",
      "loss": 0.015418121591210365,
      "timestamp": 1759561918.4952796,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.015418121591210365,
      "ssim": 0.7103571891784668,
      "attention_bam_384_mean_attention": 0.17533379793167114,
      "attention_bam_384_std_attention": 0.5394157767295837,
      "attention_bam_384_max_attention": 3.5763702392578125,
      "attention_bam_384_min_attention": -1.16357421875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.1097477867988053,
      "attention_bam_384_attention_skewness": 1.0369711926044014,
      "attention_bam_384_attention_sparsity": 0.4760233561197917,
      "attention_bam_384_attention_concentration_10": 0.7323441821430468,
      "attention_bam_384_attention_concentration_20": 1.1112448623706992,
      "attention_bam_384_attention_center_y": 0.48865384033984494,
      "attention_bam_384_attention_center_x": 0.48010577036681623,
      "attention_bam_384_attention_center_distance": 0.032388754583391355,
      "attention_bam_384_attention_spatial_variance": 166.80345450229748,
      "attention_bam_384_attention_spatial_std": 12.915241170891758,
      "attention_bam_384_num_attention_peaks": 2,
      "attention_bam_384_peak_separation_mean": 9.129168985115419,
      "attention_bam_384_peak_intensity_mean": 0.28940632939338684,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20779438316822052,
      "attention_bam_16_std_attention": 0.5239999294281006,
      "attention_bam_16_max_attention": 3.271240234375,
      "attention_bam_16_min_attention": -0.9680938720703125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.873937425101622,
      "attention_bam_16_attention_skewness": 1.2130605136510026,
      "attention_bam_16_attention_sparsity": 0.42919921875,
      "attention_bam_16_attention_concentration_10": 0.5965498002955402,
      "attention_bam_16_attention_concentration_20": 0.9169594929057846,
      "attention_bam_16_attention_center_y": 0.471397359583848,
      "attention_bam_16_attention_center_x": 0.4668524274095648,
      "attention_bam_16_attention_center_distance": 0.061917244890480456,
      "attention_bam_16_attention_spatial_variance": 42.067859654148656,
      "attention_bam_16_attention_spatial_std": 6.485974071344153,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 9.912840672907786,
      "attention_bam_16_peak_intensity_mean": 0.2783140540122986,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 167,
      "phase": "train",
      "loss": 0.014349227771162987,
      "timestamp": 1759561918.6625874,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.014349227771162987,
      "ssim": 0.7078076601028442,
      "attention_bam_384_mean_attention": 0.16992752254009247,
      "attention_bam_384_std_attention": 0.5364859700202942,
      "attention_bam_384_max_attention": 5.0213623046875,
      "attention_bam_384_min_attention": -1.28759765625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 5.792172161397698,
      "attention_bam_384_attention_skewness": 1.4366122321207406,
      "attention_bam_384_attention_sparsity": 0.4880523681640625,
      "attention_bam_384_attention_concentration_10": 0.7348322150160977,
      "attention_bam_384_attention_concentration_20": 1.1154781887236234,
      "attention_bam_384_attention_center_y": 0.4954265302190253,
      "attention_bam_384_attention_center_x": 0.4884100998871982,
      "attention_bam_384_attention_center_distance": 0.01762057947186825,
      "attention_bam_384_attention_spatial_variance": 171.59235851103264,
      "attention_bam_384_attention_spatial_std": 13.099326643420747,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 17.42746097431523,
      "attention_bam_384_peak_intensity_mean": 0.23366451263427734,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19471420347690582,
      "attention_bam_16_std_attention": 0.5876193046569824,
      "attention_bam_16_max_attention": 7.551239013671875,
      "attention_bam_16_min_attention": -1.34228515625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 16.766882095938197,
      "attention_bam_16_attention_skewness": 2.4842185249795667,
      "attention_bam_16_attention_sparsity": 0.466552734375,
      "attention_bam_16_attention_concentration_10": 0.6862605321130703,
      "attention_bam_16_attention_concentration_20": 1.020006812542976,
      "attention_bam_16_attention_center_y": 0.47493404380920234,
      "attention_bam_16_attention_center_x": 0.471198077247424,
      "attention_bam_16_attention_center_distance": 0.05399727611656612,
      "attention_bam_16_attention_spatial_variance": 42.58008871699614,
      "attention_bam_16_attention_spatial_std": 6.525342038314631,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.70306888197574,
      "attention_bam_16_peak_intensity_mean": 0.17484255135059357,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 168,
      "phase": "train",
      "loss": 0.017660735175013542,
      "timestamp": 1759561918.8297992,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.017660735175013542,
      "ssim": 0.7157888412475586,
      "attention_bam_384_mean_attention": 0.165823295712471,
      "attention_bam_384_std_attention": 0.5389087200164795,
      "attention_bam_384_max_attention": 4.5455322265625,
      "attention_bam_384_min_attention": -1.28857421875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.6284731306842515,
      "attention_bam_384_attention_skewness": 1.2489881186127023,
      "attention_bam_384_attention_sparsity": 0.4972330729166667,
      "attention_bam_384_attention_concentration_10": 0.7673334203992037,
      "attention_bam_384_attention_concentration_20": 1.1658412970753627,
      "attention_bam_384_attention_center_y": 0.48232952312519173,
      "attention_bam_384_attention_center_x": 0.47733683911720476,
      "attention_bam_384_attention_center_distance": 0.0406414717790238,
      "attention_bam_384_attention_spatial_variance": 172.0750711269142,
      "attention_bam_384_attention_spatial_std": 13.11773879626036,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 17.411719639176134,
      "attention_bam_384_peak_intensity_mean": 0.2514035999774933,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1913011372089386,
      "attention_bam_16_std_attention": 0.5287376046180725,
      "attention_bam_16_max_attention": 5.439247131347656,
      "attention_bam_16_min_attention": -1.06298828125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 9.99895983383362,
      "attention_bam_16_attention_skewness": 1.9172835427398307,
      "attention_bam_16_attention_sparsity": 0.465576171875,
      "attention_bam_16_attention_concentration_10": 0.6417576504424017,
      "attention_bam_16_attention_concentration_20": 0.9845098949072214,
      "attention_bam_16_attention_center_y": 0.46711674067039893,
      "attention_bam_16_attention_center_x": 0.46168398063943494,
      "attention_bam_16_attention_center_distance": 0.0714062473986274,
      "attention_bam_16_attention_spatial_variance": 43.32033201486092,
      "attention_bam_16_attention_spatial_std": 6.581818290933055,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 10.418196998671503,
      "attention_bam_16_peak_intensity_mean": 0.19768382608890533,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 169,
      "phase": "train",
      "loss": 0.009997907094657421,
      "timestamp": 1759561919.0155268,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.009997907094657421,
      "ssim": 0.7336505651473999,
      "attention_bam_384_mean_attention": 0.18089516460895538,
      "attention_bam_384_std_attention": 0.5009098052978516,
      "attention_bam_384_max_attention": 4.2125244140625,
      "attention_bam_384_min_attention": -1.184326171875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 4.015145268891274,
      "attention_bam_384_attention_skewness": 1.2162823685321908,
      "attention_bam_384_attention_sparsity": 0.4542185465494792,
      "attention_bam_384_attention_concentration_10": 0.6552581553016669,
      "attention_bam_384_attention_concentration_20": 0.9922318587039746,
      "attention_bam_384_attention_center_y": 0.4784038269220548,
      "attention_bam_384_attention_center_x": 0.48718644909293307,
      "attention_bam_384_attention_center_distance": 0.03551286466790762,
      "attention_bam_384_attention_spatial_variance": 171.39489677313233,
      "attention_bam_384_attention_spatial_std": 13.091787378854438,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 19.395838400220164,
      "attention_bam_384_peak_intensity_mean": 0.2601873278617859,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21646206080913544,
      "attention_bam_16_std_attention": 0.5411413908004761,
      "attention_bam_16_max_attention": 5.268218994140625,
      "attention_bam_16_min_attention": -1.0950927734375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 8.15598201247736,
      "attention_bam_16_attention_skewness": 1.731511299043093,
      "attention_bam_16_attention_sparsity": 0.444091796875,
      "attention_bam_16_attention_concentration_10": 0.5841622251865977,
      "attention_bam_16_attention_concentration_20": 0.8945965940957399,
      "attention_bam_16_attention_center_y": 0.4713689834454005,
      "attention_bam_16_attention_center_x": 0.47465197277694027,
      "attention_bam_16_attention_center_distance": 0.05407878684014143,
      "attention_bam_16_attention_spatial_variance": 43.180477567689515,
      "attention_bam_16_attention_spatial_std": 6.571185400495828,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.959034102657572,
      "attention_bam_16_peak_intensity_mean": 0.2091357558965683,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 170,
      "phase": "train",
      "loss": 0.0146073242649436,
      "timestamp": 1759561919.3226125,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0146073242649436,
      "ssim": 0.7431507706642151,
      "attention_bam_384_mean_attention": 0.17618857324123383,
      "attention_bam_384_std_attention": 0.5340849757194519,
      "attention_bam_384_max_attention": 5.004150390625,
      "attention_bam_384_min_attention": -1.3232421875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 5.357634517953027,
      "attention_bam_384_attention_skewness": 1.3957749620429127,
      "attention_bam_384_attention_sparsity": 0.48130035400390625,
      "attention_bam_384_attention_concentration_10": 0.7187318339788006,
      "attention_bam_384_attention_concentration_20": 1.0837103784101503,
      "attention_bam_384_attention_center_y": 0.4795845079299052,
      "attention_bam_384_attention_center_x": 0.49109126824594024,
      "attention_bam_384_attention_center_distance": 0.03150104182181587,
      "attention_bam_384_attention_spatial_variance": 171.85819219931327,
      "attention_bam_384_attention_spatial_std": 13.109469562088059,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 16.26586307731616,
      "attention_bam_384_peak_intensity_mean": 0.2358071357011795,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1889646351337433,
      "attention_bam_16_std_attention": 0.5357888340950012,
      "attention_bam_16_max_attention": 5.585784912109375,
      "attention_bam_16_min_attention": -1.050048828125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 11.938284349696287,
      "attention_bam_16_attention_skewness": 2.0724582725781766,
      "attention_bam_16_attention_sparsity": 0.462890625,
      "attention_bam_16_attention_concentration_10": 0.6620836100467072,
      "attention_bam_16_attention_concentration_20": 1.0011813548775554,
      "attention_bam_16_attention_center_y": 0.4643290789059258,
      "attention_bam_16_attention_center_x": 0.4717483788120921,
      "attention_bam_16_attention_center_distance": 0.06435166993085285,
      "attention_bam_16_attention_spatial_variance": 43.41722534016207,
      "attention_bam_16_attention_spatial_std": 6.589174860341928,
      "attention_bam_16_num_attention_peaks": 11,
      "attention_bam_16_peak_separation_mean": 10.206550223952291,
      "attention_bam_16_peak_intensity_mean": 0.1905498057603836,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 171,
      "phase": "train",
      "loss": 0.013479216955602169,
      "timestamp": 1759561919.493951,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.013479216955602169,
      "ssim": 0.7785229682922363,
      "attention_bam_384_mean_attention": 0.18165546655654907,
      "attention_bam_384_std_attention": 0.44096705317497253,
      "attention_bam_384_max_attention": 3.68359375,
      "attention_bam_384_min_attention": -1.24609375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6942373619630011,
      "attention_bam_384_attention_skewness": 0.43766765925510065,
      "attention_bam_384_attention_sparsity": 0.4440714518229167,
      "attention_bam_384_attention_concentration_10": 0.5584427856924814,
      "attention_bam_384_attention_concentration_20": 0.9084146604090878,
      "attention_bam_384_attention_center_y": 0.47475113642616323,
      "attention_bam_384_attention_center_x": 0.4823801327609137,
      "attention_bam_384_attention_center_distance": 0.043542274476495786,
      "attention_bam_384_attention_spatial_variance": 170.51174126887005,
      "attention_bam_384_attention_spatial_std": 13.05801444588227,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 10.601029168771166,
      "attention_bam_384_peak_intensity_mean": 0.29269132018089294,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24746659398078918,
      "attention_bam_16_std_attention": 0.44957923889160156,
      "attention_bam_16_max_attention": 2.112335205078125,
      "attention_bam_16_min_attention": -0.99609375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5409501794992662,
      "attention_bam_16_attention_skewness": 0.38722125689153686,
      "attention_bam_16_attention_sparsity": 0.370849609375,
      "attention_bam_16_attention_concentration_10": 0.4410882097976367,
      "attention_bam_16_attention_concentration_20": 0.7230527454222292,
      "attention_bam_16_attention_center_y": 0.4552862900118193,
      "attention_bam_16_attention_center_x": 0.47076355683397114,
      "attention_bam_16_attention_center_distance": 0.07555243834460361,
      "attention_bam_16_attention_spatial_variance": 43.20003636474103,
      "attention_bam_16_attention_spatial_std": 6.572673456420989,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 11.693288463923585,
      "attention_bam_16_peak_intensity_mean": 0.41579166054725647,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 172,
      "phase": "train",
      "loss": 0.016048740595579147,
      "timestamp": 1759561919.665566,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.016048740595579147,
      "ssim": 0.7463644742965698,
      "attention_bam_384_mean_attention": 0.18309801816940308,
      "attention_bam_384_std_attention": 0.5426387786865234,
      "attention_bam_384_max_attention": 4.5341796875,
      "attention_bam_384_min_attention": -1.2318115234375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 4.432946315160822,
      "attention_bam_384_attention_skewness": 1.1766114715300198,
      "attention_bam_384_attention_sparsity": 0.4661712646484375,
      "attention_bam_384_attention_concentration_10": 0.6844017090538216,
      "attention_bam_384_attention_concentration_20": 1.0581474398099582,
      "attention_bam_384_attention_center_y": 0.48249743858773364,
      "attention_bam_384_attention_center_x": 0.48638233808647857,
      "attention_bam_384_attention_center_distance": 0.03136177201566032,
      "attention_bam_384_attention_spatial_variance": 168.86460379786033,
      "attention_bam_384_attention_spatial_std": 12.994791410325151,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 16.873071823689486,
      "attention_bam_384_peak_intensity_mean": 0.24501268565654755,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20121407508850098,
      "attention_bam_16_std_attention": 0.5683653950691223,
      "attention_bam_16_max_attention": 5.4122314453125,
      "attention_bam_16_min_attention": -1.2298583984375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 8.53599004812609,
      "attention_bam_16_attention_skewness": 1.6209176609042923,
      "attention_bam_16_attention_sparsity": 0.470947265625,
      "attention_bam_16_attention_concentration_10": 0.6483440132250978,
      "attention_bam_16_attention_concentration_20": 1.0067190501007652,
      "attention_bam_16_attention_center_y": 0.4670792729931516,
      "attention_bam_16_attention_center_x": 0.47405204728552885,
      "attention_bam_16_attention_center_distance": 0.05928019090272681,
      "attention_bam_16_attention_spatial_variance": 43.29229628706711,
      "attention_bam_16_attention_spatial_std": 6.579688160320906,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 10.396928484327645,
      "attention_bam_16_peak_intensity_mean": 0.21817485988140106,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 173,
      "phase": "train",
      "loss": 0.012872293591499329,
      "timestamp": 1759561919.8465772,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.012872293591499329,
      "ssim": 0.7458649277687073,
      "attention_bam_384_mean_attention": 0.17897886037826538,
      "attention_bam_384_std_attention": 0.49119946360588074,
      "attention_bam_384_max_attention": 3.1429443359375,
      "attention_bam_384_min_attention": -1.222412109375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9280674140793299,
      "attention_bam_384_attention_skewness": 0.6175231565760385,
      "attention_bam_384_attention_sparsity": 0.46322886149088544,
      "attention_bam_384_attention_concentration_10": 0.6316344780219035,
      "attention_bam_384_attention_concentration_20": 1.005339075592469,
      "attention_bam_384_attention_center_y": 0.4863292847111396,
      "attention_bam_384_attention_center_x": 0.48282496973195405,
      "attention_bam_384_attention_center_distance": 0.031044165996765818,
      "attention_bam_384_attention_spatial_variance": 169.81455534619326,
      "attention_bam_384_attention_spatial_std": 13.031291392114339,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 18.687202761056472,
      "attention_bam_384_peak_intensity_mean": 0.32759666442871094,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2215123474597931,
      "attention_bam_16_std_attention": 0.5586497783660889,
      "attention_bam_16_max_attention": 3.611968994140625,
      "attention_bam_16_min_attention": -1.06024169921875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.4411337142122402,
      "attention_bam_16_attention_skewness": 0.7503143934183034,
      "attention_bam_16_attention_sparsity": 0.4482421875,
      "attention_bam_16_attention_concentration_10": 0.5869886680734975,
      "attention_bam_16_attention_concentration_20": 0.9383722327157347,
      "attention_bam_16_attention_center_y": 0.4721082965899256,
      "attention_bam_16_attention_center_x": 0.4681585963272528,
      "attention_bam_16_attention_center_distance": 0.059863546620065766,
      "attention_bam_16_attention_spatial_variance": 42.856424249177635,
      "attention_bam_16_attention_spatial_std": 6.546481822259773,
      "attention_bam_16_num_attention_peaks": 15,
      "attention_bam_16_peak_separation_mean": 9.405713752768046,
      "attention_bam_16_peak_intensity_mean": 0.2802779972553253,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 174,
      "phase": "train",
      "loss": 0.011655817739665508,
      "timestamp": 1759561920.045157,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.011655817739665508,
      "ssim": 0.7276219129562378,
      "attention_bam_384_mean_attention": 0.1766635626554489,
      "attention_bam_384_std_attention": 0.5117093324661255,
      "attention_bam_384_max_attention": 4.618896484375,
      "attention_bam_384_min_attention": -1.26318359375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 4.455096210913232,
      "attention_bam_384_attention_skewness": 1.1842065120792673,
      "attention_bam_384_attention_sparsity": 0.46465810139973956,
      "attention_bam_384_attention_concentration_10": 0.6680113561216561,
      "attention_bam_384_attention_concentration_20": 1.0356108031607072,
      "attention_bam_384_attention_center_y": 0.4773558614482488,
      "attention_bam_384_attention_center_x": 0.4859735314108796,
      "attention_bam_384_attention_center_distance": 0.0376695853927936,
      "attention_bam_384_attention_spatial_variance": 169.72812062715292,
      "attention_bam_384_attention_spatial_std": 13.027974540470707,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 15.060660673251377,
      "attention_bam_384_peak_intensity_mean": 0.24829410016536713,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19019870460033417,
      "attention_bam_16_std_attention": 0.552241861820221,
      "attention_bam_16_max_attention": 6.59954833984375,
      "attention_bam_16_min_attention": -1.147705078125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 15.11793632279944,
      "attention_bam_16_attention_skewness": 2.2557417863645277,
      "attention_bam_16_attention_sparsity": 0.458251953125,
      "attention_bam_16_attention_concentration_10": 0.6620182091464714,
      "attention_bam_16_attention_concentration_20": 1.0072034521285953,
      "attention_bam_16_attention_center_y": 0.46456208931430554,
      "attention_bam_16_attention_center_x": 0.4696455895255284,
      "attention_bam_16_attention_center_distance": 0.06598841942371358,
      "attention_bam_16_attention_spatial_variance": 42.5180893358631,
      "attention_bam_16_attention_spatial_std": 6.520589646332845,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 9.022248348028432,
      "attention_bam_16_peak_intensity_mean": 0.17556680738925934,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 175,
      "phase": "train",
      "loss": 0.01649545505642891,
      "timestamp": 1759561920.2152948,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.01649545505642891,
      "ssim": 0.7901754975318909,
      "attention_bam_384_mean_attention": 0.16738824546337128,
      "attention_bam_384_std_attention": 0.5302605628967285,
      "attention_bam_384_max_attention": 3.9832687377929688,
      "attention_bam_384_min_attention": -1.261474609375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.6670734148193924,
      "attention_bam_384_attention_skewness": 1.0646338325747893,
      "attention_bam_384_attention_sparsity": 0.4922129313151042,
      "attention_bam_384_attention_concentration_10": 0.7398904750022793,
      "attention_bam_384_attention_concentration_20": 1.1400406365585336,
      "attention_bam_384_attention_center_y": 0.47223453646171726,
      "attention_bam_384_attention_center_x": 0.49260043887465954,
      "attention_bam_384_attention_center_distance": 0.040636792942931856,
      "attention_bam_384_attention_spatial_variance": 173.07570888835286,
      "attention_bam_384_attention_spatial_std": 13.155824143258865,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 14.923982160821861,
      "attention_bam_384_peak_intensity_mean": 0.27725785970687866,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18458111584186554,
      "attention_bam_16_std_attention": 0.5004613399505615,
      "attention_bam_16_max_attention": 4.55059814453125,
      "attention_bam_16_min_attention": -0.9443359375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 7.824287099208176,
      "attention_bam_16_attention_skewness": 1.6814081075189022,
      "attention_bam_16_attention_sparsity": 0.458251953125,
      "attention_bam_16_attention_concentration_10": 0.6304375730368201,
      "attention_bam_16_attention_concentration_20": 0.9638184426501373,
      "attention_bam_16_attention_center_y": 0.4605799725704521,
      "attention_bam_16_attention_center_x": 0.47888538686536114,
      "attention_bam_16_attention_center_distance": 0.06324184453938347,
      "attention_bam_16_attention_spatial_variance": 43.30893596259934,
      "attention_bam_16_attention_spatial_std": 6.580952511802478,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 10.316192516970586,
      "attention_bam_16_peak_intensity_mean": 0.20882534980773926,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 176,
      "phase": "train",
      "loss": 0.010783652774989605,
      "timestamp": 1759561920.3921285,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.010783652774989605,
      "ssim": 0.7418227791786194,
      "attention_bam_384_mean_attention": 0.17873717844486237,
      "attention_bam_384_std_attention": 0.5056900382041931,
      "attention_bam_384_max_attention": 3.7476806640625,
      "attention_bam_384_min_attention": -1.273193359375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.312642276638144,
      "attention_bam_384_attention_skewness": 0.8271015380709537,
      "attention_bam_384_attention_sparsity": 0.4661153157552083,
      "attention_bam_384_attention_concentration_10": 0.6480516581727436,
      "attention_bam_384_attention_concentration_20": 1.0269207772178977,
      "attention_bam_384_attention_center_y": 0.4829872900103456,
      "attention_bam_384_attention_center_x": 0.47946594410120313,
      "attention_bam_384_attention_center_distance": 0.037711530142570455,
      "attention_bam_384_attention_spatial_variance": 168.7055845120538,
      "attention_bam_384_attention_spatial_std": 12.988671391333826,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 15.12163268597269,
      "attention_bam_384_peak_intensity_mean": 0.2902607023715973,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20645672082901,
      "attention_bam_16_std_attention": 0.5530605316162109,
      "attention_bam_16_max_attention": 6.11566162109375,
      "attention_bam_16_min_attention": -0.96331787109375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 10.269034586287397,
      "attention_bam_16_attention_skewness": 1.714801113036045,
      "attention_bam_16_attention_sparsity": 0.4609375,
      "attention_bam_16_attention_concentration_10": 0.6118520028255171,
      "attention_bam_16_attention_concentration_20": 0.9635196515589043,
      "attention_bam_16_attention_center_y": 0.4652061423263981,
      "attention_bam_16_attention_center_x": 0.46376335159530335,
      "attention_bam_16_attention_center_distance": 0.07104515774374026,
      "attention_bam_16_attention_spatial_variance": 42.83783158834349,
      "attention_bam_16_attention_spatial_std": 6.545061618376368,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 9.088721461269488,
      "attention_bam_16_peak_intensity_mean": 0.16624580323696136,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 177,
      "phase": "train",
      "loss": 0.014931309036910534,
      "timestamp": 1759561920.5660343,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.014931309036910534,
      "ssim": 0.7335267663002014,
      "attention_bam_384_mean_attention": 0.16957759857177734,
      "attention_bam_384_std_attention": 0.5485760569572449,
      "attention_bam_384_max_attention": 3.7183837890625,
      "attention_bam_384_min_attention": -1.199951171875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.86889335884646,
      "attention_bam_384_attention_skewness": 0.9706638210245044,
      "attention_bam_384_attention_sparsity": 0.4925384521484375,
      "attention_bam_384_attention_concentration_10": 0.7638876782047613,
      "attention_bam_384_attention_concentration_20": 1.171751305195299,
      "attention_bam_384_attention_center_y": 0.4759685815691377,
      "attention_bam_384_attention_center_x": 0.481663684776037,
      "attention_bam_384_attention_center_distance": 0.04274879010666212,
      "attention_bam_384_attention_spatial_variance": 173.59584484745034,
      "attention_bam_384_attention_spatial_std": 13.17557759065804,
      "attention_bam_384_num_attention_peaks": 3,
      "attention_bam_384_peak_separation_mean": 25.060063516891244,
      "attention_bam_384_peak_intensity_mean": 0.2838728427886963,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18280206620693207,
      "attention_bam_16_std_attention": 0.528639554977417,
      "attention_bam_16_max_attention": 4.739799499511719,
      "attention_bam_16_min_attention": -1.0767822265625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 6.02529548526741,
      "attention_bam_16_attention_skewness": 1.3353503337229715,
      "attention_bam_16_attention_sparsity": 0.46142578125,
      "attention_bam_16_attention_concentration_10": 0.659857124903324,
      "attention_bam_16_attention_concentration_20": 1.024233758413676,
      "attention_bam_16_attention_center_y": 0.4627869851782417,
      "attention_bam_16_attention_center_x": 0.4662519947020622,
      "attention_bam_16_attention_center_distance": 0.0710455675424448,
      "attention_bam_16_attention_spatial_variance": 43.14236289632762,
      "attention_bam_16_attention_spatial_std": 6.568284623577728,
      "attention_bam_16_num_attention_peaks": 13,
      "attention_bam_16_peak_separation_mean": 10.712027276811199,
      "attention_bam_16_peak_intensity_mean": 0.22105029225349426,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 178,
      "phase": "train",
      "loss": 0.014315667562186718,
      "timestamp": 1759561920.7437067,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.014315667562186718,
      "ssim": 0.7433826923370361,
      "attention_bam_384_mean_attention": 0.17046232521533966,
      "attention_bam_384_std_attention": 0.5588610172271729,
      "attention_bam_384_max_attention": 3.961456298828125,
      "attention_bam_384_min_attention": -1.291748046875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.4733330415498935,
      "attention_bam_384_attention_skewness": 1.0507405672785524,
      "attention_bam_384_attention_sparsity": 0.4970296223958333,
      "attention_bam_384_attention_concentration_10": 0.7698727220806227,
      "attention_bam_384_attention_concentration_20": 1.1847801483741742,
      "attention_bam_384_attention_center_y": 0.47948588803659975,
      "attention_bam_384_attention_center_x": 0.4842932310889908,
      "attention_bam_384_attention_center_distance": 0.036538510622924035,
      "attention_bam_384_attention_spatial_variance": 169.0520352341921,
      "attention_bam_384_attention_spatial_std": 13.002001201130236,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 16.102923211903047,
      "attention_bam_384_peak_intensity_mean": 0.28091368079185486,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18499356508255005,
      "attention_bam_16_std_attention": 0.557996928691864,
      "attention_bam_16_max_attention": 4.4572601318359375,
      "attention_bam_16_min_attention": -0.9398193359375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 5.358595498796266,
      "attention_bam_16_attention_skewness": 1.4615619386089895,
      "attention_bam_16_attention_sparsity": 0.476318359375,
      "attention_bam_16_attention_concentration_10": 0.7130787127561251,
      "attention_bam_16_attention_concentration_20": 1.0859445908693204,
      "attention_bam_16_attention_center_y": 0.46556821292232814,
      "attention_bam_16_attention_center_x": 0.46289255368717896,
      "attention_bam_16_attention_center_distance": 0.0715892524506441,
      "attention_bam_16_attention_spatial_variance": 43.12402860613385,
      "attention_bam_16_attention_spatial_std": 6.566888807200397,
      "attention_bam_16_num_attention_peaks": 13,
      "attention_bam_16_peak_separation_mean": 10.700690333396835,
      "attention_bam_16_peak_intensity_mean": 0.21599771082401276,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 179,
      "phase": "train",
      "loss": 0.00944580789655447,
      "timestamp": 1759561920.9195106,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00944580789655447,
      "ssim": 0.7559926509857178,
      "attention_bam_384_mean_attention": 0.17246133089065552,
      "attention_bam_384_std_attention": 0.49380868673324585,
      "attention_bam_384_max_attention": 4.0323333740234375,
      "attention_bam_384_min_attention": -1.2275390625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.4784696208568375,
      "attention_bam_384_attention_skewness": 1.146396890628003,
      "attention_bam_384_attention_sparsity": 0.46728261311848956,
      "attention_bam_384_attention_concentration_10": 0.6774520541600103,
      "attention_bam_384_attention_concentration_20": 1.0300753560115266,
      "attention_bam_384_attention_center_y": 0.4797066468495286,
      "attention_bam_384_attention_center_x": 0.48942807787904996,
      "attention_bam_384_attention_center_distance": 0.03236002841226136,
      "attention_bam_384_attention_spatial_variance": 170.29477017279848,
      "attention_bam_384_attention_spatial_std": 13.04970383467757,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 16.365504588919965,
      "attention_bam_384_peak_intensity_mean": 0.26766106486320496,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19972124695777893,
      "attention_bam_16_std_attention": 0.5283649563789368,
      "attention_bam_16_max_attention": 4.41986083984375,
      "attention_bam_16_min_attention": -0.90386962890625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 7.551461535514861,
      "attention_bam_16_attention_skewness": 1.7349294924372212,
      "attention_bam_16_attention_sparsity": 0.446533203125,
      "attention_bam_16_attention_concentration_10": 0.6145155891867814,
      "attention_bam_16_attention_concentration_20": 0.9280566103194557,
      "attention_bam_16_attention_center_y": 0.463719616434335,
      "attention_bam_16_attention_center_x": 0.47084969047089176,
      "attention_bam_16_attention_center_distance": 0.06581803365817901,
      "attention_bam_16_attention_spatial_variance": 42.87177879202056,
      "attention_bam_16_attention_spatial_std": 6.547654449649932,
      "attention_bam_16_num_attention_peaks": 11,
      "attention_bam_16_peak_separation_mean": 9.305480284226856,
      "attention_bam_16_peak_intensity_mean": 0.20938153564929962,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 180,
      "phase": "train",
      "loss": 0.010936329141259193,
      "timestamp": 1759561921.2550697,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.010936329141259193,
      "ssim": 0.7646704912185669,
      "attention_bam_384_mean_attention": 0.17561854422092438,
      "attention_bam_384_std_attention": 0.4803912043571472,
      "attention_bam_384_max_attention": 3.5816650390625,
      "attention_bam_384_min_attention": -1.2315673828125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2387399321332193,
      "attention_bam_384_attention_skewness": 0.6168582471864166,
      "attention_bam_384_attention_sparsity": 0.46205393473307294,
      "attention_bam_384_attention_concentration_10": 0.6246409872599139,
      "attention_bam_384_attention_concentration_20": 0.997309589326728,
      "attention_bam_384_attention_center_y": 0.47911438221435315,
      "attention_bam_384_attention_center_x": 0.4856653106725418,
      "attention_bam_384_attention_center_distance": 0.03582435898666915,
      "attention_bam_384_attention_spatial_variance": 170.05778663053036,
      "attention_bam_384_attention_spatial_std": 13.040620638241508,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 17.900172136330383,
      "attention_bam_384_peak_intensity_mean": 0.2934465706348419,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22681915760040283,
      "attention_bam_16_std_attention": 0.49045974016189575,
      "attention_bam_16_max_attention": 3.93402099609375,
      "attention_bam_16_min_attention": -1.142578125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.297962576436685,
      "attention_bam_16_attention_skewness": 0.8995577831373299,
      "attention_bam_16_attention_sparsity": 0.4169921875,
      "attention_bam_16_attention_concentration_10": 0.5076984800993549,
      "attention_bam_16_attention_concentration_20": 0.8199857885849438,
      "attention_bam_16_attention_center_y": 0.4667022208151488,
      "attention_bam_16_attention_center_x": 0.4688175714325401,
      "attention_bam_16_attention_center_distance": 0.06451489672948178,
      "attention_bam_16_attention_spatial_variance": 42.49635068971408,
      "attention_bam_16_attention_spatial_std": 6.518922509871864,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 8.63217220478299,
      "attention_bam_16_peak_intensity_mean": 0.2747439742088318,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 181,
      "phase": "train",
      "loss": 0.010385442525148392,
      "timestamp": 1759561921.445261,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.010385442525148392,
      "ssim": 0.7898509502410889,
      "attention_bam_384_mean_attention": 0.18234343826770782,
      "attention_bam_384_std_attention": 0.4948757290840149,
      "attention_bam_384_max_attention": 3.286376953125,
      "attention_bam_384_min_attention": -1.27587890625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8091158031443615,
      "attention_bam_384_attention_skewness": 0.493987712789485,
      "attention_bam_384_attention_sparsity": 0.45213572184244794,
      "attention_bam_384_attention_concentration_10": 0.6155633481613054,
      "attention_bam_384_attention_concentration_20": 0.9880026969877391,
      "attention_bam_384_attention_center_y": 0.48358898765243474,
      "attention_bam_384_attention_center_x": 0.4807362274711802,
      "attention_bam_384_attention_center_distance": 0.03578866463879452,
      "attention_bam_384_attention_spatial_variance": 170.18441205435312,
      "attention_bam_384_attention_spatial_std": 13.045474773052652,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 17.7262784590773,
      "attention_bam_384_peak_intensity_mean": 0.32078057527542114,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22268888354301453,
      "attention_bam_16_std_attention": 0.5485295653343201,
      "attention_bam_16_max_attention": 4.4071197509765625,
      "attention_bam_16_min_attention": -0.9677734375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.2331951712735796,
      "attention_bam_16_attention_skewness": 0.9929893908297343,
      "attention_bam_16_attention_sparsity": 0.452880859375,
      "attention_bam_16_attention_concentration_10": 0.5780378038583618,
      "attention_bam_16_attention_concentration_20": 0.9287862247678246,
      "attention_bam_16_attention_center_y": 0.46613511143573044,
      "attention_bam_16_attention_center_x": 0.46557326869630483,
      "attention_bam_16_attention_center_distance": 0.06829393100015871,
      "attention_bam_16_attention_spatial_variance": 43.548268468225245,
      "attention_bam_16_attention_spatial_std": 6.599111187745304,
      "attention_bam_16_num_attention_peaks": 13,
      "attention_bam_16_peak_separation_mean": 9.939181098081239,
      "attention_bam_16_peak_intensity_mean": 0.22671324014663696,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 182,
      "phase": "train",
      "loss": 0.014593115076422691,
      "timestamp": 1759561921.6210532,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.014593115076422691,
      "ssim": 0.8256409764289856,
      "attention_bam_384_mean_attention": 0.1809113770723343,
      "attention_bam_384_std_attention": 0.46954452991485596,
      "attention_bam_384_max_attention": 2.81640625,
      "attention_bam_384_min_attention": -1.1766357421875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.23047599001798558,
      "attention_bam_384_attention_skewness": 0.4143934351591384,
      "attention_bam_384_attention_sparsity": 0.45829010009765625,
      "attention_bam_384_attention_concentration_10": 0.5905827071962171,
      "attention_bam_384_attention_concentration_20": 0.9585119786046047,
      "attention_bam_384_attention_center_y": 0.48798267474085133,
      "attention_bam_384_attention_center_x": 0.47929301771746646,
      "attention_bam_384_attention_center_distance": 0.03385838807838703,
      "attention_bam_384_attention_spatial_variance": 167.6886193333224,
      "attention_bam_384_attention_spatial_std": 12.949464055833447,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 13.992233700214156,
      "attention_bam_384_peak_intensity_mean": 0.34905195236206055,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20216740667819977,
      "attention_bam_16_std_attention": 0.48089316487312317,
      "attention_bam_16_max_attention": 3.2563323974609375,
      "attention_bam_16_min_attention": -0.90045166015625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.8754324481721163,
      "attention_bam_16_attention_skewness": 0.806377586441436,
      "attention_bam_16_attention_sparsity": 0.456298828125,
      "attention_bam_16_attention_concentration_10": 0.5601009049314235,
      "attention_bam_16_attention_concentration_20": 0.9023907246951497,
      "attention_bam_16_attention_center_y": 0.4711027176214789,
      "attention_bam_16_attention_center_x": 0.4643011421471689,
      "attention_bam_16_attention_center_distance": 0.06495323519056813,
      "attention_bam_16_attention_spatial_variance": 42.413659129142886,
      "attention_bam_16_attention_spatial_std": 6.512576996024146,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 8.950021653341093,
      "attention_bam_16_peak_intensity_mean": 0.2703860104084015,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 183,
      "phase": "train",
      "loss": 0.016818363219499588,
      "timestamp": 1759561921.8208792,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.016818363219499588,
      "ssim": 0.8131885528564453,
      "attention_bam_384_mean_attention": 0.1768607646226883,
      "attention_bam_384_std_attention": 0.5447826385498047,
      "attention_bam_384_max_attention": 3.749420166015625,
      "attention_bam_384_min_attention": -1.322265625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.7512366460191364,
      "attention_bam_384_attention_skewness": 0.8639959220946613,
      "attention_bam_384_attention_sparsity": 0.47927602132161456,
      "attention_bam_384_attention_concentration_10": 0.718660178613091,
      "attention_bam_384_attention_concentration_20": 1.1131868833054221,
      "attention_bam_384_attention_center_y": 0.4777521500570892,
      "attention_bam_384_attention_center_x": 0.4904059707830319,
      "attention_bam_384_attention_center_distance": 0.034264040149938925,
      "attention_bam_384_attention_spatial_variance": 172.06348477974453,
      "attention_bam_384_attention_spatial_std": 13.117297159847547,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 13.680191639577467,
      "attention_bam_384_peak_intensity_mean": 0.29747089743614197,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21202054619789124,
      "attention_bam_16_std_attention": 0.5704362392425537,
      "attention_bam_16_max_attention": 3.8081207275390625,
      "attention_bam_16_min_attention": -1.17138671875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.9057216742558376,
      "attention_bam_16_attention_skewness": 1.327260583203575,
      "attention_bam_16_attention_sparsity": 0.47607421875,
      "attention_bam_16_attention_concentration_10": 0.6550045690047849,
      "attention_bam_16_attention_concentration_20": 1.0035026283126103,
      "attention_bam_16_attention_center_y": 0.4619855737219123,
      "attention_bam_16_attention_center_x": 0.4749441330113619,
      "attention_bam_16_attention_center_distance": 0.064387779520721,
      "attention_bam_16_attention_spatial_variance": 43.596231424879846,
      "attention_bam_16_attention_spatial_std": 6.602744234398289,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 10.762097433365374,
      "attention_bam_16_peak_intensity_mean": 0.29765480756759644,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 184,
      "phase": "train",
      "loss": 0.011105346493422985,
      "timestamp": 1759561922.0335517,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.011105346493422985,
      "ssim": 0.815241813659668,
      "attention_bam_384_mean_attention": 0.17250806093215942,
      "attention_bam_384_std_attention": 0.5362108945846558,
      "attention_bam_384_max_attention": 3.86181640625,
      "attention_bam_384_min_attention": -1.230712890625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.3281074799027968,
      "attention_bam_384_attention_skewness": 0.9735684184795564,
      "attention_bam_384_attention_sparsity": 0.4845123291015625,
      "attention_bam_384_attention_concentration_10": 0.727302949629699,
      "attention_bam_384_attention_concentration_20": 1.1212903025181429,
      "attention_bam_384_attention_center_y": 0.4913192415748051,
      "attention_bam_384_attention_center_x": 0.48243208827218725,
      "attention_bam_384_attention_center_distance": 0.027712347042890922,
      "attention_bam_384_attention_spatial_variance": 170.9421157732018,
      "attention_bam_384_attention_spatial_std": 13.074483384562535,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 12.199035785761488,
      "attention_bam_384_peak_intensity_mean": 0.2761722505092621,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20991528034210205,
      "attention_bam_16_std_attention": 0.5709279775619507,
      "attention_bam_16_max_attention": 5.388458251953125,
      "attention_bam_16_min_attention": -1.177001953125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 7.647986417946164,
      "attention_bam_16_attention_skewness": 1.6522569873620652,
      "attention_bam_16_attention_sparsity": 0.44384765625,
      "attention_bam_16_attention_concentration_10": 0.6431087394588264,
      "attention_bam_16_attention_concentration_20": 0.9716811942891037,
      "attention_bam_16_attention_center_y": 0.47857855675282,
      "attention_bam_16_attention_center_x": 0.4701990514946854,
      "attention_bam_16_attention_center_distance": 0.051903270852780875,
      "attention_bam_16_attention_spatial_variance": 43.84925629281393,
      "attention_bam_16_attention_spatial_std": 6.621877097380615,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 10.28437962795344,
      "attention_bam_16_peak_intensity_mean": 0.2183329164981842,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 185,
      "phase": "train",
      "loss": 0.009322620928287506,
      "timestamp": 1759561922.213984,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.009322620928287506,
      "ssim": 0.8100578188896179,
      "attention_bam_384_mean_attention": 0.17530713975429535,
      "attention_bam_384_std_attention": 0.5052855610847473,
      "attention_bam_384_max_attention": 3.2392578125,
      "attention_bam_384_min_attention": -1.417236328125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.2683505195372393,
      "attention_bam_384_attention_skewness": 0.44706462254947643,
      "attention_bam_384_attention_sparsity": 0.4636688232421875,
      "attention_bam_384_attention_concentration_10": 0.6538871719454501,
      "attention_bam_384_attention_concentration_20": 1.049181860661216,
      "attention_bam_384_attention_center_y": 0.47931975047093456,
      "attention_bam_384_attention_center_x": 0.48521477656064615,
      "attention_bam_384_attention_center_distance": 0.035952066776084785,
      "attention_bam_384_attention_spatial_variance": 170.36512408485876,
      "attention_bam_384_attention_spatial_std": 13.052399169687494,
      "attention_bam_384_num_attention_peaks": 20,
      "attention_bam_384_peak_separation_mean": 18.997711894938785,
      "attention_bam_384_peak_intensity_mean": 0.3413492441177368,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22425585985183716,
      "attention_bam_16_std_attention": 0.5568615198135376,
      "attention_bam_16_max_attention": 3.4052734375,
      "attention_bam_16_min_attention": -1.195556640625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8296265046765239,
      "attention_bam_16_attention_skewness": 0.5525841558595118,
      "attention_bam_16_attention_sparsity": 0.4296875,
      "attention_bam_16_attention_concentration_10": 0.5714664273089765,
      "attention_bam_16_attention_concentration_20": 0.9259026644937765,
      "attention_bam_16_attention_center_y": 0.45874284825742484,
      "attention_bam_16_attention_center_x": 0.47224477271572657,
      "attention_bam_16_attention_center_distance": 0.07032076807759637,
      "attention_bam_16_attention_spatial_variance": 43.07959412493874,
      "attention_bam_16_attention_spatial_std": 6.563504713561097,
      "attention_bam_16_num_attention_peaks": 15,
      "attention_bam_16_peak_separation_mean": 9.051281917402255,
      "attention_bam_16_peak_intensity_mean": 0.3151805102825165,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 186,
      "phase": "train",
      "loss": 0.012118244543671608,
      "timestamp": 1759561922.3864005,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.012118244543671608,
      "ssim": 0.730341911315918,
      "attention_bam_384_mean_attention": 0.1766536980867386,
      "attention_bam_384_std_attention": 0.5119911432266235,
      "attention_bam_384_max_attention": 4.0460205078125,
      "attention_bam_384_min_attention": -1.2642822265625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.7472414197806936,
      "attention_bam_384_attention_skewness": 1.1856641973166322,
      "attention_bam_384_attention_sparsity": 0.4712626139322917,
      "attention_bam_384_attention_concentration_10": 0.6845843879254986,
      "attention_bam_384_attention_concentration_20": 1.0418910815008997,
      "attention_bam_384_attention_center_y": 0.4795471603029324,
      "attention_bam_384_attention_center_x": 0.4837512626076321,
      "attention_bam_384_attention_center_distance": 0.036941578702596865,
      "attention_bam_384_attention_spatial_variance": 171.4404957335642,
      "attention_bam_384_attention_spatial_std": 13.093528773159823,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 17.29211182536153,
      "attention_bam_384_peak_intensity_mean": 0.27485159039497375,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18318378925323486,
      "attention_bam_16_std_attention": 0.5283821225166321,
      "attention_bam_16_max_attention": 5.61883544921875,
      "attention_bam_16_min_attention": -1.140380859375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 13.865733637555849,
      "attention_bam_16_attention_skewness": 2.24216953682764,
      "attention_bam_16_attention_sparsity": 0.4833984375,
      "attention_bam_16_attention_concentration_10": 0.6702422043346521,
      "attention_bam_16_attention_concentration_20": 1.0146854502854048,
      "attention_bam_16_attention_center_y": 0.46390934878265344,
      "attention_bam_16_attention_center_x": 0.4696725607103375,
      "attention_bam_16_attention_center_distance": 0.06666766351328539,
      "attention_bam_16_attention_spatial_variance": 43.11080353773583,
      "attention_bam_16_attention_spatial_std": 6.565881779147096,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 9.20858350989255,
      "attention_bam_16_peak_intensity_mean": 0.1950259506702423,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 187,
      "phase": "train",
      "loss": 0.007221642881631851,
      "timestamp": 1759561922.5592797,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007221642881631851,
      "ssim": 0.8092216849327087,
      "attention_bam_384_mean_attention": 0.16169537603855133,
      "attention_bam_384_std_attention": 0.5467307567596436,
      "attention_bam_384_max_attention": 5.16522216796875,
      "attention_bam_384_min_attention": -1.20654296875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 6.2610834363309475,
      "attention_bam_384_attention_skewness": 1.5183074874782023,
      "attention_bam_384_attention_sparsity": 0.4964650472005208,
      "attention_bam_384_attention_concentration_10": 0.7794847755606606,
      "attention_bam_384_attention_concentration_20": 1.1815883844417097,
      "attention_bam_384_attention_center_y": 0.4839587522116962,
      "attention_bam_384_attention_center_x": 0.48898258880574147,
      "attention_bam_384_attention_center_distance": 0.02752108210187726,
      "attention_bam_384_attention_spatial_variance": 171.77421419929087,
      "attention_bam_384_attention_spatial_std": 13.106266218847031,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 20.265473555939195,
      "attention_bam_384_peak_intensity_mean": 0.21508972346782684,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18301671743392944,
      "attention_bam_16_std_attention": 0.5678043365478516,
      "attention_bam_16_max_attention": 7.5982666015625,
      "attention_bam_16_min_attention": -0.999755859375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 20.237922412209173,
      "attention_bam_16_attention_skewness": 2.761977586394018,
      "attention_bam_16_attention_sparsity": 0.471435546875,
      "attention_bam_16_attention_concentration_10": 0.6985537586321584,
      "attention_bam_16_attention_concentration_20": 1.0398445079523924,
      "attention_bam_16_attention_center_y": 0.4727828355293719,
      "attention_bam_16_attention_center_x": 0.47638686361626015,
      "attention_bam_16_attention_center_distance": 0.05095790913485991,
      "attention_bam_16_attention_spatial_variance": 42.26380188461677,
      "attention_bam_16_attention_spatial_std": 6.501061596740702,
      "attention_bam_16_num_attention_peaks": 14,
      "attention_bam_16_peak_separation_mean": 7.721010931585402,
      "attention_bam_16_peak_intensity_mean": 0.13868702948093414,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 188,
      "phase": "train",
      "loss": 0.013611244037747383,
      "timestamp": 1759561922.7292013,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.013611244037747383,
      "ssim": 0.7307766079902649,
      "attention_bam_384_mean_attention": 0.16776089370250702,
      "attention_bam_384_std_attention": 0.5159263014793396,
      "attention_bam_384_max_attention": 3.6573486328125,
      "attention_bam_384_min_attention": -1.175048828125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4338479253075302,
      "attention_bam_384_attention_skewness": 0.7686304824243403,
      "attention_bam_384_attention_sparsity": 0.4831492106119792,
      "attention_bam_384_attention_concentration_10": 0.7048372972832347,
      "attention_bam_384_attention_concentration_20": 1.109941255485294,
      "attention_bam_384_attention_center_y": 0.4866027849894567,
      "attention_bam_384_attention_center_x": 0.48765164417344675,
      "attention_bam_384_attention_center_distance": 0.025766926928056377,
      "attention_bam_384_attention_spatial_variance": 170.4207722691784,
      "attention_bam_384_attention_spatial_std": 13.05453071807556,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 16.41453900447911,
      "attention_bam_384_peak_intensity_mean": 0.2803366184234619,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1953682005405426,
      "attention_bam_16_std_attention": 0.5285655856132507,
      "attention_bam_16_max_attention": 3.846923828125,
      "attention_bam_16_min_attention": -1.09222412109375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.780212886785508,
      "attention_bam_16_attention_skewness": 0.9851218437504018,
      "attention_bam_16_attention_sparsity": 0.46484375,
      "attention_bam_16_attention_concentration_10": 0.6390171320995723,
      "attention_bam_16_attention_concentration_20": 0.994553097561521,
      "attention_bam_16_attention_center_y": 0.4748956351609332,
      "attention_bam_16_attention_center_x": 0.4666875407519484,
      "attention_bam_16_attention_center_distance": 0.0589906615512332,
      "attention_bam_16_attention_spatial_variance": 42.952561725088685,
      "attention_bam_16_attention_spatial_std": 6.553820391579913,
      "attention_bam_16_num_attention_peaks": 12,
      "attention_bam_16_peak_separation_mean": 9.827309050784228,
      "attention_bam_16_peak_intensity_mean": 0.2645992338657379,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 189,
      "phase": "train",
      "loss": 0.01151480432599783,
      "timestamp": 1759561922.9002304,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.01151480432599783,
      "ssim": 0.7179874777793884,
      "attention_bam_384_mean_attention": 0.17417959868907928,
      "attention_bam_384_std_attention": 0.5057461857795715,
      "attention_bam_384_max_attention": 3.6185302734375,
      "attention_bam_384_min_attention": -1.15087890625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5323767123462035,
      "attention_bam_384_attention_skewness": 0.8131896902438833,
      "attention_bam_384_attention_sparsity": 0.47160593668619794,
      "attention_bam_384_attention_concentration_10": 0.6769539690096112,
      "attention_bam_384_attention_concentration_20": 1.0556919294797236,
      "attention_bam_384_attention_center_y": 0.4814754526344902,
      "attention_bam_384_attention_center_x": 0.4843620377850166,
      "attention_bam_384_attention_center_distance": 0.03428424470027785,
      "attention_bam_384_attention_spatial_variance": 170.53166370005036,
      "attention_bam_384_attention_spatial_std": 13.058777266652891,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 22.542498537363826,
      "attention_bam_384_peak_intensity_mean": 0.2757187783718109,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20791223645210266,
      "attention_bam_16_std_attention": 0.5298439860343933,
      "attention_bam_16_max_attention": 3.8685302734375,
      "attention_bam_16_min_attention": -0.9481201171875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.377007495565601,
      "attention_bam_16_attention_skewness": 1.062760478409372,
      "attention_bam_16_attention_sparsity": 0.439208984375,
      "attention_bam_16_attention_concentration_10": 0.5953525375637281,
      "attention_bam_16_attention_concentration_20": 0.9202734456473054,
      "attention_bam_16_attention_center_y": 0.46295934644970055,
      "attention_bam_16_attention_center_x": 0.47327493989606817,
      "attention_bam_16_attention_center_distance": 0.0645947188706953,
      "attention_bam_16_attention_spatial_variance": 42.917595671488534,
      "attention_bam_16_attention_spatial_std": 6.551152239987141,
      "attention_bam_16_num_attention_peaks": 12,
      "attention_bam_16_peak_separation_mean": 9.459170639279058,
      "attention_bam_16_peak_intensity_mean": 0.24331903457641602,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 190,
      "phase": "train",
      "loss": 0.009943965822458267,
      "timestamp": 1759561923.1848447,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.009943965822458267,
      "ssim": 0.7979102730751038,
      "attention_bam_384_mean_attention": 0.17075872421264648,
      "attention_bam_384_std_attention": 0.5390822887420654,
      "attention_bam_384_max_attention": 4.32110595703125,
      "attention_bam_384_min_attention": -1.287109375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.9752630281682952,
      "attention_bam_384_attention_skewness": 1.2926252899573567,
      "attention_bam_384_attention_sparsity": 0.4897613525390625,
      "attention_bam_384_attention_concentration_10": 0.7458780359872708,
      "attention_bam_384_attention_concentration_20": 1.124290133023389,
      "attention_bam_384_attention_center_y": 0.47514083373588273,
      "attention_bam_384_attention_center_x": 0.4770911677412914,
      "attention_bam_384_attention_center_distance": 0.04780779733065881,
      "attention_bam_384_attention_spatial_variance": 171.64612901363947,
      "attention_bam_384_attention_spatial_std": 13.10137889741532,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 19.158795846512973,
      "attention_bam_384_peak_intensity_mean": 0.2622402012348175,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17310985922813416,
      "attention_bam_16_std_attention": 0.5337339043617249,
      "attention_bam_16_max_attention": 4.993927001953125,
      "attention_bam_16_min_attention": -1.128662109375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 8.452888472480092,
      "attention_bam_16_attention_skewness": 1.7943973865468392,
      "attention_bam_16_attention_sparsity": 0.49755859375,
      "attention_bam_16_attention_concentration_10": 0.7192302090435653,
      "attention_bam_16_attention_concentration_20": 1.0909965786800415,
      "attention_bam_16_attention_center_y": 0.4607509146604146,
      "attention_bam_16_attention_center_x": 0.46190397512886516,
      "attention_bam_16_attention_center_distance": 0.07735370464271481,
      "attention_bam_16_attention_spatial_variance": 43.35575420993575,
      "attention_bam_16_attention_spatial_std": 6.584508653645749,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.317553593562307,
      "attention_bam_16_peak_intensity_mean": 0.2207377701997757,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 191,
      "phase": "train",
      "loss": 0.008207658305764198,
      "timestamp": 1759561923.354493,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008207658305764198,
      "ssim": 0.8096531629562378,
      "attention_bam_384_mean_attention": 0.17476658523082733,
      "attention_bam_384_std_attention": 0.5721742510795593,
      "attention_bam_384_max_attention": 4.22802734375,
      "attention_bam_384_min_attention": -1.332763671875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1257199902196717,
      "attention_bam_384_attention_skewness": 0.8257857730528292,
      "attention_bam_384_attention_sparsity": 0.4901682535807292,
      "attention_bam_384_attention_concentration_10": 0.7659107419149459,
      "attention_bam_384_attention_concentration_20": 1.1882174189344008,
      "attention_bam_384_attention_center_y": 0.47263479742225545,
      "attention_bam_384_attention_center_x": 0.4833408702187623,
      "attention_bam_384_attention_center_distance": 0.045307414783655825,
      "attention_bam_384_attention_spatial_variance": 170.064560909115,
      "attention_bam_384_attention_spatial_std": 13.040880373238418,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 14.58625059767549,
      "attention_bam_384_peak_intensity_mean": 0.2748623192310333,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21078087389469147,
      "attention_bam_16_std_attention": 0.5845425128936768,
      "attention_bam_16_max_attention": 3.69195556640625,
      "attention_bam_16_min_attention": -1.22021484375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.9574188627181162,
      "attention_bam_16_attention_skewness": 0.857056358063761,
      "attention_bam_16_attention_sparsity": 0.45068359375,
      "attention_bam_16_attention_concentration_10": 0.6408642750697849,
      "attention_bam_16_attention_concentration_20": 1.0020744043915628,
      "attention_bam_16_attention_center_y": 0.46534806080888835,
      "attention_bam_16_attention_center_x": 0.4666742910281627,
      "attention_bam_16_attention_center_distance": 0.06799058417428248,
      "attention_bam_16_attention_spatial_variance": 42.91602080735062,
      "attention_bam_16_attention_spatial_std": 6.551032041392457,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 9.735560897668778,
      "attention_bam_16_peak_intensity_mean": 0.2942247986793518,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 192,
      "phase": "train",
      "loss": 0.008621195331215858,
      "timestamp": 1759561923.5224564,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008621195331215858,
      "ssim": 0.8123114109039307,
      "attention_bam_384_mean_attention": 0.17831067740917206,
      "attention_bam_384_std_attention": 0.47595101594924927,
      "attention_bam_384_max_attention": 3.317138671875,
      "attention_bam_384_min_attention": -1.1815185546875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.237271332661588,
      "attention_bam_384_attention_skewness": 0.8677543435799471,
      "attention_bam_384_attention_sparsity": 0.45869191487630206,
      "attention_bam_384_attention_concentration_10": 0.6293307720505817,
      "attention_bam_384_attention_concentration_20": 0.9780055422649243,
      "attention_bam_384_attention_center_y": 0.48251805074622345,
      "attention_bam_384_attention_center_x": 0.48767649192258933,
      "attention_bam_384_attention_center_distance": 0.03024855041305697,
      "attention_bam_384_attention_spatial_variance": 169.29808238668804,
      "attention_bam_384_attention_spatial_std": 13.011459656267933,
      "attention_bam_384_num_attention_peaks": 4,
      "attention_bam_384_peak_separation_mean": 16.513914981533116,
      "attention_bam_384_peak_intensity_mean": 0.30296534299850464,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21407710015773773,
      "attention_bam_16_std_attention": 0.5163478255271912,
      "attention_bam_16_max_attention": 3.550048828125,
      "attention_bam_16_min_attention": -1.048095703125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 4.619853254760572,
      "attention_bam_16_attention_skewness": 1.3056742630351343,
      "attention_bam_16_attention_sparsity": 0.427734375,
      "attention_bam_16_attention_concentration_10": 0.5844171473916071,
      "attention_bam_16_attention_concentration_20": 0.8894224614976272,
      "attention_bam_16_attention_center_y": 0.47758252234301674,
      "attention_bam_16_attention_center_x": 0.46657729457883945,
      "attention_bam_16_attention_center_distance": 0.05691433109808141,
      "attention_bam_16_attention_spatial_variance": 42.60162164368794,
      "attention_bam_16_attention_spatial_std": 6.526991775978268,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 8.785501660299223,
      "attention_bam_16_peak_intensity_mean": 0.28140193223953247,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 193,
      "phase": "train",
      "loss": 0.008660119026899338,
      "timestamp": 1759561923.6907005,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008660119026899338,
      "ssim": 0.8163930773735046,
      "attention_bam_384_mean_attention": 0.1498354822397232,
      "attention_bam_384_std_attention": 0.5127663612365723,
      "attention_bam_384_max_attention": 4.252349853515625,
      "attention_bam_384_min_attention": -1.149169921875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.1272764568604012,
      "attention_bam_384_attention_skewness": 1.1635734820701444,
      "attention_bam_384_attention_sparsity": 0.5037612915039062,
      "attention_bam_384_attention_concentration_10": 0.8048532865023437,
      "attention_bam_384_attention_concentration_20": 1.2185703391658997,
      "attention_bam_384_attention_center_y": 0.4943450255601515,
      "attention_bam_384_attention_center_x": 0.4935431679034629,
      "attention_bam_384_attention_center_distance": 0.012138320859016007,
      "attention_bam_384_attention_spatial_variance": 173.60637302582893,
      "attention_bam_384_attention_spatial_std": 13.175977118446621,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 18.40269710877462,
      "attention_bam_384_peak_intensity_mean": 0.24424153566360474,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1823957860469818,
      "attention_bam_16_std_attention": 0.5191314816474915,
      "attention_bam_16_max_attention": 4.665618896484375,
      "attention_bam_16_min_attention": -1.08935546875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 5.766392879468043,
      "attention_bam_16_attention_skewness": 1.5294898288951997,
      "attention_bam_16_attention_sparsity": 0.48046875,
      "attention_bam_16_attention_concentration_10": 0.6904088061269111,
      "attention_bam_16_attention_concentration_20": 1.0312467576424578,
      "attention_bam_16_attention_center_y": 0.4805346794188998,
      "attention_bam_16_attention_center_x": 0.4714005375027149,
      "attention_bam_16_attention_center_distance": 0.048925003024192455,
      "attention_bam_16_attention_spatial_variance": 42.761794212975026,
      "attention_bam_16_attention_spatial_std": 6.539250279120308,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.663085861465712,
      "attention_bam_16_peak_intensity_mean": 0.22072412073612213,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 194,
      "phase": "train",
      "loss": 0.008541865274310112,
      "timestamp": 1759561923.8638704,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008541865274310112,
      "ssim": 0.8318567276000977,
      "attention_bam_384_mean_attention": 0.1620284616947174,
      "attention_bam_384_std_attention": 0.5338283777236938,
      "attention_bam_384_max_attention": 3.96075439453125,
      "attention_bam_384_min_attention": -1.2193603515625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.41722990674519,
      "attention_bam_384_attention_skewness": 1.0530764628897995,
      "attention_bam_384_attention_sparsity": 0.4918416341145833,
      "attention_bam_384_attention_concentration_10": 0.7665674104840033,
      "attention_bam_384_attention_concentration_20": 1.1758686019566502,
      "attention_bam_384_attention_center_y": 0.48462117587471776,
      "attention_bam_384_attention_center_x": 0.4799363232070327,
      "attention_bam_384_attention_center_distance": 0.035750786227131195,
      "attention_bam_384_attention_spatial_variance": 170.81798651345298,
      "attention_bam_384_attention_spatial_std": 13.06973551811409,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 19.607266614177373,
      "attention_bam_384_peak_intensity_mean": 0.26738083362579346,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18230704963207245,
      "attention_bam_16_std_attention": 0.5249202847480774,
      "attention_bam_16_max_attention": 4.666015625,
      "attention_bam_16_min_attention": -0.916748046875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 6.090950546275339,
      "attention_bam_16_attention_skewness": 1.476281449560694,
      "attention_bam_16_attention_sparsity": 0.474609375,
      "attention_bam_16_attention_concentration_10": 0.670837086737841,
      "attention_bam_16_attention_concentration_20": 1.0300266812695593,
      "attention_bam_16_attention_center_y": 0.4671393760984172,
      "attention_bam_16_attention_center_x": 0.46770979203716273,
      "attention_bam_16_attention_center_distance": 0.06515332890166936,
      "attention_bam_16_attention_spatial_variance": 41.86335424963683,
      "attention_bam_16_attention_spatial_std": 6.470189661025157,
      "attention_bam_16_num_attention_peaks": 12,
      "attention_bam_16_peak_separation_mean": 7.974279550064261,
      "attention_bam_16_peak_intensity_mean": 0.20125441253185272,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 195,
      "phase": "train",
      "loss": 0.01235557347536087,
      "timestamp": 1759561924.036536,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.01235557347536087,
      "ssim": 0.8110421299934387,
      "attention_bam_384_mean_attention": 0.1590210348367691,
      "attention_bam_384_std_attention": 0.5324802994728088,
      "attention_bam_384_max_attention": 4.96405029296875,
      "attention_bam_384_min_attention": -1.295654296875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 8.137838909930682,
      "attention_bam_384_attention_skewness": 1.8455630084520338,
      "attention_bam_384_attention_sparsity": 0.4991505940755208,
      "attention_bam_384_attention_concentration_10": 0.7829466061768727,
      "attention_bam_384_attention_concentration_20": 1.1583137290814463,
      "attention_bam_384_attention_center_y": 0.487853826667375,
      "attention_bam_384_attention_center_x": 0.47472384723798017,
      "attention_bam_384_attention_center_distance": 0.03965888110058412,
      "attention_bam_384_attention_spatial_variance": 173.1097097044082,
      "attention_bam_384_attention_spatial_std": 13.157116314162774,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 17.58146378854025,
      "attention_bam_384_peak_intensity_mean": 0.2336445301771164,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.15425801277160645,
      "attention_bam_16_std_attention": 0.5040253400802612,
      "attention_bam_16_max_attention": 5.1810302734375,
      "attention_bam_16_min_attention": -0.9658203125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 13.06343767523914,
      "attention_bam_16_attention_skewness": 2.3286510871820507,
      "attention_bam_16_attention_sparsity": 0.500244140625,
      "attention_bam_16_attention_concentration_10": 0.7580066517913123,
      "attention_bam_16_attention_concentration_20": 1.1243851477013103,
      "attention_bam_16_attention_center_y": 0.47179847840727435,
      "attention_bam_16_attention_center_x": 0.4664956242383742,
      "attention_bam_16_attention_center_distance": 0.06193333537475903,
      "attention_bam_16_attention_spatial_variance": 43.756039459664315,
      "attention_bam_16_attention_spatial_std": 6.61483480214467,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 10.512437748213822,
      "attention_bam_16_peak_intensity_mean": 0.18605530261993408,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 196,
      "phase": "train",
      "loss": 0.0076998937875032425,
      "timestamp": 1759561924.208566,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0076998937875032425,
      "ssim": 0.8390069007873535,
      "attention_bam_384_mean_attention": 0.17210854589939117,
      "attention_bam_384_std_attention": 0.5352699160575867,
      "attention_bam_384_max_attention": 4.34797477722168,
      "attention_bam_384_min_attention": -1.2694091796875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.0264531079448487,
      "attention_bam_384_attention_skewness": 0.9048783632267078,
      "attention_bam_384_attention_sparsity": 0.4821624755859375,
      "attention_bam_384_attention_concentration_10": 0.7184370529223331,
      "attention_bam_384_attention_concentration_20": 1.1189270034643053,
      "attention_bam_384_attention_center_y": 0.47645173752776826,
      "attention_bam_384_attention_center_x": 0.4810936263714524,
      "attention_bam_384_attention_center_distance": 0.04270764871175553,
      "attention_bam_384_attention_spatial_variance": 171.50912473778405,
      "attention_bam_384_attention_spatial_std": 13.096149233182404,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 18.66550996569255,
      "attention_bam_384_peak_intensity_mean": 0.25892728567123413,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2150515913963318,
      "attention_bam_16_std_attention": 0.5437247157096863,
      "attention_bam_16_max_attention": 3.852783203125,
      "attention_bam_16_min_attention": -0.9833984375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 4.096956960605278,
      "attention_bam_16_attention_skewness": 1.2342895456876464,
      "attention_bam_16_attention_sparsity": 0.44384765625,
      "attention_bam_16_attention_concentration_10": 0.602970176826812,
      "attention_bam_16_attention_concentration_20": 0.9243740311267087,
      "attention_bam_16_attention_center_y": 0.4681187980089436,
      "attention_bam_16_attention_center_x": 0.4704757878103977,
      "attention_bam_16_attention_center_distance": 0.06145063296356183,
      "attention_bam_16_attention_spatial_variance": 42.763240776586464,
      "attention_bam_16_attention_spatial_std": 6.5393608844126705,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.576227482990781,
      "attention_bam_16_peak_intensity_mean": 0.24904650449752808,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 197,
      "phase": "train",
      "loss": 0.011091510765254498,
      "timestamp": 1759561924.383498,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.011091510765254498,
      "ssim": 0.8051556348800659,
      "attention_bam_384_mean_attention": 0.175627663731575,
      "attention_bam_384_std_attention": 0.5526537895202637,
      "attention_bam_384_max_attention": 5.49456787109375,
      "attention_bam_384_min_attention": -1.49267578125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 4.169988227140025,
      "attention_bam_384_attention_skewness": 1.1526249933430222,
      "attention_bam_384_attention_sparsity": 0.48004404703776044,
      "attention_bam_384_attention_concentration_10": 0.7280770801491768,
      "attention_bam_384_attention_concentration_20": 1.1234763219725896,
      "attention_bam_384_attention_center_y": 0.48173949473430766,
      "attention_bam_384_attention_center_x": 0.47982105453757556,
      "attention_bam_384_attention_center_distance": 0.03848729381325419,
      "attention_bam_384_attention_spatial_variance": 169.35323011130615,
      "attention_bam_384_attention_spatial_std": 13.013578681950102,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 16.296542050714425,
      "attention_bam_384_peak_intensity_mean": 0.24035882949829102,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21720187366008759,
      "attention_bam_16_std_attention": 0.5611230731010437,
      "attention_bam_16_max_attention": 5.479736328125,
      "attention_bam_16_min_attention": -1.30859375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 7.039301464180916,
      "attention_bam_16_attention_skewness": 1.491399612184735,
      "attention_bam_16_attention_sparsity": 0.446533203125,
      "attention_bam_16_attention_concentration_10": 0.6187000001508374,
      "attention_bam_16_attention_concentration_20": 0.9368465147566194,
      "attention_bam_16_attention_center_y": 0.4670081740158657,
      "attention_bam_16_attention_center_x": 0.465217556269674,
      "attention_bam_16_attention_center_distance": 0.06779791993299934,
      "attention_bam_16_attention_spatial_variance": 42.73442112705428,
      "attention_bam_16_attention_spatial_std": 6.5371569605643005,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 10.14707691784458,
      "attention_bam_16_peak_intensity_mean": 0.22736236453056335,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 198,
      "phase": "train",
      "loss": 0.0060640787705779076,
      "timestamp": 1759561924.562289,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0060640787705779076,
      "ssim": 0.873183012008667,
      "attention_bam_384_mean_attention": 0.16467800736427307,
      "attention_bam_384_std_attention": 0.5126532912254333,
      "attention_bam_384_max_attention": 4.1640625,
      "attention_bam_384_min_attention": -1.209228515625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.351817519685773,
      "attention_bam_384_attention_skewness": 1.127142155013731,
      "attention_bam_384_attention_sparsity": 0.48350779215494794,
      "attention_bam_384_attention_concentration_10": 0.7232393424370231,
      "attention_bam_384_attention_concentration_20": 1.1108141138179182,
      "attention_bam_384_attention_center_y": 0.48194654226774924,
      "attention_bam_384_attention_center_x": 0.48529231622921537,
      "attention_bam_384_attention_center_distance": 0.032931544087441936,
      "attention_bam_384_attention_spatial_variance": 169.01690007937503,
      "attention_bam_384_attention_spatial_std": 13.000649986803547,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 15.127079994662756,
      "attention_bam_384_peak_intensity_mean": 0.2537986636161804,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19115930795669556,
      "attention_bam_16_std_attention": 0.5305468440055847,
      "attention_bam_16_max_attention": 5.197479248046875,
      "attention_bam_16_min_attention": -1.009521484375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 10.048527837551026,
      "attention_bam_16_attention_skewness": 2.005179885261815,
      "attention_bam_16_attention_sparsity": 0.46630859375,
      "attention_bam_16_attention_concentration_10": 0.654612501359689,
      "attention_bam_16_attention_concentration_20": 0.98540357534363,
      "attention_bam_16_attention_center_y": 0.46770712489335053,
      "attention_bam_16_attention_center_x": 0.4679604072487408,
      "attention_bam_16_attention_center_distance": 0.06433296645298123,
      "attention_bam_16_attention_spatial_variance": 42.15383642113892,
      "attention_bam_16_attention_spatial_std": 6.492598587710388,
      "attention_bam_16_num_attention_peaks": 12,
      "attention_bam_16_peak_separation_mean": 9.947866460749825,
      "attention_bam_16_peak_intensity_mean": 0.19370265305042267,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 199,
      "phase": "train",
      "loss": 0.006751294247806072,
      "timestamp": 1759561924.7340755,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006751294247806072,
      "ssim": 0.8611133694648743,
      "attention_bam_384_mean_attention": 0.16996431350708008,
      "attention_bam_384_std_attention": 0.5048470497131348,
      "attention_bam_384_max_attention": 4.939697265625,
      "attention_bam_384_min_attention": -1.2269287109375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 5.1275693233255115,
      "attention_bam_384_attention_skewness": 1.295688664593375,
      "attention_bam_384_attention_sparsity": 0.46813710530598956,
      "attention_bam_384_attention_concentration_10": 0.6876191758709856,
      "attention_bam_384_attention_concentration_20": 1.0514475046359537,
      "attention_bam_384_attention_center_y": 0.4912702560495946,
      "attention_bam_384_attention_center_x": 0.47392023991913507,
      "attention_bam_384_attention_center_distance": 0.03889376081880268,
      "attention_bam_384_attention_spatial_variance": 171.29334462517312,
      "attention_bam_384_attention_spatial_std": 13.087908336520893,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 16.416583227423768,
      "attention_bam_384_peak_intensity_mean": 0.226780503988266,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1952880471944809,
      "attention_bam_16_std_attention": 0.514194905757904,
      "attention_bam_16_max_attention": 5.27813720703125,
      "attention_bam_16_min_attention": -1.0045166015625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 12.934384634917356,
      "attention_bam_16_attention_skewness": 2.15787803359305,
      "attention_bam_16_attention_sparsity": 0.449462890625,
      "attention_bam_16_attention_concentration_10": 0.6054510913957049,
      "attention_bam_16_attention_concentration_20": 0.9193336964756236,
      "attention_bam_16_attention_center_y": 0.4684725765647469,
      "attention_bam_16_attention_center_x": 0.4660102170410347,
      "attention_bam_16_attention_center_distance": 0.065563461990095,
      "attention_bam_16_attention_spatial_variance": 42.249628652821286,
      "attention_bam_16_attention_spatial_std": 6.499971434769639,
      "attention_bam_16_num_attention_peaks": 11,
      "attention_bam_16_peak_separation_mean": 9.062331386110628,
      "attention_bam_16_peak_intensity_mean": 0.1924518197774887,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 200,
      "phase": "train",
      "loss": 0.014505647122859955,
      "timestamp": 1759561925.0312526,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.014505647122859955,
      "ssim": 0.8483586311340332,
      "attention_bam_384_mean_attention": 0.1762218028306961,
      "attention_bam_384_std_attention": 0.45416703820228577,
      "attention_bam_384_max_attention": 3.587890625,
      "attention_bam_384_min_attention": -1.201416015625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.34812667200570546,
      "attention_bam_384_attention_skewness": 0.2303601769736034,
      "attention_bam_384_attention_sparsity": 0.4370625813802083,
      "attention_bam_384_attention_concentration_10": 0.5656440913354948,
      "attention_bam_384_attention_concentration_20": 0.9304971377299878,
      "attention_bam_384_attention_center_y": 0.477176631695496,
      "attention_bam_384_attention_center_x": 0.48927819111193965,
      "attention_bam_384_attention_center_distance": 0.035661276662372225,
      "attention_bam_384_attention_spatial_variance": 169.7401869797274,
      "attention_bam_384_attention_spatial_std": 13.028437626197832,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 17.3119712201188,
      "attention_bam_384_peak_intensity_mean": 0.2888152003288269,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.28336474299430847,
      "attention_bam_16_std_attention": 0.47756245732307434,
      "attention_bam_16_max_attention": 1.9835205078125,
      "attention_bam_16_min_attention": -1.13201904296875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.04427058802876038,
      "attention_bam_16_attention_skewness": -0.004332812612568647,
      "attention_bam_16_attention_sparsity": 0.336669921875,
      "attention_bam_16_attention_concentration_10": 0.39634503288050377,
      "attention_bam_16_attention_concentration_20": 0.6718984979448624,
      "attention_bam_16_attention_center_y": 0.4637585100824208,
      "attention_bam_16_attention_center_x": 0.4624666034960766,
      "attention_bam_16_attention_center_distance": 0.07378619714508566,
      "attention_bam_16_attention_spatial_variance": 43.34982373701897,
      "attention_bam_16_attention_spatial_std": 6.584058302978413,
      "attention_bam_16_num_attention_peaks": 12,
      "attention_bam_16_peak_separation_mean": 9.225858193216574,
      "attention_bam_16_peak_intensity_mean": 0.4656263589859009,
      "attention_bam_16_peak_coverage": 0.1015625
    }
  ],
  "summary": {
    "total_batches": 203,
    "latest_batch": 200,
    "latest_metrics": {
      "batch_idx": 200,
      "phase": "train",
      "loss": 0.014505647122859955,
      "timestamp": 1759561925.0312526,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.014505647122859955,
      "ssim": 0.8483586311340332,
      "attention_bam_384_mean_attention": 0.1762218028306961,
      "attention_bam_384_std_attention": 0.45416703820228577,
      "attention_bam_384_max_attention": 3.587890625,
      "attention_bam_384_min_attention": -1.201416015625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.34812667200570546,
      "attention_bam_384_attention_skewness": 0.2303601769736034,
      "attention_bam_384_attention_sparsity": 0.4370625813802083,
      "attention_bam_384_attention_concentration_10": 0.5656440913354948,
      "attention_bam_384_attention_concentration_20": 0.9304971377299878,
      "attention_bam_384_attention_center_y": 0.477176631695496,
      "attention_bam_384_attention_center_x": 0.48927819111193965,
      "attention_bam_384_attention_center_distance": 0.035661276662372225,
      "attention_bam_384_attention_spatial_variance": 169.7401869797274,
      "attention_bam_384_attention_spatial_std": 13.028437626197832,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 17.3119712201188,
      "attention_bam_384_peak_intensity_mean": 0.2888152003288269,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.28336474299430847,
      "attention_bam_16_std_attention": 0.47756245732307434,
      "attention_bam_16_max_attention": 1.9835205078125,
      "attention_bam_16_min_attention": -1.13201904296875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.04427058802876038,
      "attention_bam_16_attention_skewness": -0.004332812612568647,
      "attention_bam_16_attention_sparsity": 0.336669921875,
      "attention_bam_16_attention_concentration_10": 0.39634503288050377,
      "attention_bam_16_attention_concentration_20": 0.6718984979448624,
      "attention_bam_16_attention_center_y": 0.4637585100824208,
      "attention_bam_16_attention_center_x": 0.4624666034960766,
      "attention_bam_16_attention_center_distance": 0.07378619714508566,
      "attention_bam_16_attention_spatial_variance": 43.34982373701897,
      "attention_bam_16_attention_spatial_std": 6.584058302978413,
      "attention_bam_16_num_attention_peaks": 12,
      "attention_bam_16_peak_separation_mean": 9.225858193216574,
      "attention_bam_16_peak_intensity_mean": 0.4656263589859009,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    "loss_mean": 0.17545144092475107,
    "loss_std": 0.15930995774421017,
    "loss_min": 0.0060640787705779076,
    "loss_max": 0.674382209777832,
    "mse_mean": 0.17545144092475107,
    "mse_std": 0.15930995774421017,
    "mse_min": 0.0060640787705779076,
    "mse_max": 0.674382209777832,
    "ssim_mean": 0.29494834461322816,
    "ssim_std": 0.3006935522565476,
    "ssim_min": -0.0019465561490505934,
    "ssim_max": 0.873183012008667,
    "attention_bam_384_mean_attention_mean": 0.18973951607832473,
    "attention_bam_384_mean_attention_std": 0.025474452494680232,
    "attention_bam_384_mean_attention_min": 0.027279892936348915,
    "attention_bam_384_mean_attention_max": 0.24686604738235474,
    "attention_bam_384_std_attention_mean": 0.52572940209229,
    "attention_bam_384_std_attention_std": 0.05148509938475082,
    "attention_bam_384_std_attention_min": 0.25250741839408875,
    "attention_bam_384_std_attention_max": 0.6595689654350281,
    "attention_bam_384_max_attention_mean": 4.577978042546164,
    "attention_bam_384_max_attention_std": 0.8235471275524822,
    "attention_bam_384_max_attention_min": 0.922119140625,
    "attention_bam_384_max_attention_max": 7.384765625,
    "attention_bam_384_min_attention_mean": -1.2498962703009544,
    "attention_bam_384_min_attention_std": 0.10765631325074163,
    "attention_bam_384_min_attention_min": -1.6923828125,
    "attention_bam_384_min_attention_max": -0.75048828125,
    "attention_bam_384_attention_entropy_mean": NaN,
    "attention_bam_384_attention_entropy_std": NaN,
    "attention_bam_384_attention_entropy_min": NaN,
    "attention_bam_384_attention_entropy_max": NaN,
    "attention_bam_384_attention_kurtosis_mean": 2.369732273708586,
    "attention_bam_384_attention_kurtosis_std": 1.8411980871835925,
    "attention_bam_384_attention_kurtosis_min": -0.3489305636883069,
    "attention_bam_384_attention_kurtosis_max": 9.624103586640981,
    "attention_bam_384_attention_skewness_mean": 0.8513172705884239,
    "attention_bam_384_attention_skewness_std": 0.3527973159252892,
    "attention_bam_384_attention_skewness_min": -0.018300669019679246,
    "attention_bam_384_attention_skewness_max": 2.011180050539433,
    "attention_bam_384_attention_sparsity_mean": 0.45768194088990666,
    "attention_bam_384_attention_sparsity_std": 0.026473731273891663,
    "attention_bam_384_attention_sparsity_min": 0.337982177734375,
    "attention_bam_384_attention_sparsity_max": 0.607330322265625,
    "attention_bam_384_attention_concentration_10_mean": 0.6521807162693403,
    "attention_bam_384_attention_concentration_10_std": 0.12500974465866171,
    "attention_bam_384_attention_concentration_10_min": 0.40365290629705286,
    "attention_bam_384_attention_concentration_10_max": 1.7005794433075048,
    "attention_bam_384_attention_concentration_20_mean": 1.0262222453193819,
    "attention_bam_384_attention_concentration_20_std": 0.19642039288985744,
    "attention_bam_384_attention_concentration_20_min": 0.6605103751053127,
    "attention_bam_384_attention_concentration_20_max": 2.782090788188882,
    "attention_bam_384_attention_center_y_mean": 0.4827296702485597,
    "attention_bam_384_attention_center_y_std": 0.005330606715305306,
    "attention_bam_384_attention_center_y_min": 0.4678507265121213,
    "attention_bam_384_attention_center_y_max": 0.49794774839315453,
    "attention_bam_384_attention_center_x_mean": 0.484501086623695,
    "attention_bam_384_attention_center_x_std": 0.005010599654086626,
    "attention_bam_384_attention_center_x_min": 0.4715082401941686,
    "attention_bam_384_attention_center_x_max": 0.4966933049074629,
    "attention_bam_384_attention_center_distance_mean": 0.033689624418075687,
    "attention_bam_384_attention_center_distance_std": 0.0069804080283390035,
    "attention_bam_384_attention_center_distance_min": 0.01156906506627575,
    "attention_bam_384_attention_center_distance_max": 0.05043883591377499,
    "attention_bam_384_attention_spatial_variance_mean": 169.82559097908714,
    "attention_bam_384_attention_spatial_variance_std": 1.6924294895473497,
    "attention_bam_384_attention_spatial_variance_min": 164.15266475440745,
    "attention_bam_384_attention_spatial_variance_max": 174.76127236466655,
    "attention_bam_384_attention_spatial_std_mean": 13.031553766408381,
    "attention_bam_384_attention_spatial_std_std": 0.06494760629489037,
    "attention_bam_384_attention_spatial_std_min": 12.812207645617029,
    "attention_bam_384_attention_spatial_std_max": 13.219730419515617,
    "attention_bam_384_num_attention_peaks_mean": 7.472906403940887,
    "attention_bam_384_num_attention_peaks_std": 4.050791992737239,
    "attention_bam_384_num_attention_peaks_min": 1.0,
    "attention_bam_384_num_attention_peaks_max": 23.0,
    "attention_bam_384_peak_separation_mean_mean": 16.39185677807498,
    "attention_bam_384_peak_separation_mean_std": 3.42418676125648,
    "attention_bam_384_peak_separation_mean_min": 0.0,
    "attention_bam_384_peak_separation_mean_max": 26.592365482226523,
    "attention_bam_384_peak_intensity_mean_mean": 0.25446274267335245,
    "attention_bam_384_peak_intensity_mean_std": 0.034045753274175666,
    "attention_bam_384_peak_intensity_mean_min": 0.20002229511737823,
    "attention_bam_384_peak_intensity_mean_max": 0.46574026346206665,
    "attention_bam_384_peak_coverage_mean": 0.1005859375,
    "attention_bam_384_peak_coverage_std": 0.0,
    "attention_bam_384_peak_coverage_min": 0.1005859375,
    "attention_bam_384_peak_coverage_max": 0.1005859375,
    "attention_bam_16_mean_attention_mean": 0.21616677233371243,
    "attention_bam_16_mean_attention_std": 0.03012295452322817,
    "attention_bam_16_mean_attention_min": -0.023064471781253815,
    "attention_bam_16_mean_attention_max": 0.28336474299430847,
    "attention_bam_16_std_attention_mean": 0.5048519797953479,
    "attention_bam_16_std_attention_std": 0.05746168542354969,
    "attention_bam_16_std_attention_min": 0.20926405489444733,
    "attention_bam_16_std_attention_max": 0.6517515182495117,
    "attention_bam_16_max_attention_mean": 4.018279005154013,
    "attention_bam_16_max_attention_std": 1.1349875205949322,
    "attention_bam_16_max_attention_min": 0.412109375,
    "attention_bam_16_max_attention_max": 8.320465087890625,
    "attention_bam_16_min_attention_mean": -1.0276590421282012,
    "attention_bam_16_min_attention_std": 0.13516052155823044,
    "attention_bam_16_min_attention_min": -1.34619140625,
    "attention_bam_16_min_attention_max": -0.696044921875,
    "attention_bam_16_attention_entropy_mean": NaN,
    "attention_bam_16_attention_entropy_std": NaN,
    "attention_bam_16_attention_entropy_min": NaN,
    "attention_bam_16_attention_entropy_max": NaN,
    "attention_bam_16_attention_kurtosis_mean": 5.406731714189982,
    "attention_bam_16_attention_kurtosis_std": 4.259348495819202,
    "attention_bam_16_attention_kurtosis_min": -0.05154328961484156,
    "attention_bam_16_attention_kurtosis_max": 20.832848454767497,
    "attention_bam_16_attention_skewness_mean": 1.1907496633957084,
    "attention_bam_16_attention_skewness_std": 0.6024276295586097,
    "attention_bam_16_attention_skewness_min": -0.835637469842628,
    "attention_bam_16_attention_skewness_max": 2.761977586394018,
    "attention_bam_16_attention_sparsity_mean": 0.4263392857142857,
    "attention_bam_16_attention_sparsity_std": 0.04749222659949366,
    "attention_bam_16_attention_sparsity_min": 0.31689453125,
    "attention_bam_16_attention_sparsity_max": 0.8115234375,
    "attention_bam_16_attention_concentration_10_mean": 0.5306353759600665,
    "attention_bam_16_attention_concentration_10_std": 0.2024156027462079,
    "attention_bam_16_attention_concentration_10_min": -1.383140427327069,
    "attention_bam_16_attention_concentration_10_max": 0.7580066517913123,
    "attention_bam_16_attention_concentration_20_mean": 0.8312886677861857,
    "attention_bam_16_attention_concentration_20_std": 0.31748464617564365,
    "attention_bam_16_attention_concentration_20_min": -2.230925605625802,
    "attention_bam_16_attention_concentration_20_max": 1.1243851477013103,
    "attention_bam_16_attention_center_y_mean": 0.4700112435607897,
    "attention_bam_16_attention_center_y_std": 0.004999057551783679,
    "attention_bam_16_attention_center_y_min": 0.4552862900118193,
    "attention_bam_16_attention_center_y_max": 0.48398660251050174,
    "attention_bam_16_attention_center_x_mean": 0.47053960391373223,
    "attention_bam_16_attention_center_x_std": 0.004730057835879699,
    "attention_bam_16_attention_center_x_min": 0.4547100898792418,
    "attention_bam_16_attention_center_x_max": 0.48516751516132656,
    "attention_bam_16_attention_center_distance_mean": 0.05981741817935506,
    "attention_bam_16_attention_center_distance_std": 0.007132277163051058,
    "attention_bam_16_attention_center_distance_min": 0.03845993185675838,
    "attention_bam_16_attention_center_distance_max": 0.08295486325039204,
    "attention_bam_16_attention_spatial_variance_mean": 42.50659324354205,
    "attention_bam_16_attention_spatial_variance_std": 0.5569315805966037,
    "attention_bam_16_attention_spatial_variance_min": 41.07386266117738,
    "attention_bam_16_attention_spatial_variance_max": 43.94548548713058,
    "attention_bam_16_attention_spatial_std_mean": 6.5195690305837575,
    "attention_bam_16_attention_spatial_std_std": 0.042683412969550014,
    "attention_bam_16_attention_spatial_std_min": 6.4088893469287935,
    "attention_bam_16_attention_spatial_std_max": 6.629139121117507,
    "attention_bam_16_num_attention_peaks_mean": 8.438423645320198,
    "attention_bam_16_num_attention_peaks_std": 2.7878629236428196,
    "attention_bam_16_num_attention_peaks_min": 3.0,
    "attention_bam_16_num_attention_peaks_max": 18.0,
    "attention_bam_16_peak_separation_mean_mean": 9.080127736145759,
    "attention_bam_16_peak_separation_mean_std": 0.9535940702417249,
    "attention_bam_16_peak_separation_mean_min": 6.808357026090837,
    "attention_bam_16_peak_separation_mean_max": 12.387782164371371,
    "attention_bam_16_peak_intensity_mean_mean": 0.2640877508471165,
    "attention_bam_16_peak_intensity_mean_std": 0.06890576002754645,
    "attention_bam_16_peak_intensity_mean_min": 0.13868702948093414,
    "attention_bam_16_peak_intensity_mean_max": 0.6194080114364624,
    "attention_bam_16_peak_coverage_mean": 0.1015625,
    "attention_bam_16_peak_coverage_std": 0.0,
    "attention_bam_16_peak_coverage_min": 0.1015625,
    "attention_bam_16_peak_coverage_max": 0.1015625
  },
  "metadata": {
    "created_at": "2025-10-04T14:12:06.528649",
    "total_batches": 203,
    "device": "cuda:0"
  }
}