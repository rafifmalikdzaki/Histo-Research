{
  "batch_metrics": [
    {
      "batch_idx": 0,
      "phase": "val",
      "loss": 0.3895999789237976,
      "timestamp": 1759561871.0865848,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3895999789237976,
      "ssim": 0.00040854327380657196,
      "attention_bam_384_mean_attention": 0.027279892936348915,
      "attention_bam_384_std_attention": 0.25250741839408875,
      "attention_bam_384_max_attention": 0.98193359375,
      "attention_bam_384_min_attention": -0.7830810546875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": -0.3201067576437744,
      "attention_bam_384_attention_skewness": -0.013473773464475442,
      "attention_bam_384_attention_sparsity": 0.607330322265625,
      "attention_bam_384_attention_concentration_10": 1.7005794433075048,
      "attention_bam_384_attention_concentration_20": 2.782090788188882,
      "attention_bam_384_attention_center_y": 0.48433865387215447,
      "attention_bam_384_attention_center_x": 0.4841889192949348,
      "attention_bam_384_attention_center_distance": 0.031472783022741015,
      "attention_bam_384_attention_spatial_variance": 170.47589944698439,
      "attention_bam_384_attention_spatial_std": 13.05664196671504,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 16.841797090485656,
      "attention_bam_384_peak_intensity_mean": 0.45934778451919556,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": -0.023056861013174057,
      "attention_bam_16_std_attention": 0.2135583460330963,
      "attention_bam_16_max_attention": 0.42156982421875,
      "attention_bam_16_min_attention": -0.7479248046875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.618020875036284,
      "attention_bam_16_attention_skewness": -0.8164942125515078,
      "attention_bam_16_attention_sparsity": 0.769775390625,
      "attention_bam_16_attention_concentration_10": -1.383140427327069,
      "attention_bam_16_attention_concentration_20": -2.230925605625802,
      "attention_bam_16_attention_center_y": 0.4698477388378518,
      "attention_bam_16_attention_center_x": 0.46838565310888425,
      "attention_bam_16_attention_center_distance": 0.06178391024437011,
      "attention_bam_16_attention_spatial_variance": 42.4473040781802,
      "attention_bam_16_attention_spatial_std": 6.515159558919505,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 7.2631093237814905,
      "attention_bam_16_peak_intensity_mean": 0.6194080114364624,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 1,
      "phase": "val",
      "loss": 0.3948638141155243,
      "timestamp": 1759561873.0108893,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3948638141155243,
      "ssim": 0.0006062970496714115,
      "attention_bam_384_mean_attention": 0.027856267988681793,
      "attention_bam_384_std_attention": 0.25301969051361084,
      "attention_bam_384_max_attention": 0.922119140625,
      "attention_bam_384_min_attention": -0.75048828125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": -0.3489305636883069,
      "attention_bam_384_attention_skewness": -0.018300669019679246,
      "attention_bam_384_attention_sparsity": 0.5998662312825521,
      "attention_bam_384_attention_concentration_10": 1.6659078680650583,
      "attention_bam_384_attention_concentration_20": 2.728711446569341,
      "attention_bam_384_attention_center_y": 0.4848240448428333,
      "attention_bam_384_attention_center_x": 0.484328580432118,
      "attention_bam_384_attention_center_distance": 0.030851353493969384,
      "attention_bam_384_attention_spatial_variance": 170.36773816970666,
      "attention_bam_384_attention_spatial_std": 13.052499307401117,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 15.967948666447814,
      "attention_bam_384_peak_intensity_mean": 0.46574026346206665,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": -0.023064471781253815,
      "attention_bam_16_std_attention": 0.20926405489444733,
      "attention_bam_16_max_attention": 0.412109375,
      "attention_bam_16_min_attention": -0.696044921875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.6857240283563524,
      "attention_bam_16_attention_skewness": -0.835637469842628,
      "attention_bam_16_attention_sparsity": 0.8115234375,
      "attention_bam_16_attention_concentration_10": -1.3610803962210327,
      "attention_bam_16_attention_concentration_20": -2.1846442490685716,
      "attention_bam_16_attention_center_y": 0.46929735998565686,
      "attention_bam_16_attention_center_x": 0.46821391087525055,
      "attention_bam_16_attention_center_distance": 0.06249812102290531,
      "attention_bam_16_attention_spatial_variance": 42.46409940421988,
      "attention_bam_16_attention_spatial_std": 6.516448373479213,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 8.775735827210816,
      "attention_bam_16_peak_intensity_mean": 0.6077205538749695,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 0,
      "phase": "train",
      "loss": 0.674382209777832,
      "timestamp": 1759561874.1838658,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.674382209777832,
      "ssim": 0.03018847294151783,
      "attention_bam_384_mean_attention": 0.23461361229419708,
      "attention_bam_384_std_attention": 0.6595689654350281,
      "attention_bam_384_max_attention": 7.37109375,
      "attention_bam_384_min_attention": -1.6923828125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 4.286768198118034,
      "attention_bam_384_attention_skewness": 1.1116628967717006,
      "attention_bam_384_attention_sparsity": 0.44769541422526044,
      "attention_bam_384_attention_concentration_10": 0.6542075235698351,
      "attention_bam_384_attention_concentration_20": 1.0145116776148941,
      "attention_bam_384_attention_center_y": 0.48272383779368117,
      "attention_bam_384_attention_center_x": 0.48078391599871945,
      "attention_bam_384_attention_center_distance": 0.036543772791634684,
      "attention_bam_384_attention_spatial_variance": 171.31305243638997,
      "attention_bam_384_attention_spatial_std": 13.088661216350202,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 15.21052423792029,
      "attention_bam_384_peak_intensity_mean": 0.21384508907794952,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2457546889781952,
      "attention_bam_16_std_attention": 0.6227905750274658,
      "attention_bam_16_max_attention": 2.90234375,
      "attention_bam_16_min_attention": -1.152099609375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5525255646052725,
      "attention_bam_16_attention_skewness": 0.6018279438076105,
      "attention_bam_16_attention_sparsity": 0.436279296875,
      "attention_bam_16_attention_concentration_10": 0.6002472787573981,
      "attention_bam_16_attention_concentration_20": 0.9610750289827383,
      "attention_bam_16_attention_center_y": 0.469531449824565,
      "attention_bam_16_attention_center_x": 0.460236103148496,
      "attention_bam_16_attention_center_distance": 0.07084490161768944,
      "attention_bam_16_attention_spatial_variance": 42.944681043519246,
      "attention_bam_16_attention_spatial_std": 6.553219135930008,
      "attention_bam_16_num_attention_peaks": 13,
      "attention_bam_16_peak_separation_mean": 10.095097223127974,
      "attention_bam_16_peak_intensity_mean": 0.35803619027137756,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 1,
      "phase": "train",
      "loss": 0.6144739985466003,
      "timestamp": 1759561886.2873745,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.6144739985466003,
      "ssim": 0.03929352015256882,
      "attention_bam_384_mean_attention": 0.24507178366184235,
      "attention_bam_384_std_attention": 0.6470795273780823,
      "attention_bam_384_max_attention": 7.384765625,
      "attention_bam_384_min_attention": -1.6845703125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.7057730060244056,
      "attention_bam_384_attention_skewness": 1.0353455572980284,
      "attention_bam_384_attention_sparsity": 0.44038645426432294,
      "attention_bam_384_attention_concentration_10": 0.6204706544463922,
      "attention_bam_384_attention_concentration_20": 0.9697935940451372,
      "attention_bam_384_attention_center_y": 0.48430625478923683,
      "attention_bam_384_attention_center_x": 0.48379328161105617,
      "attention_bam_384_attention_center_distance": 0.031904587747810874,
      "attention_bam_384_attention_spatial_variance": 172.113608661504,
      "attention_bam_384_attention_spatial_std": 13.119207623233349,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 19.315131767412286,
      "attention_bam_384_peak_intensity_mean": 0.21474553644657135,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23714670538902283,
      "attention_bam_16_std_attention": 0.6517515182495117,
      "attention_bam_16_max_attention": 3.302001953125,
      "attention_bam_16_min_attention": -1.2509765625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.7928361656069498,
      "attention_bam_16_attention_skewness": 0.9776529900174382,
      "attention_bam_16_attention_sparsity": 0.466552734375,
      "attention_bam_16_attention_concentration_10": 0.666880369182622,
      "attention_bam_16_attention_concentration_20": 1.0304665903238543,
      "attention_bam_16_attention_center_y": 0.4728299145913402,
      "attention_bam_16_attention_center_x": 0.47218787968920545,
      "attention_bam_16_attention_center_distance": 0.05498595415732964,
      "attention_bam_16_attention_spatial_variance": 43.05681063107941,
      "attention_bam_16_attention_spatial_std": 6.561768864496783,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.587395801406776,
      "attention_bam_16_peak_intensity_mean": 0.3330957591533661,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 2,
      "phase": "train",
      "loss": 0.5141948461532593,
      "timestamp": 1759561886.4587305,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.5141948461532593,
      "ssim": 0.04283855855464935,
      "attention_bam_384_mean_attention": 0.23788386583328247,
      "attention_bam_384_std_attention": 0.5025405883789062,
      "attention_bam_384_max_attention": 7.2119140625,
      "attention_bam_384_min_attention": -1.535400390625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.795895592311523,
      "attention_bam_384_attention_skewness": 0.701906506714188,
      "attention_bam_384_attention_sparsity": 0.39693959554036456,
      "attention_bam_384_attention_concentration_10": 0.4888951779937266,
      "attention_bam_384_attention_concentration_20": 0.795247959026689,
      "attention_bam_384_attention_center_y": 0.47962442315965287,
      "attention_bam_384_attention_center_x": 0.47967508068354775,
      "attention_bam_384_attention_center_distance": 0.04070052768201376,
      "attention_bam_384_attention_spatial_variance": 171.36987671465798,
      "attention_bam_384_attention_spatial_std": 13.090831780855561,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 16.123279626589877,
      "attention_bam_384_peak_intensity_mean": 0.203139066696167,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23465333878993988,
      "attention_bam_16_std_attention": 0.4644710123538971,
      "attention_bam_16_max_attention": 2.8439788818359375,
      "attention_bam_16_min_attention": -0.978271484375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8573802166599522,
      "attention_bam_16_attention_skewness": 0.44645333734208276,
      "attention_bam_16_attention_sparsity": 0.391845703125,
      "attention_bam_16_attention_concentration_10": 0.4695503088445131,
      "attention_bam_16_attention_concentration_20": 0.764658034797842,
      "attention_bam_16_attention_center_y": 0.46304302485440896,
      "attention_bam_16_attention_center_x": 0.4677005391776773,
      "attention_bam_16_attention_center_distance": 0.06941286885476775,
      "attention_bam_16_attention_spatial_variance": 42.682484573959094,
      "attention_bam_16_attention_spatial_std": 6.533183341523418,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.371553826958499,
      "attention_bam_16_peak_intensity_mean": 0.3213530480861664,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 3,
      "phase": "train",
      "loss": 0.4800562858581543,
      "timestamp": 1759561886.625876,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.4800562858581543,
      "ssim": 0.02482813224196434,
      "attention_bam_384_mean_attention": 0.23525206744670868,
      "attention_bam_384_std_attention": 0.5401883125305176,
      "attention_bam_384_max_attention": 5.5439453125,
      "attention_bam_384_min_attention": -1.42724609375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5079595689825673,
      "attention_bam_384_attention_skewness": 0.5590058152284704,
      "attention_bam_384_attention_sparsity": 0.42616017659505206,
      "attention_bam_384_attention_concentration_10": 0.5328799394355668,
      "attention_bam_384_attention_concentration_20": 0.8720827550979479,
      "attention_bam_384_attention_center_y": 0.4796270104540608,
      "attention_bam_384_attention_center_x": 0.48751961199998234,
      "attention_bam_384_attention_center_distance": 0.03378812772764813,
      "attention_bam_384_attention_spatial_variance": 170.85260805560662,
      "attention_bam_384_attention_spatial_std": 13.071059943845665,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 17.68275091263935,
      "attention_bam_384_peak_intensity_mean": 0.23828202486038208,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2231074571609497,
      "attention_bam_16_std_attention": 0.4671613574028015,
      "attention_bam_16_max_attention": 2.10675048828125,
      "attention_bam_16_min_attention": -1.017333984375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.14705186277783966,
      "attention_bam_16_attention_skewness": 0.40073627972728615,
      "attention_bam_16_attention_sparsity": 0.4208984375,
      "attention_bam_16_attention_concentration_10": 0.4941993608489805,
      "attention_bam_16_attention_concentration_20": 0.8147345317536079,
      "attention_bam_16_attention_center_y": 0.47289023563955745,
      "attention_bam_16_attention_center_x": 0.4672763886824233,
      "attention_bam_16_attention_center_distance": 0.060096157303816906,
      "attention_bam_16_attention_spatial_variance": 42.00355966331507,
      "attention_bam_16_attention_spatial_std": 6.481015326576158,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.631948299588975,
      "attention_bam_16_peak_intensity_mean": 0.4099538028240204,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 4,
      "phase": "train",
      "loss": 0.4695420265197754,
      "timestamp": 1759561886.7964306,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.4695420265197754,
      "ssim": 0.013416453264653683,
      "attention_bam_384_mean_attention": 0.24061687290668488,
      "attention_bam_384_std_attention": 0.5737588405609131,
      "attention_bam_384_max_attention": 5.45703125,
      "attention_bam_384_min_attention": -1.559326171875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.867155187951676,
      "attention_bam_384_attention_skewness": 0.7504933481379583,
      "attention_bam_384_attention_sparsity": 0.4301249186197917,
      "attention_bam_384_attention_concentration_10": 0.5644004976117932,
      "attention_bam_384_attention_concentration_20": 0.8979211179850428,
      "attention_bam_384_attention_center_y": 0.4818129469000245,
      "attention_bam_384_attention_center_x": 0.48235960723415977,
      "attention_bam_384_attention_center_distance": 0.03583161613420293,
      "attention_bam_384_attention_spatial_variance": 168.69745399233875,
      "attention_bam_384_attention_spatial_std": 12.988358402521035,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 13.917834979235522,
      "attention_bam_384_peak_intensity_mean": 0.2596208155155182,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24608412384986877,
      "attention_bam_16_std_attention": 0.5414301753044128,
      "attention_bam_16_max_attention": 4.2208251953125,
      "attention_bam_16_min_attention": -1.28076171875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.252109324031718,
      "attention_bam_16_attention_skewness": 1.0396536944166843,
      "attention_bam_16_attention_sparsity": 0.426025390625,
      "attention_bam_16_attention_concentration_10": 0.5339119264522136,
      "attention_bam_16_attention_concentration_20": 0.8408373987604678,
      "attention_bam_16_attention_center_y": 0.4765246746911699,
      "attention_bam_16_attention_center_x": 0.4689797949325313,
      "attention_bam_16_attention_center_distance": 0.0550153436921594,
      "attention_bam_16_attention_spatial_variance": 41.60606606801984,
      "attention_bam_16_attention_spatial_std": 6.450276433457704,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.263764654601964,
      "attention_bam_16_peak_intensity_mean": 0.2825165092945099,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 5,
      "phase": "train",
      "loss": 0.45334145426750183,
      "timestamp": 1759561886.964522,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.45334145426750183,
      "ssim": 0.0006481515010818839,
      "attention_bam_384_mean_attention": 0.23825156688690186,
      "attention_bam_384_std_attention": 0.5795870423316956,
      "attention_bam_384_max_attention": 5.154296875,
      "attention_bam_384_min_attention": -1.2939453125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.21181178454695,
      "attention_bam_384_attention_skewness": 0.6765672392983002,
      "attention_bam_384_attention_sparsity": 0.433319091796875,
      "attention_bam_384_attention_concentration_10": 0.5792252472856618,
      "attention_bam_384_attention_concentration_20": 0.9204517764693186,
      "attention_bam_384_attention_center_y": 0.4890084740976202,
      "attention_bam_384_attention_center_x": 0.4852378459580533,
      "attention_bam_384_attention_center_distance": 0.02602824748694575,
      "attention_bam_384_attention_spatial_variance": 169.49214312562054,
      "attention_bam_384_attention_spatial_std": 13.018914821352068,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 15.943614546826382,
      "attention_bam_384_peak_intensity_mean": 0.23916293680667877,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22865775227546692,
      "attention_bam_16_std_attention": 0.5442461371421814,
      "attention_bam_16_max_attention": 3.38934326171875,
      "attention_bam_16_min_attention": -0.9951171875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.480605941100677,
      "attention_bam_16_attention_skewness": 0.9339807570108357,
      "attention_bam_16_attention_sparsity": 0.423095703125,
      "attention_bam_16_attention_concentration_10": 0.5703094605191307,
      "attention_bam_16_attention_concentration_20": 0.8915840260701801,
      "attention_bam_16_attention_center_y": 0.47432327301586513,
      "attention_bam_16_attention_center_x": 0.4718586965532351,
      "attention_bam_16_attention_center_distance": 0.05387443305132226,
      "attention_bam_16_attention_spatial_variance": 41.767421490534254,
      "attention_bam_16_attention_spatial_std": 6.462771966465648,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 7.9374453949347235,
      "attention_bam_16_peak_intensity_mean": 0.2822211980819702,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 6,
      "phase": "train",
      "loss": 0.4858403205871582,
      "timestamp": 1759561887.136022,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.4858403205871582,
      "ssim": 0.0030935481190681458,
      "attention_bam_384_mean_attention": 0.239176943898201,
      "attention_bam_384_std_attention": 0.5839954018592834,
      "attention_bam_384_max_attention": 5.7822265625,
      "attention_bam_384_min_attention": -1.3358154296875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7911144873548648,
      "attention_bam_384_attention_skewness": 0.5868238725319901,
      "attention_bam_384_attention_sparsity": 0.43982187906901044,
      "attention_bam_384_attention_concentration_10": 0.5747936771119917,
      "attention_bam_384_attention_concentration_20": 0.9257709435901649,
      "attention_bam_384_attention_center_y": 0.4892179356511552,
      "attention_bam_384_attention_center_x": 0.48577622731973974,
      "attention_bam_384_attention_center_distance": 0.02524157764016935,
      "attention_bam_384_attention_spatial_variance": 171.01781698989254,
      "attention_bam_384_attention_spatial_std": 13.077378062512857,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 18.426053848297446,
      "attention_bam_384_peak_intensity_mean": 0.22272942960262299,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23707067966461182,
      "attention_bam_16_std_attention": 0.5264033675193787,
      "attention_bam_16_max_attention": 2.66021728515625,
      "attention_bam_16_min_attention": -1.11883544921875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.613426195190788,
      "attention_bam_16_attention_skewness": 0.6182504270224477,
      "attention_bam_16_attention_sparsity": 0.43017578125,
      "attention_bam_16_attention_concentration_10": 0.5409360569926689,
      "attention_bam_16_attention_concentration_20": 0.8591459943703753,
      "attention_bam_16_attention_center_y": 0.479302486716333,
      "attention_bam_16_attention_center_x": 0.4714061726132226,
      "attention_bam_16_attention_center_distance": 0.04991981612050254,
      "attention_bam_16_attention_spatial_variance": 42.177045671452255,
      "attention_bam_16_attention_spatial_std": 6.494385703933226,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 7.928983251355613,
      "attention_bam_16_peak_intensity_mean": 0.367025226354599,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 7,
      "phase": "train",
      "loss": 0.4560016989707947,
      "timestamp": 1759561887.3043792,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.4560016989707947,
      "ssim": 0.002819655928760767,
      "attention_bam_384_mean_attention": 0.232966348528862,
      "attention_bam_384_std_attention": 0.6516706943511963,
      "attention_bam_384_max_attention": 5.85888671875,
      "attention_bam_384_min_attention": -1.4969482421875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1122782481201305,
      "attention_bam_384_attention_skewness": 0.7272043230720782,
      "attention_bam_384_attention_sparsity": 0.45753224690755206,
      "attention_bam_384_attention_concentration_10": 0.6560878012003808,
      "attention_bam_384_attention_concentration_20": 1.034536969599685,
      "attention_bam_384_attention_center_y": 0.47840616145127973,
      "attention_bam_384_attention_center_x": 0.48878241626533986,
      "attention_bam_384_attention_center_distance": 0.034413022189639465,
      "attention_bam_384_attention_spatial_variance": 171.65104658316136,
      "attention_bam_384_attention_spatial_std": 13.101566569809938,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 18.419209632304916,
      "attention_bam_384_peak_intensity_mean": 0.23894982039928436,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22480495274066925,
      "attention_bam_16_std_attention": 0.6070523858070374,
      "attention_bam_16_max_attention": 3.418914794921875,
      "attention_bam_16_min_attention": -1.285400390625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.9005046331571092,
      "attention_bam_16_attention_skewness": 0.7159868201185197,
      "attention_bam_16_attention_sparsity": 0.462646484375,
      "attention_bam_16_attention_concentration_10": 0.63551933014498,
      "attention_bam_16_attention_concentration_20": 1.0070298391058048,
      "attention_bam_16_attention_center_y": 0.46922082166700074,
      "attention_bam_16_attention_center_x": 0.4725121492172216,
      "attention_bam_16_attention_center_distance": 0.05835991363103377,
      "attention_bam_16_attention_spatial_variance": 42.43074090568345,
      "attention_bam_16_attention_spatial_std": 6.513888309272999,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 8.992868689348464,
      "attention_bam_16_peak_intensity_mean": 0.3321414589881897,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 8,
      "phase": "train",
      "loss": 0.4709603190422058,
      "timestamp": 1759561887.4727755,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.4709603190422058,
      "ssim": 0.002096948679536581,
      "attention_bam_384_mean_attention": 0.24090266227722168,
      "attention_bam_384_std_attention": 0.5347017645835876,
      "attention_bam_384_max_attention": 6.17578125,
      "attention_bam_384_min_attention": -1.2586669921875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.0151457347433865,
      "attention_bam_384_attention_skewness": 0.6977032458782128,
      "attention_bam_384_attention_sparsity": 0.42211151123046875,
      "attention_bam_384_attention_concentration_10": 0.5297907353285553,
      "attention_bam_384_attention_concentration_20": 0.8521156404751321,
      "attention_bam_384_attention_center_y": 0.48831487380111066,
      "attention_bam_384_attention_center_x": 0.48565524395911286,
      "attention_bam_384_attention_center_distance": 0.026165404646461637,
      "attention_bam_384_attention_spatial_variance": 169.94338579828192,
      "attention_bam_384_attention_spatial_std": 13.03623357409194,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 15.558328156855547,
      "attention_bam_384_peak_intensity_mean": 0.20002229511737823,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23067566752433777,
      "attention_bam_16_std_attention": 0.48392632603645325,
      "attention_bam_16_max_attention": 3.1092529296875,
      "attention_bam_16_min_attention": -1.02569580078125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.6400896152557625,
      "attention_bam_16_attention_skewness": 0.7410729468412586,
      "attention_bam_16_attention_sparsity": 0.417724609375,
      "attention_bam_16_attention_concentration_10": 0.5113211676505286,
      "attention_bam_16_attention_concentration_20": 0.8138757816096951,
      "attention_bam_16_attention_center_y": 0.4809635201054975,
      "attention_bam_16_attention_center_x": 0.467113892898642,
      "attention_bam_16_attention_center_distance": 0.05373794947810692,
      "attention_bam_16_attention_spatial_variance": 42.665321303001676,
      "attention_bam_16_attention_spatial_std": 6.531869663656929,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.112248662552393,
      "attention_bam_16_peak_intensity_mean": 0.3068339228630066,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 9,
      "phase": "train",
      "loss": 0.44120165705680847,
      "timestamp": 1759561887.6396368,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.44120165705680847,
      "ssim": 0.0015531770186498761,
      "attention_bam_384_mean_attention": 0.2386624813079834,
      "attention_bam_384_std_attention": 0.6243621706962585,
      "attention_bam_384_max_attention": 5.7490234375,
      "attention_bam_384_min_attention": -1.3917236328125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7929839887477388,
      "attention_bam_384_attention_skewness": 0.5370521673129613,
      "attention_bam_384_attention_sparsity": 0.4377237955729167,
      "attention_bam_384_attention_concentration_10": 0.5989521053295174,
      "attention_bam_384_attention_concentration_20": 0.9687488033074465,
      "attention_bam_384_attention_center_y": 0.48184348954467254,
      "attention_bam_384_attention_center_x": 0.48396136784914057,
      "attention_bam_384_attention_center_distance": 0.03426066529374457,
      "attention_bam_384_attention_spatial_variance": 168.049396206901,
      "attention_bam_384_attention_spatial_std": 12.963386756820187,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 14.95450373565302,
      "attention_bam_384_peak_intensity_mean": 0.23023447394371033,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23995989561080933,
      "attention_bam_16_std_attention": 0.5747243762016296,
      "attention_bam_16_max_attention": 2.5950927734375,
      "attention_bam_16_min_attention": -1.1875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5440129785350609,
      "attention_bam_16_attention_skewness": 0.43301634536227973,
      "attention_bam_16_attention_sparsity": 0.413818359375,
      "attention_bam_16_attention_concentration_10": 0.5563420129659812,
      "attention_bam_16_attention_concentration_20": 0.9065293891223881,
      "attention_bam_16_attention_center_y": 0.4700431452491051,
      "attention_bam_16_attention_center_x": 0.4678168088250252,
      "attention_bam_16_attention_center_distance": 0.06217991541922825,
      "attention_bam_16_attention_spatial_variance": 42.200369005721384,
      "attention_bam_16_attention_spatial_std": 6.496181109368902,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.990187135814832,
      "attention_bam_16_peak_intensity_mean": 0.3892548978328705,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 10,
      "phase": "train",
      "loss": 0.4198513925075531,
      "timestamp": 1759561887.914069,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.4198513925075531,
      "ssim": 0.001457405393011868,
      "attention_bam_384_mean_attention": 0.2305784970521927,
      "attention_bam_384_std_attention": 0.5653135180473328,
      "attention_bam_384_max_attention": 5.724609375,
      "attention_bam_384_min_attention": -1.414794921875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5957995737240376,
      "attention_bam_384_attention_skewness": 0.741398018974984,
      "attention_bam_384_attention_sparsity": 0.43711598714192706,
      "attention_bam_384_attention_concentration_10": 0.5813972224643826,
      "attention_bam_384_attention_concentration_20": 0.9228012555537802,
      "attention_bam_384_attention_center_y": 0.4766546812227461,
      "attention_bam_384_attention_center_x": 0.47673215211139575,
      "attention_bam_384_attention_center_distance": 0.04661323104396063,
      "attention_bam_384_attention_spatial_variance": 170.7517006975137,
      "attention_bam_384_attention_spatial_std": 13.067199420591763,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 21.36602736143575,
      "attention_bam_384_peak_intensity_mean": 0.23476500809192657,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21765072643756866,
      "attention_bam_16_std_attention": 0.49605050683021545,
      "attention_bam_16_max_attention": 3.25384521484375,
      "attention_bam_16_min_attention": -1.009033203125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.114381506721597,
      "attention_bam_16_attention_skewness": 0.8242034441314291,
      "attention_bam_16_attention_sparsity": 0.432373046875,
      "attention_bam_16_attention_concentration_10": 0.5352786295545557,
      "attention_bam_16_attention_concentration_20": 0.8647701370812099,
      "attention_bam_16_attention_center_y": 0.4647428056750229,
      "attention_bam_16_attention_center_x": 0.46682177341139336,
      "attention_bam_16_attention_center_distance": 0.06846699162712089,
      "attention_bam_16_attention_spatial_variance": 41.92946109243847,
      "attention_bam_16_attention_spatial_std": 6.475296216578704,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.241694519456756,
      "attention_bam_16_peak_intensity_mean": 0.29687198996543884,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 11,
      "phase": "train",
      "loss": 0.5250172019004822,
      "timestamp": 1759561888.0843654,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.5250172019004822,
      "ssim": 0.0006150297704152763,
      "attention_bam_384_mean_attention": 0.23817576467990875,
      "attention_bam_384_std_attention": 0.6111212968826294,
      "attention_bam_384_max_attention": 5.970703125,
      "attention_bam_384_min_attention": -1.396728515625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.3031715253746032,
      "attention_bam_384_attention_skewness": 0.586484136260003,
      "attention_bam_384_attention_sparsity": 0.4292653401692708,
      "attention_bam_384_attention_concentration_10": 0.5982743759289552,
      "attention_bam_384_attention_concentration_20": 0.9585861567850703,
      "attention_bam_384_attention_center_y": 0.484743055607845,
      "attention_bam_384_attention_center_x": 0.4864963751157407,
      "attention_bam_384_attention_center_distance": 0.02881396318454295,
      "attention_bam_384_attention_spatial_variance": 169.68303378929812,
      "attention_bam_384_attention_spatial_std": 13.026244039987048,
      "attention_bam_384_num_attention_peaks": 20,
      "attention_bam_384_peak_separation_mean": 16.41047690734079,
      "attention_bam_384_peak_intensity_mean": 0.22255556285381317,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2470933347940445,
      "attention_bam_16_std_attention": 0.577705442905426,
      "attention_bam_16_max_attention": 3.7723388671875,
      "attention_bam_16_min_attention": -1.208740234375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7828309586074256,
      "attention_bam_16_attention_skewness": 0.4356238081947762,
      "attention_bam_16_attention_sparsity": 0.41064453125,
      "attention_bam_16_attention_concentration_10": 0.5384639738827508,
      "attention_bam_16_attention_concentration_20": 0.8768400580947684,
      "attention_bam_16_attention_center_y": 0.46900830276961736,
      "attention_bam_16_attention_center_x": 0.4625636864302809,
      "attention_bam_16_attention_center_distance": 0.06873082090168925,
      "attention_bam_16_attention_spatial_variance": 41.817843673040684,
      "attention_bam_16_attention_spatial_std": 6.466671761659214,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 6.808357026090837,
      "attention_bam_16_peak_intensity_mean": 0.2987084686756134,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 12,
      "phase": "train",
      "loss": 0.5536743402481079,
      "timestamp": 1759561888.2541296,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.5536743402481079,
      "ssim": 0.004162087105214596,
      "attention_bam_384_mean_attention": 0.24686604738235474,
      "attention_bam_384_std_attention": 0.41523653268814087,
      "attention_bam_384_max_attention": 6.2802734375,
      "attention_bam_384_min_attention": -1.354736328125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.839608499877526,
      "attention_bam_384_attention_skewness": 0.40975244281098694,
      "attention_bam_384_attention_sparsity": 0.337982177734375,
      "attention_bam_384_attention_concentration_10": 0.40365290629705286,
      "attention_bam_384_attention_concentration_20": 0.6605103751053127,
      "attention_bam_384_attention_center_y": 0.4845542781308059,
      "attention_bam_384_attention_center_x": 0.48389494299004193,
      "attention_bam_384_attention_center_distance": 0.031557667383838736,
      "attention_bam_384_attention_spatial_variance": 168.5681863574323,
      "attention_bam_384_attention_spatial_std": 12.983381160446315,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 17.49570255895203,
      "attention_bam_384_peak_intensity_mean": 0.20963945984840393,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24113669991493225,
      "attention_bam_16_std_attention": 0.3448593020439148,
      "attention_bam_16_max_attention": 2.744873046875,
      "attention_bam_16_min_attention": -0.902099609375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.4757646303591372,
      "attention_bam_16_attention_skewness": 0.17112444103071991,
      "attention_bam_16_attention_sparsity": 0.330322265625,
      "attention_bam_16_attention_concentration_10": 0.34678042392592845,
      "attention_bam_16_attention_concentration_20": 0.5869969306119315,
      "attention_bam_16_attention_center_y": 0.4777158104868729,
      "attention_bam_16_attention_center_x": 0.4688785632380198,
      "attention_bam_16_attention_center_distance": 0.05413185621031107,
      "attention_bam_16_attention_spatial_variance": 41.89478802771091,
      "attention_bam_16_attention_spatial_std": 6.472618328598629,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 8.19335436855237,
      "attention_bam_16_peak_intensity_mean": 0.31903308629989624,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 13,
      "phase": "train",
      "loss": 0.4588035047054291,
      "timestamp": 1759561888.4239938,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.4588035047054291,
      "ssim": 0.0010963589884340763,
      "attention_bam_384_mean_attention": 0.22783994674682617,
      "attention_bam_384_std_attention": 0.626022458076477,
      "attention_bam_384_max_attention": 4.6790771484375,
      "attention_bam_384_min_attention": -1.2996826171875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.3489393612556198,
      "attention_bam_384_attention_skewness": 0.9959727565562077,
      "attention_bam_384_attention_sparsity": 0.4560190836588542,
      "attention_bam_384_attention_concentration_10": 0.64931768397106,
      "attention_bam_384_attention_concentration_20": 1.0114700947715736,
      "attention_bam_384_attention_center_y": 0.48366931938053054,
      "attention_bam_384_attention_center_x": 0.47977235624793335,
      "attention_bam_384_attention_center_distance": 0.036765437608048034,
      "attention_bam_384_attention_spatial_variance": 168.00197995581308,
      "attention_bam_384_attention_spatial_std": 12.961557775044367,
      "attention_bam_384_num_attention_peaks": 2,
      "attention_bam_384_peak_separation_mean": 22.846279163767978,
      "attention_bam_384_peak_intensity_mean": 0.257546067237854,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22542516887187958,
      "attention_bam_16_std_attention": 0.5221493244171143,
      "attention_bam_16_max_attention": 3.439208984375,
      "attention_bam_16_min_attention": -1.1553955078125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.0125144458828235,
      "attention_bam_16_attention_skewness": 0.7766793692075744,
      "attention_bam_16_attention_sparsity": 0.4208984375,
      "attention_bam_16_attention_concentration_10": 0.5416607862949514,
      "attention_bam_16_attention_concentration_20": 0.865156308873474,
      "attention_bam_16_attention_center_y": 0.4737184370756668,
      "attention_bam_16_attention_center_x": 0.4697026267099578,
      "attention_bam_16_attention_center_distance": 0.05672127251784547,
      "attention_bam_16_attention_spatial_variance": 42.33413834811927,
      "attention_bam_16_attention_spatial_std": 6.506468961588864,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.209120502519376,
      "attention_bam_16_peak_intensity_mean": 0.30324259400367737,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 14,
      "phase": "train",
      "loss": 0.4143281579017639,
      "timestamp": 1759561888.5909503,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.4143281579017639,
      "ssim": 0.0005208884831517935,
      "attention_bam_384_mean_attention": 0.22821541130542755,
      "attention_bam_384_std_attention": 0.4802074432373047,
      "attention_bam_384_max_attention": 4.38232421875,
      "attention_bam_384_min_attention": -1.2034912109375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9001149091319003,
      "attention_bam_384_attention_skewness": 0.5166115888283378,
      "attention_bam_384_attention_sparsity": 0.41150156656901044,
      "attention_bam_384_attention_concentration_10": 0.501384978728809,
      "attention_bam_384_attention_concentration_20": 0.8138220676904019,
      "attention_bam_384_attention_center_y": 0.48084136165847663,
      "attention_bam_384_attention_center_x": 0.48806759186745363,
      "attention_bam_384_attention_center_distance": 0.0319197677605257,
      "attention_bam_384_attention_spatial_variance": 167.40873600883845,
      "attention_bam_384_attention_spatial_std": 12.93865278956192,
      "attention_bam_384_num_attention_peaks": 4,
      "attention_bam_384_peak_separation_mean": 15.48193666506358,
      "attention_bam_384_peak_intensity_mean": 0.25933170318603516,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23241965472698212,
      "attention_bam_16_std_attention": 0.4000910520553589,
      "attention_bam_16_max_attention": 2.1201171875,
      "attention_bam_16_min_attention": -1.0460205078125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8525213203925515,
      "attention_bam_16_attention_skewness": 0.413773414564646,
      "attention_bam_16_attention_sparsity": 0.369873046875,
      "attention_bam_16_attention_concentration_10": 0.4195136387585194,
      "attention_bam_16_attention_concentration_20": 0.6876138930349529,
      "attention_bam_16_attention_center_y": 0.4685943500284337,
      "attention_bam_16_attention_center_x": 0.46921808163789347,
      "attention_bam_16_attention_center_distance": 0.06219069622038226,
      "attention_bam_16_attention_spatial_variance": 41.730401808850125,
      "attention_bam_16_attention_spatial_std": 6.459907260081225,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 7.673835057945997,
      "attention_bam_16_peak_intensity_mean": 0.40526553988456726,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 15,
      "phase": "train",
      "loss": 0.420686811208725,
      "timestamp": 1759561888.7581387,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.420686811208725,
      "ssim": 0.0008906464790925384,
      "attention_bam_384_mean_attention": 0.2300127148628235,
      "attention_bam_384_std_attention": 0.6279935836791992,
      "attention_bam_384_max_attention": 4.27099609375,
      "attention_bam_384_min_attention": -1.257568359375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8425287749431076,
      "attention_bam_384_attention_skewness": 0.659565534934107,
      "attention_bam_384_attention_sparsity": 0.44695790608723956,
      "attention_bam_384_attention_concentration_10": 0.6318923022610067,
      "attention_bam_384_attention_concentration_20": 1.0063567862916474,
      "attention_bam_384_attention_center_y": 0.48057429874770324,
      "attention_bam_384_attention_center_x": 0.481355456716505,
      "attention_bam_384_attention_center_distance": 0.03807825792742107,
      "attention_bam_384_attention_spatial_variance": 167.666654237019,
      "attention_bam_384_attention_spatial_std": 12.94861591974289,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 15.320562050298847,
      "attention_bam_384_peak_intensity_mean": 0.271147757768631,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2325185239315033,
      "attention_bam_16_std_attention": 0.5843653678894043,
      "attention_bam_16_max_attention": 3.4407958984375,
      "attention_bam_16_min_attention": -1.2890625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.2047561706211969,
      "attention_bam_16_attention_skewness": 0.6538982284589429,
      "attention_bam_16_attention_sparsity": 0.427490234375,
      "attention_bam_16_attention_concentration_10": 0.5856363993551964,
      "attention_bam_16_attention_concentration_20": 0.9281680901545155,
      "attention_bam_16_attention_center_y": 0.4661793758436179,
      "attention_bam_16_attention_center_x": 0.47393724864508396,
      "attention_bam_16_attention_center_distance": 0.06038379959087426,
      "attention_bam_16_attention_spatial_variance": 42.319042264650946,
      "attention_bam_16_attention_spatial_std": 6.505308775504123,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.168482576159423,
      "attention_bam_16_peak_intensity_mean": 0.32268139719963074,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 16,
      "phase": "train",
      "loss": 0.3505541682243347,
      "timestamp": 1759561888.9253416,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3505541682243347,
      "ssim": 0.0010726412292569876,
      "attention_bam_384_mean_attention": 0.2351071834564209,
      "attention_bam_384_std_attention": 0.455392062664032,
      "attention_bam_384_max_attention": 4.07421875,
      "attention_bam_384_min_attention": -1.24267578125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5462567093505264,
      "attention_bam_384_attention_skewness": 0.44866465830705426,
      "attention_bam_384_attention_sparsity": 0.4034474690755208,
      "attention_bam_384_attention_concentration_10": 0.46343519306307024,
      "attention_bam_384_attention_concentration_20": 0.7623251844872623,
      "attention_bam_384_attention_center_y": 0.48713005886629623,
      "attention_bam_384_attention_center_x": 0.484401139680375,
      "attention_bam_384_attention_center_distance": 0.028599294678581532,
      "attention_bam_384_attention_spatial_variance": 170.93288231648125,
      "attention_bam_384_attention_spatial_std": 13.074130269982827,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 16.022186149912294,
      "attention_bam_384_peak_intensity_mean": 0.2815971076488495,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.244666188955307,
      "attention_bam_16_std_attention": 0.3875468075275421,
      "attention_bam_16_max_attention": 2.07183837890625,
      "attention_bam_16_min_attention": -0.79248046875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.3464903812522411,
      "attention_bam_16_attention_skewness": 0.22619211349933385,
      "attention_bam_16_attention_sparsity": 0.3525390625,
      "attention_bam_16_attention_concentration_10": 0.38806432928725937,
      "attention_bam_16_attention_concentration_20": 0.644089536251884,
      "attention_bam_16_attention_center_y": 0.4713572486753919,
      "attention_bam_16_attention_center_x": 0.472921716458883,
      "attention_bam_16_attention_center_distance": 0.05574299315566876,
      "attention_bam_16_attention_spatial_variance": 41.77901038640821,
      "attention_bam_16_attention_spatial_std": 6.463668492923211,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.727620205271657,
      "attention_bam_16_peak_intensity_mean": 0.36544889211654663,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 17,
      "phase": "train",
      "loss": 0.4083728790283203,
      "timestamp": 1759561889.0909243,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.4083728790283203,
      "ssim": 1.1694035492837429e-05,
      "attention_bam_384_mean_attention": 0.22309525310993195,
      "attention_bam_384_std_attention": 0.533692479133606,
      "attention_bam_384_max_attention": 4.45916748046875,
      "attention_bam_384_min_attention": -1.23388671875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.544587836649698,
      "attention_bam_384_attention_skewness": 0.9223814421822987,
      "attention_bam_384_attention_sparsity": 0.4303334554036458,
      "attention_bam_384_attention_concentration_10": 0.5756671801104222,
      "attention_bam_384_attention_concentration_20": 0.9012274917104631,
      "attention_bam_384_attention_center_y": 0.4871925056094225,
      "attention_bam_384_attention_center_x": 0.48787690603049955,
      "attention_bam_384_attention_center_distance": 0.024939980752118153,
      "attention_bam_384_attention_spatial_variance": 169.89145948336247,
      "attention_bam_384_attention_spatial_std": 13.034241807000608,
      "attention_bam_384_num_attention_peaks": 4,
      "attention_bam_384_peak_separation_mean": 21.5188925645129,
      "attention_bam_384_peak_intensity_mean": 0.2576117515563965,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22663649916648865,
      "attention_bam_16_std_attention": 0.4754912555217743,
      "attention_bam_16_max_attention": 3.227783203125,
      "attention_bam_16_min_attention": -0.994415283203125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.336989919326272,
      "attention_bam_16_attention_skewness": 0.9930143084424898,
      "attention_bam_16_attention_sparsity": 0.405029296875,
      "attention_bam_16_attention_concentration_10": 0.5120107620812525,
      "attention_bam_16_attention_concentration_20": 0.7991007880740658,
      "attention_bam_16_attention_center_y": 0.4649648203398738,
      "attention_bam_16_attention_center_x": 0.47049237868549704,
      "attention_bam_16_attention_center_distance": 0.06477906343036197,
      "attention_bam_16_attention_spatial_variance": 42.449067240468494,
      "attention_bam_16_attention_spatial_std": 6.515294869802018,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 9.288172455643172,
      "attention_bam_16_peak_intensity_mean": 0.2939288020133972,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 18,
      "phase": "train",
      "loss": 0.362771600484848,
      "timestamp": 1759561889.2585177,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.362771600484848,
      "ssim": 0.0003558550961315632,
      "attention_bam_384_mean_attention": 0.21454019844532013,
      "attention_bam_384_std_attention": 0.5622808933258057,
      "attention_bam_384_max_attention": 6.0714111328125,
      "attention_bam_384_min_attention": -1.218994140625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 9.624103586640981,
      "attention_bam_384_attention_skewness": 2.011180050539433,
      "attention_bam_384_attention_sparsity": 0.4417215983072917,
      "attention_bam_384_attention_concentration_10": 0.6194161561939159,
      "attention_bam_384_attention_concentration_20": 0.930453719808872,
      "attention_bam_384_attention_center_y": 0.4727514052663248,
      "attention_bam_384_attention_center_x": 0.4845249699190062,
      "attention_bam_384_attention_center_distance": 0.044316192773471305,
      "attention_bam_384_attention_spatial_variance": 169.7437119860774,
      "attention_bam_384_attention_spatial_std": 13.028572906733777,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 17.25412183415587,
      "attention_bam_384_peak_intensity_mean": 0.20034489035606384,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22808365523815155,
      "attention_bam_16_std_attention": 0.5082948207855225,
      "attention_bam_16_max_attention": 5.1500701904296875,
      "attention_bam_16_min_attention": -0.81005859375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 14.895160387256233,
      "attention_bam_16_attention_skewness": 2.413582381570918,
      "attention_bam_16_attention_sparsity": 0.40673828125,
      "attention_bam_16_attention_concentration_10": 0.5215594944162077,
      "attention_bam_16_attention_concentration_20": 0.8003257453397133,
      "attention_bam_16_attention_center_y": 0.47447201254776483,
      "attention_bam_16_attention_center_x": 0.46844265790913553,
      "attention_bam_16_attention_center_distance": 0.05740285677910677,
      "attention_bam_16_attention_spatial_variance": 42.29586167616812,
      "attention_bam_16_attention_spatial_std": 6.50352686441504,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.90656132229367,
      "attention_bam_16_peak_intensity_mean": 0.17587736248970032,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 19,
      "phase": "train",
      "loss": 0.4095955789089203,
      "timestamp": 1759561889.4316,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.4095955789089203,
      "ssim": 0.0005955170490778983,
      "attention_bam_384_mean_attention": 0.2163437008857727,
      "attention_bam_384_std_attention": 0.599531352519989,
      "attention_bam_384_max_attention": 5.4759521484375,
      "attention_bam_384_min_attention": -1.235107421875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 4.816899004628956,
      "attention_bam_384_attention_skewness": 1.4445015911829824,
      "attention_bam_384_attention_sparsity": 0.45451609293619794,
      "attention_bam_384_attention_concentration_10": 0.6596809513509958,
      "attention_bam_384_attention_concentration_20": 0.9969606761357951,
      "attention_bam_384_attention_center_y": 0.4740247236460018,
      "attention_bam_384_attention_center_x": 0.49540775478208643,
      "attention_bam_384_attention_center_distance": 0.03730425439029786,
      "attention_bam_384_attention_spatial_variance": 171.93835588715177,
      "attention_bam_384_attention_spatial_std": 13.112526678224597,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 16.605063569294263,
      "attention_bam_384_peak_intensity_mean": 0.21976801753044128,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2095968872308731,
      "attention_bam_16_std_attention": 0.49391278624534607,
      "attention_bam_16_max_attention": 3.6187820434570312,
      "attention_bam_16_min_attention": -0.901611328125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 5.448974488045083,
      "attention_bam_16_attention_skewness": 1.3101961236473323,
      "attention_bam_16_attention_sparsity": 0.433837890625,
      "attention_bam_16_attention_concentration_10": 0.5432608248776158,
      "attention_bam_16_attention_concentration_20": 0.8573518949290105,
      "attention_bam_16_attention_center_y": 0.47299707770967764,
      "attention_bam_16_attention_center_x": 0.47502680919905305,
      "attention_bam_16_attention_center_distance": 0.05201572975548242,
      "attention_bam_16_attention_spatial_variance": 42.619450655576706,
      "attention_bam_16_attention_spatial_std": 6.528357424006187,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.784318936344002,
      "attention_bam_16_peak_intensity_mean": 0.2528820335865021,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 20,
      "phase": "train",
      "loss": 0.493151992559433,
      "timestamp": 1759561889.7458375,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.493151992559433,
      "ssim": -0.0018198546022176743,
      "attention_bam_384_mean_attention": 0.24042940139770508,
      "attention_bam_384_std_attention": 0.6084676384925842,
      "attention_bam_384_max_attention": 4.34765625,
      "attention_bam_384_min_attention": -1.3076171875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.16138050116226088,
      "attention_bam_384_attention_skewness": 0.42101307847527825,
      "attention_bam_384_attention_sparsity": 0.4270375569661458,
      "attention_bam_384_attention_concentration_10": 0.5723852114598201,
      "attention_bam_384_attention_concentration_20": 0.9349130268646572,
      "attention_bam_384_attention_center_y": 0.4836135107520447,
      "attention_bam_384_attention_center_x": 0.47951705801639877,
      "attention_bam_384_attention_center_distance": 0.03709630553510496,
      "attention_bam_384_attention_spatial_variance": 167.19952736979624,
      "attention_bam_384_attention_spatial_std": 12.930565624511413,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 12.8653225085155,
      "attention_bam_384_peak_intensity_mean": 0.27862653136253357,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2676053047180176,
      "attention_bam_16_std_attention": 0.5482960939407349,
      "attention_bam_16_max_attention": 2.42578125,
      "attention_bam_16_min_attention": -1.079833984375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.05154328961484156,
      "attention_bam_16_attention_skewness": 0.38190537906592514,
      "attention_bam_16_attention_sparsity": 0.402587890625,
      "attention_bam_16_attention_concentration_10": 0.48320333868046667,
      "attention_bam_16_attention_concentration_20": 0.804043758645858,
      "attention_bam_16_attention_center_y": 0.4768061572428521,
      "attention_bam_16_attention_center_x": 0.4732510514696106,
      "attention_bam_16_attention_center_distance": 0.05006916394997471,
      "attention_bam_16_attention_spatial_variance": 42.37891650020156,
      "attention_bam_16_attention_spatial_std": 6.509909100763355,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.285930568174674,
      "attention_bam_16_peak_intensity_mean": 0.3930264413356781,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 21,
      "phase": "train",
      "loss": 0.37550705671310425,
      "timestamp": 1759561889.9269798,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.37550705671310425,
      "ssim": -0.0015474576503038406,
      "attention_bam_384_mean_attention": 0.21498708426952362,
      "attention_bam_384_std_attention": 0.6306966543197632,
      "attention_bam_384_max_attention": 5.6865234375,
      "attention_bam_384_min_attention": -1.2279052734375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5450835734580313,
      "attention_bam_384_attention_skewness": 0.7984837175018211,
      "attention_bam_384_attention_sparsity": 0.4607035319010417,
      "attention_bam_384_attention_concentration_10": 0.6710911373747965,
      "attention_bam_384_attention_concentration_20": 1.0679750965143728,
      "attention_bam_384_attention_center_y": 0.477049012430863,
      "attention_bam_384_attention_center_x": 0.48302031511971283,
      "attention_bam_384_attention_center_distance": 0.04037468338036928,
      "attention_bam_384_attention_spatial_variance": 169.6455831707751,
      "attention_bam_384_attention_spatial_std": 13.024806454253941,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 12.779439230244682,
      "attention_bam_384_peak_intensity_mean": 0.21195895969867706,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23376663029193878,
      "attention_bam_16_std_attention": 0.6153234243392944,
      "attention_bam_16_max_attention": 4.660003662109375,
      "attention_bam_16_min_attention": -1.257080078125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.2462003097303684,
      "attention_bam_16_attention_skewness": 0.9283255458015099,
      "attention_bam_16_attention_sparsity": 0.436279296875,
      "attention_bam_16_attention_concentration_10": 0.5944671828955764,
      "attention_bam_16_attention_concentration_20": 0.9517723088517221,
      "attention_bam_16_attention_center_y": 0.46629612195496745,
      "attention_bam_16_attention_center_x": 0.47810845098852217,
      "attention_bam_16_attention_center_distance": 0.05683645508643838,
      "attention_bam_16_attention_spatial_variance": 42.47954361440215,
      "attention_bam_16_attention_spatial_std": 6.517633283209646,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.377149398234952,
      "attention_bam_16_peak_intensity_mean": 0.2566264569759369,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 22,
      "phase": "train",
      "loss": 0.39059171080589294,
      "timestamp": 1759561890.0942419,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.39059171080589294,
      "ssim": 0.0008436451898887753,
      "attention_bam_384_mean_attention": 0.21690350770950317,
      "attention_bam_384_std_attention": 0.5047915577888489,
      "attention_bam_384_max_attention": 4.642425537109375,
      "attention_bam_384_min_attention": -1.227783203125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8064602109677121,
      "attention_bam_384_attention_skewness": 0.7335254661819224,
      "attention_bam_384_attention_sparsity": 0.42979685465494794,
      "attention_bam_384_attention_concentration_10": 0.5447007912623865,
      "attention_bam_384_attention_concentration_20": 0.8723040372126731,
      "attention_bam_384_attention_center_y": 0.47484425496644833,
      "attention_bam_384_attention_center_x": 0.48571724554841456,
      "attention_bam_384_attention_center_distance": 0.04090986636295316,
      "attention_bam_384_attention_spatial_variance": 171.65163257500538,
      "attention_bam_384_attention_spatial_std": 13.101588933217428,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 17.417528545987125,
      "attention_bam_384_peak_intensity_mean": 0.2568003535270691,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22295132279396057,
      "attention_bam_16_std_attention": 0.43865546584129333,
      "attention_bam_16_max_attention": 3.1556568145751953,
      "attention_bam_16_min_attention": -0.821044921875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.5064170268410706,
      "attention_bam_16_attention_skewness": 0.6850451824271553,
      "attention_bam_16_attention_sparsity": 0.385986328125,
      "attention_bam_16_attention_concentration_10": 0.4566023548925038,
      "attention_bam_16_attention_concentration_20": 0.7368764624458392,
      "attention_bam_16_attention_center_y": 0.4649586440922867,
      "attention_bam_16_attention_center_x": 0.47570097177294784,
      "attention_bam_16_attention_center_distance": 0.06030488200187627,
      "attention_bam_16_attention_spatial_variance": 42.95384011839228,
      "attention_bam_16_attention_spatial_std": 6.553917921243161,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 11.299776698468884,
      "attention_bam_16_peak_intensity_mean": 0.2690442204475403,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 23,
      "phase": "train",
      "loss": 0.3740243911743164,
      "timestamp": 1759561890.2651184,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3740243911743164,
      "ssim": 0.0014891541795805097,
      "attention_bam_384_mean_attention": 0.21272824704647064,
      "attention_bam_384_std_attention": 0.550478994846344,
      "attention_bam_384_max_attention": 5.05908203125,
      "attention_bam_384_min_attention": -1.253662109375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.344609290716928,
      "attention_bam_384_attention_skewness": 0.695600789077516,
      "attention_bam_384_attention_sparsity": 0.44581858317057294,
      "attention_bam_384_attention_concentration_10": 0.5988490387049281,
      "attention_bam_384_attention_concentration_20": 0.954789420678747,
      "attention_bam_384_attention_center_y": 0.48457475265779465,
      "attention_bam_384_attention_center_x": 0.4819133408857201,
      "attention_bam_384_attention_center_distance": 0.03361742088514163,
      "attention_bam_384_attention_spatial_variance": 171.0680720111025,
      "attention_bam_384_attention_spatial_std": 13.079299370038996,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 18.3462513524135,
      "attention_bam_384_peak_intensity_mean": 0.238263338804245,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22741693258285522,
      "attention_bam_16_std_attention": 0.5175738334655762,
      "attention_bam_16_max_attention": 4.1513671875,
      "attention_bam_16_min_attention": -1.0225830078125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.459043747144129,
      "attention_bam_16_attention_skewness": 1.0663455455627393,
      "attention_bam_16_attention_sparsity": 0.43115234375,
      "attention_bam_16_attention_concentration_10": 0.5508532081442705,
      "attention_bam_16_attention_concentration_20": 0.8654633444219817,
      "attention_bam_16_attention_center_y": 0.47431623740126744,
      "attention_bam_16_attention_center_x": 0.47314121366145917,
      "attention_bam_16_attention_center_distance": 0.05255568598748267,
      "attention_bam_16_attention_spatial_variance": 41.514125448744316,
      "attention_bam_16_attention_spatial_std": 6.443145617533746,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.131964401194235,
      "attention_bam_16_peak_intensity_mean": 0.2452806532382965,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 24,
      "phase": "train",
      "loss": 0.37603089213371277,
      "timestamp": 1759561890.4359252,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.37603089213371277,
      "ssim": -0.0019465561490505934,
      "attention_bam_384_mean_attention": 0.222737655043602,
      "attention_bam_384_std_attention": 0.4529288411140442,
      "attention_bam_384_max_attention": 4.96875,
      "attention_bam_384_min_attention": -1.265869140625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6597297297541345,
      "attention_bam_384_attention_skewness": 0.29879303043638605,
      "attention_bam_384_attention_sparsity": 0.40086110432942706,
      "attention_bam_384_attention_concentration_10": 0.4714717646530431,
      "attention_bam_384_attention_concentration_20": 0.779340335122806,
      "attention_bam_384_attention_center_y": 0.48234248182939116,
      "attention_bam_384_attention_center_x": 0.48408438635598156,
      "attention_bam_384_attention_center_distance": 0.0336182898319069,
      "attention_bam_384_attention_spatial_variance": 169.91156419366018,
      "attention_bam_384_attention_spatial_std": 13.03501301087422,
      "attention_bam_384_num_attention_peaks": 18,
      "attention_bam_384_peak_separation_mean": 16.136634286712233,
      "attention_bam_384_peak_intensity_mean": 0.24085932970046997,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23865093290805817,
      "attention_bam_16_std_attention": 0.4183272421360016,
      "attention_bam_16_max_attention": 2.42681884765625,
      "attention_bam_16_min_attention": -0.87060546875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.9065327943389447,
      "attention_bam_16_attention_skewness": 0.4126014536596339,
      "attention_bam_16_attention_sparsity": 0.382568359375,
      "attention_bam_16_attention_concentration_10": 0.42591763539009875,
      "attention_bam_16_attention_concentration_20": 0.7018853438573897,
      "attention_bam_16_attention_center_y": 0.4676718857566496,
      "attention_bam_16_attention_center_x": 0.46962146201673066,
      "attention_bam_16_attention_center_distance": 0.06273695148048004,
      "attention_bam_16_attention_spatial_variance": 41.46609177086312,
      "attention_bam_16_attention_spatial_std": 6.439417036569624,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 7.507787008539353,
      "attention_bam_16_peak_intensity_mean": 0.35090506076812744,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 25,
      "phase": "train",
      "loss": 0.3457426428794861,
      "timestamp": 1759561890.603324,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3457426428794861,
      "ssim": 0.0035340702161192894,
      "attention_bam_384_mean_attention": 0.21932904422283173,
      "attention_bam_384_std_attention": 0.578107476234436,
      "attention_bam_384_max_attention": 5.23291015625,
      "attention_bam_384_min_attention": -1.275390625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.4148345908673363,
      "attention_bam_384_attention_skewness": 1.1537459588359111,
      "attention_bam_384_attention_sparsity": 0.4630991617838542,
      "attention_bam_384_attention_concentration_10": 0.6496714614619592,
      "attention_bam_384_attention_concentration_20": 0.9848550509855014,
      "attention_bam_384_attention_center_y": 0.47465331838298613,
      "attention_bam_384_attention_center_x": 0.47490849117382355,
      "attention_bam_384_attention_center_distance": 0.05043883591377499,
      "attention_bam_384_attention_spatial_variance": 170.5667521486199,
      "attention_bam_384_attention_spatial_std": 13.060120678945502,
      "attention_bam_384_num_attention_peaks": 1,
      "attention_bam_384_peak_separation_mean": 0.0,
      "attention_bam_384_peak_intensity_mean": 0.2439144402742386,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22107093036174774,
      "attention_bam_16_std_attention": 0.5019516944885254,
      "attention_bam_16_max_attention": 3.0308837890625,
      "attention_bam_16_min_attention": -0.7967529296875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 4.215520083571065,
      "attention_bam_16_attention_skewness": 1.3570790287848808,
      "attention_bam_16_attention_sparsity": 0.454345703125,
      "attention_bam_16_attention_concentration_10": 0.5419073594731247,
      "attention_bam_16_attention_concentration_20": 0.8461263243951258,
      "attention_bam_16_attention_center_y": 0.47958557734606394,
      "attention_bam_16_attention_center_x": 0.47219890377590223,
      "attention_bam_16_attention_center_distance": 0.04877806071493783,
      "attention_bam_16_attention_spatial_variance": 42.21963562881199,
      "attention_bam_16_attention_spatial_std": 6.497663859327596,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 12.387782164371371,
      "attention_bam_16_peak_intensity_mean": 0.2724291980266571,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 26,
      "phase": "train",
      "loss": 0.4012865424156189,
      "timestamp": 1759561890.7716005,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.4012865424156189,
      "ssim": 0.0038994671776890755,
      "attention_bam_384_mean_attention": 0.21551842987537384,
      "attention_bam_384_std_attention": 0.49021756649017334,
      "attention_bam_384_max_attention": 4.328369140625,
      "attention_bam_384_min_attention": -1.15625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8517687149369841,
      "attention_bam_384_attention_skewness": 0.772410318619924,
      "attention_bam_384_attention_sparsity": 0.42986806233723956,
      "attention_bam_384_attention_concentration_10": 0.540644032790104,
      "attention_bam_384_attention_concentration_20": 0.8626493653131282,
      "attention_bam_384_attention_center_y": 0.4895707694488865,
      "attention_bam_384_attention_center_x": 0.49360174113056,
      "attention_bam_384_attention_center_distance": 0.01730355838829961,
      "attention_bam_384_attention_spatial_variance": 169.4586957578079,
      "attention_bam_384_attention_spatial_std": 13.01763018977755,
      "attention_bam_384_num_attention_peaks": 4,
      "attention_bam_384_peak_separation_mean": 13.754672309644404,
      "attention_bam_384_peak_intensity_mean": 0.2554244101047516,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21872954070568085,
      "attention_bam_16_std_attention": 0.4299331307411194,
      "attention_bam_16_max_attention": 2.939208984375,
      "attention_bam_16_min_attention": -0.8587646484375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.720072183149707,
      "attention_bam_16_attention_skewness": 0.8037452648170491,
      "attention_bam_16_attention_sparsity": 0.396484375,
      "attention_bam_16_attention_concentration_10": 0.4664711587650134,
      "attention_bam_16_attention_concentration_20": 0.7516209721886545,
      "attention_bam_16_attention_center_y": 0.4763052430899522,
      "attention_bam_16_attention_center_x": 0.4686749655591199,
      "attention_bam_16_attention_center_distance": 0.055546364196922576,
      "attention_bam_16_attention_spatial_variance": 42.29286765203727,
      "attention_bam_16_attention_spatial_std": 6.503296675689744,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.553848148201208,
      "attention_bam_16_peak_intensity_mean": 0.2868809700012207,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 27,
      "phase": "train",
      "loss": 0.402923047542572,
      "timestamp": 1759561890.9527428,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.402923047542572,
      "ssim": 0.004224345553666353,
      "attention_bam_384_mean_attention": 0.21660566329956055,
      "attention_bam_384_std_attention": 0.542765736579895,
      "attention_bam_384_max_attention": 3.9393310546875,
      "attention_bam_384_min_attention": -1.1630859375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.249210069833854,
      "attention_bam_384_attention_skewness": 0.902268242999902,
      "attention_bam_384_attention_sparsity": 0.43240102132161456,
      "attention_bam_384_attention_concentration_10": 0.5914638162118233,
      "attention_bam_384_attention_concentration_20": 0.917480545068191,
      "attention_bam_384_attention_center_y": 0.49454370868645703,
      "attention_bam_384_attention_center_x": 0.47533073470303994,
      "attention_bam_384_attention_center_distance": 0.03573076448076762,
      "attention_bam_384_attention_spatial_variance": 169.75581583276917,
      "attention_bam_384_attention_spatial_std": 13.029037410061004,
      "attention_bam_384_num_attention_peaks": 4,
      "attention_bam_384_peak_separation_mean": 12.703063658551827,
      "attention_bam_384_peak_intensity_mean": 0.26719096302986145,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2233433574438095,
      "attention_bam_16_std_attention": 0.47626420855522156,
      "attention_bam_16_max_attention": 2.919830322265625,
      "attention_bam_16_min_attention": -1.0098876953125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.9457916009380973,
      "attention_bam_16_attention_skewness": 0.7923427038304958,
      "attention_bam_16_attention_sparsity": 0.384033203125,
      "attention_bam_16_attention_concentration_10": 0.49052045128740807,
      "attention_bam_16_attention_concentration_20": 0.7732673023488029,
      "attention_bam_16_attention_center_y": 0.47797721826505124,
      "attention_bam_16_attention_center_x": 0.4730229399386866,
      "attention_bam_16_attention_center_distance": 0.04924966365158046,
      "attention_bam_16_attention_spatial_variance": 43.12364312525277,
      "attention_bam_16_attention_spatial_std": 6.566859456791562,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.239006317153017,
      "attention_bam_16_peak_intensity_mean": 0.3198828101158142,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 28,
      "phase": "train",
      "loss": 0.43928083777427673,
      "timestamp": 1759561891.1203306,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.43928083777427673,
      "ssim": 0.003647006582468748,
      "attention_bam_384_mean_attention": 0.2057025283575058,
      "attention_bam_384_std_attention": 0.5642521381378174,
      "attention_bam_384_max_attention": 4.2353515625,
      "attention_bam_384_min_attention": -1.385986328125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.821343804418524,
      "attention_bam_384_attention_skewness": 0.6739921996929042,
      "attention_bam_384_attention_sparsity": 0.4618326822916667,
      "attention_bam_384_attention_concentration_10": 0.6398801759468876,
      "attention_bam_384_attention_concentration_20": 1.0193764393291074,
      "attention_bam_384_attention_center_y": 0.4786039435572992,
      "attention_bam_384_attention_center_x": 0.4863800039753374,
      "attention_bam_384_attention_center_distance": 0.03586908203484063,
      "attention_bam_384_attention_spatial_variance": 170.58838052919077,
      "attention_bam_384_attention_spatial_std": 13.060948684119035,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 14.94895332394235,
      "attention_bam_384_peak_intensity_mean": 0.28559285402297974,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2503933608531952,
      "attention_bam_16_std_attention": 0.53554767370224,
      "attention_bam_16_max_attention": 2.9635238647460938,
      "attention_bam_16_min_attention": -1.2357177734375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.4695447381143172,
      "attention_bam_16_attention_skewness": 0.7718020537937061,
      "attention_bam_16_attention_sparsity": 0.41015625,
      "attention_bam_16_attention_concentration_10": 0.5200995452475157,
      "attention_bam_16_attention_concentration_20": 0.8255898998789627,
      "attention_bam_16_attention_center_y": 0.46996080961821085,
      "attention_bam_16_attention_center_x": 0.47749857217331615,
      "attention_bam_16_attention_center_distance": 0.05307856842517205,
      "attention_bam_16_attention_spatial_variance": 42.5621381585891,
      "attention_bam_16_attention_spatial_std": 6.523966443705018,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 9.024988241016132,
      "attention_bam_16_peak_intensity_mean": 0.35665878653526306,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 29,
      "phase": "train",
      "loss": 0.3707438111305237,
      "timestamp": 1759561891.292717,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3707438111305237,
      "ssim": 0.0031733594369143248,
      "attention_bam_384_mean_attention": 0.21745924651622772,
      "attention_bam_384_std_attention": 0.5478830337524414,
      "attention_bam_384_max_attention": 4.58154296875,
      "attention_bam_384_min_attention": -1.232421875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2074555436790382,
      "attention_bam_384_attention_skewness": 0.7384297766507006,
      "attention_bam_384_attention_sparsity": 0.44663747151692706,
      "attention_bam_384_attention_concentration_10": 0.5928736760491371,
      "attention_bam_384_attention_concentration_20": 0.9404427486243407,
      "attention_bam_384_attention_center_y": 0.4835030176167239,
      "attention_bam_384_attention_center_x": 0.4875655409313446,
      "attention_bam_384_attention_center_distance": 0.029215276828542625,
      "attention_bam_384_attention_spatial_variance": 166.6684114176571,
      "attention_bam_384_attention_spatial_std": 12.9100120610965,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 12.184244043545121,
      "attention_bam_384_peak_intensity_mean": 0.2522590160369873,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24974606931209564,
      "attention_bam_16_std_attention": 0.4644300639629364,
      "attention_bam_16_max_attention": 2.5527725219726562,
      "attention_bam_16_min_attention": -1.0343017578125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.9956650448106874,
      "attention_bam_16_attention_skewness": 0.5012949684117372,
      "attention_bam_16_attention_sparsity": 0.36767578125,
      "attention_bam_16_attention_concentration_10": 0.44547088559200687,
      "attention_bam_16_attention_concentration_20": 0.7196303141155803,
      "attention_bam_16_attention_center_y": 0.47464906488366754,
      "attention_bam_16_attention_center_x": 0.4760736800419561,
      "attention_bam_16_attention_center_distance": 0.04929784372580991,
      "attention_bam_16_attention_spatial_variance": 41.852809079244594,
      "attention_bam_16_attention_spatial_std": 6.4693747054290025,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 7.7512002420991974,
      "attention_bam_16_peak_intensity_mean": 0.36312732100486755,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 30,
      "phase": "train",
      "loss": 0.29498815536499023,
      "timestamp": 1759561891.5520668,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.29498815536499023,
      "ssim": 0.001561687677167356,
      "attention_bam_384_mean_attention": 0.21818973124027252,
      "attention_bam_384_std_attention": 0.5406831502914429,
      "attention_bam_384_max_attention": 4.485260009765625,
      "attention_bam_384_min_attention": -1.2236328125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.024312811342207,
      "attention_bam_384_attention_skewness": 0.7878073868877925,
      "attention_bam_384_attention_sparsity": 0.4372100830078125,
      "attention_bam_384_attention_concentration_10": 0.5696563939277686,
      "attention_bam_384_attention_concentration_20": 0.912620543225356,
      "attention_bam_384_attention_center_y": 0.4792098542573517,
      "attention_bam_384_attention_center_x": 0.4827863385513594,
      "attention_bam_384_attention_center_distance": 0.03817172515014153,
      "attention_bam_384_attention_spatial_variance": 168.7219232238291,
      "attention_bam_384_attention_spatial_std": 12.989300336193212,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 14.58877010186176,
      "attention_bam_384_peak_intensity_mean": 0.2549682557582855,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.26247477531433105,
      "attention_bam_16_std_attention": 0.49406519532203674,
      "attention_bam_16_max_attention": 3.674560546875,
      "attention_bam_16_min_attention": -1.06103515625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.3677880309501536,
      "attention_bam_16_attention_skewness": 0.885740890636933,
      "attention_bam_16_attention_sparsity": 0.37353515625,
      "attention_bam_16_attention_concentration_10": 0.44912572587985,
      "attention_bam_16_attention_concentration_20": 0.7215145303907187,
      "attention_bam_16_attention_center_y": 0.46810112677951055,
      "attention_bam_16_attention_center_x": 0.46976446633589397,
      "attention_bam_16_attention_center_distance": 0.06215666671709717,
      "attention_bam_16_attention_spatial_variance": 41.93253862216568,
      "attention_bam_16_attention_spatial_std": 6.475533848430234,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.179951337611845,
      "attention_bam_16_peak_intensity_mean": 0.2819732427597046,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 31,
      "phase": "train",
      "loss": 0.34274134039878845,
      "timestamp": 1759561891.7190928,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.34274134039878845,
      "ssim": 0.0063679707236588,
      "attention_bam_384_mean_attention": 0.2044781893491745,
      "attention_bam_384_std_attention": 0.47136953473091125,
      "attention_bam_384_max_attention": 4.49755859375,
      "attention_bam_384_min_attention": -1.23974609375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.33011030812241726,
      "attention_bam_384_attention_skewness": 0.33641028840130516,
      "attention_bam_384_attention_sparsity": 0.4245096842447917,
      "attention_bam_384_attention_concentration_10": 0.5269357203904153,
      "attention_bam_384_attention_concentration_20": 0.8634982826977186,
      "attention_bam_384_attention_center_y": 0.4772295171100849,
      "attention_bam_384_attention_center_x": 0.4877041012356181,
      "attention_bam_384_attention_center_distance": 0.03659737743237474,
      "attention_bam_384_attention_spatial_variance": 171.82695940054057,
      "attention_bam_384_attention_spatial_std": 13.108278277506187,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 17.70077711137111,
      "attention_bam_384_peak_intensity_mean": 0.2534187436103821,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2310323417186737,
      "attention_bam_16_std_attention": 0.4396107494831085,
      "attention_bam_16_max_attention": 2.3121337890625,
      "attention_bam_16_min_attention": -0.8807373046875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6442235305109403,
      "attention_bam_16_attention_skewness": 0.37688969813301393,
      "attention_bam_16_attention_sparsity": 0.384521484375,
      "attention_bam_16_attention_concentration_10": 0.4541403884985843,
      "attention_bam_16_attention_concentration_20": 0.7390579837100163,
      "attention_bam_16_attention_center_y": 0.4687174124500691,
      "attention_bam_16_attention_center_x": 0.4785663738282205,
      "attention_bam_16_attention_center_distance": 0.0536283621732136,
      "attention_bam_16_attention_spatial_variance": 42.123625014818145,
      "attention_bam_16_attention_spatial_std": 6.490271567108587,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.05434849822776,
      "attention_bam_16_peak_intensity_mean": 0.35422274470329285,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 32,
      "phase": "train",
      "loss": 0.377725213766098,
      "timestamp": 1759561891.920866,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.377725213766098,
      "ssim": 0.00831372570246458,
      "attention_bam_384_mean_attention": 0.2170126587152481,
      "attention_bam_384_std_attention": 0.5399659276008606,
      "attention_bam_384_max_attention": 4.89495849609375,
      "attention_bam_384_min_attention": -1.3572998046875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.6527846622980373,
      "attention_bam_384_attention_skewness": 1.1062424757178917,
      "attention_bam_384_attention_sparsity": 0.43566131591796875,
      "attention_bam_384_attention_concentration_10": 0.5908860111666808,
      "attention_bam_384_attention_concentration_20": 0.9176829153850043,
      "attention_bam_384_attention_center_y": 0.4797135912695591,
      "attention_bam_384_attention_center_x": 0.48989204835794375,
      "attention_bam_384_attention_center_distance": 0.032053363804027075,
      "attention_bam_384_attention_spatial_variance": 170.58328130314896,
      "attention_bam_384_attention_spatial_std": 13.060753473791202,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 15.503899825451072,
      "attention_bam_384_peak_intensity_mean": 0.25646573305130005,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23467044532299042,
      "attention_bam_16_std_attention": 0.4914420247077942,
      "attention_bam_16_max_attention": 4.4869384765625,
      "attention_bam_16_min_attention": -0.9874267578125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 8.06269703597677,
      "attention_bam_16_attention_skewness": 1.6904480538850455,
      "attention_bam_16_attention_sparsity": 0.40234375,
      "attention_bam_16_attention_concentration_10": 0.5111300674482321,
      "attention_bam_16_attention_concentration_20": 0.7846283704865652,
      "attention_bam_16_attention_center_y": 0.46867966448940135,
      "attention_bam_16_attention_center_x": 0.473442085175437,
      "attention_bam_16_attention_center_distance": 0.05807385395038303,
      "attention_bam_16_attention_spatial_variance": 41.90060343056128,
      "attention_bam_16_attention_spatial_std": 6.473067544106216,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.054390390018678,
      "attention_bam_16_peak_intensity_mean": 0.2269664704799652,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 33,
      "phase": "train",
      "loss": 0.36529776453971863,
      "timestamp": 1759561892.09107,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.36529776453971863,
      "ssim": 0.006355466786772013,
      "attention_bam_384_mean_attention": 0.21562041342258453,
      "attention_bam_384_std_attention": 0.5712029337882996,
      "attention_bam_384_max_attention": 3.83349609375,
      "attention_bam_384_min_attention": -1.269287109375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.38269849285083835,
      "attention_bam_384_attention_skewness": 0.4609247513435478,
      "attention_bam_384_attention_sparsity": 0.44192250569661456,
      "attention_bam_384_attention_concentration_10": 0.5962912245999792,
      "attention_bam_384_attention_concentration_20": 0.9710147798701296,
      "attention_bam_384_attention_center_y": 0.4833559279217812,
      "attention_bam_384_attention_center_x": 0.48801228499150306,
      "attention_bam_384_attention_center_distance": 0.02900794534157442,
      "attention_bam_384_attention_spatial_variance": 169.6058686541659,
      "attention_bam_384_attention_spatial_std": 13.023281792780416,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 16.820290241221368,
      "attention_bam_384_peak_intensity_mean": 0.29167091846466064,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.25534123182296753,
      "attention_bam_16_std_attention": 0.559786319732666,
      "attention_bam_16_max_attention": 2.69183349609375,
      "attention_bam_16_min_attention": -1.205322265625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6691407795578108,
      "attention_bam_16_attention_skewness": 0.496923253826016,
      "attention_bam_16_attention_sparsity": 0.413818359375,
      "attention_bam_16_attention_concentration_10": 0.5132333391253043,
      "attention_bam_16_attention_concentration_20": 0.8312521373477186,
      "attention_bam_16_attention_center_y": 0.4571274630447008,
      "attention_bam_16_attention_center_x": 0.47630272726252404,
      "attention_bam_16_attention_center_distance": 0.06927647739569061,
      "attention_bam_16_attention_spatial_variance": 42.03614925269509,
      "attention_bam_16_attention_spatial_std": 6.483529073945384,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 7.364917966145997,
      "attention_bam_16_peak_intensity_mean": 0.3690265119075775,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 34,
      "phase": "train",
      "loss": 0.3206520080566406,
      "timestamp": 1759561892.258163,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3206520080566406,
      "ssim": 0.0042001595720648766,
      "attention_bam_384_mean_attention": 0.20136402547359467,
      "attention_bam_384_std_attention": 0.5212732553482056,
      "attention_bam_384_max_attention": 3.9140625,
      "attention_bam_384_min_attention": -1.2252197265625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.10464381903344222,
      "attention_bam_384_attention_skewness": 0.36161095213515243,
      "attention_bam_384_attention_sparsity": 0.43433888753255206,
      "attention_bam_384_attention_concentration_10": 0.5769869569588091,
      "attention_bam_384_attention_concentration_20": 0.946078449268123,
      "attention_bam_384_attention_center_y": 0.4821873266196471,
      "attention_bam_384_attention_center_x": 0.48665139298155985,
      "attention_bam_384_attention_center_distance": 0.031479410486471404,
      "attention_bam_384_attention_spatial_variance": 169.5142987498533,
      "attention_bam_384_attention_spatial_std": 13.019765694890722,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 16.76740745741446,
      "attention_bam_384_peak_intensity_mean": 0.2808375656604767,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.25376883149147034,
      "attention_bam_16_std_attention": 0.4990917444229126,
      "attention_bam_16_max_attention": 3.0465087890625,
      "attention_bam_16_min_attention": -0.90576171875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6922083314573007,
      "attention_bam_16_attention_skewness": 0.5307534886530596,
      "attention_bam_16_attention_sparsity": 0.39697265625,
      "attention_bam_16_attention_concentration_10": 0.46908480717673257,
      "attention_bam_16_attention_concentration_20": 0.7737909698602103,
      "attention_bam_16_attention_center_y": 0.4778080741686284,
      "attention_bam_16_attention_center_x": 0.4790521679795775,
      "attention_bam_16_attention_center_distance": 0.04315769313716698,
      "attention_bam_16_attention_spatial_variance": 41.71373772665156,
      "attention_bam_16_attention_spatial_std": 6.458617323131287,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.223289623779307,
      "attention_bam_16_peak_intensity_mean": 0.2977506220340729,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 35,
      "phase": "train",
      "loss": 0.26291152834892273,
      "timestamp": 1759561892.4267561,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.26291152834892273,
      "ssim": 0.009922063909471035,
      "attention_bam_384_mean_attention": 0.21041877567768097,
      "attention_bam_384_std_attention": 0.5056754946708679,
      "attention_bam_384_max_attention": 3.5439453125,
      "attention_bam_384_min_attention": -1.228759765625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.735541976210182,
      "attention_bam_384_attention_skewness": 0.5432131894005443,
      "attention_bam_384_attention_sparsity": 0.43667856852213544,
      "attention_bam_384_attention_concentration_10": 0.5540159482958191,
      "attention_bam_384_attention_concentration_20": 0.8993494684592714,
      "attention_bam_384_attention_center_y": 0.4810781780863097,
      "attention_bam_384_attention_center_x": 0.48612929449607273,
      "attention_bam_384_attention_center_distance": 0.03317926508258097,
      "attention_bam_384_attention_spatial_variance": 170.24509660405084,
      "attention_bam_384_attention_spatial_std": 13.047800450805907,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 15.211052311671292,
      "attention_bam_384_peak_intensity_mean": 0.30795878171920776,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21474532783031464,
      "attention_bam_16_std_attention": 0.4744444489479065,
      "attention_bam_16_max_attention": 3.2972640991210938,
      "attention_bam_16_min_attention": -0.98828125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.2481975021604663,
      "attention_bam_16_attention_skewness": 0.8409192080387388,
      "attention_bam_16_attention_sparsity": 0.425048828125,
      "attention_bam_16_attention_concentration_10": 0.5249944921691035,
      "attention_bam_16_attention_concentration_20": 0.8387875776681429,
      "attention_bam_16_attention_center_y": 0.46923899149949894,
      "attention_bam_16_attention_center_x": 0.46923996454393835,
      "attention_bam_16_attention_center_distance": 0.06152104396425776,
      "attention_bam_16_attention_spatial_variance": 42.06022705478866,
      "attention_bam_16_attention_spatial_std": 6.4853856519707955,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 8.890056420796975,
      "attention_bam_16_peak_intensity_mean": 0.2855604887008667,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 36,
      "phase": "train",
      "loss": 0.37697935104370117,
      "timestamp": 1759561892.5974956,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.37697935104370117,
      "ssim": 0.00878603383898735,
      "attention_bam_384_mean_attention": 0.2099037915468216,
      "attention_bam_384_std_attention": 0.5548276901245117,
      "attention_bam_384_max_attention": 4.859130859375,
      "attention_bam_384_min_attention": -1.1533203125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 4.957280268283276,
      "attention_bam_384_attention_skewness": 1.4127912883547542,
      "attention_bam_384_attention_sparsity": 0.44617462158203125,
      "attention_bam_384_attention_concentration_10": 0.6273365790789112,
      "attention_bam_384_attention_concentration_20": 0.9522493744321978,
      "attention_bam_384_attention_center_y": 0.4833444925213585,
      "attention_bam_384_attention_center_x": 0.48243434414811864,
      "attention_bam_384_attention_center_distance": 0.03423326437480994,
      "attention_bam_384_attention_spatial_variance": 164.15266475440745,
      "attention_bam_384_attention_spatial_std": 12.812207645617029,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 14.134200565366907,
      "attention_bam_384_peak_intensity_mean": 0.23279781639575958,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21014413237571716,
      "attention_bam_16_std_attention": 0.502081036567688,
      "attention_bam_16_max_attention": 3.7984619140625,
      "attention_bam_16_min_attention": -0.82098388671875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 7.916623408832368,
      "attention_bam_16_attention_skewness": 1.7700650649354714,
      "attention_bam_16_attention_sparsity": 0.419677734375,
      "attention_bam_16_attention_concentration_10": 0.5553326090126083,
      "attention_bam_16_attention_concentration_20": 0.8453605571779863,
      "attention_bam_16_attention_center_y": 0.4719951717012494,
      "attention_bam_16_attention_center_x": 0.4696386409326529,
      "attention_bam_16_attention_center_distance": 0.058413740377737895,
      "attention_bam_16_attention_spatial_variance": 41.62552954269211,
      "attention_bam_16_attention_spatial_std": 6.451784988876497,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.063203071756314,
      "attention_bam_16_peak_intensity_mean": 0.22483202815055847,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 37,
      "phase": "train",
      "loss": 0.38056159019470215,
      "timestamp": 1759561892.774695,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.38056159019470215,
      "ssim": 0.011205531656742096,
      "attention_bam_384_mean_attention": 0.2068842500448227,
      "attention_bam_384_std_attention": 0.5677648186683655,
      "attention_bam_384_max_attention": 4.763671875,
      "attention_bam_384_min_attention": -1.284912109375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.6716491447345199,
      "attention_bam_384_attention_skewness": 0.8166567852236954,
      "attention_bam_384_attention_sparsity": 0.4462432861328125,
      "attention_bam_384_attention_concentration_10": 0.6414785612933261,
      "attention_bam_384_attention_concentration_20": 1.0023848475316466,
      "attention_bam_384_attention_center_y": 0.47842303029917094,
      "attention_bam_384_attention_center_x": 0.4848434722599771,
      "attention_bam_384_attention_center_distance": 0.03729037287570558,
      "attention_bam_384_attention_spatial_variance": 167.46909033406624,
      "attention_bam_384_attention_spatial_std": 12.940984905874291,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 16.196759011341413,
      "attention_bam_384_peak_intensity_mean": 0.24596118927001953,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2555862069129944,
      "attention_bam_16_std_attention": 0.5238634943962097,
      "attention_bam_16_max_attention": 3.70782470703125,
      "attention_bam_16_min_attention": -1.079345703125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 4.501042393436651,
      "attention_bam_16_attention_skewness": 1.2095806246323746,
      "attention_bam_16_attention_sparsity": 0.38232421875,
      "attention_bam_16_attention_concentration_10": 0.49671900233316146,
      "attention_bam_16_attention_concentration_20": 0.7734279767418148,
      "attention_bam_16_attention_center_y": 0.4729873190460294,
      "attention_bam_16_attention_center_x": 0.4736729637305009,
      "attention_bam_16_attention_center_distance": 0.05334412378240975,
      "attention_bam_16_attention_spatial_variance": 42.341966982872705,
      "attention_bam_16_attention_spatial_std": 6.507070537720696,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 10.027407879040803,
      "attention_bam_16_peak_intensity_mean": 0.280418336391449,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 38,
      "phase": "train",
      "loss": 0.3243849575519562,
      "timestamp": 1759561892.9519446,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3243849575519562,
      "ssim": 0.01421327330172062,
      "attention_bam_384_mean_attention": 0.20235000550746918,
      "attention_bam_384_std_attention": 0.5802842378616333,
      "attention_bam_384_max_attention": 4.87481689453125,
      "attention_bam_384_min_attention": -1.55712890625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.470079113901943,
      "attention_bam_384_attention_skewness": 1.0325577894793132,
      "attention_bam_384_attention_sparsity": 0.4690450032552083,
      "attention_bam_384_attention_concentration_10": 0.6786476535328093,
      "attention_bam_384_attention_concentration_20": 1.0480335573018718,
      "attention_bam_384_attention_center_y": 0.48797806589544523,
      "attention_bam_384_attention_center_x": 0.48615512292843993,
      "attention_bam_384_attention_center_distance": 0.02593096684432984,
      "attention_bam_384_attention_spatial_variance": 170.72216583809387,
      "attention_bam_384_attention_spatial_std": 13.06606925735869,
      "attention_bam_384_num_attention_peaks": 3,
      "attention_bam_384_peak_separation_mean": 20.174527379615466,
      "attention_bam_384_peak_intensity_mean": 0.27549228072166443,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23087292909622192,
      "attention_bam_16_std_attention": 0.5010107755661011,
      "attention_bam_16_max_attention": 3.952392578125,
      "attention_bam_16_min_attention": -1.1334228515625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 5.535319216778733,
      "attention_bam_16_attention_skewness": 1.3963715883245083,
      "attention_bam_16_attention_sparsity": 0.40771484375,
      "attention_bam_16_attention_concentration_10": 0.52437616256976,
      "attention_bam_16_attention_concentration_20": 0.8072516300172419,
      "attention_bam_16_attention_center_y": 0.47445797842694315,
      "attention_bam_16_attention_center_x": 0.476538638334049,
      "attention_bam_16_attention_center_distance": 0.04904753525426238,
      "attention_bam_16_attention_spatial_variance": 42.021504286589014,
      "attention_bam_16_attention_spatial_std": 6.482399577825253,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 7.873731559528384,
      "attention_bam_16_peak_intensity_mean": 0.2738911509513855,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 39,
      "phase": "train",
      "loss": 0.28543227910995483,
      "timestamp": 1759561893.1350648,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.28543227910995483,
      "ssim": 0.012873800471425056,
      "attention_bam_384_mean_attention": 0.20928359031677246,
      "attention_bam_384_std_attention": 0.5525324940681458,
      "attention_bam_384_max_attention": 3.8701171875,
      "attention_bam_384_min_attention": -1.085205078125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.529704801689041,
      "attention_bam_384_attention_skewness": 0.822020825176353,
      "attention_bam_384_attention_sparsity": 0.4538472493489583,
      "attention_bam_384_attention_concentration_10": 0.6089235690630032,
      "attention_bam_384_attention_concentration_20": 0.9654320066437727,
      "attention_bam_384_attention_center_y": 0.4807025613649719,
      "attention_bam_384_attention_center_x": 0.4854983069526688,
      "attention_bam_384_attention_center_distance": 0.03413766949021822,
      "attention_bam_384_attention_spatial_variance": 165.60559976302608,
      "attention_bam_384_attention_spatial_std": 12.868783927124818,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 13.226573504681806,
      "attention_bam_384_peak_intensity_mean": 0.2627199590206146,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22136399149894714,
      "attention_bam_16_std_attention": 0.5179586410522461,
      "attention_bam_16_max_attention": 3.7078857421875,
      "attention_bam_16_min_attention": -0.7835693359375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 4.227990447527364,
      "attention_bam_16_attention_skewness": 1.2216865459577142,
      "attention_bam_16_attention_sparsity": 0.4306640625,
      "attention_bam_16_attention_concentration_10": 0.5403357722467963,
      "attention_bam_16_attention_concentration_20": 0.8618293605378375,
      "attention_bam_16_attention_center_y": 0.4780762790593959,
      "attention_bam_16_attention_center_x": 0.47488602940126307,
      "attention_bam_16_attention_center_distance": 0.04714575397881987,
      "attention_bam_16_attention_spatial_variance": 41.07386266117738,
      "attention_bam_16_attention_spatial_std": 6.4088893469287935,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.044927065112576,
      "attention_bam_16_peak_intensity_mean": 0.22676727175712585,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 40,
      "phase": "train",
      "loss": 0.3111514151096344,
      "timestamp": 1759561893.4320738,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3111514151096344,
      "ssim": 0.016293345019221306,
      "attention_bam_384_mean_attention": 0.20637619495391846,
      "attention_bam_384_std_attention": 0.6428527235984802,
      "attention_bam_384_max_attention": 5.73388671875,
      "attention_bam_384_min_attention": -1.369873046875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 7.2782291003422,
      "attention_bam_384_attention_skewness": 1.829870958744409,
      "attention_bam_384_attention_sparsity": 0.46249135335286456,
      "attention_bam_384_attention_concentration_10": 0.7325788413375722,
      "attention_bam_384_attention_concentration_20": 1.0746074949162334,
      "attention_bam_384_attention_center_y": 0.4901794521142899,
      "attention_bam_384_attention_center_x": 0.477955041440164,
      "attention_bam_384_attention_center_distance": 0.03412985082535263,
      "attention_bam_384_attention_spatial_variance": 166.31785782477598,
      "attention_bam_384_attention_spatial_std": 12.896428103346135,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 12.815147123707238,
      "attention_bam_384_peak_intensity_mean": 0.22350656986236572,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23247374594211578,
      "attention_bam_16_std_attention": 0.6016060709953308,
      "attention_bam_16_max_attention": 5.371551513671875,
      "attention_bam_16_min_attention": -1.14501953125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 13.427360846551657,
      "attention_bam_16_attention_skewness": 2.4822164809429803,
      "attention_bam_16_attention_sparsity": 0.4052734375,
      "attention_bam_16_attention_concentration_10": 0.5851167443871328,
      "attention_bam_16_attention_concentration_20": 0.8689713108302928,
      "attention_bam_16_attention_center_y": 0.4758694948245887,
      "attention_bam_16_attention_center_x": 0.47013358977878617,
      "attention_bam_16_attention_center_distance": 0.054300713430347834,
      "attention_bam_16_attention_spatial_variance": 41.83541636749105,
      "attention_bam_16_attention_spatial_std": 6.468030331367583,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.263169871660528,
      "attention_bam_16_peak_intensity_mean": 0.21234066784381866,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 41,
      "phase": "train",
      "loss": 0.3168369233608246,
      "timestamp": 1759561893.6209302,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3168369233608246,
      "ssim": 0.013067459687590599,
      "attention_bam_384_mean_attention": 0.20445863902568817,
      "attention_bam_384_std_attention": 0.5789698958396912,
      "attention_bam_384_max_attention": 5.15625,
      "attention_bam_384_min_attention": -1.17431640625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 4.947036920977459,
      "attention_bam_384_attention_skewness": 1.5330234332409374,
      "attention_bam_384_attention_sparsity": 0.4588826497395833,
      "attention_bam_384_attention_concentration_10": 0.6893948345793517,
      "attention_bam_384_attention_concentration_20": 1.0182502910382243,
      "attention_bam_384_attention_center_y": 0.48284172561420813,
      "attention_bam_384_attention_center_x": 0.48982428704889835,
      "attention_bam_384_attention_center_distance": 0.02821175336491297,
      "attention_bam_384_attention_spatial_variance": 172.0055467080783,
      "attention_bam_384_attention_spatial_std": 13.11508851316217,
      "attention_bam_384_num_attention_peaks": 2,
      "attention_bam_384_peak_separation_mean": 26.588231703507848,
      "attention_bam_384_peak_intensity_mean": 0.22405794262886047,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20459800958633423,
      "attention_bam_16_std_attention": 0.5090613961219788,
      "attention_bam_16_max_attention": 3.62103271484375,
      "attention_bam_16_min_attention": -0.8507080078125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 6.0332561418184,
      "attention_bam_16_attention_skewness": 1.6222343924799938,
      "attention_bam_16_attention_sparsity": 0.437255859375,
      "attention_bam_16_attention_concentration_10": 0.5871813079576905,
      "attention_bam_16_attention_concentration_20": 0.8970078672380315,
      "attention_bam_16_attention_center_y": 0.4704993194228227,
      "attention_bam_16_attention_center_x": 0.4631800243931751,
      "attention_bam_16_attention_center_distance": 0.06672332063385072,
      "attention_bam_16_attention_spatial_variance": 42.94831711701396,
      "attention_bam_16_attention_spatial_std": 6.553496556572984,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.104977246871831,
      "attention_bam_16_peak_intensity_mean": 0.23802369832992554,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 42,
      "phase": "train",
      "loss": 0.3130760192871094,
      "timestamp": 1759561893.790868,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3130760192871094,
      "ssim": 0.011615973897278309,
      "attention_bam_384_mean_attention": 0.20067328214645386,
      "attention_bam_384_std_attention": 0.5250174403190613,
      "attention_bam_384_max_attention": 3.76220703125,
      "attention_bam_384_min_attention": -1.1907958984375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7340714786051077,
      "attention_bam_384_attention_skewness": 0.513211748682458,
      "attention_bam_384_attention_sparsity": 0.43742116292317706,
      "attention_bam_384_attention_concentration_10": 0.5909351254531704,
      "attention_bam_384_attention_concentration_20": 0.9539750482587432,
      "attention_bam_384_attention_center_y": 0.48125876628448977,
      "attention_bam_384_attention_center_x": 0.48355715544996886,
      "attention_bam_384_attention_center_distance": 0.03525906913336954,
      "attention_bam_384_attention_spatial_variance": 168.01492184934827,
      "attention_bam_384_attention_spatial_std": 12.962057006870022,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 15.88730496386554,
      "attention_bam_384_peak_intensity_mean": 0.2883421778678894,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2438998818397522,
      "attention_bam_16_std_attention": 0.4829942584037781,
      "attention_bam_16_max_attention": 3.17138671875,
      "attention_bam_16_min_attention": -1.083251953125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.4720564659346937,
      "attention_bam_16_attention_skewness": 0.5658762231239325,
      "attention_bam_16_attention_sparsity": 0.385498046875,
      "attention_bam_16_attention_concentration_10": 0.4691523819461582,
      "attention_bam_16_attention_concentration_20": 0.7624176403364478,
      "attention_bam_16_attention_center_y": 0.46762497110245727,
      "attention_bam_16_attention_center_x": 0.4699809338924944,
      "attention_bam_16_attention_center_distance": 0.062438559017381524,
      "attention_bam_16_attention_spatial_variance": 41.78741524084673,
      "attention_bam_16_attention_spatial_std": 6.46431862154448,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 7.681206167481298,
      "attention_bam_16_peak_intensity_mean": 0.3187369406223297,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 43,
      "phase": "train",
      "loss": 0.3270752429962158,
      "timestamp": 1759561893.9631045,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3270752429962158,
      "ssim": 0.015082726255059242,
      "attention_bam_384_mean_attention": 0.20002351701259613,
      "attention_bam_384_std_attention": 0.5080283880233765,
      "attention_bam_384_max_attention": 4.6240234375,
      "attention_bam_384_min_attention": -1.21484375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9114297966540268,
      "attention_bam_384_attention_skewness": 0.616122632587998,
      "attention_bam_384_attention_sparsity": 0.4474080403645833,
      "attention_bam_384_attention_concentration_10": 0.5901665585134327,
      "attention_bam_384_attention_concentration_20": 0.9433428096888271,
      "attention_bam_384_attention_center_y": 0.4779606355790335,
      "attention_bam_384_attention_center_x": 0.48060673473831506,
      "attention_bam_384_attention_center_distance": 0.04151704039524589,
      "attention_bam_384_attention_spatial_variance": 169.66646903547388,
      "attention_bam_384_attention_spatial_std": 13.025608202132977,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 14.878031639106638,
      "attention_bam_384_peak_intensity_mean": 0.24390487372875214,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2298351228237152,
      "attention_bam_16_std_attention": 0.42409834265708923,
      "attention_bam_16_max_attention": 2.64715576171875,
      "attention_bam_16_min_attention": -0.89642333984375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.4284349681300617,
      "attention_bam_16_attention_skewness": 0.5705934185132594,
      "attention_bam_16_attention_sparsity": 0.373291015625,
      "attention_bam_16_attention_concentration_10": 0.4474131634251131,
      "attention_bam_16_attention_concentration_20": 0.7187578246619346,
      "attention_bam_16_attention_center_y": 0.4723258297132091,
      "attention_bam_16_attention_center_x": 0.46993995974279607,
      "attention_bam_16_attention_center_distance": 0.05778348762972035,
      "attention_bam_16_attention_spatial_variance": 42.39090055874452,
      "attention_bam_16_attention_spatial_std": 6.510829483156852,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.028713153135449,
      "attention_bam_16_peak_intensity_mean": 0.32116371393203735,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 44,
      "phase": "train",
      "loss": 0.3815705180168152,
      "timestamp": 1759561894.133959,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3815705180168152,
      "ssim": 0.015793247148394585,
      "attention_bam_384_mean_attention": 0.2170644998550415,
      "attention_bam_384_std_attention": 0.43143969774246216,
      "attention_bam_384_max_attention": 3.9658203125,
      "attention_bam_384_min_attention": -1.121826171875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.06567493569330773,
      "attention_bam_384_attention_skewness": 0.11487026773021629,
      "attention_bam_384_attention_sparsity": 0.39072418212890625,
      "attention_bam_384_attention_concentration_10": 0.4480229403286221,
      "attention_bam_384_attention_concentration_20": 0.7586064218054703,
      "attention_bam_384_attention_center_y": 0.47590906461638116,
      "attention_bam_384_attention_center_x": 0.4817846351640035,
      "attention_bam_384_attention_center_distance": 0.042712356145877886,
      "attention_bam_384_attention_spatial_variance": 166.46919308714314,
      "attention_bam_384_attention_spatial_std": 12.902294101714746,
      "attention_bam_384_num_attention_peaks": 23,
      "attention_bam_384_peak_separation_mean": 10.781713183503149,
      "attention_bam_384_peak_intensity_mean": 0.27438947558403015,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23258009552955627,
      "attention_bam_16_std_attention": 0.3604208528995514,
      "attention_bam_16_max_attention": 1.5630569458007812,
      "attention_bam_16_min_attention": -0.8240966796875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.3027682619074641,
      "attention_bam_16_attention_skewness": 0.06707449633287875,
      "attention_bam_16_attention_sparsity": 0.34423828125,
      "attention_bam_16_attention_concentration_10": 0.37621905581714365,
      "attention_bam_16_attention_concentration_20": 0.6341691468756265,
      "attention_bam_16_attention_center_y": 0.47250191906890787,
      "attention_bam_16_attention_center_x": 0.4769457856008097,
      "attention_bam_16_attention_center_distance": 0.05074724143156407,
      "attention_bam_16_attention_spatial_variance": 42.14399648705044,
      "attention_bam_16_attention_spatial_std": 6.491840762607354,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 7.978377235156172,
      "attention_bam_16_peak_intensity_mean": 0.4477721154689789,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 45,
      "phase": "train",
      "loss": 0.3710777759552002,
      "timestamp": 1759561894.3009844,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3710777759552002,
      "ssim": 0.012795074842870235,
      "attention_bam_384_mean_attention": 0.21014732122421265,
      "attention_bam_384_std_attention": 0.543440580368042,
      "attention_bam_384_max_attention": 4.0693359375,
      "attention_bam_384_min_attention": -1.2578125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.066208699144485,
      "attention_bam_384_attention_skewness": 0.6333924271008873,
      "attention_bam_384_attention_sparsity": 0.44072214762369794,
      "attention_bam_384_attention_concentration_10": 0.5984146257641167,
      "attention_bam_384_attention_concentration_20": 0.9554840423061546,
      "attention_bam_384_attention_center_y": 0.48774481544209125,
      "attention_bam_384_attention_center_x": 0.4800967632128613,
      "attention_bam_384_attention_center_distance": 0.03305535911628599,
      "attention_bam_384_attention_spatial_variance": 167.50193331194308,
      "attention_bam_384_attention_spatial_std": 12.942253795685783,
      "attention_bam_384_num_attention_peaks": 4,
      "attention_bam_384_peak_separation_mean": 14.452962508697409,
      "attention_bam_384_peak_intensity_mean": 0.28147900104522705,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23214489221572876,
      "attention_bam_16_std_attention": 0.4933653473854065,
      "attention_bam_16_max_attention": 2.9013671875,
      "attention_bam_16_min_attention": -1.1346435546875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.047012742337145,
      "attention_bam_16_attention_skewness": 0.6850543231411442,
      "attention_bam_16_attention_sparsity": 0.39501953125,
      "attention_bam_16_attention_concentration_10": 0.49966358515885734,
      "attention_bam_16_attention_concentration_20": 0.7899004941190362,
      "attention_bam_16_attention_center_y": 0.46863617056308143,
      "attention_bam_16_attention_center_x": 0.4672060187224952,
      "attention_bam_16_attention_center_distance": 0.0641737486045105,
      "attention_bam_16_attention_spatial_variance": 41.981558684576655,
      "attention_bam_16_attention_spatial_std": 6.479317763821794,
      "attention_bam_16_num_attention_peaks": 11,
      "attention_bam_16_peak_separation_mean": 9.014316624801284,
      "attention_bam_16_peak_intensity_mean": 0.3415186107158661,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 46,
      "phase": "train",
      "loss": 0.29428496956825256,
      "timestamp": 1759561894.4696956,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.29428496956825256,
      "ssim": 0.013562352396547794,
      "attention_bam_384_mean_attention": 0.19148056209087372,
      "attention_bam_384_std_attention": 0.4997089207172394,
      "attention_bam_384_max_attention": 3.94189453125,
      "attention_bam_384_min_attention": -1.1983642578125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5254973610560163,
      "attention_bam_384_attention_skewness": 0.45978001628693177,
      "attention_bam_384_attention_sparsity": 0.43939208984375,
      "attention_bam_384_attention_concentration_10": 0.5849224158217323,
      "attention_bam_384_attention_concentration_20": 0.9488535031581514,
      "attention_bam_384_attention_center_y": 0.48814660671614035,
      "attention_bam_384_attention_center_x": 0.4774895883661772,
      "attention_bam_384_attention_center_distance": 0.0359783702873266,
      "attention_bam_384_attention_spatial_variance": 168.08812931997545,
      "attention_bam_384_attention_spatial_std": 12.964880613410038,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 12.405668047510675,
      "attention_bam_384_peak_intensity_mean": 0.270896852016449,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23772552609443665,
      "attention_bam_16_std_attention": 0.4881671667098999,
      "attention_bam_16_max_attention": 2.814117431640625,
      "attention_bam_16_min_attention": -1.0760498046875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.1203859620683314,
      "attention_bam_16_attention_skewness": 0.5493021311557776,
      "attention_bam_16_attention_sparsity": 0.38818359375,
      "attention_bam_16_attention_concentration_10": 0.4856690291541492,
      "attention_bam_16_attention_concentration_20": 0.7860214912142245,
      "attention_bam_16_attention_center_y": 0.4653387861003348,
      "attention_bam_16_attention_center_x": 0.4774995254046299,
      "attention_bam_16_attention_center_distance": 0.05844092925365301,
      "attention_bam_16_attention_spatial_variance": 41.90886837891773,
      "attention_bam_16_attention_spatial_std": 6.473705923110636,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.379682375238426,
      "attention_bam_16_peak_intensity_mean": 0.3408536911010742,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 47,
      "phase": "train",
      "loss": 0.23610316216945648,
      "timestamp": 1759561894.6349547,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.23610316216945648,
      "ssim": 0.023053178563714027,
      "attention_bam_384_mean_attention": 0.17686361074447632,
      "attention_bam_384_std_attention": 0.5187351107597351,
      "attention_bam_384_max_attention": 4.77001953125,
      "attention_bam_384_min_attention": -1.1484375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 4.450997403428944,
      "attention_bam_384_attention_skewness": 1.2677251857083767,
      "attention_bam_384_attention_sparsity": 0.47073109944661456,
      "attention_bam_384_attention_concentration_10": 0.6777827992131437,
      "attention_bam_384_attention_concentration_20": 1.0448302973867825,
      "attention_bam_384_attention_center_y": 0.48835945479809184,
      "attention_bam_384_attention_center_x": 0.47803143707055046,
      "attention_bam_384_attention_center_distance": 0.035160206193446925,
      "attention_bam_384_attention_spatial_variance": 166.8684989024319,
      "attention_bam_384_attention_spatial_std": 12.917759051106035,
      "attention_bam_384_num_attention_peaks": 4,
      "attention_bam_384_peak_separation_mean": 12.407358254736204,
      "attention_bam_384_peak_intensity_mean": 0.22989797592163086,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20484760403633118,
      "attention_bam_16_std_attention": 0.4886791706085205,
      "attention_bam_16_max_attention": 4.937713623046875,
      "attention_bam_16_min_attention": -0.9791259765625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 14.421090344833829,
      "attention_bam_16_attention_skewness": 2.4090435367291376,
      "attention_bam_16_attention_sparsity": 0.434814453125,
      "attention_bam_16_attention_concentration_10": 0.562995732180975,
      "attention_bam_16_attention_concentration_20": 0.8553840849125054,
      "attention_bam_16_attention_center_y": 0.46463494138699274,
      "attention_bam_16_attention_center_x": 0.46825133212428804,
      "attention_bam_16_attention_center_distance": 0.06721108959961448,
      "attention_bam_16_attention_spatial_variance": 41.728599450144586,
      "attention_bam_16_attention_spatial_std": 6.459767755124373,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.044344975736264,
      "attention_bam_16_peak_intensity_mean": 0.2027854025363922,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 48,
      "phase": "train",
      "loss": 0.3098300099372864,
      "timestamp": 1759561894.8018718,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3098300099372864,
      "ssim": 0.018703561276197433,
      "attention_bam_384_mean_attention": 0.20540744066238403,
      "attention_bam_384_std_attention": 0.5026587247848511,
      "attention_bam_384_max_attention": 4.30224609375,
      "attention_bam_384_min_attention": -1.23974609375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.08439773207812884,
      "attention_bam_384_attention_skewness": 0.31763046977569426,
      "attention_bam_384_attention_sparsity": 0.4340769449869792,
      "attention_bam_384_attention_concentration_10": 0.5511240272398734,
      "attention_bam_384_attention_concentration_20": 0.9094440728557528,
      "attention_bam_384_attention_center_y": 0.4830106658042467,
      "attention_bam_384_attention_center_x": 0.48461887034388446,
      "attention_bam_384_attention_center_distance": 0.03241038802338627,
      "attention_bam_384_attention_spatial_variance": 169.16124095214835,
      "attention_bam_384_attention_spatial_std": 13.00620009657503,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 14.2080556944813,
      "attention_bam_384_peak_intensity_mean": 0.26263749599456787,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24457034468650818,
      "attention_bam_16_std_attention": 0.47045955061912537,
      "attention_bam_16_max_attention": 2.78387451171875,
      "attention_bam_16_min_attention": -1.00115966796875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5942419093785891,
      "attention_bam_16_attention_skewness": 0.4486847103782806,
      "attention_bam_16_attention_sparsity": 0.37939453125,
      "attention_bam_16_attention_concentration_10": 0.46216114482603676,
      "attention_bam_16_attention_concentration_20": 0.7563028404884083,
      "attention_bam_16_attention_center_y": 0.464652248459176,
      "attention_bam_16_attention_center_x": 0.46943194603583194,
      "attention_bam_16_attention_center_distance": 0.06608887141036854,
      "attention_bam_16_attention_spatial_variance": 42.31841824969467,
      "attention_bam_16_attention_spatial_std": 6.505260813349045,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.742705661071488,
      "attention_bam_16_peak_intensity_mean": 0.33778491616249084,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 49,
      "phase": "train",
      "loss": 0.26980265974998474,
      "timestamp": 1759561894.968279,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.26980265974998474,
      "ssim": 0.031933754682540894,
      "attention_bam_384_mean_attention": 0.20950239896774292,
      "attention_bam_384_std_attention": 0.5180281400680542,
      "attention_bam_384_max_attention": 4.1453857421875,
      "attention_bam_384_min_attention": -1.278564453125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.0464347717561733,
      "attention_bam_384_attention_skewness": 0.7697306347554864,
      "attention_bam_384_attention_sparsity": 0.43368275960286456,
      "attention_bam_384_attention_concentration_10": 0.569887471322933,
      "attention_bam_384_attention_concentration_20": 0.9074754938568883,
      "attention_bam_384_attention_center_y": 0.4778418028820801,
      "attention_bam_384_attention_center_x": 0.48011637888432407,
      "attention_bam_384_attention_center_distance": 0.042103303627823475,
      "attention_bam_384_attention_spatial_variance": 169.47868841323032,
      "attention_bam_384_attention_spatial_std": 13.018398074003972,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 16.135788618302463,
      "attention_bam_384_peak_intensity_mean": 0.27694377303123474,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22860297560691833,
      "attention_bam_16_std_attention": 0.5432708263397217,
      "attention_bam_16_max_attention": 3.8021240234375,
      "attention_bam_16_min_attention": -0.941741943359375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.872168221169235,
      "attention_bam_16_attention_skewness": 1.0714173882094578,
      "attention_bam_16_attention_sparsity": 0.41162109375,
      "attention_bam_16_attention_concentration_10": 0.5468772304949141,
      "attention_bam_16_attention_concentration_20": 0.8603701149863862,
      "attention_bam_16_attention_center_y": 0.4752872959657386,
      "attention_bam_16_attention_center_x": 0.47329673072208606,
      "attention_bam_16_attention_center_distance": 0.051454491170621494,
      "attention_bam_16_attention_spatial_variance": 43.40952091255824,
      "attention_bam_16_attention_spatial_std": 6.588590206755786,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 10.314217634753092,
      "attention_bam_16_peak_intensity_mean": 0.2520168423652649,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 50,
      "phase": "train",
      "loss": 0.3179776966571808,
      "timestamp": 1759561895.2573755,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3179776966571808,
      "ssim": 0.024813691154122353,
      "attention_bam_384_mean_attention": 0.19781000912189484,
      "attention_bam_384_std_attention": 0.543398380279541,
      "attention_bam_384_max_attention": 4.99853515625,
      "attention_bam_384_min_attention": -1.328857421875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.791729662855703,
      "attention_bam_384_attention_skewness": 0.9483397491663681,
      "attention_bam_384_attention_sparsity": 0.44573720296223956,
      "attention_bam_384_attention_concentration_10": 0.6383328257719267,
      "attention_bam_384_attention_concentration_20": 0.9909619264723161,
      "attention_bam_384_attention_center_y": 0.48292078954490175,
      "attention_bam_384_attention_center_x": 0.4799466866861676,
      "attention_bam_384_attention_center_distance": 0.03725143768050478,
      "attention_bam_384_attention_spatial_variance": 167.55787866393803,
      "attention_bam_384_attention_spatial_std": 12.944414960280671,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 16.53875685595516,
      "attention_bam_384_peak_intensity_mean": 0.24577821791172028,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21372327208518982,
      "attention_bam_16_std_attention": 0.48502853512763977,
      "attention_bam_16_max_attention": 4.48223876953125,
      "attention_bam_16_min_attention": -1.1007080078125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 9.071704571323174,
      "attention_bam_16_attention_skewness": 1.5553178009878923,
      "attention_bam_16_attention_sparsity": 0.393798828125,
      "attention_bam_16_attention_concentration_10": 0.5247576715830745,
      "attention_bam_16_attention_concentration_20": 0.807380270658989,
      "attention_bam_16_attention_center_y": 0.46704956690623994,
      "attention_bam_16_attention_center_x": 0.46791493579862814,
      "attention_bam_16_attention_center_distance": 0.0650412543832376,
      "attention_bam_16_attention_spatial_variance": 42.08159545160792,
      "attention_bam_16_attention_spatial_std": 6.487032869625983,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 10.060642915583694,
      "attention_bam_16_peak_intensity_mean": 0.24246802926063538,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 51,
      "phase": "train",
      "loss": 0.34341341257095337,
      "timestamp": 1759561895.4952629,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.34341341257095337,
      "ssim": 0.021573074162006378,
      "attention_bam_384_mean_attention": 0.1927391141653061,
      "attention_bam_384_std_attention": 0.5332438945770264,
      "attention_bam_384_max_attention": 5.1669921875,
      "attention_bam_384_min_attention": -1.3182373046875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2928407392633385,
      "attention_bam_384_attention_skewness": 0.601050559222626,
      "attention_bam_384_attention_sparsity": 0.4448750813802083,
      "attention_bam_384_attention_concentration_10": 0.6228651285857147,
      "attention_bam_384_attention_concentration_20": 0.998073473150801,
      "attention_bam_384_attention_center_y": 0.4805465633010315,
      "attention_bam_384_attention_center_x": 0.4875215865540173,
      "attention_bam_384_attention_center_distance": 0.03268476714096816,
      "attention_bam_384_attention_spatial_variance": 171.7731027896837,
      "attention_bam_384_attention_spatial_std": 13.106223818845903,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 18.0893683962962,
      "attention_bam_384_peak_intensity_mean": 0.2360241860151291,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22769713401794434,
      "attention_bam_16_std_attention": 0.5143418908119202,
      "attention_bam_16_max_attention": 4.0484619140625,
      "attention_bam_16_min_attention": -1.1505126953125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.104471567178149,
      "attention_bam_16_attention_skewness": 0.9139364283888322,
      "attention_bam_16_attention_sparsity": 0.421142578125,
      "attention_bam_16_attention_concentration_10": 0.5291189500598219,
      "attention_bam_16_attention_concentration_20": 0.847785896469663,
      "attention_bam_16_attention_center_y": 0.4785021284341648,
      "attention_bam_16_attention_center_x": 0.4679353236975062,
      "attention_bam_16_attention_center_distance": 0.05459490723950092,
      "attention_bam_16_attention_spatial_variance": 42.241048370896046,
      "attention_bam_16_attention_spatial_std": 6.499311376668766,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.04128336651877,
      "attention_bam_16_peak_intensity_mean": 0.26757797598838806,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 52,
      "phase": "train",
      "loss": 0.28550463914871216,
      "timestamp": 1759561895.6756823,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.28550463914871216,
      "ssim": 0.029550574719905853,
      "attention_bam_384_mean_attention": 0.19877557456493378,
      "attention_bam_384_std_attention": 0.48330503702163696,
      "attention_bam_384_max_attention": 4.7171630859375,
      "attention_bam_384_min_attention": -1.25732421875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 4.881121208173555,
      "attention_bam_384_attention_skewness": 1.1156902241840683,
      "attention_bam_384_attention_sparsity": 0.42879486083984375,
      "attention_bam_384_attention_concentration_10": 0.5548290693715106,
      "attention_bam_384_attention_concentration_20": 0.8761796203424029,
      "attention_bam_384_attention_center_y": 0.4866167428032836,
      "attention_bam_384_attention_center_x": 0.48576994647097843,
      "attention_bam_384_attention_center_distance": 0.027626291703096186,
      "attention_bam_384_attention_spatial_variance": 166.56140114728473,
      "attention_bam_384_attention_spatial_std": 12.905866927381698,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 15.398975497143795,
      "attention_bam_384_peak_intensity_mean": 0.24863596260547638,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21523723006248474,
      "attention_bam_16_std_attention": 0.46818679571151733,
      "attention_bam_16_max_attention": 4.89813232421875,
      "attention_bam_16_min_attention": -0.8036766052246094,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 11.638033551919088,
      "attention_bam_16_attention_skewness": 1.8303630260160422,
      "attention_bam_16_attention_sparsity": 0.401611328125,
      "attention_bam_16_attention_concentration_10": 0.4897389812387065,
      "attention_bam_16_attention_concentration_20": 0.7777305773819129,
      "attention_bam_16_attention_center_y": 0.46472613590377043,
      "attention_bam_16_attention_center_x": 0.47681358838442156,
      "attention_bam_16_attention_center_distance": 0.05969682021492105,
      "attention_bam_16_attention_spatial_variance": 42.88695408164949,
      "attention_bam_16_attention_spatial_std": 6.548813181153474,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.889438493710148,
      "attention_bam_16_peak_intensity_mean": 0.18517246842384338,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 53,
      "phase": "train",
      "loss": 0.28366100788116455,
      "timestamp": 1759561895.8531492,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.28366100788116455,
      "ssim": 0.027410278096795082,
      "attention_bam_384_mean_attention": 0.1886613816022873,
      "attention_bam_384_std_attention": 0.5426255464553833,
      "attention_bam_384_max_attention": 3.8895263671875,
      "attention_bam_384_min_attention": -1.234130859375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.808497734773908,
      "attention_bam_384_attention_skewness": 0.533571978189605,
      "attention_bam_384_attention_sparsity": 0.45601654052734375,
      "attention_bam_384_attention_concentration_10": 0.6363287016627198,
      "attention_bam_384_attention_concentration_20": 1.031431379334246,
      "attention_bam_384_attention_center_y": 0.4880816901648093,
      "attention_bam_384_attention_center_x": 0.48405265680389603,
      "attention_bam_384_attention_center_distance": 0.028155420946664147,
      "attention_bam_384_attention_spatial_variance": 167.28846077392018,
      "attention_bam_384_attention_spatial_std": 12.934004050328737,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 14.688594786551903,
      "attention_bam_384_peak_intensity_mean": 0.2853670120239258,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22603605687618256,
      "attention_bam_16_std_attention": 0.5109683871269226,
      "attention_bam_16_max_attention": 4.29833984375,
      "attention_bam_16_min_attention": -1.00946044921875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 4.700405714740637,
      "attention_bam_16_attention_skewness": 1.1301953727573204,
      "attention_bam_16_attention_sparsity": 0.40673828125,
      "attention_bam_16_attention_concentration_10": 0.5309830435297648,
      "attention_bam_16_attention_concentration_20": 0.8403677679084747,
      "attention_bam_16_attention_center_y": 0.4669805985827391,
      "attention_bam_16_attention_center_x": 0.4712147512079511,
      "attention_bam_16_attention_center_distance": 0.06194951844807777,
      "attention_bam_16_attention_spatial_variance": 41.58461836658298,
      "attention_bam_16_attention_spatial_std": 6.4486136778832535,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.886687842471892,
      "attention_bam_16_peak_intensity_mean": 0.23462624847888947,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 54,
      "phase": "train",
      "loss": 0.3018132448196411,
      "timestamp": 1759561896.0230954,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3018132448196411,
      "ssim": 0.02841363102197647,
      "attention_bam_384_mean_attention": 0.1934506744146347,
      "attention_bam_384_std_attention": 0.6049466729164124,
      "attention_bam_384_max_attention": 6.48480224609375,
      "attention_bam_384_min_attention": -1.32861328125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 9.616331818313785,
      "attention_bam_384_attention_skewness": 1.7560472595907037,
      "attention_bam_384_attention_sparsity": 0.46102142333984375,
      "attention_bam_384_attention_concentration_10": 0.6930677475539804,
      "attention_bam_384_attention_concentration_20": 1.0673144500527576,
      "attention_bam_384_attention_center_y": 0.47606921112669665,
      "attention_bam_384_attention_center_x": 0.4803605953674274,
      "attention_bam_384_attention_center_distance": 0.043781020326633155,
      "attention_bam_384_attention_spatial_variance": 172.64699390254063,
      "attention_bam_384_attention_spatial_std": 13.139520307170297,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 20.933291705935822,
      "attention_bam_384_peak_intensity_mean": 0.20082202553749084,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22474230825901031,
      "attention_bam_16_std_attention": 0.6224356889724731,
      "attention_bam_16_max_attention": 8.320465087890625,
      "attention_bam_16_min_attention": -1.2979736328125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 18.97067354440745,
      "attention_bam_16_attention_skewness": 2.32888687502016,
      "attention_bam_16_attention_sparsity": 0.43212890625,
      "attention_bam_16_attention_concentration_10": 0.6024733392627039,
      "attention_bam_16_attention_concentration_20": 0.9348552641518856,
      "attention_bam_16_attention_center_y": 0.4750714950325382,
      "attention_bam_16_attention_center_x": 0.4733798338958367,
      "attention_bam_16_attention_center_distance": 0.051576421033763316,
      "attention_bam_16_attention_spatial_variance": 42.712399643311024,
      "attention_bam_16_attention_spatial_std": 6.535472411640265,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.057796649798641,
      "attention_bam_16_peak_intensity_mean": 0.15957677364349365,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 55,
      "phase": "train",
      "loss": 0.2516891360282898,
      "timestamp": 1759561896.1905243,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.2516891360282898,
      "ssim": 0.026414263993501663,
      "attention_bam_384_mean_attention": 0.18564654886722565,
      "attention_bam_384_std_attention": 0.4422983229160309,
      "attention_bam_384_max_attention": 4.32470703125,
      "attention_bam_384_min_attention": -1.1888427734375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.41718127415575657,
      "attention_bam_384_attention_skewness": 0.24872570097734503,
      "attention_bam_384_attention_sparsity": 0.4206797281901042,
      "attention_bam_384_attention_concentration_10": 0.5275518341008387,
      "attention_bam_384_attention_concentration_20": 0.871901573829301,
      "attention_bam_384_attention_center_y": 0.4895570153021939,
      "attention_bam_384_attention_center_x": 0.4828145505586215,
      "attention_bam_384_attention_center_distance": 0.028439254628094202,
      "attention_bam_384_attention_spatial_variance": 171.47091981976308,
      "attention_bam_384_attention_spatial_std": 13.09469052019799,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 19.463378742492804,
      "attention_bam_384_peak_intensity_mean": 0.25350847840309143,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23757833242416382,
      "attention_bam_16_std_attention": 0.40704143047332764,
      "attention_bam_16_max_attention": 2.478424072265625,
      "attention_bam_16_min_attention": -1.0604248046875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.2799263945820325,
      "attention_bam_16_attention_skewness": 0.49314473095030326,
      "attention_bam_16_attention_sparsity": 0.35693359375,
      "attention_bam_16_attention_concentration_10": 0.42538811154776623,
      "attention_bam_16_attention_concentration_20": 0.6916552535201358,
      "attention_bam_16_attention_center_y": 0.4722935826179994,
      "attention_bam_16_attention_center_x": 0.4727256141347534,
      "attention_bam_16_attention_center_distance": 0.054982500642877054,
      "attention_bam_16_attention_spatial_variance": 42.40809668801668,
      "attention_bam_16_attention_spatial_std": 6.512149928250783,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.071112395324596,
      "attention_bam_16_peak_intensity_mean": 0.37235909700393677,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 56,
      "phase": "train",
      "loss": 0.2977958917617798,
      "timestamp": 1759561896.3577018,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.2977958917617798,
      "ssim": 0.03110702708363533,
      "attention_bam_384_mean_attention": 0.1978563815355301,
      "attention_bam_384_std_attention": 0.45167824625968933,
      "attention_bam_384_max_attention": 4.728515625,
      "attention_bam_384_min_attention": -1.1588134765625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.37262018204400515,
      "attention_bam_384_attention_skewness": 0.28867198666815286,
      "attention_bam_384_attention_sparsity": 0.4237467447916667,
      "attention_bam_384_attention_concentration_10": 0.5132146728231218,
      "attention_bam_384_attention_concentration_20": 0.846260226754328,
      "attention_bam_384_attention_center_y": 0.48453622480236075,
      "attention_bam_384_attention_center_x": 0.48012764465180596,
      "attention_bam_384_attention_center_distance": 0.035610078642092854,
      "attention_bam_384_attention_spatial_variance": 169.0708231536015,
      "attention_bam_384_attention_spatial_std": 13.002723682121431,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 16.289734199342355,
      "attention_bam_384_peak_intensity_mean": 0.23231996595859528,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2463318556547165,
      "attention_bam_16_std_attention": 0.403676837682724,
      "attention_bam_16_max_attention": 2.9744873046875,
      "attention_bam_16_min_attention": -0.8299560546875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.0896035256243533,
      "attention_bam_16_attention_skewness": 0.5755025254042107,
      "attention_bam_16_attention_sparsity": 0.34228515625,
      "attention_bam_16_attention_concentration_10": 0.40295175424321056,
      "attention_bam_16_attention_concentration_20": 0.6519745175242143,
      "attention_bam_16_attention_center_y": 0.46937752459155113,
      "attention_bam_16_attention_center_x": 0.4716150809226072,
      "attention_bam_16_attention_center_distance": 0.05904980323711831,
      "attention_bam_16_attention_spatial_variance": 41.95163530903499,
      "attention_bam_16_attention_spatial_std": 6.477008206651817,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 8.534031410436562,
      "attention_bam_16_peak_intensity_mean": 0.2853168249130249,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 57,
      "phase": "train",
      "loss": 0.21936550736427307,
      "timestamp": 1759561896.5251825,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.21936550736427307,
      "ssim": 0.03744059056043625,
      "attention_bam_384_mean_attention": 0.1858268827199936,
      "attention_bam_384_std_attention": 0.5090001225471497,
      "attention_bam_384_max_attention": 4.6103515625,
      "attention_bam_384_min_attention": -1.15576171875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9994639025338663,
      "attention_bam_384_attention_skewness": 0.5612203994485699,
      "attention_bam_384_attention_sparsity": 0.45328013102213544,
      "attention_bam_384_attention_concentration_10": 0.6096249823451024,
      "attention_bam_384_attention_concentration_20": 0.9902608507475359,
      "attention_bam_384_attention_center_y": 0.4852770599615158,
      "attention_bam_384_attention_center_x": 0.49242736568174994,
      "attention_bam_384_attention_center_distance": 0.02341408780605125,
      "attention_bam_384_attention_spatial_variance": 171.59618966886524,
      "attention_bam_384_attention_spatial_std": 13.099472877519355,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 18.502376104015156,
      "attention_bam_384_peak_intensity_mean": 0.23330900073051453,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22627981007099152,
      "attention_bam_16_std_attention": 0.49935439229011536,
      "attention_bam_16_max_attention": 3.9670791625976562,
      "attention_bam_16_min_attention": -0.9364013671875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 4.472463211052026,
      "attention_bam_16_attention_skewness": 1.1500186786489868,
      "attention_bam_16_attention_sparsity": 0.420166015625,
      "attention_bam_16_attention_concentration_10": 0.5213221189454902,
      "attention_bam_16_attention_concentration_20": 0.8276377128676851,
      "attention_bam_16_attention_center_y": 0.47681454721661104,
      "attention_bam_16_attention_center_x": 0.47624686997839394,
      "attention_bam_16_attention_center_distance": 0.04694201543594143,
      "attention_bam_16_attention_spatial_variance": 43.39277494225124,
      "attention_bam_16_attention_spatial_std": 6.587319253099188,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 10.182917154358373,
      "attention_bam_16_peak_intensity_mean": 0.24408094584941864,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 58,
      "phase": "train",
      "loss": 0.23050940036773682,
      "timestamp": 1759561896.6983156,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.23050940036773682,
      "ssim": 0.03559616953134537,
      "attention_bam_384_mean_attention": 0.18527013063430786,
      "attention_bam_384_std_attention": 0.48376187682151794,
      "attention_bam_384_max_attention": 4.515869140625,
      "attention_bam_384_min_attention": -1.3739013671875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.374086764441712,
      "attention_bam_384_attention_skewness": 0.7278906630574989,
      "attention_bam_384_attention_sparsity": 0.43592580159505206,
      "attention_bam_384_attention_concentration_10": 0.5817537271776823,
      "attention_bam_384_attention_concentration_20": 0.9327387350345119,
      "attention_bam_384_attention_center_y": 0.47893917114902107,
      "attention_bam_384_attention_center_x": 0.48913464176210636,
      "attention_bam_384_attention_center_distance": 0.03351460939733565,
      "attention_bam_384_attention_spatial_variance": 166.88800991032497,
      "attention_bam_384_attention_spatial_std": 12.918514229985002,
      "attention_bam_384_num_attention_peaks": 2,
      "attention_bam_384_peak_separation_mean": 16.688884087370308,
      "attention_bam_384_peak_intensity_mean": 0.27017003297805786,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20919552445411682,
      "attention_bam_16_std_attention": 0.4394896626472473,
      "attention_bam_16_max_attention": 3.6439208984375,
      "attention_bam_16_min_attention": -1.2073974609375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 5.731333234811428,
      "attention_bam_16_attention_skewness": 1.1872336493509137,
      "attention_bam_16_attention_sparsity": 0.409423828125,
      "attention_bam_16_attention_concentration_10": 0.4866846158687842,
      "attention_bam_16_attention_concentration_20": 0.7719422512000268,
      "attention_bam_16_attention_center_y": 0.47332376997943804,
      "attention_bam_16_attention_center_x": 0.47322013828365556,
      "attention_bam_16_attention_center_distance": 0.05345619218867842,
      "attention_bam_16_attention_spatial_variance": 41.66989844580347,
      "attention_bam_16_attention_spatial_std": 6.455222571360609,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 10.600798850840372,
      "attention_bam_16_peak_intensity_mean": 0.29066959023475647,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 59,
      "phase": "train",
      "loss": 0.2731233835220337,
      "timestamp": 1759561896.8705013,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.2731233835220337,
      "ssim": 0.02806875668466091,
      "attention_bam_384_mean_attention": 0.20186330378055573,
      "attention_bam_384_std_attention": 0.4568077325820923,
      "attention_bam_384_max_attention": 4.21337890625,
      "attention_bam_384_min_attention": -1.170166015625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.3931620848001489,
      "attention_bam_384_attention_skewness": 0.3487112999483815,
      "attention_bam_384_attention_sparsity": 0.4234670003255208,
      "attention_bam_384_attention_concentration_10": 0.5059586443575335,
      "attention_bam_384_attention_concentration_20": 0.842341025144004,
      "attention_bam_384_attention_center_y": 0.4773846456922936,
      "attention_bam_384_attention_center_x": 0.48151803204134896,
      "attention_bam_384_attention_center_distance": 0.04130465809294873,
      "attention_bam_384_attention_spatial_variance": 168.77957179721412,
      "attention_bam_384_attention_spatial_std": 12.99151922591096,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 10.63091887324903,
      "attention_bam_384_peak_intensity_mean": 0.2602928578853607,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2314862608909607,
      "attention_bam_16_std_attention": 0.43973013758659363,
      "attention_bam_16_max_attention": 3.57647705078125,
      "attention_bam_16_min_attention": -0.9163818359375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.2744306562317,
      "attention_bam_16_attention_skewness": 0.9043556842154847,
      "attention_bam_16_attention_sparsity": 0.3974609375,
      "attention_bam_16_attention_concentration_10": 0.44964627757369785,
      "attention_bam_16_attention_concentration_20": 0.7287393834917909,
      "attention_bam_16_attention_center_y": 0.46774312808702034,
      "attention_bam_16_attention_center_x": 0.4734329282016619,
      "attention_bam_16_attention_center_distance": 0.05909847865298103,
      "attention_bam_16_attention_spatial_variance": 42.83621925806621,
      "attention_bam_16_attention_spatial_std": 6.5449384457049105,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.909198907463537,
      "attention_bam_16_peak_intensity_mean": 0.2613445520401001,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 60,
      "phase": "train",
      "loss": 0.2889419198036194,
      "timestamp": 1759561897.1477654,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.2889419198036194,
      "ssim": 0.04596628248691559,
      "attention_bam_384_mean_attention": 0.19856120645999908,
      "attention_bam_384_std_attention": 0.5066681504249573,
      "attention_bam_384_max_attention": 4.5076904296875,
      "attention_bam_384_min_attention": -1.39501953125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5034051669654485,
      "attention_bam_384_attention_skewness": 0.619498818928519,
      "attention_bam_384_attention_sparsity": 0.4430084228515625,
      "attention_bam_384_attention_concentration_10": 0.5719565999823361,
      "attention_bam_384_attention_concentration_20": 0.9280096794917879,
      "attention_bam_384_attention_center_y": 0.4862607202298221,
      "attention_bam_384_attention_center_x": 0.48911530534044906,
      "attention_bam_384_attention_center_distance": 0.024788884058580644,
      "attention_bam_384_attention_spatial_variance": 168.71950519777192,
      "attention_bam_384_attention_spatial_std": 12.989207258249902,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 9.438956126072714,
      "attention_bam_384_peak_intensity_mean": 0.27743417024612427,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22565136849880219,
      "attention_bam_16_std_attention": 0.4771805703639984,
      "attention_bam_16_max_attention": 4.162353515625,
      "attention_bam_16_min_attention": -1.228515625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.8000382325163278,
      "attention_bam_16_attention_skewness": 0.8950617118184987,
      "attention_bam_16_attention_sparsity": 0.406494140625,
      "attention_bam_16_attention_concentration_10": 0.48737787180219805,
      "attention_bam_16_attention_concentration_20": 0.7871505685599512,
      "attention_bam_16_attention_center_y": 0.4676257523365438,
      "attention_bam_16_attention_center_x": 0.46419815124700253,
      "attention_bam_16_attention_center_distance": 0.06826220456310074,
      "attention_bam_16_attention_spatial_variance": 41.945784406791674,
      "attention_bam_16_attention_spatial_std": 6.4765565238629454,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.060514312864601,
      "attention_bam_16_peak_intensity_mean": 0.27478766441345215,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 61,
      "phase": "train",
      "loss": 0.2865070700645447,
      "timestamp": 1759561897.3361166,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.2865070700645447,
      "ssim": 0.04808909446001053,
      "attention_bam_384_mean_attention": 0.18424542248249054,
      "attention_bam_384_std_attention": 0.517902135848999,
      "attention_bam_384_max_attention": 4.92529296875,
      "attention_bam_384_min_attention": -1.2493896484375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.334618182412206,
      "attention_bam_384_attention_skewness": 0.856885798903948,
      "attention_bam_384_attention_sparsity": 0.4578094482421875,
      "attention_bam_384_attention_concentration_10": 0.6443734191301178,
      "attention_bam_384_attention_concentration_20": 1.0145139159674645,
      "attention_bam_384_attention_center_y": 0.4793384263924519,
      "attention_bam_384_attention_center_x": 0.49014413141576085,
      "attention_bam_384_attention_center_distance": 0.032374025683869496,
      "attention_bam_384_attention_spatial_variance": 170.85597627749934,
      "attention_bam_384_attention_spatial_std": 13.071188785932952,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 18.47132152657398,
      "attention_bam_384_peak_intensity_mean": 0.23197484016418457,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21553188562393188,
      "attention_bam_16_std_attention": 0.47501593828201294,
      "attention_bam_16_max_attention": 4.89349365234375,
      "attention_bam_16_min_attention": -1.183837890625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 10.178256092744299,
      "attention_bam_16_attention_skewness": 1.7166216436069301,
      "attention_bam_16_attention_sparsity": 0.411376953125,
      "attention_bam_16_attention_concentration_10": 0.5194823735949619,
      "attention_bam_16_attention_concentration_20": 0.8110332478251063,
      "attention_bam_16_attention_center_y": 0.4670550904097451,
      "attention_bam_16_attention_center_x": 0.476566862212517,
      "attention_bam_16_attention_center_distance": 0.05717480239541253,
      "attention_bam_16_attention_spatial_variance": 42.75008639843482,
      "attention_bam_16_attention_spatial_std": 6.538355022361115,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.267771975914918,
      "attention_bam_16_peak_intensity_mean": 0.23369376361370087,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 62,
      "phase": "train",
      "loss": 0.25887250900268555,
      "timestamp": 1759561897.5049508,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.25887250900268555,
      "ssim": 0.03922828286886215,
      "attention_bam_384_mean_attention": 0.1839427798986435,
      "attention_bam_384_std_attention": 0.5153570175170898,
      "attention_bam_384_max_attention": 3.80859375,
      "attention_bam_384_min_attention": -1.192138671875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5954796652567032,
      "attention_bam_384_attention_skewness": 0.5605486050004038,
      "attention_bam_384_attention_sparsity": 0.45415496826171875,
      "attention_bam_384_attention_concentration_10": 0.6300293158141103,
      "attention_bam_384_attention_concentration_20": 1.0143697283568316,
      "attention_bam_384_attention_center_y": 0.4871256390348798,
      "attention_bam_384_attention_center_x": 0.4802458909005981,
      "attention_bam_384_attention_center_distance": 0.033345884200940985,
      "attention_bam_384_attention_spatial_variance": 169.11958182287685,
      "attention_bam_384_attention_spatial_std": 13.004598487568805,
      "attention_bam_384_num_attention_peaks": 2,
      "attention_bam_384_peak_separation_mean": 20.32958584083657,
      "attention_bam_384_peak_intensity_mean": 0.27656039595603943,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23444530367851257,
      "attention_bam_16_std_attention": 0.5147183537483215,
      "attention_bam_16_max_attention": 3.37164306640625,
      "attention_bam_16_min_attention": -0.8446044921875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.4598853350349605,
      "attention_bam_16_attention_skewness": 1.1456443712103845,
      "attention_bam_16_attention_sparsity": 0.42236328125,
      "attention_bam_16_attention_concentration_10": 0.5273270969816871,
      "attention_bam_16_attention_concentration_20": 0.8268540002626603,
      "attention_bam_16_attention_center_y": 0.4664857790478972,
      "attention_bam_16_attention_center_x": 0.4763894431855561,
      "attention_bam_16_attention_center_distance": 0.05797691608070321,
      "attention_bam_16_attention_spatial_variance": 41.31589719144642,
      "attention_bam_16_attention_spatial_std": 6.4277443315245835,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.882219612520858,
      "attention_bam_16_peak_intensity_mean": 0.26051512360572815,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 63,
      "phase": "train",
      "loss": 0.2851073443889618,
      "timestamp": 1759561897.6939855,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.2851073443889618,
      "ssim": 0.020429354161024094,
      "attention_bam_384_mean_attention": 0.2100030779838562,
      "attention_bam_384_std_attention": 0.46403035521507263,
      "attention_bam_384_max_attention": 4.00634765625,
      "attention_bam_384_min_attention": -1.30517578125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.694653049050304,
      "attention_bam_384_attention_skewness": 0.4677545043885484,
      "attention_bam_384_attention_sparsity": 0.43015797932942706,
      "attention_bam_384_attention_concentration_10": 0.5119461567913478,
      "attention_bam_384_attention_concentration_20": 0.8409495126728426,
      "attention_bam_384_attention_center_y": 0.48319537350552993,
      "attention_bam_384_attention_center_x": 0.48316260622212953,
      "attention_bam_384_attention_center_distance": 0.03364203622998217,
      "attention_bam_384_attention_spatial_variance": 169.51790663496087,
      "attention_bam_384_attention_spatial_std": 13.019904248302323,
      "attention_bam_384_num_attention_peaks": 19,
      "attention_bam_384_peak_separation_mean": 16.17585649945904,
      "attention_bam_384_peak_intensity_mean": 0.28673362731933594,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2648122310638428,
      "attention_bam_16_std_attention": 0.4258951246738434,
      "attention_bam_16_max_attention": 4.21630859375,
      "attention_bam_16_min_attention": -0.9898681640625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 7.264275418648401,
      "attention_bam_16_attention_skewness": 1.204089212085271,
      "attention_bam_16_attention_sparsity": 0.349609375,
      "attention_bam_16_attention_concentration_10": 0.3904302894167046,
      "attention_bam_16_attention_concentration_20": 0.6361706279657889,
      "attention_bam_16_attention_center_y": 0.4735572938272561,
      "attention_bam_16_attention_center_x": 0.4803822844703542,
      "attention_bam_16_attention_center_distance": 0.04656332188193138,
      "attention_bam_16_attention_spatial_variance": 42.11979166689643,
      "attention_bam_16_attention_spatial_std": 6.489976245480135,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 7.907197596990333,
      "attention_bam_16_peak_intensity_mean": 0.24419815838336945,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 64,
      "phase": "train",
      "loss": 0.2794792652130127,
      "timestamp": 1759561897.8651667,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.2794792652130127,
      "ssim": 0.044352225959300995,
      "attention_bam_384_mean_attention": 0.1925942301750183,
      "attention_bam_384_std_attention": 0.4793716371059418,
      "attention_bam_384_max_attention": 3.9755859375,
      "attention_bam_384_min_attention": -1.1749267578125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6131824610292305,
      "attention_bam_384_attention_skewness": 0.4897330529795727,
      "attention_bam_384_attention_sparsity": 0.44355010986328125,
      "attention_bam_384_attention_concentration_10": 0.5729866710818822,
      "attention_bam_384_attention_concentration_20": 0.9273597951633801,
      "attention_bam_384_attention_center_y": 0.4864874103141027,
      "attention_bam_384_attention_center_x": 0.48237534354145994,
      "attention_bam_384_attention_center_distance": 0.031407597657285916,
      "attention_bam_384_attention_spatial_variance": 173.32840184786198,
      "attention_bam_384_attention_spatial_std": 13.165424484150217,
      "attention_bam_384_num_attention_peaks": 3,
      "attention_bam_384_peak_separation_mean": 26.592365482226523,
      "attention_bam_384_peak_intensity_mean": 0.271841436624527,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2303624153137207,
      "attention_bam_16_std_attention": 0.4457898437976837,
      "attention_bam_16_max_attention": 4.064399719238281,
      "attention_bam_16_min_attention": -0.953369140625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.860342337131997,
      "attention_bam_16_attention_skewness": 0.9272152958621364,
      "attention_bam_16_attention_sparsity": 0.390625,
      "attention_bam_16_attention_concentration_10": 0.4696882665209327,
      "attention_bam_16_attention_concentration_20": 0.7543706207680269,
      "attention_bam_16_attention_center_y": 0.4642806859899439,
      "attention_bam_16_attention_center_x": 0.4760792079009134,
      "attention_bam_16_attention_center_distance": 0.060795948680758584,
      "attention_bam_16_attention_spatial_variance": 42.05107894696461,
      "attention_bam_16_attention_spatial_std": 6.484680327276327,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.16826318165583,
      "attention_bam_16_peak_intensity_mean": 0.23950158059597015,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 65,
      "phase": "train",
      "loss": 0.21714279055595398,
      "timestamp": 1759561898.0321255,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.21714279055595398,
      "ssim": 0.04991630092263222,
      "attention_bam_384_mean_attention": 0.20178121328353882,
      "attention_bam_384_std_attention": 0.5155739188194275,
      "attention_bam_384_max_attention": 4.072509765625,
      "attention_bam_384_min_attention": -1.140625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1732335901507396,
      "attention_bam_384_attention_skewness": 0.56287075888559,
      "attention_bam_384_attention_sparsity": 0.4378712972005208,
      "attention_bam_384_attention_concentration_10": 0.5674531096502912,
      "attention_bam_384_attention_concentration_20": 0.9273862367405781,
      "attention_bam_384_attention_center_y": 0.48055669405592094,
      "attention_bam_384_attention_center_x": 0.48290092904870474,
      "attention_bam_384_attention_center_distance": 0.03661749236177948,
      "attention_bam_384_attention_spatial_variance": 169.23990252730397,
      "attention_bam_384_attention_spatial_std": 13.00922374806829,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 16.336963068192688,
      "attention_bam_384_peak_intensity_mean": 0.264900267124176,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23389364778995514,
      "attention_bam_16_std_attention": 0.5180310606956482,
      "attention_bam_16_max_attention": 4.7000732421875,
      "attention_bam_16_min_attention": -0.8133544921875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 4.749148599672142,
      "attention_bam_16_attention_skewness": 1.121914853977987,
      "attention_bam_16_attention_sparsity": 0.425537109375,
      "attention_bam_16_attention_concentration_10": 0.503839462666828,
      "attention_bam_16_attention_concentration_20": 0.8189375648513296,
      "attention_bam_16_attention_center_y": 0.47714176191182295,
      "attention_bam_16_attention_center_x": 0.4633677342690863,
      "attention_bam_16_attention_center_distance": 0.061064260268606604,
      "attention_bam_16_attention_spatial_variance": 42.363145313586635,
      "attention_bam_16_attention_spatial_std": 6.508697666475732,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.117413213024964,
      "attention_bam_16_peak_intensity_mean": 0.1949911266565323,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 66,
      "phase": "train",
      "loss": 0.23329941928386688,
      "timestamp": 1759561898.2021565,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.23329941928386688,
      "ssim": 0.037602394819259644,
      "attention_bam_384_mean_attention": 0.17472340166568756,
      "attention_bam_384_std_attention": 0.4710453450679779,
      "attention_bam_384_max_attention": 5.04150390625,
      "attention_bam_384_min_attention": -1.18603515625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.3262826869124842,
      "attention_bam_384_attention_skewness": 0.6240342399133533,
      "attention_bam_384_attention_sparsity": 0.43914794921875,
      "attention_bam_384_attention_concentration_10": 0.6053102886849498,
      "attention_bam_384_attention_concentration_20": 0.9632101778949231,
      "attention_bam_384_attention_center_y": 0.4778793609443882,
      "attention_bam_384_attention_center_x": 0.4938636171259986,
      "attention_bam_384_attention_center_distance": 0.03246468441260428,
      "attention_bam_384_attention_spatial_variance": 170.58824130539548,
      "attention_bam_384_attention_spatial_std": 13.06094335434449,
      "attention_bam_384_num_attention_peaks": 3,
      "attention_bam_384_peak_separation_mean": 16.83139395228454,
      "attention_bam_384_peak_intensity_mean": 0.21745885908603668,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2154495120048523,
      "attention_bam_16_std_attention": 0.43196386098861694,
      "attention_bam_16_max_attention": 3.247314453125,
      "attention_bam_16_min_attention": -0.859130859375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.7314053516513184,
      "attention_bam_16_attention_skewness": 0.7968368540969181,
      "attention_bam_16_attention_sparsity": 0.389892578125,
      "attention_bam_16_attention_concentration_10": 0.4752808230247171,
      "attention_bam_16_attention_concentration_20": 0.7656431077615795,
      "attention_bam_16_attention_center_y": 0.47138609449880753,
      "attention_bam_16_attention_center_x": 0.4750334672327685,
      "attention_bam_16_attention_center_distance": 0.05370443829793616,
      "attention_bam_16_attention_spatial_variance": 42.34774772324424,
      "attention_bam_16_attention_spatial_std": 6.507514711719386,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 7.573963794724229,
      "attention_bam_16_peak_intensity_mean": 0.26624858379364014,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 67,
      "phase": "train",
      "loss": 0.2632102370262146,
      "timestamp": 1759561898.3731844,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.2632102370262146,
      "ssim": 0.03638575226068497,
      "attention_bam_384_mean_attention": 0.18643729388713837,
      "attention_bam_384_std_attention": 0.46394243836402893,
      "attention_bam_384_max_attention": 4.26513671875,
      "attention_bam_384_min_attention": -1.1357421875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5468314946120696,
      "attention_bam_384_attention_skewness": 0.7406986215440196,
      "attention_bam_384_attention_sparsity": 0.43841298421223956,
      "attention_bam_384_attention_concentration_10": 0.5839081956618429,
      "attention_bam_384_attention_concentration_20": 0.9185173944252696,
      "attention_bam_384_attention_center_y": 0.4810922327674473,
      "attention_bam_384_attention_center_x": 0.4821688544163139,
      "attention_bam_384_attention_center_distance": 0.03675468445101936,
      "attention_bam_384_attention_spatial_variance": 168.5192773438198,
      "attention_bam_384_attention_spatial_std": 12.981497500050592,
      "attention_bam_384_num_attention_peaks": 2,
      "attention_bam_384_peak_separation_mean": 18.290303223862896,
      "attention_bam_384_peak_intensity_mean": 0.24860244989395142,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20987927913665771,
      "attention_bam_16_std_attention": 0.43032923340797424,
      "attention_bam_16_max_attention": 2.952056884765625,
      "attention_bam_16_min_attention": -0.72265625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 4.328335440580349,
      "attention_bam_16_attention_skewness": 1.2208508449148705,
      "attention_bam_16_attention_sparsity": 0.399169921875,
      "attention_bam_16_attention_concentration_10": 0.5005328454242737,
      "attention_bam_16_attention_concentration_20": 0.7713405127154189,
      "attention_bam_16_attention_center_y": 0.4684778456550656,
      "attention_bam_16_attention_center_x": 0.4684323430258489,
      "attention_bam_16_attention_center_distance": 0.06308982772814545,
      "attention_bam_16_attention_spatial_variance": 42.10465681736011,
      "attention_bam_16_attention_spatial_std": 6.488810123386267,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.90846109205564,
      "attention_bam_16_peak_intensity_mean": 0.26233893632888794,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 68,
      "phase": "train",
      "loss": 0.2571694850921631,
      "timestamp": 1759561898.5530639,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.2571694850921631,
      "ssim": 0.053891342133283615,
      "attention_bam_384_mean_attention": 0.18182696402072906,
      "attention_bam_384_std_attention": 0.5013434886932373,
      "attention_bam_384_max_attention": 4.136474609375,
      "attention_bam_384_min_attention": -1.212646484375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.9724838039394834,
      "attention_bam_384_attention_skewness": 1.0265701964806841,
      "attention_bam_384_attention_sparsity": 0.46272532145182294,
      "attention_bam_384_attention_concentration_10": 0.6426811949012454,
      "attention_bam_384_attention_concentration_20": 1.0004861417900135,
      "attention_bam_384_attention_center_y": 0.48183911784454103,
      "attention_bam_384_attention_center_x": 0.4880852869953453,
      "attention_bam_384_attention_center_distance": 0.03071735752462296,
      "attention_bam_384_attention_spatial_variance": 170.00690927088706,
      "attention_bam_384_attention_spatial_std": 13.038669766156634,
      "attention_bam_384_num_attention_peaks": 2,
      "attention_bam_384_peak_separation_mean": 23.66227881306486,
      "attention_bam_384_peak_intensity_mean": 0.2657957673072815,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.201073557138443,
      "attention_bam_16_std_attention": 0.4577004313468933,
      "attention_bam_16_max_attention": 3.988037109375,
      "attention_bam_16_min_attention": -0.96337890625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 7.524301713328981,
      "attention_bam_16_attention_skewness": 1.6298486705616273,
      "attention_bam_16_attention_sparsity": 0.435302734375,
      "attention_bam_16_attention_concentration_10": 0.5461210829959707,
      "attention_bam_16_attention_concentration_20": 0.8435747391777323,
      "attention_bam_16_attention_center_y": 0.4687374893001246,
      "attention_bam_16_attention_center_x": 0.47674950310953645,
      "attention_bam_16_attention_center_distance": 0.055098642105105976,
      "attention_bam_16_attention_spatial_variance": 42.10424717179754,
      "attention_bam_16_attention_spatial_std": 6.488778557771681,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.032101400256876,
      "attention_bam_16_peak_intensity_mean": 0.23792792856693268,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 69,
      "phase": "train",
      "loss": 0.18394526839256287,
      "timestamp": 1759561898.7484503,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.18394526839256287,
      "ssim": 0.05117392912507057,
      "attention_bam_384_mean_attention": 0.1873633712530136,
      "attention_bam_384_std_attention": 0.4916772246360779,
      "attention_bam_384_max_attention": 4.1722412109375,
      "attention_bam_384_min_attention": -1.19384765625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.9773910141848576,
      "attention_bam_384_attention_skewness": 0.9058657574892792,
      "attention_bam_384_attention_sparsity": 0.4408467610677083,
      "attention_bam_384_attention_concentration_10": 0.5943124651190295,
      "attention_bam_384_attention_concentration_20": 0.9454954117611218,
      "attention_bam_384_attention_center_y": 0.4837577291193181,
      "attention_bam_384_attention_center_x": 0.4966933049074629,
      "attention_bam_384_attention_center_distance": 0.023441228457419073,
      "attention_bam_384_attention_spatial_variance": 170.79711392261592,
      "attention_bam_384_attention_spatial_std": 13.068936985180391,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 17.06815339468497,
      "attention_bam_384_peak_intensity_mean": 0.26063933968544006,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20047637820243835,
      "attention_bam_16_std_attention": 0.4531845450401306,
      "attention_bam_16_max_attention": 4.338958740234375,
      "attention_bam_16_min_attention": -0.758056640625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 9.908300788354396,
      "attention_bam_16_attention_skewness": 1.7993330886961616,
      "attention_bam_16_attention_sparsity": 0.430908203125,
      "attention_bam_16_attention_concentration_10": 0.5225860953714127,
      "attention_bam_16_attention_concentration_20": 0.8272852266577178,
      "attention_bam_16_attention_center_y": 0.4654638928959029,
      "attention_bam_16_attention_center_x": 0.4727437324816658,
      "attention_bam_16_attention_center_distance": 0.06221972055444586,
      "attention_bam_16_attention_spatial_variance": 41.25698073967317,
      "attention_bam_16_attention_spatial_std": 6.423159716189001,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 7.34401506935491,
      "attention_bam_16_peak_intensity_mean": 0.1959642767906189,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 70,
      "phase": "train",
      "loss": 0.17453041672706604,
      "timestamp": 1759561899.1135461,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.17453041672706604,
      "ssim": 0.058838505297899246,
      "attention_bam_384_mean_attention": 0.1677233725786209,
      "attention_bam_384_std_attention": 0.523624062538147,
      "attention_bam_384_max_attention": 5.4053955078125,
      "attention_bam_384_min_attention": -1.342529296875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 8.26112325754609,
      "attention_bam_384_attention_skewness": 1.754364437818365,
      "attention_bam_384_attention_sparsity": 0.47412363688151044,
      "attention_bam_384_attention_concentration_10": 0.7159584206863001,
      "attention_bam_384_attention_concentration_20": 1.0789855805529749,
      "attention_bam_384_attention_center_y": 0.4897784075216617,
      "attention_bam_384_attention_center_x": 0.4931547321763385,
      "attention_bam_384_attention_center_distance": 0.017397623077356174,
      "attention_bam_384_attention_spatial_variance": 170.27329913937137,
      "attention_bam_384_attention_spatial_std": 13.048881145116288,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 16.553007939145854,
      "attention_bam_384_peak_intensity_mean": 0.22841131687164307,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1790696680545807,
      "attention_bam_16_std_attention": 0.464398056268692,
      "attention_bam_16_max_attention": 5.2740478515625,
      "attention_bam_16_min_attention": -0.845453143119812,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 16.991411266464937,
      "attention_bam_16_attention_skewness": 2.645561641234492,
      "attention_bam_16_attention_sparsity": 0.46923828125,
      "attention_bam_16_attention_concentration_10": 0.6068240155121964,
      "attention_bam_16_attention_concentration_20": 0.9134965476749279,
      "attention_bam_16_attention_center_y": 0.4610563459132345,
      "attention_bam_16_attention_center_x": 0.4810060745349776,
      "attention_bam_16_attention_center_distance": 0.06127605402113408,
      "attention_bam_16_attention_spatial_variance": 42.126425414641716,
      "attention_bam_16_attention_spatial_std": 6.490487301785723,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 8.951043817614467,
      "attention_bam_16_peak_intensity_mean": 0.17246055603027344,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 71,
      "phase": "train",
      "loss": 0.22047963738441467,
      "timestamp": 1759561899.3203456,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.22047963738441467,
      "ssim": 0.06570248305797577,
      "attention_bam_384_mean_attention": 0.18931008875370026,
      "attention_bam_384_std_attention": 0.5906841158866882,
      "attention_bam_384_max_attention": 4.74951171875,
      "attention_bam_384_min_attention": -1.2412109375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5269620130819117,
      "attention_bam_384_attention_skewness": 0.8268602133102708,
      "attention_bam_384_attention_sparsity": 0.46941375732421875,
      "attention_bam_384_attention_concentration_10": 0.7234592695497664,
      "attention_bam_384_attention_concentration_20": 1.1233257093690758,
      "attention_bam_384_attention_center_y": 0.48995338359217466,
      "attention_bam_384_attention_center_x": 0.4787417028040229,
      "attention_bam_384_attention_center_distance": 0.03325205861051232,
      "attention_bam_384_attention_spatial_variance": 168.72146991401377,
      "attention_bam_384_attention_spatial_std": 12.989282886826885,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 14.398865479587096,
      "attention_bam_384_peak_intensity_mean": 0.2400418519973755,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2078617513179779,
      "attention_bam_16_std_attention": 0.5552895665168762,
      "attention_bam_16_max_attention": 5.298309326171875,
      "attention_bam_16_min_attention": -1.166748046875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 7.24839226907905,
      "attention_bam_16_attention_skewness": 1.4576038177864046,
      "attention_bam_16_attention_sparsity": 0.44091796875,
      "attention_bam_16_attention_concentration_10": 0.6084254295069981,
      "attention_bam_16_attention_concentration_20": 0.9403494753701302,
      "attention_bam_16_attention_center_y": 0.46389420238186163,
      "attention_bam_16_attention_center_x": 0.4662424956356786,
      "attention_bam_16_attention_center_distance": 0.06990275706364013,
      "attention_bam_16_attention_spatial_variance": 42.163115588886086,
      "attention_bam_16_attention_spatial_std": 6.493313144218911,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.30955051588553,
      "attention_bam_16_peak_intensity_mean": 0.21718241274356842,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 72,
      "phase": "train",
      "loss": 0.22797761857509613,
      "timestamp": 1759561899.5045967,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.22797761857509613,
      "ssim": 0.05239962786436081,
      "attention_bam_384_mean_attention": 0.20450609922409058,
      "attention_bam_384_std_attention": 0.5456167459487915,
      "attention_bam_384_max_attention": 5.7646484375,
      "attention_bam_384_min_attention": -1.216552734375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8602028803302506,
      "attention_bam_384_attention_skewness": 0.7213449197624631,
      "attention_bam_384_attention_sparsity": 0.4440968831380208,
      "attention_bam_384_attention_concentration_10": 0.5959674167106268,
      "attention_bam_384_attention_concentration_20": 0.9637248304183078,
      "attention_bam_384_attention_center_y": 0.4814999940978002,
      "attention_bam_384_attention_center_x": 0.48389904438885806,
      "attention_bam_384_attention_center_distance": 0.03468403061852502,
      "attention_bam_384_attention_spatial_variance": 168.72499405087447,
      "attention_bam_384_attention_spatial_std": 12.989418541677471,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 16.11660544287671,
      "attention_bam_384_peak_intensity_mean": 0.2044840008020401,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22430342435836792,
      "attention_bam_16_std_attention": 0.5357726812362671,
      "attention_bam_16_max_attention": 4.5856170654296875,
      "attention_bam_16_min_attention": -0.905517578125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 4.535827497164308,
      "attention_bam_16_attention_skewness": 1.1474276213681953,
      "attention_bam_16_attention_sparsity": 0.443359375,
      "attention_bam_16_attention_concentration_10": 0.5526353394017794,
      "attention_bam_16_attention_concentration_20": 0.8859699903203616,
      "attention_bam_16_attention_center_y": 0.4772056899046325,
      "attention_bam_16_attention_center_x": 0.48516751516132656,
      "attention_bam_16_attention_center_distance": 0.03845993185675838,
      "attention_bam_16_attention_spatial_variance": 42.71002323521435,
      "attention_bam_16_attention_spatial_std": 6.535290600670666,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.840674058816074,
      "attention_bam_16_peak_intensity_mean": 0.2095799297094345,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 73,
      "phase": "train",
      "loss": 0.21875092387199402,
      "timestamp": 1759561899.68388,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.21875092387199402,
      "ssim": 0.05593167245388031,
      "attention_bam_384_mean_attention": 0.18527990579605103,
      "attention_bam_384_std_attention": 0.4937731921672821,
      "attention_bam_384_max_attention": 4.36376953125,
      "attention_bam_384_min_attention": -1.21142578125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.6741962549342704,
      "attention_bam_384_attention_skewness": 0.7243271206387273,
      "attention_bam_384_attention_sparsity": 0.45092519124348956,
      "attention_bam_384_attention_concentration_10": 0.6118212292970122,
      "attention_bam_384_attention_concentration_20": 0.9705304080458974,
      "attention_bam_384_attention_center_y": 0.48205319329737806,
      "attention_bam_384_attention_center_x": 0.483090014273315,
      "attention_bam_384_attention_center_distance": 0.03487220922448036,
      "attention_bam_384_attention_spatial_variance": 170.47521476147622,
      "attention_bam_384_attention_spatial_std": 13.056615746872396,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 20.027661468825663,
      "attention_bam_384_peak_intensity_mean": 0.2520119547843933,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21483340859413147,
      "attention_bam_16_std_attention": 0.47944217920303345,
      "attention_bam_16_max_attention": 4.167093276977539,
      "attention_bam_16_min_attention": -1.09765625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 4.041031551835918,
      "attention_bam_16_attention_skewness": 1.1507257278483898,
      "attention_bam_16_attention_sparsity": 0.44580078125,
      "attention_bam_16_attention_concentration_10": 0.5371562462787218,
      "attention_bam_16_attention_concentration_20": 0.8541715306300985,
      "attention_bam_16_attention_center_y": 0.47598320394345767,
      "attention_bam_16_attention_center_x": 0.47117101614021684,
      "attention_bam_16_attention_center_distance": 0.0530644288240095,
      "attention_bam_16_attention_spatial_variance": 42.75199899733128,
      "attention_bam_16_attention_spatial_std": 6.538501280670616,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 9.484974593799029,
      "attention_bam_16_peak_intensity_mean": 0.2566923201084137,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 74,
      "phase": "train",
      "loss": 0.2370455265045166,
      "timestamp": 1759561899.8547325,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.2370455265045166,
      "ssim": 0.06998513638973236,
      "attention_bam_384_mean_attention": 0.17225563526153564,
      "attention_bam_384_std_attention": 0.5498421788215637,
      "attention_bam_384_max_attention": 4.98046875,
      "attention_bam_384_min_attention": -1.22021484375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.2219525311345256,
      "attention_bam_384_attention_skewness": 1.2288861834457774,
      "attention_bam_384_attention_sparsity": 0.48403676350911456,
      "attention_bam_384_attention_concentration_10": 0.753305685987402,
      "attention_bam_384_attention_concentration_20": 1.133955946486013,
      "attention_bam_384_attention_center_y": 0.4678507265121213,
      "attention_bam_384_attention_center_x": 0.49133964962186993,
      "attention_bam_384_attention_center_distance": 0.047086674430679404,
      "attention_bam_384_attention_spatial_variance": 172.55985060511523,
      "attention_bam_384_attention_spatial_std": 13.136203812559975,
      "attention_bam_384_num_attention_peaks": 2,
      "attention_bam_384_peak_separation_mean": 21.81790001915113,
      "attention_bam_384_peak_intensity_mean": 0.2444012314081192,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20285984873771667,
      "attention_bam_16_std_attention": 0.5080795288085938,
      "attention_bam_16_max_attention": 3.9051513671875,
      "attention_bam_16_min_attention": -0.8709716796875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 6.207982335257876,
      "attention_bam_16_attention_skewness": 1.5113929243727255,
      "attention_bam_16_attention_sparsity": 0.437744140625,
      "attention_bam_16_attention_concentration_10": 0.5884612949213921,
      "attention_bam_16_attention_concentration_20": 0.8993266632739545,
      "attention_bam_16_attention_center_y": 0.46692451215703623,
      "attention_bam_16_attention_center_x": 0.478847152596236,
      "attention_bam_16_attention_center_distance": 0.055523523831561145,
      "attention_bam_16_attention_spatial_variance": 42.38582431121599,
      "attention_bam_16_attention_spatial_std": 6.510439640394187,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 10.109347177225816,
      "attention_bam_16_peak_intensity_mean": 0.23852553963661194,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 75,
      "phase": "train",
      "loss": 0.23623055219650269,
      "timestamp": 1759561900.038176,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.23623055219650269,
      "ssim": 0.09072452783584595,
      "attention_bam_384_mean_attention": 0.1841244250535965,
      "attention_bam_384_std_attention": 0.48409122228622437,
      "attention_bam_384_max_attention": 5.4453125,
      "attention_bam_384_min_attention": -1.293701171875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.34732613121981837,
      "attention_bam_384_attention_skewness": 0.27099193692956985,
      "attention_bam_384_attention_sparsity": 0.43189748128255206,
      "attention_bam_384_attention_concentration_10": 0.5695831551976783,
      "attention_bam_384_attention_concentration_20": 0.9417761575502035,
      "attention_bam_384_attention_center_y": 0.47695503354449215,
      "attention_bam_384_attention_center_x": 0.4861171594721384,
      "attention_bam_384_attention_center_distance": 0.03804743723452392,
      "attention_bam_384_attention_spatial_variance": 168.02301762947357,
      "attention_bam_384_attention_spatial_std": 12.962369290738232,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 7.723304571237251,
      "attention_bam_384_peak_intensity_mean": 0.21881002187728882,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22444604337215424,
      "attention_bam_16_std_attention": 0.4566630423069,
      "attention_bam_16_max_attention": 2.31756591796875,
      "attention_bam_16_min_attention": -1.005126953125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.822215376968523,
      "attention_bam_16_attention_skewness": 0.4197797099176877,
      "attention_bam_16_attention_sparsity": 0.388916015625,
      "attention_bam_16_attention_concentration_10": 0.4738332125300471,
      "attention_bam_16_attention_concentration_20": 0.7776973784629433,
      "attention_bam_16_attention_center_y": 0.4771046755773896,
      "attention_bam_16_attention_center_x": 0.4701804898742792,
      "attention_bam_16_attention_center_distance": 0.053167641748615206,
      "attention_bam_16_attention_spatial_variance": 41.736179646281464,
      "attention_bam_16_attention_spatial_std": 6.4603544520623215,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.669767731309689,
      "attention_bam_16_peak_intensity_mean": 0.38045644760131836,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 76,
      "phase": "train",
      "loss": 0.18074417114257812,
      "timestamp": 1759561900.205854,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.18074417114257812,
      "ssim": 0.08040137588977814,
      "attention_bam_384_mean_attention": 0.1865512728691101,
      "attention_bam_384_std_attention": 0.5171400308609009,
      "attention_bam_384_max_attention": 4.290283203125,
      "attention_bam_384_min_attention": -1.1552734375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.2398576941645496,
      "attention_bam_384_attention_skewness": 0.8592424136985344,
      "attention_bam_384_attention_sparsity": 0.45742543538411456,
      "attention_bam_384_attention_concentration_10": 0.6399800712140106,
      "attention_bam_384_attention_concentration_20": 1.0073401663336552,
      "attention_bam_384_attention_center_y": 0.4796441251205463,
      "attention_bam_384_attention_center_x": 0.4855596466210261,
      "attention_bam_384_attention_center_distance": 0.035295479818742134,
      "attention_bam_384_attention_spatial_variance": 170.03818431055137,
      "attention_bam_384_attention_spatial_std": 13.039869029654836,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 18.45523286032405,
      "attention_bam_384_peak_intensity_mean": 0.24978022277355194,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.217772975564003,
      "attention_bam_16_std_attention": 0.4715286195278168,
      "attention_bam_16_max_attention": 4.26385498046875,
      "attention_bam_16_min_attention": -1.0169677734375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 6.37953645790318,
      "attention_bam_16_attention_skewness": 1.4011307465856166,
      "attention_bam_16_attention_sparsity": 0.4169921875,
      "attention_bam_16_attention_concentration_10": 0.5260477661265942,
      "attention_bam_16_attention_concentration_20": 0.8138128188651764,
      "attention_bam_16_attention_center_y": 0.4638717122269454,
      "attention_bam_16_attention_center_x": 0.4712660020954658,
      "attention_bam_16_attention_center_distance": 0.06528239905197145,
      "attention_bam_16_attention_spatial_variance": 42.28749421575013,
      "attention_bam_16_attention_spatial_std": 6.502883530846153,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.394629195500599,
      "attention_bam_16_peak_intensity_mean": 0.2365097999572754,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 77,
      "phase": "train",
      "loss": 0.19181376695632935,
      "timestamp": 1759561900.3847234,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.19181376695632935,
      "ssim": 0.08428648114204407,
      "attention_bam_384_mean_attention": 0.19792009890079498,
      "attention_bam_384_std_attention": 0.4931405484676361,
      "attention_bam_384_max_attention": 4.671875,
      "attention_bam_384_min_attention": -1.314697265625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.874290330490986,
      "attention_bam_384_attention_skewness": 0.7862393269806988,
      "attention_bam_384_attention_sparsity": 0.4311625162760417,
      "attention_bam_384_attention_concentration_10": 0.5576309936761736,
      "attention_bam_384_attention_concentration_20": 0.8977681898922167,
      "attention_bam_384_attention_center_y": 0.4836664143471049,
      "attention_bam_384_attention_center_x": 0.4855629524319992,
      "attention_bam_384_attention_center_distance": 0.030829024076709875,
      "attention_bam_384_attention_spatial_variance": 167.11268064338373,
      "attention_bam_384_attention_spatial_std": 12.927206993135977,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 14.659563848901149,
      "attention_bam_384_peak_intensity_mean": 0.25589868426322937,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21893008053302765,
      "attention_bam_16_std_attention": 0.4644608795642853,
      "attention_bam_16_max_attention": 4.146728515625,
      "attention_bam_16_min_attention": -1.077880859375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 7.972302642190879,
      "attention_bam_16_attention_skewness": 1.5032474201090442,
      "attention_bam_16_attention_sparsity": 0.421875,
      "attention_bam_16_attention_concentration_10": 0.49757173031109864,
      "attention_bam_16_attention_concentration_20": 0.7899133067511486,
      "attention_bam_16_attention_center_y": 0.4700471125830379,
      "attention_bam_16_attention_center_x": 0.470975589477028,
      "attention_bam_16_attention_center_distance": 0.05898460597171461,
      "attention_bam_16_attention_spatial_variance": 41.7198119882335,
      "attention_bam_16_attention_spatial_std": 6.459087550748442,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.550810691236476,
      "attention_bam_16_peak_intensity_mean": 0.24938097596168518,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 78,
      "phase": "train",
      "loss": 0.22506855428218842,
      "timestamp": 1759561900.5594182,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.22506855428218842,
      "ssim": 0.0856553465127945,
      "attention_bam_384_mean_attention": 0.19222591817378998,
      "attention_bam_384_std_attention": 0.5536720752716064,
      "attention_bam_384_max_attention": 4.842983245849609,
      "attention_bam_384_min_attention": -1.192626953125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.520542817445981,
      "attention_bam_384_attention_skewness": 0.8479400948443694,
      "attention_bam_384_attention_sparsity": 0.45648193359375,
      "attention_bam_384_attention_concentration_10": 0.6453689578974835,
      "attention_bam_384_attention_concentration_20": 1.0297829044136615,
      "attention_bam_384_attention_center_y": 0.4820469479200373,
      "attention_bam_384_attention_center_x": 0.4797002940715786,
      "attention_bam_384_attention_center_distance": 0.03832466933363519,
      "attention_bam_384_attention_spatial_variance": 167.93510185778788,
      "attention_bam_384_attention_spatial_std": 12.958977654807029,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 16.897837273376688,
      "attention_bam_384_peak_intensity_mean": 0.23289412260055542,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20762044191360474,
      "attention_bam_16_std_attention": 0.5092981457710266,
      "attention_bam_16_max_attention": 5.586090087890625,
      "attention_bam_16_min_attention": -1.0518798828125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 10.408496581763968,
      "attention_bam_16_attention_skewness": 1.739814304098536,
      "attention_bam_16_attention_sparsity": 0.440673828125,
      "attention_bam_16_attention_concentration_10": 0.5626099354768478,
      "attention_bam_16_attention_concentration_20": 0.8971201963094273,
      "attention_bam_16_attention_center_y": 0.4773130873024192,
      "attention_bam_16_attention_center_x": 0.46634894005734284,
      "attention_bam_16_attention_center_distance": 0.05739494477760139,
      "attention_bam_16_attention_spatial_variance": 41.96688206897633,
      "attention_bam_16_attention_spatial_std": 6.478185090669788,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.903292868570892,
      "attention_bam_16_peak_intensity_mean": 0.19190476834774017,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 79,
      "phase": "train",
      "loss": 0.2196781039237976,
      "timestamp": 1759561900.7386208,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.2196781039237976,
      "ssim": 0.10288958251476288,
      "attention_bam_384_mean_attention": 0.2041345238685608,
      "attention_bam_384_std_attention": 0.5376307964324951,
      "attention_bam_384_max_attention": 5.2421875,
      "attention_bam_384_min_attention": -1.267822265625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.074868744437948,
      "attention_bam_384_attention_skewness": 0.5953230284780431,
      "attention_bam_384_attention_sparsity": 0.43744150797526044,
      "attention_bam_384_attention_concentration_10": 0.604420275699971,
      "attention_bam_384_attention_concentration_20": 0.9659122596324606,
      "attention_bam_384_attention_center_y": 0.47660604205869805,
      "attention_bam_384_attention_center_x": 0.48582657784884636,
      "attention_bam_384_attention_center_distance": 0.038682377476939464,
      "attention_bam_384_attention_spatial_variance": 167.91577741181382,
      "attention_bam_384_attention_spatial_std": 12.958232032642949,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 13.72587509955839,
      "attention_bam_384_peak_intensity_mean": 0.23136362433433533,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21525312960147858,
      "attention_bam_16_std_attention": 0.5026288628578186,
      "attention_bam_16_max_attention": 3.8111572265625,
      "attention_bam_16_min_attention": -1.02001953125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.3368898300927192,
      "attention_bam_16_attention_skewness": 0.9671691466928823,
      "attention_bam_16_attention_sparsity": 0.42724609375,
      "attention_bam_16_attention_concentration_10": 0.5500073275894873,
      "attention_bam_16_attention_concentration_20": 0.8703426760253185,
      "attention_bam_16_attention_center_y": 0.46503248598466146,
      "attention_bam_16_attention_center_x": 0.47749628740143213,
      "attention_bam_16_attention_center_distance": 0.058807212434051646,
      "attention_bam_16_attention_spatial_variance": 42.71460383962128,
      "attention_bam_16_attention_spatial_std": 6.535641042745637,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.837471515376219,
      "attention_bam_16_peak_intensity_mean": 0.2567446231842041,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 80,
      "phase": "train",
      "loss": 0.24085359275341034,
      "timestamp": 1759561901.0190184,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.24085359275341034,
      "ssim": 0.10932691395282745,
      "attention_bam_384_mean_attention": 0.19547085464000702,
      "attention_bam_384_std_attention": 0.4963949918746948,
      "attention_bam_384_max_attention": 4.9775390625,
      "attention_bam_384_min_attention": -1.1541748046875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.33350408908145956,
      "attention_bam_384_attention_skewness": 0.3943418993835501,
      "attention_bam_384_attention_sparsity": 0.44006601969401044,
      "attention_bam_384_attention_concentration_10": 0.5710823540890685,
      "attention_bam_384_attention_concentration_20": 0.9328263726612037,
      "attention_bam_384_attention_center_y": 0.4785361526619485,
      "attention_bam_384_attention_center_x": 0.4925357005574551,
      "attention_bam_384_attention_center_distance": 0.032137595078635145,
      "attention_bam_384_attention_spatial_variance": 168.64658310645407,
      "attention_bam_384_attention_spatial_std": 12.986399928635112,
      "attention_bam_384_num_attention_peaks": 4,
      "attention_bam_384_peak_separation_mean": 13.069984547002798,
      "attention_bam_384_peak_intensity_mean": 0.22447997331619263,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2230057418346405,
      "attention_bam_16_std_attention": 0.43484923243522644,
      "attention_bam_16_max_attention": 2.5921287536621094,
      "attention_bam_16_min_attention": -0.91448974609375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.3572892172512478,
      "attention_bam_16_attention_skewness": 0.4916150814759376,
      "attention_bam_16_attention_sparsity": 0.377197265625,
      "attention_bam_16_attention_concentration_10": 0.45610892454508667,
      "attention_bam_16_attention_concentration_20": 0.7443666040217962,
      "attention_bam_16_attention_center_y": 0.47297163583177904,
      "attention_bam_16_attention_center_x": 0.4710867184475109,
      "attention_bam_16_attention_center_distance": 0.05597339224566398,
      "attention_bam_16_attention_spatial_variance": 41.585998699871155,
      "attention_bam_16_attention_spatial_std": 6.4487207025790125,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.27813502346197,
      "attention_bam_16_peak_intensity_mean": 0.32467204332351685,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 81,
      "phase": "train",
      "loss": 0.2699161469936371,
      "timestamp": 1759561901.226654,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.2699161469936371,
      "ssim": 0.09278438985347748,
      "attention_bam_384_mean_attention": 0.19579870998859406,
      "attention_bam_384_std_attention": 0.5353970527648926,
      "attention_bam_384_max_attention": 5.27587890625,
      "attention_bam_384_min_attention": -1.160888671875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6847430781410089,
      "attention_bam_384_attention_skewness": 0.5664707517991914,
      "attention_bam_384_attention_sparsity": 0.4561818440755208,
      "attention_bam_384_attention_concentration_10": 0.6191489853951637,
      "attention_bam_384_attention_concentration_20": 0.9999385075725713,
      "attention_bam_384_attention_center_y": 0.46894646076859126,
      "attention_bam_384_attention_center_x": 0.49077141823065995,
      "attention_bam_384_attention_center_distance": 0.04581460510077627,
      "attention_bam_384_attention_spatial_variance": 170.11143389329357,
      "attention_bam_384_attention_spatial_std": 13.042677405091853,
      "attention_bam_384_num_attention_peaks": 4,
      "attention_bam_384_peak_separation_mean": 16.338409306170288,
      "attention_bam_384_peak_intensity_mean": 0.2166723906993866,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21136614680290222,
      "attention_bam_16_std_attention": 0.4952723979949951,
      "attention_bam_16_max_attention": 2.90313720703125,
      "attention_bam_16_min_attention": -0.9520263671875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.8058859211224512,
      "attention_bam_16_attention_skewness": 0.8117660833866186,
      "attention_bam_16_attention_sparsity": 0.439697265625,
      "attention_bam_16_attention_concentration_10": 0.5475146113219796,
      "attention_bam_16_attention_concentration_20": 0.8847359329511693,
      "attention_bam_16_attention_center_y": 0.4668718534853057,
      "attention_bam_16_attention_center_x": 0.4600688899298177,
      "attention_bam_16_attention_center_distance": 0.07337530433239874,
      "attention_bam_16_attention_spatial_variance": 42.17443995038004,
      "attention_bam_16_attention_spatial_std": 6.494185087474797,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 7.916281876988782,
      "attention_bam_16_peak_intensity_mean": 0.31040191650390625,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 82,
      "phase": "train",
      "loss": 0.18737101554870605,
      "timestamp": 1759561901.4025521,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.18737101554870605,
      "ssim": 0.08125748485326767,
      "attention_bam_384_mean_attention": 0.1927531212568283,
      "attention_bam_384_std_attention": 0.5996799468994141,
      "attention_bam_384_max_attention": 6.214111328125,
      "attention_bam_384_min_attention": -1.42919921875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 7.308137937849477,
      "attention_bam_384_attention_skewness": 1.5510250579377647,
      "attention_bam_384_attention_sparsity": 0.46570587158203125,
      "attention_bam_384_attention_concentration_10": 0.7022683516975996,
      "attention_bam_384_attention_concentration_20": 1.0795946475532154,
      "attention_bam_384_attention_center_y": 0.489168716999879,
      "attention_bam_384_attention_center_x": 0.48491371376199094,
      "attention_bam_384_attention_center_distance": 0.02626452831801292,
      "attention_bam_384_attention_spatial_variance": 169.75633720259592,
      "attention_bam_384_attention_spatial_std": 13.02905741804049,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 18.620353467533402,
      "attention_bam_384_peak_intensity_mean": 0.21357284486293793,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2126471996307373,
      "attention_bam_16_std_attention": 0.562800407409668,
      "attention_bam_16_max_attention": 5.75384521484375,
      "attention_bam_16_min_attention": -1.259521484375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 10.854435498681486,
      "attention_bam_16_attention_skewness": 1.7676608975508876,
      "attention_bam_16_attention_sparsity": 0.434814453125,
      "attention_bam_16_attention_concentration_10": 0.5852466260428577,
      "attention_bam_16_attention_concentration_20": 0.9060679812925808,
      "attention_bam_16_attention_center_y": 0.46875431569837483,
      "attention_bam_16_attention_center_x": 0.47113452695451047,
      "attention_bam_16_attention_center_distance": 0.06015826329967826,
      "attention_bam_16_attention_spatial_variance": 42.269843327877794,
      "attention_bam_16_attention_spatial_std": 6.501526230653676,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.232924714456619,
      "attention_bam_16_peak_intensity_mean": 0.21205776929855347,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 83,
      "phase": "train",
      "loss": 0.20391565561294556,
      "timestamp": 1759561901.5703876,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.20391565561294556,
      "ssim": 0.09559334814548492,
      "attention_bam_384_mean_attention": 0.2000114470720291,
      "attention_bam_384_std_attention": 0.5718159079551697,
      "attention_bam_384_max_attention": 5.09375,
      "attention_bam_384_min_attention": -1.36376953125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.7046401248878595,
      "attention_bam_384_attention_skewness": 0.7792449560395964,
      "attention_bam_384_attention_sparsity": 0.45567576090494794,
      "attention_bam_384_attention_concentration_10": 0.6580909268447682,
      "attention_bam_384_attention_concentration_20": 1.0366213809882274,
      "attention_bam_384_attention_center_y": 0.4876570177349041,
      "attention_bam_384_attention_center_x": 0.48317657185571705,
      "attention_bam_384_attention_center_distance": 0.029508539297034793,
      "attention_bam_384_attention_spatial_variance": 168.10513032363184,
      "attention_bam_384_attention_spatial_std": 12.965536252837051,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 13.383156113084679,
      "attention_bam_384_peak_intensity_mean": 0.24365663528442383,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21335193514823914,
      "attention_bam_16_std_attention": 0.5185651183128357,
      "attention_bam_16_max_attention": 4.189697265625,
      "attention_bam_16_min_attention": -1.16064453125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 4.339868695033553,
      "attention_bam_16_attention_skewness": 1.039107237779164,
      "attention_bam_16_attention_sparsity": 0.408447265625,
      "attention_bam_16_attention_concentration_10": 0.5599583134391021,
      "attention_bam_16_attention_concentration_20": 0.8703449397105536,
      "attention_bam_16_attention_center_y": 0.47380459983969514,
      "attention_bam_16_attention_center_x": 0.4740127527230035,
      "attention_bam_16_attention_center_distance": 0.052183062589201495,
      "attention_bam_16_attention_spatial_variance": 41.53506631119785,
      "attention_bam_16_attention_spatial_std": 6.4447704622583615,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.742842131777476,
      "attention_bam_16_peak_intensity_mean": 0.2567293047904968,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 84,
      "phase": "train",
      "loss": 0.1987510621547699,
      "timestamp": 1759561901.7402253,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.1987510621547699,
      "ssim": 0.08437713235616684,
      "attention_bam_384_mean_attention": 0.18745505809783936,
      "attention_bam_384_std_attention": 0.5232647061347961,
      "attention_bam_384_max_attention": 4.9140625,
      "attention_bam_384_min_attention": -1.0869140625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.719608809822202,
      "attention_bam_384_attention_skewness": 1.1051833076273831,
      "attention_bam_384_attention_sparsity": 0.4777984619140625,
      "attention_bam_384_attention_concentration_10": 0.6618380628900963,
      "attention_bam_384_attention_concentration_20": 1.025266557582425,
      "attention_bam_384_attention_center_y": 0.49090685248872235,
      "attention_bam_384_attention_center_x": 0.4823181799148849,
      "attention_bam_384_attention_center_distance": 0.028118751507996746,
      "attention_bam_384_attention_spatial_variance": 169.13531352824864,
      "attention_bam_384_attention_spatial_std": 13.00520332514062,
      "attention_bam_384_num_attention_peaks": 3,
      "attention_bam_384_peak_separation_mean": 20.00355257766106,
      "attention_bam_384_peak_intensity_mean": 0.2157999724149704,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.211500346660614,
      "attention_bam_16_std_attention": 0.4799724519252777,
      "attention_bam_16_max_attention": 4.4376373291015625,
      "attention_bam_16_min_attention": -0.84112548828125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 8.722332200950298,
      "attention_bam_16_attention_skewness": 1.8685859681295212,
      "attention_bam_16_attention_sparsity": 0.427734375,
      "attention_bam_16_attention_concentration_10": 0.5545884651187382,
      "attention_bam_16_attention_concentration_20": 0.8418806911324827,
      "attention_bam_16_attention_center_y": 0.48398660251050174,
      "attention_bam_16_attention_center_x": 0.47025977540196806,
      "attention_bam_16_attention_center_distance": 0.04776839662994883,
      "attention_bam_16_attention_spatial_variance": 42.06522674547203,
      "attention_bam_16_attention_spatial_std": 6.485771098757034,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.052249655689192,
      "attention_bam_16_peak_intensity_mean": 0.2050231248140335,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 85,
      "phase": "train",
      "loss": 0.22740857303142548,
      "timestamp": 1759561901.9113472,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.22740857303142548,
      "ssim": 0.10188329219818115,
      "attention_bam_384_mean_attention": 0.19295306503772736,
      "attention_bam_384_std_attention": 0.5240312218666077,
      "attention_bam_384_max_attention": 5.0771484375,
      "attention_bam_384_min_attention": -1.0810546875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.04079988939997392,
      "attention_bam_384_attention_skewness": 0.3978093118063948,
      "attention_bam_384_attention_sparsity": 0.4465891520182292,
      "attention_bam_384_attention_concentration_10": 0.614947095476834,
      "attention_bam_384_attention_concentration_20": 0.9997278525183806,
      "attention_bam_384_attention_center_y": 0.48130526808953894,
      "attention_bam_384_attention_center_x": 0.4758737820468084,
      "attention_bam_384_attention_center_distance": 0.04316404508219578,
      "attention_bam_384_attention_spatial_variance": 169.07062056542372,
      "attention_bam_384_attention_spatial_std": 13.002715891898266,
      "attention_bam_384_num_attention_peaks": 2,
      "attention_bam_384_peak_separation_mean": 17.415031167456842,
      "attention_bam_384_peak_intensity_mean": 0.21024559438228607,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24036285281181335,
      "attention_bam_16_std_attention": 0.4986724555492401,
      "attention_bam_16_max_attention": 2.633270263671875,
      "attention_bam_16_min_attention": -0.8925704956054688,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7065772370468011,
      "attention_bam_16_attention_skewness": 0.5642181433168882,
      "attention_bam_16_attention_sparsity": 0.386474609375,
      "attention_bam_16_attention_concentration_10": 0.5005235740638309,
      "attention_bam_16_attention_concentration_20": 0.8043530390028253,
      "attention_bam_16_attention_center_y": 0.4673183264903562,
      "attention_bam_16_attention_center_x": 0.4772514868327357,
      "attention_bam_16_attention_center_distance": 0.056313171367134866,
      "attention_bam_16_attention_spatial_variance": 41.938558053864874,
      "attention_bam_16_attention_spatial_std": 6.475998614411902,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.355277518560085,
      "attention_bam_16_peak_intensity_mean": 0.3245202600955963,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 86,
      "phase": "train",
      "loss": 0.14706648886203766,
      "timestamp": 1759561902.1012151,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.14706648886203766,
      "ssim": 0.12164124101400375,
      "attention_bam_384_mean_attention": 0.188595250248909,
      "attention_bam_384_std_attention": 0.5539929270744324,
      "attention_bam_384_max_attention": 5.22412109375,
      "attention_bam_384_min_attention": -1.197265625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.021993483086109,
      "attention_bam_384_attention_skewness": 0.6844491334374238,
      "attention_bam_384_attention_sparsity": 0.46493784586588544,
      "attention_bam_384_attention_concentration_10": 0.667911235515817,
      "attention_bam_384_attention_concentration_20": 1.059265236807336,
      "attention_bam_384_attention_center_y": 0.4814507649187297,
      "attention_bam_384_attention_center_x": 0.4828070228958538,
      "attention_bam_384_attention_center_distance": 0.03576793490834842,
      "attention_bam_384_attention_spatial_variance": 170.22062903546805,
      "attention_bam_384_attention_spatial_std": 13.046862804347567,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 17.580363577101288,
      "attention_bam_384_peak_intensity_mean": 0.21650587022304535,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22349879145622253,
      "attention_bam_16_std_attention": 0.5362013578414917,
      "attention_bam_16_max_attention": 4.1895751953125,
      "attention_bam_16_min_attention": -1.2276611328125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.8288743685952475,
      "attention_bam_16_attention_skewness": 0.8333583044272724,
      "attention_bam_16_attention_sparsity": 0.42529296875,
      "attention_bam_16_attention_concentration_10": 0.5508349695747813,
      "attention_bam_16_attention_concentration_20": 0.8796651720880657,
      "attention_bam_16_attention_center_y": 0.46984456703096744,
      "attention_bam_16_attention_center_x": 0.46816395843333103,
      "attention_bam_16_attention_center_distance": 0.062014251268309124,
      "attention_bam_16_attention_spatial_variance": 42.603215852385304,
      "attention_bam_16_attention_spatial_std": 6.527113899142967,
      "attention_bam_16_num_attention_peaks": 16,
      "attention_bam_16_peak_separation_mean": 8.99701645937495,
      "attention_bam_16_peak_intensity_mean": 0.271987646818161,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 87,
      "phase": "train",
      "loss": 0.1583968997001648,
      "timestamp": 1759561902.2690167,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.1583968997001648,
      "ssim": 0.10555540025234222,
      "attention_bam_384_mean_attention": 0.18988072872161865,
      "attention_bam_384_std_attention": 0.6089776754379272,
      "attention_bam_384_max_attention": 5.548828125,
      "attention_bam_384_min_attention": -1.2635498046875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 4.691124115566997,
      "attention_bam_384_attention_skewness": 1.3350094643000734,
      "attention_bam_384_attention_sparsity": 0.46821339925130206,
      "attention_bam_384_attention_concentration_10": 0.7389662666460592,
      "attention_bam_384_attention_concentration_20": 1.12604758182722,
      "attention_bam_384_attention_center_y": 0.48639801559462004,
      "attention_bam_384_attention_center_x": 0.49183164122857387,
      "attention_bam_384_attention_center_distance": 0.022438184631691303,
      "attention_bam_384_attention_spatial_variance": 169.70813138689118,
      "attention_bam_384_attention_spatial_std": 13.027207351803808,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 17.7994695073506,
      "attention_bam_384_peak_intensity_mean": 0.21693654358386993,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21132829785346985,
      "attention_bam_16_std_attention": 0.5610806941986084,
      "attention_bam_16_max_attention": 5.33172607421875,
      "attention_bam_16_min_attention": -0.96875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 8.231150895349765,
      "attention_bam_16_attention_skewness": 1.6331674275885717,
      "attention_bam_16_attention_sparsity": 0.415283203125,
      "attention_bam_16_attention_concentration_10": 0.6041663229141424,
      "attention_bam_16_attention_concentration_20": 0.9255464073301046,
      "attention_bam_16_attention_center_y": 0.47121309669853634,
      "attention_bam_16_attention_center_x": 0.4667682591191629,
      "attention_bam_16_attention_center_distance": 0.0621777195409886,
      "attention_bam_16_attention_spatial_variance": 42.15073152728798,
      "attention_bam_16_attention_spatial_std": 6.492359473048914,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.887525825938875,
      "attention_bam_16_peak_intensity_mean": 0.1882127821445465,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 88,
      "phase": "train",
      "loss": 0.16586697101593018,
      "timestamp": 1759561902.4350188,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.16586697101593018,
      "ssim": 0.11295664310455322,
      "attention_bam_384_mean_attention": 0.18622201681137085,
      "attention_bam_384_std_attention": 0.4561105966567993,
      "attention_bam_384_max_attention": 4.92041015625,
      "attention_bam_384_min_attention": -1.125732421875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.3243812505121464,
      "attention_bam_384_attention_skewness": 0.23032123312198835,
      "attention_bam_384_attention_sparsity": 0.42537180582682294,
      "attention_bam_384_attention_concentration_10": 0.5328012439317428,
      "attention_bam_384_attention_concentration_20": 0.8885667887317291,
      "attention_bam_384_attention_center_y": 0.4799120243302125,
      "attention_bam_384_attention_center_x": 0.4715082401941686,
      "attention_bam_384_attention_center_distance": 0.049301260497945976,
      "attention_bam_384_attention_spatial_variance": 167.24935949896707,
      "attention_bam_384_attention_spatial_std": 12.932492393153264,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 9.088051078983037,
      "attention_bam_384_peak_intensity_mean": 0.22339417040348053,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.228728786110878,
      "attention_bam_16_std_attention": 0.41314417123794556,
      "attention_bam_16_max_attention": 2.0085296630859375,
      "attention_bam_16_min_attention": -0.9202961921691895,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6608982138167674,
      "attention_bam_16_attention_skewness": 0.21405775173308816,
      "attention_bam_16_attention_sparsity": 0.36328125,
      "attention_bam_16_attention_concentration_10": 0.4172400698365189,
      "attention_bam_16_attention_concentration_20": 0.69587951682313,
      "attention_bam_16_attention_center_y": 0.4772763514738062,
      "attention_bam_16_attention_center_x": 0.46855340907330373,
      "attention_bam_16_attention_center_distance": 0.0548680650880449,
      "attention_bam_16_attention_spatial_variance": 42.095118939477544,
      "attention_bam_16_attention_spatial_std": 6.48807513361841,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 10.565147810203673,
      "attention_bam_16_peak_intensity_mean": 0.3996369242668152,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 89,
      "phase": "train",
      "loss": 0.18185412883758545,
      "timestamp": 1759561902.599224,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.18185412883758545,
      "ssim": 0.10733895003795624,
      "attention_bam_384_mean_attention": 0.2027606964111328,
      "attention_bam_384_std_attention": 0.5472707152366638,
      "attention_bam_384_max_attention": 4.70751953125,
      "attention_bam_384_min_attention": -1.306640625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.8379245744803407,
      "attention_bam_384_attention_skewness": 0.9854232252947501,
      "attention_bam_384_attention_sparsity": 0.4525044759114583,
      "attention_bam_384_attention_concentration_10": 0.6285631555429342,
      "attention_bam_384_attention_concentration_20": 0.9814036459556958,
      "attention_bam_384_attention_center_y": 0.4796482553548875,
      "attention_bam_384_attention_center_x": 0.4804994461120349,
      "attention_bam_384_attention_center_distance": 0.03986138763358089,
      "attention_bam_384_attention_spatial_variance": 168.96665965912464,
      "attention_bam_384_attention_spatial_std": 12.998717615946761,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 14.893740309157291,
      "attention_bam_384_peak_intensity_mean": 0.2516474723815918,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2130499929189682,
      "attention_bam_16_std_attention": 0.5238876938819885,
      "attention_bam_16_max_attention": 4.529266357421875,
      "attention_bam_16_min_attention": -1.075225830078125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 7.355277315425017,
      "attention_bam_16_attention_skewness": 1.5215677546498652,
      "attention_bam_16_attention_sparsity": 0.442626953125,
      "attention_bam_16_attention_concentration_10": 0.5654967080642701,
      "attention_bam_16_attention_concentration_20": 0.8891168223697126,
      "attention_bam_16_attention_center_y": 0.4666822588725161,
      "attention_bam_16_attention_center_x": 0.4730708284755876,
      "attention_bam_16_attention_center_distance": 0.06058468705587668,
      "attention_bam_16_attention_spatial_variance": 43.4202959439562,
      "attention_bam_16_attention_spatial_std": 6.589407859888186,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.705501814940336,
      "attention_bam_16_peak_intensity_mean": 0.2356429100036621,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 90,
      "phase": "train",
      "loss": 0.13874921202659607,
      "timestamp": 1759561902.8442574,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.13874921202659607,
      "ssim": 0.13995569944381714,
      "attention_bam_384_mean_attention": 0.1922656148672104,
      "attention_bam_384_std_attention": 0.5627776384353638,
      "attention_bam_384_max_attention": 5.07611083984375,
      "attention_bam_384_min_attention": -1.31103515625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.809640443417665,
      "attention_bam_384_attention_skewness": 1.1745862810196166,
      "attention_bam_384_attention_sparsity": 0.45914459228515625,
      "attention_bam_384_attention_concentration_10": 0.6733390719996795,
      "attention_bam_384_attention_concentration_20": 1.0356579927032141,
      "attention_bam_384_attention_center_y": 0.47904274705810884,
      "attention_bam_384_attention_center_x": 0.4739084067274235,
      "attention_bam_384_attention_center_distance": 0.04732816688552313,
      "attention_bam_384_attention_spatial_variance": 169.940326977049,
      "attention_bam_384_attention_spatial_std": 13.036116253587531,
      "attention_bam_384_num_attention_peaks": 2,
      "attention_bam_384_peak_separation_mean": 17.230730813843763,
      "attention_bam_384_peak_intensity_mean": 0.24153977632522583,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1997050940990448,
      "attention_bam_16_std_attention": 0.49749311804771423,
      "attention_bam_16_max_attention": 4.11639404296875,
      "attention_bam_16_min_attention": -0.989013671875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 6.590712007238679,
      "attention_bam_16_attention_skewness": 1.4916093629194096,
      "attention_bam_16_attention_sparsity": 0.426513671875,
      "attention_bam_16_attention_concentration_10": 0.575131387275835,
      "attention_bam_16_attention_concentration_20": 0.8855519280547393,
      "attention_bam_16_attention_center_y": 0.463791314058431,
      "attention_bam_16_attention_center_x": 0.4630131615850031,
      "attention_bam_16_attention_center_distance": 0.07319966056686693,
      "attention_bam_16_attention_spatial_variance": 42.573816039974886,
      "attention_bam_16_attention_spatial_std": 6.524861380901121,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.78776662089805,
      "attention_bam_16_peak_intensity_mean": 0.23547951877117157,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 91,
      "phase": "train",
      "loss": 0.14156502485275269,
      "timestamp": 1759561903.010997,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.14156502485275269,
      "ssim": 0.09426036477088928,
      "attention_bam_384_mean_attention": 0.188145712018013,
      "attention_bam_384_std_attention": 0.5058722496032715,
      "attention_bam_384_max_attention": 4.00244140625,
      "attention_bam_384_min_attention": -1.2718505859375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.425761585768033,
      "attention_bam_384_attention_skewness": 1.0386741673036375,
      "attention_bam_384_attention_sparsity": 0.444610595703125,
      "attention_bam_384_attention_concentration_10": 0.6228071073965301,
      "attention_bam_384_attention_concentration_20": 0.9628122754675624,
      "attention_bam_384_attention_center_y": 0.4897256606001481,
      "attention_bam_384_attention_center_x": 0.4877254167547837,
      "attention_bam_384_attention_center_distance": 0.02263746646367891,
      "attention_bam_384_attention_spatial_variance": 169.51436125112454,
      "attention_bam_384_attention_spatial_std": 13.019768095136124,
      "attention_bam_384_num_attention_peaks": 3,
      "attention_bam_384_peak_separation_mean": 19.82608022879381,
      "attention_bam_384_peak_intensity_mean": 0.2766718864440918,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21156767010688782,
      "attention_bam_16_std_attention": 0.46928292512893677,
      "attention_bam_16_max_attention": 3.9979248046875,
      "attention_bam_16_min_attention": -0.97705078125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 5.64967430542659,
      "attention_bam_16_attention_skewness": 1.2478526288518377,
      "attention_bam_16_attention_sparsity": 0.396240234375,
      "attention_bam_16_attention_concentration_10": 0.5123395679324253,
      "attention_bam_16_attention_concentration_20": 0.8001217207941496,
      "attention_bam_16_attention_center_y": 0.4707328198637529,
      "attention_bam_16_attention_center_x": 0.46773956504057124,
      "attention_bam_16_attention_center_distance": 0.0616003814419857,
      "attention_bam_16_attention_spatial_variance": 42.16463256057023,
      "attention_bam_16_attention_spatial_std": 6.49342995346606,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.661506825164595,
      "attention_bam_16_peak_intensity_mean": 0.24131953716278076,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 92,
      "phase": "train",
      "loss": 0.16147130727767944,
      "timestamp": 1759561903.1779346,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.16147130727767944,
      "ssim": 0.0958770141005516,
      "attention_bam_384_mean_attention": 0.19261057674884796,
      "attention_bam_384_std_attention": 0.48934388160705566,
      "attention_bam_384_max_attention": 4.646484375,
      "attention_bam_384_min_attention": -1.1697998046875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.496221223260748,
      "attention_bam_384_attention_skewness": 0.8544138670830701,
      "attention_bam_384_attention_sparsity": 0.4453531901041667,
      "attention_bam_384_attention_concentration_10": 0.5851390822419741,
      "attention_bam_384_attention_concentration_20": 0.9285723274694867,
      "attention_bam_384_attention_center_y": 0.4803397131345871,
      "attention_bam_384_attention_center_x": 0.4776132131512994,
      "attention_bam_384_attention_center_distance": 0.0421353795530426,
      "attention_bam_384_attention_spatial_variance": 170.5090514170842,
      "attention_bam_384_attention_spatial_std": 13.057911449274123,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 17.722379812974733,
      "attention_bam_384_peak_intensity_mean": 0.23687508702278137,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22655239701271057,
      "attention_bam_16_std_attention": 0.45379820466041565,
      "attention_bam_16_max_attention": 3.99560546875,
      "attention_bam_16_min_attention": -0.9123382568359375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 7.024147251148525,
      "attention_bam_16_attention_skewness": 1.3290304970212363,
      "attention_bam_16_attention_sparsity": 0.39794921875,
      "attention_bam_16_attention_concentration_10": 0.46406421236892925,
      "attention_bam_16_attention_concentration_20": 0.7435539593836448,
      "attention_bam_16_attention_center_y": 0.46661472061255016,
      "attention_bam_16_attention_center_x": 0.4611662878214681,
      "attention_bam_16_attention_center_distance": 0.07242422359049681,
      "attention_bam_16_attention_spatial_variance": 42.22878507980044,
      "attention_bam_16_attention_spatial_std": 6.498367878152209,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.746122059983081,
      "attention_bam_16_peak_intensity_mean": 0.23901736736297607,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 93,
      "phase": "train",
      "loss": 0.15045908093452454,
      "timestamp": 1759561903.3436866,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.15045908093452454,
      "ssim": 0.1551298201084137,
      "attention_bam_384_mean_attention": 0.1910717487335205,
      "attention_bam_384_std_attention": 0.52438884973526,
      "attention_bam_384_max_attention": 4.87890625,
      "attention_bam_384_min_attention": -1.1644287109375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.7436441385916588,
      "attention_bam_384_attention_skewness": 0.7942439167861157,
      "attention_bam_384_attention_sparsity": 0.4479878743489583,
      "attention_bam_384_attention_concentration_10": 0.6296080589324933,
      "attention_bam_384_attention_concentration_20": 0.9925724938326358,
      "attention_bam_384_attention_center_y": 0.4711937442810914,
      "attention_bam_384_attention_center_x": 0.4829933597640808,
      "attention_bam_384_attention_center_distance": 0.047308058101282066,
      "attention_bam_384_attention_spatial_variance": 171.38026020854286,
      "attention_bam_384_attention_spatial_std": 13.091228368970684,
      "attention_bam_384_num_attention_peaks": 2,
      "attention_bam_384_peak_separation_mean": 16.392004376485914,
      "attention_bam_384_peak_intensity_mean": 0.23350980877876282,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21549735963344574,
      "attention_bam_16_std_attention": 0.5039222836494446,
      "attention_bam_16_max_attention": 3.746337890625,
      "attention_bam_16_min_attention": -1.0442533493041992,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 4.9385136703817825,
      "attention_bam_16_attention_skewness": 1.161566632780631,
      "attention_bam_16_attention_sparsity": 0.4150390625,
      "attention_bam_16_attention_concentration_10": 0.5388085618427355,
      "attention_bam_16_attention_concentration_20": 0.8530584368372998,
      "attention_bam_16_attention_center_y": 0.46606951594303103,
      "attention_bam_16_attention_center_x": 0.46377482792185637,
      "attention_bam_16_attention_center_distance": 0.07019317403325401,
      "attention_bam_16_attention_spatial_variance": 42.639362598064935,
      "attention_bam_16_attention_spatial_std": 6.529882280567157,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.716811054124273,
      "attention_bam_16_peak_intensity_mean": 0.2673168480396271,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 94,
      "phase": "train",
      "loss": 0.17910772562026978,
      "timestamp": 1759561903.5102246,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.17910772562026978,
      "ssim": 0.10712851583957672,
      "attention_bam_384_mean_attention": 0.18436022102832794,
      "attention_bam_384_std_attention": 0.578262209892273,
      "attention_bam_384_max_attention": 4.553466796875,
      "attention_bam_384_min_attention": -1.19403076171875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 5.467554804696979,
      "attention_bam_384_attention_skewness": 1.5496835403544218,
      "attention_bam_384_attention_sparsity": 0.48300425211588544,
      "attention_bam_384_attention_concentration_10": 0.7384661360291095,
      "attention_bam_384_attention_concentration_20": 1.1072384400559128,
      "attention_bam_384_attention_center_y": 0.47645800779626907,
      "attention_bam_384_attention_center_x": 0.4944421397654739,
      "attention_bam_384_attention_center_distance": 0.034208630703582814,
      "attention_bam_384_attention_spatial_variance": 169.27012750437248,
      "attention_bam_384_attention_spatial_std": 13.010385371093836,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 15.548609923691666,
      "attention_bam_384_peak_intensity_mean": 0.23972482979297638,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19859227538108826,
      "attention_bam_16_std_attention": 0.5362984538078308,
      "attention_bam_16_max_attention": 5.151123046875,
      "attention_bam_16_min_attention": -0.99029541015625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 13.856082277031444,
      "attention_bam_16_attention_skewness": 2.413007268902504,
      "attention_bam_16_attention_sparsity": 0.43994140625,
      "attention_bam_16_attention_concentration_10": 0.6173483200049683,
      "attention_bam_16_attention_concentration_20": 0.9167595961920724,
      "attention_bam_16_attention_center_y": 0.4649726702051093,
      "attention_bam_16_attention_center_x": 0.4763951353883602,
      "attention_bam_16_attention_center_distance": 0.05973447021433911,
      "attention_bam_16_attention_spatial_variance": 42.65841837691089,
      "attention_bam_16_attention_spatial_std": 6.531341238743455,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.524645211276683,
      "attention_bam_16_peak_intensity_mean": 0.1967005729675293,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 95,
      "phase": "train",
      "loss": 0.12295129150152206,
      "timestamp": 1759561903.6819947,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.12295129150152206,
      "ssim": 0.10622473806142807,
      "attention_bam_384_mean_attention": 0.18050207197666168,
      "attention_bam_384_std_attention": 0.5242693424224854,
      "attention_bam_384_max_attention": 4.4267578125,
      "attention_bam_384_min_attention": -1.177978515625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.137655567627088,
      "attention_bam_384_attention_skewness": 1.1380370792592225,
      "attention_bam_384_attention_sparsity": 0.48095957438151044,
      "attention_bam_384_attention_concentration_10": 0.6814500812164896,
      "attention_bam_384_attention_concentration_20": 1.0569253581216802,
      "attention_bam_384_attention_center_y": 0.48218313086624687,
      "attention_bam_384_attention_center_x": 0.475223883386738,
      "attention_bam_384_attention_center_distance": 0.04315777520130626,
      "attention_bam_384_attention_spatial_variance": 168.46837127171239,
      "attention_bam_384_attention_spatial_std": 12.979536635477878,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 14.1901024126885,
      "attention_bam_384_peak_intensity_mean": 0.24448910355567932,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20331373810768127,
      "attention_bam_16_std_attention": 0.47736719250679016,
      "attention_bam_16_max_attention": 4.0518951416015625,
      "attention_bam_16_min_attention": -0.8876953125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 7.953924237772416,
      "attention_bam_16_attention_skewness": 1.6272919381823472,
      "attention_bam_16_attention_sparsity": 0.441162109375,
      "attention_bam_16_attention_concentration_10": 0.5493722439595735,
      "attention_bam_16_attention_concentration_20": 0.8574401901253472,
      "attention_bam_16_attention_center_y": 0.4693797758379406,
      "attention_bam_16_attention_center_x": 0.46403872174552563,
      "attention_bam_16_attention_center_distance": 0.06679538399366376,
      "attention_bam_16_attention_spatial_variance": 42.524847212041635,
      "attention_bam_16_attention_spatial_std": 6.521107820918286,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.701723268608047,
      "attention_bam_16_peak_intensity_mean": 0.2278095781803131,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 96,
      "phase": "train",
      "loss": 0.14567965269088745,
      "timestamp": 1759561903.8609488,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.14567965269088745,
      "ssim": 0.1361365020275116,
      "attention_bam_384_mean_attention": 0.17992150783538818,
      "attention_bam_384_std_attention": 0.5566271543502808,
      "attention_bam_384_max_attention": 4.25079345703125,
      "attention_bam_384_min_attention": -1.217529296875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.0820124369608353,
      "attention_bam_384_attention_skewness": 0.8810804790969962,
      "attention_bam_384_attention_sparsity": 0.4722340901692708,
      "attention_bam_384_attention_concentration_10": 0.7041501053584209,
      "attention_bam_384_attention_concentration_20": 1.1061027992612187,
      "attention_bam_384_attention_center_y": 0.49198179062134156,
      "attention_bam_384_attention_center_x": 0.48270298547021573,
      "attention_bam_384_attention_center_distance": 0.02696213616476166,
      "attention_bam_384_attention_spatial_variance": 169.9395955592502,
      "attention_bam_384_attention_spatial_std": 13.036088200041076,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 16.498522871081956,
      "attention_bam_384_peak_intensity_mean": 0.25535982847213745,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22320185601711273,
      "attention_bam_16_std_attention": 0.5515015721321106,
      "attention_bam_16_max_attention": 4.8648681640625,
      "attention_bam_16_min_attention": -1.0980224609375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 7.604897779343185,
      "attention_bam_16_attention_skewness": 1.607992058947449,
      "attention_bam_16_attention_sparsity": 0.42333984375,
      "attention_bam_16_attention_concentration_10": 0.5781492978390409,
      "attention_bam_16_attention_concentration_20": 0.8865298695267813,
      "attention_bam_16_attention_center_y": 0.4731382282331778,
      "attention_bam_16_attention_center_x": 0.47034386140692036,
      "attention_bam_16_attention_center_distance": 0.056586947942167606,
      "attention_bam_16_attention_spatial_variance": 42.449055944672615,
      "attention_bam_16_attention_spatial_std": 6.5152940029343736,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.540254608965085,
      "attention_bam_16_peak_intensity_mean": 0.22320567071437836,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 97,
      "phase": "train",
      "loss": 0.1360432207584381,
      "timestamp": 1759561904.0307786,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.1360432207584381,
      "ssim": 0.10203294456005096,
      "attention_bam_384_mean_attention": 0.17942959070205688,
      "attention_bam_384_std_attention": 0.5271511673927307,
      "attention_bam_384_max_attention": 4.45654296875,
      "attention_bam_384_min_attention": -1.22998046875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.4947742220543674,
      "attention_bam_384_attention_skewness": 1.0166954159207289,
      "attention_bam_384_attention_sparsity": 0.48068491617838544,
      "attention_bam_384_attention_concentration_10": 0.6827948041558609,
      "attention_bam_384_attention_concentration_20": 1.0669655487266934,
      "attention_bam_384_attention_center_y": 0.48691269782250907,
      "attention_bam_384_attention_center_x": 0.47826712247447506,
      "attention_bam_384_attention_center_distance": 0.03587744260184736,
      "attention_bam_384_attention_spatial_variance": 171.36948082761722,
      "attention_bam_384_attention_spatial_std": 13.090816660071946,
      "attention_bam_384_num_attention_peaks": 2,
      "attention_bam_384_peak_separation_mean": 21.983981784632615,
      "attention_bam_384_peak_intensity_mean": 0.2540919780731201,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21118207275867462,
      "attention_bam_16_std_attention": 0.5025805234909058,
      "attention_bam_16_max_attention": 3.9902114868164062,
      "attention_bam_16_min_attention": -0.8153076171875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 6.1512113376520094,
      "attention_bam_16_attention_skewness": 1.4498838658652362,
      "attention_bam_16_attention_sparsity": 0.432861328125,
      "attention_bam_16_attention_concentration_10": 0.555017083099094,
      "attention_bam_16_attention_concentration_20": 0.8674089090865132,
      "attention_bam_16_attention_center_y": 0.47485579763722435,
      "attention_bam_16_attention_center_x": 0.4737303437870166,
      "attention_bam_16_attention_center_distance": 0.051426175241963086,
      "attention_bam_16_attention_spatial_variance": 43.45131146994162,
      "attention_bam_16_attention_spatial_std": 6.591760877788395,
      "attention_bam_16_num_attention_peaks": 12,
      "attention_bam_16_peak_separation_mean": 9.566137158178005,
      "attention_bam_16_peak_intensity_mean": 0.21867746114730835,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 98,
      "phase": "train",
      "loss": 0.1303795874118805,
      "timestamp": 1759561904.2013063,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.1303795874118805,
      "ssim": 0.15254449844360352,
      "attention_bam_384_mean_attention": 0.19012810289859772,
      "attention_bam_384_std_attention": 0.48719146847724915,
      "attention_bam_384_max_attention": 4.697265625,
      "attention_bam_384_min_attention": -1.248046875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8900189717380984,
      "attention_bam_384_attention_skewness": 0.7851618280241225,
      "attention_bam_384_attention_sparsity": 0.44641367594401044,
      "attention_bam_384_attention_concentration_10": 0.5958909284440616,
      "attention_bam_384_attention_concentration_20": 0.9455703931494982,
      "attention_bam_384_attention_center_y": 0.46832792697322384,
      "attention_bam_384_attention_center_x": 0.4849398925693549,
      "attention_bam_384_attention_center_distance": 0.049596916146793124,
      "attention_bam_384_attention_spatial_variance": 171.83026160290504,
      "attention_bam_384_attention_spatial_std": 13.108404235562201,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 15.165180780249553,
      "attention_bam_384_peak_intensity_mean": 0.2527591288089752,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21566063165664673,
      "attention_bam_16_std_attention": 0.4503113031387329,
      "attention_bam_16_max_attention": 4.020263671875,
      "attention_bam_16_min_attention": -0.917236328125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 6.038392229546391,
      "attention_bam_16_attention_skewness": 1.1907800903411334,
      "attention_bam_16_attention_sparsity": 0.39794921875,
      "attention_bam_16_attention_concentration_10": 0.48642544534900123,
      "attention_bam_16_attention_concentration_20": 0.7787698113745155,
      "attention_bam_16_attention_center_y": 0.4635798594630689,
      "attention_bam_16_attention_center_x": 0.4755053928266395,
      "attention_bam_16_attention_center_distance": 0.06207112722203545,
      "attention_bam_16_attention_spatial_variance": 42.99631030259441,
      "attention_bam_16_attention_spatial_std": 6.557157181476925,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.659430743942576,
      "attention_bam_16_peak_intensity_mean": 0.23366442322731018,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 99,
      "phase": "train",
      "loss": 0.15005993843078613,
      "timestamp": 1759561904.3843362,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.15005993843078613,
      "ssim": 0.168793722987175,
      "attention_bam_384_mean_attention": 0.18936489522457123,
      "attention_bam_384_std_attention": 0.51832115650177,
      "attention_bam_384_max_attention": 4.8017578125,
      "attention_bam_384_min_attention": -1.1796875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6069481753594741,
      "attention_bam_384_attention_skewness": 0.5380144376405568,
      "attention_bam_384_attention_sparsity": 0.4567921956380208,
      "attention_bam_384_attention_concentration_10": 0.6191268388456387,
      "attention_bam_384_attention_concentration_20": 1.0006885917149206,
      "attention_bam_384_attention_center_y": 0.48623193024307954,
      "attention_bam_384_attention_center_x": 0.4910414604174496,
      "attention_bam_384_attention_center_distance": 0.023229945169265895,
      "attention_bam_384_attention_spatial_variance": 169.76967790659307,
      "attention_bam_384_attention_spatial_std": 13.029569367657286,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 16.49855392568788,
      "attention_bam_384_peak_intensity_mean": 0.23163890838623047,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22293442487716675,
      "attention_bam_16_std_attention": 0.48274075984954834,
      "attention_bam_16_max_attention": 3.1402587890625,
      "attention_bam_16_min_attention": -1.07958984375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.545218410894031,
      "attention_bam_16_attention_skewness": 0.899243563018928,
      "attention_bam_16_attention_sparsity": 0.422119140625,
      "attention_bam_16_attention_concentration_10": 0.5162137564615483,
      "attention_bam_16_attention_concentration_20": 0.8231415058760688,
      "attention_bam_16_attention_center_y": 0.4697690100375449,
      "attention_bam_16_attention_center_x": 0.4715881169118333,
      "attention_bam_16_attention_center_distance": 0.05867108069101361,
      "attention_bam_16_attention_spatial_variance": 42.34578193071809,
      "attention_bam_16_attention_spatial_std": 6.50736366977581,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.151068585993677,
      "attention_bam_16_peak_intensity_mean": 0.31063324213027954,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 100,
      "phase": "train",
      "loss": 0.10103954374790192,
      "timestamp": 1759561904.6642666,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.10103954374790192,
      "ssim": 0.15977373719215393,
      "attention_bam_384_mean_attention": 0.18264003098011017,
      "attention_bam_384_std_attention": 0.5202842950820923,
      "attention_bam_384_max_attention": 4.37841796875,
      "attention_bam_384_min_attention": -1.2021484375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.2117852454836493,
      "attention_bam_384_attention_skewness": 0.8252412800768748,
      "attention_bam_384_attention_sparsity": 0.4589131673177083,
      "attention_bam_384_attention_concentration_10": 0.6555074237095248,
      "attention_bam_384_attention_concentration_20": 1.0277430456364762,
      "attention_bam_384_attention_center_y": 0.48644096813204374,
      "attention_bam_384_attention_center_x": 0.4834957548926432,
      "attention_bam_384_attention_center_distance": 0.03020719953123642,
      "attention_bam_384_attention_spatial_variance": 170.51306940318446,
      "attention_bam_384_attention_spatial_std": 13.058065300923582,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 16.998937726268654,
      "attention_bam_384_peak_intensity_mean": 0.24826422333717346,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21988123655319214,
      "attention_bam_16_std_attention": 0.5257718563079834,
      "attention_bam_16_max_attention": 4.6151123046875,
      "attention_bam_16_min_attention": -1.1630859375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 6.443374340947475,
      "attention_bam_16_attention_skewness": 1.397602610021133,
      "attention_bam_16_attention_sparsity": 0.424560546875,
      "attention_bam_16_attention_concentration_10": 0.5636283391484439,
      "attention_bam_16_attention_concentration_20": 0.8693579145443111,
      "attention_bam_16_attention_center_y": 0.4765286719956962,
      "attention_bam_16_attention_center_x": 0.47214766201580805,
      "attention_bam_16_attention_center_distance": 0.05151030905500912,
      "attention_bam_16_attention_spatial_variance": 42.99917251768331,
      "attention_bam_16_attention_spatial_std": 6.557375429063317,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 8.62334537376987,
      "attention_bam_16_peak_intensity_mean": 0.24230842292308807,
      "attention_bam_16_peak_coverage": 0.1015625
    }
  ],
  "summary": {
    "total_batches": 103,
    "latest_batch": 100,
    "latest_metrics": {
      "batch_idx": 100,
      "phase": "train",
      "loss": 0.10103954374790192,
      "timestamp": 1759561904.6642666,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.10103954374790192,
      "ssim": 0.15977373719215393,
      "attention_bam_384_mean_attention": 0.18264003098011017,
      "attention_bam_384_std_attention": 0.5202842950820923,
      "attention_bam_384_max_attention": 4.37841796875,
      "attention_bam_384_min_attention": -1.2021484375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.2117852454836493,
      "attention_bam_384_attention_skewness": 0.8252412800768748,
      "attention_bam_384_attention_sparsity": 0.4589131673177083,
      "attention_bam_384_attention_concentration_10": 0.6555074237095248,
      "attention_bam_384_attention_concentration_20": 1.0277430456364762,
      "attention_bam_384_attention_center_y": 0.48644096813204374,
      "attention_bam_384_attention_center_x": 0.4834957548926432,
      "attention_bam_384_attention_center_distance": 0.03020719953123642,
      "attention_bam_384_attention_spatial_variance": 170.51306940318446,
      "attention_bam_384_attention_spatial_std": 13.058065300923582,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 16.998937726268654,
      "attention_bam_384_peak_intensity_mean": 0.24826422333717346,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21988123655319214,
      "attention_bam_16_std_attention": 0.5257718563079834,
      "attention_bam_16_max_attention": 4.6151123046875,
      "attention_bam_16_min_attention": -1.1630859375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 6.443374340947475,
      "attention_bam_16_attention_skewness": 1.397602610021133,
      "attention_bam_16_attention_sparsity": 0.424560546875,
      "attention_bam_16_attention_concentration_10": 0.5636283391484439,
      "attention_bam_16_attention_concentration_20": 0.8693579145443111,
      "attention_bam_16_attention_center_y": 0.4765286719956962,
      "attention_bam_16_attention_center_x": 0.47214766201580805,
      "attention_bam_16_attention_center_distance": 0.05151030905500912,
      "attention_bam_16_attention_spatial_variance": 42.99917251768331,
      "attention_bam_16_attention_spatial_std": 6.557375429063317,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 8.62334537376987,
      "attention_bam_16_peak_intensity_mean": 0.24230842292308807,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    "loss_mean": 0.3070838259695803,
    "loss_std": 0.11640297615489491,
    "loss_min": 0.10103954374790192,
    "loss_max": 0.674382209777832,
    "mse_mean": 0.3070838259695803,
    "mse_std": 0.11640297615489491,
    "mse_min": 0.10103954374790192,
    "mse_max": 0.674382209777832,
    "ssim_mean": 0.04212210930259989,
    "ssim_std": 0.04508786508090239,
    "ssim_min": -0.0019465561490505934,
    "ssim_max": 0.168793722987175,
    "attention_bam_384_mean_attention_mean": 0.20121324382433034,
    "attention_bam_384_mean_attention_std": 0.031065913900753545,
    "attention_bam_384_mean_attention_min": 0.027279892936348915,
    "attention_bam_384_mean_attention_max": 0.24686604738235474,
    "attention_bam_384_std_attention_mean": 0.5291595971121371,
    "attention_bam_384_std_attention_std": 0.06447957837326171,
    "attention_bam_384_std_attention_min": 0.25250741839408875,
    "attention_bam_384_std_attention_max": 0.6595689654350281,
    "attention_bam_384_max_attention_mean": 4.781084931012496,
    "attention_bam_384_max_attention_std": 0.9384556567155976,
    "attention_bam_384_max_attention_min": 0.922119140625,
    "attention_bam_384_max_attention_max": 7.384765625,
    "attention_bam_384_min_attention_mean": -1.2531483474287015,
    "attention_bam_384_min_attention_std": 0.13242579614477762,
    "attention_bam_384_min_attention_min": -1.6923828125,
    "attention_bam_384_min_attention_max": -0.75048828125,
    "attention_bam_384_attention_entropy_mean": NaN,
    "attention_bam_384_attention_entropy_std": NaN,
    "attention_bam_384_attention_entropy_min": NaN,
    "attention_bam_384_attention_entropy_max": NaN,
    "attention_bam_384_attention_kurtosis_mean": 2.127469040714413,
    "attention_bam_384_attention_kurtosis_std": 1.9543385725699836,
    "attention_bam_384_attention_kurtosis_min": -0.3489305636883069,
    "attention_bam_384_attention_kurtosis_max": 9.624103586640981,
    "attention_bam_384_attention_skewness_mean": 0.7790035856284432,
    "attention_bam_384_attention_skewness_std": 0.3839261128795555,
    "attention_bam_384_attention_skewness_min": -0.018300669019679246,
    "attention_bam_384_attention_skewness_max": 2.011180050539433,
    "attention_bam_384_attention_sparsity_mean": 0.4469365981018659,
    "attention_bam_384_attention_sparsity_std": 0.03033126349555279,
    "attention_bam_384_attention_sparsity_min": 0.337982177734375,
    "attention_bam_384_attention_sparsity_max": 0.607330322265625,
    "attention_bam_384_attention_concentration_10_mean": 0.6265787041523844,
    "attention_bam_384_attention_concentration_10_std": 0.16276579303070887,
    "attention_bam_384_attention_concentration_10_min": 0.40365290629705286,
    "attention_bam_384_attention_concentration_10_max": 1.7005794433075048,
    "attention_bam_384_attention_concentration_20_mean": 0.9947068766239601,
    "attention_bam_384_attention_concentration_20_std": 0.2626163902554629,
    "attention_bam_384_attention_concentration_20_min": 0.6605103751053127,
    "attention_bam_384_attention_concentration_20_max": 2.782090788188882,
    "attention_bam_384_attention_center_y_mean": 0.48229361196658704,
    "attention_bam_384_attention_center_y_std": 0.005204456831734853,
    "attention_bam_384_attention_center_y_min": 0.4678507265121213,
    "attention_bam_384_attention_center_y_max": 0.49454370868645703,
    "attention_bam_384_attention_center_x_mean": 0.48427988643596226,
    "attention_bam_384_attention_center_x_std": 0.004916260999275057,
    "attention_bam_384_attention_center_x_min": 0.4715082401941686,
    "attention_bam_384_attention_center_x_max": 0.4966933049074629,
    "attention_bam_384_attention_center_distance_mean": 0.03430811562019307,
    "attention_bam_384_attention_center_distance_std": 0.006796669370206535,
    "attention_bam_384_attention_center_distance_min": 0.01730355838829961,
    "attention_bam_384_attention_center_distance_max": 0.05043883591377499,
    "attention_bam_384_attention_spatial_variance_mean": 169.49558378803567,
    "attention_bam_384_attention_spatial_variance_std": 1.682948910469431,
    "attention_bam_384_attention_spatial_variance_min": 164.15266475440745,
    "attention_bam_384_attention_spatial_variance_max": 173.32840184786198,
    "attention_bam_384_attention_spatial_std_mean": 13.018887778700389,
    "attention_bam_384_attention_spatial_std_std": 0.06469489062642415,
    "attention_bam_384_attention_spatial_std_min": 12.812207645617029,
    "attention_bam_384_attention_spatial_std_max": 13.165424484150217,
    "attention_bam_384_num_attention_peaks_mean": 7.320388349514563,
    "attention_bam_384_num_attention_peaks_std": 4.196669062513161,
    "attention_bam_384_num_attention_peaks_min": 1.0,
    "attention_bam_384_num_attention_peaks_max": 23.0,
    "attention_bam_384_peak_separation_mean_mean": 16.288809339989026,
    "attention_bam_384_peak_separation_mean_std": 3.548331388040056,
    "attention_bam_384_peak_separation_mean_min": 0.0,
    "attention_bam_384_peak_separation_mean_max": 26.592365482226523,
    "attention_bam_384_peak_intensity_mean_mean": 0.24993656691416954,
    "attention_bam_384_peak_intensity_mean_std": 0.03829795295762553,
    "attention_bam_384_peak_intensity_mean_min": 0.20002229511737823,
    "attention_bam_384_peak_intensity_mean_max": 0.46574026346206665,
    "attention_bam_384_peak_coverage_mean": 0.1005859375,
    "attention_bam_384_peak_coverage_std": 0.0,
    "attention_bam_384_peak_coverage_min": 0.1005859375,
    "attention_bam_384_peak_coverage_max": 0.1005859375,
    "attention_bam_16_mean_attention_mean": 0.22098773830000637,
    "attention_bam_16_mean_attention_std": 0.03783831722026997,
    "attention_bam_16_mean_attention_min": -0.023064471781253815,
    "attention_bam_16_mean_attention_max": 0.2676053047180176,
    "attention_bam_16_std_attention_mean": 0.48885597086068494,
    "attention_bam_16_std_attention_std": 0.0677252736402455,
    "attention_bam_16_std_attention_min": 0.20926405489444733,
    "attention_bam_16_std_attention_max": 0.6517515182495117,
    "attention_bam_16_max_attention_mean": 3.6308172281505993,
    "attention_bam_16_max_attention_std": 1.1029970470915216,
    "attention_bam_16_max_attention_min": 0.412109375,
    "attention_bam_16_max_attention_max": 8.320465087890625,
    "attention_bam_16_min_attention_mean": -1.003724712769962,
    "attention_bam_16_min_attention_std": 0.1466360701611142,
    "attention_bam_16_min_attention_min": -1.2979736328125,
    "attention_bam_16_min_attention_max": -0.696044921875,
    "attention_bam_16_attention_entropy_mean": NaN,
    "attention_bam_16_attention_entropy_std": NaN,
    "attention_bam_16_attention_entropy_min": NaN,
    "attention_bam_16_attention_entropy_max": NaN,
    "attention_bam_16_attention_kurtosis_mean": 4.517398843592519,
    "attention_bam_16_attention_kurtosis_std": 3.9481053354039455,
    "attention_bam_16_attention_kurtosis_min": -0.05154328961484156,
    "attention_bam_16_attention_kurtosis_max": 18.97067354440745,
    "attention_bam_16_attention_skewness_mean": 1.0397799969095107,
    "attention_bam_16_attention_skewness_std": 0.6142411301269067,
    "attention_bam_16_attention_skewness_min": -0.835637469842628,
    "attention_bam_16_attention_skewness_max": 2.645561641234492,
    "attention_bam_16_attention_sparsity_mean": 0.4176392786711165,
    "attention_bam_16_attention_sparsity_std": 0.05944484060328685,
    "attention_bam_16_attention_sparsity_min": 0.330322265625,
    "attention_bam_16_attention_sparsity_max": 0.8115234375,
    "attention_bam_16_attention_concentration_10_mean": 0.4806906868245846,
    "attention_bam_16_attention_concentration_10_std": 0.26840435487558534,
    "attention_bam_16_attention_concentration_10_min": -1.383140427327069,
    "attention_bam_16_attention_concentration_10_max": 0.666880369182622,
    "attention_bam_16_attention_concentration_20_mean": 0.7607334051196175,
    "attention_bam_16_attention_concentration_20_std": 0.42720519002964075,
    "attention_bam_16_attention_concentration_20_min": -2.230925605625802,
    "attention_bam_16_attention_concentration_20_max": 1.0304665903238543,
    "attention_bam_16_attention_center_y_mean": 0.47071202413857494,
    "attention_bam_16_attention_center_y_std": 0.004980378632896737,
    "attention_bam_16_attention_center_y_min": 0.4571274630447008,
    "attention_bam_16_attention_center_y_max": 0.48398660251050174,
    "attention_bam_16_attention_center_x_mean": 0.47144575423148827,
    "attention_bam_16_attention_center_x_std": 0.004721994241378978,
    "attention_bam_16_attention_center_x_min": 0.4600688899298177,
    "attention_bam_16_attention_center_x_max": 0.48516751516132656,
    "attention_bam_16_attention_center_distance_mean": 0.058259101436308386,
    "attention_bam_16_attention_center_distance_std": 0.006772859807823539,
    "attention_bam_16_attention_center_distance_min": 0.03845993185675838,
    "attention_bam_16_attention_center_distance_max": 0.07337530433239874,
    "attention_bam_16_attention_spatial_variance_mean": 42.24561496849532,
    "attention_bam_16_attention_spatial_variance_std": 0.4842130520751809,
    "attention_bam_16_attention_spatial_variance_min": 41.07386266117738,
    "attention_bam_16_attention_spatial_variance_max": 43.45131146994162,
    "attention_bam_16_attention_spatial_std_mean": 6.499557160956057,
    "attention_bam_16_attention_spatial_std_std": 0.037217305153915387,
    "attention_bam_16_attention_spatial_std_min": 6.4088893469287935,
    "attention_bam_16_attention_spatial_std_max": 6.591760877788395,
    "attention_bam_16_num_attention_peaks_mean": 7.145631067961165,
    "attention_bam_16_num_attention_peaks_std": 2.2114132070598322,
    "attention_bam_16_num_attention_peaks_min": 3.0,
    "attention_bam_16_num_attention_peaks_max": 16.0,
    "attention_bam_16_peak_separation_mean_mean": 8.949498337377065,
    "attention_bam_16_peak_separation_mean_std": 0.8863211776558328,
    "attention_bam_16_peak_separation_mean_min": 6.808357026090837,
    "attention_bam_16_peak_separation_mean_max": 12.387782164371371,
    "attention_bam_16_peak_intensity_mean_mean": 0.28465614055545585,
    "attention_bam_16_peak_intensity_mean_std": 0.07620773914858844,
    "attention_bam_16_peak_intensity_mean_min": 0.15957677364349365,
    "attention_bam_16_peak_intensity_mean_max": 0.6194080114364624,
    "attention_bam_16_peak_coverage_mean": 0.1015625,
    "attention_bam_16_peak_coverage_std": 0.0,
    "attention_bam_16_peak_coverage_min": 0.1015625,
    "attention_bam_16_peak_coverage_max": 0.1015625
  },
  "metadata": {
    "created_at": "2025-10-04T14:11:45.928259",
    "total_batches": 103,
    "device": "cuda:0"
  }
}