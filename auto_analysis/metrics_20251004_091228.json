{
  "batch_metrics": [
    {
      "batch_idx": 0,
      "phase": "val",
      "loss": 0.39310094714164734,
      "timestamp": 1759543874.6647391,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.39310094714164734,
      "ssim": 0.00020899297669529915,
      "attention_bam_384_mean_attention": 0.0018816147930920124,
      "attention_bam_384_std_attention": 0.2580847144126892,
      "attention_bam_384_max_attention": 1.1563959121704102,
      "attention_bam_384_min_attention": -0.7739594578742981,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.29628766882657454,
      "attention_bam_384_attention_skewness": 0.35071835586104816,
      "attention_bam_384_attention_sparsity": 0.6638692220052084,
      "attention_bam_384_attention_concentration_10": 26.154394441386547,
      "attention_bam_384_attention_concentration_20": 39.71070953916689,
      "attention_bam_384_attention_center_y": 0.48400760045313507,
      "attention_bam_384_attention_center_x": 0.48398210923841173,
      "attention_bam_384_attention_center_distance": 0.03201030045834436,
      "attention_bam_384_attention_spatial_variance": 170.69224720301509,
      "attention_bam_384_attention_spatial_std": 13.064924309119249,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 17.863983381061118,
      "attention_bam_384_peak_intensity_mean": 0.40234407782554626,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": -0.04029373079538345,
      "attention_bam_16_std_attention": 0.15093879401683807,
      "attention_bam_16_max_attention": 0.3247266113758087,
      "attention_bam_16_min_attention": -0.4810439944267273,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.41239729777566936,
      "attention_bam_16_attention_skewness": -0.2805927456680973,
      "attention_bam_16_attention_sparsity": 0.830322265625,
      "attention_bam_16_attention_concentration_10": -0.5440104284007552,
      "attention_bam_16_attention_concentration_20": -0.882576852360917,
      "attention_bam_16_attention_center_y": 0.4711564547432987,
      "attention_bam_16_attention_center_x": 0.47221550214925223,
      "attention_bam_16_attention_center_distance": 0.05663794529806997,
      "attention_bam_16_attention_spatial_variance": 42.06734573472946,
      "attention_bam_16_attention_spatial_std": 6.485934453471563,
      "attention_bam_16_num_attention_peaks": 18,
      "attention_bam_16_peak_separation_mean": 8.800793652546577,
      "attention_bam_16_peak_intensity_mean": 0.5501440763473511,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 1,
      "phase": "val",
      "loss": 0.3988092541694641,
      "timestamp": 1759543877.1654897,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3988092541694641,
      "ssim": 0.00020980967383366078,
      "attention_bam_384_mean_attention": 0.003926893230527639,
      "attention_bam_384_std_attention": 0.2596164047718048,
      "attention_bam_384_max_attention": 1.0809073448181152,
      "attention_bam_384_min_attention": -0.7371022701263428,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.269354234067654,
      "attention_bam_384_attention_skewness": 0.341876143137591,
      "attention_bam_384_attention_sparsity": 0.6605555216471354,
      "attention_bam_384_attention_concentration_10": 12.632917790780986,
      "attention_bam_384_attention_concentration_20": 19.18165441550895,
      "attention_bam_384_attention_center_y": 0.4844054206493133,
      "attention_bam_384_attention_center_x": 0.4839248103666182,
      "attention_bam_384_attention_center_distance": 0.03167341556807693,
      "attention_bam_384_attention_spatial_variance": 170.61314475370582,
      "attention_bam_384_attention_spatial_std": 13.06189667520402,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 16.142337763011763,
      "attention_bam_384_peak_intensity_mean": 0.4080160856246948,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": -0.036860883235931396,
      "attention_bam_16_std_attention": 0.15095260739326477,
      "attention_bam_16_max_attention": 0.3069092631340027,
      "attention_bam_16_min_attention": -0.4374985098838806,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.32570253323161236,
      "attention_bam_16_attention_skewness": -0.16595645827933456,
      "attention_bam_16_attention_sparsity": 0.831298828125,
      "attention_bam_16_attention_concentration_10": -0.6226609355982947,
      "attention_bam_16_attention_concentration_20": -1.0122358604732702,
      "attention_bam_16_attention_center_y": 0.47149141224763363,
      "attention_bam_16_attention_center_x": 0.47264896803862655,
      "attention_bam_16_attention_center_distance": 0.0558716122013039,
      "attention_bam_16_attention_spatial_variance": 42.043367512307526,
      "attention_bam_16_attention_spatial_std": 6.48408571136344,
      "attention_bam_16_num_attention_peaks": 17,
      "attention_bam_16_peak_separation_mean": 8.3456757218609,
      "attention_bam_16_peak_intensity_mean": 0.5413674116134644,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 0,
      "phase": "train",
      "loss": 0.4267430305480957,
      "timestamp": 1759543879.178167,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.4267430305480957,
      "ssim": 0.013403704389929771,
      "attention_bam_384_mean_attention": 0.24239784479141235,
      "attention_bam_384_std_attention": 0.6487302780151367,
      "attention_bam_384_max_attention": 5.856725692749023,
      "attention_bam_384_min_attention": -1.6646728515625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.534694363536178,
      "attention_bam_384_attention_skewness": 0.8736138847268147,
      "attention_bam_384_attention_sparsity": 0.44314320882161456,
      "attention_bam_384_attention_concentration_10": 0.6289784835318324,
      "attention_bam_384_attention_concentration_20": 0.9852027202974504,
      "attention_bam_384_attention_center_y": 0.48145715175717607,
      "attention_bam_384_attention_center_x": 0.4796577473827837,
      "attention_bam_384_attention_center_distance": 0.03892671222949714,
      "attention_bam_384_attention_spatial_variance": 172.18567549909645,
      "attention_bam_384_attention_spatial_std": 13.121953951264135,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 16.118103884420577,
      "attention_bam_384_peak_intensity_mean": 0.25419673323631287,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24812737107276917,
      "attention_bam_16_std_attention": 0.6378040313720703,
      "attention_bam_16_max_attention": 2.6941933631896973,
      "attention_bam_16_min_attention": -1.4626561403274536,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.057724874247045754,
      "attention_bam_16_attention_skewness": 0.29631591064328877,
      "attention_bam_16_attention_sparsity": 0.42822265625,
      "attention_bam_16_attention_concentration_10": 0.5793263280121307,
      "attention_bam_16_attention_concentration_20": 0.9474033221807019,
      "attention_bam_16_attention_center_y": 0.47220440114735296,
      "attention_bam_16_attention_center_x": 0.47425617897689026,
      "attention_bam_16_attention_center_distance": 0.0535787203364765,
      "attention_bam_16_attention_spatial_variance": 42.152301583435985,
      "attention_bam_16_attention_spatial_std": 6.492480387605032,
      "attention_bam_16_num_attention_peaks": 16,
      "attention_bam_16_peak_separation_mean": 8.706385823308292,
      "attention_bam_16_peak_intensity_mean": 0.4145677089691162,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 1,
      "phase": "train",
      "loss": 0.4258974492549896,
      "timestamp": 1759543881.86557,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.4258974492549896,
      "ssim": 0.016951894387602806,
      "attention_bam_384_mean_attention": 0.23801599442958832,
      "attention_bam_384_std_attention": 0.6105653047561646,
      "attention_bam_384_max_attention": 6.410161972045898,
      "attention_bam_384_min_attention": -1.6058658361434937,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.8801130887282147,
      "attention_bam_384_attention_skewness": 0.8517456241730891,
      "attention_bam_384_attention_sparsity": 0.4327392578125,
      "attention_bam_384_attention_concentration_10": 0.602700960797322,
      "attention_bam_384_attention_concentration_20": 0.9465016636006941,
      "attention_bam_384_attention_center_y": 0.4831309653333237,
      "attention_bam_384_attention_center_x": 0.48135246804384146,
      "attention_bam_384_attention_center_distance": 0.035561067999751624,
      "attention_bam_384_attention_spatial_variance": 171.8650237608112,
      "attention_bam_384_attention_spatial_std": 13.109730117771731,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 18.838892293518576,
      "attention_bam_384_peak_intensity_mean": 0.23134875297546387,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.26207786798477173,
      "attention_bam_16_std_attention": 0.5612547993659973,
      "attention_bam_16_max_attention": 2.8337326049804688,
      "attention_bam_16_min_attention": -1.3532273769378662,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.35006465682651333,
      "attention_bam_16_attention_skewness": 0.23969473808477748,
      "attention_bam_16_attention_sparsity": 0.39111328125,
      "attention_bam_16_attention_concentration_10": 0.49805301963152987,
      "attention_bam_16_attention_concentration_20": 0.8111083920389983,
      "attention_bam_16_attention_center_y": 0.47047880310943996,
      "attention_bam_16_attention_center_x": 0.4703908916705262,
      "attention_bam_16_attention_center_distance": 0.05913037057076041,
      "attention_bam_16_attention_spatial_variance": 42.37733068420165,
      "attention_bam_16_attention_spatial_std": 6.509787299459304,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.661368812411373,
      "attention_bam_16_peak_intensity_mean": 0.3919750452041626,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 2,
      "phase": "train",
      "loss": 0.33748167753219604,
      "timestamp": 1759543881.9946542,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.33748167753219604,
      "ssim": 0.05069499462842941,
      "attention_bam_384_mean_attention": 0.23700594902038574,
      "attention_bam_384_std_attention": 0.5310591459274292,
      "attention_bam_384_max_attention": 6.873517036437988,
      "attention_bam_384_min_attention": -1.6581459045410156,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.437382566087492,
      "attention_bam_384_attention_skewness": 0.8839038748113122,
      "attention_bam_384_attention_sparsity": 0.42022959391276044,
      "attention_bam_384_attention_concentration_10": 0.5434455817384087,
      "attention_bam_384_attention_concentration_20": 0.8552389574897019,
      "attention_bam_384_attention_center_y": 0.4835491628551401,
      "attention_bam_384_attention_center_x": 0.48364742432732055,
      "attention_bam_384_attention_center_distance": 0.03280355998660541,
      "attention_bam_384_attention_spatial_variance": 170.34239707407292,
      "attention_bam_384_attention_spatial_std": 13.051528534009835,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 18.544440013949153,
      "attention_bam_384_peak_intensity_mean": 0.2235737442970276,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2488078773021698,
      "attention_bam_16_std_attention": 0.5053659081459045,
      "attention_bam_16_max_attention": 2.4671218395233154,
      "attention_bam_16_min_attention": -0.9959535598754883,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.21039486840208,
      "attention_bam_16_attention_skewness": 0.7890960858175331,
      "attention_bam_16_attention_sparsity": 0.41748046875,
      "attention_bam_16_attention_concentration_10": 0.51635614180398,
      "attention_bam_16_attention_concentration_20": 0.8131302024317816,
      "attention_bam_16_attention_center_y": 0.46112155971991997,
      "attention_bam_16_attention_center_x": 0.47599809430865186,
      "attention_bam_16_attention_center_distance": 0.06461616818456692,
      "attention_bam_16_attention_spatial_variance": 40.405388046731694,
      "attention_bam_16_attention_spatial_std": 6.3565232672217675,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 7.887368513961374,
      "attention_bam_16_peak_intensity_mean": 0.3847465515136719,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 3,
      "phase": "train",
      "loss": 0.3694000840187073,
      "timestamp": 1759543882.120746,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3694000840187073,
      "ssim": 0.03965817019343376,
      "attention_bam_384_mean_attention": 0.23552292585372925,
      "attention_bam_384_std_attention": 0.6589744091033936,
      "attention_bam_384_max_attention": 5.477872371673584,
      "attention_bam_384_min_attention": -1.6044543981552124,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8762540201223352,
      "attention_bam_384_attention_skewness": 0.8538069973476711,
      "attention_bam_384_attention_sparsity": 0.4516398111979167,
      "attention_bam_384_attention_concentration_10": 0.6602692180538312,
      "attention_bam_384_attention_concentration_20": 1.0320847607740138,
      "attention_bam_384_attention_center_y": 0.4835124320287507,
      "attention_bam_384_attention_center_x": 0.48053814288385477,
      "attention_bam_384_attention_center_distance": 0.03607225471233585,
      "attention_bam_384_attention_spatial_variance": 170.49564287395665,
      "attention_bam_384_attention_spatial_std": 13.05739801315548,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 17.120951669398693,
      "attention_bam_384_peak_intensity_mean": 0.2602115273475647,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22047415375709534,
      "attention_bam_16_std_attention": 0.6282044053077698,
      "attention_bam_16_max_attention": 3.381847858428955,
      "attention_bam_16_min_attention": -1.1512823104858398,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.4569991340566188,
      "attention_bam_16_attention_skewness": 0.9141609711832295,
      "attention_bam_16_attention_sparsity": 0.4697265625,
      "attention_bam_16_attention_concentration_10": 0.6871251039917099,
      "attention_bam_16_attention_concentration_20": 1.06797902372266,
      "attention_bam_16_attention_center_y": 0.46410635935593303,
      "attention_bam_16_attention_center_x": 0.46132778619777604,
      "attention_bam_16_attention_center_distance": 0.07461760595262136,
      "attention_bam_16_attention_spatial_variance": 41.189074232676774,
      "attention_bam_16_attention_spatial_std": 6.41787147212195,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.910703804257718,
      "attention_bam_16_peak_intensity_mean": 0.3195565640926361,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 4,
      "phase": "train",
      "loss": 0.2841787040233612,
      "timestamp": 1759543882.249333,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.2841787040233612,
      "ssim": 0.04546130448579788,
      "attention_bam_384_mean_attention": 0.2303868979215622,
      "attention_bam_384_std_attention": 0.6338685750961304,
      "attention_bam_384_max_attention": 4.968445301055908,
      "attention_bam_384_min_attention": -1.6243762969970703,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.9175126379528553,
      "attention_bam_384_attention_skewness": 0.8813600324128805,
      "attention_bam_384_attention_sparsity": 0.458160400390625,
      "attention_bam_384_attention_concentration_10": 0.6536228525755953,
      "attention_bam_384_attention_concentration_20": 1.02240777484709,
      "attention_bam_384_attention_center_y": 0.4816905937513723,
      "attention_bam_384_attention_center_x": 0.4876451887867133,
      "attention_bam_384_attention_center_distance": 0.03123702025780441,
      "attention_bam_384_attention_spatial_variance": 171.3986565666615,
      "attention_bam_384_attention_spatial_std": 13.091930971658133,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 17.036638592722543,
      "attention_bam_384_peak_intensity_mean": 0.28282609581947327,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23555819690227509,
      "attention_bam_16_std_attention": 0.6394479274749756,
      "attention_bam_16_max_attention": 3.883251667022705,
      "attention_bam_16_min_attention": -1.0876038074493408,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.470514919654436,
      "attention_bam_16_attention_skewness": 1.1381923226463966,
      "attention_bam_16_attention_sparsity": 0.476318359375,
      "attention_bam_16_attention_concentration_10": 0.6623125329233661,
      "attention_bam_16_attention_concentration_20": 1.0233418519820787,
      "attention_bam_16_attention_center_y": 0.4615513722101179,
      "attention_bam_16_attention_center_x": 0.4875011312058462,
      "attention_bam_16_attention_center_distance": 0.057175496500832715,
      "attention_bam_16_attention_spatial_variance": 42.27590186755082,
      "attention_bam_16_attention_spatial_std": 6.501992146069605,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.904307463219222,
      "attention_bam_16_peak_intensity_mean": 0.2717783749103546,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 5,
      "phase": "train",
      "loss": 0.3167078197002411,
      "timestamp": 1759543882.3743033,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3167078197002411,
      "ssim": 0.05054883658885956,
      "attention_bam_384_mean_attention": 0.23328012228012085,
      "attention_bam_384_std_attention": 0.6209129095077515,
      "attention_bam_384_max_attention": 4.539158821105957,
      "attention_bam_384_min_attention": -1.5950757265090942,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.081839269070775,
      "attention_bam_384_attention_skewness": 0.6767320896327925,
      "attention_bam_384_attention_sparsity": 0.44707489013671875,
      "attention_bam_384_attention_concentration_10": 0.6239182589633429,
      "attention_bam_384_attention_concentration_20": 0.9942715387713794,
      "attention_bam_384_attention_center_y": 0.48250350932976205,
      "attention_bam_384_attention_center_x": 0.4787702256864887,
      "attention_bam_384_attention_center_distance": 0.03890579656494256,
      "attention_bam_384_attention_spatial_variance": 170.2881742921341,
      "attention_bam_384_attention_spatial_std": 13.049451110760717,
      "attention_bam_384_num_attention_peaks": 18,
      "attention_bam_384_peak_separation_mean": 16.575853145951577,
      "attention_bam_384_peak_intensity_mean": 0.29979491233825684,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.25082606077194214,
      "attention_bam_16_std_attention": 0.6373257040977478,
      "attention_bam_16_max_attention": 3.089731216430664,
      "attention_bam_16_min_attention": -1.224957823753357,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6696717360298168,
      "attention_bam_16_attention_skewness": 0.7356083365628369,
      "attention_bam_16_attention_sparsity": 0.45361328125,
      "attention_bam_16_attention_concentration_10": 0.6174369909090285,
      "attention_bam_16_attention_concentration_20": 0.9765555065143628,
      "attention_bam_16_attention_center_y": 0.4692406954458638,
      "attention_bam_16_attention_center_x": 0.4579268037869964,
      "attention_bam_16_attention_center_distance": 0.07370601951309005,
      "attention_bam_16_attention_spatial_variance": 41.110453610452275,
      "attention_bam_16_attention_spatial_std": 6.41174341427137,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.50284960867109,
      "attention_bam_16_peak_intensity_mean": 0.3481826186180115,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 6,
      "phase": "train",
      "loss": 0.3431699275970459,
      "timestamp": 1759543882.5003688,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3431699275970459,
      "ssim": 0.0595417320728302,
      "attention_bam_384_mean_attention": 0.2292398363351822,
      "attention_bam_384_std_attention": 0.6126567721366882,
      "attention_bam_384_max_attention": 4.780694007873535,
      "attention_bam_384_min_attention": -1.5935810804367065,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1106878861842606,
      "attention_bam_384_attention_skewness": 0.6327801681825788,
      "attention_bam_384_attention_sparsity": 0.444976806640625,
      "attention_bam_384_attention_concentration_10": 0.6200170930555069,
      "attention_bam_384_attention_concentration_20": 0.9891956322830404,
      "attention_bam_384_attention_center_y": 0.48440284475299944,
      "attention_bam_384_attention_center_x": 0.4877753152872934,
      "attention_bam_384_attention_center_distance": 0.028025494397927026,
      "attention_bam_384_attention_spatial_variance": 171.97883619786361,
      "attention_bam_384_attention_spatial_std": 13.114070161390154,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 17.704303608796547,
      "attention_bam_384_peak_intensity_mean": 0.28822392225265503,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2242298126220703,
      "attention_bam_16_std_attention": 0.6087504625320435,
      "attention_bam_16_max_attention": 2.355156421661377,
      "attention_bam_16_min_attention": -1.2386834621429443,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.11594419740688666,
      "attention_bam_16_attention_skewness": 0.47741291848688544,
      "attention_bam_16_attention_sparsity": 0.4638671875,
      "attention_bam_16_attention_concentration_10": 0.6218324954636661,
      "attention_bam_16_attention_concentration_20": 1.0162044199283713,
      "attention_bam_16_attention_center_y": 0.47499854866071384,
      "attention_bam_16_attention_center_x": 0.48640738335096384,
      "attention_bam_16_attention_center_distance": 0.0402450443269317,
      "attention_bam_16_attention_spatial_variance": 42.888893088114585,
      "attention_bam_16_attention_spatial_std": 6.548961222065266,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.199931508556464,
      "attention_bam_16_peak_intensity_mean": 0.43915703892707825,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 7,
      "phase": "train",
      "loss": 0.3647286891937256,
      "timestamp": 1759543882.6266258,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3647286891937256,
      "ssim": 0.07457921653985977,
      "attention_bam_384_mean_attention": 0.24724024534225464,
      "attention_bam_384_std_attention": 0.5537768602371216,
      "attention_bam_384_max_attention": 5.831225395202637,
      "attention_bam_384_min_attention": -1.492278814315796,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5127739494927663,
      "attention_bam_384_attention_skewness": 0.579157955451498,
      "attention_bam_384_attention_sparsity": 0.40803273518880206,
      "attention_bam_384_attention_concentration_10": 0.5329632516337234,
      "attention_bam_384_attention_concentration_20": 0.848878363877663,
      "attention_bam_384_attention_center_y": 0.48004151507879855,
      "attention_bam_384_attention_center_x": 0.48552158005331,
      "attention_bam_384_attention_center_distance": 0.034870209764282664,
      "attention_bam_384_attention_spatial_variance": 170.54754252383495,
      "attention_bam_384_attention_spatial_std": 13.059385227637438,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 17.625875102183358,
      "attention_bam_384_peak_intensity_mean": 0.2399333119392395,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.26392143964767456,
      "attention_bam_16_std_attention": 0.5027231574058533,
      "attention_bam_16_max_attention": 2.8186798095703125,
      "attention_bam_16_min_attention": -1.115267038345337,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8858798948740518,
      "attention_bam_16_attention_skewness": 0.4400892100158408,
      "attention_bam_16_attention_sparsity": 0.3759765625,
      "attention_bam_16_attention_concentration_10": 0.45712043744341835,
      "attention_bam_16_attention_concentration_20": 0.7453255709734443,
      "attention_bam_16_attention_center_y": 0.45739053846664146,
      "attention_bam_16_attention_center_x": 0.4746216382737524,
      "attention_bam_16_attention_center_distance": 0.07013740023797616,
      "attention_bam_16_attention_spatial_variance": 41.36406140800173,
      "attention_bam_16_attention_spatial_std": 6.4314898280259865,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.612880260028183,
      "attention_bam_16_peak_intensity_mean": 0.36339637637138367,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 8,
      "phase": "train",
      "loss": 0.34880995750427246,
      "timestamp": 1759543882.7533433,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.34880995750427246,
      "ssim": 0.08510035276412964,
      "attention_bam_384_mean_attention": 0.2321234941482544,
      "attention_bam_384_std_attention": 0.5946976542472839,
      "attention_bam_384_max_attention": 4.739882469177246,
      "attention_bam_384_min_attention": -1.5611920356750488,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.001334573188144,
      "attention_bam_384_attention_skewness": 0.7939721453756098,
      "attention_bam_384_attention_sparsity": 0.4349314371744792,
      "attention_bam_384_attention_concentration_10": 0.6071412369839749,
      "attention_bam_384_attention_concentration_20": 0.9496737953898068,
      "attention_bam_384_attention_center_y": 0.4840661221728107,
      "attention_bam_384_attention_center_x": 0.4783472037658916,
      "attention_bam_384_attention_center_distance": 0.03801925952376276,
      "attention_bam_384_attention_spatial_variance": 172.20422518793748,
      "attention_bam_384_attention_spatial_std": 13.122660751080074,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 15.773369234384738,
      "attention_bam_384_peak_intensity_mean": 0.2878284454345703,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2522990107536316,
      "attention_bam_16_std_attention": 0.607127845287323,
      "attention_bam_16_max_attention": 2.6932742595672607,
      "attention_bam_16_min_attention": -1.2775815725326538,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.21938135286012184,
      "attention_bam_16_attention_skewness": 0.39832400593630485,
      "attention_bam_16_attention_sparsity": 0.4111328125,
      "attention_bam_16_attention_concentration_10": 0.550753802079542,
      "attention_bam_16_attention_concentration_20": 0.8952913799635778,
      "attention_bam_16_attention_center_y": 0.47189869478173546,
      "attention_bam_16_attention_center_x": 0.45458711918542427,
      "attention_bam_16_attention_center_distance": 0.07552500379144542,
      "attention_bam_16_attention_spatial_variance": 42.562479616131576,
      "attention_bam_16_attention_spatial_std": 6.523992613126687,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.336883473956902,
      "attention_bam_16_peak_intensity_mean": 0.4106374979019165,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 9,
      "phase": "train",
      "loss": 0.3215574622154236,
      "timestamp": 1759543882.8792298,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3215574622154236,
      "ssim": 0.11707844585180283,
      "attention_bam_384_mean_attention": 0.2436491996049881,
      "attention_bam_384_std_attention": 0.5774238109588623,
      "attention_bam_384_max_attention": 5.903816223144531,
      "attention_bam_384_min_attention": -1.5801115036010742,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.105912195538444,
      "attention_bam_384_attention_skewness": 0.6702603264680402,
      "attention_bam_384_attention_sparsity": 0.41610463460286456,
      "attention_bam_384_attention_concentration_10": 0.557890532587264,
      "attention_bam_384_attention_concentration_20": 0.887278641758147,
      "attention_bam_384_attention_center_y": 0.48574233106287523,
      "attention_bam_384_attention_center_x": 0.48389681282127645,
      "attention_bam_384_attention_center_distance": 0.030416895332484515,
      "attention_bam_384_attention_spatial_variance": 169.64268409988748,
      "attention_bam_384_attention_spatial_std": 13.024695163415053,
      "attention_bam_384_num_attention_peaks": 27,
      "attention_bam_384_peak_separation_mean": 16.44021374647472,
      "attention_bam_384_peak_intensity_mean": 0.24458596110343933,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2561837434768677,
      "attention_bam_16_std_attention": 0.4674566984176636,
      "attention_bam_16_max_attention": 2.612687587738037,
      "attention_bam_16_min_attention": -1.1911619901657104,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.492367459380072,
      "attention_bam_16_attention_skewness": 0.285479177845714,
      "attention_bam_16_attention_sparsity": 0.373291015625,
      "attention_bam_16_attention_concentration_10": 0.4354928397720274,
      "attention_bam_16_attention_concentration_20": 0.7196677563012349,
      "attention_bam_16_attention_center_y": 0.4762971678631048,
      "attention_bam_16_attention_center_x": 0.47395586595993117,
      "attention_bam_16_attention_center_distance": 0.04980203146874443,
      "attention_bam_16_attention_spatial_variance": 41.09223854302123,
      "attention_bam_16_attention_spatial_std": 6.410322811139953,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 8.487033192896051,
      "attention_bam_16_peak_intensity_mean": 0.3893619775772095,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 10,
      "phase": "train",
      "loss": 0.38763195276260376,
      "timestamp": 1759543883.0696948,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.38763195276260376,
      "ssim": 0.10068527609109879,
      "attention_bam_384_mean_attention": 0.24192099273204803,
      "attention_bam_384_std_attention": 0.520797073841095,
      "attention_bam_384_max_attention": 5.182400703430176,
      "attention_bam_384_min_attention": -1.5303912162780762,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.3522756766521784,
      "attention_bam_384_attention_skewness": 0.6291289146520442,
      "attention_bam_384_attention_sparsity": 0.39889272054036456,
      "attention_bam_384_attention_concentration_10": 0.5115074535888168,
      "attention_bam_384_attention_concentration_20": 0.8164498818275525,
      "attention_bam_384_attention_center_y": 0.48000354813973395,
      "attention_bam_384_attention_center_x": 0.483614752794765,
      "attention_bam_384_attention_center_distance": 0.03656048175220339,
      "attention_bam_384_attention_spatial_variance": 169.8854043228108,
      "attention_bam_384_attention_spatial_std": 13.0340095259598,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 17.11817919812654,
      "attention_bam_384_peak_intensity_mean": 0.2640001177787781,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.27161967754364014,
      "attention_bam_16_std_attention": 0.4287073612213135,
      "attention_bam_16_max_attention": 2.820946216583252,
      "attention_bam_16_min_attention": -0.8940313458442688,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.14366590756552,
      "attention_bam_16_attention_skewness": 0.40890267903522476,
      "attention_bam_16_attention_sparsity": 0.3388671875,
      "attention_bam_16_attention_concentration_10": 0.3956453907801618,
      "attention_bam_16_attention_concentration_20": 0.6460059881153832,
      "attention_bam_16_attention_center_y": 0.45746119858992706,
      "attention_bam_16_attention_center_x": 0.47613443509192327,
      "attention_bam_16_attention_center_distance": 0.06897992191626845,
      "attention_bam_16_attention_spatial_variance": 40.84303328243487,
      "attention_bam_16_attention_spatial_std": 6.390855442148169,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.102340382672143,
      "attention_bam_16_peak_intensity_mean": 0.32119429111480713,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 11,
      "phase": "train",
      "loss": 0.36072465777397156,
      "timestamp": 1759543883.1953259,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.36072465777397156,
      "ssim": 0.1153055727481842,
      "attention_bam_384_mean_attention": 0.24331124126911163,
      "attention_bam_384_std_attention": 0.5324074029922485,
      "attention_bam_384_max_attention": 4.447498798370361,
      "attention_bam_384_min_attention": -1.5496420860290527,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5914399228261482,
      "attention_bam_384_attention_skewness": 0.5342982535306167,
      "attention_bam_384_attention_sparsity": 0.4000905354817708,
      "attention_bam_384_attention_concentration_10": 0.5161232134947481,
      "attention_bam_384_attention_concentration_20": 0.8278675539690613,
      "attention_bam_384_attention_center_y": 0.48405214614557435,
      "attention_bam_384_attention_center_x": 0.48459361764633535,
      "attention_bam_384_attention_center_distance": 0.031358911326429324,
      "attention_bam_384_attention_spatial_variance": 170.16261703253406,
      "attention_bam_384_attention_spatial_std": 13.044639398332713,
      "attention_bam_384_num_attention_peaks": 23,
      "attention_bam_384_peak_separation_mean": 17.373226302864786,
      "attention_bam_384_peak_intensity_mean": 0.3019752502441406,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2840683162212372,
      "attention_bam_16_std_attention": 0.44030794501304626,
      "attention_bam_16_max_attention": 2.489126443862915,
      "attention_bam_16_min_attention": -1.0888934135437012,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7817367879798276,
      "attention_bam_16_attention_skewness": 0.27987445353659424,
      "attention_bam_16_attention_sparsity": 0.327392578125,
      "attention_bam_16_attention_concentration_10": 0.3849497327372972,
      "attention_bam_16_attention_concentration_20": 0.6365239188421787,
      "attention_bam_16_attention_center_y": 0.4701250232974842,
      "attention_bam_16_attention_center_x": 0.4734886352153608,
      "attention_bam_16_attention_center_distance": 0.056486577090846486,
      "attention_bam_16_attention_spatial_variance": 41.21738928309028,
      "attention_bam_16_attention_spatial_std": 6.42007704650733,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.163053014619617,
      "attention_bam_16_peak_intensity_mean": 0.39459094405174255,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 12,
      "phase": "train",
      "loss": 0.35813724994659424,
      "timestamp": 1759543883.3238165,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.35813724994659424,
      "ssim": 0.10156375169754028,
      "attention_bam_384_mean_attention": 0.24812430143356323,
      "attention_bam_384_std_attention": 0.5178822875022888,
      "attention_bam_384_max_attention": 5.037986755371094,
      "attention_bam_384_min_attention": -1.5095083713531494,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.6555095870230998,
      "attention_bam_384_attention_skewness": 0.4841366846496449,
      "attention_bam_384_attention_sparsity": 0.39477284749348956,
      "attention_bam_384_attention_concentration_10": 0.4924454928751976,
      "attention_bam_384_attention_concentration_20": 0.7968639160571246,
      "attention_bam_384_attention_center_y": 0.48346307279316636,
      "attention_bam_384_attention_center_x": 0.48358932139867844,
      "attention_bam_384_attention_center_distance": 0.032947847686912356,
      "attention_bam_384_attention_spatial_variance": 169.90669361103127,
      "attention_bam_384_attention_spatial_std": 13.034826182616754,
      "attention_bam_384_num_attention_peaks": 18,
      "attention_bam_384_peak_separation_mean": 18.13803428484876,
      "attention_bam_384_peak_intensity_mean": 0.26977038383483887,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.27662530541419983,
      "attention_bam_16_std_attention": 0.4218468964099884,
      "attention_bam_16_max_attention": 1.8904609680175781,
      "attention_bam_16_min_attention": -0.9937756061553955,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.38636291159957503,
      "attention_bam_16_attention_skewness": 0.09539915780083039,
      "attention_bam_16_attention_sparsity": 0.323974609375,
      "attention_bam_16_attention_concentration_10": 0.37742626727405143,
      "attention_bam_16_attention_concentration_20": 0.6274303881487461,
      "attention_bam_16_attention_center_y": 0.4698672816463975,
      "attention_bam_16_attention_center_x": 0.4723383461835007,
      "attention_bam_16_attention_center_distance": 0.05784717464563647,
      "attention_bam_16_attention_spatial_variance": 41.00717373499204,
      "attention_bam_16_attention_spatial_std": 6.403684387521924,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.311395103274617,
      "attention_bam_16_peak_intensity_mean": 0.45308810472488403,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 13,
      "phase": "train",
      "loss": 0.30160364508628845,
      "timestamp": 1759543883.4532905,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.30160364508628845,
      "ssim": 0.14988897740840912,
      "attention_bam_384_mean_attention": 0.24462682008743286,
      "attention_bam_384_std_attention": 0.505047082901001,
      "attention_bam_384_max_attention": 4.478602409362793,
      "attention_bam_384_min_attention": -1.5382227897644043,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.6244130012394713,
      "attention_bam_384_attention_skewness": 0.552588399993684,
      "attention_bam_384_attention_sparsity": 0.3999176025390625,
      "attention_bam_384_attention_concentration_10": 0.49416932636831123,
      "attention_bam_384_attention_concentration_20": 0.7942155559187902,
      "attention_bam_384_attention_center_y": 0.485339603252443,
      "attention_bam_384_attention_center_x": 0.48462274785504056,
      "attention_bam_384_attention_center_distance": 0.030046201634331048,
      "attention_bam_384_attention_spatial_variance": 169.76282785800362,
      "attention_bam_384_attention_spatial_std": 13.02930649950348,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 16.775108218075673,
      "attention_bam_384_peak_intensity_mean": 0.3006961941719055,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2739356756210327,
      "attention_bam_16_std_attention": 0.48051154613494873,
      "attention_bam_16_max_attention": 2.624657154083252,
      "attention_bam_16_min_attention": -1.0009033679962158,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.2632208449951339,
      "attention_bam_16_attention_skewness": 0.6284168797102117,
      "attention_bam_16_attention_sparsity": 0.364501953125,
      "attention_bam_16_attention_concentration_10": 0.44628975137758664,
      "attention_bam_16_attention_concentration_20": 0.7119617840096796,
      "attention_bam_16_attention_center_y": 0.4770072215283947,
      "attention_bam_16_attention_center_x": 0.4743550427360136,
      "attention_bam_16_attention_center_distance": 0.04870999271024387,
      "attention_bam_16_attention_spatial_variance": 41.273493308656256,
      "attention_bam_16_attention_spatial_std": 6.424444980592195,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.144120862044737,
      "attention_bam_16_peak_intensity_mean": 0.37458229064941406,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 14,
      "phase": "train",
      "loss": 0.341573566198349,
      "timestamp": 1759543883.581628,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.341573566198349,
      "ssim": 0.13122831284999847,
      "attention_bam_384_mean_attention": 0.24939437210559845,
      "attention_bam_384_std_attention": 0.5101507902145386,
      "attention_bam_384_max_attention": 5.507732391357422,
      "attention_bam_384_min_attention": -1.525538444519043,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.29832872509278,
      "attention_bam_384_attention_skewness": 0.5881572962306213,
      "attention_bam_384_attention_sparsity": 0.383392333984375,
      "attention_bam_384_attention_concentration_10": 0.4921117265740076,
      "attention_bam_384_attention_concentration_20": 0.7847028822306913,
      "attention_bam_384_attention_center_y": 0.4854532320544044,
      "attention_bam_384_attention_center_x": 0.48147876313613747,
      "attention_bam_384_attention_center_distance": 0.03330599563532994,
      "attention_bam_384_attention_spatial_variance": 170.4282227519543,
      "attention_bam_384_attention_spatial_std": 13.054816074995246,
      "attention_bam_384_num_attention_peaks": 19,
      "attention_bam_384_peak_separation_mean": 16.92599069821228,
      "attention_bam_384_peak_intensity_mean": 0.25287604331970215,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.28108105063438416,
      "attention_bam_16_std_attention": 0.3759230077266693,
      "attention_bam_16_max_attention": 1.9568712711334229,
      "attention_bam_16_min_attention": -0.9256015419960022,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.900098955844518,
      "attention_bam_16_attention_skewness": 0.14517596459879994,
      "attention_bam_16_attention_sparsity": 0.2958984375,
      "attention_bam_16_attention_concentration_10": 0.3404037156249144,
      "attention_bam_16_attention_concentration_20": 0.5686716821161197,
      "attention_bam_16_attention_center_y": 0.4778454861089005,
      "attention_bam_16_attention_center_x": 0.4674434641787734,
      "attention_bam_16_attention_center_distance": 0.05569112156223344,
      "attention_bam_16_attention_spatial_variance": 41.484764528823455,
      "attention_bam_16_attention_spatial_std": 6.440866752916369,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 7.918046226826746,
      "attention_bam_16_peak_intensity_mean": 0.42545974254608154,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 15,
      "phase": "train",
      "loss": 0.2972705662250519,
      "timestamp": 1759543883.7111256,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.2972705662250519,
      "ssim": 0.1321229338645935,
      "attention_bam_384_mean_attention": 0.23019124567508698,
      "attention_bam_384_std_attention": 0.5812958478927612,
      "attention_bam_384_max_attention": 4.507612228393555,
      "attention_bam_384_min_attention": -1.5198017358779907,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0820045325307666,
      "attention_bam_384_attention_skewness": 0.6004787296170498,
      "attention_bam_384_attention_sparsity": 0.43539683024088544,
      "attention_bam_384_attention_concentration_10": 0.5892610029168412,
      "attention_bam_384_attention_concentration_20": 0.9420739251701783,
      "attention_bam_384_attention_center_y": 0.4849998011329899,
      "attention_bam_384_attention_center_x": 0.4802051216846823,
      "attention_bam_384_attention_center_distance": 0.03512387147135363,
      "attention_bam_384_attention_spatial_variance": 169.10993625830812,
      "attention_bam_384_attention_spatial_std": 13.004227630209652,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 15.546397406952842,
      "attention_bam_384_peak_intensity_mean": 0.2916646897792816,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2505493462085724,
      "attention_bam_16_std_attention": 0.5893527865409851,
      "attention_bam_16_max_attention": 2.54319429397583,
      "attention_bam_16_min_attention": -1.0245498418807983,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.009594412390050877,
      "attention_bam_16_attention_skewness": 0.45949619741914255,
      "attention_bam_16_attention_sparsity": 0.427734375,
      "attention_bam_16_attention_concentration_10": 0.5466390612291792,
      "attention_bam_16_attention_concentration_20": 0.8919518175214005,
      "attention_bam_16_attention_center_y": 0.47530738773702885,
      "attention_bam_16_attention_center_x": 0.4594955921125957,
      "attention_bam_16_attention_center_distance": 0.06708699067149534,
      "attention_bam_16_attention_spatial_variance": 40.586950211197,
      "attention_bam_16_attention_spatial_std": 6.370788821739189,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 7.5354273289990505,
      "attention_bam_16_peak_intensity_mean": 0.3725915253162384,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 16,
      "phase": "train",
      "loss": 0.3406209945678711,
      "timestamp": 1759543883.8376465,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3406209945678711,
      "ssim": 0.13283100724220276,
      "attention_bam_384_mean_attention": 0.24769681692123413,
      "attention_bam_384_std_attention": 0.5169138312339783,
      "attention_bam_384_max_attention": 5.178227424621582,
      "attention_bam_384_min_attention": -1.477972149848938,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.0588064308560723,
      "attention_bam_384_attention_skewness": 0.6246698299528917,
      "attention_bam_384_attention_sparsity": 0.39482371012369794,
      "attention_bam_384_attention_concentration_10": 0.49839464043798887,
      "attention_bam_384_attention_concentration_20": 0.7987254981935877,
      "attention_bam_384_attention_center_y": 0.4813568885865073,
      "attention_bam_384_attention_center_x": 0.48198689947217555,
      "attention_bam_384_attention_center_distance": 0.03666162554501397,
      "attention_bam_384_attention_spatial_variance": 171.04658647888172,
      "attention_bam_384_attention_spatial_std": 13.078477987857827,
      "attention_bam_384_num_attention_peaks": 21,
      "attention_bam_384_peak_separation_mean": 17.82685500225831,
      "attention_bam_384_peak_intensity_mean": 0.262633740901947,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.26532644033432007,
      "attention_bam_16_std_attention": 0.44830161333084106,
      "attention_bam_16_max_attention": 2.6386399269104004,
      "attention_bam_16_min_attention": -1.0195412635803223,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.0130331849498742,
      "attention_bam_16_attention_skewness": 0.4117404905912027,
      "attention_bam_16_attention_sparsity": 0.363037109375,
      "attention_bam_16_attention_concentration_10": 0.41334526879579153,
      "attention_bam_16_attention_concentration_20": 0.6828478386364568,
      "attention_bam_16_attention_center_y": 0.4582589991037514,
      "attention_bam_16_attention_center_x": 0.46843980201747054,
      "attention_bam_16_attention_center_distance": 0.0740048275792476,
      "attention_bam_16_attention_spatial_variance": 41.9677828089898,
      "attention_bam_16_attention_spatial_std": 6.478254611312356,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.216136486028663,
      "attention_bam_16_peak_intensity_mean": 0.3671351969242096,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 17,
      "phase": "train",
      "loss": 0.25327640771865845,
      "timestamp": 1759543883.965058,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.25327640771865845,
      "ssim": 0.18626511096954346,
      "attention_bam_384_mean_attention": 0.24724841117858887,
      "attention_bam_384_std_attention": 0.5230613946914673,
      "attention_bam_384_max_attention": 5.113018035888672,
      "attention_bam_384_min_attention": -1.5443896055221558,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.9109137643319292,
      "attention_bam_384_attention_skewness": 0.5864068210501148,
      "attention_bam_384_attention_sparsity": 0.40058644612630206,
      "attention_bam_384_attention_concentration_10": 0.5068126115961492,
      "attention_bam_384_attention_concentration_20": 0.8097147958682658,
      "attention_bam_384_attention_center_y": 0.4857368260144303,
      "attention_bam_384_attention_center_x": 0.4858405925613969,
      "attention_bam_384_attention_center_distance": 0.028422770841527795,
      "attention_bam_384_attention_spatial_variance": 171.64787471398188,
      "attention_bam_384_attention_spatial_std": 13.101445520017318,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 16.667766326738025,
      "attention_bam_384_peak_intensity_mean": 0.2714223861694336,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.26922571659088135,
      "attention_bam_16_std_attention": 0.45761919021606445,
      "attention_bam_16_max_attention": 2.574228286743164,
      "attention_bam_16_min_attention": -1.1886112689971924,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7152834132218313,
      "attention_bam_16_attention_skewness": 0.3861988332908884,
      "attention_bam_16_attention_sparsity": 0.364990234375,
      "attention_bam_16_attention_concentration_10": 0.42120415894915175,
      "attention_bam_16_attention_concentration_20": 0.693256794871923,
      "attention_bam_16_attention_center_y": 0.4787025006577269,
      "attention_bam_16_attention_center_x": 0.4797755614931721,
      "attention_bam_16_attention_center_distance": 0.0415358012117399,
      "attention_bam_16_attention_spatial_variance": 42.6692391562414,
      "attention_bam_16_attention_spatial_std": 6.532169559667095,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 12.60121261607643,
      "attention_bam_16_peak_intensity_mean": 0.4154205620288849,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 18,
      "phase": "train",
      "loss": 0.2974157929420471,
      "timestamp": 1759543884.0907073,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.2974157929420471,
      "ssim": 0.17002645134925842,
      "attention_bam_384_mean_attention": 0.24347329139709473,
      "attention_bam_384_std_attention": 0.543117344379425,
      "attention_bam_384_max_attention": 4.7456793785095215,
      "attention_bam_384_min_attention": -1.5721999406814575,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4989398846542983,
      "attention_bam_384_attention_skewness": 0.5926946859594868,
      "attention_bam_384_attention_sparsity": 0.4093221028645833,
      "attention_bam_384_attention_concentration_10": 0.5335870868385457,
      "attention_bam_384_attention_concentration_20": 0.8481611357606481,
      "attention_bam_384_attention_center_y": 0.4825666858262354,
      "attention_bam_384_attention_center_x": 0.48204163493485436,
      "attention_bam_384_attention_center_distance": 0.03539557370333824,
      "attention_bam_384_attention_spatial_variance": 170.41996978900573,
      "attention_bam_384_attention_spatial_std": 13.054499982343472,
      "attention_bam_384_num_attention_peaks": 19,
      "attention_bam_384_peak_separation_mean": 17.09156051766111,
      "attention_bam_384_peak_intensity_mean": 0.2907749116420746,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.27091631293296814,
      "attention_bam_16_std_attention": 0.4776909649372101,
      "attention_bam_16_max_attention": 2.7158210277557373,
      "attention_bam_16_min_attention": -1.0187315940856934,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8961516080158192,
      "attention_bam_16_attention_skewness": 0.5140608176948319,
      "attention_bam_16_attention_sparsity": 0.372802734375,
      "attention_bam_16_attention_concentration_10": 0.4372712913951695,
      "attention_bam_16_attention_concentration_20": 0.7184015124390691,
      "attention_bam_16_attention_center_y": 0.46803501918187407,
      "attention_bam_16_attention_center_x": 0.4659490014471433,
      "attention_bam_16_attention_center_distance": 0.06604892885050911,
      "attention_bam_16_attention_spatial_variance": 41.15139821891463,
      "attention_bam_16_attention_spatial_std": 6.414935558438185,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.106464610164595,
      "attention_bam_16_peak_intensity_mean": 0.35517948865890503,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 19,
      "phase": "train",
      "loss": 0.30042576789855957,
      "timestamp": 1759543884.218199,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.30042576789855957,
      "ssim": 0.12989182770252228,
      "attention_bam_384_mean_attention": 0.2309279888868332,
      "attention_bam_384_std_attention": 0.601518988609314,
      "attention_bam_384_max_attention": 4.401276588439941,
      "attention_bam_384_min_attention": -1.5509144067764282,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8193421654043447,
      "attention_bam_384_attention_skewness": 0.576364447572193,
      "attention_bam_384_attention_sparsity": 0.44059499104817706,
      "attention_bam_384_attention_concentration_10": 0.607371634104973,
      "attention_bam_384_attention_concentration_20": 0.9716277727598361,
      "attention_bam_384_attention_center_y": 0.48476648958039964,
      "attention_bam_384_attention_center_x": 0.4839753292946488,
      "attention_bam_384_attention_center_distance": 0.03126819185431141,
      "attention_bam_384_attention_spatial_variance": 169.683155586202,
      "attention_bam_384_attention_spatial_std": 13.026248715044634,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 19.618445011341457,
      "attention_bam_384_peak_intensity_mean": 0.2991619408130646,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2587593197822571,
      "attention_bam_16_std_attention": 0.6484429240226746,
      "attention_bam_16_max_attention": 3.207200765609741,
      "attention_bam_16_min_attention": -1.2363499402999878,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7288747890062237,
      "attention_bam_16_attention_skewness": 0.7034970187815729,
      "attention_bam_16_attention_sparsity": 0.4423828125,
      "attention_bam_16_attention_concentration_10": 0.6016990224672865,
      "attention_bam_16_attention_concentration_20": 0.9568454879724596,
      "attention_bam_16_attention_center_y": 0.47288579703909545,
      "attention_bam_16_attention_center_x": 0.46926428317563557,
      "attention_bam_16_attention_center_distance": 0.057963165733293825,
      "attention_bam_16_attention_spatial_variance": 40.726513744909816,
      "attention_bam_16_attention_spatial_std": 6.381732816791206,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 7.302959822359776,
      "attention_bam_16_peak_intensity_mean": 0.3446008265018463,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 20,
      "phase": "train",
      "loss": 0.27689290046691895,
      "timestamp": 1759543884.3836858,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.27689290046691895,
      "ssim": 0.16104765236377716,
      "attention_bam_384_mean_attention": 0.24132554233074188,
      "attention_bam_384_std_attention": 0.507631242275238,
      "attention_bam_384_max_attention": 4.227688789367676,
      "attention_bam_384_min_attention": -1.548990249633789,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5139443252308,
      "attention_bam_384_attention_skewness": 0.5635329078315346,
      "attention_bam_384_attention_sparsity": 0.3985544840494792,
      "attention_bam_384_attention_concentration_10": 0.5042365946140157,
      "attention_bam_384_attention_concentration_20": 0.8089751028953451,
      "attention_bam_384_attention_center_y": 0.48646767277823644,
      "attention_bam_384_attention_center_x": 0.48413756933847096,
      "attention_bam_384_attention_center_distance": 0.029486966155530467,
      "attention_bam_384_attention_spatial_variance": 170.09996250977127,
      "attention_bam_384_attention_spatial_std": 13.042237634308435,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 17.7508214542985,
      "attention_bam_384_peak_intensity_mean": 0.31122544407844543,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.27319836616516113,
      "attention_bam_16_std_attention": 0.4694349765777588,
      "attention_bam_16_max_attention": 2.610577344894409,
      "attention_bam_16_min_attention": -0.9233575463294983,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5167063051073186,
      "attention_bam_16_attention_skewness": 0.4384630039831073,
      "attention_bam_16_attention_sparsity": 0.364990234375,
      "attention_bam_16_attention_concentration_10": 0.43035525409410713,
      "attention_bam_16_attention_concentration_20": 0.7046563461809464,
      "attention_bam_16_attention_center_y": 0.4828027185949577,
      "attention_bam_16_attention_center_x": 0.47606298977104106,
      "attention_bam_16_attention_center_distance": 0.04168277693305709,
      "attention_bam_16_attention_spatial_variance": 41.02404633843575,
      "attention_bam_16_attention_spatial_std": 6.405001665763699,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.620085563002856,
      "attention_bam_16_peak_intensity_mean": 0.340448260307312,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 21,
      "phase": "train",
      "loss": 0.29836198687553406,
      "timestamp": 1759543884.5192096,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.29836198687553406,
      "ssim": 0.12883025407791138,
      "attention_bam_384_mean_attention": 0.2312128096818924,
      "attention_bam_384_std_attention": 0.5849518775939941,
      "attention_bam_384_max_attention": 5.1537981033325195,
      "attention_bam_384_min_attention": -1.5392740964889526,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.120743428625123,
      "attention_bam_384_attention_skewness": 0.5775211500668797,
      "attention_bam_384_attention_sparsity": 0.43449656168619794,
      "attention_bam_384_attention_concentration_10": 0.5878649744330566,
      "attention_bam_384_attention_concentration_20": 0.940477199135574,
      "attention_bam_384_attention_center_y": 0.48120668183664195,
      "attention_bam_384_attention_center_x": 0.4823454692381788,
      "attention_bam_384_attention_center_distance": 0.03646563489120394,
      "attention_bam_384_attention_spatial_variance": 170.36095969889737,
      "attention_bam_384_attention_spatial_std": 13.052239643022855,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 16.27526214615358,
      "attention_bam_384_peak_intensity_mean": 0.26849067211151123,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23785558342933655,
      "attention_bam_16_std_attention": 0.5795230269432068,
      "attention_bam_16_max_attention": 2.4573287963867188,
      "attention_bam_16_min_attention": -0.9439109563827515,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.08069079695644232,
      "attention_bam_16_attention_skewness": 0.4652122244022203,
      "attention_bam_16_attention_sparsity": 0.438720703125,
      "attention_bam_16_attention_concentration_10": 0.5653230647462262,
      "attention_bam_16_attention_concentration_20": 0.9284275531037032,
      "attention_bam_16_attention_center_y": 0.4653557790583511,
      "attention_bam_16_attention_center_x": 0.4669125534842563,
      "attention_bam_16_attention_center_distance": 0.06774955588911238,
      "attention_bam_16_attention_spatial_variance": 41.25463494664093,
      "attention_bam_16_attention_spatial_std": 6.422977109303826,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.958949818581255,
      "attention_bam_16_peak_intensity_mean": 0.3622314929962158,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 22,
      "phase": "train",
      "loss": 0.2959652841091156,
      "timestamp": 1759543884.6464934,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.2959652841091156,
      "ssim": 0.13940651714801788,
      "attention_bam_384_mean_attention": 0.2311651110649109,
      "attention_bam_384_std_attention": 0.5790621638298035,
      "attention_bam_384_max_attention": 5.222625732421875,
      "attention_bam_384_min_attention": -1.5429470539093018,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4497406464740328,
      "attention_bam_384_attention_skewness": 0.6715887548826126,
      "attention_bam_384_attention_sparsity": 0.441009521484375,
      "attention_bam_384_attention_concentration_10": 0.585242693096004,
      "attention_bam_384_attention_concentration_20": 0.9368893867005028,
      "attention_bam_384_attention_center_y": 0.4862137083927066,
      "attention_bam_384_attention_center_x": 0.4863040389166058,
      "attention_bam_384_attention_center_distance": 0.02748240114251944,
      "attention_bam_384_attention_spatial_variance": 171.1626186065503,
      "attention_bam_384_attention_spatial_std": 13.082913230872943,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 19.210810940305862,
      "attention_bam_384_peak_intensity_mean": 0.26372361183166504,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24717825651168823,
      "attention_bam_16_std_attention": 0.6150215864181519,
      "attention_bam_16_max_attention": 3.127889394760132,
      "attention_bam_16_min_attention": -0.9996352195739746,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8437714795426032,
      "attention_bam_16_attention_skewness": 0.7702646273684834,
      "attention_bam_16_attention_sparsity": 0.456298828125,
      "attention_bam_16_attention_concentration_10": 0.5999311423746551,
      "attention_bam_16_attention_concentration_20": 0.9561645473954881,
      "attention_bam_16_attention_center_y": 0.4842440765734046,
      "attention_bam_16_attention_center_x": 0.4854250404870712,
      "attention_bam_16_attention_center_distance": 0.030353865250681036,
      "attention_bam_16_attention_spatial_variance": 42.47582281079355,
      "attention_bam_16_attention_spatial_std": 6.517347835645536,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.17011408891607,
      "attention_bam_16_peak_intensity_mean": 0.3068714141845703,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 23,
      "phase": "train",
      "loss": 0.292339950799942,
      "timestamp": 1759543884.7847028,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.292339950799942,
      "ssim": 0.1663302779197693,
      "attention_bam_384_mean_attention": 0.22213225066661835,
      "attention_bam_384_std_attention": 0.5884943008422852,
      "attention_bam_384_max_attention": 4.689919471740723,
      "attention_bam_384_min_attention": -1.5907788276672363,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.3482915341740638,
      "attention_bam_384_attention_skewness": 0.6861836554938453,
      "attention_bam_384_attention_sparsity": 0.4459075927734375,
      "attention_bam_384_attention_concentration_10": 0.616714676785363,
      "attention_bam_384_attention_concentration_20": 0.9794926460708904,
      "attention_bam_384_attention_center_y": 0.4795444094605786,
      "attention_bam_384_attention_center_x": 0.4807348863974725,
      "attention_bam_384_attention_center_distance": 0.03973854014517282,
      "attention_bam_384_attention_spatial_variance": 170.91987935498815,
      "attention_bam_384_attention_spatial_std": 13.0736329822658,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 14.737760244414646,
      "attention_bam_384_peak_intensity_mean": 0.2922031879425049,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23241651058197021,
      "attention_bam_16_std_attention": 0.5974450707435608,
      "attention_bam_16_max_attention": 2.544224977493286,
      "attention_bam_16_min_attention": -1.0452451705932617,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.19207946888771765,
      "attention_bam_16_attention_skewness": 0.5576885413135743,
      "attention_bam_16_attention_sparsity": 0.450927734375,
      "attention_bam_16_attention_concentration_10": 0.5949399405266972,
      "attention_bam_16_attention_concentration_20": 0.9736118156429332,
      "attention_bam_16_attention_center_y": 0.4554098355720841,
      "attention_bam_16_attention_center_x": 0.4610646514742628,
      "attention_bam_16_attention_center_distance": 0.08371671432311716,
      "attention_bam_16_attention_spatial_variance": 41.78035681378815,
      "attention_bam_16_attention_spatial_std": 6.463772645583085,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.538119646702851,
      "attention_bam_16_peak_intensity_mean": 0.3657669126987457,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 24,
      "phase": "train",
      "loss": 0.31093689799308777,
      "timestamp": 1759543884.925554,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.31093689799308777,
      "ssim": 0.143528014421463,
      "attention_bam_384_mean_attention": 0.21615241467952728,
      "attention_bam_384_std_attention": 0.5957567095756531,
      "attention_bam_384_max_attention": 4.934524059295654,
      "attention_bam_384_min_attention": -1.6253445148468018,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8319870392905502,
      "attention_bam_384_attention_skewness": 0.7971601442120995,
      "attention_bam_384_attention_sparsity": 0.45293426513671875,
      "attention_bam_384_attention_concentration_10": 0.6473613163043539,
      "attention_bam_384_attention_concentration_20": 1.0122639245311034,
      "attention_bam_384_attention_center_y": 0.48546375789580964,
      "attention_bam_384_attention_center_x": 0.47849990708065715,
      "attention_bam_384_attention_center_distance": 0.03670303339104311,
      "attention_bam_384_attention_spatial_variance": 171.94839136003833,
      "attention_bam_384_attention_spatial_std": 13.112909340037334,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 20.114357570110396,
      "attention_bam_384_peak_intensity_mean": 0.2813744843006134,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2205199897289276,
      "attention_bam_16_std_attention": 0.6211221218109131,
      "attention_bam_16_max_attention": 2.8261966705322266,
      "attention_bam_16_min_attention": -1.0182257890701294,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.3893197427401911,
      "attention_bam_16_attention_skewness": 0.6576204467635086,
      "attention_bam_16_attention_sparsity": 0.465087890625,
      "attention_bam_16_attention_concentration_10": 0.6537767877233728,
      "attention_bam_16_attention_concentration_20": 1.0469468362484797,
      "attention_bam_16_attention_center_y": 0.48200880084335357,
      "attention_bam_16_attention_center_x": 0.45289220089300253,
      "attention_bam_16_attention_center_distance": 0.07131378525641935,
      "attention_bam_16_attention_spatial_variance": 43.242565576568566,
      "attention_bam_16_attention_spatial_std": 6.5759079659442135,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 10.876919233871009,
      "attention_bam_16_peak_intensity_mean": 0.3275264799594879,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 25,
      "phase": "train",
      "loss": 0.29102063179016113,
      "timestamp": 1759543885.0572486,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.29102063179016113,
      "ssim": 0.1589268147945404,
      "attention_bam_384_mean_attention": 0.21622376143932343,
      "attention_bam_384_std_attention": 0.5595305562019348,
      "attention_bam_384_max_attention": 4.313748359680176,
      "attention_bam_384_min_attention": -1.5844690799713135,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2699847640940858,
      "attention_bam_384_attention_skewness": 0.6197716685217126,
      "attention_bam_384_attention_sparsity": 0.4427998860677083,
      "attention_bam_384_attention_concentration_10": 0.6053437696465799,
      "attention_bam_384_attention_concentration_20": 0.9615775136364202,
      "attention_bam_384_attention_center_y": 0.48640053160490376,
      "attention_bam_384_attention_center_x": 0.48373297289579975,
      "attention_bam_384_attention_center_distance": 0.029985386822184133,
      "attention_bam_384_attention_spatial_variance": 170.39530936598,
      "attention_bam_384_attention_spatial_std": 13.053555430072683,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 19.893386667887594,
      "attention_bam_384_peak_intensity_mean": 0.3065706491470337,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24058689177036285,
      "attention_bam_16_std_attention": 0.5700751543045044,
      "attention_bam_16_max_attention": 2.467022180557251,
      "attention_bam_16_min_attention": -1.0670111179351807,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.14906680630187585,
      "attention_bam_16_attention_skewness": 0.5375802712023859,
      "attention_bam_16_attention_sparsity": 0.439697265625,
      "attention_bam_16_attention_concentration_10": 0.5671934363378278,
      "attention_bam_16_attention_concentration_20": 0.9134217661495392,
      "attention_bam_16_attention_center_y": 0.4807716253088755,
      "attention_bam_16_attention_center_x": 0.4780575973532759,
      "attention_bam_16_attention_center_distance": 0.041260136383032976,
      "attention_bam_16_attention_spatial_variance": 41.35513353145004,
      "attention_bam_16_attention_spatial_std": 6.430795715263395,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.439655324762466,
      "attention_bam_16_peak_intensity_mean": 0.3724057674407959,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 26,
      "phase": "train",
      "loss": 0.3356815278530121,
      "timestamp": 1759543885.1894681,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3356815278530121,
      "ssim": 0.14035765826702118,
      "attention_bam_384_mean_attention": 0.227347269654274,
      "attention_bam_384_std_attention": 0.5898676514625549,
      "attention_bam_384_max_attention": 5.590204238891602,
      "attention_bam_384_min_attention": -1.6020255088806152,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.339068714768131,
      "attention_bam_384_attention_skewness": 0.60216228087812,
      "attention_bam_384_attention_sparsity": 0.4375864664713542,
      "attention_bam_384_attention_concentration_10": 0.5976692429965765,
      "attention_bam_384_attention_concentration_20": 0.960311159114173,
      "attention_bam_384_attention_center_y": 0.48598162057361116,
      "attention_bam_384_attention_center_x": 0.47967997260580614,
      "attention_bam_384_attention_center_distance": 0.03491184541220904,
      "attention_bam_384_attention_spatial_variance": 170.71576509162185,
      "attention_bam_384_attention_spatial_std": 13.065824317341093,
      "attention_bam_384_num_attention_peaks": 20,
      "attention_bam_384_peak_separation_mean": 16.704901066454127,
      "attention_bam_384_peak_intensity_mean": 0.25527212023735046,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2416812926530838,
      "attention_bam_16_std_attention": 0.5803108215332031,
      "attention_bam_16_max_attention": 2.499664545059204,
      "attention_bam_16_min_attention": -1.1769309043884277,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.05555342777076078,
      "attention_bam_16_attention_skewness": 0.45759787944555164,
      "attention_bam_16_attention_sparsity": 0.43603515625,
      "attention_bam_16_attention_concentration_10": 0.5637281114875413,
      "attention_bam_16_attention_concentration_20": 0.9169840575969072,
      "attention_bam_16_attention_center_y": 0.48155646543541486,
      "attention_bam_16_attention_center_x": 0.4628581148090053,
      "attention_bam_16_attention_center_distance": 0.05864611841846105,
      "attention_bam_16_attention_spatial_variance": 41.67606740880721,
      "attention_bam_16_attention_spatial_std": 6.4557003809662055,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 8.323418297636358,
      "attention_bam_16_peak_intensity_mean": 0.39098891615867615,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 27,
      "phase": "train",
      "loss": 0.30597537755966187,
      "timestamp": 1759543885.3223212,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.30597537755966187,
      "ssim": 0.19406452775001526,
      "attention_bam_384_mean_attention": 0.22170227766036987,
      "attention_bam_384_std_attention": 0.5370602011680603,
      "attention_bam_384_max_attention": 4.518752098083496,
      "attention_bam_384_min_attention": -1.622511863708496,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.030300890152077,
      "attention_bam_384_attention_skewness": 0.7326143373846111,
      "attention_bam_384_attention_sparsity": 0.43034617106119794,
      "attention_bam_384_attention_concentration_10": 0.5779879467400431,
      "attention_bam_384_attention_concentration_20": 0.9073373719970773,
      "attention_bam_384_attention_center_y": 0.48634152793768093,
      "attention_bam_384_attention_center_x": 0.48355151773063015,
      "attention_bam_384_attention_center_distance": 0.030235953037499073,
      "attention_bam_384_attention_spatial_variance": 169.91211528737205,
      "attention_bam_384_attention_spatial_std": 13.035034149835283,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 18.119759668156068,
      "attention_bam_384_peak_intensity_mean": 0.3020004332065582,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24427729845046997,
      "attention_bam_16_std_attention": 0.554815411567688,
      "attention_bam_16_max_attention": 2.8572299480438232,
      "attention_bam_16_min_attention": -1.0810456275939941,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.9075325760979345,
      "attention_bam_16_attention_skewness": 0.6976666796770126,
      "attention_bam_16_attention_sparsity": 0.42431640625,
      "attention_bam_16_attention_concentration_10": 0.5505929541829849,
      "attention_bam_16_attention_concentration_20": 0.8793044445489826,
      "attention_bam_16_attention_center_y": 0.481603383750984,
      "attention_bam_16_attention_center_x": 0.47110592959364544,
      "attention_bam_16_attention_center_distance": 0.048441775237101574,
      "attention_bam_16_attention_spatial_variance": 41.32756804565733,
      "attention_bam_16_attention_spatial_std": 6.428652117330454,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.802201120638433,
      "attention_bam_16_peak_intensity_mean": 0.34488141536712646,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 28,
      "phase": "train",
      "loss": 0.28691303730010986,
      "timestamp": 1759543885.455693,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.28691303730010986,
      "ssim": 0.16142484545707703,
      "attention_bam_384_mean_attention": 0.22218656539916992,
      "attention_bam_384_std_attention": 0.5818865895271301,
      "attention_bam_384_max_attention": 5.667741775512695,
      "attention_bam_384_min_attention": -1.6151950359344482,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4712806390457098,
      "attention_bam_384_attention_skewness": 0.5865356965658145,
      "attention_bam_384_attention_sparsity": 0.4362843831380208,
      "attention_bam_384_attention_concentration_10": 0.5963627343463729,
      "attention_bam_384_attention_concentration_20": 0.9615368519546756,
      "attention_bam_384_attention_center_y": 0.48809905793181046,
      "attention_bam_384_attention_center_x": 0.48121151050882155,
      "attention_bam_384_attention_center_distance": 0.03145281416568401,
      "attention_bam_384_attention_spatial_variance": 171.20730682282547,
      "attention_bam_384_attention_spatial_std": 13.084621004172245,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 17.64744371333968,
      "attention_bam_384_peak_intensity_mean": 0.2533702850341797,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2149694859981537,
      "attention_bam_16_std_attention": 0.6139112710952759,
      "attention_bam_16_max_attention": 2.321500539779663,
      "attention_bam_16_min_attention": -1.1593317985534668,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.4782488894355934,
      "attention_bam_16_attention_skewness": 0.2680721119903088,
      "attention_bam_16_attention_sparsity": 0.44677734375,
      "attention_bam_16_attention_concentration_10": 0.6182416241090584,
      "attention_bam_16_attention_concentration_20": 1.0271841305914984,
      "attention_bam_16_attention_center_y": 0.49191437181592323,
      "attention_bam_16_attention_center_x": 0.4599169502052379,
      "attention_bam_16_attention_center_distance": 0.057827817942241545,
      "attention_bam_16_attention_spatial_variance": 42.53204175496788,
      "attention_bam_16_attention_spatial_std": 6.521659432611295,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.95209736419586,
      "attention_bam_16_peak_intensity_mean": 0.4144841730594635,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 29,
      "phase": "train",
      "loss": 0.26490646600723267,
      "timestamp": 1759543885.5835576,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.26490646600723267,
      "ssim": 0.21171525120735168,
      "attention_bam_384_mean_attention": 0.2364654541015625,
      "attention_bam_384_std_attention": 0.5169011354446411,
      "attention_bam_384_max_attention": 4.945559501647949,
      "attention_bam_384_min_attention": -1.611642837524414,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.414296086998382,
      "attention_bam_384_attention_skewness": 0.5859224446227671,
      "attention_bam_384_attention_sparsity": 0.39877065022786456,
      "attention_bam_384_attention_concentration_10": 0.5123886545244766,
      "attention_bam_384_attention_concentration_20": 0.8210438243422575,
      "attention_bam_384_attention_center_y": 0.483482027909863,
      "attention_bam_384_attention_center_x": 0.48489862091947433,
      "attention_bam_384_attention_center_distance": 0.03165106797895714,
      "attention_bam_384_attention_spatial_variance": 170.84295331973493,
      "attention_bam_384_attention_spatial_std": 13.070690621376322,
      "attention_bam_384_num_attention_peaks": 22,
      "attention_bam_384_peak_separation_mean": 17.39973128916825,
      "attention_bam_384_peak_intensity_mean": 0.28293561935424805,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2639024555683136,
      "attention_bam_16_std_attention": 0.44963252544403076,
      "attention_bam_16_max_attention": 2.038027763366699,
      "attention_bam_16_min_attention": -1.0252678394317627,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.09694927010072796,
      "attention_bam_16_attention_skewness": 0.005952850582026436,
      "attention_bam_16_attention_sparsity": 0.3466796875,
      "attention_bam_16_attention_concentration_10": 0.3937613557443519,
      "attention_bam_16_attention_concentration_20": 0.6682494838786359,
      "attention_bam_16_attention_center_y": 0.4727337034620337,
      "attention_bam_16_attention_center_x": 0.47849725315696323,
      "attention_bam_16_attention_center_distance": 0.04910843203955999,
      "attention_bam_16_attention_spatial_variance": 42.12185141012284,
      "attention_bam_16_attention_spatial_std": 6.490134930039809,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 8.389349523664121,
      "attention_bam_16_peak_intensity_mean": 0.4294973313808441,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 30,
      "phase": "train",
      "loss": 0.3020942509174347,
      "timestamp": 1759543885.7526467,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3020942509174347,
      "ssim": 0.17036043107509613,
      "attention_bam_384_mean_attention": 0.2337094396352768,
      "attention_bam_384_std_attention": 0.4925580620765686,
      "attention_bam_384_max_attention": 5.252037048339844,
      "attention_bam_384_min_attention": -1.6291651725769043,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.58055299459581,
      "attention_bam_384_attention_skewness": 0.6557225003331142,
      "attention_bam_384_attention_sparsity": 0.40692138671875,
      "attention_bam_384_attention_concentration_10": 0.5011098802250347,
      "attention_bam_384_attention_concentration_20": 0.8057389534165675,
      "attention_bam_384_attention_center_y": 0.48699479627964976,
      "attention_bam_384_attention_center_x": 0.4842224047630533,
      "attention_bam_384_attention_center_distance": 0.02891601062625118,
      "attention_bam_384_attention_spatial_variance": 170.34436297489867,
      "attention_bam_384_attention_spatial_std": 13.051603846841916,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 15.722986467884713,
      "attention_bam_384_peak_intensity_mean": 0.2722119092941284,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2635646462440491,
      "attention_bam_16_std_attention": 0.43870529532432556,
      "attention_bam_16_max_attention": 2.2576403617858887,
      "attention_bam_16_min_attention": -0.9359070062637329,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.07531559353170358,
      "attention_bam_16_attention_skewness": 0.2891027923002997,
      "attention_bam_16_attention_sparsity": 0.375,
      "attention_bam_16_attention_concentration_10": 0.4084907531395052,
      "attention_bam_16_attention_concentration_20": 0.6878535401499556,
      "attention_bam_16_attention_center_y": 0.4857220578051647,
      "attention_bam_16_attention_center_x": 0.4730118542577001,
      "attention_bam_16_attention_center_distance": 0.04317915339435637,
      "attention_bam_16_attention_spatial_variance": 41.26727829845637,
      "attention_bam_16_attention_spatial_std": 6.423961262216356,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.668472886786978,
      "attention_bam_16_peak_intensity_mean": 0.38154563307762146,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 31,
      "phase": "train",
      "loss": 0.21787279844284058,
      "timestamp": 1759543885.8813806,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.21787279844284058,
      "ssim": 0.22583094239234924,
      "attention_bam_384_mean_attention": 0.22570741176605225,
      "attention_bam_384_std_attention": 0.5528326630592346,
      "attention_bam_384_max_attention": 5.928731918334961,
      "attention_bam_384_min_attention": -1.542466640472412,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.3347267171505077,
      "attention_bam_384_attention_skewness": 0.5428709865719916,
      "attention_bam_384_attention_sparsity": 0.42875417073567706,
      "attention_bam_384_attention_concentration_10": 0.5606651663443388,
      "attention_bam_384_attention_concentration_20": 0.9110173512392126,
      "attention_bam_384_attention_center_y": 0.4812839631393476,
      "attention_bam_384_attention_center_x": 0.4792057571724197,
      "attention_bam_384_attention_center_distance": 0.0395648978399205,
      "attention_bam_384_attention_spatial_variance": 170.12817197390828,
      "attention_bam_384_attention_spatial_std": 13.043319055129652,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 15.742029598686647,
      "attention_bam_384_peak_intensity_mean": 0.2377193719148636,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24231381714344025,
      "attention_bam_16_std_attention": 0.5490895509719849,
      "attention_bam_16_max_attention": 2.3561995029449463,
      "attention_bam_16_min_attention": -1.125166654586792,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.09091130172355255,
      "attention_bam_16_attention_skewness": 0.44658727505483714,
      "attention_bam_16_attention_sparsity": 0.423828125,
      "attention_bam_16_attention_concentration_10": 0.5329705520471741,
      "attention_bam_16_attention_concentration_20": 0.8752789811124312,
      "attention_bam_16_attention_center_y": 0.46327712327425835,
      "attention_bam_16_attention_center_x": 0.4557349659254822,
      "attention_bam_16_attention_center_distance": 0.08133834171695709,
      "attention_bam_16_attention_spatial_variance": 41.336798173426345,
      "attention_bam_16_attention_spatial_std": 6.4293699670672515,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.208000829755116,
      "attention_bam_16_peak_intensity_mean": 0.4094815254211426,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 32,
      "phase": "train",
      "loss": 0.2503387928009033,
      "timestamp": 1759543886.0137608,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.2503387928009033,
      "ssim": 0.21875518560409546,
      "attention_bam_384_mean_attention": 0.21799390017986298,
      "attention_bam_384_std_attention": 0.6210964322090149,
      "attention_bam_384_max_attention": 4.952032089233398,
      "attention_bam_384_min_attention": -1.6348559856414795,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.205084030827601,
      "attention_bam_384_attention_skewness": 1.1188193510331117,
      "attention_bam_384_attention_sparsity": 0.46062978108723956,
      "attention_bam_384_attention_concentration_10": 0.6864583021933593,
      "attention_bam_384_attention_concentration_20": 1.0397153953446803,
      "attention_bam_384_attention_center_y": 0.4788064751145566,
      "attention_bam_384_attention_center_x": 0.47484888282326265,
      "attention_bam_384_attention_center_distance": 0.046513314057544455,
      "attention_bam_384_attention_spatial_variance": 170.27144541609326,
      "attention_bam_384_attention_spatial_std": 13.048810114952753,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 14.056577568320922,
      "attention_bam_384_peak_intensity_mean": 0.2862311601638794,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2377633899450302,
      "attention_bam_16_std_attention": 0.7150695323944092,
      "attention_bam_16_max_attention": 4.082350730895996,
      "attention_bam_16_min_attention": -1.2297980785369873,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.7766449556298234,
      "attention_bam_16_attention_skewness": 1.2561722685461798,
      "attention_bam_16_attention_sparsity": 0.488525390625,
      "attention_bam_16_attention_concentration_10": 0.7412832176045877,
      "attention_bam_16_attention_concentration_20": 1.1219953132339848,
      "attention_bam_16_attention_center_y": 0.4527947378476442,
      "attention_bam_16_attention_center_x": 0.4481796290942535,
      "attention_bam_16_attention_center_distance": 0.09913311874123373,
      "attention_bam_16_attention_spatial_variance": 40.938194490122704,
      "attention_bam_16_attention_spatial_std": 6.39829621775381,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 7.117094512809319,
      "attention_bam_16_peak_intensity_mean": 0.29533472657203674,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 33,
      "phase": "train",
      "loss": 0.24428290128707886,
      "timestamp": 1759543886.142257,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.24428290128707886,
      "ssim": 0.22591455280780792,
      "attention_bam_384_mean_attention": 0.20671193301677704,
      "attention_bam_384_std_attention": 0.5395390391349792,
      "attention_bam_384_max_attention": 4.292047500610352,
      "attention_bam_384_min_attention": -1.6421823501586914,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.2235236804487464,
      "attention_bam_384_attention_skewness": 0.7403625595584061,
      "attention_bam_384_attention_sparsity": 0.442047119140625,
      "attention_bam_384_attention_concentration_10": 0.6093531217151787,
      "attention_bam_384_attention_concentration_20": 0.9571700797911041,
      "attention_bam_384_attention_center_y": 0.48439470860962647,
      "attention_bam_384_attention_center_x": 0.4839652162241953,
      "attention_bam_384_attention_center_distance": 0.0316429900646344,
      "attention_bam_384_attention_spatial_variance": 171.48831715284157,
      "attention_bam_384_attention_spatial_std": 13.095354792934844,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 20.844470961474045,
      "attention_bam_384_peak_intensity_mean": 0.31291463971138,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23821523785591125,
      "attention_bam_16_std_attention": 0.5911238193511963,
      "attention_bam_16_max_attention": 2.424424648284912,
      "attention_bam_16_min_attention": -1.1198607683181763,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.1093022154125256,
      "attention_bam_16_attention_skewness": 0.5050546361067412,
      "attention_bam_16_attention_sparsity": 0.450439453125,
      "attention_bam_16_attention_concentration_10": 0.5789782961083647,
      "attention_bam_16_attention_concentration_20": 0.9395937309936998,
      "attention_bam_16_attention_center_y": 0.474470198213707,
      "attention_bam_16_attention_center_x": 0.4726701302767751,
      "attention_bam_16_attention_center_distance": 0.052890312124922324,
      "attention_bam_16_attention_spatial_variance": 43.08416584503805,
      "attention_bam_16_attention_spatial_std": 6.56385297253359,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.267599191836704,
      "attention_bam_16_peak_intensity_mean": 0.38697630167007446,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 34,
      "phase": "train",
      "loss": 0.19831185042858124,
      "timestamp": 1759543886.2694435,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.19831185042858124,
      "ssim": 0.2389984279870987,
      "attention_bam_384_mean_attention": 0.21794486045837402,
      "attention_bam_384_std_attention": 0.5283489227294922,
      "attention_bam_384_max_attention": 5.722368240356445,
      "attention_bam_384_min_attention": -1.591370701789856,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.0797550918821397,
      "attention_bam_384_attention_skewness": 0.6207271984999225,
      "attention_bam_384_attention_sparsity": 0.42224375406901044,
      "attention_bam_384_attention_concentration_10": 0.567150817118343,
      "attention_bam_384_attention_concentration_20": 0.9005000581610331,
      "attention_bam_384_attention_center_y": 0.4852092474458066,
      "attention_bam_384_attention_center_x": 0.48064905961575505,
      "attention_bam_384_attention_center_distance": 0.03444489090921845,
      "attention_bam_384_attention_spatial_variance": 170.9346849415136,
      "attention_bam_384_attention_spatial_std": 13.074199208422426,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 16.75860867550525,
      "attention_bam_384_peak_intensity_mean": 0.24868886172771454,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23239950835704803,
      "attention_bam_16_std_attention": 0.5335832834243774,
      "attention_bam_16_max_attention": 2.5675549507141113,
      "attention_bam_16_min_attention": -1.03937828540802,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.34320456769434315,
      "attention_bam_16_attention_skewness": 0.4745627968568583,
      "attention_bam_16_attention_sparsity": 0.42431640625,
      "attention_bam_16_attention_concentration_10": 0.5390501335953277,
      "attention_bam_16_attention_concentration_20": 0.8754813633370876,
      "attention_bam_16_attention_center_y": 0.47871701708772085,
      "attention_bam_16_attention_center_x": 0.454767903667098,
      "attention_bam_16_attention_center_distance": 0.07069523180969549,
      "attention_bam_16_attention_spatial_variance": 41.94578602335785,
      "attention_bam_16_attention_spatial_std": 6.476556648664308,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 8.025132040137212,
      "attention_bam_16_peak_intensity_mean": 0.36239925026893616,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 35,
      "phase": "train",
      "loss": 0.2605200409889221,
      "timestamp": 1759543886.3977544,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.2605200409889221,
      "ssim": 0.2079371213912964,
      "attention_bam_384_mean_attention": 0.22766314446926117,
      "attention_bam_384_std_attention": 0.5356962084770203,
      "attention_bam_384_max_attention": 4.747298717498779,
      "attention_bam_384_min_attention": -1.6275405883789062,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9395882567154588,
      "attention_bam_384_attention_skewness": 0.45507969565399975,
      "attention_bam_384_attention_sparsity": 0.41879526774088544,
      "attention_bam_384_attention_concentration_10": 0.5459006510445943,
      "attention_bam_384_attention_concentration_20": 0.8830221087785798,
      "attention_bam_384_attention_center_y": 0.4862686858764546,
      "attention_bam_384_attention_center_x": 0.48233422334285947,
      "attention_bam_384_attention_center_distance": 0.03164265009317166,
      "attention_bam_384_attention_spatial_variance": 170.41019733365957,
      "attention_bam_384_attention_spatial_std": 13.054125682467577,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 18.029154310030584,
      "attention_bam_384_peak_intensity_mean": 0.2923210561275482,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.25620946288108826,
      "attention_bam_16_std_attention": 0.5473846197128296,
      "attention_bam_16_max_attention": 2.1846871376037598,
      "attention_bam_16_min_attention": -1.0939794778823853,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.023214624215838864,
      "attention_bam_16_attention_skewness": 0.30932232422143474,
      "attention_bam_16_attention_sparsity": 0.4013671875,
      "attention_bam_16_attention_concentration_10": 0.5029064333484746,
      "attention_bam_16_attention_concentration_20": 0.8201013543890812,
      "attention_bam_16_attention_center_y": 0.4803994421478508,
      "attention_bam_16_attention_center_x": 0.4669242776613444,
      "attention_bam_16_attention_center_distance": 0.05437251651964045,
      "attention_bam_16_attention_spatial_variance": 41.78859471078374,
      "attention_bam_16_attention_spatial_std": 6.464409850155213,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.219188280786781,
      "attention_bam_16_peak_intensity_mean": 0.41315728425979614,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 36,
      "phase": "train",
      "loss": 0.2320100963115692,
      "timestamp": 1759543886.5254416,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.2320100963115692,
      "ssim": 0.22538501024246216,
      "attention_bam_384_mean_attention": 0.2355656772851944,
      "attention_bam_384_std_attention": 0.5231867432594299,
      "attention_bam_384_max_attention": 5.290745258331299,
      "attention_bam_384_min_attention": -1.5880557298660278,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.934096465030395,
      "attention_bam_384_attention_skewness": 0.5720078421734823,
      "attention_bam_384_attention_sparsity": 0.4121042887369792,
      "attention_bam_384_attention_concentration_10": 0.5185422078471935,
      "attention_bam_384_attention_concentration_20": 0.8391722147910827,
      "attention_bam_384_attention_center_y": 0.4837810871668948,
      "attention_bam_384_attention_center_x": 0.4837501118437962,
      "attention_bam_384_attention_center_distance": 0.032468815764576275,
      "attention_bam_384_attention_spatial_variance": 168.8863494252955,
      "attention_bam_384_attention_spatial_std": 12.995628088911113,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 15.240854660552138,
      "attention_bam_384_peak_intensity_mean": 0.2668587565422058,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2751716077327728,
      "attention_bam_16_std_attention": 0.4861895442008972,
      "attention_bam_16_max_attention": 2.0748538970947266,
      "attention_bam_16_min_attention": -1.0498344898223877,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.26206878755058893,
      "attention_bam_16_attention_skewness": 0.331621166107437,
      "attention_bam_16_attention_sparsity": 0.376953125,
      "attention_bam_16_attention_concentration_10": 0.42759901277906104,
      "attention_bam_16_attention_concentration_20": 0.7112742922860809,
      "attention_bam_16_attention_center_y": 0.47371917707957906,
      "attention_bam_16_attention_center_x": 0.4730659323088918,
      "attention_bam_16_attention_center_distance": 0.05321889994661144,
      "attention_bam_16_attention_spatial_variance": 40.53969485761468,
      "attention_bam_16_attention_spatial_std": 6.367078989427937,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.313205955317857,
      "attention_bam_16_peak_intensity_mean": 0.4490419924259186,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 37,
      "phase": "train",
      "loss": 0.23838186264038086,
      "timestamp": 1759543886.6555977,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.23838186264038086,
      "ssim": 0.23413622379302979,
      "attention_bam_384_mean_attention": 0.2283911108970642,
      "attention_bam_384_std_attention": 0.5848062634468079,
      "attention_bam_384_max_attention": 5.267142295837402,
      "attention_bam_384_min_attention": -1.6233408451080322,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8046863275042213,
      "attention_bam_384_attention_skewness": 0.506774832000831,
      "attention_bam_384_attention_sparsity": 0.44130706787109375,
      "attention_bam_384_attention_concentration_10": 0.5817515348227293,
      "attention_bam_384_attention_concentration_20": 0.9485187904169526,
      "attention_bam_384_attention_center_y": 0.4839635119735641,
      "attention_bam_384_attention_center_x": 0.4903953521509151,
      "attention_bam_384_attention_center_distance": 0.026435514314155247,
      "attention_bam_384_attention_spatial_variance": 170.32333971593167,
      "attention_bam_384_attention_spatial_std": 13.050798432124054,
      "attention_bam_384_num_attention_peaks": 26,
      "attention_bam_384_peak_separation_mean": 15.345491187642198,
      "attention_bam_384_peak_intensity_mean": 0.2696146070957184,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.25875866413116455,
      "attention_bam_16_std_attention": 0.5958693027496338,
      "attention_bam_16_max_attention": 2.3669371604919434,
      "attention_bam_16_min_attention": -1.1310365200042725,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.3175069205350418,
      "attention_bam_16_attention_skewness": 0.3538629085854442,
      "attention_bam_16_attention_sparsity": 0.432861328125,
      "attention_bam_16_attention_concentration_10": 0.5277936078268659,
      "attention_bam_16_attention_concentration_20": 0.8838243017480677,
      "attention_bam_16_attention_center_y": 0.47539770240015905,
      "attention_bam_16_attention_center_x": 0.4951061975999892,
      "attention_bam_16_attention_center_distance": 0.035474564102226575,
      "attention_bam_16_attention_spatial_variance": 41.6719037635998,
      "attention_bam_16_attention_spatial_std": 6.455377894716916,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 7.70842382238601,
      "attention_bam_16_peak_intensity_mean": 0.403571754693985,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 38,
      "phase": "train",
      "loss": 0.2889630198478699,
      "timestamp": 1759543886.7836964,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.2889630198478699,
      "ssim": 0.22962580621242523,
      "attention_bam_384_mean_attention": 0.22620785236358643,
      "attention_bam_384_std_attention": 0.5495300889015198,
      "attention_bam_384_max_attention": 5.142239093780518,
      "attention_bam_384_min_attention": -1.6721932888031006,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.100240984508506,
      "attention_bam_384_attention_skewness": 0.6607252630975764,
      "attention_bam_384_attention_sparsity": 0.4318796793619792,
      "attention_bam_384_attention_concentration_10": 0.5650419036145086,
      "attention_bam_384_attention_concentration_20": 0.9045591139679983,
      "attention_bam_384_attention_center_y": 0.48682516881256205,
      "attention_bam_384_attention_center_x": 0.4805234815042005,
      "attention_bam_384_attention_center_distance": 0.03325390050910444,
      "attention_bam_384_attention_spatial_variance": 170.39489721039857,
      "attention_bam_384_attention_spatial_std": 13.053539642962692,
      "attention_bam_384_num_attention_peaks": 20,
      "attention_bam_384_peak_separation_mean": 17.357947814153626,
      "attention_bam_384_peak_intensity_mean": 0.2795321047306061,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.254856675863266,
      "attention_bam_16_std_attention": 0.5198972821235657,
      "attention_bam_16_max_attention": 1.9171342849731445,
      "attention_bam_16_min_attention": -1.152980089187622,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.3180335361915785,
      "attention_bam_16_attention_skewness": 0.29202979823748737,
      "attention_bam_16_attention_sparsity": 0.41015625,
      "attention_bam_16_attention_concentration_10": 0.4759074092890083,
      "attention_bam_16_attention_concentration_20": 0.7995046757998624,
      "attention_bam_16_attention_center_y": 0.4848417101890606,
      "attention_bam_16_attention_center_x": 0.4557425590369721,
      "attention_bam_16_attention_center_distance": 0.06615882149174562,
      "attention_bam_16_attention_spatial_variance": 41.47404772368933,
      "attention_bam_16_attention_spatial_std": 6.440034761062189,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 9.261856469282037,
      "attention_bam_16_peak_intensity_mean": 0.4676327705383301,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 39,
      "phase": "train",
      "loss": 0.2680726945400238,
      "timestamp": 1759543886.91344,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.2680726945400238,
      "ssim": 0.23713000118732452,
      "attention_bam_384_mean_attention": 0.21623878180980682,
      "attention_bam_384_std_attention": 0.6116053462028503,
      "attention_bam_384_max_attention": 5.754106521606445,
      "attention_bam_384_min_attention": -1.69685697555542,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8830247087667153,
      "attention_bam_384_attention_skewness": 0.7280841022993836,
      "attention_bam_384_attention_sparsity": 0.4540812174479167,
      "attention_bam_384_attention_concentration_10": 0.6487254188711962,
      "attention_bam_384_attention_concentration_20": 1.030744729665118,
      "attention_bam_384_attention_center_y": 0.4820419313136003,
      "attention_bam_384_attention_center_x": 0.4800221363635516,
      "attention_bam_384_attention_center_distance": 0.03798966350000948,
      "attention_bam_384_attention_spatial_variance": 170.02599887028435,
      "attention_bam_384_attention_spatial_std": 13.039401783451737,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 17.468626575240936,
      "attention_bam_384_peak_intensity_mean": 0.25783783197402954,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2260163426399231,
      "attention_bam_16_std_attention": 0.6412940621376038,
      "attention_bam_16_max_attention": 2.2788639068603516,
      "attention_bam_16_min_attention": -1.0855107307434082,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.3082457417641917,
      "attention_bam_16_attention_skewness": 0.4484007935795763,
      "attention_bam_16_attention_sparsity": 0.46630859375,
      "attention_bam_16_attention_concentration_10": 0.6507781667552349,
      "attention_bam_16_attention_concentration_20": 1.0649356197594573,
      "attention_bam_16_attention_center_y": 0.4618024711218646,
      "attention_bam_16_attention_center_x": 0.45360532005135995,
      "attention_bam_16_attention_center_distance": 0.0849884408603044,
      "attention_bam_16_attention_spatial_variance": 40.81019514557617,
      "attention_bam_16_attention_spatial_std": 6.38828577519636,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 6.482148793870536,
      "attention_bam_16_peak_intensity_mean": 0.40469643473625183,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 40,
      "phase": "train",
      "loss": 0.20632950961589813,
      "timestamp": 1759543887.080663,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.20632950961589813,
      "ssim": 0.2691352963447571,
      "attention_bam_384_mean_attention": 0.23177647590637207,
      "attention_bam_384_std_attention": 0.5208592414855957,
      "attention_bam_384_max_attention": 4.732554912567139,
      "attention_bam_384_min_attention": -1.5615198612213135,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2790315950493198,
      "attention_bam_384_attention_skewness": 0.4802896307652563,
      "attention_bam_384_attention_sparsity": 0.4076131184895833,
      "attention_bam_384_attention_concentration_10": 0.5248717349986035,
      "attention_bam_384_attention_concentration_20": 0.8434985254195739,
      "attention_bam_384_attention_center_y": 0.48926220670341414,
      "attention_bam_384_attention_center_x": 0.4798316144941069,
      "attention_bam_384_attention_center_distance": 0.032312968876119195,
      "attention_bam_384_attention_spatial_variance": 169.77427523916563,
      "attention_bam_384_attention_spatial_std": 13.029745785669252,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 16.568369997662728,
      "attention_bam_384_peak_intensity_mean": 0.2873612344264984,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2593216300010681,
      "attention_bam_16_std_attention": 0.5020548105239868,
      "attention_bam_16_max_attention": 2.2338013648986816,
      "attention_bam_16_min_attention": -1.142506718635559,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.08516063149162578,
      "attention_bam_16_attention_skewness": 0.2502222976065376,
      "attention_bam_16_attention_sparsity": 0.395263671875,
      "attention_bam_16_attention_concentration_10": 0.4521995910955556,
      "attention_bam_16_attention_concentration_20": 0.7513528298281597,
      "attention_bam_16_attention_center_y": 0.4849272172848713,
      "attention_bam_16_attention_center_x": 0.45888589608039126,
      "attention_bam_16_attention_center_distance": 0.061928318560895354,
      "attention_bam_16_attention_spatial_variance": 41.30650667652969,
      "attention_bam_16_attention_spatial_std": 6.427013822649652,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 7.397915805165652,
      "attention_bam_16_peak_intensity_mean": 0.43067213892936707,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 41,
      "phase": "train",
      "loss": 0.22675108909606934,
      "timestamp": 1759543887.2196364,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.22675108909606934,
      "ssim": 0.24016980826854706,
      "attention_bam_384_mean_attention": 0.21978534758090973,
      "attention_bam_384_std_attention": 0.5584614872932434,
      "attention_bam_384_max_attention": 5.049464225769043,
      "attention_bam_384_min_attention": -1.6354448795318604,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.3019204710211536,
      "attention_bam_384_attention_skewness": 0.5833373456615342,
      "attention_bam_384_attention_sparsity": 0.43923695882161456,
      "attention_bam_384_attention_concentration_10": 0.5853543146504449,
      "attention_bam_384_attention_concentration_20": 0.9432660477939969,
      "attention_bam_384_attention_center_y": 0.48152726607506086,
      "attention_bam_384_attention_center_x": 0.485198297963291,
      "attention_bam_384_attention_center_distance": 0.03347632840814872,
      "attention_bam_384_attention_spatial_variance": 172.19200921498052,
      "attention_bam_384_attention_spatial_std": 13.12219528946969,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 16.981791254298482,
      "attention_bam_384_peak_intensity_mean": 0.28114941716194153,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23281627893447876,
      "attention_bam_16_std_attention": 0.5845001935958862,
      "attention_bam_16_max_attention": 2.165127754211426,
      "attention_bam_16_min_attention": -1.1348919868469238,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.33028284613511616,
      "attention_bam_16_attention_skewness": 0.2572706171198683,
      "attention_bam_16_attention_sparsity": 0.437255859375,
      "attention_bam_16_attention_concentration_10": 0.5602849353334953,
      "attention_bam_16_attention_concentration_20": 0.9296787974533393,
      "attention_bam_16_attention_center_y": 0.46385771229616746,
      "attention_bam_16_attention_center_x": 0.46982657712571296,
      "attention_bam_16_attention_center_distance": 0.06658378794296932,
      "attention_bam_16_attention_spatial_variance": 43.33339766618157,
      "attention_bam_16_attention_spatial_std": 6.5828107724726195,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.397377393562788,
      "attention_bam_16_peak_intensity_mean": 0.4347938597202301,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 42,
      "phase": "train",
      "loss": 0.24152283370494843,
      "timestamp": 1759543887.3450298,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.24152283370494843,
      "ssim": 0.26487648487091064,
      "attention_bam_384_mean_attention": 0.2217838168144226,
      "attention_bam_384_std_attention": 0.5682394504547119,
      "attention_bam_384_max_attention": 4.584859848022461,
      "attention_bam_384_min_attention": -1.6161856651306152,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2081361029117277,
      "attention_bam_384_attention_skewness": 0.6081567239974875,
      "attention_bam_384_attention_sparsity": 0.4341684977213542,
      "attention_bam_384_attention_concentration_10": 0.6032547997826008,
      "attention_bam_384_attention_concentration_20": 0.9473665303649584,
      "attention_bam_384_attention_center_y": 0.48481826997242616,
      "attention_bam_384_attention_center_x": 0.47786747571475274,
      "attention_bam_384_attention_center_distance": 0.0379561209258058,
      "attention_bam_384_attention_spatial_variance": 170.66395072848212,
      "attention_bam_384_attention_spatial_std": 13.063841346574986,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 18.308330829943724,
      "attention_bam_384_peak_intensity_mean": 0.2970249354839325,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24293583631515503,
      "attention_bam_16_std_attention": 0.6057959794998169,
      "attention_bam_16_max_attention": 2.8300094604492188,
      "attention_bam_16_min_attention": -1.2900885343551636,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6205496236863866,
      "attention_bam_16_attention_skewness": 0.6054870643685979,
      "attention_bam_16_attention_sparsity": 0.42822265625,
      "attention_bam_16_attention_concentration_10": 0.5940121502854956,
      "attention_bam_16_attention_concentration_20": 0.9444184031111823,
      "attention_bam_16_attention_center_y": 0.4739802099584787,
      "attention_bam_16_attention_center_x": 0.45011550494164454,
      "attention_bam_16_attention_center_distance": 0.07956748482931882,
      "attention_bam_16_attention_spatial_variance": 41.82532734193377,
      "attention_bam_16_attention_spatial_std": 6.467250369510506,
      "attention_bam_16_num_attention_peaks": 2,
      "attention_bam_16_peak_separation_mean": 8.613516245204034,
      "attention_bam_16_peak_intensity_mean": 0.37644073367118835,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 43,
      "phase": "train",
      "loss": 0.2179861068725586,
      "timestamp": 1759543887.4716516,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.2179861068725586,
      "ssim": 0.2778950333595276,
      "attention_bam_384_mean_attention": 0.22322244942188263,
      "attention_bam_384_std_attention": 0.5780821442604065,
      "attention_bam_384_max_attention": 5.404193878173828,
      "attention_bam_384_min_attention": -1.6288421154022217,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.865460934159504,
      "attention_bam_384_attention_skewness": 0.7255545400844741,
      "attention_bam_384_attention_sparsity": 0.4413909912109375,
      "attention_bam_384_attention_concentration_10": 0.6098824279577494,
      "attention_bam_384_attention_concentration_20": 0.9615873534086644,
      "attention_bam_384_attention_center_y": 0.48502390602654916,
      "attention_bam_384_attention_center_x": 0.47499291477260164,
      "attention_bam_384_attention_center_distance": 0.04122226830905829,
      "attention_bam_384_attention_spatial_variance": 171.0321270984746,
      "attention_bam_384_attention_spatial_std": 13.077925183241973,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 16.69185212676989,
      "attention_bam_384_peak_intensity_mean": 0.2649221122264862,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24962781369686127,
      "attention_bam_16_std_attention": 0.5911195278167725,
      "attention_bam_16_max_attention": 2.4490230083465576,
      "attention_bam_16_min_attention": -1.1694793701171875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.15909614801518446,
      "attention_bam_16_attention_skewness": 0.5620629083512534,
      "attention_bam_16_attention_sparsity": 0.437744140625,
      "attention_bam_16_attention_concentration_10": 0.5727591398323626,
      "attention_bam_16_attention_concentration_20": 0.9166725116475363,
      "attention_bam_16_attention_center_y": 0.47580703411049174,
      "attention_bam_16_attention_center_x": 0.4446634812230204,
      "attention_bam_16_attention_center_distance": 0.08540995151486652,
      "attention_bam_16_attention_spatial_variance": 41.997759390571936,
      "attention_bam_16_attention_spatial_std": 6.480567829331928,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 7.301520674936229,
      "attention_bam_16_peak_intensity_mean": 0.38898035883903503,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 44,
      "phase": "train",
      "loss": 0.22746527194976807,
      "timestamp": 1759543887.6005228,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.22746527194976807,
      "ssim": 0.25375422835350037,
      "attention_bam_384_mean_attention": 0.2195112556219101,
      "attention_bam_384_std_attention": 0.5865639448165894,
      "attention_bam_384_max_attention": 5.658783912658691,
      "attention_bam_384_min_attention": -1.6080029010772705,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0966538632476865,
      "attention_bam_384_attention_skewness": 0.5686459151165985,
      "attention_bam_384_attention_sparsity": 0.44067637125651044,
      "attention_bam_384_attention_concentration_10": 0.6111120262792975,
      "attention_bam_384_attention_concentration_20": 0.9816468738399294,
      "attention_bam_384_attention_center_y": 0.4780488102653145,
      "attention_bam_384_attention_center_x": 0.4845986616311254,
      "attention_bam_384_attention_center_distance": 0.037922445973874924,
      "attention_bam_384_attention_spatial_variance": 170.23177320917696,
      "attention_bam_384_attention_spatial_std": 13.047289879863058,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 15.566248835057372,
      "attention_bam_384_peak_intensity_mean": 0.2543160319328308,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23721404373645782,
      "attention_bam_16_std_attention": 0.6194597482681274,
      "attention_bam_16_max_attention": 2.5603630542755127,
      "attention_bam_16_min_attention": -1.1490602493286133,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.05486194315063475,
      "attention_bam_16_attention_skewness": 0.45255541231017204,
      "attention_bam_16_attention_sparsity": 0.4501953125,
      "attention_bam_16_attention_concentration_10": 0.5975920219372115,
      "attention_bam_16_attention_concentration_20": 0.9770009293728614,
      "attention_bam_16_attention_center_y": 0.45180512317039034,
      "attention_bam_16_attention_center_x": 0.4741262204577075,
      "attention_bam_16_attention_center_distance": 0.07735888598505536,
      "attention_bam_16_attention_spatial_variance": 41.85293379010512,
      "attention_bam_16_attention_spatial_std": 6.469384343977804,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.171489906532212,
      "attention_bam_16_peak_intensity_mean": 0.3851636052131653,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 45,
      "phase": "train",
      "loss": 0.201954185962677,
      "timestamp": 1759543887.7226925,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.201954185962677,
      "ssim": 0.2877354919910431,
      "attention_bam_384_mean_attention": 0.2169194370508194,
      "attention_bam_384_std_attention": 0.5979010462760925,
      "attention_bam_384_max_attention": 5.1048359870910645,
      "attention_bam_384_min_attention": -1.6191970109939575,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5522961312372718,
      "attention_bam_384_attention_skewness": 0.6526588805385922,
      "attention_bam_384_attention_sparsity": 0.44954172770182294,
      "attention_bam_384_attention_concentration_10": 0.6273968752085859,
      "attention_bam_384_attention_concentration_20": 1.004224983291103,
      "attention_bam_384_attention_center_y": 0.4862991096966862,
      "attention_bam_384_attention_center_x": 0.4828867374573833,
      "attention_bam_384_attention_center_distance": 0.031002520863825416,
      "attention_bam_384_attention_spatial_variance": 170.09144581573838,
      "attention_bam_384_attention_spatial_std": 13.041911125894792,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 17.096335339941444,
      "attention_bam_384_peak_intensity_mean": 0.2746352255344391,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2521512508392334,
      "attention_bam_16_std_attention": 0.628609299659729,
      "attention_bam_16_max_attention": 2.6603214740753174,
      "attention_bam_16_min_attention": -1.2926708459854126,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.15761909490733528,
      "attention_bam_16_attention_skewness": 0.3853628763731341,
      "attention_bam_16_attention_sparsity": 0.43994140625,
      "attention_bam_16_attention_concentration_10": 0.5596551126601568,
      "attention_bam_16_attention_concentration_20": 0.9330217549283292,
      "attention_bam_16_attention_center_y": 0.47408689892320055,
      "attention_bam_16_attention_center_x": 0.47087479031127194,
      "attention_bam_16_attention_center_distance": 0.05513196254132087,
      "attention_bam_16_attention_spatial_variance": 41.19353380118267,
      "attention_bam_16_attention_spatial_std": 6.418218896328066,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.27745536108274,
      "attention_bam_16_peak_intensity_mean": 0.39888226985931396,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 46,
      "phase": "train",
      "loss": 0.1932862251996994,
      "timestamp": 1759543887.8502433,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.1932862251996994,
      "ssim": 0.32851600646972656,
      "attention_bam_384_mean_attention": 0.21869464218616486,
      "attention_bam_384_std_attention": 0.5682958960533142,
      "attention_bam_384_max_attention": 4.823041915893555,
      "attention_bam_384_min_attention": -1.6328338384628296,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.3402294018451864,
      "attention_bam_384_attention_skewness": 0.6173595917720495,
      "attention_bam_384_attention_sparsity": 0.4404551188151042,
      "attention_bam_384_attention_concentration_10": 0.6008157160244965,
      "attention_bam_384_attention_concentration_20": 0.959372548777232,
      "attention_bam_384_attention_center_y": 0.4837609212697618,
      "attention_bam_384_attention_center_x": 0.4867325267070155,
      "attention_bam_384_attention_center_distance": 0.02965580973728191,
      "attention_bam_384_attention_spatial_variance": 170.8427813087271,
      "attention_bam_384_attention_spatial_std": 13.070684041347151,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 17.41842648903043,
      "attention_bam_384_peak_intensity_mean": 0.288838654756546,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2435303032398224,
      "attention_bam_16_std_attention": 0.5995962023735046,
      "attention_bam_16_max_attention": 2.4487905502319336,
      "attention_bam_16_min_attention": -1.035926103591919,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.23308775087920308,
      "attention_bam_16_attention_skewness": 0.3137625767137986,
      "attention_bam_16_attention_sparsity": 0.42578125,
      "attention_bam_16_attention_concentration_10": 0.5571270024215027,
      "attention_bam_16_attention_concentration_20": 0.9213596220244091,
      "attention_bam_16_attention_center_y": 0.472918565175789,
      "attention_bam_16_attention_center_x": 0.4774437661107188,
      "attention_bam_16_attention_center_distance": 0.0498435111003618,
      "attention_bam_16_attention_spatial_variance": 42.5855168842801,
      "attention_bam_16_attention_spatial_std": 6.5257579547727715,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.018042342581968,
      "attention_bam_16_peak_intensity_mean": 0.38524129986763,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 47,
      "phase": "train",
      "loss": 0.21877416968345642,
      "timestamp": 1759543887.9779463,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.21877416968345642,
      "ssim": 0.2989337146282196,
      "attention_bam_384_mean_attention": 0.20950108766555786,
      "attention_bam_384_std_attention": 0.5510633587837219,
      "attention_bam_384_max_attention": 4.409530162811279,
      "attention_bam_384_min_attention": -1.6228246688842773,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0787332210096716,
      "attention_bam_384_attention_skewness": 0.5756811230451302,
      "attention_bam_384_attention_sparsity": 0.44528452555338544,
      "attention_bam_384_attention_concentration_10": 0.6031518696651136,
      "attention_bam_384_attention_concentration_20": 0.9682422221557196,
      "attention_bam_384_attention_center_y": 0.4843526070515367,
      "attention_bam_384_attention_center_x": 0.48569832223061804,
      "attention_bam_384_attention_center_distance": 0.02997928928786847,
      "attention_bam_384_attention_spatial_variance": 170.05204042900178,
      "attention_bam_384_attention_spatial_std": 13.040400317053223,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 18.974060618548283,
      "attention_bam_384_peak_intensity_mean": 0.30575141310691833,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23592066764831543,
      "attention_bam_16_std_attention": 0.6000331044197083,
      "attention_bam_16_max_attention": 2.7070281505584717,
      "attention_bam_16_min_attention": -1.1612765789031982,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5179661029994498,
      "attention_bam_16_attention_skewness": 0.5950583306905527,
      "attention_bam_16_attention_sparsity": 0.44140625,
      "attention_bam_16_attention_concentration_10": 0.5995556697457871,
      "attention_bam_16_attention_concentration_20": 0.9589542132827436,
      "attention_bam_16_attention_center_y": 0.47289446628346693,
      "attention_bam_16_attention_center_x": 0.47670036699212176,
      "attention_bam_16_attention_center_distance": 0.050548646991980306,
      "attention_bam_16_attention_spatial_variance": 41.4858907823962,
      "attention_bam_16_attention_spatial_std": 6.440954182603397,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.332167661314656,
      "attention_bam_16_peak_intensity_mean": 0.38060012459754944,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 48,
      "phase": "train",
      "loss": 0.17469635605812073,
      "timestamp": 1759543888.302214,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.17469635605812073,
      "ssim": 0.27606481313705444,
      "attention_bam_384_mean_attention": 0.22378522157669067,
      "attention_bam_384_std_attention": 0.5560377240180969,
      "attention_bam_384_max_attention": 4.513160705566406,
      "attention_bam_384_min_attention": -1.607234239578247,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1204240130612702,
      "attention_bam_384_attention_skewness": 0.5356035713556936,
      "attention_bam_384_attention_sparsity": 0.4262593587239583,
      "attention_bam_384_attention_concentration_10": 0.577190093753383,
      "attention_bam_384_attention_concentration_20": 0.9254882971769927,
      "attention_bam_384_attention_center_y": 0.4797906211581428,
      "attention_bam_384_attention_center_x": 0.4896435719403289,
      "attention_bam_384_attention_center_distance": 0.03211462580597344,
      "attention_bam_384_attention_spatial_variance": 169.13849657363141,
      "attention_bam_384_attention_spatial_std": 13.005325700405638,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 15.775449188604838,
      "attention_bam_384_peak_intensity_mean": 0.30079203844070435,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2581324875354767,
      "attention_bam_16_std_attention": 0.5643094778060913,
      "attention_bam_16_max_attention": 2.714266777038574,
      "attention_bam_16_min_attention": -1.1618061065673828,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.1762964713309576,
      "attention_bam_16_attention_skewness": 0.3497533222159321,
      "attention_bam_16_attention_sparsity": 0.388427734375,
      "attention_bam_16_attention_concentration_10": 0.5170010606672418,
      "attention_bam_16_attention_concentration_20": 0.833755085289804,
      "attention_bam_16_attention_center_y": 0.4587763999722974,
      "attention_bam_16_attention_center_x": 0.489127025181608,
      "attention_bam_16_attention_center_distance": 0.06029273224270712,
      "attention_bam_16_attention_spatial_variance": 40.99498165833969,
      "attention_bam_16_attention_spatial_std": 6.402732358793369,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.895055189776379,
      "attention_bam_16_peak_intensity_mean": 0.3825609087944031,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 49,
      "phase": "train",
      "loss": 0.18336626887321472,
      "timestamp": 1759543888.4286363,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.18336626887321472,
      "ssim": 0.3371489346027374,
      "attention_bam_384_mean_attention": 0.215324267745018,
      "attention_bam_384_std_attention": 0.5656055212020874,
      "attention_bam_384_max_attention": 5.282240867614746,
      "attention_bam_384_min_attention": -1.6547415256500244,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0641128553029287,
      "attention_bam_384_attention_skewness": 0.535067956861508,
      "attention_bam_384_attention_sparsity": 0.4379221598307292,
      "attention_bam_384_attention_concentration_10": 0.598693809759909,
      "attention_bam_384_attention_concentration_20": 0.9666028304170667,
      "attention_bam_384_attention_center_y": 0.4855280568536936,
      "attention_bam_384_attention_center_x": 0.48172219389920706,
      "attention_bam_384_attention_center_distance": 0.03297014814307355,
      "attention_bam_384_attention_spatial_variance": 170.45858626207894,
      "attention_bam_384_attention_spatial_std": 13.055978946907004,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 17.76112786755904,
      "attention_bam_384_peak_intensity_mean": 0.26997968554496765,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2338845133781433,
      "attention_bam_16_std_attention": 0.5859747529029846,
      "attention_bam_16_max_attention": 2.2361364364624023,
      "attention_bam_16_min_attention": -1.1390143632888794,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.03309594343779931,
      "attention_bam_16_attention_skewness": 0.420212264862497,
      "attention_bam_16_attention_sparsity": 0.434326171875,
      "attention_bam_16_attention_concentration_10": 0.5795238244444825,
      "attention_bam_16_attention_concentration_20": 0.9409940567154358,
      "attention_bam_16_attention_center_y": 0.4786856836454099,
      "attention_bam_16_attention_center_x": 0.4663322608924569,
      "attention_bam_16_attention_center_distance": 0.05635275926300564,
      "attention_bam_16_attention_spatial_variance": 41.988458015365254,
      "attention_bam_16_attention_spatial_std": 6.4798501537740245,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.216190348293198,
      "attention_bam_16_peak_intensity_mean": 0.4079855978488922,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 50,
      "phase": "train",
      "loss": 0.21537809073925018,
      "timestamp": 1759543888.6206334,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.21537809073925018,
      "ssim": 0.2911420464515686,
      "attention_bam_384_mean_attention": 0.20731614530086517,
      "attention_bam_384_std_attention": 0.6580814123153687,
      "attention_bam_384_max_attention": 5.832986354827881,
      "attention_bam_384_min_attention": -1.7347540855407715,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.213193756606766,
      "attention_bam_384_attention_skewness": 0.9077229977440746,
      "attention_bam_384_attention_sparsity": 0.4718983968098958,
      "attention_bam_384_attention_concentration_10": 0.7299575458980953,
      "attention_bam_384_attention_concentration_20": 1.1404837940983767,
      "attention_bam_384_attention_center_y": 0.48057263448985926,
      "attention_bam_384_attention_center_x": 0.477998579928088,
      "attention_bam_384_attention_center_distance": 0.04150867417408894,
      "attention_bam_384_attention_spatial_variance": 171.70246334060968,
      "attention_bam_384_attention_spatial_std": 13.103528659891948,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 20.560977110878117,
      "attention_bam_384_peak_intensity_mean": 0.2599378228187561,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2300647497177124,
      "attention_bam_16_std_attention": 0.7584808468818665,
      "attention_bam_16_max_attention": 4.281631946563721,
      "attention_bam_16_min_attention": -1.3536972999572754,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.4607218287773867,
      "attention_bam_16_attention_skewness": 0.9059022734949265,
      "attention_bam_16_attention_sparsity": 0.487060546875,
      "attention_bam_16_attention_concentration_10": 0.7491192653720682,
      "attention_bam_16_attention_concentration_20": 1.1860208930489509,
      "attention_bam_16_attention_center_y": 0.46003511975035294,
      "attention_bam_16_attention_center_x": 0.4528982051502863,
      "attention_bam_16_attention_center_distance": 0.08735869426030986,
      "attention_bam_16_attention_spatial_variance": 42.32526619468175,
      "attention_bam_16_attention_spatial_std": 6.505787131061218,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.117053105867818,
      "attention_bam_16_peak_intensity_mean": 0.2868344187736511,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 51,
      "phase": "train",
      "loss": 0.13767674565315247,
      "timestamp": 1759543888.7611783,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.13767674565315247,
      "ssim": 0.36909326910972595,
      "attention_bam_384_mean_attention": 0.2092844843864441,
      "attention_bam_384_std_attention": 0.5707380175590515,
      "attention_bam_384_max_attention": 5.160214900970459,
      "attention_bam_384_min_attention": -1.6421761512756348,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9481463046287657,
      "attention_bam_384_attention_skewness": 0.5745269329246484,
      "attention_bam_384_attention_sparsity": 0.4488423665364583,
      "attention_bam_384_attention_concentration_10": 0.6246584155722152,
      "attention_bam_384_attention_concentration_20": 1.0026669810879796,
      "attention_bam_384_attention_center_y": 0.4803689960370547,
      "attention_bam_384_attention_center_x": 0.47817234918432155,
      "attention_bam_384_attention_center_distance": 0.041516807601846326,
      "attention_bam_384_attention_spatial_variance": 169.83037028826223,
      "attention_bam_384_attention_spatial_std": 13.031898184388268,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 15.709390432273542,
      "attention_bam_384_peak_intensity_mean": 0.27702271938323975,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23479336500167847,
      "attention_bam_16_std_attention": 0.6376686692237854,
      "attention_bam_16_max_attention": 2.549048900604248,
      "attention_bam_16_min_attention": -1.0491633415222168,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.3050355837177774,
      "attention_bam_16_attention_skewness": 0.388929624689484,
      "attention_bam_16_attention_sparsity": 0.44091796875,
      "attention_bam_16_attention_concentration_10": 0.6099573032794438,
      "attention_bam_16_attention_concentration_20": 1.0032888832822537,
      "attention_bam_16_attention_center_y": 0.45939444066208807,
      "attention_bam_16_attention_center_x": 0.4505031157131625,
      "attention_bam_16_attention_center_distance": 0.09054007955871554,
      "attention_bam_16_attention_spatial_variance": 41.0253228944342,
      "attention_bam_16_attention_spatial_std": 6.405101318045968,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.509321923966093,
      "attention_bam_16_peak_intensity_mean": 0.37643739581108093,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 52,
      "phase": "train",
      "loss": 0.1911657303571701,
      "timestamp": 1759543888.9060936,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.1911657303571701,
      "ssim": 0.3318321704864502,
      "attention_bam_384_mean_attention": 0.2109827846288681,
      "attention_bam_384_std_attention": 0.5515671968460083,
      "attention_bam_384_max_attention": 4.708316326141357,
      "attention_bam_384_min_attention": -1.63358473777771,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.127975480915782,
      "attention_bam_384_attention_skewness": 0.5842638868644643,
      "attention_bam_384_attention_sparsity": 0.4411366780598958,
      "attention_bam_384_attention_concentration_10": 0.6028478278454034,
      "attention_bam_384_attention_concentration_20": 0.9648249274349581,
      "attention_bam_384_attention_center_y": 0.4795636911494219,
      "attention_bam_384_attention_center_x": 0.48770021830031496,
      "attention_bam_384_attention_center_distance": 0.03373210190000394,
      "attention_bam_384_attention_spatial_variance": 170.10844452215312,
      "attention_bam_384_attention_spatial_std": 13.042562804991706,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 14.467713764645,
      "attention_bam_384_peak_intensity_mean": 0.2959420382976532,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23898504674434662,
      "attention_bam_16_std_attention": 0.6141867637634277,
      "attention_bam_16_max_attention": 2.8625926971435547,
      "attention_bam_16_min_attention": -1.2333275079727173,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.3976137383948024,
      "attention_bam_16_attention_skewness": 0.5558567528795305,
      "attention_bam_16_attention_sparsity": 0.43359375,
      "attention_bam_16_attention_concentration_10": 0.5940827465183606,
      "attention_bam_16_attention_concentration_20": 0.9590198038749106,
      "attention_bam_16_attention_center_y": 0.45907597416897605,
      "attention_bam_16_attention_center_x": 0.4808985996586693,
      "attention_bam_16_attention_center_distance": 0.06386923179776163,
      "attention_bam_16_attention_spatial_variance": 41.89676368156782,
      "attention_bam_16_attention_spatial_std": 6.472770943079001,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.102292807192809,
      "attention_bam_16_peak_intensity_mean": 0.3672121465206146,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 53,
      "phase": "train",
      "loss": 0.17484644055366516,
      "timestamp": 1759543889.0375593,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.17484644055366516,
      "ssim": 0.3378574848175049,
      "attention_bam_384_mean_attention": 0.2175879031419754,
      "attention_bam_384_std_attention": 0.5948794484138489,
      "attention_bam_384_max_attention": 5.534738063812256,
      "attention_bam_384_min_attention": -1.6719194650650024,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.652872923481624,
      "attention_bam_384_attention_skewness": 0.6576921766996981,
      "attention_bam_384_attention_sparsity": 0.44371795654296875,
      "attention_bam_384_attention_concentration_10": 0.6272122194850447,
      "attention_bam_384_attention_concentration_20": 0.9965733642645845,
      "attention_bam_384_attention_center_y": 0.48089116467265935,
      "attention_bam_384_attention_center_x": 0.48005694535051563,
      "attention_bam_384_attention_center_distance": 0.03906079918075773,
      "attention_bam_384_attention_spatial_variance": 171.57673865167703,
      "attention_bam_384_attention_spatial_std": 13.098730421368211,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 16.519796138346923,
      "attention_bam_384_peak_intensity_mean": 0.2632811963558197,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24614375829696655,
      "attention_bam_16_std_attention": 0.6506559252738953,
      "attention_bam_16_max_attention": 2.6810526847839355,
      "attention_bam_16_min_attention": -1.1628999710083008,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.22848471522390001,
      "attention_bam_16_attention_skewness": 0.5294834685478591,
      "attention_bam_16_attention_sparsity": 0.437255859375,
      "attention_bam_16_attention_concentration_10": 0.6168889678787188,
      "attention_bam_16_attention_concentration_20": 0.9871863109394101,
      "attention_bam_16_attention_center_y": 0.461945979955498,
      "attention_bam_16_attention_center_x": 0.45410969974331283,
      "attention_bam_16_attention_center_distance": 0.08430928892116527,
      "attention_bam_16_attention_spatial_variance": 42.62939621288438,
      "attention_bam_16_attention_spatial_std": 6.529119099303089,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 10.699570967526961,
      "attention_bam_16_peak_intensity_mean": 0.3839751183986664,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 54,
      "phase": "train",
      "loss": 0.16401001811027527,
      "timestamp": 1759543889.1686745,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.16401001811027527,
      "ssim": 0.31631478667259216,
      "attention_bam_384_mean_attention": 0.23395782709121704,
      "attention_bam_384_std_attention": 0.5039607882499695,
      "attention_bam_384_max_attention": 6.086740493774414,
      "attention_bam_384_min_attention": -1.6212210655212402,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.0766687422668424,
      "attention_bam_384_attention_skewness": 0.5616832261984743,
      "attention_bam_384_attention_sparsity": 0.41947174072265625,
      "attention_bam_384_attention_concentration_10": 0.504112018165145,
      "attention_bam_384_attention_concentration_20": 0.8257395471590374,
      "attention_bam_384_attention_center_y": 0.4791364060388429,
      "attention_bam_384_attention_center_x": 0.4868435576721526,
      "attention_bam_384_attention_center_distance": 0.034882130889669176,
      "attention_bam_384_attention_spatial_variance": 169.2634755568226,
      "attention_bam_384_attention_spatial_std": 13.010129728669988,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 15.465894495919565,
      "attention_bam_384_peak_intensity_mean": 0.24441561102867126,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.27353519201278687,
      "attention_bam_16_std_attention": 0.4792853593826294,
      "attention_bam_16_max_attention": 1.6352365016937256,
      "attention_bam_16_min_attention": -0.8757575154304504,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.40416626056661187,
      "attention_bam_16_attention_skewness": 0.21304086389064555,
      "attention_bam_16_attention_sparsity": 0.384765625,
      "attention_bam_16_attention_concentration_10": 0.41969438190805974,
      "attention_bam_16_attention_concentration_20": 0.7147328083360643,
      "attention_bam_16_attention_center_y": 0.4519503565213673,
      "attention_bam_16_attention_center_x": 0.48032684416101146,
      "attention_bam_16_attention_center_distance": 0.07342753297079836,
      "attention_bam_16_attention_spatial_variance": 40.3827107328896,
      "attention_bam_16_attention_spatial_std": 6.354739234059066,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 6.148782730323421,
      "attention_bam_16_peak_intensity_mean": 0.496286004781723,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 55,
      "phase": "train",
      "loss": 0.1858994960784912,
      "timestamp": 1759543889.300625,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.1858994960784912,
      "ssim": 0.31313443183898926,
      "attention_bam_384_mean_attention": 0.20454515516757965,
      "attention_bam_384_std_attention": 0.5623360872268677,
      "attention_bam_384_max_attention": 5.570217132568359,
      "attention_bam_384_min_attention": -1.6638240814208984,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.6426724350377961,
      "attention_bam_384_attention_skewness": 0.6752236489242972,
      "attention_bam_384_attention_sparsity": 0.4576873779296875,
      "attention_bam_384_attention_concentration_10": 0.633029806912825,
      "attention_bam_384_attention_concentration_20": 1.008295309562341,
      "attention_bam_384_attention_center_y": 0.47944301495727487,
      "attention_bam_384_attention_center_x": 0.48220184886255374,
      "attention_bam_384_attention_center_distance": 0.03845422780288805,
      "attention_bam_384_attention_spatial_variance": 170.85489298074754,
      "attention_bam_384_attention_spatial_std": 13.071147347526441,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 17.896189509667522,
      "attention_bam_384_peak_intensity_mean": 0.2598431408405304,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22502174973487854,
      "attention_bam_16_std_attention": 0.5784091353416443,
      "attention_bam_16_max_attention": 2.2579104900360107,
      "attention_bam_16_min_attention": -0.9883726835250854,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.1614880399019598,
      "attention_bam_16_attention_skewness": 0.47720182960122653,
      "attention_bam_16_attention_sparsity": 0.4599609375,
      "attention_bam_16_attention_concentration_10": 0.5920221993857476,
      "attention_bam_16_attention_concentration_20": 0.9775325452842145,
      "attention_bam_16_attention_center_y": 0.45880016915858174,
      "attention_bam_16_attention_center_x": 0.4624593813061813,
      "attention_bam_16_attention_center_distance": 0.07882542880665055,
      "attention_bam_16_attention_spatial_variance": 42.06900358790179,
      "attention_bam_16_attention_spatial_std": 6.486062255937865,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.982078222408571,
      "attention_bam_16_peak_intensity_mean": 0.3836973011493683,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 56,
      "phase": "train",
      "loss": 0.19472068548202515,
      "timestamp": 1759543889.4296877,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.19472068548202515,
      "ssim": 0.3355256915092468,
      "attention_bam_384_mean_attention": 0.20474748313426971,
      "attention_bam_384_std_attention": 0.5514143109321594,
      "attention_bam_384_max_attention": 5.652107238769531,
      "attention_bam_384_min_attention": -1.6282145977020264,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5781041221772334,
      "attention_bam_384_attention_skewness": 0.5481704004420285,
      "attention_bam_384_attention_sparsity": 0.44143931070963544,
      "attention_bam_384_attention_concentration_10": 0.6033133701001786,
      "attention_bam_384_attention_concentration_20": 0.9764761319392598,
      "attention_bam_384_attention_center_y": 0.4820507336232506,
      "attention_bam_384_attention_center_x": 0.4903309078354736,
      "attention_bam_384_attention_center_distance": 0.02883288077003791,
      "attention_bam_384_attention_spatial_variance": 171.64253383852682,
      "attention_bam_384_attention_spatial_std": 13.101241690714923,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 16.81544479486104,
      "attention_bam_384_peak_intensity_mean": 0.2522509694099426,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22686001658439636,
      "attention_bam_16_std_attention": 0.5776309370994568,
      "attention_bam_16_max_attention": 2.5307321548461914,
      "attention_bam_16_min_attention": -1.0157206058502197,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.11742333394801063,
      "attention_bam_16_attention_skewness": 0.3350767083932012,
      "attention_bam_16_attention_sparsity": 0.43896484375,
      "attention_bam_16_attention_concentration_10": 0.5694800253060069,
      "attention_bam_16_attention_concentration_20": 0.9422146857314481,
      "attention_bam_16_attention_center_y": 0.4623605270969322,
      "attention_bam_16_attention_center_x": 0.48952103722545515,
      "attention_bam_16_attention_center_distance": 0.05525465738290432,
      "attention_bam_16_attention_spatial_variance": 42.458639761598015,
      "attention_bam_16_attention_spatial_std": 6.516029447569894,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 8.612837140765828,
      "attention_bam_16_peak_intensity_mean": 0.35801127552986145,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 57,
      "phase": "train",
      "loss": 0.1658623218536377,
      "timestamp": 1759543889.5602407,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.1658623218536377,
      "ssim": 0.30894070863723755,
      "attention_bam_384_mean_attention": 0.20077712833881378,
      "attention_bam_384_std_attention": 0.5312519669532776,
      "attention_bam_384_max_attention": 4.970900058746338,
      "attention_bam_384_min_attention": -1.5987014770507812,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2797566999736496,
      "attention_bam_384_attention_skewness": 0.5393340044945065,
      "attention_bam_384_attention_sparsity": 0.4481862386067708,
      "attention_bam_384_attention_concentration_10": 0.5994962715145651,
      "attention_bam_384_attention_concentration_20": 0.970308677184175,
      "attention_bam_384_attention_center_y": 0.4865006821157008,
      "attention_bam_384_attention_center_x": 0.4875777459524826,
      "attention_bam_384_attention_center_distance": 0.02594393875117742,
      "attention_bam_384_attention_spatial_variance": 169.1463825080124,
      "attention_bam_384_attention_spatial_std": 13.005628877836411,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 18.734084003308435,
      "attention_bam_384_peak_intensity_mean": 0.2763108015060425,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23564758896827698,
      "attention_bam_16_std_attention": 0.5902009010314941,
      "attention_bam_16_max_attention": 2.2332983016967773,
      "attention_bam_16_min_attention": -1.0402394533157349,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.26716999627326876,
      "attention_bam_16_attention_skewness": 0.38223889809699557,
      "attention_bam_16_attention_sparsity": 0.44921875,
      "attention_bam_16_attention_concentration_10": 0.5689336097568721,
      "attention_bam_16_attention_concentration_20": 0.9454054820295219,
      "attention_bam_16_attention_center_y": 0.48713415956758865,
      "attention_bam_16_attention_center_x": 0.4833300569840824,
      "attention_bam_16_attention_center_distance": 0.029779753195290627,
      "attention_bam_16_attention_spatial_variance": 40.85366632796779,
      "attention_bam_16_attention_spatial_std": 6.391687283336677,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 6.91432551545319,
      "attention_bam_16_peak_intensity_mean": 0.4088817536830902,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 58,
      "phase": "train",
      "loss": 0.15661858022212982,
      "timestamp": 1759543889.6880462,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.15661858022212982,
      "ssim": 0.33754152059555054,
      "attention_bam_384_mean_attention": 0.20382829010486603,
      "attention_bam_384_std_attention": 0.5030319094657898,
      "attention_bam_384_max_attention": 4.762381553649902,
      "attention_bam_384_min_attention": -1.5881736278533936,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9367608424708096,
      "attention_bam_384_attention_skewness": 0.46972788383129643,
      "attention_bam_384_attention_sparsity": 0.4392140706380208,
      "attention_bam_384_attention_concentration_10": 0.5678074910512134,
      "attention_bam_384_attention_concentration_20": 0.9194860246802299,
      "attention_bam_384_attention_center_y": 0.4813510598570135,
      "attention_bam_384_attention_center_x": 0.48638804088985627,
      "attention_bam_384_attention_center_distance": 0.032651750313663706,
      "attention_bam_384_attention_spatial_variance": 169.63169409282068,
      "attention_bam_384_attention_spatial_std": 13.024273265438678,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 17.724423323795268,
      "attention_bam_384_peak_intensity_mean": 0.28303343057632446,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24619464576244354,
      "attention_bam_16_std_attention": 0.5641090869903564,
      "attention_bam_16_max_attention": 2.074225902557373,
      "attention_bam_16_min_attention": -1.0279585123062134,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.23594817546170654,
      "attention_bam_16_attention_skewness": 0.36868502487163696,
      "attention_bam_16_attention_sparsity": 0.434326171875,
      "attention_bam_16_attention_concentration_10": 0.5337495943952832,
      "attention_bam_16_attention_concentration_20": 0.8823487185936482,
      "attention_bam_16_attention_center_y": 0.4604516279182991,
      "attention_bam_16_attention_center_x": 0.48040637146745746,
      "attention_bam_16_attention_center_distance": 0.06241769001467334,
      "attention_bam_16_attention_spatial_variance": 41.0473038277435,
      "attention_bam_16_attention_spatial_std": 6.406816980977644,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 8.333721114302994,
      "attention_bam_16_peak_intensity_mean": 0.42081424593925476,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 59,
      "phase": "train",
      "loss": 0.1549050658941269,
      "timestamp": 1759543889.8172648,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.1549050658941269,
      "ssim": 0.35179415345191956,
      "attention_bam_384_mean_attention": 0.2145875096321106,
      "attention_bam_384_std_attention": 0.5446670651435852,
      "attention_bam_384_max_attention": 5.145356178283691,
      "attention_bam_384_min_attention": -1.6404484510421753,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.575800354003336,
      "attention_bam_384_attention_skewness": 0.5627826580166607,
      "attention_bam_384_attention_sparsity": 0.44131215413411456,
      "attention_bam_384_attention_concentration_10": 0.5808617214893045,
      "attention_bam_384_attention_concentration_20": 0.9399623704103393,
      "attention_bam_384_attention_center_y": 0.48277953085630215,
      "attention_bam_384_attention_center_x": 0.4804489081159582,
      "attention_bam_384_attention_center_distance": 0.03684534574101036,
      "attention_bam_384_attention_spatial_variance": 169.69928132415924,
      "attention_bam_384_attention_spatial_std": 13.026867671246194,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 16.835845771390712,
      "attention_bam_384_peak_intensity_mean": 0.2748323082923889,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24927473068237305,
      "attention_bam_16_std_attention": 0.550190806388855,
      "attention_bam_16_max_attention": 2.1488146781921387,
      "attention_bam_16_min_attention": -1.1727216243743896,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.2244003686824474,
      "attention_bam_16_attention_skewness": 0.30066948862904463,
      "attention_bam_16_attention_sparsity": 0.41259765625,
      "attention_bam_16_attention_concentration_10": 0.5097199134554978,
      "attention_bam_16_attention_concentration_20": 0.8432352510691812,
      "attention_bam_16_attention_center_y": 0.4672889943401844,
      "attention_bam_16_attention_center_x": 0.46249260398662995,
      "attention_bam_16_attention_center_distance": 0.07038202394049572,
      "attention_bam_16_attention_spatial_variance": 41.33597278469357,
      "attention_bam_16_attention_spatial_std": 6.42930577781875,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.345157838512332,
      "attention_bam_16_peak_intensity_mean": 0.4352724850177765,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 60,
      "phase": "train",
      "loss": 0.15707820653915405,
      "timestamp": 1759543889.9876466,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.15707820653915405,
      "ssim": 0.39389801025390625,
      "attention_bam_384_mean_attention": 0.21094006299972534,
      "attention_bam_384_std_attention": 0.5291146039962769,
      "attention_bam_384_max_attention": 5.080113410949707,
      "attention_bam_384_min_attention": -1.6072943210601807,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5009053050696348,
      "attention_bam_384_attention_skewness": 0.5767443025420907,
      "attention_bam_384_attention_sparsity": 0.4353383382161458,
      "attention_bam_384_attention_concentration_10": 0.5765043311357424,
      "attention_bam_384_attention_concentration_20": 0.9284835839557866,
      "attention_bam_384_attention_center_y": 0.4854841547410833,
      "attention_bam_384_attention_center_x": 0.48262576711756655,
      "attention_bam_384_attention_center_distance": 0.03201792409991147,
      "attention_bam_384_attention_spatial_variance": 170.3235055165059,
      "attention_bam_384_attention_spatial_std": 13.050804784246292,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 18.43200299027942,
      "attention_bam_384_peak_intensity_mean": 0.27449727058410645,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2352849841117859,
      "attention_bam_16_std_attention": 0.5607309341430664,
      "attention_bam_16_max_attention": 2.4928839206695557,
      "attention_bam_16_min_attention": -1.202850580215454,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.09116525357824612,
      "attention_bam_16_attention_skewness": 0.35424330018258227,
      "attention_bam_16_attention_sparsity": 0.42578125,
      "attention_bam_16_attention_concentration_10": 0.5419449808641938,
      "attention_bam_16_attention_concentration_20": 0.8899954324585473,
      "attention_bam_16_attention_center_y": 0.4781047962264992,
      "attention_bam_16_attention_center_x": 0.4680086822511628,
      "attention_bam_16_attention_center_distance": 0.05482416181922325,
      "attention_bam_16_attention_spatial_variance": 41.73192690283798,
      "attention_bam_16_attention_spatial_std": 6.4600253020276925,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.482604641161661,
      "attention_bam_16_peak_intensity_mean": 0.3991970121860504,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 61,
      "phase": "train",
      "loss": 0.11353062093257904,
      "timestamp": 1759543890.1258812,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.11353062093257904,
      "ssim": 0.3071877360343933,
      "attention_bam_384_mean_attention": 0.21604900062084198,
      "attention_bam_384_std_attention": 0.48516008257865906,
      "attention_bam_384_max_attention": 5.109823703765869,
      "attention_bam_384_min_attention": -1.5677331686019897,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.2549916070690808,
      "attention_bam_384_attention_skewness": 0.6774015020869443,
      "attention_bam_384_attention_sparsity": 0.42863210042317706,
      "attention_bam_384_attention_concentration_10": 0.529162454058213,
      "attention_bam_384_attention_concentration_20": 0.8501662022297485,
      "attention_bam_384_attention_center_y": 0.48020224292359476,
      "attention_bam_384_attention_center_x": 0.480088356591782,
      "attention_bam_384_attention_center_distance": 0.03970956379695916,
      "attention_bam_384_attention_spatial_variance": 170.03706015071776,
      "attention_bam_384_attention_spatial_std": 13.039825924862562,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 16.74305869871085,
      "attention_bam_384_peak_intensity_mean": 0.26920032501220703,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2587539255619049,
      "attention_bam_16_std_attention": 0.47801974415779114,
      "attention_bam_16_max_attention": 2.784224033355713,
      "attention_bam_16_min_attention": -0.9836270213127136,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.015967105759804312,
      "attention_bam_16_attention_skewness": 0.3925537810435487,
      "attention_bam_16_attention_sparsity": 0.402099609375,
      "attention_bam_16_attention_concentration_10": 0.44800371235860237,
      "attention_bam_16_attention_concentration_20": 0.7480088607368363,
      "attention_bam_16_attention_center_y": 0.4624268023889731,
      "attention_bam_16_attention_center_x": 0.45872867416126645,
      "attention_bam_16_attention_center_distance": 0.07893120441503719,
      "attention_bam_16_attention_spatial_variance": 41.0147928237676,
      "attention_bam_16_attention_spatial_std": 6.404279258727526,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 7.506588559788867,
      "attention_bam_16_peak_intensity_mean": 0.3456994891166687,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 62,
      "phase": "train",
      "loss": 0.14304064214229584,
      "timestamp": 1759543890.2545388,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.14304064214229584,
      "ssim": 0.3468208312988281,
      "attention_bam_384_mean_attention": 0.2016938477754593,
      "attention_bam_384_std_attention": 0.5412432551383972,
      "attention_bam_384_max_attention": 5.287590980529785,
      "attention_bam_384_min_attention": -1.5843007564544678,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2025621666811697,
      "attention_bam_384_attention_skewness": 0.5315894370838025,
      "attention_bam_384_attention_sparsity": 0.44082387288411456,
      "attention_bam_384_attention_concentration_10": 0.6083244250354646,
      "attention_bam_384_attention_concentration_20": 0.9804558579231325,
      "attention_bam_384_attention_center_y": 0.4874826649655523,
      "attention_bam_384_attention_center_x": 0.4855714817325829,
      "attention_bam_384_attention_center_distance": 0.027013545334065282,
      "attention_bam_384_attention_spatial_variance": 170.74211118938354,
      "attention_bam_384_attention_spatial_std": 13.066832484936183,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 16.53524018982025,
      "attention_bam_384_peak_intensity_mean": 0.261453241109848,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22818008065223694,
      "attention_bam_16_std_attention": 0.5792118310928345,
      "attention_bam_16_max_attention": 2.3040835857391357,
      "attention_bam_16_min_attention": -1.0603572130203247,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.0831107227878185,
      "attention_bam_16_attention_skewness": 0.35217640308758663,
      "attention_bam_16_attention_sparsity": 0.430908203125,
      "attention_bam_16_attention_concentration_10": 0.574521517986584,
      "attention_bam_16_attention_concentration_20": 0.9377560340177337,
      "attention_bam_16_attention_center_y": 0.4813280237444168,
      "attention_bam_16_attention_center_x": 0.47725372238153224,
      "attention_bam_16_attention_center_distance": 0.04161816533163061,
      "attention_bam_16_attention_spatial_variance": 42.10450473219017,
      "attention_bam_16_attention_spatial_std": 6.488798404341914,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.82714501885612,
      "attention_bam_16_peak_intensity_mean": 0.3883568346500397,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 63,
      "phase": "train",
      "loss": 0.11710494011640549,
      "timestamp": 1759543890.3863225,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.11710494011640549,
      "ssim": 0.4097574055194855,
      "attention_bam_384_mean_attention": 0.21411161124706268,
      "attention_bam_384_std_attention": 0.527942419052124,
      "attention_bam_384_max_attention": 4.8740129470825195,
      "attention_bam_384_min_attention": -1.5787067413330078,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2932459892631787,
      "attention_bam_384_attention_skewness": 0.596402510441007,
      "attention_bam_384_attention_sparsity": 0.446380615234375,
      "attention_bam_384_attention_concentration_10": 0.5719136572885549,
      "attention_bam_384_attention_concentration_20": 0.9206157049677887,
      "attention_bam_384_attention_center_y": 0.48271178862647407,
      "attention_bam_384_attention_center_x": 0.4803236882847356,
      "attention_bam_384_attention_center_distance": 0.037041584610055835,
      "attention_bam_384_attention_spatial_variance": 169.12986699844495,
      "attention_bam_384_attention_spatial_std": 13.004993925352098,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 17.058462944832137,
      "attention_bam_384_peak_intensity_mean": 0.2789416015148163,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24821464717388153,
      "attention_bam_16_std_attention": 0.5368967056274414,
      "attention_bam_16_max_attention": 2.3709659576416016,
      "attention_bam_16_min_attention": -1.2028172016143799,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.48542988107439244,
      "attention_bam_16_attention_skewness": 0.5044323353477415,
      "attention_bam_16_attention_sparsity": 0.418212890625,
      "attention_bam_16_attention_concentration_10": 0.5144710132735403,
      "attention_bam_16_attention_concentration_20": 0.8367479612435929,
      "attention_bam_16_attention_center_y": 0.46997086357256324,
      "attention_bam_16_attention_center_x": 0.45919019699818064,
      "attention_bam_16_attention_center_distance": 0.07165457494989295,
      "attention_bam_16_attention_spatial_variance": 40.95330773983202,
      "attention_bam_16_attention_spatial_std": 6.399477145816838,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.549283492541583,
      "attention_bam_16_peak_intensity_mean": 0.4115794599056244,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 64,
      "phase": "train",
      "loss": 0.13942019641399384,
      "timestamp": 1759543890.5154047,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.13942019641399384,
      "ssim": 0.4026842713356018,
      "attention_bam_384_mean_attention": 0.21155627071857452,
      "attention_bam_384_std_attention": 0.539480447769165,
      "attention_bam_384_max_attention": 4.662264823913574,
      "attention_bam_384_min_attention": -1.5923089981079102,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8564679487260727,
      "attention_bam_384_attention_skewness": 0.5738672482601315,
      "attention_bam_384_attention_sparsity": 0.45234934488932294,
      "attention_bam_384_attention_concentration_10": 0.5930010548482868,
      "attention_bam_384_attention_concentration_20": 0.9548455030325743,
      "attention_bam_384_attention_center_y": 0.48570204117706794,
      "attention_bam_384_attention_center_x": 0.4817849452323581,
      "attention_bam_384_attention_center_distance": 0.032748125036113275,
      "attention_bam_384_attention_spatial_variance": 169.7853634791312,
      "attention_bam_384_attention_spatial_std": 13.03017127589393,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 16.485919386302307,
      "attention_bam_384_peak_intensity_mean": 0.29164278507232666,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23896808922290802,
      "attention_bam_16_std_attention": 0.5760939121246338,
      "attention_bam_16_max_attention": 2.4459035396575928,
      "attention_bam_16_min_attention": -0.9887725114822388,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.14350060459090974,
      "attention_bam_16_attention_skewness": 0.5311916489582564,
      "attention_bam_16_attention_sparsity": 0.439697265625,
      "attention_bam_16_attention_concentration_10": 0.5580548506987095,
      "attention_bam_16_attention_concentration_20": 0.9153925667603501,
      "attention_bam_16_attention_center_y": 0.4789242632476081,
      "attention_bam_16_attention_center_x": 0.46334466373241534,
      "attention_bam_16_attention_center_distance": 0.05979632691973361,
      "attention_bam_16_attention_spatial_variance": 41.389870124342345,
      "attention_bam_16_attention_spatial_std": 6.433495948886759,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 9.612143302855765,
      "attention_bam_16_peak_intensity_mean": 0.3646821081638336,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 65,
      "phase": "train",
      "loss": 0.13059592247009277,
      "timestamp": 1759543890.6451635,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.13059592247009277,
      "ssim": 0.37299486994743347,
      "attention_bam_384_mean_attention": 0.20298437774181366,
      "attention_bam_384_std_attention": 0.5240222215652466,
      "attention_bam_384_max_attention": 4.456543922424316,
      "attention_bam_384_min_attention": -1.593395471572876,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.6102564593768216,
      "attention_bam_384_attention_skewness": 0.6313593693658008,
      "attention_bam_384_attention_sparsity": 0.44271087646484375,
      "attention_bam_384_attention_concentration_10": 0.5945609461834566,
      "attention_bam_384_attention_concentration_20": 0.9502197319677942,
      "attention_bam_384_attention_center_y": 0.484470702396529,
      "attention_bam_384_attention_center_x": 0.4819748637396219,
      "attention_bam_384_attention_center_distance": 0.033647128295364745,
      "attention_bam_384_attention_spatial_variance": 170.66992238064168,
      "attention_bam_384_attention_spatial_std": 13.064069901092909,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 17.043694419063247,
      "attention_bam_384_peak_intensity_mean": 0.2978850305080414,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21464410424232483,
      "attention_bam_16_std_attention": 0.5479816198348999,
      "attention_bam_16_max_attention": 2.8313560485839844,
      "attention_bam_16_min_attention": -1.027978539466858,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5857210713935905,
      "attention_bam_16_attention_skewness": 0.49530882446624247,
      "attention_bam_16_attention_sparsity": 0.435302734375,
      "attention_bam_16_attention_concentration_10": 0.5847152026220794,
      "attention_bam_16_attention_concentration_20": 0.9442368167333353,
      "attention_bam_16_attention_center_y": 0.4748814619957356,
      "attention_bam_16_attention_center_x": 0.4715407583990777,
      "attention_bam_16_attention_center_distance": 0.053681829029408816,
      "attention_bam_16_attention_spatial_variance": 42.30567197865459,
      "attention_bam_16_attention_spatial_std": 6.504281050097281,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.006587198845152,
      "attention_bam_16_peak_intensity_mean": 0.3264297842979431,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 66,
      "phase": "train",
      "loss": 0.16074232757091522,
      "timestamp": 1759543890.7750251,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.16074232757091522,
      "ssim": 0.36747193336486816,
      "attention_bam_384_mean_attention": 0.20270727574825287,
      "attention_bam_384_std_attention": 0.5856889486312866,
      "attention_bam_384_max_attention": 5.601900100708008,
      "attention_bam_384_min_attention": -1.6935887336730957,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.7048513015170794,
      "attention_bam_384_attention_skewness": 0.6908221302627051,
      "attention_bam_384_attention_sparsity": 0.45873769124348956,
      "attention_bam_384_attention_concentration_10": 0.660128245854328,
      "attention_bam_384_attention_concentration_20": 1.0498233242907273,
      "attention_bam_384_attention_center_y": 0.4848194807107984,
      "attention_bam_384_attention_center_x": 0.48222693547738094,
      "attention_bam_384_attention_center_distance": 0.03305540767907734,
      "attention_bam_384_attention_spatial_variance": 170.57227451816948,
      "attention_bam_384_attention_spatial_std": 13.06033209831088,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 15.692513284861453,
      "attention_bam_384_peak_intensity_mean": 0.2618721127510071,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2308451384305954,
      "attention_bam_16_std_attention": 0.6210359930992126,
      "attention_bam_16_max_attention": 2.6269419193267822,
      "attention_bam_16_min_attention": -1.1083056926727295,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.1255094246168218,
      "attention_bam_16_attention_skewness": 0.6122489444629965,
      "attention_bam_16_attention_sparsity": 0.4638671875,
      "attention_bam_16_attention_concentration_10": 0.6346600498068823,
      "attention_bam_16_attention_concentration_20": 1.0227887027539764,
      "attention_bam_16_attention_center_y": 0.4726130636719491,
      "attention_bam_16_attention_center_x": 0.46405112769512613,
      "attention_bam_16_attention_center_distance": 0.0639119034519993,
      "attention_bam_16_attention_spatial_variance": 42.071629192042764,
      "attention_bam_16_attention_spatial_std": 6.486264656336709,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 8.571051616165706,
      "attention_bam_16_peak_intensity_mean": 0.3720695674419403,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 67,
      "phase": "train",
      "loss": 0.13932204246520996,
      "timestamp": 1759543890.9065704,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.13932204246520996,
      "ssim": 0.3864298462867737,
      "attention_bam_384_mean_attention": 0.20917899906635284,
      "attention_bam_384_std_attention": 0.559612512588501,
      "attention_bam_384_max_attention": 5.000951290130615,
      "attention_bam_384_min_attention": -1.697650671005249,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.6255334510256567,
      "attention_bam_384_attention_skewness": 0.835185993018009,
      "attention_bam_384_attention_sparsity": 0.44555918375651044,
      "attention_bam_384_attention_concentration_10": 0.6121535583440647,
      "attention_bam_384_attention_concentration_20": 0.9702857738799412,
      "attention_bam_384_attention_center_y": 0.4755026919551683,
      "attention_bam_384_attention_center_x": 0.47946383801473036,
      "attention_bam_384_attention_center_distance": 0.04520734565374546,
      "attention_bam_384_attention_spatial_variance": 172.09134832813083,
      "attention_bam_384_attention_spatial_std": 13.118359208686536,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 18.41138683682925,
      "attention_bam_384_peak_intensity_mean": 0.28912562131881714,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2310781031847,
      "attention_bam_16_std_attention": 0.6188189387321472,
      "attention_bam_16_max_attention": 3.7262158393859863,
      "attention_bam_16_min_attention": -1.1711714267730713,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.6992122828160046,
      "attention_bam_16_attention_skewness": 0.7412975401477824,
      "attention_bam_16_attention_sparsity": 0.434326171875,
      "attention_bam_16_attention_concentration_10": 0.6068812744621657,
      "attention_bam_16_attention_concentration_20": 0.9781698259997048,
      "attention_bam_16_attention_center_y": 0.44570562423575644,
      "attention_bam_16_attention_center_x": 0.45267697229161286,
      "attention_bam_16_attention_center_distance": 0.10185625352542332,
      "attention_bam_16_attention_spatial_variance": 43.03512315666501,
      "attention_bam_16_attention_spatial_std": 6.560116093230745,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 10.136587933476152,
      "attention_bam_16_peak_intensity_mean": 0.3122994303703308,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 68,
      "phase": "train",
      "loss": 0.11577676981687546,
      "timestamp": 1759543891.0366147,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.11577676981687546,
      "ssim": 0.4141920804977417,
      "attention_bam_384_mean_attention": 0.1997838020324707,
      "attention_bam_384_std_attention": 0.5299570560455322,
      "attention_bam_384_max_attention": 5.498289108276367,
      "attention_bam_384_min_attention": -1.6759636402130127,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.0088112863067025,
      "attention_bam_384_attention_skewness": 0.6392695443208471,
      "attention_bam_384_attention_sparsity": 0.44899749755859375,
      "attention_bam_384_attention_concentration_10": 0.6018431003769529,
      "attention_bam_384_attention_concentration_20": 0.9678539434542113,
      "attention_bam_384_attention_center_y": 0.47755092782394554,
      "attention_bam_384_attention_center_x": 0.47984920447889695,
      "attention_bam_384_attention_center_distance": 0.04266181903526874,
      "attention_bam_384_attention_spatial_variance": 172.351689953156,
      "attention_bam_384_attention_spatial_std": 13.128278255474173,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 18.501197434518474,
      "attention_bam_384_peak_intensity_mean": 0.2670666575431824,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20792827010154724,
      "attention_bam_16_std_attention": 0.5274553894996643,
      "attention_bam_16_max_attention": 2.233051300048828,
      "attention_bam_16_min_attention": -1.062178373336792,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.34791420670350615,
      "attention_bam_16_attention_skewness": 0.1669415754166634,
      "attention_bam_16_attention_sparsity": 0.427978515625,
      "attention_bam_16_attention_concentration_10": 0.5477372878923034,
      "attention_bam_16_attention_concentration_20": 0.9224760513671775,
      "attention_bam_16_attention_center_y": 0.4547744200398721,
      "attention_bam_16_attention_center_x": 0.4546847622471538,
      "attention_bam_16_attention_center_distance": 0.09054086210465301,
      "attention_bam_16_attention_spatial_variance": 43.42371548227817,
      "attention_bam_16_attention_spatial_std": 6.5896673271325445,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.921331495463603,
      "attention_bam_16_peak_intensity_mean": 0.4038902223110199,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 69,
      "phase": "train",
      "loss": 0.1375133991241455,
      "timestamp": 1759543891.1674047,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.1375133991241455,
      "ssim": 0.42756301164627075,
      "attention_bam_384_mean_attention": 0.1786058098077774,
      "attention_bam_384_std_attention": 0.5668291449546814,
      "attention_bam_384_max_attention": 5.79689884185791,
      "attention_bam_384_min_attention": -1.6420589685440063,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.550768683399826,
      "attention_bam_384_attention_skewness": 0.8885510407943003,
      "attention_bam_384_attention_sparsity": 0.47380320231119794,
      "attention_bam_384_attention_concentration_10": 0.7322517596868647,
      "attention_bam_384_attention_concentration_20": 1.1302681732347988,
      "attention_bam_384_attention_center_y": 0.48251633231655255,
      "attention_bam_384_attention_center_x": 0.4851617823358305,
      "attention_bam_384_attention_center_distance": 0.03242996574510975,
      "attention_bam_384_attention_spatial_variance": 170.5032675778161,
      "attention_bam_384_attention_spatial_std": 13.05768997862241,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 19.81062922403865,
      "attention_bam_384_peak_intensity_mean": 0.24792508780956268,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22220410406589508,
      "attention_bam_16_std_attention": 0.6424652338027954,
      "attention_bam_16_max_attention": 3.032526731491089,
      "attention_bam_16_min_attention": -1.3568023443222046,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.273852005242511,
      "attention_bam_16_attention_skewness": 0.8770632331185487,
      "attention_bam_16_attention_sparsity": 0.470703125,
      "attention_bam_16_attention_concentration_10": 0.6946685743122128,
      "attention_bam_16_attention_concentration_20": 1.075294471873493,
      "attention_bam_16_attention_center_y": 0.46618229847311,
      "attention_bam_16_attention_center_x": 0.4698612495155987,
      "attention_bam_16_attention_center_distance": 0.06406217631836773,
      "attention_bam_16_attention_spatial_variance": 41.966984159342594,
      "attention_bam_16_attention_spatial_std": 6.478192970214965,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.565958334266007,
      "attention_bam_16_peak_intensity_mean": 0.38007310032844543,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 70,
      "phase": "train",
      "loss": 0.10200232267379761,
      "timestamp": 1759543891.3681507,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.10200232267379761,
      "ssim": 0.4096519947052002,
      "attention_bam_384_mean_attention": 0.1885831207036972,
      "attention_bam_384_std_attention": 0.5088109970092773,
      "attention_bam_384_max_attention": 5.91633415222168,
      "attention_bam_384_min_attention": -1.633140206336975,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.402797495195042,
      "attention_bam_384_attention_skewness": 0.7186125017951274,
      "attention_bam_384_attention_sparsity": 0.44916534423828125,
      "attention_bam_384_attention_concentration_10": 0.6228788439244863,
      "attention_bam_384_attention_concentration_20": 0.9813863671823921,
      "attention_bam_384_attention_center_y": 0.481043897803974,
      "attention_bam_384_attention_center_x": 0.4887081369096616,
      "attention_bam_384_attention_center_distance": 0.031203845356530303,
      "attention_bam_384_attention_spatial_variance": 171.0069618033788,
      "attention_bam_384_attention_spatial_std": 13.076963019117963,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 17.331581877329427,
      "attention_bam_384_peak_intensity_mean": 0.2431548535823822,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23200905323028564,
      "attention_bam_16_std_attention": 0.5449327230453491,
      "attention_bam_16_max_attention": 2.4886536598205566,
      "attention_bam_16_min_attention": -1.1039608716964722,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5828931029294613,
      "attention_bam_16_attention_skewness": 0.5778826965479009,
      "attention_bam_16_attention_sparsity": 0.42724609375,
      "attention_bam_16_attention_concentration_10": 0.568399312923149,
      "attention_bam_16_attention_concentration_20": 0.8970232495192656,
      "attention_bam_16_attention_center_y": 0.466551115955846,
      "attention_bam_16_attention_center_x": 0.48230406314778657,
      "attention_bam_16_attention_center_distance": 0.05351586727087186,
      "attention_bam_16_attention_spatial_variance": 42.326636177858596,
      "attention_bam_16_attention_spatial_std": 6.50589241978828,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.772877907838978,
      "attention_bam_16_peak_intensity_mean": 0.38305968046188354,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 71,
      "phase": "train",
      "loss": 0.13298079371452332,
      "timestamp": 1759543891.5380595,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.13298079371452332,
      "ssim": 0.4155440330505371,
      "attention_bam_384_mean_attention": 0.18453079462051392,
      "attention_bam_384_std_attention": 0.5412961840629578,
      "attention_bam_384_max_attention": 5.912436485290527,
      "attention_bam_384_min_attention": -1.726932406425476,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.0289064528946517,
      "attention_bam_384_attention_skewness": 0.6558294963939312,
      "attention_bam_384_attention_sparsity": 0.4609476725260417,
      "attention_bam_384_attention_concentration_10": 0.6551617137388509,
      "attention_bam_384_attention_concentration_20": 1.0471811277210374,
      "attention_bam_384_attention_center_y": 0.4784451401975904,
      "attention_bam_384_attention_center_x": 0.48520754773239083,
      "attention_bam_384_attention_center_distance": 0.03697103258474206,
      "attention_bam_384_attention_spatial_variance": 170.51858850289995,
      "attention_bam_384_attention_spatial_std": 13.05827662836486,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 16.673435181981375,
      "attention_bam_384_peak_intensity_mean": 0.25036489963531494,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23491977155208588,
      "attention_bam_16_std_attention": 0.6061755418777466,
      "attention_bam_16_max_attention": 2.532808780670166,
      "attention_bam_16_min_attention": -1.1000186204910278,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.03236303670521501,
      "attention_bam_16_attention_skewness": 0.4052351981400986,
      "attention_bam_16_attention_sparsity": 0.434814453125,
      "attention_bam_16_attention_concentration_10": 0.5831183608849125,
      "attention_bam_16_attention_concentration_20": 0.956228462440806,
      "attention_bam_16_attention_center_y": 0.4547926597685565,
      "attention_bam_16_attention_center_x": 0.47832526237585987,
      "attention_bam_16_attention_center_distance": 0.07090130974639053,
      "attention_bam_16_attention_spatial_variance": 41.57433336392701,
      "attention_bam_16_attention_spatial_std": 6.447816170140632,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.2886676043837,
      "attention_bam_16_peak_intensity_mean": 0.37665003538131714,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 72,
      "phase": "train",
      "loss": 0.1431681513786316,
      "timestamp": 1759543891.6770008,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.1431681513786316,
      "ssim": 0.3943381905555725,
      "attention_bam_384_mean_attention": 0.17437994480133057,
      "attention_bam_384_std_attention": 0.5595401525497437,
      "attention_bam_384_max_attention": 5.694760322570801,
      "attention_bam_384_min_attention": -1.6873753070831299,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.6624695391386872,
      "attention_bam_384_attention_skewness": 0.645097321803035,
      "attention_bam_384_attention_sparsity": 0.47427622477213544,
      "attention_bam_384_attention_concentration_10": 0.7116341549282702,
      "attention_bam_384_attention_concentration_20": 1.138657920912054,
      "attention_bam_384_attention_center_y": 0.48425416923597026,
      "attention_bam_384_attention_center_x": 0.4782901023550599,
      "attention_bam_384_attention_center_distance": 0.03792758474259178,
      "attention_bam_384_attention_spatial_variance": 170.27373961031526,
      "attention_bam_384_attention_spatial_std": 13.048898022833777,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 18.335899636185943,
      "attention_bam_384_peak_intensity_mean": 0.2534812390804291,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21599966287612915,
      "attention_bam_16_std_attention": 0.6447221636772156,
      "attention_bam_16_max_attention": 2.663745641708374,
      "attention_bam_16_min_attention": -1.1022684574127197,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.10994355697587554,
      "attention_bam_16_attention_skewness": 0.5170971960458619,
      "attention_bam_16_attention_sparsity": 0.46435546875,
      "attention_bam_16_attention_concentration_10": 0.6814905627134522,
      "attention_bam_16_attention_concentration_20": 1.1009304133878053,
      "attention_bam_16_attention_center_y": 0.47388894330147113,
      "attention_bam_16_attention_center_x": 0.4471035977899022,
      "attention_bam_16_attention_center_distance": 0.08342441667385186,
      "attention_bam_16_attention_spatial_variance": 41.5110304279273,
      "attention_bam_16_attention_spatial_std": 6.442905433725324,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.47675366060541,
      "attention_bam_16_peak_intensity_mean": 0.3609986901283264,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 73,
      "phase": "train",
      "loss": 0.10593005269765854,
      "timestamp": 1759543891.8078556,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.10593005269765854,
      "ssim": 0.41601577401161194,
      "attention_bam_384_mean_attention": 0.19253261387348175,
      "attention_bam_384_std_attention": 0.6290463805198669,
      "attention_bam_384_max_attention": 5.1023454666137695,
      "attention_bam_384_min_attention": -1.7229784727096558,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.697754493427916,
      "attention_bam_384_attention_skewness": 0.8022996696774274,
      "attention_bam_384_attention_sparsity": 0.4758249918619792,
      "attention_bam_384_attention_concentration_10": 0.7379520465643467,
      "attention_bam_384_attention_concentration_20": 1.1592908052888293,
      "attention_bam_384_attention_center_y": 0.4784160597907817,
      "attention_bam_384_attention_center_x": 0.4834462329261702,
      "attention_bam_384_attention_center_distance": 0.03846800434880188,
      "attention_bam_384_attention_spatial_variance": 173.57168946436312,
      "attention_bam_384_attention_spatial_std": 13.174660886123904,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 19.008690067479375,
      "attention_bam_384_peak_intensity_mean": 0.28300562500953674,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2251504361629486,
      "attention_bam_16_std_attention": 0.7343723773956299,
      "attention_bam_16_max_attention": 3.4434776306152344,
      "attention_bam_16_min_attention": -1.140854001045227,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.9341595941211183,
      "attention_bam_16_attention_skewness": 0.8044133099642008,
      "attention_bam_16_attention_sparsity": 0.471435546875,
      "attention_bam_16_attention_concentration_10": 0.7493718889709928,
      "attention_bam_16_attention_concentration_20": 1.172694560197058,
      "attention_bam_16_attention_center_y": 0.44955668315965175,
      "attention_bam_16_attention_center_x": 0.4626751577427786,
      "attention_bam_16_attention_center_distance": 0.08874313565997338,
      "attention_bam_16_attention_spatial_variance": 44.74752906971685,
      "attention_bam_16_attention_spatial_std": 6.689359391579798,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.901304936748181,
      "attention_bam_16_peak_intensity_mean": 0.321146696805954,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 74,
      "phase": "train",
      "loss": 0.11617612838745117,
      "timestamp": 1759543891.9383862,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.11617612838745117,
      "ssim": 0.34339630603790283,
      "attention_bam_384_mean_attention": 0.16831915080547333,
      "attention_bam_384_std_attention": 0.5072980523109436,
      "attention_bam_384_max_attention": 5.418515205383301,
      "attention_bam_384_min_attention": -1.6489791870117188,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.032197185292663,
      "attention_bam_384_attention_skewness": 0.653613222106997,
      "attention_bam_384_attention_sparsity": 0.4703216552734375,
      "attention_bam_384_attention_concentration_10": 0.6710144149162445,
      "attention_bam_384_attention_concentration_20": 1.0729428762312792,
      "attention_bam_384_attention_center_y": 0.486796156901043,
      "attention_bam_384_attention_center_x": 0.48461353860193557,
      "attention_bam_384_attention_center_distance": 0.028673495320103593,
      "attention_bam_384_attention_spatial_variance": 172.94335909295862,
      "attention_bam_384_attention_spatial_std": 13.150793097488783,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 21.302898129549778,
      "attention_bam_384_peak_intensity_mean": 0.2637166678905487,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21337881684303284,
      "attention_bam_16_std_attention": 0.5771364569664001,
      "attention_bam_16_max_attention": 2.5673742294311523,
      "attention_bam_16_min_attention": -1.1021085977554321,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.11638400436848517,
      "attention_bam_16_attention_skewness": 0.5339058339400604,
      "attention_bam_16_attention_sparsity": 0.45166015625,
      "attention_bam_16_attention_concentration_10": 0.6170605204959423,
      "attention_bam_16_attention_concentration_20": 1.0023441979101229,
      "attention_bam_16_attention_center_y": 0.48361540669423586,
      "attention_bam_16_attention_center_x": 0.465311427716153,
      "attention_bam_16_attention_center_distance": 0.05425406795599695,
      "attention_bam_16_attention_spatial_variance": 44.448065428127265,
      "attention_bam_16_attention_spatial_std": 6.6669382349116795,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.900742483544887,
      "attention_bam_16_peak_intensity_mean": 0.39157867431640625,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 75,
      "phase": "train",
      "loss": 0.10228870809078217,
      "timestamp": 1759543892.0684907,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.10228870809078217,
      "ssim": 0.4136846363544464,
      "attention_bam_384_mean_attention": 0.20044982433319092,
      "attention_bam_384_std_attention": 0.5110326409339905,
      "attention_bam_384_max_attention": 5.027342796325684,
      "attention_bam_384_min_attention": -1.5682073831558228,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0985955480469256,
      "attention_bam_384_attention_skewness": 0.46312265234280353,
      "attention_bam_384_attention_sparsity": 0.44041188557942706,
      "attention_bam_384_attention_concentration_10": 0.5775521683580446,
      "attention_bam_384_attention_concentration_20": 0.9359041606822899,
      "attention_bam_384_attention_center_y": 0.4909521004143252,
      "attention_bam_384_attention_center_x": 0.48400612879357385,
      "attention_bam_384_attention_center_distance": 0.025987243142749937,
      "attention_bam_384_attention_spatial_variance": 170.83659656108003,
      "attention_bam_384_attention_spatial_std": 13.070447450683547,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 14.138651087944508,
      "attention_bam_384_peak_intensity_mean": 0.2717214822769165,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2519083619117737,
      "attention_bam_16_std_attention": 0.5653866529464722,
      "attention_bam_16_max_attention": 2.476820230484009,
      "attention_bam_16_min_attention": -1.1862894296646118,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.015950049555982115,
      "attention_bam_16_attention_skewness": 0.2907356689421112,
      "attention_bam_16_attention_sparsity": 0.41259765625,
      "attention_bam_16_attention_concentration_10": 0.5172074009472578,
      "attention_bam_16_attention_concentration_20": 0.8502064798119158,
      "attention_bam_16_attention_center_y": 0.4938104027186415,
      "attention_bam_16_attention_center_x": 0.47329502814119756,
      "attention_bam_16_attention_center_distance": 0.038767683358303225,
      "attention_bam_16_attention_spatial_variance": 42.383388086097526,
      "attention_bam_16_attention_spatial_std": 6.510252536276725,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 6.067357419481231,
      "attention_bam_16_peak_intensity_mean": 0.425223171710968,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 76,
      "phase": "train",
      "loss": 0.09586694836616516,
      "timestamp": 1759543892.1978245,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.09586694836616516,
      "ssim": 0.4727137088775635,
      "attention_bam_384_mean_attention": 0.2049913853406906,
      "attention_bam_384_std_attention": 0.4509098529815674,
      "attention_bam_384_max_attention": 4.674900054931641,
      "attention_bam_384_min_attention": -1.6272480487823486,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.460639876421201,
      "attention_bam_384_attention_skewness": 0.49371327341580945,
      "attention_bam_384_attention_sparsity": 0.40956878662109375,
      "attention_bam_384_attention_concentration_10": 0.5088090161679163,
      "attention_bam_384_attention_concentration_20": 0.8226976083671524,
      "attention_bam_384_attention_center_y": 0.4810328149367796,
      "attention_bam_384_attention_center_x": 0.48360981496803374,
      "attention_bam_384_attention_center_distance": 0.03545115723370799,
      "attention_bam_384_attention_spatial_variance": 170.41531958767757,
      "attention_bam_384_attention_spatial_std": 13.054321873911244,
      "attention_bam_384_num_attention_peaks": 19,
      "attention_bam_384_peak_separation_mean": 17.72625346315736,
      "attention_bam_384_peak_intensity_mean": 0.29347220063209534,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2589622735977173,
      "attention_bam_16_std_attention": 0.44466373324394226,
      "attention_bam_16_max_attention": 2.2191011905670166,
      "attention_bam_16_min_attention": -1.0539392232894897,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.007872129583769372,
      "attention_bam_16_attention_skewness": -0.0024004899527185096,
      "attention_bam_16_attention_sparsity": 0.343017578125,
      "attention_bam_16_attention_concentration_10": 0.4049870576894546,
      "attention_bam_16_attention_concentration_20": 0.6774306701532989,
      "attention_bam_16_attention_center_y": 0.46021017906513634,
      "attention_bam_16_attention_center_x": 0.4679259731006788,
      "attention_bam_16_attention_center_distance": 0.07227687114930882,
      "attention_bam_16_attention_spatial_variance": 42.19878478388444,
      "attention_bam_16_attention_spatial_std": 6.496059173366914,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.704853340593948,
      "attention_bam_16_peak_intensity_mean": 0.41541895270347595,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 77,
      "phase": "train",
      "loss": 0.08364953845739365,
      "timestamp": 1759543892.3293464,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.08364953845739365,
      "ssim": 0.49321597814559937,
      "attention_bam_384_mean_attention": 0.1887327879667282,
      "attention_bam_384_std_attention": 0.5005728602409363,
      "attention_bam_384_max_attention": 5.09230375289917,
      "attention_bam_384_min_attention": -1.5994162559509277,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8145222999580337,
      "attention_bam_384_attention_skewness": 0.6543581222170243,
      "attention_bam_384_attention_sparsity": 0.45232899983723956,
      "attention_bam_384_attention_concentration_10": 0.6061386857378812,
      "attention_bam_384_attention_concentration_20": 0.9684298688566361,
      "attention_bam_384_attention_center_y": 0.4825072737350755,
      "attention_bam_384_attention_center_x": 0.4765909250004129,
      "attention_bam_384_attention_center_distance": 0.04132747910327638,
      "attention_bam_384_attention_spatial_variance": 171.72005474051898,
      "attention_bam_384_attention_spatial_std": 13.104199889368255,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 16.798662473893124,
      "attention_bam_384_peak_intensity_mean": 0.2708131670951843,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2367222011089325,
      "attention_bam_16_std_attention": 0.5758397579193115,
      "attention_bam_16_max_attention": 2.9336817264556885,
      "attention_bam_16_min_attention": -1.046679139137268,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.1628703178244031,
      "attention_bam_16_attention_skewness": 0.4103051102202257,
      "attention_bam_16_attention_sparsity": 0.4345703125,
      "attention_bam_16_attention_concentration_10": 0.5628450881520745,
      "attention_bam_16_attention_concentration_20": 0.9236918706114255,
      "attention_bam_16_attention_center_y": 0.465961423378862,
      "attention_bam_16_attention_center_x": 0.4419615538746422,
      "attention_bam_16_attention_center_distance": 0.0951534122040733,
      "attention_bam_16_attention_spatial_variance": 42.75390369283524,
      "attention_bam_16_attention_spatial_std": 6.5386469313486595,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 7.1428574410284185,
      "attention_bam_16_peak_intensity_mean": 0.34462472796440125,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 78,
      "phase": "train",
      "loss": 0.060246698558330536,
      "timestamp": 1759543892.4562118,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.060246698558330536,
      "ssim": 0.49308881163597107,
      "attention_bam_384_mean_attention": 0.18907113373279572,
      "attention_bam_384_std_attention": 0.5650099515914917,
      "attention_bam_384_max_attention": 5.527416706085205,
      "attention_bam_384_min_attention": -1.6419658660888672,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7391883233352865,
      "attention_bam_384_attention_skewness": 0.46411946562032913,
      "attention_bam_384_attention_sparsity": 0.4557342529296875,
      "attention_bam_384_attention_concentration_10": 0.659541950400184,
      "attention_bam_384_attention_concentration_20": 1.0742419660155034,
      "attention_bam_384_attention_center_y": 0.4838673051987581,
      "attention_bam_384_attention_center_x": 0.4832777642673094,
      "attention_bam_384_attention_center_distance": 0.032860219398223506,
      "attention_bam_384_attention_spatial_variance": 170.92267629665147,
      "attention_bam_384_attention_spatial_std": 13.073739950628186,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 18.96829818741721,
      "attention_bam_384_peak_intensity_mean": 0.25711679458618164,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2186567783355713,
      "attention_bam_16_std_attention": 0.640129566192627,
      "attention_bam_16_max_attention": 2.5969223976135254,
      "attention_bam_16_min_attention": -1.1393948793411255,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.039738856312999005,
      "attention_bam_16_attention_skewness": 0.4124729933599267,
      "attention_bam_16_attention_sparsity": 0.441650390625,
      "attention_bam_16_attention_concentration_10": 0.6560190101909823,
      "attention_bam_16_attention_concentration_20": 1.0666612919989984,
      "attention_bam_16_attention_center_y": 0.47098600769418886,
      "attention_bam_16_attention_center_x": 0.46628167438658635,
      "attention_bam_16_attention_center_distance": 0.06290846098409744,
      "attention_bam_16_attention_spatial_variance": 42.74766928812799,
      "attention_bam_16_attention_spatial_std": 6.538170178890114,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.096532927367917,
      "attention_bam_16_peak_intensity_mean": 0.37218987941741943,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 79,
      "phase": "train",
      "loss": 0.06384425610303879,
      "timestamp": 1759543892.5848343,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.06384425610303879,
      "ssim": 0.4928283095359802,
      "attention_bam_384_mean_attention": 0.18266242742538452,
      "attention_bam_384_std_attention": 0.5235061645507812,
      "attention_bam_384_max_attention": 4.720354080200195,
      "attention_bam_384_min_attention": -1.6281105279922485,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2540538741981022,
      "attention_bam_384_attention_skewness": 0.5030740716871287,
      "attention_bam_384_attention_sparsity": 0.45863596598307294,
      "attention_bam_384_attention_concentration_10": 0.6307776922481156,
      "attention_bam_384_attention_concentration_20": 1.0257699266050404,
      "attention_bam_384_attention_center_y": 0.4882215667446747,
      "attention_bam_384_attention_center_x": 0.48228092950223744,
      "attention_bam_384_attention_center_distance": 0.030089764015519698,
      "attention_bam_384_attention_spatial_variance": 170.63558674961925,
      "attention_bam_384_attention_spatial_std": 13.062755710401204,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 14.790928479448688,
      "attention_bam_384_peak_intensity_mean": 0.2887001931667328,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22964677214622498,
      "attention_bam_16_std_attention": 0.5893468260765076,
      "attention_bam_16_max_attention": 2.292074680328369,
      "attention_bam_16_min_attention": -1.0079749822616577,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.4617728327996513,
      "attention_bam_16_attention_skewness": 0.28655603568265087,
      "attention_bam_16_attention_sparsity": 0.44482421875,
      "attention_bam_16_attention_concentration_10": 0.5701453229101768,
      "attention_bam_16_attention_concentration_20": 0.9551436624398322,
      "attention_bam_16_attention_center_y": 0.48844776808169393,
      "attention_bam_16_attention_center_x": 0.4621694442906268,
      "attention_bam_16_attention_center_distance": 0.05593934228384026,
      "attention_bam_16_attention_spatial_variance": 42.308769355087904,
      "attention_bam_16_attention_spatial_std": 6.504519148644879,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 10.780069586359375,
      "attention_bam_16_peak_intensity_mean": 0.37757301330566406,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 80,
      "phase": "train",
      "loss": 0.08325887471437454,
      "timestamp": 1759543892.758876,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.08325887471437454,
      "ssim": 0.4976925253868103,
      "attention_bam_384_mean_attention": 0.19448083639144897,
      "attention_bam_384_std_attention": 0.5132721662521362,
      "attention_bam_384_max_attention": 4.289984226226807,
      "attention_bam_384_min_attention": -1.6011719703674316,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2612468561347132,
      "attention_bam_384_attention_skewness": 0.6044955157854439,
      "attention_bam_384_attention_sparsity": 0.4544423421223958,
      "attention_bam_384_attention_concentration_10": 0.6080180897234043,
      "attention_bam_384_attention_concentration_20": 0.9718264448193819,
      "attention_bam_384_attention_center_y": 0.4803279036366359,
      "attention_bam_384_attention_center_x": 0.4842815347753927,
      "attention_bam_384_attention_center_distance": 0.03561071536340351,
      "attention_bam_384_attention_spatial_variance": 170.05265957871362,
      "attention_bam_384_attention_spatial_std": 13.040424056705886,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 18.440982706268805,
      "attention_bam_384_peak_intensity_mean": 0.30657708644866943,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24684260785579681,
      "attention_bam_16_std_attention": 0.5892136096954346,
      "attention_bam_16_max_attention": 2.935710906982422,
      "attention_bam_16_min_attention": -1.0426582098007202,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.07463017394895077,
      "attention_bam_16_attention_skewness": 0.4422543765120728,
      "attention_bam_16_attention_sparsity": 0.438232421875,
      "attention_bam_16_attention_concentration_10": 0.5514411517448253,
      "attention_bam_16_attention_concentration_20": 0.9110429875516937,
      "attention_bam_16_attention_center_y": 0.4573505811247969,
      "attention_bam_16_attention_center_x": 0.4698922661922038,
      "attention_bam_16_attention_center_distance": 0.07383019118807219,
      "attention_bam_16_attention_spatial_variance": 41.659941183858,
      "attention_bam_16_attention_spatial_std": 6.4544512689970786,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.956621605910435,
      "attention_bam_16_peak_intensity_mean": 0.33668380975723267,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 81,
      "phase": "train",
      "loss": 0.09463455528020859,
      "timestamp": 1759543892.8959284,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.09463455528020859,
      "ssim": 0.5149726867675781,
      "attention_bam_384_mean_attention": 0.20070761442184448,
      "attention_bam_384_std_attention": 0.4930904805660248,
      "attention_bam_384_max_attention": 5.023857116699219,
      "attention_bam_384_min_attention": -1.6635560989379883,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.3796886916721016,
      "attention_bam_384_attention_skewness": 0.6544589715873053,
      "attention_bam_384_attention_sparsity": 0.43000539143880206,
      "attention_bam_384_attention_concentration_10": 0.5718642301061101,
      "attention_bam_384_attention_concentration_20": 0.9082011434430536,
      "attention_bam_384_attention_center_y": 0.48168429628422416,
      "attention_bam_384_attention_center_x": 0.4791907960917954,
      "attention_bam_384_attention_center_distance": 0.03920428471219245,
      "attention_bam_384_attention_spatial_variance": 170.00462371059177,
      "attention_bam_384_attention_spatial_std": 13.038582120406796,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 16.021856099836253,
      "attention_bam_384_peak_intensity_mean": 0.2807266414165497,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2362278699874878,
      "attention_bam_16_std_attention": 0.5004534721374512,
      "attention_bam_16_max_attention": 2.010982036590576,
      "attention_bam_16_min_attention": -0.9938292503356934,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.1266854475172865,
      "attention_bam_16_attention_skewness": 0.23040417726596832,
      "attention_bam_16_attention_sparsity": 0.38818359375,
      "attention_bam_16_attention_concentration_10": 0.4907467262894857,
      "attention_bam_16_attention_concentration_20": 0.8047099523892888,
      "attention_bam_16_attention_center_y": 0.46614764342749754,
      "attention_bam_16_attention_center_x": 0.45393414277319444,
      "attention_bam_16_attention_center_distance": 0.08084609140276708,
      "attention_bam_16_attention_spatial_variance": 41.48679672933894,
      "attention_bam_16_attention_spatial_std": 6.441024509295003,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 8.27903613693555,
      "attention_bam_16_peak_intensity_mean": 0.41423916816711426,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 82,
      "phase": "train",
      "loss": 0.0779833272099495,
      "timestamp": 1759543893.0267515,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0779833272099495,
      "ssim": 0.48057088255882263,
      "attention_bam_384_mean_attention": 0.1918247789144516,
      "attention_bam_384_std_attention": 0.5491883158683777,
      "attention_bam_384_max_attention": 4.624741077423096,
      "attention_bam_384_min_attention": -1.6354137659072876,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2678475757278687,
      "attention_bam_384_attention_skewness": 0.6434452045677801,
      "attention_bam_384_attention_sparsity": 0.46433258056640625,
      "attention_bam_384_attention_concentration_10": 0.6512200025333535,
      "attention_bam_384_attention_concentration_20": 1.0452528711713351,
      "attention_bam_384_attention_center_y": 0.48299208408116223,
      "attention_bam_384_attention_center_x": 0.48090229218992653,
      "attention_bam_384_attention_center_distance": 0.03616605169219323,
      "attention_bam_384_attention_spatial_variance": 169.47161754210643,
      "attention_bam_384_attention_spatial_std": 13.018126498928577,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 14.876020319700705,
      "attention_bam_384_peak_intensity_mean": 0.29276278614997864,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22748494148254395,
      "attention_bam_16_std_attention": 0.6163967251777649,
      "attention_bam_16_max_attention": 2.5491878986358643,
      "attention_bam_16_min_attention": -0.981217622756958,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.021136614623777472,
      "attention_bam_16_attention_skewness": 0.5781905643461712,
      "attention_bam_16_attention_sparsity": 0.46337890625,
      "attention_bam_16_attention_concentration_10": 0.6303247502135905,
      "attention_bam_16_attention_concentration_20": 1.025063774630273,
      "attention_bam_16_attention_center_y": 0.46696986620431546,
      "attention_bam_16_attention_center_x": 0.4610478706021566,
      "attention_bam_16_attention_center_distance": 0.07222545428292104,
      "attention_bam_16_attention_spatial_variance": 41.11790901645595,
      "attention_bam_16_attention_spatial_std": 6.412324774717509,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 7.447195927169501,
      "attention_bam_16_peak_intensity_mean": 0.3525165915489197,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 83,
      "phase": "train",
      "loss": 0.10675238072872162,
      "timestamp": 1759543893.155548,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.10675238072872162,
      "ssim": 0.40902137756347656,
      "attention_bam_384_mean_attention": 0.1810203343629837,
      "attention_bam_384_std_attention": 0.5185955762863159,
      "attention_bam_384_max_attention": 5.710108757019043,
      "attention_bam_384_min_attention": -1.6255205869674683,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1672606274616442,
      "attention_bam_384_attention_skewness": 0.5468200032681478,
      "attention_bam_384_attention_sparsity": 0.463714599609375,
      "attention_bam_384_attention_concentration_10": 0.637998718479401,
      "attention_bam_384_attention_concentration_20": 1.034040635483002,
      "attention_bam_384_attention_center_y": 0.484901253273808,
      "attention_bam_384_attention_center_x": 0.48433569846082886,
      "attention_bam_384_attention_center_distance": 0.030768246469754262,
      "attention_bam_384_attention_spatial_variance": 169.53140740356056,
      "attention_bam_384_attention_spatial_std": 13.020422704488537,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 18.877473631661363,
      "attention_bam_384_peak_intensity_mean": 0.24764196574687958,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2092425376176834,
      "attention_bam_16_std_attention": 0.5748314261436462,
      "attention_bam_16_max_attention": 2.2136876583099365,
      "attention_bam_16_min_attention": -1.1121151447296143,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.3839861722384148,
      "attention_bam_16_attention_skewness": 0.36300143672158336,
      "attention_bam_16_attention_sparsity": 0.459716796875,
      "attention_bam_16_attention_concentration_10": 0.606622732363009,
      "attention_bam_16_attention_concentration_20": 1.0116787253347965,
      "attention_bam_16_attention_center_y": 0.4689143688386893,
      "attention_bam_16_attention_center_x": 0.4697064227653998,
      "attention_bam_16_attention_center_distance": 0.0613843186223605,
      "attention_bam_16_attention_spatial_variance": 41.511834155002894,
      "attention_bam_16_attention_spatial_std": 6.442967806454018,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.703652162358392,
      "attention_bam_16_peak_intensity_mean": 0.39565494656562805,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 84,
      "phase": "train",
      "loss": 0.09296214580535889,
      "timestamp": 1759543893.2840226,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.09296214580535889,
      "ssim": 0.4591371417045593,
      "attention_bam_384_mean_attention": 0.2097277045249939,
      "attention_bam_384_std_attention": 0.4723827540874481,
      "attention_bam_384_max_attention": 4.880828857421875,
      "attention_bam_384_min_attention": -1.541947841644287,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8002055420796061,
      "attention_bam_384_attention_skewness": 0.5490570511958179,
      "attention_bam_384_attention_sparsity": 0.41172027587890625,
      "attention_bam_384_attention_concentration_10": 0.5352485391874884,
      "attention_bam_384_attention_concentration_20": 0.8512076753743613,
      "attention_bam_384_attention_center_y": 0.4814901343010799,
      "attention_bam_384_attention_center_x": 0.48503093201802594,
      "attention_bam_384_attention_center_distance": 0.03366565384604968,
      "attention_bam_384_attention_spatial_variance": 170.0877208831512,
      "attention_bam_384_attention_spatial_std": 13.041768318872682,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 15.969351368941103,
      "attention_bam_384_peak_intensity_mean": 0.27411824464797974,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.25460657477378845,
      "attention_bam_16_std_attention": 0.46578824520111084,
      "attention_bam_16_max_attention": 1.9584729671478271,
      "attention_bam_16_min_attention": -1.0333985090255737,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.4104617903157015,
      "attention_bam_16_attention_skewness": 0.20449470901644254,
      "attention_bam_16_attention_sparsity": 0.34716796875,
      "attention_bam_16_attention_concentration_10": 0.4444787473098233,
      "attention_bam_16_attention_concentration_20": 0.7121940205094214,
      "attention_bam_16_attention_center_y": 0.4617302451437313,
      "attention_bam_16_attention_center_x": 0.471026707541915,
      "attention_bam_16_attention_center_distance": 0.0678826312486578,
      "attention_bam_16_attention_spatial_variance": 41.57124196219422,
      "attention_bam_16_attention_spatial_std": 6.447576440973323,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 6.911923388049601,
      "attention_bam_16_peak_intensity_mean": 0.4492246210575104,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 85,
      "phase": "train",
      "loss": 0.10111957043409348,
      "timestamp": 1759543893.411089,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.10111957043409348,
      "ssim": 0.4746168255805969,
      "attention_bam_384_mean_attention": 0.18112637102603912,
      "attention_bam_384_std_attention": 0.5508099794387817,
      "attention_bam_384_max_attention": 4.452502727508545,
      "attention_bam_384_min_attention": -1.6099839210510254,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8159977636685847,
      "attention_bam_384_attention_skewness": 0.5492047210069659,
      "attention_bam_384_attention_sparsity": 0.46432749430338544,
      "attention_bam_384_attention_concentration_10": 0.6780088037049683,
      "attention_bam_384_attention_concentration_20": 1.0857151883271556,
      "attention_bam_384_attention_center_y": 0.4884108696271942,
      "attention_bam_384_attention_center_x": 0.48541658060267445,
      "attention_bam_384_attention_center_distance": 0.026343274819816184,
      "attention_bam_384_attention_spatial_variance": 170.016142424925,
      "attention_bam_384_attention_spatial_std": 13.039023829448467,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 13.076116372764108,
      "attention_bam_384_peak_intensity_mean": 0.298215389251709,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22505784034729004,
      "attention_bam_16_std_attention": 0.675399124622345,
      "attention_bam_16_max_attention": 2.884866237640381,
      "attention_bam_16_min_attention": -1.3552292585372925,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.24440224104583264,
      "attention_bam_16_attention_skewness": 0.6060306727983286,
      "attention_bam_16_attention_sparsity": 0.4658203125,
      "attention_bam_16_attention_concentration_10": 0.6906287044622902,
      "attention_bam_16_attention_concentration_20": 1.0992154336765438,
      "attention_bam_16_attention_center_y": 0.4843107347394633,
      "attention_bam_16_attention_center_x": 0.4732631064643782,
      "attention_bam_16_attention_center_distance": 0.0438409516400057,
      "attention_bam_16_attention_spatial_variance": 42.23519194613883,
      "attention_bam_16_attention_spatial_std": 6.498860819108133,
      "attention_bam_16_num_attention_peaks": 2,
      "attention_bam_16_peak_separation_mean": 10.67359150218686,
      "attention_bam_16_peak_intensity_mean": 0.3833422064781189,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 86,
      "phase": "train",
      "loss": 0.08100821822881699,
      "timestamp": 1759543893.5439758,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.08100821822881699,
      "ssim": 0.49844276905059814,
      "attention_bam_384_mean_attention": 0.1987227350473404,
      "attention_bam_384_std_attention": 0.5286148190498352,
      "attention_bam_384_max_attention": 5.313092231750488,
      "attention_bam_384_min_attention": -1.578941822052002,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1780533836683267,
      "attention_bam_384_attention_skewness": 0.540165744771926,
      "attention_bam_384_attention_sparsity": 0.44416554768880206,
      "attention_bam_384_attention_concentration_10": 0.6070108376857831,
      "attention_bam_384_attention_concentration_20": 0.9776564647841195,
      "attention_bam_384_attention_center_y": 0.4833604861913687,
      "attention_bam_384_attention_center_x": 0.4805280194343193,
      "attention_bam_384_attention_center_distance": 0.03622240872548042,
      "attention_bam_384_attention_spatial_variance": 171.4186887822949,
      "attention_bam_384_attention_spatial_std": 13.092696008931656,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 17.149456733508806,
      "attention_bam_384_peak_intensity_mean": 0.25983038544654846,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2254011332988739,
      "attention_bam_16_std_attention": 0.5914055109024048,
      "attention_bam_16_max_attention": 2.2609457969665527,
      "attention_bam_16_min_attention": -1.1631311178207397,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.10440851251754024,
      "attention_bam_16_attention_skewness": 0.28338236480303003,
      "attention_bam_16_attention_sparsity": 0.428955078125,
      "attention_bam_16_attention_concentration_10": 0.5875210079470085,
      "attention_bam_16_attention_concentration_20": 0.9642225844038133,
      "attention_bam_16_attention_center_y": 0.4679821389493054,
      "attention_bam_16_attention_center_x": 0.4602864138938068,
      "attention_bam_16_attention_center_distance": 0.07214308487548349,
      "attention_bam_16_attention_spatial_variance": 42.89828152123903,
      "attention_bam_16_attention_spatial_std": 6.549677970804292,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.266626333327965,
      "attention_bam_16_peak_intensity_mean": 0.41235747933387756,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 87,
      "phase": "train",
      "loss": 0.05698442459106445,
      "timestamp": 1759543893.6832342,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.05698442459106445,
      "ssim": 0.5218861699104309,
      "attention_bam_384_mean_attention": 0.1938149780035019,
      "attention_bam_384_std_attention": 0.5615091323852539,
      "attention_bam_384_max_attention": 5.84591007232666,
      "attention_bam_384_min_attention": -1.5966639518737793,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8499046198037776,
      "attention_bam_384_attention_skewness": 0.6733144630902748,
      "attention_bam_384_attention_sparsity": 0.443817138671875,
      "attention_bam_384_attention_concentration_10": 0.6578271900220428,
      "attention_bam_384_attention_concentration_20": 1.0348211235087996,
      "attention_bam_384_attention_center_y": 0.4790166027229624,
      "attention_bam_384_attention_center_x": 0.4849154863607543,
      "attention_bam_384_attention_center_distance": 0.03654710694483427,
      "attention_bam_384_attention_spatial_variance": 169.56562377088093,
      "attention_bam_384_attention_spatial_std": 13.021736588139115,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 16.706629631609687,
      "attention_bam_384_peak_intensity_mean": 0.2419014722108841,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22490042448043823,
      "attention_bam_16_std_attention": 0.622229278087616,
      "attention_bam_16_max_attention": 3.367877960205078,
      "attention_bam_16_min_attention": -1.1587200164794922,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6711529821035804,
      "attention_bam_16_attention_skewness": 0.4823639694369112,
      "attention_bam_16_attention_sparsity": 0.419189453125,
      "attention_bam_16_attention_concentration_10": 0.6270938112723631,
      "attention_bam_16_attention_concentration_20": 0.9964365818534507,
      "attention_bam_16_attention_center_y": 0.4533528594790052,
      "attention_bam_16_attention_center_x": 0.47488396932462423,
      "attention_bam_16_attention_center_distance": 0.07492357059926935,
      "attention_bam_16_attention_spatial_variance": 41.43930431418879,
      "attention_bam_16_attention_spatial_std": 6.437336740779434,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.066440015816887,
      "attention_bam_16_peak_intensity_mean": 0.3122766613960266,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 88,
      "phase": "train",
      "loss": 0.06989113986492157,
      "timestamp": 1759543893.8119287,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.06989113986492157,
      "ssim": 0.5508337616920471,
      "attention_bam_384_mean_attention": 0.19070939719676971,
      "attention_bam_384_std_attention": 0.5458773374557495,
      "attention_bam_384_max_attention": 5.02385950088501,
      "attention_bam_384_min_attention": -1.5774145126342773,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7246186076568764,
      "attention_bam_384_attention_skewness": 0.4626945938364674,
      "attention_bam_384_attention_sparsity": 0.45542653401692706,
      "attention_bam_384_attention_concentration_10": 0.6378345003988224,
      "attention_bam_384_attention_concentration_20": 1.0341858152306045,
      "attention_bam_384_attention_center_y": 0.4888400351060427,
      "attention_bam_384_attention_center_x": 0.48031775989852904,
      "attention_bam_384_attention_center_distance": 0.03199798093149977,
      "attention_bam_384_attention_spatial_variance": 170.79852773302932,
      "attention_bam_384_attention_spatial_std": 13.06899107555856,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 17.09632432635136,
      "attention_bam_384_peak_intensity_mean": 0.26988065242767334,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2307218313217163,
      "attention_bam_16_std_attention": 0.6092807054519653,
      "attention_bam_16_max_attention": 2.6415340900421143,
      "attention_bam_16_min_attention": -1.1162047386169434,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.45328581015247504,
      "attention_bam_16_attention_skewness": 0.23212934325211115,
      "attention_bam_16_attention_sparsity": 0.432861328125,
      "attention_bam_16_attention_concentration_10": 0.5725438338090787,
      "attention_bam_16_attention_concentration_20": 0.960505777760725,
      "attention_bam_16_attention_center_y": 0.48374963034340046,
      "attention_bam_16_attention_center_x": 0.4583316581593204,
      "attention_bam_16_attention_center_distance": 0.06325069526460336,
      "attention_bam_16_attention_spatial_variance": 42.33185965471846,
      "attention_bam_16_attention_spatial_std": 6.506293849398324,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.714460443360412,
      "attention_bam_16_peak_intensity_mean": 0.3690241873264313,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 89,
      "phase": "train",
      "loss": 0.04552658647298813,
      "timestamp": 1759543893.9403017,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.04552658647298813,
      "ssim": 0.5432523488998413,
      "attention_bam_384_mean_attention": 0.185505673289299,
      "attention_bam_384_std_attention": 0.5994012355804443,
      "attention_bam_384_max_attention": 5.244689464569092,
      "attention_bam_384_min_attention": -1.52577543258667,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8563355580355818,
      "attention_bam_384_attention_skewness": 0.8939709179805483,
      "attention_bam_384_attention_sparsity": 0.4834391276041667,
      "attention_bam_384_attention_concentration_10": 0.73965679483959,
      "attention_bam_384_attention_concentration_20": 1.1524962604983466,
      "attention_bam_384_attention_center_y": 0.48506810193959227,
      "attention_bam_384_attention_center_x": 0.4814137642531219,
      "attention_bam_384_attention_center_distance": 0.03371675366712929,
      "attention_bam_384_attention_spatial_variance": 167.7767104802668,
      "attention_bam_384_attention_spatial_std": 12.952864952598972,
      "attention_bam_384_num_attention_peaks": 3,
      "attention_bam_384_peak_separation_mean": 20.603727489878196,
      "attention_bam_384_peak_intensity_mean": 0.2554689943790436,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21689221262931824,
      "attention_bam_16_std_attention": 0.7376825213432312,
      "attention_bam_16_max_attention": 3.573336124420166,
      "attention_bam_16_min_attention": -1.221166729927063,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.5604038433374514,
      "attention_bam_16_attention_skewness": 1.0490949516972563,
      "attention_bam_16_attention_sparsity": 0.490966796875,
      "attention_bam_16_attention_concentration_10": 0.8076213691194588,
      "attention_bam_16_attention_concentration_20": 1.2337929797688592,
      "attention_bam_16_attention_center_y": 0.47131759708145576,
      "attention_bam_16_attention_center_x": 0.4621610366308909,
      "attention_bam_16_attention_center_distance": 0.06714860216014171,
      "attention_bam_16_attention_spatial_variance": 40.055511059999354,
      "attention_bam_16_attention_spatial_std": 6.328942333439242,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 10.454402603310248,
      "attention_bam_16_peak_intensity_mean": 0.30826666951179504,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 90,
      "phase": "train",
      "loss": 0.06336280703544617,
      "timestamp": 1759543894.1082695,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.06336280703544617,
      "ssim": 0.520622968673706,
      "attention_bam_384_mean_attention": 0.18826361000537872,
      "attention_bam_384_std_attention": 0.5208513140678406,
      "attention_bam_384_max_attention": 5.285727500915527,
      "attention_bam_384_min_attention": -1.5079671144485474,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2302630151451934,
      "attention_bam_384_attention_skewness": 0.5511290651872318,
      "attention_bam_384_attention_sparsity": 0.45332082112630206,
      "attention_bam_384_attention_concentration_10": 0.6309910340411773,
      "attention_bam_384_attention_concentration_20": 1.0104745674634317,
      "attention_bam_384_attention_center_y": 0.4850974772689807,
      "attention_bam_384_attention_center_x": 0.48645019408774576,
      "attention_bam_384_attention_center_distance": 0.028484466784839284,
      "attention_bam_384_attention_spatial_variance": 170.03227522243878,
      "attention_bam_384_attention_spatial_std": 13.039642449946195,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 16.618626392677175,
      "attention_bam_384_peak_intensity_mean": 0.25064727663993835,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2179812788963318,
      "attention_bam_16_std_attention": 0.5715456008911133,
      "attention_bam_16_max_attention": 2.433363199234009,
      "attention_bam_16_min_attention": -1.0605459213256836,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.14158057477609542,
      "attention_bam_16_attention_skewness": 0.48717701279123576,
      "attention_bam_16_attention_sparsity": 0.44580078125,
      "attention_bam_16_attention_concentration_10": 0.6092572459291166,
      "attention_bam_16_attention_concentration_20": 0.9881813389062604,
      "attention_bam_16_attention_center_y": 0.4760516723351316,
      "attention_bam_16_attention_center_x": 0.47911379933809217,
      "attention_bam_16_attention_center_distance": 0.04493897586802304,
      "attention_bam_16_attention_spatial_variance": 41.79016037409244,
      "attention_bam_16_attention_spatial_std": 6.464530947724857,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.585729187407773,
      "attention_bam_16_peak_intensity_mean": 0.37316185235977173,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 91,
      "phase": "train",
      "loss": 0.08710753172636032,
      "timestamp": 1759543894.236427,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.08710753172636032,
      "ssim": 0.501352071762085,
      "attention_bam_384_mean_attention": 0.19819127023220062,
      "attention_bam_384_std_attention": 0.5461499094963074,
      "attention_bam_384_max_attention": 4.700160026550293,
      "attention_bam_384_min_attention": -1.5380427837371826,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.389205773403627,
      "attention_bam_384_attention_skewness": 0.7000641948452275,
      "attention_bam_384_attention_sparsity": 0.45965830485026044,
      "attention_bam_384_attention_concentration_10": 0.6432923824893341,
      "attention_bam_384_attention_concentration_20": 1.0157990346748411,
      "attention_bam_384_attention_center_y": 0.4892241994476647,
      "attention_bam_384_attention_center_x": 0.48511236295468246,
      "attention_bam_384_attention_center_distance": 0.025990752753116658,
      "attention_bam_384_attention_spatial_variance": 171.30460406872862,
      "attention_bam_384_attention_spatial_std": 13.088338476243981,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 17.26121961109617,
      "attention_bam_384_peak_intensity_mean": 0.28235694766044617,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2337483912706375,
      "attention_bam_16_std_attention": 0.6012226939201355,
      "attention_bam_16_max_attention": 3.0991415977478027,
      "attention_bam_16_min_attention": -1.1236199140548706,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.31553485970512263,
      "attention_bam_16_attention_skewness": 0.5407557936773546,
      "attention_bam_16_attention_sparsity": 0.4443359375,
      "attention_bam_16_attention_concentration_10": 0.599827151709127,
      "attention_bam_16_attention_concentration_20": 0.966203360070293,
      "attention_bam_16_attention_center_y": 0.485451532852787,
      "attention_bam_16_attention_center_x": 0.47233716525255287,
      "attention_bam_16_attention_center_distance": 0.044201590980373164,
      "attention_bam_16_attention_spatial_variance": 42.792419364076885,
      "attention_bam_16_attention_spatial_std": 6.541591500856415,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.648285204264583,
      "attention_bam_16_peak_intensity_mean": 0.33525317907333374,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 92,
      "phase": "train",
      "loss": 0.053917743265628815,
      "timestamp": 1759543894.3646472,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.053917743265628815,
      "ssim": 0.5272382497787476,
      "attention_bam_384_mean_attention": 0.19981642067432404,
      "attention_bam_384_std_attention": 0.5206329822540283,
      "attention_bam_384_max_attention": 4.344592571258545,
      "attention_bam_384_min_attention": -1.4740962982177734,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7270693938851611,
      "attention_bam_384_attention_skewness": 0.5171267784812194,
      "attention_bam_384_attention_sparsity": 0.45008595784505206,
      "attention_bam_384_attention_concentration_10": 0.5971722436608637,
      "attention_bam_384_attention_concentration_20": 0.96793436272309,
      "attention_bam_384_attention_center_y": 0.4808429332826123,
      "attention_bam_384_attention_center_x": 0.48382117434619526,
      "attention_bam_384_attention_center_distance": 0.03546117890738135,
      "attention_bam_384_attention_spatial_variance": 170.38151290964814,
      "attention_bam_384_attention_spatial_std": 13.05302696349196,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 16.51704790385862,
      "attention_bam_384_peak_intensity_mean": 0.29000839591026306,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23829466104507446,
      "attention_bam_16_std_attention": 0.5540207624435425,
      "attention_bam_16_max_attention": 2.362051248550415,
      "attention_bam_16_min_attention": -1.1470146179199219,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.10319527819428975,
      "attention_bam_16_attention_skewness": 0.34341525256973277,
      "attention_bam_16_attention_sparsity": 0.4248046875,
      "attention_bam_16_attention_concentration_10": 0.531584666124775,
      "attention_bam_16_attention_concentration_20": 0.8818528430061222,
      "attention_bam_16_attention_center_y": 0.4639118971567538,
      "attention_bam_16_attention_center_x": 0.47148897525716543,
      "attention_bam_16_attention_center_distance": 0.06504198180731026,
      "attention_bam_16_attention_spatial_variance": 41.83970999679665,
      "attention_bam_16_attention_spatial_std": 6.46836223450702,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.32345756619776,
      "attention_bam_16_peak_intensity_mean": 0.3977319300174713,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 93,
      "phase": "train",
      "loss": 0.04614986479282379,
      "timestamp": 1759543894.4946685,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.04614986479282379,
      "ssim": 0.6140308976173401,
      "attention_bam_384_mean_attention": 0.20472872257232666,
      "attention_bam_384_std_attention": 0.5215386748313904,
      "attention_bam_384_max_attention": 4.644651889801025,
      "attention_bam_384_min_attention": -1.4527274370193481,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8310762360395203,
      "attention_bam_384_attention_skewness": 0.5915288407047299,
      "attention_bam_384_attention_sparsity": 0.4532877604166667,
      "attention_bam_384_attention_concentration_10": 0.5905694632956622,
      "attention_bam_384_attention_concentration_20": 0.9533871864012541,
      "attention_bam_384_attention_center_y": 0.48274308203701616,
      "attention_bam_384_attention_center_x": 0.4739270384573591,
      "attention_bam_384_attention_center_distance": 0.044217655776514986,
      "attention_bam_384_attention_spatial_variance": 168.38407449396234,
      "attention_bam_384_attention_spatial_std": 12.976288933819344,
      "attention_bam_384_num_attention_peaks": 4,
      "attention_bam_384_peak_separation_mean": 13.140418798268934,
      "attention_bam_384_peak_intensity_mean": 0.27378201484680176,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24346205592155457,
      "attention_bam_16_std_attention": 0.5767073631286621,
      "attention_bam_16_max_attention": 2.493480682373047,
      "attention_bam_16_min_attention": -1.062589406967163,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.0678912044390998,
      "attention_bam_16_attention_skewness": 0.4457590210072839,
      "attention_bam_16_attention_sparsity": 0.43994140625,
      "attention_bam_16_attention_concentration_10": 0.5456624374993557,
      "attention_bam_16_attention_concentration_20": 0.894742418218643,
      "attention_bam_16_attention_center_y": 0.4691259369791295,
      "attention_bam_16_attention_center_x": 0.44641344287296725,
      "attention_bam_16_attention_center_distance": 0.08746115563089052,
      "attention_bam_16_attention_spatial_variance": 40.271786917029594,
      "attention_bam_16_attention_spatial_std": 6.346005587535327,
      "attention_bam_16_num_attention_peaks": 2,
      "attention_bam_16_peak_separation_mean": 4.233323162097244,
      "attention_bam_16_peak_intensity_mean": 0.3823208808898926,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 94,
      "phase": "train",
      "loss": 0.05720360204577446,
      "timestamp": 1759543894.6262105,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.05720360204577446,
      "ssim": 0.5562981963157654,
      "attention_bam_384_mean_attention": 0.19766074419021606,
      "attention_bam_384_std_attention": 0.5704951286315918,
      "attention_bam_384_max_attention": 5.292250633239746,
      "attention_bam_384_min_attention": -1.5687477588653564,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0381794575729417,
      "attention_bam_384_attention_skewness": 0.6518020947172193,
      "attention_bam_384_attention_sparsity": 0.46315765380859375,
      "attention_bam_384_attention_concentration_10": 0.663915221763479,
      "attention_bam_384_attention_concentration_20": 1.058574525779444,
      "attention_bam_384_attention_center_y": 0.4794872142889754,
      "attention_bam_384_attention_center_x": 0.4882043918033233,
      "attention_bam_384_attention_center_distance": 0.033463734111898555,
      "attention_bam_384_attention_spatial_variance": 169.43772589719023,
      "attention_bam_384_attention_spatial_std": 13.01682472407116,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 14.435656619025476,
      "attention_bam_384_peak_intensity_mean": 0.2583702802658081,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22208955883979797,
      "attention_bam_16_std_attention": 0.6176315546035767,
      "attention_bam_16_max_attention": 2.4934144020080566,
      "attention_bam_16_min_attention": -1.0302672386169434,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.02686769435705383,
      "attention_bam_16_attention_skewness": 0.49920420958415895,
      "attention_bam_16_attention_sparsity": 0.4453125,
      "attention_bam_16_attention_concentration_10": 0.634337432087571,
      "attention_bam_16_attention_concentration_20": 1.0249757483996815,
      "attention_bam_16_attention_center_y": 0.4577557379499103,
      "attention_bam_16_attention_center_x": 0.48648071540126586,
      "attention_bam_16_attention_center_distance": 0.06272716687717081,
      "attention_bam_16_attention_spatial_variance": 41.37588107918374,
      "attention_bam_16_attention_spatial_std": 6.43240865299957,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 8.899215317091132,
      "attention_bam_16_peak_intensity_mean": 0.3668612539768219,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 95,
      "phase": "train",
      "loss": 0.04292255640029907,
      "timestamp": 1759543894.753903,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.04292255640029907,
      "ssim": 0.4471227824687958,
      "attention_bam_384_mean_attention": 0.2152259796857834,
      "attention_bam_384_std_attention": 0.4033755362033844,
      "attention_bam_384_max_attention": 5.035792827606201,
      "attention_bam_384_min_attention": -1.5089378356933594,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.6381226374450524,
      "attention_bam_384_attention_skewness": 0.7931450219629571,
      "attention_bam_384_attention_sparsity": 0.39102935791015625,
      "attention_bam_384_attention_concentration_10": 0.4702837100852991,
      "attention_bam_384_attention_concentration_20": 0.7411019232731788,
      "attention_bam_384_attention_center_y": 0.48373099216478466,
      "attention_bam_384_attention_center_x": 0.4875765092416759,
      "attention_bam_384_attention_center_distance": 0.028949049675748004,
      "attention_bam_384_attention_spatial_variance": 169.61696175880456,
      "attention_bam_384_attention_spatial_std": 13.023707680948792,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 14.906508861936492,
      "attention_bam_384_peak_intensity_mean": 0.26440849900245667,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.26178687810897827,
      "attention_bam_16_std_attention": 0.37161460518836975,
      "attention_bam_16_max_attention": 2.643282413482666,
      "attention_bam_16_min_attention": -0.9439424276351929,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.691459654380509,
      "attention_bam_16_attention_skewness": 0.5851429931387492,
      "attention_bam_16_attention_sparsity": 0.3466796875,
      "attention_bam_16_attention_concentration_10": 0.37843486704617757,
      "attention_bam_16_attention_concentration_20": 0.6148158436027822,
      "attention_bam_16_attention_center_y": 0.4719914877635676,
      "attention_bam_16_attention_center_x": 0.4807320696508491,
      "attention_bam_16_attention_center_distance": 0.048077643403938074,
      "attention_bam_16_attention_spatial_variance": 41.491169801600975,
      "attention_bam_16_attention_spatial_std": 6.441363970588914,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 5.457889266112063,
      "attention_bam_16_peak_intensity_mean": 0.3454344868659973,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 96,
      "phase": "train",
      "loss": 0.04527075216174126,
      "timestamp": 1759543894.8820972,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.04527075216174126,
      "ssim": 0.5658904314041138,
      "attention_bam_384_mean_attention": 0.202057883143425,
      "attention_bam_384_std_attention": 0.5238495469093323,
      "attention_bam_384_max_attention": 4.857700347900391,
      "attention_bam_384_min_attention": -1.585749626159668,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.235151931190086,
      "attention_bam_384_attention_skewness": 0.6233325727209018,
      "attention_bam_384_attention_sparsity": 0.45453135172526044,
      "attention_bam_384_attention_concentration_10": 0.6029743047771757,
      "attention_bam_384_attention_concentration_20": 0.9682962654717517,
      "attention_bam_384_attention_center_y": 0.47790456635609657,
      "attention_bam_384_attention_center_x": 0.4811982755764121,
      "attention_bam_384_attention_center_distance": 0.04102957541122456,
      "attention_bam_384_attention_spatial_variance": 171.05675867804598,
      "attention_bam_384_attention_spatial_std": 13.07886687286196,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 16.286076609931076,
      "attention_bam_384_peak_intensity_mean": 0.28031373023986816,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24006369709968567,
      "attention_bam_16_std_attention": 0.5717806220054626,
      "attention_bam_16_max_attention": 2.2304506301879883,
      "attention_bam_16_min_attention": -1.0005919933319092,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.31786259866469946,
      "attention_bam_16_attention_skewness": 0.32337634920569913,
      "attention_bam_16_attention_sparsity": 0.432373046875,
      "attention_bam_16_attention_concentration_10": 0.5418008811891367,
      "attention_bam_16_attention_concentration_20": 0.9028881464194419,
      "attention_bam_16_attention_center_y": 0.4508944821510073,
      "attention_bam_16_attention_center_x": 0.4597411923777582,
      "attention_bam_16_attention_center_distance": 0.08980115226858078,
      "attention_bam_16_attention_spatial_variance": 42.219593444327955,
      "attention_bam_16_attention_spatial_std": 6.4976606131997965,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 7.892674790898096,
      "attention_bam_16_peak_intensity_mean": 0.40128204226493835,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 97,
      "phase": "train",
      "loss": 0.0482923686504364,
      "timestamp": 1759543895.010589,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0482923686504364,
      "ssim": 0.5717211961746216,
      "attention_bam_384_mean_attention": 0.2046075016260147,
      "attention_bam_384_std_attention": 0.4853082001209259,
      "attention_bam_384_max_attention": 4.994378089904785,
      "attention_bam_384_min_attention": -1.5139350891113281,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.6492075797432504,
      "attention_bam_384_attention_skewness": 0.5812250474763444,
      "attention_bam_384_attention_sparsity": 0.4324849446614583,
      "attention_bam_384_attention_concentration_10": 0.5562017289761543,
      "attention_bam_384_attention_concentration_20": 0.8940403659539317,
      "attention_bam_384_attention_center_y": 0.48284896613316314,
      "attention_bam_384_attention_center_x": 0.48450403376035134,
      "attention_bam_384_attention_center_distance": 0.03268892572115872,
      "attention_bam_384_attention_spatial_variance": 170.42894207585627,
      "attention_bam_384_attention_spatial_std": 13.054843625101615,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 17.50309862075634,
      "attention_bam_384_peak_intensity_mean": 0.2656165659427643,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24332723021507263,
      "attention_bam_16_std_attention": 0.48471179604530334,
      "attention_bam_16_max_attention": 2.1905550956726074,
      "attention_bam_16_min_attention": -0.9031440019607544,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.048386751353392654,
      "attention_bam_16_attention_skewness": 0.28021733039206,
      "attention_bam_16_attention_sparsity": 0.395263671875,
      "attention_bam_16_attention_concentration_10": 0.4672357807771576,
      "attention_bam_16_attention_concentration_20": 0.7698001287660339,
      "attention_bam_16_attention_center_y": 0.46574337058793525,
      "attention_bam_16_attention_center_x": 0.4747755674977644,
      "attention_bam_16_attention_center_distance": 0.060162923029643094,
      "attention_bam_16_attention_spatial_variance": 41.953696880188915,
      "attention_bam_16_attention_spatial_std": 6.477167350021838,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.481776212491969,
      "attention_bam_16_peak_intensity_mean": 0.381286084651947,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 98,
      "phase": "train",
      "loss": 0.049247682094573975,
      "timestamp": 1759543895.141603,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.049247682094573975,
      "ssim": 0.5240183472633362,
      "attention_bam_384_mean_attention": 0.19770844280719757,
      "attention_bam_384_std_attention": 0.5408373475074768,
      "attention_bam_384_max_attention": 4.816963195800781,
      "attention_bam_384_min_attention": -1.5159029960632324,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0035590167465642,
      "attention_bam_384_attention_skewness": 0.6668340328612868,
      "attention_bam_384_attention_sparsity": 0.46226755777994794,
      "attention_bam_384_attention_concentration_10": 0.6334304660278282,
      "attention_bam_384_attention_concentration_20": 1.0126254749273946,
      "attention_bam_384_attention_center_y": 0.4856074611241307,
      "attention_bam_384_attention_center_x": 0.48508162103248115,
      "attention_bam_384_attention_center_distance": 0.029315634269512822,
      "attention_bam_384_attention_spatial_variance": 170.01359902114297,
      "attention_bam_384_attention_spatial_std": 13.038926298631454,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 16.480264780367786,
      "attention_bam_384_peak_intensity_mean": 0.2754080593585968,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22817859053611755,
      "attention_bam_16_std_attention": 0.6352635025978088,
      "attention_bam_16_max_attention": 2.8091797828674316,
      "attention_bam_16_min_attention": -1.1285350322723389,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.14715108216411643,
      "attention_bam_16_attention_skewness": 0.5670695639357156,
      "attention_bam_16_attention_sparsity": 0.453369140625,
      "attention_bam_16_attention_concentration_10": 0.6444950716344481,
      "attention_bam_16_attention_concentration_20": 1.03992730005393,
      "attention_bam_16_attention_center_y": 0.47649938412795495,
      "attention_bam_16_attention_center_x": 0.47509347272014474,
      "attention_bam_16_attention_center_distance": 0.0484275551211826,
      "attention_bam_16_attention_spatial_variance": 41.910513240886864,
      "attention_bam_16_attention_spatial_std": 6.473832963622622,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.409359280072232,
      "attention_bam_16_peak_intensity_mean": 0.35592490434646606,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 99,
      "phase": "train",
      "loss": 0.04676174744963646,
      "timestamp": 1759543895.26985,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.04676174744963646,
      "ssim": 0.5311862826347351,
      "attention_bam_384_mean_attention": 0.18921451270580292,
      "attention_bam_384_std_attention": 0.5192182660102844,
      "attention_bam_384_max_attention": 4.673749923706055,
      "attention_bam_384_min_attention": -1.489107370376587,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2240279559629244,
      "attention_bam_384_attention_skewness": 0.5998436956191098,
      "attention_bam_384_attention_sparsity": 0.4550577799479167,
      "attention_bam_384_attention_concentration_10": 0.6245453604239124,
      "attention_bam_384_attention_concentration_20": 1.0013978086575848,
      "attention_bam_384_attention_center_y": 0.4840180646394935,
      "attention_bam_384_attention_center_x": 0.4866847624965803,
      "attention_bam_384_attention_center_distance": 0.02941828708949188,
      "attention_bam_384_attention_spatial_variance": 168.82727176242105,
      "attention_bam_384_attention_spatial_std": 12.993354907891227,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 16.663025683096002,
      "attention_bam_384_peak_intensity_mean": 0.2739536464214325,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22107011079788208,
      "attention_bam_16_std_attention": 0.5919705629348755,
      "attention_bam_16_max_attention": 2.9546499252319336,
      "attention_bam_16_min_attention": -1.1306917667388916,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.757652167125253,
      "attention_bam_16_attention_skewness": 0.6318310398442819,
      "attention_bam_16_attention_sparsity": 0.44677734375,
      "attention_bam_16_attention_concentration_10": 0.6177989889768252,
      "attention_bam_16_attention_concentration_20": 0.991782560024378,
      "attention_bam_16_attention_center_y": 0.47203747096907334,
      "attention_bam_16_attention_center_x": 0.47970416302561025,
      "attention_bam_16_attention_center_distance": 0.0488635657376009,
      "attention_bam_16_attention_spatial_variance": 40.87317100066558,
      "attention_bam_16_attention_spatial_std": 6.3932128856049815,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.843195594818651,
      "attention_bam_16_peak_intensity_mean": 0.336359441280365,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 100,
      "phase": "train",
      "loss": 0.04336698353290558,
      "timestamp": 1759543895.645121,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.04336698353290558,
      "ssim": 0.5929754972457886,
      "attention_bam_384_mean_attention": 0.1902947872877121,
      "attention_bam_384_std_attention": 0.5476369261741638,
      "attention_bam_384_max_attention": 4.7972259521484375,
      "attention_bam_384_min_attention": -1.6384613513946533,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7837278214734011,
      "attention_bam_384_attention_skewness": 0.5046946992049592,
      "attention_bam_384_attention_sparsity": 0.45286814371744794,
      "attention_bam_384_attention_concentration_10": 0.6389820784413185,
      "attention_bam_384_attention_concentration_20": 1.0330790313064704,
      "attention_bam_384_attention_center_y": 0.4810554522538573,
      "attention_bam_384_attention_center_x": 0.4830312318869551,
      "attention_bam_384_attention_center_distance": 0.03596762379085302,
      "attention_bam_384_attention_spatial_variance": 170.87901011331732,
      "attention_bam_384_attention_spatial_std": 13.07206984808899,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 18.060838785571864,
      "attention_bam_384_peak_intensity_mean": 0.2844005823135376,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21897898614406586,
      "attention_bam_16_std_attention": 0.61314457654953,
      "attention_bam_16_max_attention": 2.3962109088897705,
      "attention_bam_16_min_attention": -1.0099741220474243,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.19995886710754984,
      "attention_bam_16_attention_skewness": 0.3849270835801891,
      "attention_bam_16_attention_sparsity": 0.438720703125,
      "attention_bam_16_attention_concentration_10": 0.6238774487048242,
      "attention_bam_16_attention_concentration_20": 1.0151204819942798,
      "attention_bam_16_attention_center_y": 0.4609671468595275,
      "attention_bam_16_attention_center_x": 0.46808192687262484,
      "attention_bam_16_attention_center_distance": 0.07130676007855302,
      "attention_bam_16_attention_spatial_variance": 42.363408404328716,
      "attention_bam_16_attention_spatial_std": 6.508717877149747,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.534965282616854,
      "attention_bam_16_peak_intensity_mean": 0.36926040053367615,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 101,
      "phase": "train",
      "loss": 0.042137689888477325,
      "timestamp": 1759543897.9028838,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.042137689888477325,
      "ssim": 0.5923938155174255,
      "attention_bam_384_mean_attention": 0.18481862545013428,
      "attention_bam_384_std_attention": 0.5254484415054321,
      "attention_bam_384_max_attention": 4.687544345855713,
      "attention_bam_384_min_attention": -1.5943883657455444,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.428054387586708,
      "attention_bam_384_attention_skewness": 0.6692068022990094,
      "attention_bam_384_attention_sparsity": 0.4607594807942708,
      "attention_bam_384_attention_concentration_10": 0.6459690400984854,
      "attention_bam_384_attention_concentration_20": 1.0300564617542813,
      "attention_bam_384_attention_center_y": 0.482491946618982,
      "attention_bam_384_attention_center_x": 0.481252765378526,
      "attention_bam_384_attention_center_distance": 0.03627645900980881,
      "attention_bam_384_attention_spatial_variance": 170.02710576047656,
      "attention_bam_384_attention_spatial_std": 13.039444227438398,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 17.777384966295184,
      "attention_bam_384_peak_intensity_mean": 0.28449249267578125,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2261243462562561,
      "attention_bam_16_std_attention": 0.6062214374542236,
      "attention_bam_16_max_attention": 2.7912487983703613,
      "attention_bam_16_min_attention": -1.1270520687103271,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5727499555533919,
      "attention_bam_16_attention_skewness": 0.5802636773414834,
      "attention_bam_16_attention_sparsity": 0.435791015625,
      "attention_bam_16_attention_concentration_10": 0.6171072217116588,
      "attention_bam_16_attention_concentration_20": 0.9927074544069182,
      "attention_bam_16_attention_center_y": 0.46905543270062894,
      "attention_bam_16_attention_center_x": 0.4616136430057036,
      "attention_bam_16_attention_center_distance": 0.06972917106403706,
      "attention_bam_16_attention_spatial_variance": 41.89832133583619,
      "attention_bam_16_attention_spatial_std": 6.472891265565658,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 7.739757261379198,
      "attention_bam_16_peak_intensity_mean": 0.3498072624206543,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 102,
      "phase": "train",
      "loss": 0.04071524366736412,
      "timestamp": 1759543898.0383797,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.04071524366736412,
      "ssim": 0.6253974437713623,
      "attention_bam_384_mean_attention": 0.18805915117263794,
      "attention_bam_384_std_attention": 0.5306676030158997,
      "attention_bam_384_max_attention": 7.007475852966309,
      "attention_bam_384_min_attention": -1.5912740230560303,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.5055865813824267,
      "attention_bam_384_attention_skewness": 0.6750921950683332,
      "attention_bam_384_attention_sparsity": 0.46517181396484375,
      "attention_bam_384_attention_concentration_10": 0.6229335764099014,
      "attention_bam_384_attention_concentration_20": 1.0170960813079886,
      "attention_bam_384_attention_center_y": 0.4829349917533819,
      "attention_bam_384_attention_center_x": 0.4875451379417736,
      "attention_bam_384_attention_center_distance": 0.02987768717108441,
      "attention_bam_384_attention_spatial_variance": 171.3667528888628,
      "attention_bam_384_attention_spatial_std": 13.090712466816418,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 17.40550002640533,
      "attention_bam_384_peak_intensity_mean": 0.2087377905845642,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22032994031906128,
      "attention_bam_16_std_attention": 0.5878260135650635,
      "attention_bam_16_max_attention": 2.3355112075805664,
      "attention_bam_16_min_attention": -1.1926541328430176,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.5592412723956599,
      "attention_bam_16_attention_skewness": 0.25733393282113315,
      "attention_bam_16_attention_sparsity": 0.45263671875,
      "attention_bam_16_attention_concentration_10": 0.577418089912155,
      "attention_bam_16_attention_concentration_20": 0.9774722083319819,
      "attention_bam_16_attention_center_y": 0.46679930008039155,
      "attention_bam_16_attention_center_x": 0.48467108240199025,
      "attention_bam_16_attention_center_distance": 0.05171580396510261,
      "attention_bam_16_attention_spatial_variance": 42.542207666564174,
      "attention_bam_16_attention_spatial_std": 6.522438782124687,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.950889401516797,
      "attention_bam_16_peak_intensity_mean": 0.41080835461616516,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 103,
      "phase": "train",
      "loss": 0.04832009598612785,
      "timestamp": 1759543898.1685774,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.04832009598612785,
      "ssim": 0.6086645126342773,
      "attention_bam_384_mean_attention": 0.17682047188282013,
      "attention_bam_384_std_attention": 0.5830510854721069,
      "attention_bam_384_max_attention": 4.641313552856445,
      "attention_bam_384_min_attention": -1.672898769378662,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.02324160700329,
      "attention_bam_384_attention_skewness": 0.737579741255548,
      "attention_bam_384_attention_sparsity": 0.49156443277994794,
      "attention_bam_384_attention_concentration_10": 0.7572254396961674,
      "attention_bam_384_attention_concentration_20": 1.193146686628293,
      "attention_bam_384_attention_center_y": 0.48217345654320193,
      "attention_bam_384_attention_center_x": 0.4905181587151206,
      "attention_bam_384_attention_center_distance": 0.028554893302856283,
      "attention_bam_384_attention_spatial_variance": 169.29171268324774,
      "attention_bam_384_attention_spatial_std": 13.011214881141873,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 15.004692244205273,
      "attention_bam_384_peak_intensity_mean": 0.29287979006767273,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20385265350341797,
      "attention_bam_16_std_attention": 0.7017507553100586,
      "attention_bam_16_max_attention": 3.4124410152435303,
      "attention_bam_16_min_attention": -1.211066722869873,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.2515447391194434,
      "attention_bam_16_attention_skewness": 0.7816075947104634,
      "attention_bam_16_attention_sparsity": 0.510009765625,
      "attention_bam_16_attention_concentration_10": 0.8015077132602659,
      "attention_bam_16_attention_concentration_20": 1.2813501438409383,
      "attention_bam_16_attention_center_y": 0.4631263048208851,
      "attention_bam_16_attention_center_x": 0.4914502715910652,
      "attention_bam_16_attention_center_distance": 0.05353068749845879,
      "attention_bam_16_attention_spatial_variance": 41.072466975072295,
      "attention_bam_16_attention_spatial_std": 6.408780459266201,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 7.353218451538588,
      "attention_bam_16_peak_intensity_mean": 0.3065744936466217,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 104,
      "phase": "train",
      "loss": 0.03118988871574402,
      "timestamp": 1759543898.2997985,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.03118988871574402,
      "ssim": 0.5589684247970581,
      "attention_bam_384_mean_attention": 0.19625715911388397,
      "attention_bam_384_std_attention": 0.5272821187973022,
      "attention_bam_384_max_attention": 5.172338962554932,
      "attention_bam_384_min_attention": -1.6112682819366455,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.192599067721762,
      "attention_bam_384_attention_skewness": 0.5747814891239115,
      "attention_bam_384_attention_sparsity": 0.44959259033203125,
      "attention_bam_384_attention_concentration_10": 0.6144722293480055,
      "attention_bam_384_attention_concentration_20": 0.9865417365106812,
      "attention_bam_384_attention_center_y": 0.4815250716069528,
      "attention_bam_384_attention_center_x": 0.48838446108726985,
      "attention_bam_384_attention_center_distance": 0.03086239534972521,
      "attention_bam_384_attention_spatial_variance": 170.71637959962288,
      "attention_bam_384_attention_spatial_std": 13.065847833172667,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 16.509371436068335,
      "attention_bam_384_peak_intensity_mean": 0.2683217525482178,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22609898447990417,
      "attention_bam_16_std_attention": 0.5816664099693298,
      "attention_bam_16_max_attention": 2.4431943893432617,
      "attention_bam_16_min_attention": -1.0662821531295776,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.034597532517965934,
      "attention_bam_16_attention_skewness": 0.4071678982179355,
      "attention_bam_16_attention_sparsity": 0.4287109375,
      "attention_bam_16_attention_concentration_10": 0.5878158173869779,
      "attention_bam_16_attention_concentration_20": 0.9559993293355534,
      "attention_bam_16_attention_center_y": 0.4644474549640731,
      "attention_bam_16_attention_center_x": 0.48497677812113493,
      "attention_bam_16_attention_center_distance": 0.05458352597905749,
      "attention_bam_16_attention_spatial_variance": 42.22240563215081,
      "attention_bam_16_attention_spatial_std": 6.497877009620204,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.795471641190709,
      "attention_bam_16_peak_intensity_mean": 0.37607240676879883,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 105,
      "phase": "train",
      "loss": 0.030194725841283798,
      "timestamp": 1759543898.441331,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.030194725841283798,
      "ssim": 0.6471701860427856,
      "attention_bam_384_mean_attention": 0.18788059055805206,
      "attention_bam_384_std_attention": 0.47218576073646545,
      "attention_bam_384_max_attention": 5.612591743469238,
      "attention_bam_384_min_attention": -1.6101996898651123,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.2128643630757807,
      "attention_bam_384_attention_skewness": 0.7075720933699515,
      "attention_bam_384_attention_sparsity": 0.44592030843098956,
      "attention_bam_384_attention_concentration_10": 0.5788050133560404,
      "attention_bam_384_attention_concentration_20": 0.9281371016692306,
      "attention_bam_384_attention_center_y": 0.4805070860848429,
      "attention_bam_384_attention_center_x": 0.4874496796991423,
      "attention_bam_384_attention_center_distance": 0.03278671171550591,
      "attention_bam_384_attention_spatial_variance": 170.01105582269898,
      "attention_bam_384_attention_spatial_std": 13.038828774959006,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 14.863124996732797,
      "attention_bam_384_peak_intensity_mean": 0.25082096457481384,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21776805818080902,
      "attention_bam_16_std_attention": 0.5022638440132141,
      "attention_bam_16_max_attention": 2.019083261489868,
      "attention_bam_16_min_attention": -1.0403791666030884,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.16017613871961034,
      "attention_bam_16_attention_skewness": 0.27517106054745677,
      "attention_bam_16_attention_sparsity": 0.430419921875,
      "attention_bam_16_attention_concentration_10": 0.5220884638799091,
      "attention_bam_16_attention_concentration_20": 0.8701323174873694,
      "attention_bam_16_attention_center_y": 0.4604273580547424,
      "attention_bam_16_attention_center_x": 0.4788035110690251,
      "attention_bam_16_attention_center_distance": 0.06348677237863812,
      "attention_bam_16_attention_spatial_variance": 41.066884732360755,
      "attention_bam_16_attention_spatial_std": 6.408344929259095,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 7.397320541269685,
      "attention_bam_16_peak_intensity_mean": 0.4210311770439148,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 106,
      "phase": "train",
      "loss": 0.03803764283657074,
      "timestamp": 1759543898.5769444,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.03803764283657074,
      "ssim": 0.6048275828361511,
      "attention_bam_384_mean_attention": 0.1808294802904129,
      "attention_bam_384_std_attention": 0.5614739656448364,
      "attention_bam_384_max_attention": 5.975358009338379,
      "attention_bam_384_min_attention": -1.661684274673462,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2578545951957185,
      "attention_bam_384_attention_skewness": 0.5619541050087131,
      "attention_bam_384_attention_sparsity": 0.4672088623046875,
      "attention_bam_384_attention_concentration_10": 0.6832259950780487,
      "attention_bam_384_attention_concentration_20": 1.1066054778546819,
      "attention_bam_384_attention_center_y": 0.4879926903117905,
      "attention_bam_384_attention_center_x": 0.48440773235927737,
      "attention_bam_384_attention_center_distance": 0.027831431732072146,
      "attention_bam_384_attention_spatial_variance": 170.33771884250964,
      "attention_bam_384_attention_spatial_std": 13.051349311182719,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 18.604448481381297,
      "attention_bam_384_peak_intensity_mean": 0.2418280988931656,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21611115336418152,
      "attention_bam_16_std_attention": 0.6412731409072876,
      "attention_bam_16_max_attention": 2.9168975353240967,
      "attention_bam_16_min_attention": -1.4211018085479736,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.032061590331307066,
      "attention_bam_16_attention_skewness": 0.45392024751601523,
      "attention_bam_16_attention_sparsity": 0.459228515625,
      "attention_bam_16_attention_concentration_10": 0.6507521836482214,
      "attention_bam_16_attention_concentration_20": 1.068957994396519,
      "attention_bam_16_attention_center_y": 0.4826537477440539,
      "attention_bam_16_attention_center_x": 0.4712618281193586,
      "attention_bam_16_attention_center_distance": 0.04747157023668387,
      "attention_bam_16_attention_spatial_variance": 41.94902805391731,
      "attention_bam_16_attention_spatial_std": 6.476806933506457,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 7.2145001772712325,
      "attention_bam_16_peak_intensity_mean": 0.39287349581718445,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 107,
      "phase": "train",
      "loss": 0.04333024471998215,
      "timestamp": 1759543898.7102606,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.04333024471998215,
      "ssim": 0.5530779361724854,
      "attention_bam_384_mean_attention": 0.17300468683242798,
      "attention_bam_384_std_attention": 0.5584560632705688,
      "attention_bam_384_max_attention": 5.879068374633789,
      "attention_bam_384_min_attention": -1.6110005378723145,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.10125595127532,
      "attention_bam_384_attention_skewness": 0.6149725003638039,
      "attention_bam_384_attention_sparsity": 0.48348236083984375,
      "attention_bam_384_attention_concentration_10": 0.719293558244515,
      "attention_bam_384_attention_concentration_20": 1.156023391490332,
      "attention_bam_384_attention_center_y": 0.4851504427853562,
      "attention_bam_384_attention_center_x": 0.48469901261087694,
      "attention_bam_384_attention_center_distance": 0.030153923942103554,
      "attention_bam_384_attention_spatial_variance": 169.4998728249634,
      "attention_bam_384_attention_spatial_std": 13.019211682162764,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 17.637361476855837,
      "attention_bam_384_peak_intensity_mean": 0.24010854959487915,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20333747565746307,
      "attention_bam_16_std_attention": 0.6685174703598022,
      "attention_bam_16_max_attention": 2.7977190017700195,
      "attention_bam_16_min_attention": -1.1095569133758545,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.23232947908007962,
      "attention_bam_16_attention_skewness": 0.7005672035962055,
      "attention_bam_16_attention_sparsity": 0.4912109375,
      "attention_bam_16_attention_concentration_10": 0.7557243293369122,
      "attention_bam_16_attention_concentration_20": 1.214053433630353,
      "attention_bam_16_attention_center_y": 0.47567307427308503,
      "attention_bam_16_attention_center_x": 0.4716219213113799,
      "attention_bam_16_attention_center_distance": 0.05286047039859465,
      "attention_bam_16_attention_spatial_variance": 41.14094403559613,
      "attention_bam_16_attention_spatial_std": 6.414120675166326,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 9.82226401629656,
      "attention_bam_16_peak_intensity_mean": 0.3429315984249115,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 108,
      "phase": "train",
      "loss": 0.03159930929541588,
      "timestamp": 1759543898.8451967,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.03159930929541588,
      "ssim": 0.6009725332260132,
      "attention_bam_384_mean_attention": 0.17810086905956268,
      "attention_bam_384_std_attention": 0.5434595346450806,
      "attention_bam_384_max_attention": 7.411942481994629,
      "attention_bam_384_min_attention": -1.676159143447876,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.564308597676755,
      "attention_bam_384_attention_skewness": 0.7789452007904826,
      "attention_bam_384_attention_sparsity": 0.46874745686848956,
      "attention_bam_384_attention_concentration_10": 0.6800468758191421,
      "attention_bam_384_attention_concentration_20": 1.0790496769895304,
      "attention_bam_384_attention_center_y": 0.4770149299637895,
      "attention_bam_384_attention_center_x": 0.48509581506979793,
      "attention_bam_384_attention_center_distance": 0.03874140351105424,
      "attention_bam_384_attention_spatial_variance": 172.45276451850478,
      "attention_bam_384_attention_spatial_std": 13.132127189397185,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 18.542201056352994,
      "attention_bam_384_peak_intensity_mean": 0.20472685992717743,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20853668451309204,
      "attention_bam_16_std_attention": 0.6328861713409424,
      "attention_bam_16_max_attention": 3.170994997024536,
      "attention_bam_16_min_attention": -1.0107682943344116,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6302142724424287,
      "attention_bam_16_attention_skewness": 0.6009857320174731,
      "attention_bam_16_attention_sparsity": 0.4560546875,
      "attention_bam_16_attention_concentration_10": 0.6672383609098528,
      "attention_bam_16_attention_concentration_20": 1.0796590270734057,
      "attention_bam_16_attention_center_y": 0.44664276836270134,
      "attention_bam_16_attention_center_x": 0.4711174463296172,
      "attention_bam_16_attention_center_distance": 0.08580438304094828,
      "attention_bam_16_attention_spatial_variance": 43.813550113958435,
      "attention_bam_16_attention_spatial_std": 6.619180471475183,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.13687007171536,
      "attention_bam_16_peak_intensity_mean": 0.28999611735343933,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 109,
      "phase": "train",
      "loss": 0.03276991471648216,
      "timestamp": 1759543898.9747727,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.03276991471648216,
      "ssim": 0.5930843353271484,
      "attention_bam_384_mean_attention": 0.19009090960025787,
      "attention_bam_384_std_attention": 0.49448174238204956,
      "attention_bam_384_max_attention": 5.146444320678711,
      "attention_bam_384_min_attention": -1.5702722072601318,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4240616503773253,
      "attention_bam_384_attention_skewness": 0.5098328018644469,
      "attention_bam_384_attention_sparsity": 0.444610595703125,
      "attention_bam_384_attention_concentration_10": 0.5899670230398949,
      "attention_bam_384_attention_concentration_20": 0.9536305332512486,
      "attention_bam_384_attention_center_y": 0.48620546395230035,
      "attention_bam_384_attention_center_x": 0.48699758649257013,
      "attention_bam_384_attention_center_distance": 0.026808654639480872,
      "attention_bam_384_attention_spatial_variance": 171.11578377741577,
      "attention_bam_384_attention_spatial_std": 13.081123184857475,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 17.80364091282905,
      "attention_bam_384_peak_intensity_mean": 0.26267266273498535,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22796989977359772,
      "attention_bam_16_std_attention": 0.5362153649330139,
      "attention_bam_16_max_attention": 2.032930374145508,
      "attention_bam_16_min_attention": -1.0602259635925293,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.2570828336331936,
      "attention_bam_16_attention_skewness": 0.2877856979315247,
      "attention_bam_16_attention_sparsity": 0.424072265625,
      "attention_bam_16_attention_concentration_10": 0.5398398214285912,
      "attention_bam_16_attention_concentration_20": 0.8876438094628832,
      "attention_bam_16_attention_center_y": 0.47841570657193977,
      "attention_bam_16_attention_center_x": 0.480108065329374,
      "attention_bam_16_attention_center_distance": 0.04151074048313416,
      "attention_bam_16_attention_spatial_variance": 42.68853921790083,
      "attention_bam_16_attention_spatial_std": 6.533646701337687,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.467630513654372,
      "attention_bam_16_peak_intensity_mean": 0.42748764157295227,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 110,
      "phase": "train",
      "loss": 0.031081557273864746,
      "timestamp": 1759543899.1468012,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.031081557273864746,
      "ssim": 0.6572989821434021,
      "attention_bam_384_mean_attention": 0.18384207785129547,
      "attention_bam_384_std_attention": 0.5571780204772949,
      "attention_bam_384_max_attention": 4.672264575958252,
      "attention_bam_384_min_attention": -1.5875005722045898,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6164219331085863,
      "attention_bam_384_attention_skewness": 0.5147923157685382,
      "attention_bam_384_attention_sparsity": 0.4648691813151042,
      "attention_bam_384_attention_concentration_10": 0.6689379476551465,
      "attention_bam_384_attention_concentration_20": 1.0861924279224593,
      "attention_bam_384_attention_center_y": 0.4806787529949179,
      "attention_bam_384_attention_center_x": 0.4850571761338793,
      "attention_bam_384_attention_center_distance": 0.03454268579382039,
      "attention_bam_384_attention_spatial_variance": 167.96533838705773,
      "attention_bam_384_attention_spatial_std": 12.96014422709322,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 16.050145355248095,
      "attention_bam_384_peak_intensity_mean": 0.2852725386619568,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22316396236419678,
      "attention_bam_16_std_attention": 0.6560134887695312,
      "attention_bam_16_max_attention": 3.2337381839752197,
      "attention_bam_16_min_attention": -1.298189640045166,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.374944855952406,
      "attention_bam_16_attention_skewness": 0.570412409240366,
      "attention_bam_16_attention_sparsity": 0.45263671875,
      "attention_bam_16_attention_concentration_10": 0.6655383713372719,
      "attention_bam_16_attention_concentration_20": 1.071057632457761,
      "attention_bam_16_attention_center_y": 0.46065650443025213,
      "attention_bam_16_attention_center_x": 0.47566983543245644,
      "attention_bam_16_attention_center_distance": 0.06541968436992832,
      "attention_bam_16_attention_spatial_variance": 39.73843997103557,
      "attention_bam_16_attention_spatial_std": 6.303843269866056,
      "attention_bam_16_num_attention_peaks": 2,
      "attention_bam_16_peak_separation_mean": 6.212414002948457,
      "attention_bam_16_peak_intensity_mean": 0.35980314016342163,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 111,
      "phase": "train",
      "loss": 0.03889867663383484,
      "timestamp": 1759543899.2765076,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.03889867663383484,
      "ssim": 0.6287326812744141,
      "attention_bam_384_mean_attention": 0.17825675010681152,
      "attention_bam_384_std_attention": 0.4976932108402252,
      "attention_bam_384_max_attention": 4.299455642700195,
      "attention_bam_384_min_attention": -1.5888274908065796,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9335370710256172,
      "attention_bam_384_attention_skewness": 0.45143468430584777,
      "attention_bam_384_attention_sparsity": 0.46050262451171875,
      "attention_bam_384_attention_concentration_10": 0.6181511590113916,
      "attention_bam_384_attention_concentration_20": 1.0078336318188263,
      "attention_bam_384_attention_center_y": 0.48053623606235546,
      "attention_bam_384_attention_center_x": 0.47984860343441305,
      "attention_bam_384_attention_center_distance": 0.03962112795375471,
      "attention_bam_384_attention_spatial_variance": 169.159497441661,
      "attention_bam_384_attention_spatial_std": 13.006133070273462,
      "attention_bam_384_num_attention_peaks": 19,
      "attention_bam_384_peak_separation_mean": 16.00368145134854,
      "attention_bam_384_peak_intensity_mean": 0.3030655086040497,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.225677028298378,
      "attention_bam_16_std_attention": 0.5634136199951172,
      "attention_bam_16_max_attention": 2.144028663635254,
      "attention_bam_16_min_attention": -1.065087914466858,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.5841703410821704,
      "attention_bam_16_attention_skewness": 0.20045913863677767,
      "attention_bam_16_attention_sparsity": 0.431884765625,
      "attention_bam_16_attention_concentration_10": 0.5417396146202628,
      "attention_bam_16_attention_concentration_20": 0.9180095859049319,
      "attention_bam_16_attention_center_y": 0.45627054730173494,
      "attention_bam_16_attention_center_x": 0.46141671698700815,
      "attention_bam_16_attention_center_distance": 0.08247344737975279,
      "attention_bam_16_attention_spatial_variance": 40.67862067165636,
      "attention_bam_16_attention_spatial_std": 6.377979356477752,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 7.959934367759885,
      "attention_bam_16_peak_intensity_mean": 0.4104294776916504,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 112,
      "phase": "train",
      "loss": 0.0379340834915638,
      "timestamp": 1759543899.4084063,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0379340834915638,
      "ssim": 0.5731933116912842,
      "attention_bam_384_mean_attention": 0.17743246257305145,
      "attention_bam_384_std_attention": 0.49174055457115173,
      "attention_bam_384_max_attention": 4.104841709136963,
      "attention_bam_384_min_attention": -1.6286256313323975,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5511923984144964,
      "attention_bam_384_attention_skewness": 0.378250966417706,
      "attention_bam_384_attention_sparsity": 0.4532623291015625,
      "attention_bam_384_attention_concentration_10": 0.613876282855413,
      "attention_bam_384_attention_concentration_20": 1.003819172746458,
      "attention_bam_384_attention_center_y": 0.49069745165856893,
      "attention_bam_384_attention_center_x": 0.4826465095223872,
      "attention_bam_384_attention_center_distance": 0.02784532411020782,
      "attention_bam_384_attention_spatial_variance": 170.82705540296485,
      "attention_bam_384_attention_spatial_std": 13.070082455859444,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 17.11947943282082,
      "attention_bam_384_peak_intensity_mean": 0.31903523206710815,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22194130718708038,
      "attention_bam_16_std_attention": 0.5574005246162415,
      "attention_bam_16_max_attention": 2.3259236812591553,
      "attention_bam_16_min_attention": -1.0436975955963135,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.5164691367351439,
      "attention_bam_16_attention_skewness": 0.2651453375932699,
      "attention_bam_16_attention_sparsity": 0.442626953125,
      "attention_bam_16_attention_concentration_10": 0.5539983976283185,
      "attention_bam_16_attention_concentration_20": 0.9323799842104776,
      "attention_bam_16_attention_center_y": 0.4924023819999626,
      "attention_bam_16_attention_center_x": 0.465096596344735,
      "attention_bam_16_attention_center_distance": 0.05051675733846856,
      "attention_bam_16_attention_spatial_variance": 42.58066678335719,
      "attention_bam_16_attention_spatial_std": 6.525386332115302,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.798623820269734,
      "attention_bam_16_peak_intensity_mean": 0.3940683603286743,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 113,
      "phase": "train",
      "loss": 0.02727271430194378,
      "timestamp": 1759543899.5396833,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.02727271430194378,
      "ssim": 0.6913403272628784,
      "attention_bam_384_mean_attention": 0.17593713104724884,
      "attention_bam_384_std_attention": 0.53399658203125,
      "attention_bam_384_max_attention": 4.571272850036621,
      "attention_bam_384_min_attention": -1.558364987373352,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1161224878834801,
      "attention_bam_384_attention_skewness": 0.5635326989493653,
      "attention_bam_384_attention_sparsity": 0.45847829182942706,
      "attention_bam_384_attention_concentration_10": 0.682011293695384,
      "attention_bam_384_attention_concentration_20": 1.0844271719933576,
      "attention_bam_384_attention_center_y": 0.488981504257043,
      "attention_bam_384_attention_center_x": 0.4848843610664682,
      "attention_bam_384_attention_center_distance": 0.026453347191100922,
      "attention_bam_384_attention_spatial_variance": 170.76470698161785,
      "attention_bam_384_attention_spatial_std": 13.067697080266969,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 16.739557891635734,
      "attention_bam_384_peak_intensity_mean": 0.2834506630897522,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22202590107917786,
      "attention_bam_16_std_attention": 0.6241893768310547,
      "attention_bam_16_max_attention": 2.6788604259490967,
      "attention_bam_16_min_attention": -1.1531126499176025,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.36982129181763135,
      "attention_bam_16_attention_skewness": 0.5382061897193354,
      "attention_bam_16_attention_sparsity": 0.4453125,
      "attention_bam_16_attention_concentration_10": 0.6426596919399832,
      "attention_bam_16_attention_concentration_20": 1.0280742710612778,
      "attention_bam_16_attention_center_y": 0.4884436216126561,
      "attention_bam_16_attention_center_x": 0.4740396529549351,
      "attention_bam_16_attention_center_distance": 0.040186801319131604,
      "attention_bam_16_attention_spatial_variance": 42.47813421400101,
      "attention_bam_16_attention_spatial_std": 6.517525160212349,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.125027363745154,
      "attention_bam_16_peak_intensity_mean": 0.36959972977638245,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 114,
      "phase": "train",
      "loss": 0.024297699332237244,
      "timestamp": 1759543899.669835,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.024297699332237244,
      "ssim": 0.6728736758232117,
      "attention_bam_384_mean_attention": 0.17577438056468964,
      "attention_bam_384_std_attention": 0.5290766358375549,
      "attention_bam_384_max_attention": 5.975139617919922,
      "attention_bam_384_min_attention": -1.6540099382400513,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.3856443382298194,
      "attention_bam_384_attention_skewness": 0.5461117134278024,
      "attention_bam_384_attention_sparsity": 0.46540069580078125,
      "attention_bam_384_attention_concentration_10": 0.6619831278665494,
      "attention_bam_384_attention_concentration_20": 1.0736261974942762,
      "attention_bam_384_attention_center_y": 0.48485216762925176,
      "attention_bam_384_attention_center_x": 0.48508558097420545,
      "attention_bam_384_attention_center_distance": 0.030063157532410675,
      "attention_bam_384_attention_spatial_variance": 172.00179530907675,
      "attention_bam_384_attention_spatial_std": 13.114945493942274,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 19.624766278363804,
      "attention_bam_384_peak_intensity_mean": 0.24132563173770905,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21697211265563965,
      "attention_bam_16_std_attention": 0.6085931658744812,
      "attention_bam_16_max_attention": 2.8856992721557617,
      "attention_bam_16_min_attention": -1.010050654411316,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.47312033453209956,
      "attention_bam_16_attention_skewness": 0.2901260039618466,
      "attention_bam_16_attention_sparsity": 0.44873046875,
      "attention_bam_16_attention_concentration_10": 0.605488095662971,
      "attention_bam_16_attention_concentration_20": 1.0140611556212107,
      "attention_bam_16_attention_center_y": 0.473439498662257,
      "attention_bam_16_attention_center_x": 0.4734722057047876,
      "attention_bam_16_attention_center_distance": 0.0530883057081567,
      "attention_bam_16_attention_spatial_variance": 43.61539342724379,
      "attention_bam_16_attention_spatial_std": 6.604195138489155,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.8246737842244,
      "attention_bam_16_peak_intensity_mean": 0.318141907453537,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 115,
      "phase": "train",
      "loss": 0.048028554767370224,
      "timestamp": 1759543899.800607,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.048028554767370224,
      "ssim": 0.6182036399841309,
      "attention_bam_384_mean_attention": 0.16855382919311523,
      "attention_bam_384_std_attention": 0.5186357498168945,
      "attention_bam_384_max_attention": 5.7777299880981445,
      "attention_bam_384_min_attention": -1.6341904401779175,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4808872402959787,
      "attention_bam_384_attention_skewness": 0.5603149097250635,
      "attention_bam_384_attention_sparsity": 0.4703165690104167,
      "attention_bam_384_attention_concentration_10": 0.6791175247464908,
      "attention_bam_384_attention_concentration_20": 1.0925874323044533,
      "attention_bam_384_attention_center_y": 0.48197926809942765,
      "attention_bam_384_attention_center_x": 0.4842880311691301,
      "attention_bam_384_attention_center_distance": 0.03381161761213246,
      "attention_bam_384_attention_spatial_variance": 170.14292101839928,
      "attention_bam_384_attention_spatial_std": 13.043884429816115,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 18.302494562542353,
      "attention_bam_384_peak_intensity_mean": 0.24397169053554535,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22136874496936798,
      "attention_bam_16_std_attention": 0.6021919846534729,
      "attention_bam_16_max_attention": 2.7839515209198,
      "attention_bam_16_min_attention": -1.0339429378509521,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.004009188236172356,
      "attention_bam_16_attention_skewness": 0.4767753129926453,
      "attention_bam_16_attention_sparsity": 0.4638671875,
      "attention_bam_16_attention_concentration_10": 0.6126475811913003,
      "attention_bam_16_attention_concentration_20": 1.0036263938464167,
      "attention_bam_16_attention_center_y": 0.4640623001285244,
      "attention_bam_16_attention_center_x": 0.47070933891014693,
      "attention_bam_16_attention_center_distance": 0.06556616656680318,
      "attention_bam_16_attention_spatial_variance": 41.36986912982938,
      "attention_bam_16_attention_spatial_std": 6.431941318904378,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.33431560394576,
      "attention_bam_16_peak_intensity_mean": 0.34148189425468445,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 116,
      "phase": "train",
      "loss": 0.031727712601423264,
      "timestamp": 1759543899.9332423,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.031727712601423264,
      "ssim": 0.5906537771224976,
      "attention_bam_384_mean_attention": 0.1800498366355896,
      "attention_bam_384_std_attention": 0.45751678943634033,
      "attention_bam_384_max_attention": 5.515199661254883,
      "attention_bam_384_min_attention": -1.5745933055877686,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.223838596428412,
      "attention_bam_384_attention_skewness": 0.5065799959981421,
      "attention_bam_384_attention_sparsity": 0.44294484456380206,
      "attention_bam_384_attention_concentration_10": 0.5693381467313167,
      "attention_bam_384_attention_concentration_20": 0.9287847714765679,
      "attention_bam_384_attention_center_y": 0.4865256288850431,
      "attention_bam_384_attention_center_x": 0.48238591431179584,
      "attention_bam_384_attention_center_distance": 0.031362866309538225,
      "attention_bam_384_attention_spatial_variance": 170.4690505738108,
      "attention_bam_384_attention_spatial_std": 13.05637968863539,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 18.597384482663145,
      "attention_bam_384_peak_intensity_mean": 0.2501307725906372,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21885471045970917,
      "attention_bam_16_std_attention": 0.49387454986572266,
      "attention_bam_16_max_attention": 2.2288129329681396,
      "attention_bam_16_min_attention": -1.052551031112671,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.42891236874414496,
      "attention_bam_16_attention_skewness": 0.09929581438502158,
      "attention_bam_16_attention_sparsity": 0.412353515625,
      "attention_bam_16_attention_concentration_10": 0.4977272898982142,
      "attention_bam_16_attention_concentration_20": 0.8447724603777285,
      "attention_bam_16_attention_center_y": 0.4774075833512968,
      "attention_bam_16_attention_center_x": 0.4673848583794725,
      "attention_bam_16_attention_center_distance": 0.056109976883895886,
      "attention_bam_16_attention_spatial_variance": 42.203565166807664,
      "attention_bam_16_attention_spatial_std": 6.496427107788378,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.67299487047313,
      "attention_bam_16_peak_intensity_mean": 0.39659520983695984,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 117,
      "phase": "train",
      "loss": 0.022669954225420952,
      "timestamp": 1759543900.0596504,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.022669954225420952,
      "ssim": 0.6759999990463257,
      "attention_bam_384_mean_attention": 0.17894601821899414,
      "attention_bam_384_std_attention": 0.5097276568412781,
      "attention_bam_384_max_attention": 5.790998458862305,
      "attention_bam_384_min_attention": -1.6380183696746826,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.1742411967693966,
      "attention_bam_384_attention_skewness": 0.6050191435723186,
      "attention_bam_384_attention_sparsity": 0.45660400390625,
      "attention_bam_384_attention_concentration_10": 0.6452634764897189,
      "attention_bam_384_attention_concentration_20": 1.0273545718672124,
      "attention_bam_384_attention_center_y": 0.4830275818882712,
      "attention_bam_384_attention_center_x": 0.480064613707692,
      "attention_bam_384_attention_center_distance": 0.03702654731899482,
      "attention_bam_384_attention_spatial_variance": 171.34197254328683,
      "attention_bam_384_attention_spatial_std": 13.089765946848967,
      "attention_bam_384_num_attention_peaks": 23,
      "attention_bam_384_peak_separation_mean": 19.561553578769715,
      "attention_bam_384_peak_intensity_mean": 0.24561376869678497,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21527454257011414,
      "attention_bam_16_std_attention": 0.5452346801757812,
      "attention_bam_16_max_attention": 2.3549535274505615,
      "attention_bam_16_min_attention": -1.0262737274169922,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.12670093212020106,
      "attention_bam_16_attention_skewness": 0.30269064282703984,
      "attention_bam_16_attention_sparsity": 0.433349609375,
      "attention_bam_16_attention_concentration_10": 0.5653526067592248,
      "attention_bam_16_attention_concentration_20": 0.9318257361543902,
      "attention_bam_16_attention_center_y": 0.46462821062919424,
      "attention_bam_16_attention_center_x": 0.4550562299028052,
      "attention_bam_16_attention_center_distance": 0.0808839409752288,
      "attention_bam_16_attention_spatial_variance": 42.28056448352924,
      "attention_bam_16_attention_spatial_std": 6.502350689060783,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.430534253949324,
      "attention_bam_16_peak_intensity_mean": 0.3709664046764374,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 118,
      "phase": "train",
      "loss": 0.03071744740009308,
      "timestamp": 1759543900.1887202,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.03071744740009308,
      "ssim": 0.5608291625976562,
      "attention_bam_384_mean_attention": 0.16809479892253876,
      "attention_bam_384_std_attention": 0.5389368534088135,
      "attention_bam_384_max_attention": 5.455548286437988,
      "attention_bam_384_min_attention": -1.6731858253479004,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4735756128639803,
      "attention_bam_384_attention_skewness": 0.6715418028606444,
      "attention_bam_384_attention_sparsity": 0.47968800862630206,
      "attention_bam_384_attention_concentration_10": 0.7197896858903504,
      "attention_bam_384_attention_concentration_20": 1.1424648318156752,
      "attention_bam_384_attention_center_y": 0.47706457083087006,
      "attention_bam_384_attention_center_x": 0.4863198420864751,
      "attention_bam_384_attention_center_distance": 0.037767198246922,
      "attention_bam_384_attention_spatial_variance": 171.6901864572804,
      "attention_bam_384_attention_spatial_std": 13.103060194369878,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 20.897557834959947,
      "attention_bam_384_peak_intensity_mean": 0.2615083158016205,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20570212602615356,
      "attention_bam_16_std_attention": 0.622373640537262,
      "attention_bam_16_max_attention": 3.0833187103271484,
      "attention_bam_16_min_attention": -1.144278883934021,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.22716071856090592,
      "attention_bam_16_attention_skewness": 0.5939565551851648,
      "attention_bam_16_attention_sparsity": 0.47705078125,
      "attention_bam_16_attention_concentration_10": 0.6866885398206412,
      "attention_bam_16_attention_concentration_20": 1.1096793813103405,
      "attention_bam_16_attention_center_y": 0.4500948536145512,
      "attention_bam_16_attention_center_x": 0.47843570131470164,
      "attention_bam_16_attention_center_distance": 0.07688358229871749,
      "attention_bam_16_attention_spatial_variance": 43.140212675527806,
      "attention_bam_16_attention_spatial_std": 6.568120939471791,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 10.71579397026724,
      "attention_bam_16_peak_intensity_mean": 0.3278782069683075,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 119,
      "phase": "train",
      "loss": 0.02589377388358116,
      "timestamp": 1759543900.3175828,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.02589377388358116,
      "ssim": 0.7131959795951843,
      "attention_bam_384_mean_attention": 0.16867470741271973,
      "attention_bam_384_std_attention": 0.528401255607605,
      "attention_bam_384_max_attention": 6.39737606048584,
      "attention_bam_384_min_attention": -1.7483779191970825,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.000577077611978,
      "attention_bam_384_attention_skewness": 0.8402488593430444,
      "attention_bam_384_attention_sparsity": 0.4688873291015625,
      "attention_bam_384_attention_concentration_10": 0.7130184355679873,
      "attention_bam_384_attention_concentration_20": 1.113846158557591,
      "attention_bam_384_attention_center_y": 0.4780244896190598,
      "attention_bam_384_attention_center_x": 0.4903239761732107,
      "attention_bam_384_attention_center_distance": 0.033957281799325584,
      "attention_bam_384_attention_spatial_variance": 170.7887294799435,
      "attention_bam_384_attention_spatial_std": 13.068616203712752,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 15.025754173541731,
      "attention_bam_384_peak_intensity_mean": 0.23471741378307343,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20264539122581482,
      "attention_bam_16_std_attention": 0.6239097714424133,
      "attention_bam_16_max_attention": 3.048466444015503,
      "attention_bam_16_min_attention": -1.07327139377594,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5862994876218757,
      "attention_bam_16_attention_skewness": 0.6842228296550895,
      "attention_bam_16_attention_sparsity": 0.465576171875,
      "attention_bam_16_attention_concentration_10": 0.7091516167435514,
      "attention_bam_16_attention_concentration_20": 1.1184855663780942,
      "attention_bam_16_attention_center_y": 0.4483325270656393,
      "attention_bam_16_attention_center_x": 0.4910365557716895,
      "attention_bam_16_attention_center_distance": 0.07416024665353976,
      "attention_bam_16_attention_spatial_variance": 42.466432555754196,
      "attention_bam_16_attention_spatial_std": 6.516627391201234,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.942100726285398,
      "attention_bam_16_peak_intensity_mean": 0.32378536462783813,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 120,
      "phase": "train",
      "loss": 0.025796299800276756,
      "timestamp": 1759543900.493592,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.025796299800276756,
      "ssim": 0.6535546183586121,
      "attention_bam_384_mean_attention": 0.17599086463451385,
      "attention_bam_384_std_attention": 0.46500614285469055,
      "attention_bam_384_max_attention": 4.874183177947998,
      "attention_bam_384_min_attention": -1.6323423385620117,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.7103965036080462,
      "attention_bam_384_attention_skewness": 0.4788040357913535,
      "attention_bam_384_attention_sparsity": 0.45148468017578125,
      "attention_bam_384_attention_concentration_10": 0.5877795100649305,
      "attention_bam_384_attention_concentration_20": 0.960102552407822,
      "attention_bam_384_attention_center_y": 0.4844358582118263,
      "attention_bam_384_attention_center_x": 0.48069067637242463,
      "attention_bam_384_attention_center_distance": 0.035073992888087775,
      "attention_bam_384_attention_spatial_variance": 169.83136211894134,
      "attention_bam_384_attention_spatial_std": 13.03193623829327,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 16.19390714004558,
      "attention_bam_384_peak_intensity_mean": 0.27859124541282654,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21654972434043884,
      "attention_bam_16_std_attention": 0.5239937901496887,
      "attention_bam_16_max_attention": 2.921572208404541,
      "attention_bam_16_min_attention": -1.0629454851150513,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.38964123030500053,
      "attention_bam_16_attention_skewness": 0.17421183008837066,
      "attention_bam_16_attention_sparsity": 0.4267578125,
      "attention_bam_16_attention_concentration_10": 0.5216426309528192,
      "attention_bam_16_attention_concentration_20": 0.8880709773629017,
      "attention_bam_16_attention_center_y": 0.46985761381282487,
      "attention_bam_16_attention_center_x": 0.45965063442464643,
      "attention_bam_16_attention_center_distance": 0.07122688744273939,
      "attention_bam_16_attention_spatial_variance": 41.79029092380436,
      "attention_bam_16_attention_spatial_std": 6.464541045101683,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 7.786178166197044,
      "attention_bam_16_peak_intensity_mean": 0.32411137223243713,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 121,
      "phase": "train",
      "loss": 0.02241542562842369,
      "timestamp": 1759543900.6310825,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.02241542562842369,
      "ssim": 0.6462014317512512,
      "attention_bam_384_mean_attention": 0.17460709810256958,
      "attention_bam_384_std_attention": 0.49526554346084595,
      "attention_bam_384_max_attention": 4.235883712768555,
      "attention_bam_384_min_attention": -1.5997896194458008,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9800320751039147,
      "attention_bam_384_attention_skewness": 0.5290106234212018,
      "attention_bam_384_attention_sparsity": 0.4679005940755208,
      "attention_bam_384_attention_concentration_10": 0.6400198196161382,
      "attention_bam_384_attention_concentration_20": 1.0320282859079979,
      "attention_bam_384_attention_center_y": 0.48487637663635175,
      "attention_bam_384_attention_center_x": 0.483100322578964,
      "attention_bam_384_attention_center_distance": 0.032072514107271376,
      "attention_bam_384_attention_spatial_variance": 169.13141793465897,
      "attention_bam_384_attention_spatial_std": 13.005053553702075,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 15.394956980399252,
      "attention_bam_384_peak_intensity_mean": 0.3052161633968353,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21795111894607544,
      "attention_bam_16_std_attention": 0.5674583911895752,
      "attention_bam_16_max_attention": 2.5646204948425293,
      "attention_bam_16_min_attention": -1.0836604833602905,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.09256423855684126,
      "attention_bam_16_attention_skewness": 0.4737276018401867,
      "attention_bam_16_attention_sparsity": 0.458251953125,
      "attention_bam_16_attention_concentration_10": 0.6005290278121864,
      "attention_bam_16_attention_concentration_20": 0.979046524737482,
      "attention_bam_16_attention_center_y": 0.4694460338283625,
      "attention_bam_16_attention_center_x": 0.4719101837375606,
      "attention_bam_16_attention_center_distance": 0.05869553009344365,
      "attention_bam_16_attention_spatial_variance": 40.749869501976484,
      "attention_bam_16_attention_spatial_std": 6.3835624459996065,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.402190452749004,
      "attention_bam_16_peak_intensity_mean": 0.3615896999835968,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 122,
      "phase": "train",
      "loss": 0.019418619573116302,
      "timestamp": 1759543900.7638924,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.019418619573116302,
      "ssim": 0.7167020440101624,
      "attention_bam_384_mean_attention": 0.1716325879096985,
      "attention_bam_384_std_attention": 0.5147639513015747,
      "attention_bam_384_max_attention": 4.834719181060791,
      "attention_bam_384_min_attention": -1.5424422025680542,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0747210118736898,
      "attention_bam_384_attention_skewness": 0.5559789703700625,
      "attention_bam_384_attention_sparsity": 0.4704081217447917,
      "attention_bam_384_attention_concentration_10": 0.6704718187111637,
      "attention_bam_384_attention_concentration_20": 1.079004800689215,
      "attention_bam_384_attention_center_y": 0.4768736784882251,
      "attention_bam_384_attention_center_x": 0.4870419739793779,
      "attention_bam_384_attention_center_distance": 0.03748965684071015,
      "attention_bam_384_attention_spatial_variance": 170.61098228900605,
      "attention_bam_384_attention_spatial_std": 13.061813897350017,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 19.470988193802242,
      "attention_bam_384_peak_intensity_mean": 0.27050790190696716,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20803582668304443,
      "attention_bam_16_std_attention": 0.6000232696533203,
      "attention_bam_16_max_attention": 2.343005895614624,
      "attention_bam_16_min_attention": -1.1201168298721313,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.23315507097003518,
      "attention_bam_16_attention_skewness": 0.4421241935148825,
      "attention_bam_16_attention_sparsity": 0.458251953125,
      "attention_bam_16_attention_concentration_10": 0.6411735709163775,
      "attention_bam_16_attention_concentration_20": 1.0584513426088489,
      "attention_bam_16_attention_center_y": 0.4512581622104187,
      "attention_bam_16_attention_center_x": 0.4766029493563867,
      "attention_bam_16_attention_center_distance": 0.07646160775089235,
      "attention_bam_16_attention_spatial_variance": 42.24383071067269,
      "attention_bam_16_attention_spatial_std": 6.499525421957567,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 12.077154643507741,
      "attention_bam_16_peak_intensity_mean": 0.38029980659484863,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 123,
      "phase": "train",
      "loss": 0.024330593645572662,
      "timestamp": 1759543900.8927572,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.024330593645572662,
      "ssim": 0.7324366569519043,
      "attention_bam_384_mean_attention": 0.16998596489429474,
      "attention_bam_384_std_attention": 0.540945827960968,
      "attention_bam_384_max_attention": 4.883136749267578,
      "attention_bam_384_min_attention": -1.5786315202713013,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.660317469418116,
      "attention_bam_384_attention_skewness": 0.5251126364727703,
      "attention_bam_384_attention_sparsity": 0.48167165120442706,
      "attention_bam_384_attention_concentration_10": 0.6946256951818304,
      "attention_bam_384_attention_concentration_20": 1.1363359566994424,
      "attention_bam_384_attention_center_y": 0.4802995970371031,
      "attention_bam_384_attention_center_x": 0.48954815344810465,
      "attention_bam_384_attention_center_distance": 0.03153876894378989,
      "attention_bam_384_attention_spatial_variance": 170.3496860142849,
      "attention_bam_384_attention_spatial_std": 13.051807768055923,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 15.984029210198969,
      "attention_bam_384_peak_intensity_mean": 0.2700428366661072,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20066632330417633,
      "attention_bam_16_std_attention": 0.6175705194473267,
      "attention_bam_16_max_attention": 2.8101654052734375,
      "attention_bam_16_min_attention": -1.0679931640625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.42335222931631256,
      "attention_bam_16_attention_skewness": 0.4858445129383722,
      "attention_bam_16_attention_sparsity": 0.48876953125,
      "attention_bam_16_attention_concentration_10": 0.6808705669227106,
      "attention_bam_16_attention_concentration_20": 1.1304667459955438,
      "attention_bam_16_attention_center_y": 0.46117245037597443,
      "attention_bam_16_attention_center_x": 0.49077146338015504,
      "attention_bam_16_attention_center_distance": 0.05644013639157842,
      "attention_bam_16_attention_spatial_variance": 42.258271714449485,
      "attention_bam_16_attention_spatial_std": 6.500636254586891,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 7.51373086203799,
      "attention_bam_16_peak_intensity_mean": 0.32656803727149963,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 124,
      "phase": "train",
      "loss": 0.017485812306404114,
      "timestamp": 1759543901.0239432,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.017485812306404114,
      "ssim": 0.7318340539932251,
      "attention_bam_384_mean_attention": 0.173378586769104,
      "attention_bam_384_std_attention": 0.5105518698692322,
      "attention_bam_384_max_attention": 4.586516380310059,
      "attention_bam_384_min_attention": -1.5621697902679443,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8374658604781309,
      "attention_bam_384_attention_skewness": 0.5165451769958664,
      "attention_bam_384_attention_sparsity": 0.4682464599609375,
      "attention_bam_384_attention_concentration_10": 0.6576099848390646,
      "attention_bam_384_attention_concentration_20": 1.0649431669077316,
      "attention_bam_384_attention_center_y": 0.4854217855558531,
      "attention_bam_384_attention_center_x": 0.48163496788761007,
      "attention_bam_384_attention_center_distance": 0.03316017915719537,
      "attention_bam_384_attention_spatial_variance": 169.37056484427143,
      "attention_bam_384_attention_spatial_std": 13.014244689734069,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 15.933953398851175,
      "attention_bam_384_peak_intensity_mean": 0.28262385725975037,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22395586967468262,
      "attention_bam_16_std_attention": 0.5879549980163574,
      "attention_bam_16_max_attention": 2.549246311187744,
      "attention_bam_16_min_attention": -1.0871466398239136,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.0036190960950901463,
      "attention_bam_16_attention_skewness": 0.49597147976407346,
      "attention_bam_16_attention_sparsity": 0.451904296875,
      "attention_bam_16_attention_concentration_10": 0.6033112113878185,
      "attention_bam_16_attention_concentration_20": 0.9841544160201187,
      "attention_bam_16_attention_center_y": 0.47912161220072536,
      "attention_bam_16_attention_center_x": 0.4600607101737571,
      "attention_bam_16_attention_center_distance": 0.06373466794330272,
      "attention_bam_16_attention_spatial_variance": 41.0364261959129,
      "attention_bam_16_attention_spatial_std": 6.405968013962675,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.028630700664078,
      "attention_bam_16_peak_intensity_mean": 0.366681843996048,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 125,
      "phase": "train",
      "loss": 0.01995094306766987,
      "timestamp": 1759543901.151899,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.01995094306766987,
      "ssim": 0.7043875455856323,
      "attention_bam_384_mean_attention": 0.17914138734340668,
      "attention_bam_384_std_attention": 0.49647241830825806,
      "attention_bam_384_max_attention": 5.013365268707275,
      "attention_bam_384_min_attention": -1.527954339981079,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1973781284669682,
      "attention_bam_384_attention_skewness": 0.5412181033207161,
      "attention_bam_384_attention_sparsity": 0.45967356363932294,
      "attention_bam_384_attention_concentration_10": 0.6246056526930186,
      "attention_bam_384_attention_concentration_20": 1.0079577609045824,
      "attention_bam_384_attention_center_y": 0.4821886552027991,
      "attention_bam_384_attention_center_x": 0.4848514889206125,
      "attention_bam_384_attention_center_distance": 0.03306724637483753,
      "attention_bam_384_attention_spatial_variance": 169.65279115083175,
      "attention_bam_384_attention_spatial_std": 13.025083153317361,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 17.80562660398955,
      "attention_bam_384_peak_intensity_mean": 0.2627931237220764,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22063475847244263,
      "attention_bam_16_std_attention": 0.5696463584899902,
      "attention_bam_16_max_attention": 2.395390510559082,
      "attention_bam_16_min_attention": -1.1029698848724365,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.20242394687624898,
      "attention_bam_16_attention_skewness": 0.3998486569397448,
      "attention_bam_16_attention_sparsity": 0.445068359375,
      "attention_bam_16_attention_concentration_10": 0.5822913618964122,
      "attention_bam_16_attention_concentration_20": 0.9624576234678273,
      "attention_bam_16_attention_center_y": 0.4633446570273902,
      "attention_bam_16_attention_center_x": 0.4721037447918329,
      "attention_bam_16_attention_center_distance": 0.06514315348643851,
      "attention_bam_16_attention_spatial_variance": 41.07090807368266,
      "attention_bam_16_attention_spatial_std": 6.408658835800409,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 9.163667062234301,
      "attention_bam_16_peak_intensity_mean": 0.3879789113998413,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 126,
      "phase": "train",
      "loss": 0.018539804965257645,
      "timestamp": 1759543901.2794988,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.018539804965257645,
      "ssim": 0.7202233076095581,
      "attention_bam_384_mean_attention": 0.17672890424728394,
      "attention_bam_384_std_attention": 0.5174628496170044,
      "attention_bam_384_max_attention": 4.916935920715332,
      "attention_bam_384_min_attention": -1.561211347579956,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5877553784813792,
      "attention_bam_384_attention_skewness": 0.6389929167741264,
      "attention_bam_384_attention_sparsity": 0.46650441487630206,
      "attention_bam_384_attention_concentration_10": 0.6648470043529962,
      "attention_bam_384_attention_concentration_20": 1.0601051797642942,
      "attention_bam_384_attention_center_y": 0.486798031932349,
      "attention_bam_384_attention_center_x": 0.48760689954223224,
      "attention_bam_384_attention_center_distance": 0.025607846446571807,
      "attention_bam_384_attention_spatial_variance": 170.19116118920158,
      "attention_bam_384_attention_spatial_std": 13.045733447729246,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 19.22010953266855,
      "attention_bam_384_peak_intensity_mean": 0.26887139678001404,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20778867602348328,
      "attention_bam_16_std_attention": 0.5884791016578674,
      "attention_bam_16_max_attention": 2.5294599533081055,
      "attention_bam_16_min_attention": -1.0384167432785034,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.1472745215777107,
      "attention_bam_16_attention_skewness": 0.5262923937894897,
      "attention_bam_16_attention_sparsity": 0.46240234375,
      "attention_bam_16_attention_concentration_10": 0.6463559511936783,
      "attention_bam_16_attention_concentration_20": 1.0476986491001479,
      "attention_bam_16_attention_center_y": 0.48006307360496364,
      "attention_bam_16_attention_center_x": 0.4819459935850249,
      "attention_bam_16_attention_center_distance": 0.038037565161641466,
      "attention_bam_16_attention_spatial_variance": 41.63121164305742,
      "attention_bam_16_attention_spatial_std": 6.452225324882681,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.233426076846191,
      "attention_bam_16_peak_intensity_mean": 0.3513451814651489,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 127,
      "phase": "train",
      "loss": 0.014162315055727959,
      "timestamp": 1759543901.408587,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.014162315055727959,
      "ssim": 0.7406516075134277,
      "attention_bam_384_mean_attention": 0.1648077815771103,
      "attention_bam_384_std_attention": 0.5320079326629639,
      "attention_bam_384_max_attention": 4.604140758514404,
      "attention_bam_384_min_attention": -1.6643249988555908,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.037006662768797,
      "attention_bam_384_attention_skewness": 0.6200895270613345,
      "attention_bam_384_attention_sparsity": 0.48344167073567706,
      "attention_bam_384_attention_concentration_10": 0.7300757910110776,
      "attention_bam_384_attention_concentration_20": 1.1552612058736402,
      "attention_bam_384_attention_center_y": 0.48855528562662487,
      "attention_bam_384_attention_center_x": 0.4892143907895324,
      "attention_bam_384_attention_center_distance": 0.022240092316762678,
      "attention_bam_384_attention_spatial_variance": 172.68219058917146,
      "attention_bam_384_attention_spatial_std": 13.14085958334429,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 19.875618911916487,
      "attention_bam_384_peak_intensity_mean": 0.29446154832839966,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20163089036941528,
      "attention_bam_16_std_attention": 0.621902585029602,
      "attention_bam_16_max_attention": 2.9695498943328857,
      "attention_bam_16_min_attention": -1.087627649307251,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.30684079685907006,
      "attention_bam_16_attention_skewness": 0.6662232952665799,
      "attention_bam_16_attention_sparsity": 0.485107421875,
      "attention_bam_16_attention_concentration_10": 0.7109595439201725,
      "attention_bam_16_attention_concentration_20": 1.1348287885212176,
      "attention_bam_16_attention_center_y": 0.4855380688574572,
      "attention_bam_16_attention_center_x": 0.48624984697287993,
      "attention_bam_16_attention_center_distance": 0.02822106166113771,
      "attention_bam_16_attention_spatial_variance": 44.24127984094668,
      "attention_bam_16_attention_spatial_std": 6.651411868238704,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 11.337821214258978,
      "attention_bam_16_peak_intensity_mean": 0.3330634534358978,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 128,
      "phase": "train",
      "loss": 0.018513698130846024,
      "timestamp": 1759543901.5381358,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.018513698130846024,
      "ssim": 0.6634955406188965,
      "attention_bam_384_mean_attention": 0.16814835369586945,
      "attention_bam_384_std_attention": 0.4861285388469696,
      "attention_bam_384_max_attention": 5.623443603515625,
      "attention_bam_384_min_attention": -1.61465322971344,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.142513724491965,
      "attention_bam_384_attention_skewness": 0.7186819247116323,
      "attention_bam_384_attention_sparsity": 0.4703623453776042,
      "attention_bam_384_attention_concentration_10": 0.654452863130373,
      "attention_bam_384_attention_concentration_20": 1.0398192925970497,
      "attention_bam_384_attention_center_y": 0.47952825362609586,
      "attention_bam_384_attention_center_x": 0.48685917960777575,
      "attention_bam_384_attention_center_distance": 0.03440271966511235,
      "attention_bam_384_attention_spatial_variance": 171.35558291555517,
      "attention_bam_384_attention_spatial_std": 13.090285822530964,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 18.343925199456606,
      "attention_bam_384_peak_intensity_mean": 0.24847900867462158,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21199651062488556,
      "attention_bam_16_std_attention": 0.5665954351425171,
      "attention_bam_16_max_attention": 2.9916391372680664,
      "attention_bam_16_min_attention": -1.0100030899047852,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.34730784633604417,
      "attention_bam_16_attention_skewness": 0.5651978504375765,
      "attention_bam_16_attention_sparsity": 0.45263671875,
      "attention_bam_16_attention_concentration_10": 0.6144291302744447,
      "attention_bam_16_attention_concentration_20": 0.9939239515041568,
      "attention_bam_16_attention_center_y": 0.45433722514265207,
      "attention_bam_16_attention_center_x": 0.48024232995182214,
      "attention_bam_16_attention_center_distance": 0.07036269655727401,
      "attention_bam_16_attention_spatial_variance": 42.39829116515071,
      "attention_bam_16_attention_spatial_std": 6.51139702100484,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.354866126279436,
      "attention_bam_16_peak_intensity_mean": 0.3199376165866852,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 129,
      "phase": "train",
      "loss": 0.01840660721063614,
      "timestamp": 1759543901.6694086,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.01840660721063614,
      "ssim": 0.6864922642707825,
      "attention_bam_384_mean_attention": 0.17540878057479858,
      "attention_bam_384_std_attention": 0.5120491981506348,
      "attention_bam_384_max_attention": 4.2582221031188965,
      "attention_bam_384_min_attention": -1.4730939865112305,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.50824791569543,
      "attention_bam_384_attention_skewness": 0.4650800822200246,
      "attention_bam_384_attention_sparsity": 0.468475341796875,
      "attention_bam_384_attention_concentration_10": 0.6479761883320937,
      "attention_bam_384_attention_concentration_20": 1.0540816547286251,
      "attention_bam_384_attention_center_y": 0.4878642384567063,
      "attention_bam_384_attention_center_x": 0.48694140227949806,
      "attention_bam_384_attention_center_distance": 0.025211254735200507,
      "attention_bam_384_attention_spatial_variance": 169.71610197184427,
      "attention_bam_384_attention_spatial_std": 13.027513268918373,
      "attention_bam_384_num_attention_peaks": 21,
      "attention_bam_384_peak_separation_mean": 14.046534579935297,
      "attention_bam_384_peak_intensity_mean": 0.2903495728969574,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21040940284729004,
      "attention_bam_16_std_attention": 0.5870165228843689,
      "attention_bam_16_max_attention": 2.3512377738952637,
      "attention_bam_16_min_attention": -1.0432227849960327,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.35106736394178517,
      "attention_bam_16_attention_skewness": 0.37047829870929166,
      "attention_bam_16_attention_sparsity": 0.456787109375,
      "attention_bam_16_attention_concentration_10": 0.6128608412646547,
      "attention_bam_16_attention_concentration_20": 1.0205090020402348,
      "attention_bam_16_attention_center_y": 0.4824658229542182,
      "attention_bam_16_attention_center_x": 0.4797520815189044,
      "attention_bam_16_attention_center_distance": 0.0378794289157034,
      "attention_bam_16_attention_spatial_variance": 41.17090589087629,
      "attention_bam_16_attention_spatial_std": 6.416455866822142,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 6.9001158512709075,
      "attention_bam_16_peak_intensity_mean": 0.38272011280059814,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 130,
      "phase": "train",
      "loss": 0.021225741133093834,
      "timestamp": 1759543901.8379874,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.021225741133093834,
      "ssim": 0.7209907174110413,
      "attention_bam_384_mean_attention": 0.17021216452121735,
      "attention_bam_384_std_attention": 0.5103753209114075,
      "attention_bam_384_max_attention": 5.4800639152526855,
      "attention_bam_384_min_attention": -1.641516923904419,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.261372742338488,
      "attention_bam_384_attention_skewness": 0.8305122222594596,
      "attention_bam_384_attention_sparsity": 0.4750874837239583,
      "attention_bam_384_attention_concentration_10": 0.6883597976854273,
      "attention_bam_384_attention_concentration_20": 1.078069381802859,
      "attention_bam_384_attention_center_y": 0.47497786955325305,
      "attention_bam_384_attention_center_x": 0.4812512828875508,
      "attention_bam_384_attention_center_distance": 0.04421812762785565,
      "attention_bam_384_attention_spatial_variance": 171.42344272501757,
      "attention_bam_384_attention_spatial_std": 13.092877557092542,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 15.621688091910595,
      "attention_bam_384_peak_intensity_mean": 0.2580510675907135,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2017698436975479,
      "attention_bam_16_std_attention": 0.606592059135437,
      "attention_bam_16_max_attention": 3.5698342323303223,
      "attention_bam_16_min_attention": -1.127834677696228,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.929906030384327,
      "attention_bam_16_attention_skewness": 0.9112985557340706,
      "attention_bam_16_attention_sparsity": 0.4677734375,
      "attention_bam_16_attention_concentration_10": 0.6890828987966955,
      "attention_bam_16_attention_concentration_20": 1.0874566717825487,
      "attention_bam_16_attention_center_y": 0.44013998147358985,
      "attention_bam_16_attention_center_x": 0.45843553743117105,
      "attention_bam_16_attention_center_distance": 0.10306140273271802,
      "attention_bam_16_attention_spatial_variance": 42.377808401546105,
      "attention_bam_16_attention_spatial_std": 6.509823991595019,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.632346632500907,
      "attention_bam_16_peak_intensity_mean": 0.29443666338920593,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 131,
      "phase": "train",
      "loss": 0.01853237859904766,
      "timestamp": 1759543901.9672608,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.01853237859904766,
      "ssim": 0.7185113430023193,
      "attention_bam_384_mean_attention": 0.16962824761867523,
      "attention_bam_384_std_attention": 0.5382463932037354,
      "attention_bam_384_max_attention": 5.248068809509277,
      "attention_bam_384_min_attention": -1.6215767860412598,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0684017799315244,
      "attention_bam_384_attention_skewness": 0.6254146678674296,
      "attention_bam_384_attention_sparsity": 0.4772084554036458,
      "attention_bam_384_attention_concentration_10": 0.717326532569848,
      "attention_bam_384_attention_concentration_20": 1.1358955237077646,
      "attention_bam_384_attention_center_y": 0.48725613406190016,
      "attention_bam_384_attention_center_x": 0.48164888320338134,
      "attention_bam_384_attention_center_distance": 0.0315965063490064,
      "attention_bam_384_attention_spatial_variance": 170.4770171332228,
      "attention_bam_384_attention_spatial_std": 13.056684768088061,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 17.951228465353374,
      "attention_bam_384_peak_intensity_mean": 0.26291242241859436,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2106776237487793,
      "attention_bam_16_std_attention": 0.6438029408454895,
      "attention_bam_16_max_attention": 2.7863481044769287,
      "attention_bam_16_min_attention": -1.1000534296035767,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.29222100271006957,
      "attention_bam_16_attention_skewness": 0.6573341179896903,
      "attention_bam_16_attention_sparsity": 0.482421875,
      "attention_bam_16_attention_concentration_10": 0.7057683450078118,
      "attention_bam_16_attention_concentration_20": 1.1301564059458507,
      "attention_bam_16_attention_center_y": 0.48290910389466063,
      "attention_bam_16_attention_center_x": 0.4637911588302714,
      "attention_bam_16_attention_center_distance": 0.05662471030456823,
      "attention_bam_16_attention_spatial_variance": 42.02101176661602,
      "attention_bam_16_attention_spatial_std": 6.482361588697133,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.456765346018267,
      "attention_bam_16_peak_intensity_mean": 0.3361654579639435,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 132,
      "phase": "train",
      "loss": 0.011951364576816559,
      "timestamp": 1759543902.0960147,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.011951364576816559,
      "ssim": 0.7076120972633362,
      "attention_bam_384_mean_attention": 0.17008012533187866,
      "attention_bam_384_std_attention": 0.4571542739868164,
      "attention_bam_384_max_attention": 4.223622798919678,
      "attention_bam_384_min_attention": -1.4340062141418457,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.099637034034746,
      "attention_bam_384_attention_skewness": 0.5665289048675773,
      "attention_bam_384_attention_sparsity": 0.4675750732421875,
      "attention_bam_384_attention_concentration_10": 0.6124198096516157,
      "attention_bam_384_attention_concentration_20": 0.9887239085309009,
      "attention_bam_384_attention_center_y": 0.48834334114308026,
      "attention_bam_384_attention_center_x": 0.4910823764269972,
      "attention_bam_384_attention_center_distance": 0.02075580429163759,
      "attention_bam_384_attention_spatial_variance": 171.01568933344862,
      "attention_bam_384_attention_spatial_std": 13.077296713520292,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 17.423870036474753,
      "attention_bam_384_peak_intensity_mean": 0.2867366075515747,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20149016380310059,
      "attention_bam_16_std_attention": 0.5522218346595764,
      "attention_bam_16_max_attention": 2.5762434005737305,
      "attention_bam_16_min_attention": -0.9512450695037842,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.04590184735197633,
      "attention_bam_16_attention_skewness": 0.566206086645007,
      "attention_bam_16_attention_sparsity": 0.473388671875,
      "attention_bam_16_attention_concentration_10": 0.6314387991560092,
      "attention_bam_16_attention_concentration_20": 1.0280824796854762,
      "attention_bam_16_attention_center_y": 0.4805878142109923,
      "attention_bam_16_attention_center_x": 0.4934033398722606,
      "attention_bam_16_attention_center_distance": 0.02899478856442516,
      "attention_bam_16_attention_spatial_variance": 42.41362175372032,
      "attention_bam_16_attention_spatial_std": 6.512574126543231,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.969304773043332,
      "attention_bam_16_peak_intensity_mean": 0.3347676396369934,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 133,
      "phase": "train",
      "loss": 0.013379557989537716,
      "timestamp": 1759543902.227619,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.013379557989537716,
      "ssim": 0.7462832927703857,
      "attention_bam_384_mean_attention": 0.16837656497955322,
      "attention_bam_384_std_attention": 0.5282300114631653,
      "attention_bam_384_max_attention": 3.731142044067383,
      "attention_bam_384_min_attention": -1.567223310470581,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.386642189233509,
      "attention_bam_384_attention_skewness": 0.7412799320719033,
      "attention_bam_384_attention_sparsity": 0.47735341389973956,
      "attention_bam_384_attention_concentration_10": 0.7231421400478218,
      "attention_bam_384_attention_concentration_20": 1.122585304206366,
      "attention_bam_384_attention_center_y": 0.4853097866792319,
      "attention_bam_384_attention_center_x": 0.4858236326822357,
      "attention_bam_384_attention_center_distance": 0.02887115369145637,
      "attention_bam_384_attention_spatial_variance": 172.7432059930609,
      "attention_bam_384_attention_spatial_std": 13.143180969349121,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 18.557839457097195,
      "attention_bam_384_peak_intensity_mean": 0.3288409113883972,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.203912153840065,
      "attention_bam_16_std_attention": 0.6502395868301392,
      "attention_bam_16_max_attention": 2.872403860092163,
      "attention_bam_16_min_attention": -1.2450761795043945,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5272584291993727,
      "attention_bam_16_attention_skewness": 0.7562492472664494,
      "attention_bam_16_attention_sparsity": 0.477783203125,
      "attention_bam_16_attention_concentration_10": 0.7376564683867682,
      "attention_bam_16_attention_concentration_20": 1.1612718884616084,
      "attention_bam_16_attention_center_y": 0.4712742905995633,
      "attention_bam_16_attention_center_x": 0.4739145660915613,
      "attention_bam_16_attention_center_distance": 0.05487469804472481,
      "attention_bam_16_attention_spatial_variance": 43.70649784456314,
      "attention_bam_16_attention_spatial_std": 6.611089005947744,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.39566243723903,
      "attention_bam_16_peak_intensity_mean": 0.3580973148345947,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 134,
      "phase": "train",
      "loss": 0.018046334385871887,
      "timestamp": 1759543902.3583891,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.018046334385871887,
      "ssim": 0.7374681234359741,
      "attention_bam_384_mean_attention": 0.172984316945076,
      "attention_bam_384_std_attention": 0.5276946425437927,
      "attention_bam_384_max_attention": 4.426222324371338,
      "attention_bam_384_min_attention": -1.6479204893112183,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.9942235885081105,
      "attention_bam_384_attention_skewness": 0.8531055426686622,
      "attention_bam_384_attention_sparsity": 0.47632090250651044,
      "attention_bam_384_attention_concentration_10": 0.7129115246778803,
      "attention_bam_384_attention_concentration_20": 1.0991037129821717,
      "attention_bam_384_attention_center_y": 0.4780234554573079,
      "attention_bam_384_attention_center_x": 0.47824986009039766,
      "attention_bam_384_attention_center_distance": 0.043727270578534996,
      "attention_bam_384_attention_spatial_variance": 170.45135589814518,
      "attention_bam_384_attention_spatial_std": 13.055702045395536,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 17.666190956691384,
      "attention_bam_384_peak_intensity_mean": 0.30244866013526917,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21044056117534637,
      "attention_bam_16_std_attention": 0.6091065406799316,
      "attention_bam_16_max_attention": 3.0246448516845703,
      "attention_bam_16_min_attention": -1.0840545892715454,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.123123595737959,
      "attention_bam_16_attention_skewness": 0.8332467617434811,
      "attention_bam_16_attention_sparsity": 0.462646484375,
      "attention_bam_16_attention_concentration_10": 0.6827374643103583,
      "attention_bam_16_attention_concentration_20": 1.0614114698433985,
      "attention_bam_16_attention_center_y": 0.45055886323805017,
      "attention_bam_16_attention_center_x": 0.44839530584418164,
      "attention_bam_16_attention_center_distance": 0.10106899092431249,
      "attention_bam_16_attention_spatial_variance": 41.9815581938291,
      "attention_bam_16_attention_spatial_std": 6.479317725951484,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 8.679150187247243,
      "attention_bam_16_peak_intensity_mean": 0.33048295974731445,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 135,
      "phase": "train",
      "loss": 0.013914048671722412,
      "timestamp": 1759543902.490429,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.013914048671722412,
      "ssim": 0.7229335308074951,
      "attention_bam_384_mean_attention": 0.1705063134431839,
      "attention_bam_384_std_attention": 0.49718913435935974,
      "attention_bam_384_max_attention": 4.342754364013672,
      "attention_bam_384_min_attention": -1.5168681144714355,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.1952311265257825,
      "attention_bam_384_attention_skewness": 0.9204509515573241,
      "attention_bam_384_attention_sparsity": 0.47978464762369794,
      "attention_bam_384_attention_concentration_10": 0.6952096304484795,
      "attention_bam_384_attention_concentration_20": 1.067121082319486,
      "attention_bam_384_attention_center_y": 0.4787251399105507,
      "attention_bam_384_attention_center_x": 0.48458950464199557,
      "attention_bam_384_attention_center_distance": 0.037151124855237375,
      "attention_bam_384_attention_spatial_variance": 169.60758732763784,
      "attention_bam_384_attention_spatial_std": 13.023347777266713,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 18.33208732392971,
      "attention_bam_384_peak_intensity_mean": 0.2896946668624878,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19795823097229004,
      "attention_bam_16_std_attention": 0.5857661962509155,
      "attention_bam_16_max_attention": 2.826446533203125,
      "attention_bam_16_min_attention": -1.0271003246307373,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.6713240835382956,
      "attention_bam_16_attention_skewness": 1.0540125439068209,
      "attention_bam_16_attention_sparsity": 0.489501953125,
      "attention_bam_16_attention_concentration_10": 0.7175731997016153,
      "attention_bam_16_attention_concentration_20": 1.1011568751768634,
      "attention_bam_16_attention_center_y": 0.4542615904108578,
      "attention_bam_16_attention_center_x": 0.47457806348717224,
      "attention_bam_16_attention_center_distance": 0.07400374271354633,
      "attention_bam_16_attention_spatial_variance": 40.968590349358216,
      "attention_bam_16_attention_spatial_std": 6.40067108585953,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 10.074937964800972,
      "attention_bam_16_peak_intensity_mean": 0.3295035660266876,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 136,
      "phase": "train",
      "loss": 0.01887301728129387,
      "timestamp": 1759543902.6234348,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.01887301728129387,
      "ssim": 0.7509950995445251,
      "attention_bam_384_mean_attention": 0.17252744734287262,
      "attention_bam_384_std_attention": 0.5268973708152771,
      "attention_bam_384_max_attention": 5.713760852813721,
      "attention_bam_384_min_attention": -1.5888311862945557,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.9035790010227807,
      "attention_bam_384_attention_skewness": 0.9410812904598167,
      "attention_bam_384_attention_sparsity": 0.4730428059895833,
      "attention_bam_384_attention_concentration_10": 0.7023978904578879,
      "attention_bam_384_attention_concentration_20": 1.089121309375189,
      "attention_bam_384_attention_center_y": 0.47593712634645435,
      "attention_bam_384_attention_center_x": 0.4835663357630217,
      "attention_bam_384_attention_center_distance": 0.04120891186916345,
      "attention_bam_384_attention_spatial_variance": 170.2565023687935,
      "attention_bam_384_attention_spatial_std": 13.048237519634347,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 13.815912946092253,
      "attention_bam_384_peak_intensity_mean": 0.24313120543956757,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1999158263206482,
      "attention_bam_16_std_attention": 0.6289928555488586,
      "attention_bam_16_max_attention": 3.6070680618286133,
      "attention_bam_16_min_attention": -1.1336166858673096,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.7449062280884657,
      "attention_bam_16_attention_skewness": 0.9543443533054858,
      "attention_bam_16_attention_sparsity": 0.481689453125,
      "attention_bam_16_attention_concentration_10": 0.7270339779120171,
      "attention_bam_16_attention_concentration_20": 1.137850544599437,
      "attention_bam_16_attention_center_y": 0.44582630170067206,
      "attention_bam_16_attention_center_x": 0.4666690840168001,
      "attention_bam_16_attention_center_distance": 0.08995264918506557,
      "attention_bam_16_attention_spatial_variance": 41.527348024198865,
      "attention_bam_16_attention_spatial_std": 6.444171632118349,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 9.721558071671714,
      "attention_bam_16_peak_intensity_mean": 0.28958308696746826,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 137,
      "phase": "train",
      "loss": 0.014822853729128838,
      "timestamp": 1759543902.7476432,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.014822853729128838,
      "ssim": 0.7345585823059082,
      "attention_bam_384_mean_attention": 0.1707100123167038,
      "attention_bam_384_std_attention": 0.495784729719162,
      "attention_bam_384_max_attention": 3.971101999282837,
      "attention_bam_384_min_attention": -1.4752905368804932,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.815021259232406,
      "attention_bam_384_attention_skewness": 0.5950196044693001,
      "attention_bam_384_attention_sparsity": 0.4738820393880208,
      "attention_bam_384_attention_concentration_10": 0.6588637769787044,
      "attention_bam_384_attention_concentration_20": 1.054825726281937,
      "attention_bam_384_attention_center_y": 0.4845650275180201,
      "attention_bam_384_attention_center_x": 0.48087533757762146,
      "attention_bam_384_attention_center_distance": 0.03475603798736024,
      "attention_bam_384_attention_spatial_variance": 170.0803719432231,
      "attention_bam_384_attention_spatial_std": 13.041486569529683,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 16.678706731223723,
      "attention_bam_384_peak_intensity_mean": 0.305668443441391,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21070986986160278,
      "attention_bam_16_std_attention": 0.5671334266662598,
      "attention_bam_16_max_attention": 2.64501690864563,
      "attention_bam_16_min_attention": -0.9460572600364685,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.27050330587621607,
      "attention_bam_16_attention_skewness": 0.580896966792913,
      "attention_bam_16_attention_sparsity": 0.4580078125,
      "attention_bam_16_attention_concentration_10": 0.6148175807007721,
      "attention_bam_16_attention_concentration_20": 1.0007173720756721,
      "attention_bam_16_attention_center_y": 0.4634422194372189,
      "attention_bam_16_attention_center_x": 0.46031211358460766,
      "attention_bam_16_attention_center_distance": 0.07630988989374231,
      "attention_bam_16_attention_spatial_variance": 41.44777030789112,
      "attention_bam_16_attention_spatial_std": 6.437994276783035,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.639994031944067,
      "attention_bam_16_peak_intensity_mean": 0.32985126972198486,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 138,
      "phase": "train",
      "loss": 0.012738185934722424,
      "timestamp": 1759543902.877666,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.012738185934722424,
      "ssim": 0.78151535987854,
      "attention_bam_384_mean_attention": 0.16785770654678345,
      "attention_bam_384_std_attention": 0.5199347138404846,
      "attention_bam_384_max_attention": 4.3088603019714355,
      "attention_bam_384_min_attention": -1.504619836807251,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1014566995781623,
      "attention_bam_384_attention_skewness": 0.6561231552732596,
      "attention_bam_384_attention_sparsity": 0.4790802001953125,
      "attention_bam_384_attention_concentration_10": 0.7032768917287158,
      "attention_bam_384_attention_concentration_20": 1.115983265777233,
      "attention_bam_384_attention_center_y": 0.4853190304232901,
      "attention_bam_384_attention_center_x": 0.4832512342466186,
      "attention_bam_384_attention_center_distance": 0.031497683152064485,
      "attention_bam_384_attention_spatial_variance": 168.35279132976652,
      "attention_bam_384_attention_spatial_std": 12.975083480647303,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 15.577548426289868,
      "attention_bam_384_peak_intensity_mean": 0.29099953174591064,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20700234174728394,
      "attention_bam_16_std_attention": 0.6090412139892578,
      "attention_bam_16_max_attention": 3.3599886894226074,
      "attention_bam_16_min_attention": -1.0278512239456177,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.22515738080269943,
      "attention_bam_16_attention_skewness": 0.5943631622529135,
      "attention_bam_16_attention_sparsity": 0.466552734375,
      "attention_bam_16_attention_concentration_10": 0.6718257214376714,
      "attention_bam_16_attention_concentration_20": 1.081127770456102,
      "attention_bam_16_attention_center_y": 0.474599304466212,
      "attention_bam_16_attention_center_x": 0.4649820127557911,
      "attention_bam_16_attention_center_distance": 0.06117932271994802,
      "attention_bam_16_attention_spatial_variance": 40.49814880513352,
      "attention_bam_16_attention_spatial_std": 6.363815585412066,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 7.708282266732498,
      "attention_bam_16_peak_intensity_mean": 0.2896735668182373,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 139,
      "phase": "train",
      "loss": 0.01578447036445141,
      "timestamp": 1759543903.0087101,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.01578447036445141,
      "ssim": 0.7133201956748962,
      "attention_bam_384_mean_attention": 0.17083938419818878,
      "attention_bam_384_std_attention": 0.5031391978263855,
      "attention_bam_384_max_attention": 4.082921504974365,
      "attention_bam_384_min_attention": -1.5324435234069824,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.7451713345232003,
      "attention_bam_384_attention_skewness": 0.9117603467535813,
      "attention_bam_384_attention_sparsity": 0.4643402099609375,
      "attention_bam_384_attention_concentration_10": 0.6864630613161915,
      "attention_bam_384_attention_concentration_20": 1.0543949569627447,
      "attention_bam_384_attention_center_y": 0.4893394335860352,
      "attention_bam_384_attention_center_x": 0.48641751387538584,
      "attention_bam_384_attention_center_distance": 0.024418501411507223,
      "attention_bam_384_attention_spatial_variance": 172.5114707674899,
      "attention_bam_384_attention_spatial_std": 13.134362213959607,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 18.746969015628217,
      "attention_bam_384_peak_intensity_mean": 0.30596452951431274,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2113543450832367,
      "attention_bam_16_std_attention": 0.5578665733337402,
      "attention_bam_16_max_attention": 3.347878932952881,
      "attention_bam_16_min_attention": -1.1028547286987305,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.6364080711657412,
      "attention_bam_16_attention_skewness": 0.7369383859637412,
      "attention_bam_16_attention_sparsity": 0.43310546875,
      "attention_bam_16_attention_concentration_10": 0.6012535471861454,
      "attention_bam_16_attention_concentration_20": 0.9557028289305309,
      "attention_bam_16_attention_center_y": 0.47942932631263796,
      "attention_bam_16_attention_center_x": 0.4754079335303237,
      "attention_bam_16_attention_center_distance": 0.04534142364771771,
      "attention_bam_16_attention_spatial_variance": 43.36064891963737,
      "attention_bam_16_attention_spatial_std": 6.584880326903244,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 10.588066252848401,
      "attention_bam_16_peak_intensity_mean": 0.30608659982681274,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 140,
      "phase": "train",
      "loss": 0.018906310200691223,
      "timestamp": 1759543903.1827374,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.018906310200691223,
      "ssim": 0.665652871131897,
      "attention_bam_384_mean_attention": 0.1698518544435501,
      "attention_bam_384_std_attention": 0.5106370449066162,
      "attention_bam_384_max_attention": 4.529942512512207,
      "attention_bam_384_min_attention": -1.4063955545425415,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.4542784764690504,
      "attention_bam_384_attention_skewness": 0.910704013017009,
      "attention_bam_384_attention_sparsity": 0.4772135416666667,
      "attention_bam_384_attention_concentration_10": 0.6963909142248906,
      "attention_bam_384_attention_concentration_20": 1.0823275537364252,
      "attention_bam_384_attention_center_y": 0.49033025747487274,
      "attention_bam_384_attention_center_x": 0.47790210274779843,
      "attention_bam_384_attention_center_distance": 0.03411219674753041,
      "attention_bam_384_attention_spatial_variance": 169.4440064382144,
      "attention_bam_384_attention_spatial_std": 13.017065968881559,
      "attention_bam_384_num_attention_peaks": 4,
      "attention_bam_384_peak_separation_mean": 21.14482426190487,
      "attention_bam_384_peak_intensity_mean": 0.2691563069820404,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19710548222064972,
      "attention_bam_16_std_attention": 0.6219751834869385,
      "attention_bam_16_max_attention": 3.5729804039001465,
      "attention_bam_16_min_attention": -1.118790864944458,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.2700469441837203,
      "attention_bam_16_attention_skewness": 1.0786283982927696,
      "attention_bam_16_attention_sparsity": 0.48193359375,
      "attention_bam_16_attention_concentration_10": 0.7368495617947631,
      "attention_bam_16_attention_concentration_20": 1.1392289940720843,
      "attention_bam_16_attention_center_y": 0.4848628494538785,
      "attention_bam_16_attention_center_x": 0.4544111192047323,
      "attention_bam_16_attention_center_distance": 0.06793348774825378,
      "attention_bam_16_attention_spatial_variance": 41.50516965759325,
      "attention_bam_16_attention_spatial_std": 6.442450594113489,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 10.515334880016574,
      "attention_bam_16_peak_intensity_mean": 0.28935950994491577,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 141,
      "phase": "train",
      "loss": 0.01841416023671627,
      "timestamp": 1759543903.3234124,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.01841416023671627,
      "ssim": 0.7173675298690796,
      "attention_bam_384_mean_attention": 0.17503221333026886,
      "attention_bam_384_std_attention": 0.507006824016571,
      "attention_bam_384_max_attention": 4.211553573608398,
      "attention_bam_384_min_attention": -1.6011443138122559,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4976557557779824,
      "attention_bam_384_attention_skewness": 0.666986736524229,
      "attention_bam_384_attention_sparsity": 0.4624684651692708,
      "attention_bam_384_attention_concentration_10": 0.6690003359947085,
      "attention_bam_384_attention_concentration_20": 1.0456927963166185,
      "attention_bam_384_attention_center_y": 0.48190889153122773,
      "attention_bam_384_attention_center_x": 0.48319383774155117,
      "attention_bam_384_attention_center_distance": 0.03492091910262939,
      "attention_bam_384_attention_spatial_variance": 171.4315835468047,
      "attention_bam_384_attention_spatial_std": 13.093188440819322,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 17.60815856482487,
      "attention_bam_384_peak_intensity_mean": 0.30834564566612244,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2070835828781128,
      "attention_bam_16_std_attention": 0.6020380854606628,
      "attention_bam_16_max_attention": 2.456374168395996,
      "attention_bam_16_min_attention": -1.1232774257659912,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.3693087806989026,
      "attention_bam_16_attention_skewness": 0.6209514534671634,
      "attention_bam_16_attention_sparsity": 0.468505859375,
      "attention_bam_16_attention_concentration_10": 0.6717792519016811,
      "attention_bam_16_attention_concentration_20": 1.066763070154934,
      "attention_bam_16_attention_center_y": 0.46160816232513213,
      "attention_bam_16_attention_center_x": 0.46874122865694196,
      "attention_bam_16_attention_center_distance": 0.07001491249628167,
      "attention_bam_16_attention_spatial_variance": 42.841413682399654,
      "attention_bam_16_attention_spatial_std": 6.545335261268108,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.500441169796854,
      "attention_bam_16_peak_intensity_mean": 0.3760649561882019,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 142,
      "phase": "train",
      "loss": 0.014186881482601166,
      "timestamp": 1759543903.4549243,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.014186881482601166,
      "ssim": 0.7390872240066528,
      "attention_bam_384_mean_attention": 0.16994662582874298,
      "attention_bam_384_std_attention": 0.4886970818042755,
      "attention_bam_384_max_attention": 3.7980751991271973,
      "attention_bam_384_min_attention": -1.4844577312469482,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0690626404539447,
      "attention_bam_384_attention_skewness": 0.6628678043293992,
      "attention_bam_384_attention_sparsity": 0.4766794840494792,
      "attention_bam_384_attention_concentration_10": 0.6710487889792576,
      "attention_bam_384_attention_concentration_20": 1.057345750268673,
      "attention_bam_384_attention_center_y": 0.48146492861749884,
      "attention_bam_384_attention_center_x": 0.48578737742524836,
      "attention_bam_384_attention_center_distance": 0.03303172752390505,
      "attention_bam_384_attention_spatial_variance": 171.4285324594594,
      "attention_bam_384_attention_spatial_std": 13.093071926001912,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 20.72668559864939,
      "attention_bam_384_peak_intensity_mean": 0.31496870517730713,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19861790537834167,
      "attention_bam_16_std_attention": 0.5630149841308594,
      "attention_bam_16_max_attention": 2.4321482181549072,
      "attention_bam_16_min_attention": -1.141275405883789,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.3700939204540359,
      "attention_bam_16_attention_skewness": 0.6632679925349231,
      "attention_bam_16_attention_sparsity": 0.47314453125,
      "attention_bam_16_attention_concentration_10": 0.6597441282557646,
      "attention_bam_16_attention_concentration_20": 1.0540367477694392,
      "attention_bam_16_attention_center_y": 0.46287013618930795,
      "attention_bam_16_attention_center_x": 0.47154061299383027,
      "attention_bam_16_attention_center_distance": 0.06615985936151138,
      "attention_bam_16_attention_spatial_variance": 42.67534072168842,
      "attention_bam_16_attention_spatial_std": 6.532636582704446,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 10.274666187623726,
      "attention_bam_16_peak_intensity_mean": 0.37922370433807373,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 143,
      "phase": "train",
      "loss": 0.014677217230200768,
      "timestamp": 1759543903.5865912,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.014677217230200768,
      "ssim": 0.7301625609397888,
      "attention_bam_384_mean_attention": 0.16786076128482819,
      "attention_bam_384_std_attention": 0.5623955130577087,
      "attention_bam_384_max_attention": 5.688475608825684,
      "attention_bam_384_min_attention": -1.5263051986694336,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 4.029575715796619,
      "attention_bam_384_attention_skewness": 1.0796098955829192,
      "attention_bam_384_attention_sparsity": 0.48334503173828125,
      "attention_bam_384_attention_concentration_10": 0.7566985677929056,
      "attention_bam_384_attention_concentration_20": 1.176177212399965,
      "attention_bam_384_attention_center_y": 0.4851260030717135,
      "attention_bam_384_attention_center_x": 0.4794074946982337,
      "attention_bam_384_attention_center_distance": 0.035924561492826884,
      "attention_bam_384_attention_spatial_variance": 171.01804350543048,
      "attention_bam_384_attention_spatial_std": 13.077386723096877,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 18.145289891916242,
      "attention_bam_384_peak_intensity_mean": 0.23671436309814453,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20554065704345703,
      "attention_bam_16_std_attention": 0.6826980113983154,
      "attention_bam_16_max_attention": 5.8794450759887695,
      "attention_bam_16_min_attention": -1.1611019372940063,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 6.662568445496703,
      "attention_bam_16_attention_skewness": 1.6026950813635896,
      "attention_bam_16_attention_sparsity": 0.475830078125,
      "attention_bam_16_attention_concentration_10": 0.7654916047931346,
      "attention_bam_16_attention_concentration_20": 1.1641686724139646,
      "attention_bam_16_attention_center_y": 0.47188143584748715,
      "attention_bam_16_attention_center_x": 0.4536526463884713,
      "attention_bam_16_attention_center_distance": 0.07666460508984654,
      "attention_bam_16_attention_spatial_variance": 42.32622840859376,
      "attention_bam_16_attention_spatial_std": 6.505861081255405,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 7.735322591823821,
      "attention_bam_16_peak_intensity_mean": 0.20142525434494019,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 144,
      "phase": "train",
      "loss": 0.01606033742427826,
      "timestamp": 1759543903.7191894,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.01606033742427826,
      "ssim": 0.7295436263084412,
      "attention_bam_384_mean_attention": 0.16325049102306366,
      "attention_bam_384_std_attention": 0.5410979390144348,
      "attention_bam_384_max_attention": 4.230222225189209,
      "attention_bam_384_min_attention": -1.4386793375015259,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8021315038753922,
      "attention_bam_384_attention_skewness": 0.8636369494945377,
      "attention_bam_384_attention_sparsity": 0.49386342366536456,
      "attention_bam_384_attention_concentration_10": 0.7604819886799618,
      "attention_bam_384_attention_concentration_20": 1.1846856133617314,
      "attention_bam_384_attention_center_y": 0.4863655684809577,
      "attention_bam_384_attention_center_x": 0.4910460551282586,
      "attention_bam_384_attention_center_distance": 0.02306819679184476,
      "attention_bam_384_attention_spatial_variance": 169.6703387611978,
      "attention_bam_384_attention_spatial_std": 13.025756744281608,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 10.676092112277066,
      "attention_bam_384_peak_intensity_mean": 0.28520697355270386,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18498361110687256,
      "attention_bam_16_std_attention": 0.6489489674568176,
      "attention_bam_16_max_attention": 3.411390781402588,
      "attention_bam_16_min_attention": -1.1675609350204468,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.030310322870643,
      "attention_bam_16_attention_skewness": 1.1507056244020686,
      "attention_bam_16_attention_sparsity": 0.506591796875,
      "attention_bam_16_attention_concentration_10": 0.8510897338707268,
      "attention_bam_16_attention_concentration_20": 1.2738981830082137,
      "attention_bam_16_attention_center_y": 0.47552907461385263,
      "attention_bam_16_attention_center_x": 0.48977281003109635,
      "attention_bam_16_attention_center_distance": 0.03750790860377142,
      "attention_bam_16_attention_spatial_variance": 41.65023676323617,
      "attention_bam_16_attention_spatial_std": 6.453699463349388,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 7.723139367797984,
      "attention_bam_16_peak_intensity_mean": 0.3041437864303589,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 145,
      "phase": "train",
      "loss": 0.014669719152152538,
      "timestamp": 1759543903.8491797,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.014669719152152538,
      "ssim": 0.7669651508331299,
      "attention_bam_384_mean_attention": 0.17045362293720245,
      "attention_bam_384_std_attention": 0.5545074939727783,
      "attention_bam_384_max_attention": 3.713916301727295,
      "attention_bam_384_min_attention": -1.3960769176483154,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.2791509339988334,
      "attention_bam_384_attention_skewness": 0.5588106480397227,
      "attention_bam_384_attention_sparsity": 0.48514048258463544,
      "attention_bam_384_attention_concentration_10": 0.725145619434404,
      "attention_bam_384_attention_concentration_20": 1.1701943022271162,
      "attention_bam_384_attention_center_y": 0.48459286180250644,
      "attention_bam_384_attention_center_x": 0.48352590236523174,
      "attention_bam_384_attention_center_distance": 0.03189908463628831,
      "attention_bam_384_attention_spatial_variance": 168.5333899301698,
      "attention_bam_384_attention_spatial_std": 12.982041054093528,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 16.150389300796462,
      "attention_bam_384_peak_intensity_mean": 0.3119887113571167,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20758378505706787,
      "attention_bam_16_std_attention": 0.6686274409294128,
      "attention_bam_16_max_attention": 3.238940477371216,
      "attention_bam_16_min_attention": -1.0824934244155884,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.4129226746059289,
      "attention_bam_16_attention_skewness": 0.7295189951397496,
      "attention_bam_16_attention_sparsity": 0.4912109375,
      "attention_bam_16_attention_concentration_10": 0.7440648403238895,
      "attention_bam_16_attention_concentration_20": 1.1874797928351002,
      "attention_bam_16_attention_center_y": 0.4703425985383341,
      "attention_bam_16_attention_center_x": 0.46887285096730974,
      "attention_bam_16_attention_center_distance": 0.060802316869700494,
      "attention_bam_16_attention_spatial_variance": 40.988027328773555,
      "attention_bam_16_attention_spatial_std": 6.402189260618086,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 7.366846824929818,
      "attention_bam_16_peak_intensity_mean": 0.3253222107887268,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 146,
      "phase": "train",
      "loss": 0.015403184108436108,
      "timestamp": 1759543903.9796221,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.015403184108436108,
      "ssim": 0.7615155577659607,
      "attention_bam_384_mean_attention": 0.16795724630355835,
      "attention_bam_384_std_attention": 0.5154668092727661,
      "attention_bam_384_max_attention": 4.306217193603516,
      "attention_bam_384_min_attention": -1.4656920433044434,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0906549259520197,
      "attention_bam_384_attention_skewness": 0.6352865586841021,
      "attention_bam_384_attention_sparsity": 0.47644297281901044,
      "attention_bam_384_attention_concentration_10": 0.6935840677866808,
      "attention_bam_384_attention_concentration_20": 1.1046894416732569,
      "attention_bam_384_attention_center_y": 0.47915014232159187,
      "attention_bam_384_attention_center_x": 0.4862671825198651,
      "attention_bam_384_attention_center_distance": 0.03530741681722334,
      "attention_bam_384_attention_spatial_variance": 170.04150338361308,
      "attention_bam_384_attention_spatial_std": 13.03999629538341,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 17.15846296854913,
      "attention_bam_384_peak_intensity_mean": 0.2864462733268738,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18723931908607483,
      "attention_bam_16_std_attention": 0.5982174873352051,
      "attention_bam_16_max_attention": 3.057715892791748,
      "attention_bam_16_min_attention": -1.0480324029922485,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5329571093021035,
      "attention_bam_16_attention_skewness": 0.6946503752416604,
      "attention_bam_16_attention_sparsity": 0.485107421875,
      "attention_bam_16_attention_concentration_10": 0.7356600472725594,
      "attention_bam_16_attention_concentration_20": 1.171927109771278,
      "attention_bam_16_attention_center_y": 0.45343166470324153,
      "attention_bam_16_attention_center_x": 0.477286617244155,
      "attention_bam_16_attention_center_distance": 0.07327356424420525,
      "attention_bam_16_attention_spatial_variance": 41.657128822906785,
      "attention_bam_16_attention_spatial_std": 6.454233403194123,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.735654740389595,
      "attention_bam_16_peak_intensity_mean": 0.30449753999710083,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 147,
      "phase": "train",
      "loss": 0.01455793809145689,
      "timestamp": 1759543904.1110241,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.01455793809145689,
      "ssim": 0.7357597351074219,
      "attention_bam_384_mean_attention": 0.16934321820735931,
      "attention_bam_384_std_attention": 0.5513037443161011,
      "attention_bam_384_max_attention": 4.816652774810791,
      "attention_bam_384_min_attention": -1.3710829019546509,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.4042351671001994,
      "attention_bam_384_attention_skewness": 0.9612256568159842,
      "attention_bam_384_attention_sparsity": 0.48944854736328125,
      "attention_bam_384_attention_concentration_10": 0.748289663550125,
      "attention_bam_384_attention_concentration_20": 1.1610762609839513,
      "attention_bam_384_attention_center_y": 0.4842422649427095,
      "attention_bam_384_attention_center_x": 0.4808515755236192,
      "attention_bam_384_attention_center_distance": 0.03507045406217097,
      "attention_bam_384_attention_spatial_variance": 167.08087798156726,
      "attention_bam_384_attention_spatial_std": 12.925976867593693,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 12.488593947101272,
      "attention_bam_384_peak_intensity_mean": 0.2535953223705292,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1980426013469696,
      "attention_bam_16_std_attention": 0.6761423945426941,
      "attention_bam_16_max_attention": 4.460664749145508,
      "attention_bam_16_min_attention": -1.1326154470443726,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.7080097032174537,
      "attention_bam_16_attention_skewness": 1.384202865749232,
      "attention_bam_16_attention_sparsity": 0.501220703125,
      "attention_bam_16_attention_concentration_10": 0.82058075842224,
      "attention_bam_16_attention_concentration_20": 1.2318699778500632,
      "attention_bam_16_attention_center_y": 0.47192090903030554,
      "attention_bam_16_attention_center_x": 0.46357182544586084,
      "attention_bam_16_attention_center_distance": 0.06504532651976172,
      "attention_bam_16_attention_spatial_variance": 39.47168520702132,
      "attention_bam_16_attention_spatial_std": 6.282649537179463,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 7.133777721965423,
      "attention_bam_16_peak_intensity_mean": 0.25619250535964966,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 148,
      "phase": "train",
      "loss": 0.011368323117494583,
      "timestamp": 1759543904.2404249,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.011368323117494583,
      "ssim": 0.788063108921051,
      "attention_bam_384_mean_attention": 0.17053638398647308,
      "attention_bam_384_std_attention": 0.5447936654090881,
      "attention_bam_384_max_attention": 3.7034292221069336,
      "attention_bam_384_min_attention": -1.4709349870681763,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1234238604461435,
      "attention_bam_384_attention_skewness": 0.6746253098692803,
      "attention_bam_384_attention_sparsity": 0.48014068603515625,
      "attention_bam_384_attention_concentration_10": 0.7276142012635667,
      "attention_bam_384_attention_concentration_20": 1.144013014923909,
      "attention_bam_384_attention_center_y": 0.49068344886505777,
      "attention_bam_384_attention_center_x": 0.48155304613805516,
      "attention_bam_384_attention_center_distance": 0.029226297467681902,
      "attention_bam_384_attention_spatial_variance": 170.56445318610537,
      "attention_bam_384_attention_spatial_std": 13.060032664052008,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 16.050836082571095,
      "attention_bam_384_peak_intensity_mean": 0.31725484132766724,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20077842473983765,
      "attention_bam_16_std_attention": 0.6371825933456421,
      "attention_bam_16_max_attention": 3.339731216430664,
      "attention_bam_16_min_attention": -1.384159803390503,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6425764552835385,
      "attention_bam_16_attention_skewness": 0.7285550060170377,
      "attention_bam_16_attention_sparsity": 0.481689453125,
      "attention_bam_16_attention_concentration_10": 0.7287014439263234,
      "attention_bam_16_attention_concentration_20": 1.1647092936988013,
      "attention_bam_16_attention_center_y": 0.48437159216519704,
      "attention_bam_16_attention_center_x": 0.46530713376302474,
      "attention_bam_16_attention_center_distance": 0.053811561939560694,
      "attention_bam_16_attention_spatial_variance": 42.359482078510915,
      "attention_bam_16_attention_spatial_std": 6.508416249634846,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.445158592083615,
      "attention_bam_16_peak_intensity_mean": 0.34160149097442627,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 149,
      "phase": "train",
      "loss": 0.010426566004753113,
      "timestamp": 1759543904.369889,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.010426566004753113,
      "ssim": 0.7738374471664429,
      "attention_bam_384_mean_attention": 0.1686343401670456,
      "attention_bam_384_std_attention": 0.5356895923614502,
      "attention_bam_384_max_attention": 3.807150363922119,
      "attention_bam_384_min_attention": -1.4553546905517578,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.314243433869417,
      "attention_bam_384_attention_skewness": 0.7810973054245759,
      "attention_bam_384_attention_sparsity": 0.48541514078776044,
      "attention_bam_384_attention_concentration_10": 0.738367855673383,
      "attention_bam_384_attention_concentration_20": 1.145929070540486,
      "attention_bam_384_attention_center_y": 0.4911382721376774,
      "attention_bam_384_attention_center_x": 0.47957583972500195,
      "attention_bam_384_attention_center_distance": 0.0314857600716474,
      "attention_bam_384_attention_spatial_variance": 173.03030477070675,
      "attention_bam_384_attention_spatial_std": 13.154098402045909,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 18.547917925343405,
      "attention_bam_384_peak_intensity_mean": 0.3111734092235565,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19175496697425842,
      "attention_bam_16_std_attention": 0.6355879902839661,
      "attention_bam_16_max_attention": 3.2889404296875,
      "attention_bam_16_min_attention": -1.2090363502502441,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.3542005870061562,
      "attention_bam_16_attention_skewness": 0.9522061567612273,
      "attention_bam_16_attention_sparsity": 0.491455078125,
      "attention_bam_16_attention_concentration_10": 0.7840598306239597,
      "attention_bam_16_attention_concentration_20": 1.2099806363592092,
      "attention_bam_16_attention_center_y": 0.49011962954146715,
      "attention_bam_16_attention_center_x": 0.45520503758820896,
      "attention_bam_16_attention_center_distance": 0.06487234199366662,
      "attention_bam_16_attention_spatial_variance": 43.7246235483708,
      "attention_bam_16_attention_spatial_std": 6.612459719980969,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.347400378432678,
      "attention_bam_16_peak_intensity_mean": 0.3190714418888092,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 150,
      "phase": "train",
      "loss": 0.01082709338515997,
      "timestamp": 1759543904.5415096,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.01082709338515997,
      "ssim": 0.7650290727615356,
      "attention_bam_384_mean_attention": 0.1741958111524582,
      "attention_bam_384_std_attention": 0.4799386262893677,
      "attention_bam_384_max_attention": 3.779201030731201,
      "attention_bam_384_min_attention": -1.3791297674179077,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0184390136978578,
      "attention_bam_384_attention_skewness": 0.5892438332081626,
      "attention_bam_384_attention_sparsity": 0.4617767333984375,
      "attention_bam_384_attention_concentration_10": 0.6353607764620526,
      "attention_bam_384_attention_concentration_20": 1.0096749814827324,
      "attention_bam_384_attention_center_y": 0.48034957193822914,
      "attention_bam_384_attention_center_x": 0.4846003985716354,
      "attention_bam_384_attention_center_distance": 0.03530685619432353,
      "attention_bam_384_attention_spatial_variance": 171.04864025238626,
      "attention_bam_384_attention_spatial_std": 13.078556504920039,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 19.597918007578517,
      "attention_bam_384_peak_intensity_mean": 0.3025730848312378,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20623520016670227,
      "attention_bam_16_std_attention": 0.5872301459312439,
      "attention_bam_16_max_attention": 2.9654970169067383,
      "attention_bam_16_min_attention": -0.999289870262146,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5672034510391164,
      "attention_bam_16_attention_skewness": 0.6305024116474286,
      "attention_bam_16_attention_sparsity": 0.4677734375,
      "attention_bam_16_attention_concentration_10": 0.657803241417018,
      "attention_bam_16_attention_concentration_20": 1.0533452888234658,
      "attention_bam_16_attention_center_y": 0.45657382708550187,
      "attention_bam_16_attention_center_x": 0.47094967454817643,
      "attention_bam_16_attention_center_distance": 0.07388848222634918,
      "attention_bam_16_attention_spatial_variance": 42.36721337953908,
      "attention_bam_16_attention_spatial_std": 6.509010168953424,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.350085788768995,
      "attention_bam_16_peak_intensity_mean": 0.3057723045349121,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 151,
      "phase": "train",
      "loss": 0.0130386371165514,
      "timestamp": 1759543904.6696355,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0130386371165514,
      "ssim": 0.7318618297576904,
      "attention_bam_384_mean_attention": 0.1685047298669815,
      "attention_bam_384_std_attention": 0.5207090973854065,
      "attention_bam_384_max_attention": 4.279864311218262,
      "attention_bam_384_min_attention": -1.443182349205017,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1993122124142204,
      "attention_bam_384_attention_skewness": 0.7384793863681993,
      "attention_bam_384_attention_sparsity": 0.48641713460286456,
      "attention_bam_384_attention_concentration_10": 0.7141074864984341,
      "attention_bam_384_attention_concentration_20": 1.1247098113561356,
      "attention_bam_384_attention_center_y": 0.4774634964188209,
      "attention_bam_384_attention_center_x": 0.4830919461514446,
      "attention_bam_384_attention_center_distance": 0.0398441031674738,
      "attention_bam_384_attention_spatial_variance": 170.75197990687383,
      "attention_bam_384_attention_spatial_std": 13.067210104183442,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 19.700314131582125,
      "attention_bam_384_peak_intensity_mean": 0.2860713303089142,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1857975870370865,
      "attention_bam_16_std_attention": 0.6181589961051941,
      "attention_bam_16_max_attention": 2.907565116882324,
      "attention_bam_16_min_attention": -1.0637726783752441,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5599250465949916,
      "attention_bam_16_attention_skewness": 0.7713898264199236,
      "attention_bam_16_attention_sparsity": 0.489501953125,
      "attention_bam_16_attention_concentration_10": 0.7724839828380533,
      "attention_bam_16_attention_concentration_20": 1.2190002698605087,
      "attention_bam_16_attention_center_y": 0.45181346839453906,
      "attention_bam_16_attention_center_x": 0.4671170293354258,
      "attention_bam_16_attention_center_distance": 0.0825012919643242,
      "attention_bam_16_attention_spatial_variance": 42.107482741391465,
      "attention_bam_16_attention_spatial_std": 6.489027873371439,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 10.468042051540571,
      "attention_bam_16_peak_intensity_mean": 0.3282340168952942,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 152,
      "phase": "train",
      "loss": 0.011072240769863129,
      "timestamp": 1759543904.8003452,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.011072240769863129,
      "ssim": 0.7858601212501526,
      "attention_bam_384_mean_attention": 0.17300017178058624,
      "attention_bam_384_std_attention": 0.5051867365837097,
      "attention_bam_384_max_attention": 4.237845420837402,
      "attention_bam_384_min_attention": -1.4566600322723389,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.47973916447433274,
      "attention_bam_384_attention_skewness": 0.5115274976843484,
      "attention_bam_384_attention_sparsity": 0.471954345703125,
      "attention_bam_384_attention_concentration_10": 0.65513402188294,
      "attention_bam_384_attention_concentration_20": 1.0586015271634563,
      "attention_bam_384_attention_center_y": 0.4853127627830016,
      "attention_bam_384_attention_center_x": 0.482543819410753,
      "attention_bam_384_attention_center_distance": 0.03226246047135231,
      "attention_bam_384_attention_spatial_variance": 169.6032271730385,
      "attention_bam_384_attention_spatial_std": 13.023180378580284,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 17.251903603376643,
      "attention_bam_384_peak_intensity_mean": 0.28773757815361023,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20701321959495544,
      "attention_bam_16_std_attention": 0.6170648336410522,
      "attention_bam_16_max_attention": 2.7359535694122314,
      "attention_bam_16_min_attention": -1.1924470663070679,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.22320816122296305,
      "attention_bam_16_attention_skewness": 0.6427893030075139,
      "attention_bam_16_attention_sparsity": 0.4755859375,
      "attention_bam_16_attention_concentration_10": 0.691980851135002,
      "attention_bam_16_attention_concentration_20": 1.1102697571250062,
      "attention_bam_16_attention_center_y": 0.47338184150674484,
      "attention_bam_16_attention_center_x": 0.467152465091311,
      "attention_bam_16_attention_center_distance": 0.059791084806174837,
      "attention_bam_16_attention_spatial_variance": 41.58317335518609,
      "attention_bam_16_attention_spatial_std": 6.448501636441297,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.810880122508413,
      "attention_bam_16_peak_intensity_mean": 0.3634525239467621,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 153,
      "phase": "train",
      "loss": 0.012158561497926712,
      "timestamp": 1759543904.9320018,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.012158561497926712,
      "ssim": 0.7745479941368103,
      "attention_bam_384_mean_attention": 0.1687934398651123,
      "attention_bam_384_std_attention": 0.5065830945968628,
      "attention_bam_384_max_attention": 3.965653896331787,
      "attention_bam_384_min_attention": -1.4180082082748413,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5430952998793837,
      "attention_bam_384_attention_skewness": 0.5976428175367297,
      "attention_bam_384_attention_sparsity": 0.48206329345703125,
      "attention_bam_384_attention_concentration_10": 0.6843119280308474,
      "attention_bam_384_attention_concentration_20": 1.0964947716783358,
      "attention_bam_384_attention_center_y": 0.4837154054669627,
      "attention_bam_384_attention_center_x": 0.4913877856289247,
      "attention_bam_384_attention_center_distance": 0.026052188218220158,
      "attention_bam_384_attention_spatial_variance": 170.0105894298148,
      "attention_bam_384_attention_spatial_std": 13.038810890177631,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 15.749177123197502,
      "attention_bam_384_peak_intensity_mean": 0.2955654561519623,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2000313401222229,
      "attention_bam_16_std_attention": 0.600017786026001,
      "attention_bam_16_max_attention": 2.725856304168701,
      "attention_bam_16_min_attention": -1.0474169254302979,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.11978680152507382,
      "attention_bam_16_attention_skewness": 0.6321585644566446,
      "attention_bam_16_attention_sparsity": 0.486572265625,
      "attention_bam_16_attention_concentration_10": 0.6902479581818924,
      "attention_bam_16_attention_concentration_20": 1.1114217681851282,
      "attention_bam_16_attention_center_y": 0.4690539714884095,
      "attention_bam_16_attention_center_x": 0.48969225243355974,
      "attention_bam_16_attention_center_distance": 0.04612822000757514,
      "attention_bam_16_attention_spatial_variance": 41.72591102273633,
      "attention_bam_16_attention_spatial_std": 6.459559661674805,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.60810208784006,
      "attention_bam_16_peak_intensity_mean": 0.32986098527908325,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 154,
      "phase": "train",
      "loss": 0.012915875762701035,
      "timestamp": 1759543905.0631561,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.012915875762701035,
      "ssim": 0.7875270247459412,
      "attention_bam_384_mean_attention": 0.17212367057800293,
      "attention_bam_384_std_attention": 0.5051249861717224,
      "attention_bam_384_max_attention": 4.364995002746582,
      "attention_bam_384_min_attention": -1.4347385168075562,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.5078745464387984,
      "attention_bam_384_attention_skewness": 0.904081232820254,
      "attention_bam_384_attention_sparsity": 0.47332509358723956,
      "attention_bam_384_attention_concentration_10": 0.6828473966174342,
      "attention_bam_384_attention_concentration_20": 1.0590279557320221,
      "attention_bam_384_attention_center_y": 0.48763735625091276,
      "attention_bam_384_attention_center_x": 0.4815561338242224,
      "attention_bam_384_attention_center_distance": 0.03140099234026971,
      "attention_bam_384_attention_spatial_variance": 168.64189667745816,
      "attention_bam_384_attention_spatial_std": 12.98621949134767,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 18.4332387801684,
      "attention_bam_384_peak_intensity_mean": 0.27723515033721924,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21111075580120087,
      "attention_bam_16_std_attention": 0.6357596516609192,
      "attention_bam_16_max_attention": 4.017589569091797,
      "attention_bam_16_min_attention": -1.1965217590332031,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.8052995680845783,
      "attention_bam_16_attention_skewness": 1.105554571517433,
      "attention_bam_16_attention_sparsity": 0.46923828125,
      "attention_bam_16_attention_concentration_10": 0.7091819862739704,
      "attention_bam_16_attention_concentration_20": 1.0907546711151854,
      "attention_bam_16_attention_center_y": 0.4791213689373799,
      "attention_bam_16_attention_center_x": 0.46258298867853637,
      "attention_bam_16_attention_center_distance": 0.06059620402763762,
      "attention_bam_16_attention_spatial_variance": 41.09305691968636,
      "attention_bam_16_attention_spatial_std": 6.410386643540806,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 7.917222466762949,
      "attention_bam_16_peak_intensity_mean": 0.2800446152687073,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 155,
      "phase": "train",
      "loss": 0.010304424911737442,
      "timestamp": 1759543905.196757,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.010304424911737442,
      "ssim": 0.7972153425216675,
      "attention_bam_384_mean_attention": 0.16610336303710938,
      "attention_bam_384_std_attention": 0.5434231758117676,
      "attention_bam_384_max_attention": 4.63404655456543,
      "attention_bam_384_min_attention": -1.4315621852874756,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8780575337032799,
      "attention_bam_384_attention_skewness": 0.9022657954859029,
      "attention_bam_384_attention_sparsity": 0.49162546793619794,
      "attention_bam_384_attention_concentration_10": 0.7589290327950519,
      "attention_bam_384_attention_concentration_20": 1.175359462676561,
      "attention_bam_384_attention_center_y": 0.49057118793022125,
      "attention_bam_384_attention_center_x": 0.4808249704877348,
      "attention_bam_384_attention_center_distance": 0.03021867812606786,
      "attention_bam_384_attention_spatial_variance": 170.23444152260262,
      "attention_bam_384_attention_spatial_std": 13.047392134928828,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 19.06183538771448,
      "attention_bam_384_peak_intensity_mean": 0.2647281587123871,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18774625658988953,
      "attention_bam_16_std_attention": 0.664514422416687,
      "attention_bam_16_max_attention": 3.7435407638549805,
      "attention_bam_16_min_attention": -1.0539772510528564,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.325980667626272,
      "attention_bam_16_attention_skewness": 1.1938035241769924,
      "attention_bam_16_attention_sparsity": 0.503173828125,
      "attention_bam_16_attention_concentration_10": 0.8462577457709899,
      "attention_bam_16_attention_concentration_20": 1.2789499817206496,
      "attention_bam_16_attention_center_y": 0.4929370246526051,
      "attention_bam_16_attention_center_x": 0.4632935934082399,
      "attention_bam_16_attention_center_distance": 0.05286295310777706,
      "attention_bam_16_attention_spatial_variance": 42.15901580056751,
      "attention_bam_16_attention_spatial_std": 6.492997443443784,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.39549076337123,
      "attention_bam_16_peak_intensity_mean": 0.2596574127674103,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 156,
      "phase": "train",
      "loss": 0.01284073106944561,
      "timestamp": 1759543905.3246384,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.01284073106944561,
      "ssim": 0.7624608278274536,
      "attention_bam_384_mean_attention": 0.1698429435491562,
      "attention_bam_384_std_attention": 0.5279277563095093,
      "attention_bam_384_max_attention": 4.375811576843262,
      "attention_bam_384_min_attention": -1.3632311820983887,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.6872136768937303,
      "attention_bam_384_attention_skewness": 0.7684297650466686,
      "attention_bam_384_attention_sparsity": 0.4772898356119792,
      "attention_bam_384_attention_concentration_10": 0.7114867856546447,
      "attention_bam_384_attention_concentration_20": 1.1142486817822563,
      "attention_bam_384_attention_center_y": 0.48535100775413004,
      "attention_bam_384_attention_center_x": 0.48762750032450525,
      "attention_bam_384_attention_center_distance": 0.027117216746549638,
      "attention_bam_384_attention_spatial_variance": 168.7174447774982,
      "attention_bam_384_attention_spatial_std": 12.989127945227816,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 16.79104501405047,
      "attention_bam_384_peak_intensity_mean": 0.26747560501098633,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20825308561325073,
      "attention_bam_16_std_attention": 0.6476866006851196,
      "attention_bam_16_max_attention": 3.765005111694336,
      "attention_bam_16_min_attention": -1.2079449892044067,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.7998285408284653,
      "attention_bam_16_attention_skewness": 0.9700886375926282,
      "attention_bam_16_attention_sparsity": 0.47412109375,
      "attention_bam_16_attention_concentration_10": 0.7292812888179704,
      "attention_bam_16_attention_concentration_20": 1.133880352268551,
      "attention_bam_16_attention_center_y": 0.47368647601625413,
      "attention_bam_16_attention_center_x": 0.4811410664518803,
      "attention_bam_16_attention_center_distance": 0.04578342317947759,
      "attention_bam_16_attention_spatial_variance": 41.344515125705755,
      "attention_bam_16_attention_spatial_std": 6.429970071913691,
      "attention_bam_16_num_attention_peaks": 2,
      "attention_bam_16_peak_separation_mean": 8.039900496896712,
      "attention_bam_16_peak_intensity_mean": 0.2841978669166565,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 157,
      "phase": "train",
      "loss": 0.012962063774466515,
      "timestamp": 1759543905.45682,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.012962063774466515,
      "ssim": 0.7625176906585693,
      "attention_bam_384_mean_attention": 0.16692166030406952,
      "attention_bam_384_std_attention": 0.515139102935791,
      "attention_bam_384_max_attention": 4.260313034057617,
      "attention_bam_384_min_attention": -1.4900639057159424,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.789958452022372,
      "attention_bam_384_attention_skewness": 0.857667867527762,
      "attention_bam_384_attention_sparsity": 0.4823455810546875,
      "attention_bam_384_attention_concentration_10": 0.721497035865876,
      "attention_bam_384_attention_concentration_20": 1.1119291188344307,
      "attention_bam_384_attention_center_y": 0.48300510839374255,
      "attention_bam_384_attention_center_x": 0.4872064849789798,
      "attention_bam_384_attention_center_distance": 0.030083230122495478,
      "attention_bam_384_attention_spatial_variance": 172.78322503645214,
      "attention_bam_384_attention_spatial_std": 13.144703307281308,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 17.173624705847097,
      "attention_bam_384_peak_intensity_mean": 0.29019036889076233,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19283470511436462,
      "attention_bam_16_std_attention": 0.6091687679290771,
      "attention_bam_16_max_attention": 3.750261068344116,
      "attention_bam_16_min_attention": -1.1662577390670776,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.6282796062066929,
      "attention_bam_16_attention_skewness": 0.9388081445941269,
      "attention_bam_16_attention_sparsity": 0.4833984375,
      "attention_bam_16_attention_concentration_10": 0.7484992950173524,
      "attention_bam_16_attention_concentration_20": 1.1451878452372832,
      "attention_bam_16_attention_center_y": 0.46567045337098145,
      "attention_bam_16_attention_center_x": 0.4774275989632022,
      "attention_bam_16_attention_center_distance": 0.05810389075302943,
      "attention_bam_16_attention_spatial_variance": 43.67993228274832,
      "attention_bam_16_attention_spatial_std": 6.609079533698193,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.07662107027146,
      "attention_bam_16_peak_intensity_mean": 0.28703510761260986,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 158,
      "phase": "train",
      "loss": 0.008918299339711666,
      "timestamp": 1759543905.5878043,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008918299339711666,
      "ssim": 0.8261681795120239,
      "attention_bam_384_mean_attention": 0.16658200323581696,
      "attention_bam_384_std_attention": 0.5403400659561157,
      "attention_bam_384_max_attention": 4.827775001525879,
      "attention_bam_384_min_attention": -1.406973958015442,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.337035022180296,
      "attention_bam_384_attention_skewness": 1.1415094285282605,
      "attention_bam_384_attention_sparsity": 0.49320729573567706,
      "attention_bam_384_attention_concentration_10": 0.7558298815637082,
      "attention_bam_384_attention_concentration_20": 1.156830818189958,
      "attention_bam_384_attention_center_y": 0.48994793451052737,
      "attention_bam_384_attention_center_x": 0.48486541970999536,
      "attention_bam_384_attention_center_distance": 0.02569433949955684,
      "attention_bam_384_attention_spatial_variance": 171.4462730501396,
      "attention_bam_384_attention_spatial_std": 13.093749388549469,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 15.640942115536696,
      "attention_bam_384_peak_intensity_mean": 0.2542608976364136,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19678160548210144,
      "attention_bam_16_std_attention": 0.6504195928573608,
      "attention_bam_16_max_attention": 4.140196800231934,
      "attention_bam_16_min_attention": -1.0230071544647217,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 4.028071978245494,
      "attention_bam_16_attention_skewness": 1.3921371806964422,
      "attention_bam_16_attention_sparsity": 0.491943359375,
      "attention_bam_16_attention_concentration_10": 0.7754690177469843,
      "attention_bam_16_attention_concentration_20": 1.1773054849279831,
      "attention_bam_16_attention_center_y": 0.484460544748469,
      "attention_bam_16_attention_center_x": 0.4730552978625976,
      "attention_bam_16_attention_center_distance": 0.04398844490971855,
      "attention_bam_16_attention_spatial_variance": 43.06090308037571,
      "attention_bam_16_attention_spatial_std": 6.56208069749037,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.613906056204215,
      "attention_bam_16_peak_intensity_mean": 0.24371245503425598,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 159,
      "phase": "train",
      "loss": 0.01071099005639553,
      "timestamp": 1759543905.719607,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.01071099005639553,
      "ssim": 0.787902295589447,
      "attention_bam_384_mean_attention": 0.16953031718730927,
      "attention_bam_384_std_attention": 0.5079508423805237,
      "attention_bam_384_max_attention": 3.4970078468322754,
      "attention_bam_384_min_attention": -1.3448822498321533,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.42514097313658006,
      "attention_bam_384_attention_skewness": 0.5374904252526977,
      "attention_bam_384_attention_sparsity": 0.48158009847005206,
      "attention_bam_384_attention_concentration_10": 0.6725041428660828,
      "attention_bam_384_attention_concentration_20": 1.0867264208212848,
      "attention_bam_384_attention_center_y": 0.4910677580146589,
      "attention_bam_384_attention_center_x": 0.480633549156971,
      "attention_bam_384_attention_center_distance": 0.030161046571369154,
      "attention_bam_384_attention_spatial_variance": 172.0966454417762,
      "attention_bam_384_attention_spatial_std": 13.118561104091263,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 18.437511247489947,
      "attention_bam_384_peak_intensity_mean": 0.3157607614994049,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20984195172786713,
      "attention_bam_16_std_attention": 0.6268020868301392,
      "attention_bam_16_max_attention": 2.6503279209136963,
      "attention_bam_16_min_attention": -1.1071901321411133,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.2025164728194757,
      "attention_bam_16_attention_skewness": 0.6335665635210795,
      "attention_bam_16_attention_sparsity": 0.470947265625,
      "attention_bam_16_attention_concentration_10": 0.6849644463821863,
      "attention_bam_16_attention_concentration_20": 1.102594009256284,
      "attention_bam_16_attention_center_y": 0.4902697616535744,
      "attention_bam_16_attention_center_x": 0.458554232402959,
      "attention_bam_16_attention_center_distance": 0.060206796792159345,
      "attention_bam_16_attention_spatial_variance": 43.13747227265178,
      "attention_bam_16_attention_spatial_std": 6.5679123222415035,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.784414098176075,
      "attention_bam_16_peak_intensity_mean": 0.3626616895198822,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 160,
      "phase": "train",
      "loss": 0.01200124528259039,
      "timestamp": 1759543905.888198,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.01200124528259039,
      "ssim": 0.7787598371505737,
      "attention_bam_384_mean_attention": 0.162216454744339,
      "attention_bam_384_std_attention": 0.5071648359298706,
      "attention_bam_384_max_attention": 3.8349404335021973,
      "attention_bam_384_min_attention": -1.4046118259429932,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.6552513472477255,
      "attention_bam_384_attention_skewness": 0.9199346563533372,
      "attention_bam_384_attention_sparsity": 0.5000991821289062,
      "attention_bam_384_attention_concentration_10": 0.7422322026806816,
      "attention_bam_384_attention_concentration_20": 1.1437773324824103,
      "attention_bam_384_attention_center_y": 0.48446064341125644,
      "attention_bam_384_attention_center_x": 0.47863598663159757,
      "attention_bam_384_attention_center_distance": 0.03736021066314818,
      "attention_bam_384_attention_spatial_variance": 169.41998140243706,
      "attention_bam_384_attention_spatial_std": 13.016143107788768,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 17.300166153734224,
      "attention_bam_384_peak_intensity_mean": 0.29915285110473633,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18591459095478058,
      "attention_bam_16_std_attention": 0.6129887104034424,
      "attention_bam_16_max_attention": 3.2468020915985107,
      "attention_bam_16_min_attention": -1.0446536540985107,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.255171338205919,
      "attention_bam_16_attention_skewness": 0.9793254597330218,
      "attention_bam_16_attention_sparsity": 0.501708984375,
      "attention_bam_16_attention_concentration_10": 0.7854806754057488,
      "attention_bam_16_attention_concentration_20": 1.2125048200392259,
      "attention_bam_16_attention_center_y": 0.47084626685348624,
      "attention_bam_16_attention_center_x": 0.4545967664410203,
      "attention_bam_16_attention_center_distance": 0.07630719198069594,
      "attention_bam_16_attention_spatial_variance": 41.06629109850005,
      "attention_bam_16_attention_spatial_std": 6.408298611839187,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.762440834553125,
      "attention_bam_16_peak_intensity_mean": 0.28475895524024963,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 161,
      "phase": "train",
      "loss": 0.01225089468061924,
      "timestamp": 1759543906.0314262,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.01225089468061924,
      "ssim": 0.7785990238189697,
      "attention_bam_384_mean_attention": 0.166873499751091,
      "attention_bam_384_std_attention": 0.48178836703300476,
      "attention_bam_384_max_attention": 4.036611557006836,
      "attention_bam_384_min_attention": -1.434733510017395,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4164805840359183,
      "attention_bam_384_attention_skewness": 0.6340652052071146,
      "attention_bam_384_attention_sparsity": 0.46555836995442706,
      "attention_bam_384_attention_concentration_10": 0.6607618890683594,
      "attention_bam_384_attention_concentration_20": 1.0438609608883638,
      "attention_bam_384_attention_center_y": 0.48408992278424684,
      "attention_bam_384_attention_center_x": 0.4854931092675281,
      "attention_bam_384_attention_center_distance": 0.03044931643683015,
      "attention_bam_384_attention_spatial_variance": 172.83088717817085,
      "attention_bam_384_attention_spatial_std": 13.146516161256216,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 19.331153578906793,
      "attention_bam_384_peak_intensity_mean": 0.29568275809288025,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19007042050361633,
      "attention_bam_16_std_attention": 0.5777944922447205,
      "attention_bam_16_max_attention": 3.5212838649749756,
      "attention_bam_16_min_attention": -1.1051182746887207,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.2585053321307935,
      "attention_bam_16_attention_skewness": 0.7891235900897356,
      "attention_bam_16_attention_sparsity": 0.47607421875,
      "attention_bam_16_attention_concentration_10": 0.7032990707382022,
      "attention_bam_16_attention_concentration_20": 1.1021303117515961,
      "attention_bam_16_attention_center_y": 0.4687487543675605,
      "attention_bam_16_attention_center_x": 0.4723572179569744,
      "attention_bam_16_attention_center_distance": 0.05900447021467588,
      "attention_bam_16_attention_spatial_variance": 44.01504424712026,
      "attention_bam_16_attention_spatial_std": 6.634383486588656,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.436322678195976,
      "attention_bam_16_peak_intensity_mean": 0.2895285189151764,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 162,
      "phase": "train",
      "loss": 0.012274045497179031,
      "timestamp": 1759543906.3547952,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.012274045497179031,
      "ssim": 0.8156254291534424,
      "attention_bam_384_mean_attention": 0.16454850137233734,
      "attention_bam_384_std_attention": 0.5243272185325623,
      "attention_bam_384_max_attention": 3.6772494316101074,
      "attention_bam_384_min_attention": -1.470108151435852,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.3627601426621898,
      "attention_bam_384_attention_skewness": 0.5153457321021709,
      "attention_bam_384_attention_sparsity": 0.48279062906901044,
      "attention_bam_384_attention_concentration_10": 0.7039151306139206,
      "attention_bam_384_attention_concentration_20": 1.138739726662367,
      "attention_bam_384_attention_center_y": 0.487543040616643,
      "attention_bam_384_attention_center_x": 0.4886381654717013,
      "attention_bam_384_attention_center_distance": 0.023843956086482227,
      "attention_bam_384_attention_spatial_variance": 172.59726486566942,
      "attention_bam_384_attention_spatial_std": 13.137627824903149,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 20.546474302671154,
      "attention_bam_384_peak_intensity_mean": 0.32235127687454224,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18903440237045288,
      "attention_bam_16_std_attention": 0.6202760934829712,
      "attention_bam_16_max_attention": 2.8650262355804443,
      "attention_bam_16_min_attention": -1.2102470397949219,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.3931382668561838,
      "attention_bam_16_attention_skewness": 0.6425483135691342,
      "attention_bam_16_attention_sparsity": 0.482666015625,
      "attention_bam_16_attention_concentration_10": 0.7431996067344013,
      "attention_bam_16_attention_concentration_20": 1.1833399233199768,
      "attention_bam_16_attention_center_y": 0.4797858936343832,
      "attention_bam_16_attention_center_x": 0.4776243148986746,
      "attention_bam_16_attention_center_distance": 0.0426446099739263,
      "attention_bam_16_attention_spatial_variance": 43.877355557817936,
      "attention_bam_16_attention_spatial_std": 6.623998456960715,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.015101601147064,
      "attention_bam_16_peak_intensity_mean": 0.3494011163711548,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 163,
      "phase": "train",
      "loss": 0.013061387464404106,
      "timestamp": 1759543906.4862182,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.013061387464404106,
      "ssim": 0.7889271974563599,
      "attention_bam_384_mean_attention": 0.1650305837392807,
      "attention_bam_384_std_attention": 0.5165056586265564,
      "attention_bam_384_max_attention": 3.646787405014038,
      "attention_bam_384_min_attention": -1.4477728605270386,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.48237785178921966,
      "attention_bam_384_attention_skewness": 0.5342915733229392,
      "attention_bam_384_attention_sparsity": 0.48048655192057294,
      "attention_bam_384_attention_concentration_10": 0.705651754402278,
      "attention_bam_384_attention_concentration_20": 1.129334538769163,
      "attention_bam_384_attention_center_y": 0.4868654224600779,
      "attention_bam_384_attention_center_x": 0.4883596502179776,
      "attention_bam_384_attention_center_distance": 0.02481994642218449,
      "attention_bam_384_attention_spatial_variance": 170.7436598634865,
      "attention_bam_384_attention_spatial_std": 13.066891744538427,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 17.10766004737918,
      "attention_bam_384_peak_intensity_mean": 0.31921619176864624,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19245469570159912,
      "attention_bam_16_std_attention": 0.6060044169425964,
      "attention_bam_16_max_attention": 2.792428970336914,
      "attention_bam_16_min_attention": -1.2396190166473389,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.49176310777791077,
      "attention_bam_16_attention_skewness": 0.691501959911584,
      "attention_bam_16_attention_sparsity": 0.48681640625,
      "attention_bam_16_attention_concentration_10": 0.7270376734191824,
      "attention_bam_16_attention_concentration_20": 1.1583811160097524,
      "attention_bam_16_attention_center_y": 0.47832365213664835,
      "attention_bam_16_attention_center_x": 0.4819787621155872,
      "attention_bam_16_attention_center_distance": 0.039865500663596946,
      "attention_bam_16_attention_spatial_variance": 42.61804063290182,
      "attention_bam_16_attention_spatial_std": 6.528249430965534,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.901721849492404,
      "attention_bam_16_peak_intensity_mean": 0.3650215268135071,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 164,
      "phase": "train",
      "loss": 0.012314270250499249,
      "timestamp": 1759543906.6193595,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.012314270250499249,
      "ssim": 0.8028583526611328,
      "attention_bam_384_mean_attention": 0.16364562511444092,
      "attention_bam_384_std_attention": 0.4929617941379547,
      "attention_bam_384_max_attention": 3.4174976348876953,
      "attention_bam_384_min_attention": -1.359971523284912,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.091940646559939,
      "attention_bam_384_attention_skewness": 0.6929571886703986,
      "attention_bam_384_attention_sparsity": 0.4812571207682292,
      "attention_bam_384_attention_concentration_10": 0.6954058699790119,
      "attention_bam_384_attention_concentration_20": 1.0946168749696292,
      "attention_bam_384_attention_center_y": 0.4879015531469944,
      "attention_bam_384_attention_center_x": 0.4822329981872028,
      "attention_bam_384_attention_center_distance": 0.030398643708920328,
      "attention_bam_384_attention_spatial_variance": 168.8726017138489,
      "attention_bam_384_attention_spatial_std": 12.995099142132348,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 17.659589869644744,
      "attention_bam_384_peak_intensity_mean": 0.3209206461906433,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19852469861507416,
      "attention_bam_16_std_attention": 0.6089495420455933,
      "attention_bam_16_max_attention": 3.5545568466186523,
      "attention_bam_16_min_attention": -0.9735555648803711,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.1601936707523937,
      "attention_bam_16_attention_skewness": 0.894654129732202,
      "attention_bam_16_attention_sparsity": 0.488037109375,
      "attention_bam_16_attention_concentration_10": 0.731907493381824,
      "attention_bam_16_attention_concentration_20": 1.1388857134417651,
      "attention_bam_16_attention_center_y": 0.48337597314926917,
      "attention_bam_16_attention_center_x": 0.46563976603163465,
      "attention_bam_16_attention_center_distance": 0.053981180926219605,
      "attention_bam_16_attention_spatial_variance": 41.04897027340187,
      "attention_bam_16_attention_spatial_std": 6.406947032198867,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.746896159654481,
      "attention_bam_16_peak_intensity_mean": 0.2634510397911072,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 165,
      "phase": "train",
      "loss": 0.010861638002097607,
      "timestamp": 1759543906.7516346,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.010861638002097607,
      "ssim": 0.7804886102676392,
      "attention_bam_384_mean_attention": 0.16834880411624908,
      "attention_bam_384_std_attention": 0.5088216662406921,
      "attention_bam_384_max_attention": 3.7616825103759766,
      "attention_bam_384_min_attention": -1.3889517784118652,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.706289917375146,
      "attention_bam_384_attention_skewness": 0.606709422042609,
      "attention_bam_384_attention_sparsity": 0.48113250732421875,
      "attention_bam_384_attention_concentration_10": 0.6918965079962742,
      "attention_bam_384_attention_concentration_20": 1.101867011720098,
      "attention_bam_384_attention_center_y": 0.48263945220990584,
      "attention_bam_384_attention_center_x": 0.48797317066317875,
      "attention_bam_384_attention_center_distance": 0.029867482099071144,
      "attention_bam_384_attention_spatial_variance": 168.70539075595647,
      "attention_bam_384_attention_spatial_std": 12.988663932674386,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 18.37504573051512,
      "attention_bam_384_peak_intensity_mean": 0.3039731979370117,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20493727922439575,
      "attention_bam_16_std_attention": 0.6102845072746277,
      "attention_bam_16_max_attention": 2.817310333251953,
      "attention_bam_16_min_attention": -1.2357138395309448,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8703383898759451,
      "attention_bam_16_attention_skewness": 0.7921874999920664,
      "attention_bam_16_attention_sparsity": 0.480712890625,
      "attention_bam_16_attention_concentration_10": 0.7074192247951587,
      "attention_bam_16_attention_concentration_20": 1.1086547127978896,
      "attention_bam_16_attention_center_y": 0.4666883625093027,
      "attention_bam_16_attention_center_x": 0.4806784192796633,
      "attention_bam_16_attention_center_distance": 0.05446078724814979,
      "attention_bam_16_attention_spatial_variance": 41.08631069219202,
      "attention_bam_16_attention_spatial_std": 6.409860426888562,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 8.610974268816152,
      "attention_bam_16_peak_intensity_mean": 0.35979345440864563,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 166,
      "phase": "train",
      "loss": 0.010890758596360683,
      "timestamp": 1759543906.8802757,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.010890758596360683,
      "ssim": 0.7980587482452393,
      "attention_bam_384_mean_attention": 0.16656292974948883,
      "attention_bam_384_std_attention": 0.5242964625358582,
      "attention_bam_384_max_attention": 3.774331569671631,
      "attention_bam_384_min_attention": -1.4474633932113647,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5182954466172722,
      "attention_bam_384_attention_skewness": 0.5043800081111243,
      "attention_bam_384_attention_sparsity": 0.47436777750651044,
      "attention_bam_384_attention_concentration_10": 0.7058245495420135,
      "attention_bam_384_attention_concentration_20": 1.1282840174431366,
      "attention_bam_384_attention_center_y": 0.4812580291723646,
      "attention_bam_384_attention_center_x": 0.4859827194321423,
      "attention_bam_384_attention_center_distance": 0.03309820614540849,
      "attention_bam_384_attention_spatial_variance": 170.1523381508372,
      "attention_bam_384_attention_spatial_std": 13.044245403657401,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 17.71118693772917,
      "attention_bam_384_peak_intensity_mean": 0.30994483828544617,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19624127447605133,
      "attention_bam_16_std_attention": 0.6401301622390747,
      "attention_bam_16_max_attention": 2.8719658851623535,
      "attention_bam_16_min_attention": -1.1933445930480957,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.14750109443586457,
      "attention_bam_16_attention_skewness": 0.5968114545888988,
      "attention_bam_16_attention_sparsity": 0.487548828125,
      "attention_bam_16_attention_concentration_10": 0.7417109601929179,
      "attention_bam_16_attention_concentration_20": 1.1895523370505585,
      "attention_bam_16_attention_center_y": 0.46055056554558005,
      "attention_bam_16_attention_center_x": 0.4755141616359637,
      "attention_bam_16_attention_center_distance": 0.06566299047657344,
      "attention_bam_16_attention_spatial_variance": 41.79954587905501,
      "attention_bam_16_attention_spatial_std": 6.46525683009229,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.121808696956,
      "attention_bam_16_peak_intensity_mean": 0.3431508541107178,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 167,
      "phase": "train",
      "loss": 0.009453070349991322,
      "timestamp": 1759543907.0122206,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.009453070349991322,
      "ssim": 0.8082031011581421,
      "attention_bam_384_mean_attention": 0.1604079157114029,
      "attention_bam_384_std_attention": 0.5085203051567078,
      "attention_bam_384_max_attention": 3.3957746028900146,
      "attention_bam_384_min_attention": -1.4255003929138184,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5553728347461955,
      "attention_bam_384_attention_skewness": 0.6255472617225338,
      "attention_bam_384_attention_sparsity": 0.49326324462890625,
      "attention_bam_384_attention_concentration_10": 0.7229958725322501,
      "attention_bam_384_attention_concentration_20": 1.1510284545500182,
      "attention_bam_384_attention_center_y": 0.4814712804919716,
      "attention_bam_384_attention_center_x": 0.479396693311853,
      "attention_bam_384_attention_center_distance": 0.03918697980434412,
      "attention_bam_384_attention_spatial_variance": 170.53583753302632,
      "attention_bam_384_attention_spatial_std": 13.05893707516145,
      "attention_bam_384_num_attention_peaks": 18,
      "attention_bam_384_peak_separation_mean": 17.461824737070323,
      "attention_bam_384_peak_intensity_mean": 0.3352700471878052,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.186926007270813,
      "attention_bam_16_std_attention": 0.6007857322692871,
      "attention_bam_16_max_attention": 3.3755204677581787,
      "attention_bam_16_min_attention": -1.1802576780319214,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.25932262989772203,
      "attention_bam_16_attention_skewness": 0.6285542515130672,
      "attention_bam_16_attention_sparsity": 0.484619140625,
      "attention_bam_16_attention_concentration_10": 0.728495011944831,
      "attention_bam_16_attention_concentration_20": 1.1716776707717704,
      "attention_bam_16_attention_center_y": 0.4632577801066833,
      "attention_bam_16_attention_center_x": 0.45936549239910307,
      "attention_bam_16_attention_center_distance": 0.07747456267261131,
      "attention_bam_16_attention_spatial_variance": 42.463136858733705,
      "attention_bam_16_attention_spatial_std": 6.516374517991864,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 8.63718415725599,
      "attention_bam_16_peak_intensity_mean": 0.3102570176124573,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 168,
      "phase": "train",
      "loss": 0.00934852845966816,
      "timestamp": 1759543907.143205,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00934852845966816,
      "ssim": 0.8066010475158691,
      "attention_bam_384_mean_attention": 0.1583845466375351,
      "attention_bam_384_std_attention": 0.4870871603488922,
      "attention_bam_384_max_attention": 4.422791004180908,
      "attention_bam_384_min_attention": -1.47981858253479,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0132515788699914,
      "attention_bam_384_attention_skewness": 0.6683942633285616,
      "attention_bam_384_attention_sparsity": 0.4872589111328125,
      "attention_bam_384_attention_concentration_10": 0.7095944368585201,
      "attention_bam_384_attention_concentration_20": 1.1203844071974824,
      "attention_bam_384_attention_center_y": 0.48387572100468873,
      "attention_bam_384_attention_center_x": 0.4827739216430546,
      "attention_bam_384_attention_center_distance": 0.03336855252114657,
      "attention_bam_384_attention_spatial_variance": 169.9770446233536,
      "attention_bam_384_attention_spatial_std": 13.037524482176577,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 17.752070517761577,
      "attention_bam_384_peak_intensity_mean": 0.2791328430175781,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1838051676750183,
      "attention_bam_16_std_attention": 0.5853610634803772,
      "attention_bam_16_max_attention": 3.046708822250366,
      "attention_bam_16_min_attention": -1.1062774658203125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.9611584178563755,
      "attention_bam_16_attention_skewness": 0.8624741945851578,
      "attention_bam_16_attention_sparsity": 0.499755859375,
      "attention_bam_16_attention_concentration_10": 0.7527501516727477,
      "attention_bam_16_attention_concentration_20": 1.1856036616430372,
      "attention_bam_16_attention_center_y": 0.46954762196019717,
      "attention_bam_16_attention_center_x": 0.46808783260904957,
      "attention_bam_16_attention_center_distance": 0.062381627998427634,
      "attention_bam_16_attention_spatial_variance": 42.16283732021195,
      "attention_bam_16_attention_spatial_std": 6.493291716857633,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.03700546906818,
      "attention_bam_16_peak_intensity_mean": 0.31428244709968567,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 169,
      "phase": "train",
      "loss": 0.014404991641640663,
      "timestamp": 1759543907.2747715,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.014404991641640663,
      "ssim": 0.7964107990264893,
      "attention_bam_384_mean_attention": 0.15710614621639252,
      "attention_bam_384_std_attention": 0.508847713470459,
      "attention_bam_384_max_attention": 3.5746591091156006,
      "attention_bam_384_min_attention": -1.4642047882080078,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4311417558011694,
      "attention_bam_384_attention_skewness": 0.8297499174854697,
      "attention_bam_384_attention_sparsity": 0.4989776611328125,
      "attention_bam_384_attention_concentration_10": 0.7540997455360753,
      "attention_bam_384_attention_concentration_20": 1.1691589592875626,
      "attention_bam_384_attention_center_y": 0.4899986317555891,
      "attention_bam_384_attention_center_x": 0.4800450862405647,
      "attention_bam_384_attention_center_distance": 0.0315666263609785,
      "attention_bam_384_attention_spatial_variance": 168.77812315908938,
      "attention_bam_384_attention_spatial_std": 12.9914634725688,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 16.830922217195635,
      "attention_bam_384_peak_intensity_mean": 0.32289913296699524,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18790818750858307,
      "attention_bam_16_std_attention": 0.6266178488731384,
      "attention_bam_16_max_attention": 3.6681761741638184,
      "attention_bam_16_min_attention": -1.2325613498687744,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.4672212306149977,
      "attention_bam_16_attention_skewness": 0.9965122799256098,
      "attention_bam_16_attention_sparsity": 0.501953125,
      "attention_bam_16_attention_concentration_10": 0.7972803195378203,
      "attention_bam_16_attention_concentration_20": 1.2243855322927872,
      "attention_bam_16_attention_center_y": 0.4815006509891594,
      "attention_bam_16_attention_center_x": 0.4578692571739666,
      "attention_bam_16_attention_center_distance": 0.06507265792786175,
      "attention_bam_16_attention_spatial_variance": 41.23008918336297,
      "attention_bam_16_attention_spatial_std": 6.421066047266837,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.111659421874766,
      "attention_bam_16_peak_intensity_mean": 0.29478922486305237,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 170,
      "phase": "train",
      "loss": 0.011335785500705242,
      "timestamp": 1759543907.44643,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.011335785500705242,
      "ssim": 0.8185372352600098,
      "attention_bam_384_mean_attention": 0.15662790834903717,
      "attention_bam_384_std_attention": 0.5914278030395508,
      "attention_bam_384_max_attention": 5.914130687713623,
      "attention_bam_384_min_attention": -1.4095180034637451,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 5.548939854860967,
      "attention_bam_384_attention_skewness": 1.4774391747647857,
      "attention_bam_384_attention_sparsity": 0.505523681640625,
      "attention_bam_384_attention_concentration_10": 0.8701013865884503,
      "attention_bam_384_attention_concentration_20": 1.3012577599557364,
      "attention_bam_384_attention_center_y": 0.48532646143873304,
      "attention_bam_384_attention_center_x": 0.47574766183769335,
      "attention_bam_384_attention_center_distance": 0.040087121130055324,
      "attention_bam_384_attention_spatial_variance": 169.66533288868834,
      "attention_bam_384_attention_spatial_std": 13.025564590016371,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 16.032673503381247,
      "attention_bam_384_peak_intensity_mean": 0.21461665630340576,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17466142773628235,
      "attention_bam_16_std_attention": 0.7318344116210938,
      "attention_bam_16_max_attention": 5.2992048263549805,
      "attention_bam_16_min_attention": -1.2928037643432617,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 7.531336645250047,
      "attention_bam_16_attention_skewness": 2.0136314147787924,
      "attention_bam_16_attention_sparsity": 0.526611328125,
      "attention_bam_16_attention_concentration_10": 0.9910174015950094,
      "attention_bam_16_attention_concentration_20": 1.432155565943912,
      "attention_bam_16_attention_center_y": 0.4730489520575971,
      "attention_bam_16_attention_center_x": 0.45002872207737604,
      "attention_bam_16_attention_center_distance": 0.08029305826052241,
      "attention_bam_16_attention_spatial_variance": 41.80000883474839,
      "attention_bam_16_attention_spatial_std": 6.465292633342159,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.593108010818218,
      "attention_bam_16_peak_intensity_mean": 0.22071433067321777,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 171,
      "phase": "train",
      "loss": 0.010014120489358902,
      "timestamp": 1759543907.5780225,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.010014120489358902,
      "ssim": 0.8077216148376465,
      "attention_bam_384_mean_attention": 0.16111767292022705,
      "attention_bam_384_std_attention": 0.506921648979187,
      "attention_bam_384_max_attention": 3.9518370628356934,
      "attention_bam_384_min_attention": -1.4388192892074585,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.468010928032644,
      "attention_bam_384_attention_skewness": 0.7720961462778684,
      "attention_bam_384_attention_sparsity": 0.48944854736328125,
      "attention_bam_384_attention_concentration_10": 0.7236043154306039,
      "attention_bam_384_attention_concentration_20": 1.1353203808259273,
      "attention_bam_384_attention_center_y": 0.4847045702122579,
      "attention_bam_384_attention_center_x": 0.48055301421044816,
      "attention_bam_384_attention_center_distance": 0.034989582126421004,
      "attention_bam_384_attention_spatial_variance": 169.35754489652166,
      "attention_bam_384_attention_spatial_std": 13.013744461012044,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 16.896407196903933,
      "attention_bam_384_peak_intensity_mean": 0.2992841303348541,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1981237828731537,
      "attention_bam_16_std_attention": 0.6271114945411682,
      "attention_bam_16_max_attention": 3.618175506591797,
      "attention_bam_16_min_attention": -1.2299885749816895,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.6559856921977358,
      "attention_bam_16_attention_skewness": 0.9393103945536205,
      "attention_bam_16_attention_sparsity": 0.48486328125,
      "attention_bam_16_attention_concentration_10": 0.7438211978943623,
      "attention_bam_16_attention_concentration_20": 1.1631501590351516,
      "attention_bam_16_attention_center_y": 0.4707373331664623,
      "attention_bam_16_attention_center_x": 0.4597024033964836,
      "attention_bam_16_attention_center_distance": 0.07043010666228415,
      "attention_bam_16_attention_spatial_variance": 41.642051926476,
      "attention_bam_16_attention_spatial_std": 6.453065312429125,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.733427602308286,
      "attention_bam_16_peak_intensity_mean": 0.3014480173587799,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 172,
      "phase": "train",
      "loss": 0.012497412972152233,
      "timestamp": 1759543907.7081869,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.012497412972152233,
      "ssim": 0.7563959360122681,
      "attention_bam_384_mean_attention": 0.16117335855960846,
      "attention_bam_384_std_attention": 0.5022755265235901,
      "attention_bam_384_max_attention": 3.717916965484619,
      "attention_bam_384_min_attention": -1.4144978523254395,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9726121895213065,
      "attention_bam_384_attention_skewness": 0.6635877450096012,
      "attention_bam_384_attention_sparsity": 0.4838714599609375,
      "attention_bam_384_attention_concentration_10": 0.7097465631983413,
      "attention_bam_384_attention_concentration_20": 1.1252472688706887,
      "attention_bam_384_attention_center_y": 0.48030059432660577,
      "attention_bam_384_attention_center_x": 0.48602974202725324,
      "attention_bam_384_attention_center_distance": 0.0341536145000804,
      "attention_bam_384_attention_spatial_variance": 172.08459796422008,
      "attention_bam_384_attention_spatial_std": 13.118101919264848,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 19.464082636193794,
      "attention_bam_384_peak_intensity_mean": 0.3080075979232788,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19499419629573822,
      "attention_bam_16_std_attention": 0.6174744963645935,
      "attention_bam_16_max_attention": 3.4781270027160645,
      "attention_bam_16_min_attention": -1.2153418064117432,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.0107149237949633,
      "attention_bam_16_attention_skewness": 0.837343529768862,
      "attention_bam_16_attention_sparsity": 0.488037109375,
      "attention_bam_16_attention_concentration_10": 0.7398752957207236,
      "attention_bam_16_attention_concentration_20": 1.1608239257574398,
      "attention_bam_16_attention_center_y": 0.4592044920192695,
      "attention_bam_16_attention_center_x": 0.4739063894534935,
      "attention_bam_16_attention_center_distance": 0.06848576469250528,
      "attention_bam_16_attention_spatial_variance": 43.32744998621228,
      "attention_bam_16_attention_spatial_std": 6.582358998581912,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 10.061379675281044,
      "attention_bam_16_peak_intensity_mean": 0.3015986680984497,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 173,
      "phase": "train",
      "loss": 0.011656182818114758,
      "timestamp": 1759543907.8389733,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.011656182818114758,
      "ssim": 0.8258647918701172,
      "attention_bam_384_mean_attention": 0.1597001850605011,
      "attention_bam_384_std_attention": 0.5423822402954102,
      "attention_bam_384_max_attention": 4.03858757019043,
      "attention_bam_384_min_attention": -1.3941229581832886,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1149840921517606,
      "attention_bam_384_attention_skewness": 0.7956453421684712,
      "attention_bam_384_attention_sparsity": 0.4982248942057292,
      "attention_bam_384_attention_concentration_10": 0.7785808201531149,
      "attention_bam_384_attention_concentration_20": 1.2199507749059435,
      "attention_bam_384_attention_center_y": 0.4862407541931809,
      "attention_bam_384_attention_center_x": 0.4831209942049676,
      "attention_bam_384_attention_center_distance": 0.03079667780138647,
      "attention_bam_384_attention_spatial_variance": 166.45106420840077,
      "attention_bam_384_attention_spatial_std": 12.90159153780652,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 16.76997433612264,
      "attention_bam_384_peak_intensity_mean": 0.28894081711769104,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20063194632530212,
      "attention_bam_16_std_attention": 0.6718416213989258,
      "attention_bam_16_max_attention": 3.515962600708008,
      "attention_bam_16_min_attention": -1.074573040008545,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.473863008218549,
      "attention_bam_16_attention_skewness": 1.0196321672331234,
      "attention_bam_16_attention_sparsity": 0.500244140625,
      "attention_bam_16_attention_concentration_10": 0.7914295127524518,
      "attention_bam_16_attention_concentration_20": 1.2310164850563006,
      "attention_bam_16_attention_center_y": 0.4747548465805735,
      "attention_bam_16_attention_center_x": 0.46653538985088017,
      "attention_bam_16_attention_center_distance": 0.059282339758193685,
      "attention_bam_16_attention_spatial_variance": 39.75247005630119,
      "attention_bam_16_attention_spatial_std": 6.304955991622875,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 10.276847951501738,
      "attention_bam_16_peak_intensity_mean": 0.28057846426963806,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 174,
      "phase": "train",
      "loss": 0.010366073809564114,
      "timestamp": 1759543907.9685743,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.010366073809564114,
      "ssim": 0.7830952405929565,
      "attention_bam_384_mean_attention": 0.15864236652851105,
      "attention_bam_384_std_attention": 0.553508996963501,
      "attention_bam_384_max_attention": 4.216187000274658,
      "attention_bam_384_min_attention": -1.439873456954956,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.7776492631847134,
      "attention_bam_384_attention_skewness": 0.8451372262525401,
      "attention_bam_384_attention_sparsity": 0.4969126383463542,
      "attention_bam_384_attention_concentration_10": 0.7945416198401891,
      "attention_bam_384_attention_concentration_20": 1.2329331299366075,
      "attention_bam_384_attention_center_y": 0.48405000299005285,
      "attention_bam_384_attention_center_x": 0.47860207414850175,
      "attention_bam_384_attention_center_distance": 0.03774317515428557,
      "attention_bam_384_attention_spatial_variance": 171.4512663125805,
      "attention_bam_384_attention_spatial_std": 13.093940060676179,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 18.302176666235663,
      "attention_bam_384_peak_intensity_mean": 0.28640443086624146,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19230026006698608,
      "attention_bam_16_std_attention": 0.6618496775627136,
      "attention_bam_16_max_attention": 4.081779479980469,
      "attention_bam_16_min_attention": -1.2937555313110352,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.8339558591722884,
      "attention_bam_16_attention_skewness": 0.9881238003669277,
      "attention_bam_16_attention_sparsity": 0.49365234375,
      "attention_bam_16_attention_concentration_10": 0.802600950377302,
      "attention_bam_16_attention_concentration_20": 1.2430985942401729,
      "attention_bam_16_attention_center_y": 0.46850301024228,
      "attention_bam_16_attention_center_x": 0.46002325046599307,
      "attention_bam_16_attention_center_distance": 0.07197500770548954,
      "attention_bam_16_attention_spatial_variance": 43.1597086297388,
      "attention_bam_16_attention_spatial_std": 6.569604906669715,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.321258659509663,
      "attention_bam_16_peak_intensity_mean": 0.28736454248428345,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 175,
      "phase": "train",
      "loss": 0.008600165136158466,
      "timestamp": 1759543908.0992699,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008600165136158466,
      "ssim": 0.8236581683158875,
      "attention_bam_384_mean_attention": 0.1621374636888504,
      "attention_bam_384_std_attention": 0.45458126068115234,
      "attention_bam_384_max_attention": 3.5133228302001953,
      "attention_bam_384_min_attention": -1.3576223850250244,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5666928107450224,
      "attention_bam_384_attention_skewness": 0.4909044560820296,
      "attention_bam_384_attention_sparsity": 0.47193145751953125,
      "attention_bam_384_attention_concentration_10": 0.6412652038370223,
      "attention_bam_384_attention_concentration_20": 1.0266432967831634,
      "attention_bam_384_attention_center_y": 0.4812345147281321,
      "attention_bam_384_attention_center_x": 0.48227977752041423,
      "attention_bam_384_attention_center_distance": 0.03650067731466657,
      "attention_bam_384_attention_spatial_variance": 170.32365449919817,
      "attention_bam_384_attention_spatial_std": 13.050810492042176,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 19.14210997688359,
      "attention_bam_384_peak_intensity_mean": 0.3144693374633789,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2077992558479309,
      "attention_bam_16_std_attention": 0.5556672811508179,
      "attention_bam_16_max_attention": 2.610626220703125,
      "attention_bam_16_min_attention": -1.0880987644195557,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.15037516847277166,
      "attention_bam_16_attention_skewness": 0.4684127704175472,
      "attention_bam_16_attention_sparsity": 0.450439453125,
      "attention_bam_16_attention_concentration_10": 0.6055558870052506,
      "attention_bam_16_attention_concentration_20": 0.988553386063509,
      "attention_bam_16_attention_center_y": 0.46263719497325306,
      "attention_bam_16_attention_center_x": 0.4670555229148019,
      "attention_bam_16_attention_center_distance": 0.07044597603673113,
      "attention_bam_16_attention_spatial_variance": 42.309935369512154,
      "attention_bam_16_attention_spatial_std": 6.5046087791282385,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.281009094040458,
      "attention_bam_16_peak_intensity_mean": 0.35489416122436523,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 176,
      "phase": "train",
      "loss": 0.009172128513455391,
      "timestamp": 1759543908.2298853,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.009172128513455391,
      "ssim": 0.8056057095527649,
      "attention_bam_384_mean_attention": 0.15785343945026398,
      "attention_bam_384_std_attention": 0.5149142146110535,
      "attention_bam_384_max_attention": 4.145018577575684,
      "attention_bam_384_min_attention": -1.4152905941009521,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.158408886955785,
      "attention_bam_384_attention_skewness": 0.7369271152186686,
      "attention_bam_384_attention_sparsity": 0.4940643310546875,
      "attention_bam_384_attention_concentration_10": 0.7492840644208342,
      "attention_bam_384_attention_concentration_20": 1.1730575749711123,
      "attention_bam_384_attention_center_y": 0.4900514824078671,
      "attention_bam_384_attention_center_x": 0.4817954245933698,
      "attention_bam_384_attention_center_distance": 0.029338696904145613,
      "attention_bam_384_attention_spatial_variance": 172.88990517374242,
      "attention_bam_384_attention_spatial_std": 13.148760594586184,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 19.446851117395656,
      "attention_bam_384_peak_intensity_mean": 0.2855428457260132,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18913693726062775,
      "attention_bam_16_std_attention": 0.6189548373222351,
      "attention_bam_16_max_attention": 3.16576886177063,
      "attention_bam_16_min_attention": -1.2202317714691162,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7778845287644409,
      "attention_bam_16_attention_skewness": 0.8155441371759671,
      "attention_bam_16_attention_sparsity": 0.499267578125,
      "attention_bam_16_attention_concentration_10": 0.7640719732757059,
      "attention_bam_16_attention_concentration_20": 1.205057841991289,
      "attention_bam_16_attention_center_y": 0.48035579646433235,
      "attention_bam_16_attention_center_x": 0.4641966061355847,
      "attention_bam_16_attention_center_distance": 0.057754268149829174,
      "attention_bam_16_attention_spatial_variance": 43.89764638195277,
      "attention_bam_16_attention_spatial_std": 6.625529894427522,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.882985272352803,
      "attention_bam_16_peak_intensity_mean": 0.33165329694747925,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 177,
      "phase": "train",
      "loss": 0.010124437510967255,
      "timestamp": 1759543908.360752,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.010124437510967255,
      "ssim": 0.8309708833694458,
      "attention_bam_384_mean_attention": 0.15780293941497803,
      "attention_bam_384_std_attention": 0.5154240131378174,
      "attention_bam_384_max_attention": 3.552849054336548,
      "attention_bam_384_min_attention": -1.3863630294799805,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.97154654303516,
      "attention_bam_384_attention_skewness": 0.6698221291994904,
      "attention_bam_384_attention_sparsity": 0.4918365478515625,
      "attention_bam_384_attention_concentration_10": 0.7408378136707205,
      "attention_bam_384_attention_concentration_20": 1.1690529484358294,
      "attention_bam_384_attention_center_y": 0.4784866387435174,
      "attention_bam_384_attention_center_x": 0.48142815247590454,
      "attention_bam_384_attention_center_distance": 0.040192990259749976,
      "attention_bam_384_attention_spatial_variance": 170.817289456797,
      "attention_bam_384_attention_spatial_std": 13.069708851263558,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 17.582977087227313,
      "attention_bam_384_peak_intensity_mean": 0.3171423375606537,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19429050385951996,
      "attention_bam_16_std_attention": 0.6308012008666992,
      "attention_bam_16_max_attention": 3.508965492248535,
      "attention_bam_16_min_attention": -1.319667100906372,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8467775753568803,
      "attention_bam_16_attention_skewness": 0.8173248354463866,
      "attention_bam_16_attention_sparsity": 0.491455078125,
      "attention_bam_16_attention_concentration_10": 0.7530931774484186,
      "attention_bam_16_attention_concentration_20": 1.1906878146033852,
      "attention_bam_16_attention_center_y": 0.45625755459183753,
      "attention_bam_16_attention_center_x": 0.4624779251506565,
      "attention_bam_16_attention_center_distance": 0.0815022408438665,
      "attention_bam_16_attention_spatial_variance": 42.372406544208104,
      "attention_bam_16_attention_spatial_std": 6.509409077958467,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.8282069970942,
      "attention_bam_16_peak_intensity_mean": 0.3199658989906311,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 178,
      "phase": "train",
      "loss": 0.013340703211724758,
      "timestamp": 1759543908.4923792,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.013340703211724758,
      "ssim": 0.8164659738540649,
      "attention_bam_384_mean_attention": 0.15076841413974762,
      "attention_bam_384_std_attention": 0.5074009895324707,
      "attention_bam_384_max_attention": 5.111636161804199,
      "attention_bam_384_min_attention": -1.5416643619537354,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 4.7561157874919635,
      "attention_bam_384_attention_skewness": 1.2688570959856738,
      "attention_bam_384_attention_sparsity": 0.5011062622070312,
      "attention_bam_384_attention_concentration_10": 0.7795116323904192,
      "attention_bam_384_attention_concentration_20": 1.1788048715785204,
      "attention_bam_384_attention_center_y": 0.48444244089807986,
      "attention_bam_384_attention_center_x": 0.4808137300167587,
      "attention_bam_384_attention_center_distance": 0.034932809823418565,
      "attention_bam_384_attention_spatial_variance": 169.34158666595687,
      "attention_bam_384_attention_spatial_std": 13.013131316710703,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 17.703980983837702,
      "attention_bam_384_peak_intensity_mean": 0.25646811723709106,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16986311972141266,
      "attention_bam_16_std_attention": 0.6436349749565125,
      "attention_bam_16_max_attention": 4.457035064697266,
      "attention_bam_16_min_attention": -1.3536083698272705,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 6.117594259497759,
      "attention_bam_16_attention_skewness": 1.7351754749211359,
      "attention_bam_16_attention_sparsity": 0.521484375,
      "attention_bam_16_attention_concentration_10": 0.9011260407398265,
      "attention_bam_16_attention_concentration_20": 1.3299579860749688,
      "attention_bam_16_attention_center_y": 0.4697044053194732,
      "attention_bam_16_attention_center_x": 0.46044532990692844,
      "attention_bam_16_attention_center_distance": 0.07046126571696669,
      "attention_bam_16_attention_spatial_variance": 41.70682843975733,
      "attention_bam_16_attention_spatial_std": 6.458082411966987,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.513023058440215,
      "attention_bam_16_peak_intensity_mean": 0.2646504044532776,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 179,
      "phase": "train",
      "loss": 0.00822908990085125,
      "timestamp": 1759543908.622947,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00822908990085125,
      "ssim": 0.8320255279541016,
      "attention_bam_384_mean_attention": 0.15759141743183136,
      "attention_bam_384_std_attention": 0.4871453046798706,
      "attention_bam_384_max_attention": 3.5271472930908203,
      "attention_bam_384_min_attention": -1.3720998764038086,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1469816088361187,
      "attention_bam_384_attention_skewness": 0.7620305370834044,
      "attention_bam_384_attention_sparsity": 0.4950154622395833,
      "attention_bam_384_attention_concentration_10": 0.7165665049049278,
      "attention_bam_384_attention_concentration_20": 1.1286549545399773,
      "attention_bam_384_attention_center_y": 0.48721432085453953,
      "attention_bam_384_attention_center_x": 0.48489892415545927,
      "attention_bam_384_attention_center_distance": 0.02798271190836351,
      "attention_bam_384_attention_spatial_variance": 174.43347843800723,
      "attention_bam_384_attention_spatial_std": 13.20732669536145,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 23.121545967567652,
      "attention_bam_384_peak_intensity_mean": 0.32092756032943726,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19249579310417175,
      "attention_bam_16_std_attention": 0.6230990886688232,
      "attention_bam_16_max_attention": 3.1378655433654785,
      "attention_bam_16_min_attention": -1.0766228437423706,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6619117970040418,
      "attention_bam_16_attention_skewness": 0.8246506584807197,
      "attention_bam_16_attention_sparsity": 0.503662109375,
      "attention_bam_16_attention_concentration_10": 0.7532566909128633,
      "attention_bam_16_attention_concentration_20": 1.2005219932633906,
      "attention_bam_16_attention_center_y": 0.4770867524823968,
      "attention_bam_16_attention_center_x": 0.47103003330714266,
      "attention_bam_16_attention_center_distance": 0.052235541195400914,
      "attention_bam_16_attention_spatial_variance": 45.066126391784685,
      "attention_bam_16_attention_spatial_std": 6.7131308933898115,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 11.763384504675026,
      "attention_bam_16_peak_intensity_mean": 0.32754188776016235,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 180,
      "phase": "train",
      "loss": 0.011679391376674175,
      "timestamp": 1759543908.7931948,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.011679391376674175,
      "ssim": 0.7841788530349731,
      "attention_bam_384_mean_attention": 0.15437227487564087,
      "attention_bam_384_std_attention": 0.47519320249557495,
      "attention_bam_384_max_attention": 3.73545503616333,
      "attention_bam_384_min_attention": -1.4435107707977295,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4559564680166819,
      "attention_bam_384_attention_skewness": 0.666381426481583,
      "attention_bam_384_attention_sparsity": 0.48415883382161456,
      "attention_bam_384_attention_concentration_10": 0.6931301160348834,
      "attention_bam_384_attention_concentration_20": 1.0980651910321364,
      "attention_bam_384_attention_center_y": 0.4800459282901589,
      "attention_bam_384_attention_center_x": 0.48834640576308247,
      "attention_bam_384_attention_center_distance": 0.03267938911424747,
      "attention_bam_384_attention_spatial_variance": 168.2293251857191,
      "attention_bam_384_attention_spatial_std": 12.970324791065146,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 15.228142714957231,
      "attention_bam_384_peak_intensity_mean": 0.3106768727302551,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19374647736549377,
      "attention_bam_16_std_attention": 0.616377055644989,
      "attention_bam_16_max_attention": 3.4913105964660645,
      "attention_bam_16_min_attention": -1.441026210784912,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.031525491389865,
      "attention_bam_16_attention_skewness": 1.0203598006957437,
      "attention_bam_16_attention_sparsity": 0.4853515625,
      "attention_bam_16_attention_concentration_10": 0.7495654934575361,
      "attention_bam_16_attention_concentration_20": 1.1567224571012176,
      "attention_bam_16_attention_center_y": 0.45942204136816533,
      "attention_bam_16_attention_center_x": 0.47656549621815375,
      "attention_bam_16_attention_center_distance": 0.06626834378839193,
      "attention_bam_16_attention_spatial_variance": 40.968665415406356,
      "attention_bam_16_attention_spatial_std": 6.400676949776981,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 7.6534733706505715,
      "attention_bam_16_peak_intensity_mean": 0.34376102685928345,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 181,
      "phase": "train",
      "loss": 0.010697919875383377,
      "timestamp": 1759543908.934704,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.010697919875383377,
      "ssim": 0.8475911617279053,
      "attention_bam_384_mean_attention": 0.15826784074306488,
      "attention_bam_384_std_attention": 0.5174939632415771,
      "attention_bam_384_max_attention": 3.99308180809021,
      "attention_bam_384_min_attention": -1.3210182189941406,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.7818045431878113,
      "attention_bam_384_attention_skewness": 0.8569076358378749,
      "attention_bam_384_attention_sparsity": 0.49546559651692706,
      "attention_bam_384_attention_concentration_10": 0.7516514494754615,
      "attention_bam_384_attention_concentration_20": 1.1733324914091108,
      "attention_bam_384_attention_center_y": 0.4872186955408154,
      "attention_bam_384_attention_center_x": 0.4886299108037966,
      "attention_bam_384_attention_center_distance": 0.024192588617508174,
      "attention_bam_384_attention_spatial_variance": 171.12029367652863,
      "attention_bam_384_attention_spatial_std": 13.081295565674244,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 16.905694186750697,
      "attention_bam_384_peak_intensity_mean": 0.2819007635116577,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18947970867156982,
      "attention_bam_16_std_attention": 0.6574559211730957,
      "attention_bam_16_max_attention": 3.677934169769287,
      "attention_bam_16_min_attention": -1.1572991609573364,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.5956932100926169,
      "attention_bam_16_attention_skewness": 1.0420442174445734,
      "attention_bam_16_attention_sparsity": 0.5107421875,
      "attention_bam_16_attention_concentration_10": 0.8188216393902314,
      "attention_bam_16_attention_concentration_20": 1.2651235064836603,
      "attention_bam_16_attention_center_y": 0.47444412219749965,
      "attention_bam_16_attention_center_x": 0.4788913505107775,
      "attention_bam_16_attention_center_distance": 0.04687596342508989,
      "attention_bam_16_attention_spatial_variance": 42.511578150561974,
      "attention_bam_16_attention_spatial_std": 6.520090348343493,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.61131421104128,
      "attention_bam_16_peak_intensity_mean": 0.29018422961235046,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 182,
      "phase": "train",
      "loss": 0.009238882921636105,
      "timestamp": 1759543909.0644042,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.009238882921636105,
      "ssim": 0.8086845874786377,
      "attention_bam_384_mean_attention": 0.15355491638183594,
      "attention_bam_384_std_attention": 0.49453088641166687,
      "attention_bam_384_max_attention": 3.4040379524230957,
      "attention_bam_384_min_attention": -1.3725483417510986,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0244209564462627,
      "attention_bam_384_attention_skewness": 0.7179103824037614,
      "attention_bam_384_attention_sparsity": 0.4959665934244792,
      "attention_bam_384_attention_concentration_10": 0.7449323764805967,
      "attention_bam_384_attention_concentration_20": 1.1632963593225991,
      "attention_bam_384_attention_center_y": 0.49097811722789314,
      "attention_bam_384_attention_center_x": 0.4814014209098859,
      "attention_bam_384_attention_center_distance": 0.029233594131576345,
      "attention_bam_384_attention_spatial_variance": 172.8733220282785,
      "attention_bam_384_attention_spatial_std": 13.148129982179158,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 17.556154513747554,
      "attention_bam_384_peak_intensity_mean": 0.32239046692848206,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1821173131465912,
      "attention_bam_16_std_attention": 0.6099525094032288,
      "attention_bam_16_max_attention": 2.741161823272705,
      "attention_bam_16_min_attention": -1.1126065254211426,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5108841740269532,
      "attention_bam_16_attention_skewness": 0.7872259460630113,
      "attention_bam_16_attention_sparsity": 0.502197265625,
      "attention_bam_16_attention_concentration_10": 0.7782424617906639,
      "attention_bam_16_attention_concentration_20": 1.2339536459861453,
      "attention_bam_16_attention_center_y": 0.487213763734357,
      "attention_bam_16_attention_center_x": 0.4608624095316745,
      "attention_bam_16_attention_center_distance": 0.05822780822780824,
      "attention_bam_16_attention_spatial_variance": 43.952102421125204,
      "attention_bam_16_attention_spatial_std": 6.629638181765669,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.54667428597862,
      "attention_bam_16_peak_intensity_mean": 0.34746047854423523,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 183,
      "phase": "train",
      "loss": 0.0075522176921367645,
      "timestamp": 1759543909.194525,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0075522176921367645,
      "ssim": 0.8304653167724609,
      "attention_bam_384_mean_attention": 0.15531323850154877,
      "attention_bam_384_std_attention": 0.521289050579071,
      "attention_bam_384_max_attention": 3.860607147216797,
      "attention_bam_384_min_attention": -1.4470109939575195,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2778436613049085,
      "attention_bam_384_attention_skewness": 0.8138542202804372,
      "attention_bam_384_attention_sparsity": 0.5037129720052084,
      "attention_bam_384_attention_concentration_10": 0.7803219988406294,
      "attention_bam_384_attention_concentration_20": 1.2108058017406105,
      "attention_bam_384_attention_center_y": 0.481734794048488,
      "attention_bam_384_attention_center_x": 0.48221927103177276,
      "attention_bam_384_attention_center_distance": 0.03604919058987883,
      "attention_bam_384_attention_spatial_variance": 171.66430021028467,
      "attention_bam_384_attention_spatial_std": 13.102072363190667,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 19.118748033213286,
      "attention_bam_384_peak_intensity_mean": 0.30453571677207947,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19309593737125397,
      "attention_bam_16_std_attention": 0.6663825511932373,
      "attention_bam_16_max_attention": 3.097515106201172,
      "attention_bam_16_min_attention": -1.176264762878418,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7870856267534614,
      "attention_bam_16_attention_skewness": 0.8966041102191346,
      "attention_bam_16_attention_sparsity": 0.506103515625,
      "attention_bam_16_attention_concentration_10": 0.8172320622526743,
      "attention_bam_16_attention_concentration_20": 1.2702218452063119,
      "attention_bam_16_attention_center_y": 0.464449314212895,
      "attention_bam_16_attention_center_x": 0.4605889389798343,
      "attention_bam_16_attention_center_distance": 0.07506108166911396,
      "attention_bam_16_attention_spatial_variance": 43.12915120926892,
      "attention_bam_16_attention_spatial_std": 6.567278828348079,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 11.392054566435036,
      "attention_bam_16_peak_intensity_mean": 0.33214229345321655,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 184,
      "phase": "train",
      "loss": 0.016519859433174133,
      "timestamp": 1759543909.3249657,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.016519859433174133,
      "ssim": 0.7281478643417358,
      "attention_bam_384_mean_attention": 0.156519815325737,
      "attention_bam_384_std_attention": 0.47690701484680176,
      "attention_bam_384_max_attention": 3.564960479736328,
      "attention_bam_384_min_attention": -1.3450160026550293,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.9160081721115763,
      "attention_bam_384_attention_skewness": 0.8678827256685536,
      "attention_bam_384_attention_sparsity": 0.492767333984375,
      "attention_bam_384_attention_concentration_10": 0.7153137257389767,
      "attention_bam_384_attention_concentration_20": 1.1040446057957816,
      "attention_bam_384_attention_center_y": 0.48142657234652403,
      "attention_bam_384_attention_center_x": 0.48135549695855345,
      "attention_bam_384_attention_center_distance": 0.03721799856148676,
      "attention_bam_384_attention_spatial_variance": 169.68776715919242,
      "attention_bam_384_attention_spatial_std": 13.026425724625785,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 18.221791807958045,
      "attention_bam_384_peak_intensity_mean": 0.3103923499584198,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19286702573299408,
      "attention_bam_16_std_attention": 0.6360377669334412,
      "attention_bam_16_max_attention": 2.9409987926483154,
      "attention_bam_16_min_attention": -1.1790739297866821,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.0490171628032972,
      "attention_bam_16_attention_skewness": 0.9295272103708584,
      "attention_bam_16_attention_sparsity": 0.501953125,
      "attention_bam_16_attention_concentration_10": 0.780328834989068,
      "attention_bam_16_attention_concentration_20": 1.2195723477560017,
      "attention_bam_16_attention_center_y": 0.46163168521574954,
      "attention_bam_16_attention_center_x": 0.46174914756027646,
      "attention_bam_16_attention_center_distance": 0.07661925726276438,
      "attention_bam_16_attention_spatial_variance": 41.96072399892804,
      "attention_bam_16_attention_spatial_std": 6.477709780387513,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.729703588398138,
      "attention_bam_16_peak_intensity_mean": 0.3502369523048401,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 185,
      "phase": "train",
      "loss": 0.01074168086051941,
      "timestamp": 1759543909.45575,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.01074168086051941,
      "ssim": 0.8022099733352661,
      "attention_bam_384_mean_attention": 0.15661363303661346,
      "attention_bam_384_std_attention": 0.49218931794166565,
      "attention_bam_384_max_attention": 4.382248878479004,
      "attention_bam_384_min_attention": -1.3799583911895752,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.587388311282428,
      "attention_bam_384_attention_skewness": 0.7492553425627234,
      "attention_bam_384_attention_sparsity": 0.48757171630859375,
      "attention_bam_384_attention_concentration_10": 0.7079239808831508,
      "attention_bam_384_attention_concentration_20": 1.1218276658559463,
      "attention_bam_384_attention_center_y": 0.47874131922087915,
      "attention_bam_384_attention_center_x": 0.4885493649734522,
      "attention_bam_384_attention_center_distance": 0.034148163961764205,
      "attention_bam_384_attention_spatial_variance": 168.3788628609676,
      "attention_bam_384_attention_spatial_std": 12.976088118572854,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 15.088940445890687,
      "attention_bam_384_peak_intensity_mean": 0.2694528102874756,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20632654428482056,
      "attention_bam_16_std_attention": 0.6304484605789185,
      "attention_bam_16_max_attention": 3.4802868366241455,
      "attention_bam_16_min_attention": -1.07463538646698,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.2239261348251702,
      "attention_bam_16_attention_skewness": 0.8424980071730832,
      "attention_bam_16_attention_sparsity": 0.4755859375,
      "attention_bam_16_attention_concentration_10": 0.7079410154513042,
      "attention_bam_16_attention_concentration_20": 1.1190538438184137,
      "attention_bam_16_attention_center_y": 0.45347941343269293,
      "attention_bam_16_attention_center_x": 0.48204930296911336,
      "attention_bam_16_attention_center_distance": 0.07051797640972113,
      "attention_bam_16_attention_spatial_variance": 40.53894451210884,
      "attention_bam_16_attention_spatial_std": 6.367020065313823,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.49195081908737,
      "attention_bam_16_peak_intensity_mean": 0.2895861268043518,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 186,
      "phase": "train",
      "loss": 0.009759718552231789,
      "timestamp": 1759543909.584297,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.009759718552231789,
      "ssim": 0.8289735913276672,
      "attention_bam_384_mean_attention": 0.14991602301597595,
      "attention_bam_384_std_attention": 0.5351817011833191,
      "attention_bam_384_max_attention": 4.029781818389893,
      "attention_bam_384_min_attention": -1.413668155670166,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4979067422221828,
      "attention_bam_384_attention_skewness": 0.8422508894388904,
      "attention_bam_384_attention_sparsity": 0.5060323079427084,
      "attention_bam_384_attention_concentration_10": 0.8115482556834829,
      "attention_bam_384_attention_concentration_20": 1.2687465364381922,
      "attention_bam_384_attention_center_y": 0.4807074376375798,
      "attention_bam_384_attention_center_x": 0.48345651025800634,
      "attention_bam_384_attention_center_distance": 0.035941341526195776,
      "attention_bam_384_attention_spatial_variance": 169.7580576173635,
      "attention_bam_384_attention_spatial_std": 13.02912344010001,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 18.211388397734158,
      "attention_bam_384_peak_intensity_mean": 0.2899209260940552,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18429841101169586,
      "attention_bam_16_std_attention": 0.675880491733551,
      "attention_bam_16_max_attention": 4.2148637771606445,
      "attention_bam_16_min_attention": -1.0542947053909302,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.355567026896571,
      "attention_bam_16_attention_skewness": 0.9781997161854439,
      "attention_bam_16_attention_sparsity": 0.5146484375,
      "attention_bam_16_attention_concentration_10": 0.8585218357143195,
      "attention_bam_16_attention_concentration_20": 1.3347108603866655,
      "attention_bam_16_attention_center_y": 0.45370866753279465,
      "attention_bam_16_attention_center_x": 0.4681222393479705,
      "attention_bam_16_attention_center_distance": 0.07948684275749567,
      "attention_bam_16_attention_spatial_variance": 41.7990646084605,
      "attention_bam_16_attention_spatial_std": 6.465219610226748,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.20942852840964,
      "attention_bam_16_peak_intensity_mean": 0.23076261579990387,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 187,
      "phase": "train",
      "loss": 0.009813033975660801,
      "timestamp": 1759543909.7158713,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.009813033975660801,
      "ssim": 0.8166975378990173,
      "attention_bam_384_mean_attention": 0.1540554016828537,
      "attention_bam_384_std_attention": 0.48788920044898987,
      "attention_bam_384_max_attention": 3.515484094619751,
      "attention_bam_384_min_attention": -1.215493083000183,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5042183999703767,
      "attention_bam_384_attention_skewness": 0.5748536462384537,
      "attention_bam_384_attention_sparsity": 0.49105580647786456,
      "attention_bam_384_attention_concentration_10": 0.7198542661801236,
      "attention_bam_384_attention_concentration_20": 1.1435735415734463,
      "attention_bam_384_attention_center_y": 0.4925429116275196,
      "attention_bam_384_attention_center_x": 0.4821346433627732,
      "attention_bam_384_attention_center_distance": 0.02737806182951184,
      "attention_bam_384_attention_spatial_variance": 169.26640543551582,
      "attention_bam_384_attention_spatial_std": 13.010242328085816,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 18.44318138302434,
      "attention_bam_384_peak_intensity_mean": 0.29241427779197693,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19499416649341583,
      "attention_bam_16_std_attention": 0.6117215752601624,
      "attention_bam_16_max_attention": 2.6606152057647705,
      "attention_bam_16_min_attention": -1.099857211112976,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.05630494347810089,
      "attention_bam_16_attention_skewness": 0.6416904508228523,
      "attention_bam_16_attention_sparsity": 0.49755859375,
      "attention_bam_16_attention_concentration_10": 0.726091651598674,
      "attention_bam_16_attention_concentration_20": 1.1733826426087803,
      "attention_bam_16_attention_center_y": 0.49980089724886084,
      "attention_bam_16_attention_center_x": 0.46456590737785947,
      "attention_bam_16_attention_center_distance": 0.050112165426370175,
      "attention_bam_16_attention_spatial_variance": 41.209983738461105,
      "attention_bam_16_attention_spatial_std": 6.4195002717081575,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 7.3654841049877975,
      "attention_bam_16_peak_intensity_mean": 0.3668877184391022,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 188,
      "phase": "train",
      "loss": 0.009005602449178696,
      "timestamp": 1759543909.8467112,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.009005602449178696,
      "ssim": 0.83002108335495,
      "attention_bam_384_mean_attention": 0.15203024446964264,
      "attention_bam_384_std_attention": 0.5201114416122437,
      "attention_bam_384_max_attention": 4.488273620605469,
      "attention_bam_384_min_attention": -1.3535737991333008,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.331884885757769,
      "attention_bam_384_attention_skewness": 0.9616241501690947,
      "attention_bam_384_attention_sparsity": 0.49873097737630206,
      "attention_bam_384_attention_concentration_10": 0.7927119717795453,
      "attention_bam_384_attention_concentration_20": 1.2118436747839123,
      "attention_bam_384_attention_center_y": 0.47566027064225663,
      "attention_bam_384_attention_center_x": 0.48623702724971857,
      "attention_bam_384_attention_center_distance": 0.03954344052136039,
      "attention_bam_384_attention_spatial_variance": 170.47798748669294,
      "attention_bam_384_attention_spatial_std": 13.056721927294497,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 15.274095441707702,
      "attention_bam_384_peak_intensity_mean": 0.2585636079311371,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20255911350250244,
      "attention_bam_16_std_attention": 0.6596841812133789,
      "attention_bam_16_max_attention": 3.529550552368164,
      "attention_bam_16_min_attention": -1.241339921951294,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.9338398990805539,
      "attention_bam_16_attention_skewness": 1.0974776175764267,
      "attention_bam_16_attention_sparsity": 0.509521484375,
      "attention_bam_16_attention_concentration_10": 0.7807003076079302,
      "attention_bam_16_attention_concentration_20": 1.2002314044967448,
      "attention_bam_16_attention_center_y": 0.4466469922845373,
      "attention_bam_16_attention_center_x": 0.47385447593048635,
      "attention_bam_16_attention_center_distance": 0.08402537546664983,
      "attention_bam_16_attention_spatial_variance": 42.178759355284576,
      "attention_bam_16_attention_spatial_std": 6.494517638384284,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 10.879255457694319,
      "attention_bam_16_peak_intensity_mean": 0.307131290435791,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 189,
      "phase": "train",
      "loss": 0.012292146682739258,
      "timestamp": 1759543909.9761717,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.012292146682739258,
      "ssim": 0.794190526008606,
      "attention_bam_384_mean_attention": 0.1550624668598175,
      "attention_bam_384_std_attention": 0.4586993455886841,
      "attention_bam_384_max_attention": 4.488096714019775,
      "attention_bam_384_min_attention": -1.3030000925064087,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0964114310786677,
      "attention_bam_384_attention_skewness": 0.5730471709950226,
      "attention_bam_384_attention_sparsity": 0.47820790608723956,
      "attention_bam_384_attention_concentration_10": 0.6707008521118537,
      "attention_bam_384_attention_concentration_20": 1.064625831381893,
      "attention_bam_384_attention_center_y": 0.48628538691194184,
      "attention_bam_384_attention_center_x": 0.47863207254655166,
      "attention_bam_384_attention_center_distance": 0.035907629713223,
      "attention_bam_384_attention_spatial_variance": 170.31972882991374,
      "attention_bam_384_attention_spatial_std": 13.050660091731519,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 17.305180327369854,
      "attention_bam_384_peak_intensity_mean": 0.2553086578845978,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20682388544082642,
      "attention_bam_16_std_attention": 0.5732237100601196,
      "attention_bam_16_max_attention": 2.864482879638672,
      "attention_bam_16_min_attention": -1.1348549127578735,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.27985270622772696,
      "attention_bam_16_attention_skewness": 0.5340611271425421,
      "attention_bam_16_attention_sparsity": 0.45361328125,
      "attention_bam_16_attention_concentration_10": 0.6390993158574203,
      "attention_bam_16_attention_concentration_20": 1.026997094164732,
      "attention_bam_16_attention_center_y": 0.4743478312867929,
      "attention_bam_16_attention_center_x": 0.45548863531435574,
      "attention_bam_16_attention_center_distance": 0.07265391036784268,
      "attention_bam_16_attention_spatial_variance": 42.229124888784135,
      "attention_bam_16_attention_spatial_std": 6.49839402381728,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.203113475666694,
      "attention_bam_16_peak_intensity_mean": 0.3487781286239624,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 190,
      "phase": "train",
      "loss": 0.00853176973760128,
      "timestamp": 1759543910.1494718,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00853176973760128,
      "ssim": 0.8311448097229004,
      "attention_bam_384_mean_attention": 0.14852704107761383,
      "attention_bam_384_std_attention": 0.511890709400177,
      "attention_bam_384_max_attention": 4.3653483390808105,
      "attention_bam_384_min_attention": -1.3967338800430298,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7919436116835916,
      "attention_bam_384_attention_skewness": 0.6457235812591122,
      "attention_bam_384_attention_sparsity": 0.49853515625,
      "attention_bam_384_attention_concentration_10": 0.7784388980671216,
      "attention_bam_384_attention_concentration_20": 1.2297802299890326,
      "attention_bam_384_attention_center_y": 0.4803313496261327,
      "attention_bam_384_attention_center_x": 0.4838044016331598,
      "attention_bam_384_attention_center_distance": 0.03603201948238335,
      "attention_bam_384_attention_spatial_variance": 169.65573067977076,
      "attention_bam_384_attention_spatial_std": 13.025195993910064,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 15.3518973379408,
      "attention_bam_384_peak_intensity_mean": 0.26996082067489624,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1812298744916916,
      "attention_bam_16_std_attention": 0.6345568895339966,
      "attention_bam_16_max_attention": 2.79272198677063,
      "attention_bam_16_min_attention": -1.0656991004943848,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.34739737380896596,
      "attention_bam_16_attention_skewness": 0.7350631229357791,
      "attention_bam_16_attention_sparsity": 0.50537109375,
      "attention_bam_16_attention_concentration_10": 0.8062485102214327,
      "attention_bam_16_attention_concentration_20": 1.278397182187114,
      "attention_bam_16_attention_center_y": 0.4569460714760007,
      "attention_bam_16_attention_center_x": 0.4683668228294778,
      "attention_bam_16_attention_center_distance": 0.07555526003199631,
      "attention_bam_16_attention_spatial_variance": 41.621901234478074,
      "attention_bam_16_attention_spatial_std": 6.4515037963623705,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 7.591885193924568,
      "attention_bam_16_peak_intensity_mean": 0.3328935205936432,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 191,
      "phase": "train",
      "loss": 0.009435735642910004,
      "timestamp": 1759543910.4668763,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.009435735642910004,
      "ssim": 0.7934062480926514,
      "attention_bam_384_mean_attention": 0.15299127995967865,
      "attention_bam_384_std_attention": 0.4921712577342987,
      "attention_bam_384_max_attention": 3.790971517562866,
      "attention_bam_384_min_attention": -1.2621790170669556,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.9853569023835256,
      "attention_bam_384_attention_skewness": 0.8713263267707461,
      "attention_bam_384_attention_sparsity": 0.49174245198567706,
      "attention_bam_384_attention_concentration_10": 0.746815239165449,
      "attention_bam_384_attention_concentration_20": 1.1552169339816958,
      "attention_bam_384_attention_center_y": 0.4841578256553989,
      "attention_bam_384_attention_center_x": 0.48975480123570747,
      "attention_bam_384_attention_center_distance": 0.026681026430203123,
      "attention_bam_384_attention_spatial_variance": 170.7550407252798,
      "attention_bam_384_attention_spatial_std": 13.067327221940982,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 20.22036424987237,
      "attention_bam_384_peak_intensity_mean": 0.28179383277893066,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20641207695007324,
      "attention_bam_16_std_attention": 0.638505756855011,
      "attention_bam_16_max_attention": 3.623220682144165,
      "attention_bam_16_min_attention": -1.140231966972351,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.879090987596988,
      "attention_bam_16_attention_skewness": 1.0503809089861385,
      "attention_bam_16_attention_sparsity": 0.4892578125,
      "attention_bam_16_attention_concentration_10": 0.7441296180702163,
      "attention_bam_16_attention_concentration_20": 1.148152479614028,
      "attention_bam_16_attention_center_y": 0.46994598782229097,
      "attention_bam_16_attention_center_x": 0.4824656674962838,
      "attention_bam_16_attention_center_distance": 0.04920765111908436,
      "attention_bam_16_attention_spatial_variance": 42.701187774187325,
      "attention_bam_16_attention_spatial_std": 6.534614584976479,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 10.29715387292591,
      "attention_bam_16_peak_intensity_mean": 0.28934210538864136,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 192,
      "phase": "train",
      "loss": 0.006707347463816404,
      "timestamp": 1759543910.5970812,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006707347463816404,
      "ssim": 0.8558022975921631,
      "attention_bam_384_mean_attention": 0.14633528888225555,
      "attention_bam_384_std_attention": 0.49214819073677063,
      "attention_bam_384_max_attention": 4.283814430236816,
      "attention_bam_384_min_attention": -1.382073163986206,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.696028379362013,
      "attention_bam_384_attention_skewness": 0.8304457575265883,
      "attention_bam_384_attention_sparsity": 0.5024464925130209,
      "attention_bam_384_attention_concentration_10": 0.763829331242676,
      "attention_bam_384_attention_concentration_20": 1.2027526658293337,
      "attention_bam_384_attention_center_y": 0.4899780505353789,
      "attention_bam_384_attention_center_x": 0.482231209736573,
      "attention_bam_384_attention_center_distance": 0.028850281748956163,
      "attention_bam_384_attention_spatial_variance": 170.4416530078137,
      "attention_bam_384_attention_spatial_std": 13.055330444221383,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 17.63758530099728,
      "attention_bam_384_peak_intensity_mean": 0.2710633873939514,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18510985374450684,
      "attention_bam_16_std_attention": 0.6272825598716736,
      "attention_bam_16_max_attention": 4.120862007141113,
      "attention_bam_16_min_attention": -1.312334656715393,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.980911063845955,
      "attention_bam_16_attention_skewness": 1.0498315797450593,
      "attention_bam_16_attention_sparsity": 0.5146484375,
      "attention_bam_16_attention_concentration_10": 0.7914159390524504,
      "attention_bam_16_attention_concentration_20": 1.2403018004568471,
      "attention_bam_16_attention_center_y": 0.4808565240184025,
      "attention_bam_16_attention_center_x": 0.46528754832386404,
      "attention_bam_16_attention_center_distance": 0.056061162564222194,
      "attention_bam_16_attention_spatial_variance": 42.43759067537752,
      "attention_bam_16_attention_spatial_std": 6.514414069997203,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.753855527375539,
      "attention_bam_16_peak_intensity_mean": 0.27612683176994324,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 193,
      "phase": "train",
      "loss": 0.00949489139020443,
      "timestamp": 1759543910.7306983,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00949489139020443,
      "ssim": 0.812744140625,
      "attention_bam_384_mean_attention": 0.15091665089130402,
      "attention_bam_384_std_attention": 0.48192086815834045,
      "attention_bam_384_max_attention": 3.929131031036377,
      "attention_bam_384_min_attention": -1.2138062715530396,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.9369965325805545,
      "attention_bam_384_attention_skewness": 0.8772814491330282,
      "attention_bam_384_attention_sparsity": 0.4930572509765625,
      "attention_bam_384_attention_concentration_10": 0.7355702772710929,
      "attention_bam_384_attention_concentration_20": 1.1464435212542126,
      "attention_bam_384_attention_center_y": 0.4730053084834942,
      "attention_bam_384_attention_center_x": 0.4797501873503538,
      "attention_bam_384_attention_center_distance": 0.04772354308760156,
      "attention_bam_384_attention_spatial_variance": 171.86351127758547,
      "attention_bam_384_attention_spatial_std": 13.109672432123752,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 19.515219756618578,
      "attention_bam_384_peak_intensity_mean": 0.2767146825790405,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19409558176994324,
      "attention_bam_16_std_attention": 0.6015519499778748,
      "attention_bam_16_max_attention": 3.206672191619873,
      "attention_bam_16_min_attention": -0.9898277521133423,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.6548126549923392,
      "attention_bam_16_attention_skewness": 0.9525794858193954,
      "attention_bam_16_attention_sparsity": 0.4853515625,
      "attention_bam_16_attention_concentration_10": 0.7266624155202346,
      "attention_bam_16_attention_concentration_20": 1.1415420665143532,
      "attention_bam_16_attention_center_y": 0.4458923631880066,
      "attention_bam_16_attention_center_x": 0.46170937761597763,
      "attention_bam_16_attention_center_distance": 0.09374228633796357,
      "attention_bam_16_attention_spatial_variance": 43.1859941204716,
      "attention_bam_16_attention_spatial_std": 6.571605140334559,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 10.646670379825284,
      "attention_bam_16_peak_intensity_mean": 0.29802316427230835,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 194,
      "phase": "train",
      "loss": 0.017351647838950157,
      "timestamp": 1759543910.8550882,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.017351647838950157,
      "ssim": 0.8022069931030273,
      "attention_bam_384_mean_attention": 0.147705540060997,
      "attention_bam_384_std_attention": 0.5020759701728821,
      "attention_bam_384_max_attention": 4.210869312286377,
      "attention_bam_384_min_attention": -1.294559121131897,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.0245035543822993,
      "attention_bam_384_attention_skewness": 0.922564997874937,
      "attention_bam_384_attention_sparsity": 0.5017293294270834,
      "attention_bam_384_attention_concentration_10": 0.7855471349344239,
      "attention_bam_384_attention_concentration_20": 1.212751015130679,
      "attention_bam_384_attention_center_y": 0.4948224063987425,
      "attention_bam_384_attention_center_x": 0.4863113021597306,
      "attention_bam_384_attention_center_distance": 0.020697242524644603,
      "attention_bam_384_attention_spatial_variance": 171.348426392829,
      "attention_bam_384_attention_spatial_std": 13.090012467252619,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 17.05981413926973,
      "attention_bam_384_peak_intensity_mean": 0.2707752287387848,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1835981011390686,
      "attention_bam_16_std_attention": 0.6545537710189819,
      "attention_bam_16_max_attention": 4.214827537536621,
      "attention_bam_16_min_attention": -1.3184703588485718,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.566925001903699,
      "attention_bam_16_attention_skewness": 1.1315386948736181,
      "attention_bam_16_attention_sparsity": 0.4951171875,
      "attention_bam_16_attention_concentration_10": 0.834197707004375,
      "attention_bam_16_attention_concentration_20": 1.2761777801415553,
      "attention_bam_16_attention_center_y": 0.4906315078396219,
      "attention_bam_16_attention_center_x": 0.4726202451197807,
      "attention_bam_16_attention_center_distance": 0.04092479988124462,
      "attention_bam_16_attention_spatial_variance": 43.172615603549595,
      "attention_bam_16_attention_spatial_std": 6.570587158203565,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.24379620691304,
      "attention_bam_16_peak_intensity_mean": 0.2938913404941559,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 195,
      "phase": "train",
      "loss": 0.012298354879021645,
      "timestamp": 1759543910.9854186,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.012298354879021645,
      "ssim": 0.8219423294067383,
      "attention_bam_384_mean_attention": 0.14342518150806427,
      "attention_bam_384_std_attention": 0.4766761362552643,
      "attention_bam_384_max_attention": 4.716835975646973,
      "attention_bam_384_min_attention": -1.3502368927001953,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.3032577175715563,
      "attention_bam_384_attention_skewness": 0.961715427070382,
      "attention_bam_384_attention_sparsity": 0.5073750813802084,
      "attention_bam_384_attention_concentration_10": 0.7667528464289681,
      "attention_bam_384_attention_concentration_20": 1.1922115308090595,
      "attention_bam_384_attention_center_y": 0.48053888678442713,
      "attention_bam_384_attention_center_x": 0.4884499266655776,
      "attention_bam_384_attention_center_distance": 0.03200434725533016,
      "attention_bam_384_attention_spatial_variance": 169.88196729205808,
      "attention_bam_384_attention_spatial_std": 13.033877676733738,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 19.429657907791324,
      "attention_bam_384_peak_intensity_mean": 0.2532617747783661,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17728310823440552,
      "attention_bam_16_std_attention": 0.6027597784996033,
      "attention_bam_16_max_attention": 3.4974558353424072,
      "attention_bam_16_min_attention": -1.1651828289031982,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.346804096413873,
      "attention_bam_16_attention_skewness": 0.8966743550329677,
      "attention_bam_16_attention_sparsity": 0.505859375,
      "attention_bam_16_attention_concentration_10": 0.7812984459854138,
      "attention_bam_16_attention_concentration_20": 1.231504997600981,
      "attention_bam_16_attention_center_y": 0.46138051945175074,
      "attention_bam_16_attention_center_x": 0.4783952980663322,
      "attention_bam_16_attention_center_distance": 0.06258158552576361,
      "attention_bam_16_attention_spatial_variance": 42.33082406315534,
      "attention_bam_16_attention_spatial_std": 6.50621426508191,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 7.0935201395395895,
      "attention_bam_16_peak_intensity_mean": 0.31961214542388916,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 196,
      "phase": "train",
      "loss": 0.00983511283993721,
      "timestamp": 1759543911.1175032,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00983511283993721,
      "ssim": 0.8342832326889038,
      "attention_bam_384_mean_attention": 0.14710350334644318,
      "attention_bam_384_std_attention": 0.4745241403579712,
      "attention_bam_384_max_attention": 3.754079580307007,
      "attention_bam_384_min_attention": -1.2847673892974854,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.39002192419398574,
      "attention_bam_384_attention_skewness": 0.4990279483416945,
      "attention_bam_384_attention_sparsity": 0.48823801676432294,
      "attention_bam_384_attention_concentration_10": 0.7148863000646256,
      "attention_bam_384_attention_concentration_20": 1.15299875931272,
      "attention_bam_384_attention_center_y": 0.4872835189424102,
      "attention_bam_384_attention_center_x": 0.48346533552385645,
      "attention_bam_384_attention_center_distance": 0.02949928879911121,
      "attention_bam_384_attention_spatial_variance": 171.01989587051315,
      "attention_bam_384_attention_spatial_std": 13.077457546117792,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 15.759135459023094,
      "attention_bam_384_peak_intensity_mean": 0.2850953936576843,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19524824619293213,
      "attention_bam_16_std_attention": 0.597293496131897,
      "attention_bam_16_max_attention": 2.623300790786743,
      "attention_bam_16_min_attention": -1.2038376331329346,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.029531373200969213,
      "attention_bam_16_attention_skewness": 0.4954963891241227,
      "attention_bam_16_attention_sparsity": 0.46142578125,
      "attention_bam_16_attention_concentration_10": 0.6795678937260747,
      "attention_bam_16_attention_concentration_20": 1.1076593953805085,
      "attention_bam_16_attention_center_y": 0.4744798360515681,
      "attention_bam_16_attention_center_x": 0.4668306901774729,
      "attention_bam_16_attention_center_distance": 0.05918584090908286,
      "attention_bam_16_attention_spatial_variance": 42.7803123854736,
      "attention_bam_16_attention_spatial_std": 6.540666050600168,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.128452192091487,
      "attention_bam_16_peak_intensity_mean": 0.3668041229248047,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 197,
      "phase": "train",
      "loss": 0.008955925703048706,
      "timestamp": 1759543911.2459614,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008955925703048706,
      "ssim": 0.8170914649963379,
      "attention_bam_384_mean_attention": 0.1445036232471466,
      "attention_bam_384_std_attention": 0.4816187918186188,
      "attention_bam_384_max_attention": 3.689765214920044,
      "attention_bam_384_min_attention": -1.3271178007125854,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7170223818199366,
      "attention_bam_384_attention_skewness": 0.6509410083848471,
      "attention_bam_384_attention_sparsity": 0.4989217122395833,
      "attention_bam_384_attention_concentration_10": 0.7598208220682386,
      "attention_bam_384_attention_concentration_20": 1.1938825856435704,
      "attention_bam_384_attention_center_y": 0.4889265114647527,
      "attention_bam_384_attention_center_x": 0.4878289418942422,
      "attention_bam_384_attention_center_distance": 0.02327044493575429,
      "attention_bam_384_attention_spatial_variance": 171.59884140764714,
      "attention_bam_384_attention_spatial_std": 13.099574092604962,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 18.3880140974965,
      "attention_bam_384_peak_intensity_mean": 0.29613032937049866,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.189358651638031,
      "attention_bam_16_std_attention": 0.5930258631706238,
      "attention_bam_16_max_attention": 2.818603515625,
      "attention_bam_16_min_attention": -1.1211920976638794,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.4372713765100338,
      "attention_bam_16_attention_skewness": 0.6826282530799811,
      "attention_bam_16_attention_sparsity": 0.47607421875,
      "attention_bam_16_attention_concentration_10": 0.7263033178991324,
      "attention_bam_16_attention_concentration_20": 1.1502917456462847,
      "attention_bam_16_attention_center_y": 0.48007753339268666,
      "attention_bam_16_attention_center_x": 0.47836839208946136,
      "attention_bam_16_attention_center_distance": 0.04158920861268685,
      "attention_bam_16_attention_spatial_variance": 43.30517348252322,
      "attention_bam_16_attention_spatial_std": 6.580666644233183,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.268595202212415,
      "attention_bam_16_peak_intensity_mean": 0.3410319685935974,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 198,
      "phase": "train",
      "loss": 0.008614829741418362,
      "timestamp": 1759543911.377339,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008614829741418362,
      "ssim": 0.8165087103843689,
      "attention_bam_384_mean_attention": 0.13887996971607208,
      "attention_bam_384_std_attention": 0.4952761232852936,
      "attention_bam_384_max_attention": 4.90936279296875,
      "attention_bam_384_min_attention": -1.3608472347259521,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.7437818065960906,
      "attention_bam_384_attention_skewness": 1.1423822368578416,
      "attention_bam_384_attention_sparsity": 0.5080490112304688,
      "attention_bam_384_attention_concentration_10": 0.8222820182606422,
      "attention_bam_384_attention_concentration_20": 1.2462138368520554,
      "attention_bam_384_attention_center_y": 0.48201924346248337,
      "attention_bam_384_attention_center_x": 0.4792176771263824,
      "attention_bam_384_attention_center_distance": 0.03886418787739519,
      "attention_bam_384_attention_spatial_variance": 169.7848832879808,
      "attention_bam_384_attention_spatial_std": 13.030152849755094,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 16.471073349806726,
      "attention_bam_384_peak_intensity_mean": 0.2403397560119629,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1755947470664978,
      "attention_bam_16_std_attention": 0.6101706624031067,
      "attention_bam_16_max_attention": 4.499420166015625,
      "attention_bam_16_min_attention": -1.066493272781372,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.6634448899744942,
      "attention_bam_16_attention_skewness": 1.2802626348179562,
      "attention_bam_16_attention_sparsity": 0.499267578125,
      "attention_bam_16_attention_concentration_10": 0.8208502673519295,
      "attention_bam_16_attention_concentration_20": 1.2402783986608235,
      "attention_bam_16_attention_center_y": 0.4619253324042445,
      "attention_bam_16_attention_center_x": 0.45899409119812384,
      "attention_bam_16_attention_center_distance": 0.079134883195656,
      "attention_bam_16_attention_spatial_variance": 41.93830187607725,
      "attention_bam_16_attention_spatial_std": 6.4759788353635965,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.383604530663076,
      "attention_bam_16_peak_intensity_mean": 0.2273620367050171,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 199,
      "phase": "train",
      "loss": 0.007519576698541641,
      "timestamp": 1759543911.5173364,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007519576698541641,
      "ssim": 0.8390247821807861,
      "attention_bam_384_mean_attention": 0.14188824594020844,
      "attention_bam_384_std_attention": 0.47779011726379395,
      "attention_bam_384_max_attention": 3.660221576690674,
      "attention_bam_384_min_attention": -1.4077683687210083,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8068839570945183,
      "attention_bam_384_attention_skewness": 0.8743367004041966,
      "attention_bam_384_attention_sparsity": 0.5031077067057291,
      "attention_bam_384_attention_concentration_10": 0.7779949055298013,
      "attention_bam_384_attention_concentration_20": 1.2007502938118844,
      "attention_bam_384_attention_center_y": 0.4774826143818948,
      "attention_bam_384_attention_center_x": 0.4818585635821838,
      "attention_bam_384_attention_center_distance": 0.040893627141062386,
      "attention_bam_384_attention_spatial_variance": 169.61064769732602,
      "attention_bam_384_attention_spatial_std": 13.023465272243252,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 17.590857311039418,
      "attention_bam_384_peak_intensity_mean": 0.3048146069049835,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19306091964244843,
      "attention_bam_16_std_attention": 0.6028867363929749,
      "attention_bam_16_max_attention": 3.5798587799072266,
      "attention_bam_16_min_attention": -1.2818440198898315,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.3807082501532673,
      "attention_bam_16_attention_skewness": 0.9163019242940298,
      "attention_bam_16_attention_sparsity": 0.48681640625,
      "attention_bam_16_attention_concentration_10": 0.736296164445746,
      "attention_bam_16_attention_concentration_20": 1.1411407090832693,
      "attention_bam_16_attention_center_y": 0.4570575004693984,
      "attention_bam_16_attention_center_x": 0.4655837900287233,
      "attention_bam_16_attention_center_distance": 0.07782716459852206,
      "attention_bam_16_attention_spatial_variance": 42.02114590920369,
      "attention_bam_16_attention_spatial_std": 6.48237193542639,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.546863316031624,
      "attention_bam_16_peak_intensity_mean": 0.3038835823535919,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 200,
      "phase": "train",
      "loss": 0.012391421012580395,
      "timestamp": 1759543911.730621,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.012391421012580395,
      "ssim": 0.8507910966873169,
      "attention_bam_384_mean_attention": 0.14395858347415924,
      "attention_bam_384_std_attention": 0.47958746552467346,
      "attention_bam_384_max_attention": 3.54939866065979,
      "attention_bam_384_min_attention": -1.2895009517669678,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8785932480547953,
      "attention_bam_384_attention_skewness": 0.636993790960357,
      "attention_bam_384_attention_sparsity": 0.4995981852213542,
      "attention_bam_384_attention_concentration_10": 0.7373112019621445,
      "attention_bam_384_attention_concentration_20": 1.1836673545483163,
      "attention_bam_384_attention_center_y": 0.484133136667208,
      "attention_bam_384_attention_center_x": 0.48278204651647294,
      "attention_bam_384_attention_center_distance": 0.03311239267049126,
      "attention_bam_384_attention_spatial_variance": 167.34679307529623,
      "attention_bam_384_attention_spatial_std": 12.936258851588285,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 15.19542198032123,
      "attention_bam_384_peak_intensity_mean": 0.3000822365283966,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2035994678735733,
      "attention_bam_16_std_attention": 0.5996523499488831,
      "attention_bam_16_max_attention": 2.849184036254883,
      "attention_bam_16_min_attention": -1.2806262969970703,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.4820705119106825,
      "attention_bam_16_attention_skewness": 0.6197650567441203,
      "attention_bam_16_attention_sparsity": 0.47216796875,
      "attention_bam_16_attention_concentration_10": 0.6629999906970969,
      "attention_bam_16_attention_concentration_20": 1.0716943872042028,
      "attention_bam_16_attention_center_y": 0.4684966499822603,
      "attention_bam_16_attention_center_x": 0.46770131095994766,
      "attention_bam_16_attention_center_distance": 0.06380699610616716,
      "attention_bam_16_attention_spatial_variance": 41.2339227301045,
      "attention_bam_16_attention_spatial_std": 6.4213645535901875,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 7.329997783660099,
      "attention_bam_16_peak_intensity_mean": 0.36567845940589905,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 201,
      "phase": "train",
      "loss": 0.007504624780267477,
      "timestamp": 1759543913.9554021,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007504624780267477,
      "ssim": 0.8457408547401428,
      "attention_bam_384_mean_attention": 0.14505413174629211,
      "attention_bam_384_std_attention": 0.49353283643722534,
      "attention_bam_384_max_attention": 4.463116645812988,
      "attention_bam_384_min_attention": -1.4484611749649048,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.4574995636771417,
      "attention_bam_384_attention_skewness": 0.9135135768808836,
      "attention_bam_384_attention_sparsity": 0.5004119873046875,
      "attention_bam_384_attention_concentration_10": 0.7771692154578398,
      "attention_bam_384_attention_concentration_20": 1.20152117294853,
      "attention_bam_384_attention_center_y": 0.4852565341943822,
      "attention_bam_384_attention_center_x": 0.48247325362936705,
      "attention_bam_384_attention_center_distance": 0.032390017669088014,
      "attention_bam_384_attention_spatial_variance": 170.0989004135916,
      "attention_bam_384_attention_spatial_std": 13.042196916685148,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 17.22062614829871,
      "attention_bam_384_peak_intensity_mean": 0.27108892798423767,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2000674605369568,
      "attention_bam_16_std_attention": 0.6083325147628784,
      "attention_bam_16_max_attention": 3.9837355613708496,
      "attention_bam_16_min_attention": -1.1598223447799683,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.991967808524982,
      "attention_bam_16_attention_skewness": 1.0982809771769833,
      "attention_bam_16_attention_sparsity": 0.469970703125,
      "attention_bam_16_attention_concentration_10": 0.7064481651597428,
      "attention_bam_16_attention_concentration_20": 1.100182030776889,
      "attention_bam_16_attention_center_y": 0.4712976606176873,
      "attention_bam_16_attention_center_x": 0.46535963551507914,
      "attention_bam_16_attention_center_distance": 0.06362042341364328,
      "attention_bam_16_attention_spatial_variance": 42.118390481796716,
      "attention_bam_16_attention_spatial_std": 6.489868294641789,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 7.689147707158228,
      "attention_bam_16_peak_intensity_mean": 0.27098506689071655,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 202,
      "phase": "train",
      "loss": 0.007833022624254227,
      "timestamp": 1759543914.0871758,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007833022624254227,
      "ssim": 0.8590744733810425,
      "attention_bam_384_mean_attention": 0.14339473843574524,
      "attention_bam_384_std_attention": 0.5029557347297668,
      "attention_bam_384_max_attention": 4.846997261047363,
      "attention_bam_384_min_attention": -1.4436633586883545,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.454277362700825,
      "attention_bam_384_attention_skewness": 0.8490973172351725,
      "attention_bam_384_attention_sparsity": 0.5014724731445312,
      "attention_bam_384_attention_concentration_10": 0.7863817648539572,
      "attention_bam_384_attention_concentration_20": 1.229097029239344,
      "attention_bam_384_attention_center_y": 0.48361414714283824,
      "attention_bam_384_attention_center_x": 0.4770526853113457,
      "attention_bam_384_attention_center_distance": 0.03987669558217395,
      "attention_bam_384_attention_spatial_variance": 169.8537923985868,
      "attention_bam_384_attention_spatial_std": 13.032796798791377,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 15.296104646039915,
      "attention_bam_384_peak_intensity_mean": 0.2534787952899933,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20178402960300446,
      "attention_bam_16_std_attention": 0.6279023289680481,
      "attention_bam_16_max_attention": 4.080934047698975,
      "attention_bam_16_min_attention": -1.2787673473358154,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.490307887362855,
      "attention_bam_16_attention_skewness": 1.012302567667483,
      "attention_bam_16_attention_sparsity": 0.481201171875,
      "attention_bam_16_attention_concentration_10": 0.7120443182820436,
      "attention_bam_16_attention_concentration_20": 1.1236403183352552,
      "attention_bam_16_attention_center_y": 0.4663840968554941,
      "attention_bam_16_attention_center_x": 0.45485888289325593,
      "attention_bam_16_attention_center_distance": 0.07959584659849513,
      "attention_bam_16_attention_spatial_variance": 42.103530711207746,
      "attention_bam_16_attention_spatial_std": 6.488723349874592,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 7.894895787316868,
      "attention_bam_16_peak_intensity_mean": 0.2791069746017456,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 203,
      "phase": "train",
      "loss": 0.015508456155657768,
      "timestamp": 1759543914.2192883,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.015508456155657768,
      "ssim": 0.8005753755569458,
      "attention_bam_384_mean_attention": 0.1383049488067627,
      "attention_bam_384_std_attention": 0.42259883880615234,
      "attention_bam_384_max_attention": 3.8458409309387207,
      "attention_bam_384_min_attention": -1.4024103879928589,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 4.169508057486888,
      "attention_bam_384_attention_skewness": 1.12683728084083,
      "attention_bam_384_attention_sparsity": 0.49613698323567706,
      "attention_bam_384_attention_concentration_10": 0.7162424818088197,
      "attention_bam_384_attention_concentration_20": 1.0794477494698578,
      "attention_bam_384_attention_center_y": 0.4797556701004041,
      "attention_bam_384_attention_center_x": 0.48171021871384523,
      "attention_bam_384_attention_center_distance": 0.03858364919442042,
      "attention_bam_384_attention_spatial_variance": 170.510405393903,
      "attention_bam_384_attention_spatial_std": 13.05796329424704,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 17.347553223192396,
      "attention_bam_384_peak_intensity_mean": 0.29600128531455994,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1794079691171646,
      "attention_bam_16_std_attention": 0.5479638576507568,
      "attention_bam_16_max_attention": 3.802489757537842,
      "attention_bam_16_min_attention": -1.1101642847061157,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.552945380436361,
      "attention_bam_16_attention_skewness": 1.1924255852598111,
      "attention_bam_16_attention_sparsity": 0.47216796875,
      "attention_bam_16_attention_concentration_10": 0.7230150005736394,
      "attention_bam_16_attention_concentration_20": 1.095755143419006,
      "attention_bam_16_attention_center_y": 0.45637191680925615,
      "attention_bam_16_attention_center_x": 0.46494450258318915,
      "attention_bam_16_attention_center_distance": 0.07914919509430905,
      "attention_bam_16_attention_spatial_variance": 42.461898449947306,
      "attention_bam_16_attention_spatial_std": 6.516279494462105,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.506230187241222,
      "attention_bam_16_peak_intensity_mean": 0.2716118097305298,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 204,
      "phase": "train",
      "loss": 0.009196639060974121,
      "timestamp": 1759543914.3509638,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.009196639060974121,
      "ssim": 0.8216139674186707,
      "attention_bam_384_mean_attention": 0.13492482900619507,
      "attention_bam_384_std_attention": 0.4715151786804199,
      "attention_bam_384_max_attention": 5.106144905090332,
      "attention_bam_384_min_attention": -1.3426003456115723,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 4.162077033629643,
      "attention_bam_384_attention_skewness": 1.1722459956197577,
      "attention_bam_384_attention_sparsity": 0.5129903157552084,
      "attention_bam_384_attention_concentration_10": 0.7950408990500475,
      "attention_bam_384_attention_concentration_20": 1.2268080540254784,
      "attention_bam_384_attention_center_y": 0.47971695146222676,
      "attention_bam_384_attention_center_x": 0.4830800043071246,
      "attention_bam_384_attention_center_distance": 0.037354740321211895,
      "attention_bam_384_attention_spatial_variance": 170.31597835378145,
      "attention_bam_384_attention_spatial_std": 13.050516401805005,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 17.151469078842187,
      "attention_bam_384_peak_intensity_mean": 0.22992846369743347,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1922927349805832,
      "attention_bam_16_std_attention": 0.616927444934845,
      "attention_bam_16_max_attention": 4.462656497955322,
      "attention_bam_16_min_attention": -1.3186448812484741,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 4.780389788069414,
      "attention_bam_16_attention_skewness": 1.4359166273313169,
      "attention_bam_16_attention_sparsity": 0.4873046875,
      "attention_bam_16_attention_concentration_10": 0.7546555489221247,
      "attention_bam_16_attention_concentration_20": 1.1469423141945305,
      "attention_bam_16_attention_center_y": 0.4602664804916983,
      "attention_bam_16_attention_center_x": 0.46598591832734315,
      "attention_bam_16_attention_center_distance": 0.07396905196838417,
      "attention_bam_16_attention_spatial_variance": 42.33005979224493,
      "attention_bam_16_attention_spatial_std": 6.506155530898791,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.007552191932184,
      "attention_bam_16_peak_intensity_mean": 0.25726109743118286,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 205,
      "phase": "train",
      "loss": 0.008867939934134483,
      "timestamp": 1759543914.481155,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008867939934134483,
      "ssim": 0.8093408942222595,
      "attention_bam_384_mean_attention": 0.13543765246868134,
      "attention_bam_384_std_attention": 0.494917631149292,
      "attention_bam_384_max_attention": 4.63588809967041,
      "attention_bam_384_min_attention": -1.4181973934173584,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.9817502433061192,
      "attention_bam_384_attention_skewness": 0.8734048525702397,
      "attention_bam_384_attention_sparsity": 0.5102132161458334,
      "attention_bam_384_attention_concentration_10": 0.8327203379883427,
      "attention_bam_384_attention_concentration_20": 1.284589543480571,
      "attention_bam_384_attention_center_y": 0.48094253124122216,
      "attention_bam_384_attention_center_x": 0.48405866433062117,
      "attention_bam_384_attention_center_distance": 0.03513725368937086,
      "attention_bam_384_attention_spatial_variance": 170.35626596929424,
      "attention_bam_384_attention_spatial_std": 13.052059836259343,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 14.452733999598713,
      "attention_bam_384_peak_intensity_mean": 0.25683319568634033,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18779432773590088,
      "attention_bam_16_std_attention": 0.6170536279678345,
      "attention_bam_16_max_attention": 4.444238185882568,
      "attention_bam_16_min_attention": -1.372320294380188,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.268428198696598,
      "attention_bam_16_attention_skewness": 1.012964310326288,
      "attention_bam_16_attention_sparsity": 0.484375,
      "attention_bam_16_attention_concentration_10": 0.7686819231135623,
      "attention_bam_16_attention_concentration_20": 1.1813158709782672,
      "attention_bam_16_attention_center_y": 0.4639657875728878,
      "attention_bam_16_attention_center_x": 0.46423647352666686,
      "attention_bam_16_attention_center_distance": 0.0717982491576368,
      "attention_bam_16_attention_spatial_variance": 42.37416330185883,
      "attention_bam_16_attention_spatial_std": 6.509544016431476,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.950691405628502,
      "attention_bam_16_peak_intensity_mean": 0.27100369334220886,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 206,
      "phase": "train",
      "loss": 0.00840152706950903,
      "timestamp": 1759543914.6122339,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00840152706950903,
      "ssim": 0.8228289484977722,
      "attention_bam_384_mean_attention": 0.1325465887784958,
      "attention_bam_384_std_attention": 0.471238911151886,
      "attention_bam_384_max_attention": 3.878072738647461,
      "attention_bam_384_min_attention": -1.3703830242156982,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.3334399546495934,
      "attention_bam_384_attention_skewness": 0.9214267573133625,
      "attention_bam_384_attention_sparsity": 0.5085627237955729,
      "attention_bam_384_attention_concentration_10": 0.8099053735948686,
      "attention_bam_384_attention_concentration_20": 1.2491824667138343,
      "attention_bam_384_attention_center_y": 0.4823528656155446,
      "attention_bam_384_attention_center_x": 0.4905909112291975,
      "attention_bam_384_attention_center_distance": 0.02828258487054782,
      "attention_bam_384_attention_spatial_variance": 170.8578827818668,
      "attention_bam_384_attention_spatial_std": 13.071261713463885,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 19.86435297348198,
      "attention_bam_384_peak_intensity_mean": 0.28779903054237366,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18535752594470978,
      "attention_bam_16_std_attention": 0.5840983986854553,
      "attention_bam_16_max_attention": 3.636023998260498,
      "attention_bam_16_min_attention": -1.1032296419143677,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.7125189797525664,
      "attention_bam_16_attention_skewness": 1.1068508416872047,
      "attention_bam_16_attention_sparsity": 0.48583984375,
      "attention_bam_16_attention_concentration_10": 0.7395065234754575,
      "attention_bam_16_attention_concentration_20": 1.1348035268868075,
      "attention_bam_16_attention_center_y": 0.46576722030371215,
      "attention_bam_16_attention_center_x": 0.4815002277732648,
      "attention_bam_16_attention_center_distance": 0.0550295334920379,
      "attention_bam_16_attention_spatial_variance": 42.949559735268245,
      "attention_bam_16_attention_spatial_std": 6.553591361632814,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 7.901296515851425,
      "attention_bam_16_peak_intensity_mean": 0.2731432318687439,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 207,
      "phase": "train",
      "loss": 0.009956100955605507,
      "timestamp": 1759543914.7428536,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.009956100955605507,
      "ssim": 0.8102021217346191,
      "attention_bam_384_mean_attention": 0.13996027410030365,
      "attention_bam_384_std_attention": 0.44727057218551636,
      "attention_bam_384_max_attention": 3.3968007564544678,
      "attention_bam_384_min_attention": -1.2538071870803833,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2420405185877756,
      "attention_bam_384_attention_skewness": 0.6171240615062648,
      "attention_bam_384_attention_sparsity": 0.48303476969401044,
      "attention_bam_384_attention_concentration_10": 0.7116452193479473,
      "attention_bam_384_attention_concentration_20": 1.126074616524919,
      "attention_bam_384_attention_center_y": 0.4894685054595933,
      "attention_bam_384_attention_center_x": 0.4849534612887511,
      "attention_bam_384_attention_center_distance": 0.02597347510225489,
      "attention_bam_384_attention_spatial_variance": 169.2480382818185,
      "attention_bam_384_attention_spatial_std": 13.00953643608482,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 17.220041687005214,
      "attention_bam_384_peak_intensity_mean": 0.3024619221687317,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2095615118741989,
      "attention_bam_16_std_attention": 0.5744051933288574,
      "attention_bam_16_max_attention": 3.1379787921905518,
      "attention_bam_16_min_attention": -1.0899072885513306,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.9874698006930136,
      "attention_bam_16_attention_skewness": 0.6640271979410144,
      "attention_bam_16_attention_sparsity": 0.452392578125,
      "attention_bam_16_attention_concentration_10": 0.6376306357511896,
      "attention_bam_16_attention_concentration_20": 1.0128529054127995,
      "attention_bam_16_attention_center_y": 0.4761413072841516,
      "attention_bam_16_attention_center_x": 0.4704860290030856,
      "attention_bam_16_attention_center_distance": 0.05367143937171763,
      "attention_bam_16_attention_spatial_variance": 42.31859762427656,
      "attention_bam_16_attention_spatial_std": 6.505274600220698,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.587756881833515,
      "attention_bam_16_peak_intensity_mean": 0.31284552812576294,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 208,
      "phase": "train",
      "loss": 0.007442230358719826,
      "timestamp": 1759543914.8739023,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007442230358719826,
      "ssim": 0.8567006587982178,
      "attention_bam_384_mean_attention": 0.13515399396419525,
      "attention_bam_384_std_attention": 0.4915706515312195,
      "attention_bam_384_max_attention": 3.9395689964294434,
      "attention_bam_384_min_attention": -1.3813108205795288,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.316524083623385,
      "attention_bam_384_attention_skewness": 0.9701774005826872,
      "attention_bam_384_attention_sparsity": 0.5150807698567709,
      "attention_bam_384_attention_concentration_10": 0.8350590777082845,
      "attention_bam_384_attention_concentration_20": 1.2855179405110992,
      "attention_bam_384_attention_center_y": 0.4794959580316606,
      "attention_bam_384_attention_center_x": 0.48836519591347183,
      "attention_bam_384_attention_center_distance": 0.03334019805494008,
      "attention_bam_384_attention_spatial_variance": 173.2606796319607,
      "attention_bam_384_attention_spatial_std": 13.162852260508005,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 19.233837990128492,
      "attention_bam_384_peak_intensity_mean": 0.28608086705207825,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19278064370155334,
      "attention_bam_16_std_attention": 0.6090941429138184,
      "attention_bam_16_max_attention": 4.275623798370361,
      "attention_bam_16_min_attention": -1.1482385396957397,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.345685455681152,
      "attention_bam_16_attention_skewness": 1.038692656907698,
      "attention_bam_16_attention_sparsity": 0.486083984375,
      "attention_bam_16_attention_concentration_10": 0.7393849871092678,
      "attention_bam_16_attention_concentration_20": 1.1487200951522145,
      "attention_bam_16_attention_center_y": 0.4580630164947441,
      "attention_bam_16_attention_center_x": 0.47462378697807533,
      "attention_bam_16_attention_center_distance": 0.06932045546379802,
      "attention_bam_16_attention_spatial_variance": 43.855899485965274,
      "attention_bam_16_attention_spatial_std": 6.6223786879009925,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.293225001673722,
      "attention_bam_16_peak_intensity_mean": 0.24935713410377502,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 209,
      "phase": "train",
      "loss": 0.008819065056741238,
      "timestamp": 1759543915.0039825,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008819065056741238,
      "ssim": 0.7889212369918823,
      "attention_bam_384_mean_attention": 0.13678045570850372,
      "attention_bam_384_std_attention": 0.5199711322784424,
      "attention_bam_384_max_attention": 3.4097723960876465,
      "attention_bam_384_min_attention": -1.3611754179000854,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1336377632455994,
      "attention_bam_384_attention_skewness": 0.7568721154531336,
      "attention_bam_384_attention_sparsity": 0.5143966674804688,
      "attention_bam_384_attention_concentration_10": 0.8556278552383368,
      "attention_bam_384_attention_concentration_20": 1.3358025926930284,
      "attention_bam_384_attention_center_y": 0.4868951176036421,
      "attention_bam_384_attention_center_x": 0.47441875165637076,
      "attention_bam_384_attention_center_distance": 0.04064820314456234,
      "attention_bam_384_attention_spatial_variance": 167.73250350918022,
      "attention_bam_384_attention_spatial_std": 12.951158384838795,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 16.518356023892377,
      "attention_bam_384_peak_intensity_mean": 0.3169579803943634,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19181230664253235,
      "attention_bam_16_std_attention": 0.6569133996963501,
      "attention_bam_16_max_attention": 3.167470932006836,
      "attention_bam_16_min_attention": -1.3829344511032104,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.2516623697161702,
      "attention_bam_16_attention_skewness": 0.914318199440645,
      "attention_bam_16_attention_sparsity": 0.502197265625,
      "attention_bam_16_attention_concentration_10": 0.7968154268449996,
      "attention_bam_16_attention_concentration_20": 1.235947467361132,
      "attention_bam_16_attention_center_y": 0.47152160947987976,
      "attention_bam_16_attention_center_x": 0.4528262013016736,
      "attention_bam_16_attention_center_distance": 0.07792799253473291,
      "attention_bam_16_attention_spatial_variance": 41.26265154670689,
      "attention_bam_16_attention_spatial_std": 6.423601135399589,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.513358824975827,
      "attention_bam_16_peak_intensity_mean": 0.3468717932701111,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 210,
      "phase": "train",
      "loss": 0.008261008188128471,
      "timestamp": 1759543915.178717,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008261008188128471,
      "ssim": 0.8505794405937195,
      "attention_bam_384_mean_attention": 0.13946765661239624,
      "attention_bam_384_std_attention": 0.48086652159690857,
      "attention_bam_384_max_attention": 3.5354511737823486,
      "attention_bam_384_min_attention": -1.3249573707580566,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2825390791207667,
      "attention_bam_384_attention_skewness": 0.6739302431801518,
      "attention_bam_384_attention_sparsity": 0.49725341796875,
      "attention_bam_384_attention_concentration_10": 0.766773125162885,
      "attention_bam_384_attention_concentration_20": 1.2132994911273114,
      "attention_bam_384_attention_center_y": 0.48593116025699756,
      "attention_bam_384_attention_center_x": 0.49267376336514257,
      "attention_bam_384_attention_center_distance": 0.02243238707512921,
      "attention_bam_384_attention_spatial_variance": 168.42814855094616,
      "attention_bam_384_attention_spatial_std": 12.977987076235905,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 17.900611419099853,
      "attention_bam_384_peak_intensity_mean": 0.3051481246948242,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19579678773880005,
      "attention_bam_16_std_attention": 0.6071983575820923,
      "attention_bam_16_max_attention": 3.706533908843994,
      "attention_bam_16_min_attention": -1.1295156478881836,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.5127893607332403,
      "attention_bam_16_attention_skewness": 0.8362190692473871,
      "attention_bam_16_attention_sparsity": 0.477294921875,
      "attention_bam_16_attention_concentration_10": 0.7106242151558689,
      "attention_bam_16_attention_concentration_20": 1.123670327314619,
      "attention_bam_16_attention_center_y": 0.47208029811217456,
      "attention_bam_16_attention_center_x": 0.48692821278590126,
      "attention_bam_16_attention_center_distance": 0.04359773788800788,
      "attention_bam_16_attention_spatial_variance": 41.62320612075522,
      "attention_bam_16_attention_spatial_std": 6.451604925966501,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.462663422835943,
      "attention_bam_16_peak_intensity_mean": 0.27703380584716797,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 211,
      "phase": "train",
      "loss": 0.008133772760629654,
      "timestamp": 1759543915.3107197,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008133772760629654,
      "ssim": 0.8109790682792664,
      "attention_bam_384_mean_attention": 0.1366269737482071,
      "attention_bam_384_std_attention": 0.429181307554245,
      "attention_bam_384_max_attention": 3.2370073795318604,
      "attention_bam_384_min_attention": -1.3290420770645142,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7134842797826138,
      "attention_bam_384_attention_skewness": 0.5858950839714103,
      "attention_bam_384_attention_sparsity": 0.5001653035481771,
      "attention_bam_384_attention_concentration_10": 0.7102871582587961,
      "attention_bam_384_attention_concentration_20": 1.1336927180209333,
      "attention_bam_384_attention_center_y": 0.48499282940460625,
      "attention_bam_384_attention_center_x": 0.48526186654136777,
      "attention_bam_384_attention_center_distance": 0.0297465207082679,
      "attention_bam_384_attention_spatial_variance": 168.62436633027332,
      "attention_bam_384_attention_spatial_std": 12.98554451420014,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 16.320031446737286,
      "attention_bam_384_peak_intensity_mean": 0.323563814163208,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19693982601165771,
      "attention_bam_16_std_attention": 0.5564566850662231,
      "attention_bam_16_max_attention": 2.679421901702881,
      "attention_bam_16_min_attention": -1.0643064975738525,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.42072256381154016,
      "attention_bam_16_attention_skewness": 0.628235075862957,
      "attention_bam_16_attention_sparsity": 0.471923828125,
      "attention_bam_16_attention_concentration_10": 0.6515459419755543,
      "attention_bam_16_attention_concentration_20": 1.0489595962706462,
      "attention_bam_16_attention_center_y": 0.46931731481149047,
      "attention_bam_16_attention_center_x": 0.4716671787744202,
      "attention_bam_16_attention_center_distance": 0.059062271019286856,
      "attention_bam_16_attention_spatial_variance": 41.53125786301622,
      "attention_bam_16_attention_spatial_std": 6.444474987383861,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.045935753708488,
      "attention_bam_16_peak_intensity_mean": 0.3436731696128845,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 212,
      "phase": "train",
      "loss": 0.010335159488022327,
      "timestamp": 1759543915.4431076,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.010335159488022327,
      "ssim": 0.8514715433120728,
      "attention_bam_384_mean_attention": 0.13798673450946808,
      "attention_bam_384_std_attention": 0.4526837468147278,
      "attention_bam_384_max_attention": 3.551018476486206,
      "attention_bam_384_min_attention": -1.3102734088897705,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9659517654278389,
      "attention_bam_384_attention_skewness": 0.6136826235431846,
      "attention_bam_384_attention_sparsity": 0.49946339925130206,
      "attention_bam_384_attention_concentration_10": 0.736142892110849,
      "attention_bam_384_attention_concentration_20": 1.1707187801469383,
      "attention_bam_384_attention_center_y": 0.48669787094620715,
      "attention_bam_384_attention_center_x": 0.48732094193981407,
      "attention_bam_384_attention_center_distance": 0.025988657166438046,
      "attention_bam_384_attention_spatial_variance": 169.31140497406454,
      "attention_bam_384_attention_spatial_std": 13.011971602107982,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 16.587172392856154,
      "attention_bam_384_peak_intensity_mean": 0.3010706305503845,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1986703872680664,
      "attention_bam_16_std_attention": 0.5755923986434937,
      "attention_bam_16_max_attention": 2.9727301597595215,
      "attention_bam_16_min_attention": -1.1389588117599487,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.9883101891106358,
      "attention_bam_16_attention_skewness": 0.7515112377782878,
      "attention_bam_16_attention_sparsity": 0.470703125,
      "attention_bam_16_attention_concentration_10": 0.6706490524156621,
      "attention_bam_16_attention_concentration_20": 1.0692876018128878,
      "attention_bam_16_attention_center_y": 0.4718502352220413,
      "attention_bam_16_attention_center_x": 0.4761635519341372,
      "attention_bam_16_attention_center_distance": 0.052164844741472795,
      "attention_bam_16_attention_spatial_variance": 41.9588491613469,
      "attention_bam_16_attention_spatial_std": 6.477565064231072,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.188670172353264,
      "attention_bam_16_peak_intensity_mean": 0.32940489053726196,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 213,
      "phase": "train",
      "loss": 0.0071368589997291565,
      "timestamp": 1759543915.5752351,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0071368589997291565,
      "ssim": 0.8678572773933411,
      "attention_bam_384_mean_attention": 0.1339748054742813,
      "attention_bam_384_std_attention": 0.464016854763031,
      "attention_bam_384_max_attention": 3.922628402709961,
      "attention_bam_384_min_attention": -1.4318163394927979,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1633332748512561,
      "attention_bam_384_attention_skewness": 0.696915507599391,
      "attention_bam_384_attention_sparsity": 0.5089187622070312,
      "attention_bam_384_attention_concentration_10": 0.7802395845396524,
      "attention_bam_384_attention_concentration_20": 1.229718487127414,
      "attention_bam_384_attention_center_y": 0.487237518681383,
      "attention_bam_384_attention_center_x": 0.4853920857711389,
      "attention_bam_384_attention_center_distance": 0.027432538618429418,
      "attention_bam_384_attention_spatial_variance": 169.61384646780985,
      "attention_bam_384_attention_spatial_std": 13.023588079627283,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 16.997225586240383,
      "attention_bam_384_peak_intensity_mean": 0.2943425476551056,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19117391109466553,
      "attention_bam_16_std_attention": 0.6070590615272522,
      "attention_bam_16_max_attention": 3.323629140853882,
      "attention_bam_16_min_attention": -1.2427978515625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.4759207964576566,
      "attention_bam_16_attention_skewness": 0.8937494118544789,
      "attention_bam_16_attention_sparsity": 0.488525390625,
      "attention_bam_16_attention_concentration_10": 0.7382652151234879,
      "attention_bam_16_attention_concentration_20": 1.1585689783930317,
      "attention_bam_16_attention_center_y": 0.4741247502189748,
      "attention_bam_16_attention_center_x": 0.4731239022524424,
      "attention_bam_16_attention_center_distance": 0.05276084118674976,
      "attention_bam_16_attention_spatial_variance": 42.240152885495654,
      "attention_bam_16_attention_spatial_std": 6.499242485512881,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 7.2116030377781,
      "attention_bam_16_peak_intensity_mean": 0.3226604461669922,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 214,
      "phase": "train",
      "loss": 0.009815896861255169,
      "timestamp": 1759543915.707284,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.009815896861255169,
      "ssim": 0.8291031122207642,
      "attention_bam_384_mean_attention": 0.1375407725572586,
      "attention_bam_384_std_attention": 0.4411123991012573,
      "attention_bam_384_max_attention": 3.671097993850708,
      "attention_bam_384_min_attention": -1.2387478351593018,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.4248072952386597,
      "attention_bam_384_attention_skewness": 0.5159070171393044,
      "attention_bam_384_attention_sparsity": 0.49716949462890625,
      "attention_bam_384_attention_concentration_10": 0.7129958394568163,
      "attention_bam_384_attention_concentration_20": 1.149115209282239,
      "attention_bam_384_attention_center_y": 0.49104608621726453,
      "attention_bam_384_attention_center_x": 0.48350476469463227,
      "attention_bam_384_attention_center_distance": 0.026542997562751275,
      "attention_bam_384_attention_spatial_variance": 169.80320963964795,
      "attention_bam_384_attention_spatial_std": 13.03085605935573,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 16.536504034033634,
      "attention_bam_384_peak_intensity_mean": 0.28190284967422485,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20211347937583923,
      "attention_bam_16_std_attention": 0.5565438866615295,
      "attention_bam_16_max_attention": 2.8918843269348145,
      "attention_bam_16_min_attention": -1.0685179233551025,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.40307320998817486,
      "attention_bam_16_attention_skewness": 0.5954378594583114,
      "attention_bam_16_attention_sparsity": 0.46826171875,
      "attention_bam_16_attention_concentration_10": 0.6268768791940206,
      "attention_bam_16_attention_concentration_20": 1.020278456911299,
      "attention_bam_16_attention_center_y": 0.4859976483201087,
      "attention_bam_16_attention_center_x": 0.46989616786750665,
      "attention_bam_16_attention_center_distance": 0.046953307905379646,
      "attention_bam_16_attention_spatial_variance": 42.23255859924248,
      "attention_bam_16_attention_spatial_std": 6.498658215296638,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 7.815213108919347,
      "attention_bam_16_peak_intensity_mean": 0.33379989862442017,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 215,
      "phase": "train",
      "loss": 0.010383591055870056,
      "timestamp": 1759543915.8406806,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.010383591055870056,
      "ssim": 0.7825644016265869,
      "attention_bam_384_mean_attention": 0.14124812185764313,
      "attention_bam_384_std_attention": 0.45451587438583374,
      "attention_bam_384_max_attention": 3.4672060012817383,
      "attention_bam_384_min_attention": -1.3203827142715454,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8626148121388852,
      "attention_bam_384_attention_skewness": 0.5713293522330193,
      "attention_bam_384_attention_sparsity": 0.49098968505859375,
      "attention_bam_384_attention_concentration_10": 0.7115195398219994,
      "attention_bam_384_attention_concentration_20": 1.1430626095489578,
      "attention_bam_384_attention_center_y": 0.4846408902706839,
      "attention_bam_384_attention_center_x": 0.48540633839650327,
      "attention_bam_384_attention_center_distance": 0.0299625503145025,
      "attention_bam_384_attention_spatial_variance": 169.53463135728936,
      "attention_bam_384_attention_spatial_std": 13.020546507627449,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 17.760836737876133,
      "attention_bam_384_peak_intensity_mean": 0.3059798777103424,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20706364512443542,
      "attention_bam_16_std_attention": 0.5718452334403992,
      "attention_bam_16_max_attention": 3.798508644104004,
      "attention_bam_16_min_attention": -1.1648198366165161,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.40086963558345,
      "attention_bam_16_attention_skewness": 0.7343183213675178,
      "attention_bam_16_attention_sparsity": 0.451416015625,
      "attention_bam_16_attention_concentration_10": 0.6292892258208626,
      "attention_bam_16_attention_concentration_20": 1.0070603317169946,
      "attention_bam_16_attention_center_y": 0.47202480650396356,
      "attention_bam_16_attention_center_x": 0.4746727102222486,
      "attention_bam_16_attention_center_distance": 0.05336821261063311,
      "attention_bam_16_attention_spatial_variance": 42.008377067297396,
      "attention_bam_16_attention_spatial_std": 6.481386970957481,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.640809132024216,
      "attention_bam_16_peak_intensity_mean": 0.27673834562301636,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 216,
      "phase": "train",
      "loss": 0.0076491208747029305,
      "timestamp": 1759543915.9681692,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0076491208747029305,
      "ssim": 0.8519669771194458,
      "attention_bam_384_mean_attention": 0.1364513486623764,
      "attention_bam_384_std_attention": 0.47262170910835266,
      "attention_bam_384_max_attention": 3.2097394466400146,
      "attention_bam_384_min_attention": -1.3886449337005615,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4306563306253812,
      "attention_bam_384_attention_skewness": 0.8087058897250925,
      "attention_bam_384_attention_sparsity": 0.5128555297851562,
      "attention_bam_384_attention_concentration_10": 0.8062789634236953,
      "attention_bam_384_attention_concentration_20": 1.238803017812623,
      "attention_bam_384_attention_center_y": 0.48449459714410326,
      "attention_bam_384_attention_center_x": 0.4753221263228697,
      "attention_bam_384_attention_center_distance": 0.041216864678139994,
      "attention_bam_384_attention_spatial_variance": 171.06078776355633,
      "attention_bam_384_attention_spatial_std": 13.079020902328903,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 15.796004892385021,
      "attention_bam_384_peak_intensity_mean": 0.3347734212875366,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18397152423858643,
      "attention_bam_16_std_attention": 0.6044011116027832,
      "attention_bam_16_max_attention": 3.101771593093872,
      "attention_bam_16_min_attention": -1.1644920110702515,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.0919950316515719,
      "attention_bam_16_attention_skewness": 0.8814322898694597,
      "attention_bam_16_attention_sparsity": 0.50439453125,
      "attention_bam_16_attention_concentration_10": 0.7646345572434677,
      "attention_bam_16_attention_concentration_20": 1.2041157869681096,
      "attention_bam_16_attention_center_y": 0.4696370845516518,
      "attention_bam_16_attention_center_x": 0.4516713511770879,
      "attention_bam_16_attention_center_distance": 0.08071635437223244,
      "attention_bam_16_attention_spatial_variance": 42.60117776421375,
      "attention_bam_16_attention_spatial_std": 6.526957772516515,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.500793774496115,
      "attention_bam_16_peak_intensity_mean": 0.3183252811431885,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 217,
      "phase": "train",
      "loss": 0.008716429583728313,
      "timestamp": 1759543916.1002843,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008716429583728313,
      "ssim": 0.8376187682151794,
      "attention_bam_384_mean_attention": 0.1350044161081314,
      "attention_bam_384_std_attention": 0.4448260962963104,
      "attention_bam_384_max_attention": 3.3900413513183594,
      "attention_bam_384_min_attention": -1.2885005474090576,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5754006507401646,
      "attention_bam_384_attention_skewness": 0.5515994838549786,
      "attention_bam_384_attention_sparsity": 0.49894968668619794,
      "attention_bam_384_attention_concentration_10": 0.7341549920197235,
      "attention_bam_384_attention_concentration_20": 1.173591224128715,
      "attention_bam_384_attention_center_y": 0.4842080158887582,
      "attention_bam_384_attention_center_x": 0.4915655066720525,
      "attention_bam_384_attention_center_distance": 0.025319061588807094,
      "attention_bam_384_attention_spatial_variance": 171.5180604140882,
      "attention_bam_384_attention_spatial_std": 13.096490385369975,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 17.708768996308365,
      "attention_bam_384_peak_intensity_mean": 0.3082263767719269,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19579248130321503,
      "attention_bam_16_std_attention": 0.5715126395225525,
      "attention_bam_16_max_attention": 2.6180131435394287,
      "attention_bam_16_min_attention": -1.056281566619873,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.4454804751209269,
      "attention_bam_16_attention_skewness": 0.7019608061406786,
      "attention_bam_16_attention_sparsity": 0.480712890625,
      "attention_bam_16_attention_concentration_10": 0.6868432686889441,
      "attention_bam_16_attention_concentration_20": 1.0944310973924698,
      "attention_bam_16_attention_center_y": 0.4683932132055539,
      "attention_bam_16_attention_center_x": 0.48566909288519217,
      "attention_bam_16_attention_center_distance": 0.04907879114653953,
      "attention_bam_16_attention_spatial_variance": 43.08257085155008,
      "attention_bam_16_attention_spatial_std": 6.563731473144684,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.566852064091233,
      "attention_bam_16_peak_intensity_mean": 0.3563878536224365,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 218,
      "phase": "train",
      "loss": 0.008928279392421246,
      "timestamp": 1759543916.2357216,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008928279392421246,
      "ssim": 0.8326166868209839,
      "attention_bam_384_mean_attention": 0.13423390686511993,
      "attention_bam_384_std_attention": 0.45164015889167786,
      "attention_bam_384_max_attention": 2.871805429458618,
      "attention_bam_384_min_attention": -1.295610785484314,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8391118384450511,
      "attention_bam_384_attention_skewness": 0.6168841705086398,
      "attention_bam_384_attention_sparsity": 0.5036493937174479,
      "attention_bam_384_attention_concentration_10": 0.7589217866691358,
      "attention_bam_384_attention_concentration_20": 1.200173647548533,
      "attention_bam_384_attention_center_y": 0.4882183785785238,
      "attention_bam_384_attention_center_x": 0.48742653152836585,
      "attention_bam_384_attention_center_distance": 0.02436795899233931,
      "attention_bam_384_attention_spatial_variance": 172.38165097050378,
      "attention_bam_384_attention_spatial_std": 13.129419292965846,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 16.489495114056908,
      "attention_bam_384_peak_intensity_mean": 0.34344619512557983,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20872926712036133,
      "attention_bam_16_std_attention": 0.5717573761940002,
      "attention_bam_16_max_attention": 2.9049854278564453,
      "attention_bam_16_min_attention": -1.128018856048584,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8530275739931286,
      "attention_bam_16_attention_skewness": 0.7922501408664032,
      "attention_bam_16_attention_sparsity": 0.48193359375,
      "attention_bam_16_attention_concentration_10": 0.652391304588508,
      "attention_bam_16_attention_concentration_20": 1.0355116913687858,
      "attention_bam_16_attention_center_y": 0.4782102385901725,
      "attention_bam_16_attention_center_x": 0.47645031130211196,
      "attention_bam_16_attention_center_distance": 0.045373594525112165,
      "attention_bam_16_attention_spatial_variance": 43.445786651086074,
      "attention_bam_16_attention_spatial_std": 6.591341794436553,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.497964787502546,
      "attention_bam_16_peak_intensity_mean": 0.3409404456615448,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 219,
      "phase": "train",
      "loss": 0.006573709659278393,
      "timestamp": 1759543916.3847966,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006573709659278393,
      "ssim": 0.8477177619934082,
      "attention_bam_384_mean_attention": 0.13046623766422272,
      "attention_bam_384_std_attention": 0.4330170750617981,
      "attention_bam_384_max_attention": 3.724935293197632,
      "attention_bam_384_min_attention": -1.3114166259765625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.629929704673293,
      "attention_bam_384_attention_skewness": 0.9584104914814678,
      "attention_bam_384_attention_sparsity": 0.5088551839192709,
      "attention_bam_384_attention_concentration_10": 0.7664275188584103,
      "attention_bam_384_attention_concentration_20": 1.1777661904850618,
      "attention_bam_384_attention_center_y": 0.48894389324965093,
      "attention_bam_384_attention_center_x": 0.4800052157315069,
      "attention_bam_384_attention_center_distance": 0.032311883090240766,
      "attention_bam_384_attention_spatial_variance": 170.47628102708097,
      "attention_bam_384_attention_spatial_std": 13.05665657919672,
      "attention_bam_384_num_attention_peaks": 18,
      "attention_bam_384_peak_separation_mean": 17.67356345876599,
      "attention_bam_384_peak_intensity_mean": 0.2890484631061554,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18211400508880615,
      "attention_bam_16_std_attention": 0.5408937335014343,
      "attention_bam_16_max_attention": 3.4697680473327637,
      "attention_bam_16_min_attention": -1.012907862663269,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.42782476361738,
      "attention_bam_16_attention_skewness": 1.201380786726843,
      "attention_bam_16_attention_sparsity": 0.482421875,
      "attention_bam_16_attention_concentration_10": 0.6964976536269211,
      "attention_bam_16_attention_concentration_20": 1.0782810471661444,
      "attention_bam_16_attention_center_y": 0.47999574533542505,
      "attention_bam_16_attention_center_x": 0.46024566190998756,
      "attention_bam_16_attention_center_distance": 0.06293770891381704,
      "attention_bam_16_attention_spatial_variance": 42.451594581041995,
      "attention_bam_16_attention_spatial_std": 6.515488821342724,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.253947653961136,
      "attention_bam_16_peak_intensity_mean": 0.27819254994392395,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 220,
      "phase": "train",
      "loss": 0.007585862651467323,
      "timestamp": 1759543916.5876906,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007585862651467323,
      "ssim": 0.8481943607330322,
      "attention_bam_384_mean_attention": 0.13177074491977692,
      "attention_bam_384_std_attention": 0.4747800827026367,
      "attention_bam_384_max_attention": 4.001222610473633,
      "attention_bam_384_min_attention": -1.2455739974975586,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.763134168047416,
      "attention_bam_384_attention_skewness": 0.8592191654628965,
      "attention_bam_384_attention_sparsity": 0.5113932291666666,
      "attention_bam_384_attention_concentration_10": 0.8252836504596365,
      "attention_bam_384_attention_concentration_20": 1.2737304305323716,
      "attention_bam_384_attention_center_y": 0.49061871163167237,
      "attention_bam_384_attention_center_x": 0.4831164255132347,
      "attention_bam_384_attention_center_distance": 0.027315331185979484,
      "attention_bam_384_attention_spatial_variance": 171.84318003013365,
      "attention_bam_384_attention_spatial_std": 13.108896979919159,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 17.412332495988576,
      "attention_bam_384_peak_intensity_mean": 0.2639829218387604,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18701305985450745,
      "attention_bam_16_std_attention": 0.6117917895317078,
      "attention_bam_16_max_attention": 4.00971794128418,
      "attention_bam_16_min_attention": -1.0807652473449707,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.814377277561312,
      "attention_bam_16_attention_skewness": 1.1742244197177116,
      "attention_bam_16_attention_sparsity": 0.490478515625,
      "attention_bam_16_attention_concentration_10": 0.7689678933376073,
      "attention_bam_16_attention_concentration_20": 1.1746114056365444,
      "attention_bam_16_attention_center_y": 0.48520279744725636,
      "attention_bam_16_attention_center_x": 0.46893317644607496,
      "attention_bam_16_attention_center_distance": 0.04866425236490609,
      "attention_bam_16_attention_spatial_variance": 43.26512076728686,
      "attention_bam_16_attention_spatial_std": 6.577622729169472,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 10.1116475040631,
      "attention_bam_16_peak_intensity_mean": 0.25709205865859985,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 221,
      "phase": "train",
      "loss": 0.0066953254863619804,
      "timestamp": 1759543916.731933,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0066953254863619804,
      "ssim": 0.8674718141555786,
      "attention_bam_384_mean_attention": 0.13190415501594543,
      "attention_bam_384_std_attention": 0.49865758419036865,
      "attention_bam_384_max_attention": 3.560309648513794,
      "attention_bam_384_min_attention": -1.3141976594924927,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4348551319735128,
      "attention_bam_384_attention_skewness": 0.8004050446938036,
      "attention_bam_384_attention_sparsity": 0.5127766927083334,
      "attention_bam_384_attention_concentration_10": 0.8470606850912445,
      "attention_bam_384_attention_concentration_20": 1.3225771200232548,
      "attention_bam_384_attention_center_y": 0.477619790789429,
      "attention_bam_384_attention_center_x": 0.482373621094825,
      "attention_bam_384_attention_center_distance": 0.04028803786777719,
      "attention_bam_384_attention_spatial_variance": 170.60898525971615,
      "attention_bam_384_attention_spatial_std": 13.061737451798523,
      "attention_bam_384_num_attention_peaks": 19,
      "attention_bam_384_peak_separation_mean": 17.24076952316878,
      "attention_bam_384_peak_intensity_mean": 0.29729798436164856,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1825694739818573,
      "attention_bam_16_std_attention": 0.636785089969635,
      "attention_bam_16_max_attention": 3.6130142211914062,
      "attention_bam_16_min_attention": -1.1391899585723877,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.6782306522588124,
      "attention_bam_16_attention_skewness": 0.9811703542507976,
      "attention_bam_16_attention_sparsity": 0.497802734375,
      "attention_bam_16_attention_concentration_10": 0.8053796799279831,
      "attention_bam_16_attention_concentration_20": 1.2597256944190969,
      "attention_bam_16_attention_center_y": 0.4540344698505598,
      "attention_bam_16_attention_center_x": 0.4646055431411208,
      "attention_bam_16_attention_center_distance": 0.0820438606874903,
      "attention_bam_16_attention_spatial_variance": 42.34874355875019,
      "attention_bam_16_attention_spatial_std": 6.507591225541921,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.026377076997045,
      "attention_bam_16_peak_intensity_mean": 0.28347980976104736,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 222,
      "phase": "train",
      "loss": 0.007730675395578146,
      "timestamp": 1759543916.8645706,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007730675395578146,
      "ssim": 0.8721374273300171,
      "attention_bam_384_mean_attention": 0.13316012918949127,
      "attention_bam_384_std_attention": 0.4650684595108032,
      "attention_bam_384_max_attention": 3.2781763076782227,
      "attention_bam_384_min_attention": -1.3156633377075195,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.818076670862053,
      "attention_bam_384_attention_skewness": 0.6384542046600988,
      "attention_bam_384_attention_sparsity": 0.5062459309895834,
      "attention_bam_384_attention_concentration_10": 0.7867726691740133,
      "attention_bam_384_attention_concentration_20": 1.2377343989484024,
      "attention_bam_384_attention_center_y": 0.4884442958658934,
      "attention_bam_384_attention_center_x": 0.4849489362020423,
      "attention_bam_384_attention_center_distance": 0.026835380358221153,
      "attention_bam_384_attention_spatial_variance": 169.7782794081166,
      "attention_bam_384_attention_spatial_std": 13.029899439677829,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 18.33870100699202,
      "attention_bam_384_peak_intensity_mean": 0.31760090589523315,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1946919858455658,
      "attention_bam_16_std_attention": 0.6002321243286133,
      "attention_bam_16_max_attention": 2.9524481296539307,
      "attention_bam_16_min_attention": -1.2656350135803223,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.40975887638420305,
      "attention_bam_16_attention_skewness": 0.7001480903975414,
      "attention_bam_16_attention_sparsity": 0.482177734375,
      "attention_bam_16_attention_concentration_10": 0.7209982152987168,
      "attention_bam_16_attention_concentration_20": 1.1441532003311716,
      "attention_bam_16_attention_center_y": 0.47878992613818655,
      "attention_bam_16_attention_center_x": 0.4711625238589596,
      "attention_bam_16_attention_center_distance": 0.050625433596338795,
      "attention_bam_16_attention_spatial_variance": 42.21487087604356,
      "attention_bam_16_attention_spatial_std": 6.497297197761817,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.05115312965414,
      "attention_bam_16_peak_intensity_mean": 0.3503398597240448,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 223,
      "phase": "train",
      "loss": 0.010498329997062683,
      "timestamp": 1759543916.9987483,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.010498329997062683,
      "ssim": 0.8489426970481873,
      "attention_bam_384_mean_attention": 0.13188326358795166,
      "attention_bam_384_std_attention": 0.4730830490589142,
      "attention_bam_384_max_attention": 4.012442111968994,
      "attention_bam_384_min_attention": -1.259866714477539,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0840689852390577,
      "attention_bam_384_attention_skewness": 0.6938148450760244,
      "attention_bam_384_attention_sparsity": 0.5088144938151041,
      "attention_bam_384_attention_concentration_10": 0.8032198275899481,
      "attention_bam_384_attention_concentration_20": 1.2649758914787204,
      "attention_bam_384_attention_center_y": 0.47668190565094926,
      "attention_bam_384_attention_center_x": 0.48501538319192594,
      "attention_bam_384_attention_center_distance": 0.03919878225037221,
      "attention_bam_384_attention_spatial_variance": 171.65177193649728,
      "attention_bam_384_attention_spatial_std": 13.101594251712166,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 20.934021255406844,
      "attention_bam_384_peak_intensity_mean": 0.2690623700618744,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1997165083885193,
      "attention_bam_16_std_attention": 0.5976754426956177,
      "attention_bam_16_max_attention": 3.1469528675079346,
      "attention_bam_16_min_attention": -1.137474536895752,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7613845587092838,
      "attention_bam_16_attention_skewness": 0.7631843256433762,
      "attention_bam_16_attention_sparsity": 0.479736328125,
      "attention_bam_16_attention_concentration_10": 0.6944513916016493,
      "attention_bam_16_attention_concentration_20": 1.1115436923694966,
      "attention_bam_16_attention_center_y": 0.450904148618071,
      "attention_bam_16_attention_center_x": 0.4726481534272039,
      "attention_bam_16_attention_center_distance": 0.07947988593170272,
      "attention_bam_16_attention_spatial_variance": 43.07422123676593,
      "attention_bam_16_attention_spatial_std": 6.563095400553456,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.512559545945154,
      "attention_bam_16_peak_intensity_mean": 0.3260394334793091,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 224,
      "phase": "train",
      "loss": 0.00997413881123066,
      "timestamp": 1759543917.134466,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00997413881123066,
      "ssim": 0.8176301717758179,
      "attention_bam_384_mean_attention": 0.13414861261844635,
      "attention_bam_384_std_attention": 0.40455782413482666,
      "attention_bam_384_max_attention": 3.5545811653137207,
      "attention_bam_384_min_attention": -1.3861501216888428,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9932416645910007,
      "attention_bam_384_attention_skewness": 0.5649992163057217,
      "attention_bam_384_attention_sparsity": 0.493927001953125,
      "attention_bam_384_attention_concentration_10": 0.6752312415976336,
      "attention_bam_384_attention_concentration_20": 1.0821111502931706,
      "attention_bam_384_attention_center_y": 0.4817860290804402,
      "attention_bam_384_attention_center_x": 0.47767326435797386,
      "attention_bam_384_attention_center_distance": 0.04074878798412267,
      "attention_bam_384_attention_spatial_variance": 168.28847115045045,
      "attention_bam_384_attention_spatial_std": 12.972604640181187,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 13.909381619009363,
      "attention_bam_384_peak_intensity_mean": 0.313362717628479,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20612859725952148,
      "attention_bam_16_std_attention": 0.5294400453567505,
      "attention_bam_16_max_attention": 2.8051013946533203,
      "attention_bam_16_min_attention": -1.1460700035095215,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.36956379137279116,
      "attention_bam_16_attention_skewness": 0.5585163907246564,
      "attention_bam_16_attention_sparsity": 0.448486328125,
      "attention_bam_16_attention_concentration_10": 0.5884133990279222,
      "attention_bam_16_attention_concentration_20": 0.9630149693489435,
      "attention_bam_16_attention_center_y": 0.46282788178865913,
      "attention_bam_16_attention_center_x": 0.4542411227514469,
      "attention_bam_16_attention_center_distance": 0.08337435120426484,
      "attention_bam_16_attention_spatial_variance": 40.94579701427282,
      "attention_bam_16_attention_spatial_std": 6.398890295533501,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 6.954487912277304,
      "attention_bam_16_peak_intensity_mean": 0.3592725396156311,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 225,
      "phase": "train",
      "loss": 0.01563510112464428,
      "timestamp": 1759543917.2690752,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.01563510112464428,
      "ssim": 0.7729825973510742,
      "attention_bam_384_mean_attention": 0.13401025533676147,
      "attention_bam_384_std_attention": 0.3737199306488037,
      "attention_bam_384_max_attention": 3.8265786170959473,
      "attention_bam_384_min_attention": -1.1596988439559937,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8776776156325461,
      "attention_bam_384_attention_skewness": 0.5452653565577057,
      "attention_bam_384_attention_sparsity": 0.49168141682942706,
      "attention_bam_384_attention_concentration_10": 0.6342566750239014,
      "attention_bam_384_attention_concentration_20": 1.0198713646356374,
      "attention_bam_384_attention_center_y": 0.48918802166760506,
      "attention_bam_384_attention_center_x": 0.4875449988899365,
      "attention_bam_384_attention_center_distance": 0.023324919211515405,
      "attention_bam_384_attention_spatial_variance": 171.4379041770537,
      "attention_bam_384_attention_spatial_std": 13.09342980952866,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 18.622675288142343,
      "attention_bam_384_peak_intensity_mean": 0.2597815990447998,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20580607652664185,
      "attention_bam_16_std_attention": 0.5195553302764893,
      "attention_bam_16_max_attention": 2.540323257446289,
      "attention_bam_16_min_attention": -0.9622884392738342,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6121038162609338,
      "attention_bam_16_attention_skewness": 0.6638616411859803,
      "attention_bam_16_attention_sparsity": 0.46044921875,
      "attention_bam_16_attention_concentration_10": 0.6028880320057951,
      "attention_bam_16_attention_concentration_20": 0.9572279792857651,
      "attention_bam_16_attention_center_y": 0.4820966486240603,
      "attention_bam_16_attention_center_x": 0.4801149935565717,
      "attention_bam_16_attention_center_distance": 0.037840282021822866,
      "attention_bam_16_attention_spatial_variance": 43.25253818786893,
      "attention_bam_16_attention_spatial_std": 6.576666191002013,
      "attention_bam_16_num_attention_peaks": 2,
      "attention_bam_16_peak_separation_mean": 8.527427155296543,
      "attention_bam_16_peak_intensity_mean": 0.3451263904571533,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 226,
      "phase": "train",
      "loss": 0.008171802386641502,
      "timestamp": 1759543917.4002469,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008171802386641502,
      "ssim": 0.8540301322937012,
      "attention_bam_384_mean_attention": 0.1330956518650055,
      "attention_bam_384_std_attention": 0.4719393253326416,
      "attention_bam_384_max_attention": 3.4655466079711914,
      "attention_bam_384_min_attention": -1.490977168083191,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.229124686693827,
      "attention_bam_384_attention_skewness": 0.8394091813059043,
      "attention_bam_384_attention_sparsity": 0.505279541015625,
      "attention_bam_384_attention_concentration_10": 0.7960087915616564,
      "attention_bam_384_attention_concentration_20": 1.2308859774258394,
      "attention_bam_384_attention_center_y": 0.4789184866403141,
      "attention_bam_384_attention_center_x": 0.48064373043439645,
      "attention_bam_384_attention_center_distance": 0.04047456922639016,
      "attention_bam_384_attention_spatial_variance": 169.2303365397765,
      "attention_bam_384_attention_spatial_std": 13.00885608113859,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 18.03609949298975,
      "attention_bam_384_peak_intensity_mean": 0.332861989736557,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1930851936340332,
      "attention_bam_16_std_attention": 0.6161863803863525,
      "attention_bam_16_max_attention": 3.743299961090088,
      "attention_bam_16_min_attention": -1.4154951572418213,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.1591575896257478,
      "attention_bam_16_attention_skewness": 0.9626659870651094,
      "attention_bam_16_attention_sparsity": 0.4765625,
      "attention_bam_16_attention_concentration_10": 0.741022963275552,
      "attention_bam_16_attention_concentration_20": 1.142179709267926,
      "attention_bam_16_attention_center_y": 0.4574914304173079,
      "attention_bam_16_attention_center_x": 0.4623082220850084,
      "attention_bam_16_attention_center_distance": 0.0803448643083007,
      "attention_bam_16_attention_spatial_variance": 41.65567765966588,
      "attention_bam_16_attention_spatial_std": 6.454120982726144,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 9.435245372911181,
      "attention_bam_16_peak_intensity_mean": 0.320027619600296,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 227,
      "phase": "train",
      "loss": 0.008784333243966103,
      "timestamp": 1759543917.531186,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008784333243966103,
      "ssim": 0.8327431678771973,
      "attention_bam_384_mean_attention": 0.12970729172229767,
      "attention_bam_384_std_attention": 0.5003383159637451,
      "attention_bam_384_max_attention": 4.881320953369141,
      "attention_bam_384_min_attention": -1.3673555850982666,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.863175530970456,
      "attention_bam_384_attention_skewness": 1.0142430140015588,
      "attention_bam_384_attention_sparsity": 0.5192286173502604,
      "attention_bam_384_attention_concentration_10": 0.8742819334315682,
      "attention_bam_384_attention_concentration_20": 1.3433511812994203,
      "attention_bam_384_attention_center_y": 0.4848052411764825,
      "attention_bam_384_attention_center_x": 0.47624776258245566,
      "attention_bam_384_attention_center_distance": 0.03987604489024097,
      "attention_bam_384_attention_spatial_variance": 170.5436262956141,
      "attention_bam_384_attention_spatial_std": 13.05923528755088,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 16.58126803671798,
      "attention_bam_384_peak_intensity_mean": 0.2409682720899582,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1824280023574829,
      "attention_bam_16_std_attention": 0.6507234573364258,
      "attention_bam_16_max_attention": 4.836528778076172,
      "attention_bam_16_min_attention": -1.1960928440093994,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.4026645432732643,
      "attention_bam_16_attention_skewness": 1.262092378464825,
      "attention_bam_16_attention_sparsity": 0.507568359375,
      "attention_bam_16_attention_concentration_10": 0.8334168672130883,
      "attention_bam_16_attention_concentration_20": 1.2820659869646245,
      "attention_bam_16_attention_center_y": 0.4686342589382211,
      "attention_bam_16_attention_center_x": 0.4498746802711456,
      "attention_bam_16_attention_center_distance": 0.08362245380607349,
      "attention_bam_16_attention_spatial_variance": 42.25997402814793,
      "attention_bam_16_attention_spatial_std": 6.50076718765931,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 7.412775608852621,
      "attention_bam_16_peak_intensity_mean": 0.22915750741958618,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 228,
      "phase": "train",
      "loss": 0.0059167868457734585,
      "timestamp": 1759543917.6622186,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0059167868457734585,
      "ssim": 0.8731276988983154,
      "attention_bam_384_mean_attention": 0.12893076241016388,
      "attention_bam_384_std_attention": 0.5039969682693481,
      "attention_bam_384_max_attention": 3.684678554534912,
      "attention_bam_384_min_attention": -1.2303731441497803,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.41011684620939,
      "attention_bam_384_attention_skewness": 1.048453723129749,
      "attention_bam_384_attention_sparsity": 0.5242411295572916,
      "attention_bam_384_attention_concentration_10": 0.8946755792901859,
      "attention_bam_384_attention_concentration_20": 1.3650235637984316,
      "attention_bam_384_attention_center_y": 0.4819250994683755,
      "attention_bam_384_attention_center_x": 0.48964230166937234,
      "attention_bam_384_attention_center_distance": 0.029461294741962976,
      "attention_bam_384_attention_spatial_variance": 165.6335767446653,
      "attention_bam_384_attention_spatial_std": 12.869870890753539,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 14.389329546918944,
      "attention_bam_384_peak_intensity_mean": 0.28336217999458313,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16586270928382874,
      "attention_bam_16_std_attention": 0.6690589785575867,
      "attention_bam_16_max_attention": 3.753737449645996,
      "attention_bam_16_min_attention": -1.1553488969802856,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.2563456116477836,
      "attention_bam_16_attention_skewness": 1.4151924087113223,
      "attention_bam_16_attention_sparsity": 0.540771484375,
      "attention_bam_16_attention_concentration_10": 0.9633172033855943,
      "attention_bam_16_attention_concentration_20": 1.4416738583641797,
      "attention_bam_16_attention_center_y": 0.4640306479258831,
      "attention_bam_16_attention_center_x": 0.4822198704083262,
      "attention_bam_16_attention_center_distance": 0.05674376259869433,
      "attention_bam_16_attention_spatial_variance": 39.96175640911426,
      "attention_bam_16_attention_spatial_std": 6.321531175997968,
      "attention_bam_16_num_attention_peaks": 1,
      "attention_bam_16_peak_separation_mean": 0.0,
      "attention_bam_16_peak_intensity_mean": 0.29529517889022827,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 229,
      "phase": "train",
      "loss": 0.010245620273053646,
      "timestamp": 1759543917.7930844,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.010245620273053646,
      "ssim": 0.8144851922988892,
      "attention_bam_384_mean_attention": 0.1347106546163559,
      "attention_bam_384_std_attention": 0.44141867756843567,
      "attention_bam_384_max_attention": 3.4170889854431152,
      "attention_bam_384_min_attention": -1.199782371520996,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.37264485921831847,
      "attention_bam_384_attention_skewness": 0.49069166518001706,
      "attention_bam_384_attention_sparsity": 0.4967905680338542,
      "attention_bam_384_attention_concentration_10": 0.7247733274317073,
      "attention_bam_384_attention_concentration_20": 1.1677242421489344,
      "attention_bam_384_attention_center_y": 0.4786289654797876,
      "attention_bam_384_attention_center_x": 0.4827025661579038,
      "attention_bam_384_attention_center_distance": 0.03888244678478463,
      "attention_bam_384_attention_spatial_variance": 171.90536879680286,
      "attention_bam_384_attention_spatial_std": 13.111268771434855,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 17.083218823477782,
      "attention_bam_384_peak_intensity_mean": 0.28968366980552673,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19186446070671082,
      "attention_bam_16_std_attention": 0.560887336730957,
      "attention_bam_16_max_attention": 3.1413309574127197,
      "attention_bam_16_min_attention": -1.0228081941604614,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5010077117477283,
      "attention_bam_16_attention_skewness": 0.6347168816324997,
      "attention_bam_16_attention_sparsity": 0.4775390625,
      "attention_bam_16_attention_concentration_10": 0.6686845856399547,
      "attention_bam_16_attention_concentration_20": 1.0767257599115418,
      "attention_bam_16_attention_center_y": 0.45446956988954545,
      "attention_bam_16_attention_center_x": 0.46545951272719394,
      "attention_bam_16_attention_center_distance": 0.08082159769623294,
      "attention_bam_16_attention_spatial_variance": 43.28377015592412,
      "attention_bam_16_attention_spatial_std": 6.5790402154055965,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.86937795682205,
      "attention_bam_16_peak_intensity_mean": 0.29536113142967224,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 230,
      "phase": "train",
      "loss": 0.008150190114974976,
      "timestamp": 1759543917.9674156,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008150190114974976,
      "ssim": 0.8043915629386902,
      "attention_bam_384_mean_attention": 0.1334977149963379,
      "attention_bam_384_std_attention": 0.4400249123573303,
      "attention_bam_384_max_attention": 3.2811222076416016,
      "attention_bam_384_min_attention": -1.2105252742767334,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6627276174027652,
      "attention_bam_384_attention_skewness": 0.5998241583772398,
      "attention_bam_384_attention_sparsity": 0.5059026082356771,
      "attention_bam_384_attention_concentration_10": 0.7432250459877497,
      "attention_bam_384_attention_concentration_20": 1.1820354032347031,
      "attention_bam_384_attention_center_y": 0.4842117041856073,
      "attention_bam_384_attention_center_x": 0.48492618418365785,
      "attention_bam_384_attention_center_distance": 0.030870380884847455,
      "attention_bam_384_attention_spatial_variance": 171.08279056914824,
      "attention_bam_384_attention_spatial_std": 13.079862024086808,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 18.016463982297235,
      "attention_bam_384_peak_intensity_mean": 0.3005560338497162,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19148598611354828,
      "attention_bam_16_std_attention": 0.5892837047576904,
      "attention_bam_16_max_attention": 3.3410744667053223,
      "attention_bam_16_min_attention": -1.1293500661849976,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5337088131619034,
      "attention_bam_16_attention_skewness": 0.7180066719660436,
      "attention_bam_16_attention_sparsity": 0.4853515625,
      "attention_bam_16_attention_concentration_10": 0.7167477263469217,
      "attention_bam_16_attention_concentration_20": 1.1405630965473024,
      "attention_bam_16_attention_center_y": 0.46874727502157304,
      "attention_bam_16_attention_center_x": 0.4722101194657837,
      "attention_bam_16_attention_center_distance": 0.05914406612134826,
      "attention_bam_16_attention_spatial_variance": 42.84563278866579,
      "attention_bam_16_attention_spatial_std": 6.545657552046684,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.311615387487384,
      "attention_bam_16_peak_intensity_mean": 0.3014879822731018,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 231,
      "phase": "train",
      "loss": 0.006593569181859493,
      "timestamp": 1759543918.1245456,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006593569181859493,
      "ssim": 0.8286765813827515,
      "attention_bam_384_mean_attention": 0.1276565045118332,
      "attention_bam_384_std_attention": 0.4488396942615509,
      "attention_bam_384_max_attention": 3.6454219818115234,
      "attention_bam_384_min_attention": -1.2578856945037842,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.9304230160857996,
      "attention_bam_384_attention_skewness": 0.9147090676349922,
      "attention_bam_384_attention_sparsity": 0.5216242472330729,
      "attention_bam_384_attention_concentration_10": 0.8122721263680138,
      "attention_bam_384_attention_concentration_20": 1.2540633216716397,
      "attention_bam_384_attention_center_y": 0.4917185903169701,
      "attention_bam_384_attention_center_x": 0.4831550231332586,
      "attention_bam_384_attention_center_distance": 0.026545620805670946,
      "attention_bam_384_attention_spatial_variance": 172.59905241616295,
      "attention_bam_384_attention_spatial_std": 13.137695856433995,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 22.465438993717168,
      "attention_bam_384_peak_intensity_mean": 0.2838350832462311,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16658499836921692,
      "attention_bam_16_std_attention": 0.5975565314292908,
      "attention_bam_16_max_attention": 3.6221678256988525,
      "attention_bam_16_min_attention": -1.0952627658843994,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.539234587771607,
      "attention_bam_16_attention_skewness": 1.1742642185568575,
      "attention_bam_16_attention_sparsity": 0.5185546875,
      "attention_bam_16_attention_concentration_10": 0.8444139317706563,
      "attention_bam_16_attention_concentration_20": 1.2924305839248191,
      "attention_bam_16_attention_center_y": 0.4854625800208289,
      "attention_bam_16_attention_center_x": 0.4689828170881901,
      "attention_bam_16_attention_center_distance": 0.04844382758278856,
      "attention_bam_16_attention_spatial_variance": 43.93249862446573,
      "attention_bam_16_attention_spatial_std": 6.62815952014326,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 11.238593913890009,
      "attention_bam_16_peak_intensity_mean": 0.26884716749191284,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 232,
      "phase": "train",
      "loss": 0.007916438393294811,
      "timestamp": 1759543918.2923317,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007916438393294811,
      "ssim": 0.8501567840576172,
      "attention_bam_384_mean_attention": 0.12769095599651337,
      "attention_bam_384_std_attention": 0.478133887052536,
      "attention_bam_384_max_attention": 3.5820329189300537,
      "attention_bam_384_min_attention": -1.3184800148010254,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5066152236566328,
      "attention_bam_384_attention_skewness": 0.8370715893815621,
      "attention_bam_384_attention_sparsity": 0.5205790201822916,
      "attention_bam_384_attention_concentration_10": 0.847548645566836,
      "attention_bam_384_attention_concentration_20": 1.3206102914997084,
      "attention_bam_384_attention_center_y": 0.47736768370897886,
      "attention_bam_384_attention_center_x": 0.49270477509889105,
      "attention_bam_384_attention_center_distance": 0.03362862016362196,
      "attention_bam_384_attention_spatial_variance": 174.31390303177454,
      "attention_bam_384_attention_spatial_std": 13.202799060493746,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 18.57393158921126,
      "attention_bam_384_peak_intensity_mean": 0.2983597218990326,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17085057497024536,
      "attention_bam_16_std_attention": 0.637872576713562,
      "attention_bam_16_max_attention": 3.6103315353393555,
      "attention_bam_16_min_attention": -1.085226058959961,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.944042845790804,
      "attention_bam_16_attention_skewness": 1.098209059667924,
      "attention_bam_16_attention_sparsity": 0.520263671875,
      "attention_bam_16_attention_concentration_10": 0.8686706691237882,
      "attention_bam_16_attention_concentration_20": 1.347008108069059,
      "attention_bam_16_attention_center_y": 0.4504962856998515,
      "attention_bam_16_attention_center_x": 0.48864928953040243,
      "attention_bam_16_attention_center_distance": 0.07182557145857398,
      "attention_bam_16_attention_spatial_variance": 44.77230454284265,
      "attention_bam_16_attention_spatial_std": 6.691210992252646,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.08721828915318,
      "attention_bam_16_peak_intensity_mean": 0.28345978260040283,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 233,
      "phase": "train",
      "loss": 0.0072007919661700726,
      "timestamp": 1759543918.4454985,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0072007919661700726,
      "ssim": 0.8700513243675232,
      "attention_bam_384_mean_attention": 0.12783847749233246,
      "attention_bam_384_std_attention": 0.49350640177726746,
      "attention_bam_384_max_attention": 3.615260601043701,
      "attention_bam_384_min_attention": -1.363590955734253,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0987389299605033,
      "attention_bam_384_attention_skewness": 0.7428074381316688,
      "attention_bam_384_attention_sparsity": 0.5182876586914062,
      "attention_bam_384_attention_concentration_10": 0.85780948309762,
      "attention_bam_384_attention_concentration_20": 1.3538515288672268,
      "attention_bam_384_attention_center_y": 0.4803710396673667,
      "attention_bam_384_attention_center_x": 0.4849113947251915,
      "attention_bam_384_attention_center_distance": 0.0350132001644828,
      "attention_bam_384_attention_spatial_variance": 170.08609978216373,
      "attention_bam_384_attention_spatial_std": 13.04170616837244,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 14.760155769409925,
      "attention_bam_384_peak_intensity_mean": 0.30100715160369873,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16847997903823853,
      "attention_bam_16_std_attention": 0.6493444442749023,
      "attention_bam_16_max_attention": 3.8179972171783447,
      "attention_bam_16_min_attention": -1.0372188091278076,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.769822695148859,
      "attention_bam_16_attention_skewness": 1.0775546411035222,
      "attention_bam_16_attention_sparsity": 0.525146484375,
      "attention_bam_16_attention_concentration_10": 0.8988896652237851,
      "attention_bam_16_attention_concentration_20": 1.390341750300465,
      "attention_bam_16_attention_center_y": 0.45674002294432575,
      "attention_bam_16_attention_center_x": 0.4704396423813077,
      "attention_bam_16_attention_center_distance": 0.07409777806928412,
      "attention_bam_16_attention_spatial_variance": 42.0800070866271,
      "attention_bam_16_attention_spatial_std": 6.486910442315903,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.725295749608541,
      "attention_bam_16_peak_intensity_mean": 0.2503816783428192,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 234,
      "phase": "train",
      "loss": 0.007953397929668427,
      "timestamp": 1759543918.5851145,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007953397929668427,
      "ssim": 0.8396388292312622,
      "attention_bam_384_mean_attention": 0.13132481276988983,
      "attention_bam_384_std_attention": 0.48100996017456055,
      "attention_bam_384_max_attention": 3.8069071769714355,
      "attention_bam_384_min_attention": -1.3213398456573486,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7707843941019932,
      "attention_bam_384_attention_skewness": 0.6452245179507216,
      "attention_bam_384_attention_sparsity": 0.5095316569010416,
      "attention_bam_384_attention_concentration_10": 0.8135345962720867,
      "attention_bam_384_attention_concentration_20": 1.2902063747970303,
      "attention_bam_384_attention_center_y": 0.48327169044120893,
      "attention_bam_384_attention_center_x": 0.48758648013161104,
      "attention_bam_384_attention_center_distance": 0.02945952532603429,
      "attention_bam_384_attention_spatial_variance": 170.83924794136527,
      "attention_bam_384_attention_spatial_std": 13.070548876820945,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 17.206378047823023,
      "attention_bam_384_peak_intensity_mean": 0.2853277921676636,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17652831971645355,
      "attention_bam_16_std_attention": 0.6238294243812561,
      "attention_bam_16_max_attention": 2.574910879135132,
      "attention_bam_16_min_attention": -1.0978896617889404,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.42987000649987817,
      "attention_bam_16_attention_skewness": 0.7719780786017821,
      "attention_bam_16_attention_sparsity": 0.508056640625,
      "attention_bam_16_attention_concentration_10": 0.8207022849873602,
      "attention_bam_16_attention_concentration_20": 1.294874527431494,
      "attention_bam_16_attention_center_y": 0.46647006013395703,
      "attention_bam_16_attention_center_x": 0.4797916655793064,
      "attention_bam_16_attention_center_distance": 0.055364856135982986,
      "attention_bam_16_attention_spatial_variance": 42.66162354153341,
      "attention_bam_16_attention_spatial_std": 6.531586602161331,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 8.334130969402002,
      "attention_bam_16_peak_intensity_mean": 0.35630497336387634,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 235,
      "phase": "train",
      "loss": 0.0075638494454324245,
      "timestamp": 1759543918.7252805,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0075638494454324245,
      "ssim": 0.8780252933502197,
      "attention_bam_384_mean_attention": 0.12997104227542877,
      "attention_bam_384_std_attention": 0.46669846773147583,
      "attention_bam_384_max_attention": 3.133932590484619,
      "attention_bam_384_min_attention": -1.2765189409255981,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6693312449079318,
      "attention_bam_384_attention_skewness": 0.6027955580135205,
      "attention_bam_384_attention_sparsity": 0.5085830688476562,
      "attention_bam_384_attention_concentration_10": 0.7990852164125367,
      "attention_bam_384_attention_concentration_20": 1.2673050014164422,
      "attention_bam_384_attention_center_y": 0.4887298139832673,
      "attention_bam_384_attention_center_x": 0.49011776455827544,
      "attention_bam_384_attention_center_distance": 0.021197908867500777,
      "attention_bam_384_attention_spatial_variance": 171.5385776360408,
      "attention_bam_384_attention_spatial_std": 13.097273671876938,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 16.86239849907312,
      "attention_bam_384_peak_intensity_mean": 0.32358354330062866,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17592555284500122,
      "attention_bam_16_std_attention": 0.6112313270568848,
      "attention_bam_16_max_attention": 2.831490993499756,
      "attention_bam_16_min_attention": -1.1840726137161255,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6501315921967423,
      "attention_bam_16_attention_skewness": 0.7687491910723686,
      "attention_bam_16_attention_sparsity": 0.498046875,
      "attention_bam_16_attention_concentration_10": 0.7978191730920632,
      "attention_bam_16_attention_concentration_20": 1.2625997741343535,
      "attention_bam_16_attention_center_y": 0.4818288047120421,
      "attention_bam_16_attention_center_x": 0.4857616676645715,
      "attention_bam_16_attention_center_distance": 0.03264728000575889,
      "attention_bam_16_attention_spatial_variance": 43.38426996313013,
      "attention_bam_16_attention_spatial_std": 6.586673664538887,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 7.397969761795077,
      "attention_bam_16_peak_intensity_mean": 0.3624539375305176,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 236,
      "phase": "train",
      "loss": 0.01044672355055809,
      "timestamp": 1759543918.8653593,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.01044672355055809,
      "ssim": 0.8402445316314697,
      "attention_bam_384_mean_attention": 0.13099785149097443,
      "attention_bam_384_std_attention": 0.4401285946369171,
      "attention_bam_384_max_attention": 3.325806140899658,
      "attention_bam_384_min_attention": -1.214839220046997,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8043010879457371,
      "attention_bam_384_attention_skewness": 0.6609299724831552,
      "attention_bam_384_attention_sparsity": 0.5099538167317709,
      "attention_bam_384_attention_concentration_10": 0.7615588644172383,
      "attention_bam_384_attention_concentration_20": 1.2025129759764266,
      "attention_bam_384_attention_center_y": 0.47976448837510954,
      "attention_bam_384_attention_center_x": 0.49105665340029214,
      "attention_bam_384_attention_center_distance": 0.03128767741854875,
      "attention_bam_384_attention_spatial_variance": 170.39633428606552,
      "attention_bam_384_attention_spatial_std": 13.053594688286653,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 16.675330395256267,
      "attention_bam_384_peak_intensity_mean": 0.29845860600471497,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18938857316970825,
      "attention_bam_16_std_attention": 0.5948646068572998,
      "attention_bam_16_max_attention": 2.5208792686462402,
      "attention_bam_16_min_attention": -1.1428383588790894,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.19410938197263894,
      "attention_bam_16_attention_skewness": 0.6894018079925602,
      "attention_bam_16_attention_sparsity": 0.49072265625,
      "attention_bam_16_attention_concentration_10": 0.7271442994568903,
      "attention_bam_16_attention_concentration_20": 1.167902315485007,
      "attention_bam_16_attention_center_y": 0.4534726002410123,
      "attention_bam_16_attention_center_x": 0.4873517481828499,
      "attention_bam_16_attention_center_distance": 0.06818764114357803,
      "attention_bam_16_attention_spatial_variance": 42.29309583403421,
      "attention_bam_16_attention_spatial_std": 6.503314219229623,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 7.751419725318602,
      "attention_bam_16_peak_intensity_mean": 0.36521482467651367,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 237,
      "phase": "train",
      "loss": 0.007739420980215073,
      "timestamp": 1759543918.999066,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007739420980215073,
      "ssim": 0.863426685333252,
      "attention_bam_384_mean_attention": 0.129477396607399,
      "attention_bam_384_std_attention": 0.48728010058403015,
      "attention_bam_384_max_attention": 3.52601957321167,
      "attention_bam_384_min_attention": -1.296148657798767,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8130041867935422,
      "attention_bam_384_attention_skewness": 0.6601953597581833,
      "attention_bam_384_attention_sparsity": 0.5109151204427084,
      "attention_bam_384_attention_concentration_10": 0.8373871821660822,
      "attention_bam_384_attention_concentration_20": 1.3217202401601502,
      "attention_bam_384_attention_center_y": 0.4910474646871457,
      "attention_bam_384_attention_center_x": 0.4744055896634311,
      "attention_bam_384_attention_center_distance": 0.038346361731057814,
      "attention_bam_384_attention_spatial_variance": 169.8351556671256,
      "attention_bam_384_attention_spatial_std": 13.03208178562142,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 18.263938878306494,
      "attention_bam_384_peak_intensity_mean": 0.2983458936214447,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18626725673675537,
      "attention_bam_16_std_attention": 0.6589603424072266,
      "attention_bam_16_max_attention": 3.4537699222564697,
      "attention_bam_16_min_attention": -1.2163515090942383,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8829894404737737,
      "attention_bam_16_attention_skewness": 0.8450657835127987,
      "attention_bam_16_attention_sparsity": 0.5126953125,
      "attention_bam_16_attention_concentration_10": 0.8064391692048591,
      "attention_bam_16_attention_concentration_20": 1.2804850712429676,
      "attention_bam_16_attention_center_y": 0.4858680466203264,
      "attention_bam_16_attention_center_x": 0.44081755511950904,
      "attention_bam_16_attention_center_distance": 0.08604968202564862,
      "attention_bam_16_attention_spatial_variance": 41.689525497297474,
      "attention_bam_16_attention_spatial_std": 6.4567426383043545,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 7.3527037692804385,
      "attention_bam_16_peak_intensity_mean": 0.3071153163909912,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 238,
      "phase": "train",
      "loss": 0.008153803646564484,
      "timestamp": 1759543919.1437695,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008153803646564484,
      "ssim": 0.8549270629882812,
      "attention_bam_384_mean_attention": 0.13247652351856232,
      "attention_bam_384_std_attention": 0.4333188831806183,
      "attention_bam_384_max_attention": 3.233541488647461,
      "attention_bam_384_min_attention": -1.1287341117858887,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.3410290635770767,
      "attention_bam_384_attention_skewness": 0.7777663556196776,
      "attention_bam_384_attention_sparsity": 0.5078023274739584,
      "attention_bam_384_attention_concentration_10": 0.7608904427668906,
      "attention_bam_384_attention_concentration_20": 1.176603722253487,
      "attention_bam_384_attention_center_y": 0.4873967257204112,
      "attention_bam_384_attention_center_x": 0.47365256965061986,
      "attention_bam_384_attention_center_distance": 0.041304469699585344,
      "attention_bam_384_attention_spatial_variance": 171.33988890192924,
      "attention_bam_384_attention_spatial_std": 13.089686356132802,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 17.189812917620092,
      "attention_bam_384_peak_intensity_mean": 0.2914477586746216,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2029736042022705,
      "attention_bam_16_std_attention": 0.602501392364502,
      "attention_bam_16_max_attention": 2.9024910926818848,
      "attention_bam_16_min_attention": -1.0326060056686401,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.0279255266012557,
      "attention_bam_16_attention_skewness": 0.8953916338544696,
      "attention_bam_16_attention_sparsity": 0.483154296875,
      "attention_bam_16_attention_concentration_10": 0.7115194641729077,
      "attention_bam_16_attention_concentration_20": 1.1067962683094235,
      "attention_bam_16_attention_center_y": 0.47972936787176135,
      "attention_bam_16_attention_center_x": 0.4414305807066977,
      "attention_bam_16_attention_center_distance": 0.0876501614742726,
      "attention_bam_16_attention_spatial_variance": 42.73747812970511,
      "attention_bam_16_attention_spatial_std": 6.537390773825985,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.67761780467074,
      "attention_bam_16_peak_intensity_mean": 0.32004454731941223,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 239,
      "phase": "train",
      "loss": 0.00717120710760355,
      "timestamp": 1759543919.301038,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00717120710760355,
      "ssim": 0.8630017042160034,
      "attention_bam_384_mean_attention": 0.1294112652540207,
      "attention_bam_384_std_attention": 0.49391257762908936,
      "attention_bam_384_max_attention": 3.9933652877807617,
      "attention_bam_384_min_attention": -1.2685658931732178,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.879176352365957,
      "attention_bam_384_attention_skewness": 0.8971417137390933,
      "attention_bam_384_attention_sparsity": 0.5168329874674479,
      "attention_bam_384_attention_concentration_10": 0.8728181025139676,
      "attention_bam_384_attention_concentration_20": 1.3360740077270945,
      "attention_bam_384_attention_center_y": 0.491453892492319,
      "attention_bam_384_attention_center_x": 0.4812319648076032,
      "attention_bam_384_attention_center_distance": 0.029164193749043887,
      "attention_bam_384_attention_spatial_variance": 170.8653588034668,
      "attention_bam_384_attention_spatial_std": 13.071547682025521,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 19.718187459449187,
      "attention_bam_384_peak_intensity_mean": 0.26948651671409607,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18712449073791504,
      "attention_bam_16_std_attention": 0.6755611300468445,
      "attention_bam_16_max_attention": 3.512343645095825,
      "attention_bam_16_min_attention": -1.2630118131637573,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.5347155083565376,
      "attention_bam_16_attention_skewness": 1.064448934339398,
      "attention_bam_16_attention_sparsity": 0.509033203125,
      "attention_bam_16_attention_concentration_10": 0.8627568461403355,
      "attention_bam_16_attention_concentration_20": 1.3156701634648447,
      "attention_bam_16_attention_center_y": 0.48968083075650504,
      "attention_bam_16_attention_center_x": 0.46110917285925185,
      "attention_bam_16_attention_center_distance": 0.05690310518007687,
      "attention_bam_16_attention_spatial_variance": 42.570900226880006,
      "attention_bam_16_attention_spatial_std": 6.524637938374819,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 11.040466573974143,
      "attention_bam_16_peak_intensity_mean": 0.31667134165763855,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 240,
      "phase": "train",
      "loss": 0.007412581704556942,
      "timestamp": 1759543919.487512,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007412581704556942,
      "ssim": 0.8670365214347839,
      "attention_bam_384_mean_attention": 0.13300871849060059,
      "attention_bam_384_std_attention": 0.39585116505622864,
      "attention_bam_384_max_attention": 2.6982550621032715,
      "attention_bam_384_min_attention": -1.1542987823486328,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.3009055722438734,
      "attention_bam_384_attention_skewness": 0.3604465388710129,
      "attention_bam_384_attention_sparsity": 0.4845174153645833,
      "attention_bam_384_attention_concentration_10": 0.6544054953372749,
      "attention_bam_384_attention_concentration_20": 1.0631829811360887,
      "attention_bam_384_attention_center_y": 0.48348472801405273,
      "attention_bam_384_attention_center_x": 0.48730021747566626,
      "attention_bam_384_attention_center_distance": 0.029463152748312155,
      "attention_bam_384_attention_spatial_variance": 169.25752325870715,
      "attention_bam_384_attention_spatial_std": 13.009900970365115,
      "attention_bam_384_num_attention_peaks": 19,
      "attention_bam_384_peak_separation_mean": 16.742553280438724,
      "attention_bam_384_peak_intensity_mean": 0.33955177664756775,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20456436276435852,
      "attention_bam_16_std_attention": 0.5447896122932434,
      "attention_bam_16_max_attention": 2.8377151489257812,
      "attention_bam_16_min_attention": -1.0859533548355103,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.018071155471068412,
      "attention_bam_16_attention_skewness": 0.40145951813907954,
      "attention_bam_16_attention_sparsity": 0.447998046875,
      "attention_bam_16_attention_concentration_10": 0.6007527489930183,
      "attention_bam_16_attention_concentration_20": 0.9816893576130417,
      "attention_bam_16_attention_center_y": 0.4683809350311538,
      "attention_bam_16_attention_center_x": 0.4776118123720892,
      "attention_bam_16_attention_center_distance": 0.0547904410416024,
      "attention_bam_16_attention_spatial_variance": 41.969678299428516,
      "attention_bam_16_attention_spatial_std": 6.478400906043753,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.896984193575648,
      "attention_bam_16_peak_intensity_mean": 0.3376511037349701,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 241,
      "phase": "train",
      "loss": 0.009473673067986965,
      "timestamp": 1759543919.6304846,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.009473673067986965,
      "ssim": 0.8358873724937439,
      "attention_bam_384_mean_attention": 0.12508578598499298,
      "attention_bam_384_std_attention": 0.44437554478645325,
      "attention_bam_384_max_attention": 3.361773729324341,
      "attention_bam_384_min_attention": -1.2794393301010132,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2776494077424072,
      "attention_bam_384_attention_skewness": 0.7927082917013214,
      "attention_bam_384_attention_sparsity": 0.5187861124674479,
      "attention_bam_384_attention_concentration_10": 0.8176224241846918,
      "attention_bam_384_attention_concentration_20": 1.2675626539323646,
      "attention_bam_384_attention_center_y": 0.4907846352570779,
      "attention_bam_384_attention_center_x": 0.48233514423279866,
      "attention_bam_384_attention_center_distance": 0.028176943646219626,
      "attention_bam_384_attention_spatial_variance": 170.8387077005476,
      "attention_bam_384_attention_spatial_std": 13.070528210464472,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 17.74406069636281,
      "attention_bam_384_peak_intensity_mean": 0.3067088723182678,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17142248153686523,
      "attention_bam_16_std_attention": 0.6039673686027527,
      "attention_bam_16_max_attention": 2.9022021293640137,
      "attention_bam_16_min_attention": -1.1247352361679077,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6155749845656189,
      "attention_bam_16_attention_skewness": 0.8314930882758972,
      "attention_bam_16_attention_sparsity": 0.510498046875,
      "attention_bam_16_attention_concentration_10": 0.8223805038283539,
      "attention_bam_16_attention_concentration_20": 1.288772013255674,
      "attention_bam_16_attention_center_y": 0.4869760435680235,
      "attention_bam_16_attention_center_x": 0.4640037436161623,
      "attention_bam_16_attention_center_distance": 0.05413601231699648,
      "attention_bam_16_attention_spatial_variance": 42.64259202653326,
      "attention_bam_16_attention_spatial_std": 6.530129556642292,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 7.475685895050363,
      "attention_bam_16_peak_intensity_mean": 0.33276286721229553,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 242,
      "phase": "train",
      "loss": 0.006615319289267063,
      "timestamp": 1759543919.7637703,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006615319289267063,
      "ssim": 0.8614001274108887,
      "attention_bam_384_mean_attention": 0.12820394337177277,
      "attention_bam_384_std_attention": 0.43177330493927,
      "attention_bam_384_max_attention": 4.055536270141602,
      "attention_bam_384_min_attention": -1.3033242225646973,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.0367117169182976,
      "attention_bam_384_attention_skewness": 0.8621692083308765,
      "attention_bam_384_attention_sparsity": 0.5079625447591146,
      "attention_bam_384_attention_concentration_10": 0.7722028212614676,
      "attention_bam_384_attention_concentration_20": 1.1901524877274123,
      "attention_bam_384_attention_center_y": 0.4860769141001919,
      "attention_bam_384_attention_center_x": 0.4798379240189023,
      "attention_bam_384_attention_center_distance": 0.03465145390430227,
      "attention_bam_384_attention_spatial_variance": 171.54759968948295,
      "attention_bam_384_attention_spatial_std": 13.097618092213674,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 18.87565618308635,
      "attention_bam_384_peak_intensity_mean": 0.2680321931838989,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20130258798599243,
      "attention_bam_16_std_attention": 0.6085913777351379,
      "attention_bam_16_max_attention": 3.508129835128784,
      "attention_bam_16_min_attention": -1.1192073822021484,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.7808530793405346,
      "attention_bam_16_attention_skewness": 0.9818277985863958,
      "attention_bam_16_attention_sparsity": 0.48291015625,
      "attention_bam_16_attention_concentration_10": 0.7163422405464069,
      "attention_bam_16_attention_concentration_20": 1.1096433775159689,
      "attention_bam_16_attention_center_y": 0.4751981560840871,
      "attention_bam_16_attention_center_x": 0.4553535514219923,
      "attention_bam_16_attention_center_distance": 0.07222792856309797,
      "attention_bam_16_attention_spatial_variance": 43.082402296422785,
      "attention_bam_16_attention_spatial_std": 6.563718633246156,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.599413588397336,
      "attention_bam_16_peak_intensity_mean": 0.2964784502983093,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 243,
      "phase": "train",
      "loss": 0.008623386733233929,
      "timestamp": 1759543919.8966515,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008623386733233929,
      "ssim": 0.8687101602554321,
      "attention_bam_384_mean_attention": 0.12607616186141968,
      "attention_bam_384_std_attention": 0.4517747461795807,
      "attention_bam_384_max_attention": 2.6850743293762207,
      "attention_bam_384_min_attention": -1.2614941596984863,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.3762473675252216,
      "attention_bam_384_attention_skewness": 0.6103744152238162,
      "attention_bam_384_attention_sparsity": 0.5191497802734375,
      "attention_bam_384_attention_concentration_10": 0.8013575030716418,
      "attention_bam_384_attention_concentration_20": 1.27895914363596,
      "attention_bam_384_attention_center_y": 0.48602197004267345,
      "attention_bam_384_attention_center_x": 0.4818716887700826,
      "attention_bam_384_attention_center_distance": 0.032373476474937594,
      "attention_bam_384_attention_spatial_variance": 172.33757664506248,
      "attention_bam_384_attention_spatial_std": 13.127740728894004,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 21.88323001782372,
      "attention_bam_384_peak_intensity_mean": 0.35756245255470276,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18341538310050964,
      "attention_bam_16_std_attention": 0.616194486618042,
      "attention_bam_16_max_attention": 2.8847005367279053,
      "attention_bam_16_min_attention": -1.1624476909637451,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.010240728222376205,
      "attention_bam_16_attention_skewness": 0.6507213262608174,
      "attention_bam_16_attention_sparsity": 0.505126953125,
      "attention_bam_16_attention_concentration_10": 0.7652453960065493,
      "attention_bam_16_attention_concentration_20": 1.237019731723384,
      "attention_bam_16_attention_center_y": 0.4732959299532236,
      "attention_bam_16_attention_center_x": 0.4612501375515769,
      "attention_bam_16_attention_center_distance": 0.06655312459734479,
      "attention_bam_16_attention_spatial_variance": 43.450214733788236,
      "attention_bam_16_attention_spatial_std": 6.591677687340927,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 11.839913694548214,
      "attention_bam_16_peak_intensity_mean": 0.33585500717163086,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 244,
      "phase": "train",
      "loss": 0.008328416384756565,
      "timestamp": 1759543920.0305383,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008328416384756565,
      "ssim": 0.8273974657058716,
      "attention_bam_384_mean_attention": 0.12502162158489227,
      "attention_bam_384_std_attention": 0.4190943241119385,
      "attention_bam_384_max_attention": 2.98634672164917,
      "attention_bam_384_min_attention": -1.2681220769882202,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9025194275625572,
      "attention_bam_384_attention_skewness": 0.6942174224385066,
      "attention_bam_384_attention_sparsity": 0.5197728474934896,
      "attention_bam_384_attention_concentration_10": 0.7728739939779545,
      "attention_bam_384_attention_concentration_20": 1.2133073512628234,
      "attention_bam_384_attention_center_y": 0.4872965244581332,
      "attention_bam_384_attention_center_x": 0.48642618173020463,
      "attention_bam_384_attention_center_distance": 0.026291703378223265,
      "attention_bam_384_attention_spatial_variance": 171.52839147112118,
      "attention_bam_384_attention_spatial_std": 13.096884800253882,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 17.676989919921922,
      "attention_bam_384_peak_intensity_mean": 0.32845789194107056,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17951279878616333,
      "attention_bam_16_std_attention": 0.5791409015655518,
      "attention_bam_16_max_attention": 2.9169819355010986,
      "attention_bam_16_min_attention": -1.0637755393981934,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.37701242190701034,
      "attention_bam_16_attention_skewness": 0.7525686249073393,
      "attention_bam_16_attention_sparsity": 0.51123046875,
      "attention_bam_16_attention_concentration_10": 0.755550473555538,
      "attention_bam_16_attention_concentration_20": 1.2050648714443186,
      "attention_bam_16_attention_center_y": 0.47612839213653724,
      "attention_bam_16_attention_center_x": 0.4749739673086386,
      "attention_bam_16_attention_center_distance": 0.04891126606940421,
      "attention_bam_16_attention_spatial_variance": 43.17874772516863,
      "attention_bam_16_attention_spatial_std": 6.571053775854268,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.599247621962856,
      "attention_bam_16_peak_intensity_mean": 0.3146653473377228,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 245,
      "phase": "train",
      "loss": 0.010381321422755718,
      "timestamp": 1759543920.1658316,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.010381321422755718,
      "ssim": 0.8387474417686462,
      "attention_bam_384_mean_attention": 0.1255512237548828,
      "attention_bam_384_std_attention": 0.47494375705718994,
      "attention_bam_384_max_attention": 3.542207717895508,
      "attention_bam_384_min_attention": -1.312160849571228,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8621007409401193,
      "attention_bam_384_attention_skewness": 0.685916960917682,
      "attention_bam_384_attention_sparsity": 0.515380859375,
      "attention_bam_384_attention_concentration_10": 0.8454725281679514,
      "attention_bam_384_attention_concentration_20": 1.3276177364220632,
      "attention_bam_384_attention_center_y": 0.4859029210261321,
      "attention_bam_384_attention_center_x": 0.4836645045062498,
      "attention_bam_384_attention_center_distance": 0.03051478489590911,
      "attention_bam_384_attention_spatial_variance": 169.74476911653576,
      "attention_bam_384_attention_spatial_std": 13.028613476365617,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 14.898584902714846,
      "attention_bam_384_peak_intensity_mean": 0.29712969064712524,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18249130249023438,
      "attention_bam_16_std_attention": 0.6456621885299683,
      "attention_bam_16_max_attention": 4.8227386474609375,
      "attention_bam_16_min_attention": -1.1644854545593262,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.7949005821574993,
      "attention_bam_16_attention_skewness": 0.9699576889554351,
      "attention_bam_16_attention_sparsity": 0.50732421875,
      "attention_bam_16_attention_concentration_10": 0.8195051043494955,
      "attention_bam_16_attention_concentration_20": 1.2850854558869864,
      "attention_bam_16_attention_center_y": 0.47069529523696785,
      "attention_bam_16_attention_center_x": 0.4683415866637306,
      "attention_bam_16_attention_center_distance": 0.06100853802900966,
      "attention_bam_16_attention_spatial_variance": 42.05418142374759,
      "attention_bam_16_attention_spatial_std": 6.484919538725796,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.48095382213553,
      "attention_bam_16_peak_intensity_mean": 0.22707781195640564,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 246,
      "phase": "train",
      "loss": 0.005734874866902828,
      "timestamp": 1759543920.3221755,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005734874866902828,
      "ssim": 0.8679025173187256,
      "attention_bam_384_mean_attention": 0.12517012655735016,
      "attention_bam_384_std_attention": 0.4469403922557831,
      "attention_bam_384_max_attention": 3.23671817779541,
      "attention_bam_384_min_attention": -1.2897554636001587,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5359646952292652,
      "attention_bam_384_attention_skewness": 0.7940712960885372,
      "attention_bam_384_attention_sparsity": 0.5162785847981771,
      "attention_bam_384_attention_concentration_10": 0.8147776220990695,
      "attention_bam_384_attention_concentration_20": 1.2643990438756425,
      "attention_bam_384_attention_center_y": 0.4839873193030177,
      "attention_bam_384_attention_center_x": 0.4849704461629932,
      "attention_bam_384_attention_center_distance": 0.031057798751456818,
      "attention_bam_384_attention_spatial_variance": 171.83560312964985,
      "attention_bam_384_attention_spatial_std": 13.108607978334307,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 18.311117567001858,
      "attention_bam_384_peak_intensity_mean": 0.31381165981292725,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1793990433216095,
      "attention_bam_16_std_attention": 0.6096744537353516,
      "attention_bam_16_max_attention": 3.1912007331848145,
      "attention_bam_16_min_attention": -1.2118079662322998,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.1434316774908222,
      "attention_bam_16_attention_skewness": 0.9058884792074064,
      "attention_bam_16_attention_sparsity": 0.5146484375,
      "attention_bam_16_attention_concentration_10": 0.7940366131847162,
      "attention_bam_16_attention_concentration_20": 1.2492309746952452,
      "attention_bam_16_attention_center_y": 0.4698367194696201,
      "attention_bam_16_attention_center_x": 0.46960612473734525,
      "attention_bam_16_attention_center_distance": 0.060557594830643866,
      "attention_bam_16_attention_spatial_variance": 43.2029161981742,
      "attention_bam_16_attention_spatial_std": 6.572892529029682,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.44318323596997,
      "attention_bam_16_peak_intensity_mean": 0.3205616772174835,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 247,
      "phase": "train",
      "loss": 0.005957173183560371,
      "timestamp": 1759543920.498755,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005957173183560371,
      "ssim": 0.8608056306838989,
      "attention_bam_384_mean_attention": 0.1257910281419754,
      "attention_bam_384_std_attention": 0.4452663064002991,
      "attention_bam_384_max_attention": 3.010497570037842,
      "attention_bam_384_min_attention": -1.3021764755249023,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.6453080957022124,
      "attention_bam_384_attention_skewness": 0.8147210749314614,
      "attention_bam_384_attention_sparsity": 0.5147145589192709,
      "attention_bam_384_attention_concentration_10": 0.8086643602833469,
      "attention_bam_384_attention_concentration_20": 1.248468810243886,
      "attention_bam_384_attention_center_y": 0.4914754286543752,
      "attention_bam_384_attention_center_x": 0.4823357913738489,
      "attention_bam_384_attention_center_distance": 0.027737793099482076,
      "attention_bam_384_attention_spatial_variance": 170.53458449156764,
      "attention_bam_384_attention_spatial_std": 13.058889098677867,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 18.601552432535684,
      "attention_bam_384_peak_intensity_mean": 0.33340662717819214,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19623731076717377,
      "attention_bam_16_std_attention": 0.6083473563194275,
      "attention_bam_16_max_attention": 3.5042500495910645,
      "attention_bam_16_min_attention": -1.218586802482605,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.3995234298811203,
      "attention_bam_16_attention_skewness": 0.9538762777054594,
      "attention_bam_16_attention_sparsity": 0.495361328125,
      "attention_bam_16_attention_concentration_10": 0.744854970234702,
      "attention_bam_16_attention_concentration_20": 1.1500741537177572,
      "attention_bam_16_attention_center_y": 0.48778133980399974,
      "attention_bam_16_attention_center_x": 0.4656029609844972,
      "attention_bam_16_attention_center_distance": 0.05162270721338318,
      "attention_bam_16_attention_spatial_variance": 42.44394223496688,
      "attention_bam_16_attention_spatial_std": 6.514901552208359,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 6.910521901650028,
      "attention_bam_16_peak_intensity_mean": 0.3125452399253845,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 248,
      "phase": "train",
      "loss": 0.005761319771409035,
      "timestamp": 1759543920.6637108,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005761319771409035,
      "ssim": 0.8799788355827332,
      "attention_bam_384_mean_attention": 0.12157538533210754,
      "attention_bam_384_std_attention": 0.4678060710430145,
      "attention_bam_384_max_attention": 5.2420759201049805,
      "attention_bam_384_min_attention": -1.38933265209198,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 4.635326795806498,
      "attention_bam_384_attention_skewness": 1.1702892037755726,
      "attention_bam_384_attention_sparsity": 0.5221227010091146,
      "attention_bam_384_attention_concentration_10": 0.8602973530619056,
      "attention_bam_384_attention_concentration_20": 1.3298277464316053,
      "attention_bam_384_attention_center_y": 0.4895003821322324,
      "attention_bam_384_attention_center_x": 0.48538471886942713,
      "attention_bam_384_attention_center_distance": 0.025449888718610297,
      "attention_bam_384_attention_spatial_variance": 173.1701819429833,
      "attention_bam_384_attention_spatial_std": 13.159414194521856,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 17.28224943462304,
      "attention_bam_384_peak_intensity_mean": 0.22946830093860626,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18173879384994507,
      "attention_bam_16_std_attention": 0.6398770213127136,
      "attention_bam_16_max_attention": 4.834367752075195,
      "attention_bam_16_min_attention": -1.1306283473968506,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 4.5097408554539875,
      "attention_bam_16_attention_skewness": 1.4085670991880515,
      "attention_bam_16_attention_sparsity": 0.512939453125,
      "attention_bam_16_attention_concentration_10": 0.8232606751257282,
      "attention_bam_16_attention_concentration_20": 1.2699200018458028,
      "attention_bam_16_attention_center_y": 0.4814901029094491,
      "attention_bam_16_attention_center_x": 0.47180687229693263,
      "attention_bam_16_attention_center_distance": 0.04769630467833434,
      "attention_bam_16_attention_spatial_variance": 44.28803091804814,
      "attention_bam_16_attention_spatial_std": 6.654925312732528,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.20999673739181,
      "attention_bam_16_peak_intensity_mean": 0.2221987247467041,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 249,
      "phase": "train",
      "loss": 0.0072485413402318954,
      "timestamp": 1759543920.8120527,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0072485413402318954,
      "ssim": 0.845007598400116,
      "attention_bam_384_mean_attention": 0.1214880421757698,
      "attention_bam_384_std_attention": 0.43753185868263245,
      "attention_bam_384_max_attention": 3.819861650466919,
      "attention_bam_384_min_attention": -1.2157511711120605,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.6210327322752685,
      "attention_bam_384_attention_skewness": 0.790976347056727,
      "attention_bam_384_attention_sparsity": 0.5158894856770834,
      "attention_bam_384_attention_concentration_10": 0.8136304787801644,
      "attention_bam_384_attention_concentration_20": 1.2651288245270806,
      "attention_bam_384_attention_center_y": 0.48306701328853036,
      "attention_bam_384_attention_center_x": 0.4911664471445649,
      "attention_bam_384_attention_center_distance": 0.027009542573711715,
      "attention_bam_384_attention_spatial_variance": 173.96411083783605,
      "attention_bam_384_attention_spatial_std": 13.18954551293698,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 17.91902119043012,
      "attention_bam_384_peak_intensity_mean": 0.2668631970882416,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17647209763526917,
      "attention_bam_16_std_attention": 0.6062365770339966,
      "attention_bam_16_max_attention": 3.3739938735961914,
      "attention_bam_16_min_attention": -1.1964561939239502,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.689146739385012,
      "attention_bam_16_attention_skewness": 1.0251745192749508,
      "attention_bam_16_attention_sparsity": 0.49853515625,
      "attention_bam_16_attention_concentration_10": 0.8165779801728514,
      "attention_bam_16_attention_concentration_20": 1.253754461960616,
      "attention_bam_16_attention_center_y": 0.46544540641458715,
      "attention_bam_16_attention_center_x": 0.48788652034675445,
      "attention_bam_16_attention_center_distance": 0.051783324094975755,
      "attention_bam_16_attention_spatial_variance": 45.05955089667682,
      "attention_bam_16_attention_spatial_std": 6.712641126760525,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 10.504422563100215,
      "attention_bam_16_peak_intensity_mean": 0.30396631360054016,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 250,
      "phase": "train",
      "loss": 0.009731816127896309,
      "timestamp": 1759543920.9948835,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.009731816127896309,
      "ssim": 0.8305110931396484,
      "attention_bam_384_mean_attention": 0.12486197799444199,
      "attention_bam_384_std_attention": 0.43561509251594543,
      "attention_bam_384_max_attention": 3.5427136421203613,
      "attention_bam_384_min_attention": -1.168286681175232,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.6476098554942178,
      "attention_bam_384_attention_skewness": 0.7746327844210396,
      "attention_bam_384_attention_sparsity": 0.5110092163085938,
      "attention_bam_384_attention_concentration_10": 0.7835069533672395,
      "attention_bam_384_attention_concentration_20": 1.2254147460045697,
      "attention_bam_384_attention_center_y": 0.4842814915329936,
      "attention_bam_384_attention_center_x": 0.4919582973415297,
      "attention_bam_384_attention_center_distance": 0.024969601121147305,
      "attention_bam_384_attention_spatial_variance": 171.05497380058668,
      "attention_bam_384_attention_spatial_std": 13.078798637512035,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 16.84352498394724,
      "attention_bam_384_peak_intensity_mean": 0.27835607528686523,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19535213708877563,
      "attention_bam_16_std_attention": 0.6043063402175903,
      "attention_bam_16_max_attention": 3.486992359161377,
      "attention_bam_16_min_attention": -1.1448171138763428,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.7476725733753113,
      "attention_bam_16_attention_skewness": 0.9594272313620333,
      "attention_bam_16_attention_sparsity": 0.48291015625,
      "attention_bam_16_attention_concentration_10": 0.7236908708316817,
      "attention_bam_16_attention_concentration_20": 1.1372132120261909,
      "attention_bam_16_attention_center_y": 0.4689788587680988,
      "attention_bam_16_attention_center_x": 0.4928856067471685,
      "attention_bam_16_attention_center_distance": 0.04500946110953773,
      "attention_bam_16_attention_spatial_variance": 42.93474259073473,
      "attention_bam_16_attention_spatial_std": 6.5524608042120125,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.741502552715295,
      "attention_bam_16_peak_intensity_mean": 0.29788920283317566,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 251,
      "phase": "train",
      "loss": 0.007160609588027,
      "timestamp": 1759543921.1364663,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007160609588027,
      "ssim": 0.856939435005188,
      "attention_bam_384_mean_attention": 0.1247178390622139,
      "attention_bam_384_std_attention": 0.45267820358276367,
      "attention_bam_384_max_attention": 4.3997039794921875,
      "attention_bam_384_min_attention": -1.2657129764556885,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1976054055655299,
      "attention_bam_384_attention_skewness": 0.6705503950795456,
      "attention_bam_384_attention_sparsity": 0.51123046875,
      "attention_bam_384_attention_concentration_10": 0.809144029447741,
      "attention_bam_384_attention_concentration_20": 1.2744717455693997,
      "attention_bam_384_attention_center_y": 0.48663357839900906,
      "attention_bam_384_attention_center_x": 0.48314426842814184,
      "attention_bam_384_attention_center_distance": 0.03042291614023787,
      "attention_bam_384_attention_spatial_variance": 171.65843567322244,
      "attention_bam_384_attention_spatial_std": 13.101848559391245,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 17.40552278716975,
      "attention_bam_384_peak_intensity_mean": 0.24702583253383636,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18994398415088654,
      "attention_bam_16_std_attention": 0.6166006922721863,
      "attention_bam_16_max_attention": 3.917904853820801,
      "attention_bam_16_min_attention": -1.1410908699035645,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.0309652452848317,
      "attention_bam_16_attention_skewness": 0.7865772210757622,
      "attention_bam_16_attention_sparsity": 0.492919921875,
      "attention_bam_16_attention_concentration_10": 0.746259744987731,
      "attention_bam_16_attention_concentration_20": 1.1859126808862295,
      "attention_bam_16_attention_center_y": 0.47855909996534807,
      "attention_bam_16_attention_center_x": 0.4627840640366828,
      "attention_bam_16_attention_center_distance": 0.060741058336543044,
      "attention_bam_16_attention_spatial_variance": 43.00460996567068,
      "attention_bam_16_attention_spatial_std": 6.557790021468413,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.377921825329159,
      "attention_bam_16_peak_intensity_mean": 0.266818642616272,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 252,
      "phase": "train",
      "loss": 0.01316110324114561,
      "timestamp": 1759543921.2768607,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.01316110324114561,
      "ssim": 0.8284634351730347,
      "attention_bam_384_mean_attention": 0.11939582228660583,
      "attention_bam_384_std_attention": 0.4686383008956909,
      "attention_bam_384_max_attention": 3.548692226409912,
      "attention_bam_384_min_attention": -1.197556972503662,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1654120005931636,
      "attention_bam_384_attention_skewness": 0.750097393542593,
      "attention_bam_384_attention_sparsity": 0.5251998901367188,
      "attention_bam_384_attention_concentration_10": 0.8816958663928737,
      "attention_bam_384_attention_concentration_20": 1.374284588190336,
      "attention_bam_384_attention_center_y": 0.48419793230630365,
      "attention_bam_384_attention_center_x": 0.487458574876062,
      "attention_bam_384_attention_center_distance": 0.028530428932475087,
      "attention_bam_384_attention_spatial_variance": 169.92082065380768,
      "attention_bam_384_attention_spatial_std": 13.035368067446646,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 18.005373032282396,
      "attention_bam_384_peak_intensity_mean": 0.27857211232185364,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1744784712791443,
      "attention_bam_16_std_attention": 0.6372165679931641,
      "attention_bam_16_max_attention": 3.5621745586395264,
      "attention_bam_16_min_attention": -1.0670267343521118,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8412403778261384,
      "attention_bam_16_attention_skewness": 0.8716363153879835,
      "attention_bam_16_attention_sparsity": 0.514892578125,
      "attention_bam_16_attention_concentration_10": 0.8533345824973866,
      "attention_bam_16_attention_concentration_20": 1.331953090632937,
      "attention_bam_16_attention_center_y": 0.46860719021870434,
      "attention_bam_16_attention_center_x": 0.4787387178102127,
      "attention_bam_16_attention_center_distance": 0.05361997065121126,
      "attention_bam_16_attention_spatial_variance": 42.01548887540431,
      "attention_bam_16_attention_spatial_std": 6.481935580936015,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 7.865158077320531,
      "attention_bam_16_peak_intensity_mean": 0.27154842019081116,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 253,
      "phase": "train",
      "loss": 0.0062513453885912895,
      "timestamp": 1759543921.410482,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0062513453885912895,
      "ssim": 0.8906629085540771,
      "attention_bam_384_mean_attention": 0.12318124622106552,
      "attention_bam_384_std_attention": 0.4335375428199768,
      "attention_bam_384_max_attention": 2.695049285888672,
      "attention_bam_384_min_attention": -1.3197256326675415,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7198934719440295,
      "attention_bam_384_attention_skewness": 0.6222843605470796,
      "attention_bam_384_attention_sparsity": 0.5152765909830729,
      "attention_bam_384_attention_concentration_10": 0.7942584696724042,
      "attention_bam_384_attention_concentration_20": 1.2527003999245792,
      "attention_bam_384_attention_center_y": 0.48535902070413894,
      "attention_bam_384_attention_center_x": 0.48001913080513453,
      "attention_bam_384_attention_center_distance": 0.035031226313794836,
      "attention_bam_384_attention_spatial_variance": 171.07211113140823,
      "attention_bam_384_attention_spatial_std": 13.079453778021781,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 17.88042324791431,
      "attention_bam_384_peak_intensity_mean": 0.3598291873931885,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1882266104221344,
      "attention_bam_16_std_attention": 0.5837174654006958,
      "attention_bam_16_max_attention": 2.527555227279663,
      "attention_bam_16_min_attention": -0.9881402850151062,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.2463157044167792,
      "attention_bam_16_attention_skewness": 0.6423711216438174,
      "attention_bam_16_attention_sparsity": 0.49267578125,
      "attention_bam_16_attention_concentration_10": 0.7164967208528822,
      "attention_bam_16_attention_concentration_20": 1.1485096907830132,
      "attention_bam_16_attention_center_y": 0.4720877843506287,
      "attention_bam_16_attention_center_x": 0.4580855743587479,
      "attention_bam_16_attention_center_distance": 0.07121672358783515,
      "attention_bam_16_attention_spatial_variance": 43.0012214714958,
      "attention_bam_16_attention_spatial_std": 6.557531659969001,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.104742372197753,
      "attention_bam_16_peak_intensity_mean": 0.34188875555992126,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 254,
      "phase": "train",
      "loss": 0.00888579897582531,
      "timestamp": 1759543921.5468187,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00888579897582531,
      "ssim": 0.860553503036499,
      "attention_bam_384_mean_attention": 0.11997216194868088,
      "attention_bam_384_std_attention": 0.43147900700569153,
      "attention_bam_384_max_attention": 2.721970558166504,
      "attention_bam_384_min_attention": -1.26265549659729,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7342855814998903,
      "attention_bam_384_attention_skewness": 0.6164519893785756,
      "attention_bam_384_attention_sparsity": 0.5144526163736979,
      "attention_bam_384_attention_concentration_10": 0.8069669654847884,
      "attention_bam_384_attention_concentration_20": 1.2686545178009387,
      "attention_bam_384_attention_center_y": 0.48278745377119486,
      "attention_bam_384_attention_center_x": 0.48200081585029814,
      "attention_bam_384_attention_center_distance": 0.03522051611585591,
      "attention_bam_384_attention_spatial_variance": 169.61941102549122,
      "attention_bam_384_attention_spatial_std": 13.023801711692759,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 18.272477420050233,
      "attention_bam_384_peak_intensity_mean": 0.3455794155597687,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17715969681739807,
      "attention_bam_16_std_attention": 0.5990957021713257,
      "attention_bam_16_max_attention": 2.6046125888824463,
      "attention_bam_16_min_attention": -1.1280863285064697,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.560933091595532,
      "attention_bam_16_attention_skewness": 0.756783021543432,
      "attention_bam_16_attention_sparsity": 0.501220703125,
      "attention_bam_16_attention_concentration_10": 0.7804931387649143,
      "attention_bam_16_attention_concentration_20": 1.2351277896868276,
      "attention_bam_16_attention_center_y": 0.465795886487715,
      "attention_bam_16_attention_center_x": 0.4630277809246066,
      "attention_bam_16_attention_center_distance": 0.07123013919009505,
      "attention_bam_16_attention_spatial_variance": 41.77466374117903,
      "attention_bam_16_attention_spatial_std": 6.463332247469492,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.530914572634956,
      "attention_bam_16_peak_intensity_mean": 0.34722572565078735,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 255,
      "phase": "train",
      "loss": 0.009768643416464329,
      "timestamp": 1759543921.6846561,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.009768643416464329,
      "ssim": 0.8487281799316406,
      "attention_bam_384_mean_attention": 0.11708908528089523,
      "attention_bam_384_std_attention": 0.4651225507259369,
      "attention_bam_384_max_attention": 3.4087347984313965,
      "attention_bam_384_min_attention": -1.2502989768981934,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.402445807557256,
      "attention_bam_384_attention_skewness": 0.7460825650184465,
      "attention_bam_384_attention_sparsity": 0.5191014607747396,
      "attention_bam_384_attention_concentration_10": 0.875865783887968,
      "attention_bam_384_attention_concentration_20": 1.3710448321150255,
      "attention_bam_384_attention_center_y": 0.4816169871713759,
      "attention_bam_384_attention_center_x": 0.48485685768799747,
      "attention_bam_384_attention_center_distance": 0.03368233720331531,
      "attention_bam_384_attention_spatial_variance": 168.59241140530247,
      "attention_bam_384_attention_spatial_std": 12.98431405216704,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 14.434864523847812,
      "attention_bam_384_peak_intensity_mean": 0.29469066858291626,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17781665921211243,
      "attention_bam_16_std_attention": 0.6502586603164673,
      "attention_bam_16_max_attention": 3.6305766105651855,
      "attention_bam_16_min_attention": -1.0665600299835205,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.0590645781170744,
      "attention_bam_16_attention_skewness": 0.8938556451894649,
      "attention_bam_16_attention_sparsity": 0.515380859375,
      "attention_bam_16_attention_concentration_10": 0.8403238763006348,
      "attention_bam_16_attention_concentration_20": 1.3221267210597523,
      "attention_bam_16_attention_center_y": 0.46251806821442615,
      "attention_bam_16_attention_center_x": 0.47121976057315346,
      "attention_bam_16_attention_center_distance": 0.06683109144470145,
      "attention_bam_16_attention_spatial_variance": 40.77724854692455,
      "attention_bam_16_attention_spatial_std": 6.385706581649719,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 7.2387766834224,
      "attention_bam_16_peak_intensity_mean": 0.2749912142753601,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 256,
      "phase": "train",
      "loss": 0.006107610650360584,
      "timestamp": 1759543921.8319142,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006107610650360584,
      "ssim": 0.8699754476547241,
      "attention_bam_384_mean_attention": 0.11749713867902756,
      "attention_bam_384_std_attention": 0.45533299446105957,
      "attention_bam_384_max_attention": 2.838047981262207,
      "attention_bam_384_min_attention": -1.293292760848999,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5239261411723763,
      "attention_bam_384_attention_skewness": 0.6377116300683929,
      "attention_bam_384_attention_sparsity": 0.5253702799479166,
      "attention_bam_384_attention_concentration_10": 0.8626582510182532,
      "attention_bam_384_attention_concentration_20": 1.369075375841513,
      "attention_bam_384_attention_center_y": 0.48066671159425245,
      "attention_bam_384_attention_center_x": 0.49050915038997916,
      "attention_bam_384_attention_center_distance": 0.030458242460780473,
      "attention_bam_384_attention_spatial_variance": 170.4492002233838,
      "attention_bam_384_attention_spatial_std": 13.055619488304023,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 17.831800815106615,
      "attention_bam_384_peak_intensity_mean": 0.3410469591617584,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.175735205411911,
      "attention_bam_16_std_attention": 0.6200176477432251,
      "attention_bam_16_max_attention": 2.6892566680908203,
      "attention_bam_16_min_attention": -1.02369225025177,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.34150265008144576,
      "attention_bam_16_attention_skewness": 0.7431879046156917,
      "attention_bam_16_attention_sparsity": 0.51025390625,
      "attention_bam_16_attention_concentration_10": 0.8097723385614591,
      "attention_bam_16_attention_concentration_20": 1.295469580823474,
      "attention_bam_16_attention_center_y": 0.45704296600732425,
      "attention_bam_16_attention_center_x": 0.49287535578018515,
      "attention_bam_16_attention_center_distance": 0.061580310566070405,
      "attention_bam_16_attention_spatial_variance": 42.62332738410084,
      "attention_bam_16_attention_spatial_std": 6.528654331797697,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 7.728774884128959,
      "attention_bam_16_peak_intensity_mean": 0.32932648062705994,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 257,
      "phase": "train",
      "loss": 0.014961285516619682,
      "timestamp": 1759543921.9859076,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.014961285516619682,
      "ssim": 0.8598815202713013,
      "attention_bam_384_mean_attention": 0.11887192726135254,
      "attention_bam_384_std_attention": 0.40851089358329773,
      "attention_bam_384_max_attention": 2.857158899307251,
      "attention_bam_384_min_attention": -1.19216787815094,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7277730995202685,
      "attention_bam_384_attention_skewness": 0.6450051259865216,
      "attention_bam_384_attention_sparsity": 0.5161488850911459,
      "attention_bam_384_attention_concentration_10": 0.7758993785745338,
      "attention_bam_384_attention_concentration_20": 1.2257063322533488,
      "attention_bam_384_attention_center_y": 0.48448670787764575,
      "attention_bam_384_attention_center_x": 0.4913928963609195,
      "attention_bam_384_attention_center_distance": 0.025089617993400034,
      "attention_bam_384_attention_spatial_variance": 172.9449730275656,
      "attention_bam_384_attention_spatial_std": 13.15085445997961,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 17.88018253434723,
      "attention_bam_384_peak_intensity_mean": 0.32996222376823425,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18885844945907593,
      "attention_bam_16_std_attention": 0.5844645500183105,
      "attention_bam_16_max_attention": 3.0817317962646484,
      "attention_bam_16_min_attention": -0.9786288738250732,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.37103863291430406,
      "attention_bam_16_attention_skewness": 0.685949195611958,
      "attention_bam_16_attention_sparsity": 0.485595703125,
      "attention_bam_16_attention_concentration_10": 0.7166146076355066,
      "attention_bam_16_attention_concentration_20": 1.1397696368408443,
      "attention_bam_16_attention_center_y": 0.46817806971843823,
      "attention_bam_16_attention_center_x": 0.49439433256354565,
      "attention_bam_16_attention_center_distance": 0.04569592441898298,
      "attention_bam_16_attention_spatial_variance": 44.65776455010459,
      "attention_bam_16_attention_spatial_std": 6.68264652290577,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.674141037183645,
      "attention_bam_16_peak_intensity_mean": 0.29815673828125,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 258,
      "phase": "train",
      "loss": 0.013713951222598553,
      "timestamp": 1759543922.138267,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.013713951222598553,
      "ssim": 0.8692094683647156,
      "attention_bam_384_mean_attention": 0.11941944807767868,
      "attention_bam_384_std_attention": 0.4077672064304352,
      "attention_bam_384_max_attention": 3.264796733856201,
      "attention_bam_384_min_attention": -1.303701639175415,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7772092931460874,
      "attention_bam_384_attention_skewness": 0.6227697007945988,
      "attention_bam_384_attention_sparsity": 0.5169626871744791,
      "attention_bam_384_attention_concentration_10": 0.7713985053847177,
      "attention_bam_384_attention_concentration_20": 1.2186040359679982,
      "attention_bam_384_attention_center_y": 0.4770889614757288,
      "attention_bam_384_attention_center_x": 0.4854273296305835,
      "attention_bam_384_attention_center_distance": 0.038399958540506464,
      "attention_bam_384_attention_spatial_variance": 171.19674024006,
      "attention_bam_384_attention_spatial_std": 13.08421721923249,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 16.4451410667268,
      "attention_bam_384_peak_intensity_mean": 0.31517496705055237,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1816418468952179,
      "attention_bam_16_std_attention": 0.574830174446106,
      "attention_bam_16_max_attention": 2.584702253341675,
      "attention_bam_16_min_attention": -1.0144736766815186,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.22780484546978075,
      "attention_bam_16_attention_skewness": 0.6639686649481726,
      "attention_bam_16_attention_sparsity": 0.491943359375,
      "attention_bam_16_attention_concentration_10": 0.7391594826319967,
      "attention_bam_16_attention_concentration_20": 1.1749761152178073,
      "attention_bam_16_attention_center_y": 0.4484082768375862,
      "attention_bam_16_attention_center_x": 0.4675089014360622,
      "attention_bam_16_attention_center_distance": 0.08622502403315017,
      "attention_bam_16_attention_spatial_variance": 42.912540414028626,
      "attention_bam_16_attention_spatial_std": 6.550766398981773,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.411177259948062,
      "attention_bam_16_peak_intensity_mean": 0.34249821305274963,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 259,
      "phase": "train",
      "loss": 0.00742822652682662,
      "timestamp": 1759543922.2717974,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00742822652682662,
      "ssim": 0.8730816841125488,
      "attention_bam_384_mean_attention": 0.11668276786804199,
      "attention_bam_384_std_attention": 0.43855857849121094,
      "attention_bam_384_max_attention": 3.152961254119873,
      "attention_bam_384_min_attention": -1.4648969173431396,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2712195414561096,
      "attention_bam_384_attention_skewness": 0.783746690532811,
      "attention_bam_384_attention_sparsity": 0.5255304972330729,
      "attention_bam_384_attention_concentration_10": 0.8553244973976637,
      "attention_bam_384_attention_concentration_20": 1.3264221919356003,
      "attention_bam_384_attention_center_y": 0.48325187123302094,
      "attention_bam_384_attention_center_x": 0.47881976634404233,
      "attention_bam_384_attention_center_distance": 0.03818644039227206,
      "attention_bam_384_attention_spatial_variance": 170.45692253193073,
      "attention_bam_384_attention_spatial_std": 13.055915231492992,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 18.524536539256857,
      "attention_bam_384_peak_intensity_mean": 0.3439022898674011,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16934910416603088,
      "attention_bam_16_std_attention": 0.5966850519180298,
      "attention_bam_16_max_attention": 2.783108711242676,
      "attention_bam_16_min_attention": -1.110460638999939,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.9410611674104912,
      "attention_bam_16_attention_skewness": 0.901932827233074,
      "attention_bam_16_attention_sparsity": 0.51416015625,
      "attention_bam_16_attention_concentration_10": 0.833605019545695,
      "attention_bam_16_attention_concentration_20": 1.2907439145824604,
      "attention_bam_16_attention_center_y": 0.4659372446140893,
      "attention_bam_16_attention_center_x": 0.4542249600797649,
      "attention_bam_16_attention_center_distance": 0.08069232409813844,
      "attention_bam_16_attention_spatial_variance": 42.46823073962259,
      "attention_bam_16_attention_spatial_std": 6.51676535864401,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.761555559435516,
      "attention_bam_16_peak_intensity_mean": 0.3379482626914978,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 260,
      "phase": "train",
      "loss": 0.006951767485588789,
      "timestamp": 1759543922.4609904,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006951767485588789,
      "ssim": 0.8812186121940613,
      "attention_bam_384_mean_attention": 0.11816040426492691,
      "attention_bam_384_std_attention": 0.4147416651248932,
      "attention_bam_384_max_attention": 3.1521918773651123,
      "attention_bam_384_min_attention": -1.2007560729980469,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0327897020725878,
      "attention_bam_384_attention_skewness": 0.7706811574386812,
      "attention_bam_384_attention_sparsity": 0.5271631876627604,
      "attention_bam_384_attention_concentration_10": 0.8073557373475027,
      "attention_bam_384_attention_concentration_20": 1.2597329704961366,
      "attention_bam_384_attention_center_y": 0.4864807022399445,
      "attention_bam_384_attention_center_x": 0.4880607250198561,
      "attention_bam_384_attention_center_distance": 0.025507555703223782,
      "attention_bam_384_attention_spatial_variance": 168.26093464061498,
      "attention_bam_384_attention_spatial_std": 12.971543263645039,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 13.031826409293584,
      "attention_bam_384_peak_intensity_mean": 0.3064271807670593,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18745052814483643,
      "attention_bam_16_std_attention": 0.5794767737388611,
      "attention_bam_16_max_attention": 2.9524471759796143,
      "attention_bam_16_min_attention": -0.9745572209358215,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6728278164437147,
      "attention_bam_16_attention_skewness": 0.8450481714572955,
      "attention_bam_16_attention_sparsity": 0.503173828125,
      "attention_bam_16_attention_concentration_10": 0.7350991987561728,
      "attention_bam_16_attention_concentration_20": 1.1606066396914818,
      "attention_bam_16_attention_center_y": 0.47581472731299185,
      "attention_bam_16_attention_center_x": 0.48095538966786594,
      "attention_bam_16_attention_center_distance": 0.043534459859926364,
      "attention_bam_16_attention_spatial_variance": 40.88606519921624,
      "attention_bam_16_attention_spatial_std": 6.394221234772553,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 7.9909508648552645,
      "attention_bam_16_peak_intensity_mean": 0.3048546314239502,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 261,
      "phase": "train",
      "loss": 0.012952476739883423,
      "timestamp": 1759543922.6172905,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.012952476739883423,
      "ssim": 0.8176043033599854,
      "attention_bam_384_mean_attention": 0.11909559369087219,
      "attention_bam_384_std_attention": 0.4161824882030487,
      "attention_bam_384_max_attention": 3.2072620391845703,
      "attention_bam_384_min_attention": -1.185072898864746,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.3041912162849796,
      "attention_bam_384_attention_skewness": 0.7522291551874888,
      "attention_bam_384_attention_sparsity": 0.5197957356770834,
      "attention_bam_384_attention_concentration_10": 0.7943517796763636,
      "attention_bam_384_attention_concentration_20": 1.2414934910835227,
      "attention_bam_384_attention_center_y": 0.48188014667717693,
      "attention_bam_384_attention_center_x": 0.4927941273614935,
      "attention_bam_384_attention_center_distance": 0.02757729808821013,
      "attention_bam_384_attention_spatial_variance": 171.53196147896986,
      "attention_bam_384_attention_spatial_std": 13.097021091796785,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 17.00576878798724,
      "attention_bam_384_peak_intensity_mean": 0.29540783166885376,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1859361082315445,
      "attention_bam_16_std_attention": 0.5757910013198853,
      "attention_bam_16_max_attention": 2.9618258476257324,
      "attention_bam_16_min_attention": -1.190239667892456,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8161258544880754,
      "attention_bam_16_attention_skewness": 0.8040501175179127,
      "attention_bam_16_attention_sparsity": 0.491455078125,
      "attention_bam_16_attention_concentration_10": 0.7242755446888586,
      "attention_bam_16_attention_concentration_20": 1.1507209390870403,
      "attention_bam_16_attention_center_y": 0.46258855126859333,
      "attention_bam_16_attention_center_x": 0.49023745788220896,
      "attention_bam_16_attention_center_distance": 0.054679497524836744,
      "attention_bam_16_attention_spatial_variance": 43.18400393224195,
      "attention_bam_16_attention_spatial_std": 6.571453715293288,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 7.803561342157279,
      "attention_bam_16_peak_intensity_mean": 0.3248702585697174,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 262,
      "phase": "train",
      "loss": 0.005346134305000305,
      "timestamp": 1759543922.7608962,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005346134305000305,
      "ssim": 0.8839638829231262,
      "attention_bam_384_mean_attention": 0.11349823325872421,
      "attention_bam_384_std_attention": 0.4625406563282013,
      "attention_bam_384_max_attention": 3.3596596717834473,
      "attention_bam_384_min_attention": -1.3030905723571777,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0025414707933527,
      "attention_bam_384_attention_skewness": 0.7688199825909307,
      "attention_bam_384_attention_sparsity": 0.5338134765625,
      "attention_bam_384_attention_concentration_10": 0.9122089545600421,
      "attention_bam_384_attention_concentration_20": 1.4292382057546198,
      "attention_bam_384_attention_center_y": 0.49095229050180855,
      "attention_bam_384_attention_center_x": 0.49059190080012643,
      "attention_bam_384_attention_center_distance": 0.018459327058066084,
      "attention_bam_384_attention_spatial_variance": 171.0463100131746,
      "attention_bam_384_attention_spatial_std": 13.078467418362695,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 17.022412626845927,
      "attention_bam_384_peak_intensity_mean": 0.3048912286758423,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1707424819469452,
      "attention_bam_16_std_attention": 0.6396780610084534,
      "attention_bam_16_max_attention": 3.1612722873687744,
      "attention_bam_16_min_attention": -1.0259605646133423,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.01347828171202,
      "attention_bam_16_attention_skewness": 0.9723332845572721,
      "attention_bam_16_attention_sparsity": 0.521728515625,
      "attention_bam_16_attention_concentration_10": 0.8824631050077103,
      "attention_bam_16_attention_concentration_20": 1.3733606473484705,
      "attention_bam_16_attention_center_y": 0.4870775059775783,
      "attention_bam_16_attention_center_x": 0.48881990013387405,
      "attention_bam_16_attention_center_distance": 0.024165491295484707,
      "attention_bam_16_attention_spatial_variance": 43.01654501227809,
      "attention_bam_16_attention_spatial_std": 6.5586999483341275,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.382395455169828,
      "attention_bam_16_peak_intensity_mean": 0.29404354095458984,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 263,
      "phase": "train",
      "loss": 0.008631547912955284,
      "timestamp": 1759543923.12411,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008631547912955284,
      "ssim": 0.8719766736030579,
      "attention_bam_384_mean_attention": 0.11758964508771896,
      "attention_bam_384_std_attention": 0.463252454996109,
      "attention_bam_384_max_attention": 3.872917652130127,
      "attention_bam_384_min_attention": -1.394453763961792,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.3259498775523246,
      "attention_bam_384_attention_skewness": 0.9092351593134096,
      "attention_bam_384_attention_sparsity": 0.526031494140625,
      "attention_bam_384_attention_concentration_10": 0.8911191816884181,
      "attention_bam_384_attention_concentration_20": 1.3651505652503633,
      "attention_bam_384_attention_center_y": 0.4834248875019331,
      "attention_bam_384_attention_center_x": 0.4850789881831564,
      "attention_bam_384_attention_center_distance": 0.03153952910117588,
      "attention_bam_384_attention_spatial_variance": 168.5344830592827,
      "attention_bam_384_attention_spatial_std": 12.98208315561423,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 14.583829001075985,
      "attention_bam_384_peak_intensity_mean": 0.2896345555782318,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18324510753154755,
      "attention_bam_16_std_attention": 0.62212735414505,
      "attention_bam_16_max_attention": 3.855800151824951,
      "attention_bam_16_min_attention": -1.2426837682724,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.954969782421836,
      "attention_bam_16_attention_skewness": 1.0240568786113355,
      "attention_bam_16_attention_sparsity": 0.506591796875,
      "attention_bam_16_attention_concentration_10": 0.7922406341867867,
      "attention_bam_16_attention_concentration_20": 1.2378317284074127,
      "attention_bam_16_attention_center_y": 0.4672302017908989,
      "attention_bam_16_attention_center_x": 0.46838946147112165,
      "attention_bam_16_attention_center_distance": 0.06439077295313216,
      "attention_bam_16_attention_spatial_variance": 41.23353847621132,
      "attention_bam_16_attention_spatial_std": 6.421334633564219,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.88414539479788,
      "attention_bam_16_peak_intensity_mean": 0.29838281869888306,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 264,
      "phase": "train",
      "loss": 0.00614527054131031,
      "timestamp": 1759543923.2541702,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00614527054131031,
      "ssim": 0.8798012733459473,
      "attention_bam_384_mean_attention": 0.11750543117523193,
      "attention_bam_384_std_attention": 0.4554016590118408,
      "attention_bam_384_max_attention": 3.128943920135498,
      "attention_bam_384_min_attention": -1.3048783540725708,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7025488845297403,
      "attention_bam_384_attention_skewness": 0.6422739924915849,
      "attention_bam_384_attention_sparsity": 0.5202458699544271,
      "attention_bam_384_attention_concentration_10": 0.8595257008419507,
      "attention_bam_384_attention_concentration_20": 1.355450284245769,
      "attention_bam_384_attention_center_y": 0.48489490017026865,
      "attention_bam_384_attention_center_x": 0.48348150149766533,
      "attention_bam_384_attention_center_distance": 0.03165516809741445,
      "attention_bam_384_attention_spatial_variance": 170.8106003836289,
      "attention_bam_384_attention_spatial_std": 13.069452948904514,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 17.146986436259148,
      "attention_bam_384_peak_intensity_mean": 0.3220212161540985,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17172057926654816,
      "attention_bam_16_std_attention": 0.6192870140075684,
      "attention_bam_16_max_attention": 3.1431024074554443,
      "attention_bam_16_min_attention": -1.0224120616912842,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6771083751737756,
      "attention_bam_16_attention_skewness": 0.7814054033758949,
      "attention_bam_16_attention_sparsity": 0.50927734375,
      "attention_bam_16_attention_concentration_10": 0.8229412720652131,
      "attention_bam_16_attention_concentration_20": 1.301107265678844,
      "attention_bam_16_attention_center_y": 0.468389930251825,
      "attention_bam_16_attention_center_x": 0.46572093718946833,
      "attention_bam_16_attention_center_distance": 0.06594316729810394,
      "attention_bam_16_attention_spatial_variance": 42.65584996829005,
      "attention_bam_16_attention_spatial_std": 6.531144613947087,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.99942082307197,
      "attention_bam_16_peak_intensity_mean": 0.2889474928379059,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 265,
      "phase": "train",
      "loss": 0.005559922195971012,
      "timestamp": 1759543923.3927107,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005559922195971012,
      "ssim": 0.8924224376678467,
      "attention_bam_384_mean_attention": 0.11481144279241562,
      "attention_bam_384_std_attention": 0.44631636142730713,
      "attention_bam_384_max_attention": 2.8546926975250244,
      "attention_bam_384_min_attention": -1.206907868385315,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0665956813472022,
      "attention_bam_384_attention_skewness": 0.7709044110717471,
      "attention_bam_384_attention_sparsity": 0.5313491821289062,
      "attention_bam_384_attention_concentration_10": 0.8854424278060264,
      "attention_bam_384_attention_concentration_20": 1.3740713443571744,
      "attention_bam_384_attention_center_y": 0.4812827371837745,
      "attention_bam_384_attention_center_x": 0.48791638127353876,
      "attention_bam_384_attention_center_distance": 0.031507134711304424,
      "attention_bam_384_attention_spatial_variance": 171.1644816852006,
      "attention_bam_384_attention_spatial_std": 13.08298443342346,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 17.547227915418354,
      "attention_bam_384_peak_intensity_mean": 0.3329552412033081,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1758013665676117,
      "attention_bam_16_std_attention": 0.6116763353347778,
      "attention_bam_16_max_attention": 3.1744346618652344,
      "attention_bam_16_min_attention": -1.0787353515625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.0033312702249795,
      "attention_bam_16_attention_skewness": 0.9296048769432027,
      "attention_bam_16_attention_sparsity": 0.52099609375,
      "attention_bam_16_attention_concentration_10": 0.8169339615731158,
      "attention_bam_16_attention_concentration_20": 1.286119566037931,
      "attention_bam_16_attention_center_y": 0.4591295192300498,
      "attention_bam_16_attention_center_x": 0.47902265259144905,
      "attention_bam_16_attention_center_distance": 0.06496838158159565,
      "attention_bam_16_attention_spatial_variance": 42.91769172117681,
      "attention_bam_16_attention_spatial_std": 6.551159570730728,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.562482375738119,
      "attention_bam_16_peak_intensity_mean": 0.311785489320755,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 266,
      "phase": "train",
      "loss": 0.006996700074523687,
      "timestamp": 1759543923.5410647,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006996700074523687,
      "ssim": 0.8795108795166016,
      "attention_bam_384_mean_attention": 0.11694830656051636,
      "attention_bam_384_std_attention": 0.4792553186416626,
      "attention_bam_384_max_attention": 2.7753477096557617,
      "attention_bam_384_min_attention": -1.1597533226013184,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7086083651791832,
      "attention_bam_384_attention_skewness": 0.6881402130862996,
      "attention_bam_384_attention_sparsity": 0.5292078653971354,
      "attention_bam_384_attention_concentration_10": 0.9208542997425371,
      "attention_bam_384_attention_concentration_20": 1.4338006806084544,
      "attention_bam_384_attention_center_y": 0.47895497359809536,
      "attention_bam_384_attention_center_x": 0.48851802770267766,
      "attention_bam_384_attention_center_distance": 0.033903652431363236,
      "attention_bam_384_attention_spatial_variance": 170.9648567344774,
      "attention_bam_384_attention_spatial_std": 13.075353025233293,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 19.46438726430861,
      "attention_bam_384_peak_intensity_mean": 0.32637256383895874,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18104100227355957,
      "attention_bam_16_std_attention": 0.648539125919342,
      "attention_bam_16_max_attention": 3.0995378494262695,
      "attention_bam_16_min_attention": -1.221906065940857,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7026353372545509,
      "attention_bam_16_attention_skewness": 0.909481473818987,
      "attention_bam_16_attention_sparsity": 0.522705078125,
      "attention_bam_16_attention_concentration_10": 0.8528556340185328,
      "attention_bam_16_attention_concentration_20": 1.3293163084653505,
      "attention_bam_16_attention_center_y": 0.4538635584663391,
      "attention_bam_16_attention_center_x": 0.4809988164254215,
      "attention_bam_16_attention_center_distance": 0.07056367641533061,
      "attention_bam_16_attention_spatial_variance": 42.79114261193963,
      "attention_bam_16_attention_spatial_std": 6.541493912856575,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 10.364244738606276,
      "attention_bam_16_peak_intensity_mean": 0.3390728235244751,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 267,
      "phase": "train",
      "loss": 0.007502625696361065,
      "timestamp": 1759543923.6701875,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007502625696361065,
      "ssim": 0.8753948211669922,
      "attention_bam_384_mean_attention": 0.11536290496587753,
      "attention_bam_384_std_attention": 0.42047396302223206,
      "attention_bam_384_max_attention": 3.283900499343872,
      "attention_bam_384_min_attention": -1.2346514463424683,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6007307193573812,
      "attention_bam_384_attention_skewness": 0.5905567048546888,
      "attention_bam_384_attention_sparsity": 0.5161997477213541,
      "attention_bam_384_attention_concentration_10": 0.8126093512248904,
      "attention_bam_384_attention_concentration_20": 1.2820621365540914,
      "attention_bam_384_attention_center_y": 0.48444642817912215,
      "attention_bam_384_attention_center_x": 0.4783911236627281,
      "attention_bam_384_attention_center_distance": 0.037652546605686954,
      "attention_bam_384_attention_spatial_variance": 170.02014185876212,
      "attention_bam_384_attention_spatial_std": 13.039177192551765,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 17.569163766101866,
      "attention_bam_384_peak_intensity_mean": 0.3022180497646332,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18065235018730164,
      "attention_bam_16_std_attention": 0.572559654712677,
      "attention_bam_16_max_attention": 2.6262941360473633,
      "attention_bam_16_min_attention": -1.2015231847763062,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.40847139917853204,
      "attention_bam_16_attention_skewness": 0.7049150181558721,
      "attention_bam_16_attention_sparsity": 0.498046875,
      "attention_bam_16_attention_concentration_10": 0.7316004603899983,
      "attention_bam_16_attention_concentration_20": 1.1688280011660532,
      "attention_bam_16_attention_center_y": 0.46855820439886886,
      "attention_bam_16_attention_center_x": 0.4557769160151961,
      "attention_bam_16_attention_center_distance": 0.07673679258022618,
      "attention_bam_16_attention_spatial_variance": 42.0368645101232,
      "attention_bam_16_attention_spatial_std": 6.483584233286647,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.18846002576334,
      "attention_bam_16_peak_intensity_mean": 0.37766900658607483,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 268,
      "phase": "train",
      "loss": 0.005460366606712341,
      "timestamp": 1759543923.813845,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005460366606712341,
      "ssim": 0.8955014944076538,
      "attention_bam_384_mean_attention": 0.11145009845495224,
      "attention_bam_384_std_attention": 0.4553467631340027,
      "attention_bam_384_max_attention": 3.9085910320281982,
      "attention_bam_384_min_attention": -1.4289195537567139,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.0430398459974963,
      "attention_bam_384_attention_skewness": 0.9455390817810687,
      "attention_bam_384_attention_sparsity": 0.5363032023111979,
      "attention_bam_384_attention_concentration_10": 0.927000372762477,
      "attention_bam_384_attention_concentration_20": 1.4238526583716737,
      "attention_bam_384_attention_center_y": 0.4911046725802252,
      "attention_bam_384_attention_center_x": 0.4857082711676485,
      "attention_bam_384_attention_center_distance": 0.02380673698441115,
      "attention_bam_384_attention_spatial_variance": 172.44950411768474,
      "attention_bam_384_attention_spatial_std": 13.132003050475001,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 17.444206001193933,
      "attention_bam_384_peak_intensity_mean": 0.292471706867218,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16204333305358887,
      "attention_bam_16_std_attention": 0.6218740344047546,
      "attention_bam_16_max_attention": 3.2246253490448,
      "attention_bam_16_min_attention": -1.1219761371612549,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.6718513523737206,
      "attention_bam_16_attention_skewness": 1.0791678657177044,
      "attention_bam_16_attention_sparsity": 0.525390625,
      "attention_bam_16_attention_concentration_10": 0.9049030469555083,
      "attention_bam_16_attention_concentration_20": 1.3886353303432757,
      "attention_bam_16_attention_center_y": 0.48791420749382586,
      "attention_bam_16_attention_center_x": 0.474249920403625,
      "attention_bam_16_attention_center_distance": 0.04022767653548841,
      "attention_bam_16_attention_spatial_variance": 43.89861986724435,
      "attention_bam_16_attention_spatial_std": 6.6256033587322705,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.986119903063564,
      "attention_bam_16_peak_intensity_mean": 0.31153789162635803,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 269,
      "phase": "train",
      "loss": 0.006334502249956131,
      "timestamp": 1759543923.9578,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006334502249956131,
      "ssim": 0.8848559856414795,
      "attention_bam_384_mean_attention": 0.11554829031229019,
      "attention_bam_384_std_attention": 0.39965736865997314,
      "attention_bam_384_max_attention": 2.9253761768341064,
      "attention_bam_384_min_attention": -1.2328062057495117,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6751637049978751,
      "attention_bam_384_attention_skewness": 0.528144092653466,
      "attention_bam_384_attention_sparsity": 0.5116475423177084,
      "attention_bam_384_attention_concentration_10": 0.7627040670345119,
      "attention_bam_384_attention_concentration_20": 1.2155421085135991,
      "attention_bam_384_attention_center_y": 0.48277909862052343,
      "attention_bam_384_attention_center_x": 0.48425627748672334,
      "attention_bam_384_attention_center_distance": 0.032997704250347856,
      "attention_bam_384_attention_spatial_variance": 170.78050208239762,
      "attention_bam_384_attention_spatial_std": 13.068301423000527,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 18.008543240830456,
      "attention_bam_384_peak_intensity_mean": 0.32788339257240295,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18678933382034302,
      "attention_bam_16_std_attention": 0.5574252009391785,
      "attention_bam_16_max_attention": 2.4681944847106934,
      "attention_bam_16_min_attention": -1.090050220489502,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.2167475222998254,
      "attention_bam_16_attention_skewness": 0.5912073078567349,
      "attention_bam_16_attention_sparsity": 0.475830078125,
      "attention_bam_16_attention_concentration_10": 0.6875497199001973,
      "attention_bam_16_attention_concentration_20": 1.1005443063480087,
      "attention_bam_16_attention_center_y": 0.4653065005876159,
      "attention_bam_16_attention_center_x": 0.4730377114428737,
      "attention_bam_16_attention_center_distance": 0.0621386177141854,
      "attention_bam_16_attention_spatial_variance": 42.82336290469133,
      "attention_bam_16_attention_spatial_std": 6.543956212009012,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.006731787937559,
      "attention_bam_16_peak_intensity_mean": 0.36829400062561035,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 270,
      "phase": "train",
      "loss": 0.004674128722399473,
      "timestamp": 1759543924.1382072,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004674128722399473,
      "ssim": 0.900266706943512,
      "attention_bam_384_mean_attention": 0.11052047461271286,
      "attention_bam_384_std_attention": 0.42138490080833435,
      "attention_bam_384_max_attention": 3.1505722999572754,
      "attention_bam_384_min_attention": -1.2694952487945557,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0100713612161627,
      "attention_bam_384_attention_skewness": 0.7091215299292398,
      "attention_bam_384_attention_sparsity": 0.5298792521158854,
      "attention_bam_384_attention_concentration_10": 0.8599216833977702,
      "attention_bam_384_attention_concentration_20": 1.3359387633020772,
      "attention_bam_384_attention_center_y": 0.4815432043146323,
      "attention_bam_384_attention_center_x": 0.4837214519370009,
      "attention_bam_384_attention_center_distance": 0.03480357550628323,
      "attention_bam_384_attention_spatial_variance": 173.19683521210615,
      "attention_bam_384_attention_spatial_std": 13.160426862837928,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 16.696481076673063,
      "attention_bam_384_peak_intensity_mean": 0.31598761677742004,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1722475290298462,
      "attention_bam_16_std_attention": 0.5909645557403564,
      "attention_bam_16_max_attention": 2.6598286628723145,
      "attention_bam_16_min_attention": -1.1102641820907593,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8200466937649935,
      "attention_bam_16_attention_skewness": 0.8552398592443071,
      "attention_bam_16_attention_sparsity": 0.5078125,
      "attention_bam_16_attention_concentration_10": 0.8001341945479313,
      "attention_bam_16_attention_concentration_20": 1.2593081470937149,
      "attention_bam_16_attention_center_y": 0.4622324082992401,
      "attention_bam_16_attention_center_x": 0.4710903455019765,
      "attention_bam_16_attention_center_distance": 0.06726305235521798,
      "attention_bam_16_attention_spatial_variance": 44.248797640366554,
      "attention_bam_16_attention_spatial_std": 6.65197697232684,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.899931101997405,
      "attention_bam_16_peak_intensity_mean": 0.3437173366546631,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 271,
      "phase": "train",
      "loss": 0.006569835357367992,
      "timestamp": 1759543924.268443,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006569835357367992,
      "ssim": 0.8613429069519043,
      "attention_bam_384_mean_attention": 0.10955566167831421,
      "attention_bam_384_std_attention": 0.41820135712623596,
      "attention_bam_384_max_attention": 2.6883249282836914,
      "attention_bam_384_min_attention": -1.1469337940216064,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9047334793656181,
      "attention_bam_384_attention_skewness": 0.7462391347926741,
      "attention_bam_384_attention_sparsity": 0.5329767862955729,
      "attention_bam_384_attention_concentration_10": 0.8652861373813601,
      "attention_bam_384_attention_concentration_20": 1.345650536613256,
      "attention_bam_384_attention_center_y": 0.4863005415371589,
      "attention_bam_384_attention_center_x": 0.48981360984325034,
      "attention_bam_384_attention_center_distance": 0.02414281286845569,
      "attention_bam_384_attention_spatial_variance": 171.29929018718101,
      "attention_bam_384_attention_spatial_std": 13.08813547405363,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 16.15117180115395,
      "attention_bam_384_peak_intensity_mean": 0.3361262381076813,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17933697998523712,
      "attention_bam_16_std_attention": 0.5939844846725464,
      "attention_bam_16_max_attention": 2.887204170227051,
      "attention_bam_16_min_attention": -1.200984239578247,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7177286646258567,
      "attention_bam_16_attention_skewness": 0.8395145299271946,
      "attention_bam_16_attention_sparsity": 0.509033203125,
      "attention_bam_16_attention_concentration_10": 0.7745774630286105,
      "attention_bam_16_attention_concentration_20": 1.2224947675802393,
      "attention_bam_16_attention_center_y": 0.4751030732250358,
      "attention_bam_16_attention_center_x": 0.48503644344497304,
      "attention_bam_16_attention_center_distance": 0.04107955665810961,
      "attention_bam_16_attention_spatial_variance": 43.04786613285864,
      "attention_bam_16_attention_spatial_std": 6.561087267584439,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 9.7152308953669,
      "attention_bam_16_peak_intensity_mean": 0.35729965567588806,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 272,
      "phase": "train",
      "loss": 0.005390016362071037,
      "timestamp": 1759543924.4213018,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005390016362071037,
      "ssim": 0.8887228965759277,
      "attention_bam_384_mean_attention": 0.11345567554235458,
      "attention_bam_384_std_attention": 0.4557287096977234,
      "attention_bam_384_max_attention": 2.952072858810425,
      "attention_bam_384_min_attention": -1.2373062372207642,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.0879957625672132,
      "attention_bam_384_attention_skewness": 0.5203159744426044,
      "attention_bam_384_attention_sparsity": 0.5249303181966146,
      "attention_bam_384_attention_concentration_10": 0.8774478754679614,
      "attention_bam_384_attention_concentration_20": 1.4047372422051938,
      "attention_bam_384_attention_center_y": 0.48187098101741693,
      "attention_bam_384_attention_center_x": 0.48904228331919275,
      "attention_bam_384_attention_center_distance": 0.029957733029309763,
      "attention_bam_384_attention_spatial_variance": 169.47677177971067,
      "attention_bam_384_attention_spatial_std": 13.018324461301104,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 16.729025776296798,
      "attention_bam_384_peak_intensity_mean": 0.32403409481048584,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18124771118164062,
      "attention_bam_16_std_attention": 0.616668164730072,
      "attention_bam_16_max_attention": 2.5878407955169678,
      "attention_bam_16_min_attention": -1.1688477993011475,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.1400382831979181,
      "attention_bam_16_attention_skewness": 0.5641563613903647,
      "attention_bam_16_attention_sparsity": 0.491455078125,
      "attention_bam_16_attention_concentration_10": 0.7568896440082838,
      "attention_bam_16_attention_concentration_20": 1.2362938827101797,
      "attention_bam_16_attention_center_y": 0.4660503743373963,
      "attention_bam_16_attention_center_x": 0.4824062263760873,
      "attention_bam_16_attention_center_distance": 0.054076204618305146,
      "attention_bam_16_attention_spatial_variance": 41.74412608284206,
      "attention_bam_16_attention_spatial_std": 6.460969438315125,
      "attention_bam_16_num_attention_peaks": 11,
      "attention_bam_16_peak_separation_mean": 7.267395940498079,
      "attention_bam_16_peak_intensity_mean": 0.3647085130214691,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 273,
      "phase": "train",
      "loss": 0.0069220419973134995,
      "timestamp": 1759543924.5958238,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0069220419973134995,
      "ssim": 0.8528751134872437,
      "attention_bam_384_mean_attention": 0.11140316724777222,
      "attention_bam_384_std_attention": 0.45352861285209656,
      "attention_bam_384_max_attention": 3.8567123413085938,
      "attention_bam_384_min_attention": -1.2835967540740967,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.138730521576539,
      "attention_bam_384_attention_skewness": 0.8599422601738312,
      "attention_bam_384_attention_sparsity": 0.5257492065429688,
      "attention_bam_384_attention_concentration_10": 0.9062603607385344,
      "attention_bam_384_attention_concentration_20": 1.3991130003804475,
      "attention_bam_384_attention_center_y": 0.48084963005877035,
      "attention_bam_384_attention_center_x": 0.4832674463111106,
      "attention_bam_384_attention_center_distance": 0.03596428844944711,
      "attention_bam_384_attention_spatial_variance": 169.35223847410555,
      "attention_bam_384_attention_spatial_std": 13.01354058179808,
      "attention_bam_384_num_attention_peaks": 20,
      "attention_bam_384_peak_separation_mean": 18.01345906341177,
      "attention_bam_384_peak_intensity_mean": 0.27242138981819153,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17896121740341187,
      "attention_bam_16_std_attention": 0.6309845447540283,
      "attention_bam_16_max_attention": 4.13220739364624,
      "attention_bam_16_min_attention": -1.0770151615142822,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.593902132846461,
      "attention_bam_16_attention_skewness": 1.0765560329171318,
      "attention_bam_16_attention_sparsity": 0.499267578125,
      "attention_bam_16_attention_concentration_10": 0.8175682629296045,
      "attention_bam_16_attention_concentration_20": 1.2670330537574226,
      "attention_bam_16_attention_center_y": 0.4593543282510865,
      "attention_bam_16_attention_center_x": 0.4683427646880382,
      "attention_bam_16_attention_center_distance": 0.07285946993380263,
      "attention_bam_16_attention_spatial_variance": 41.3970609432355,
      "attention_bam_16_attention_spatial_std": 6.434054782424183,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 7.397427702040403,
      "attention_bam_16_peak_intensity_mean": 0.24710315465927124,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 274,
      "phase": "train",
      "loss": 0.008767685852944851,
      "timestamp": 1759543924.7607338,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008767685852944851,
      "ssim": 0.8759475946426392,
      "attention_bam_384_mean_attention": 0.11098432540893555,
      "attention_bam_384_std_attention": 0.40888330340385437,
      "attention_bam_384_max_attention": 3.0823147296905518,
      "attention_bam_384_min_attention": -1.1768184900283813,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.38497003116298245,
      "attention_bam_384_attention_skewness": 0.546983967175112,
      "attention_bam_384_attention_sparsity": 0.5201746622721354,
      "attention_bam_384_attention_concentration_10": 0.8039700509698797,
      "attention_bam_384_attention_concentration_20": 1.2910722367104668,
      "attention_bam_384_attention_center_y": 0.4808009032819593,
      "attention_bam_384_attention_center_x": 0.4814183901221643,
      "attention_bam_384_attention_center_distance": 0.03778575235299047,
      "attention_bam_384_attention_spatial_variance": 169.84981765685413,
      "attention_bam_384_attention_spatial_std": 13.032644307923627,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 17.45658471197269,
      "attention_bam_384_peak_intensity_mean": 0.3045421242713928,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18401744961738586,
      "attention_bam_16_std_attention": 0.5700114965438843,
      "attention_bam_16_max_attention": 2.8671224117279053,
      "attention_bam_16_min_attention": -1.0311490297317505,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.2590801989135243,
      "attention_bam_16_attention_skewness": 0.620502144442281,
      "attention_bam_16_attention_sparsity": 0.483642578125,
      "attention_bam_16_attention_concentration_10": 0.7049945413383386,
      "attention_bam_16_attention_concentration_20": 1.135498228939324,
      "attention_bam_16_attention_center_y": 0.45584765696949064,
      "attention_bam_16_attention_center_x": 0.4620450119544014,
      "attention_bam_16_attention_center_distance": 0.08234088307305552,
      "attention_bam_16_attention_spatial_variance": 41.834530065553714,
      "attention_bam_16_attention_spatial_std": 6.467961816952363,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 10.112037936043182,
      "attention_bam_16_peak_intensity_mean": 0.31398332118988037,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 275,
      "phase": "train",
      "loss": 0.005753647070378065,
      "timestamp": 1759543924.9148479,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005753647070378065,
      "ssim": 0.8811764717102051,
      "attention_bam_384_mean_attention": 0.11186736077070236,
      "attention_bam_384_std_attention": 0.428305059671402,
      "attention_bam_384_max_attention": 3.3597428798675537,
      "attention_bam_384_min_attention": -1.3765047788619995,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9180245502751414,
      "attention_bam_384_attention_skewness": 0.6114339972537735,
      "attention_bam_384_attention_sparsity": 0.5216700236002604,
      "attention_bam_384_attention_concentration_10": 0.8488804262023513,
      "attention_bam_384_attention_concentration_20": 1.333943702908256,
      "attention_bam_384_attention_center_y": 0.48121763084853275,
      "attention_bam_384_attention_center_x": 0.48664760466505314,
      "attention_bam_384_attention_center_distance": 0.03259030076948353,
      "attention_bam_384_attention_spatial_variance": 171.93367652232297,
      "attention_bam_384_attention_spatial_std": 13.11234824592159,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 18.545876810115043,
      "attention_bam_384_peak_intensity_mean": 0.3176390528678894,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18495222926139832,
      "attention_bam_16_std_attention": 0.5891148447990417,
      "attention_bam_16_max_attention": 2.9847495555877686,
      "attention_bam_16_min_attention": -1.1639724969863892,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.4798839941042363,
      "attention_bam_16_attention_skewness": 0.6549473715943667,
      "attention_bam_16_attention_sparsity": 0.485595703125,
      "attention_bam_16_attention_concentration_10": 0.7296113562866561,
      "attention_bam_16_attention_concentration_20": 1.1589897271295602,
      "attention_bam_16_attention_center_y": 0.45681256980744384,
      "attention_bam_16_attention_center_x": 0.4722631956281694,
      "attention_bam_16_attention_center_distance": 0.07258766346147413,
      "attention_bam_16_attention_spatial_variance": 43.21298360888489,
      "attention_bam_16_attention_spatial_std": 6.573658312453188,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.548300083761943,
      "attention_bam_16_peak_intensity_mean": 0.33034273982048035,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 276,
      "phase": "train",
      "loss": 0.006321682594716549,
      "timestamp": 1759543925.0552924,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006321682594716549,
      "ssim": 0.8695756196975708,
      "attention_bam_384_mean_attention": 0.10784256458282471,
      "attention_bam_384_std_attention": 0.3974257707595825,
      "attention_bam_384_max_attention": 2.766134023666382,
      "attention_bam_384_min_attention": -1.214680552482605,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.3652493493013793,
      "attention_bam_384_attention_skewness": 0.8210210526208309,
      "attention_bam_384_attention_sparsity": 0.5363667805989584,
      "attention_bam_384_attention_concentration_10": 0.8421918335175526,
      "attention_bam_384_attention_concentration_20": 1.3029860199919772,
      "attention_bam_384_attention_center_y": 0.4941248693917663,
      "attention_bam_384_attention_center_x": 0.4865659368930267,
      "attention_bam_384_attention_center_distance": 0.020736017516675948,
      "attention_bam_384_attention_spatial_variance": 171.11916208014682,
      "attention_bam_384_attention_spatial_std": 13.081252313144443,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 19.246407449967116,
      "attention_bam_384_peak_intensity_mean": 0.3344988524913788,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1787288784980774,
      "attention_bam_16_std_attention": 0.5782532691955566,
      "attention_bam_16_max_attention": 2.9020867347717285,
      "attention_bam_16_min_attention": -0.9856900572776794,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.2120430954381973,
      "attention_bam_16_attention_skewness": 0.9553807164134028,
      "attention_bam_16_attention_sparsity": 0.503173828125,
      "attention_bam_16_attention_concentration_10": 0.77328816072456,
      "attention_bam_16_attention_concentration_20": 1.1940810678783176,
      "attention_bam_16_attention_center_y": 0.493273563604582,
      "attention_bam_16_attention_center_x": 0.4759211474079475,
      "attention_bam_16_attention_center_distance": 0.035356359788060676,
      "attention_bam_16_attention_spatial_variance": 42.77221217705556,
      "attention_bam_16_attention_spatial_std": 6.540046802359717,
      "attention_bam_16_num_attention_peaks": 2,
      "attention_bam_16_peak_separation_mean": 9.946655237476724,
      "attention_bam_16_peak_intensity_mean": 0.29758769273757935,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 277,
      "phase": "train",
      "loss": 0.007199970539659262,
      "timestamp": 1759543925.1876006,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007199970539659262,
      "ssim": 0.8652420043945312,
      "attention_bam_384_mean_attention": 0.10891321301460266,
      "attention_bam_384_std_attention": 0.38016340136528015,
      "attention_bam_384_max_attention": 3.7052249908447266,
      "attention_bam_384_min_attention": -1.1311874389648438,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.3963635245100168,
      "attention_bam_384_attention_skewness": 0.7271017062740271,
      "attention_bam_384_attention_sparsity": 0.5264383951822916,
      "attention_bam_384_attention_concentration_10": 0.7838128900247113,
      "attention_bam_384_attention_concentration_20": 1.2351068717347489,
      "attention_bam_384_attention_center_y": 0.4811442764926955,
      "attention_bam_384_attention_center_x": 0.47550940850412265,
      "attention_bam_384_attention_center_distance": 0.043711037068499214,
      "attention_bam_384_attention_spatial_variance": 170.5842634047215,
      "attention_bam_384_attention_spatial_std": 13.060791071168756,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 17.405410205191462,
      "attention_bam_384_peak_intensity_mean": 0.2571030855178833,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18326427042484283,
      "attention_bam_16_std_attention": 0.5479277968406677,
      "attention_bam_16_max_attention": 3.252774238586426,
      "attention_bam_16_min_attention": -1.1528433561325073,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.2388925516071456,
      "attention_bam_16_attention_skewness": 0.8195625973779364,
      "attention_bam_16_attention_sparsity": 0.48583984375,
      "attention_bam_16_attention_concentration_10": 0.6957389737664861,
      "attention_bam_16_attention_concentration_20": 1.1011969843389875,
      "attention_bam_16_attention_center_y": 0.4589681368799967,
      "attention_bam_16_attention_center_x": 0.4493199756536857,
      "attention_bam_16_attention_center_distance": 0.09221798803749402,
      "attention_bam_16_attention_spatial_variance": 42.32146945839269,
      "attention_bam_16_attention_spatial_std": 6.505495327674342,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 7.888793698581982,
      "attention_bam_16_peak_intensity_mean": 0.3122337758541107,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 278,
      "phase": "train",
      "loss": 0.0042844247072935104,
      "timestamp": 1759543925.3208084,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0042844247072935104,
      "ssim": 0.9108481407165527,
      "attention_bam_384_mean_attention": 0.10785537213087082,
      "attention_bam_384_std_attention": 0.45620784163475037,
      "attention_bam_384_max_attention": 2.93451189994812,
      "attention_bam_384_min_attention": -1.2106592655181885,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9117449343852342,
      "attention_bam_384_attention_skewness": 0.8052225927920852,
      "attention_bam_384_attention_sparsity": 0.5418268839518229,
      "attention_bam_384_attention_concentration_10": 0.9678837130838736,
      "attention_bam_384_attention_concentration_20": 1.4902395000050368,
      "attention_bam_384_attention_center_y": 0.4813160057592265,
      "attention_bam_384_attention_center_x": 0.48682082134207183,
      "attention_bam_384_attention_center_distance": 0.032335194166321204,
      "attention_bam_384_attention_spatial_variance": 168.66713772336024,
      "attention_bam_384_attention_spatial_std": 12.98719129463181,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 17.772457197182327,
      "attention_bam_384_peak_intensity_mean": 0.3206435739994049,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17273667454719543,
      "attention_bam_16_std_attention": 0.6336904168128967,
      "attention_bam_16_max_attention": 3.157243251800537,
      "attention_bam_16_min_attention": -1.005469799041748,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6619003147757558,
      "attention_bam_16_attention_skewness": 0.8953195937220382,
      "attention_bam_16_attention_sparsity": 0.526123046875,
      "attention_bam_16_attention_concentration_10": 0.858808305116793,
      "attention_bam_16_attention_concentration_20": 1.356795910873028,
      "attention_bam_16_attention_center_y": 0.4606894941134732,
      "attention_bam_16_attention_center_x": 0.47810188795875724,
      "attention_bam_16_attention_center_distance": 0.06363714613377125,
      "attention_bam_16_attention_spatial_variance": 40.95453558335516,
      "attention_bam_16_attention_spatial_std": 6.399573078210386,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 7.964015337815233,
      "attention_bam_16_peak_intensity_mean": 0.29462531208992004,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 279,
      "phase": "train",
      "loss": 0.007103726267814636,
      "timestamp": 1759543925.4566958,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007103726267814636,
      "ssim": 0.8385519981384277,
      "attention_bam_384_mean_attention": 0.10551980137825012,
      "attention_bam_384_std_attention": 0.4078785479068756,
      "attention_bam_384_max_attention": 3.5503435134887695,
      "attention_bam_384_min_attention": -1.1814186573028564,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.6905950343323308,
      "attention_bam_384_attention_skewness": 0.877144494043817,
      "attention_bam_384_attention_sparsity": 0.5399729410807291,
      "attention_bam_384_attention_concentration_10": 0.8838073461128578,
      "attention_bam_384_attention_concentration_20": 1.359931974959875,
      "attention_bam_384_attention_center_y": 0.48084462190462623,
      "attention_bam_384_attention_center_x": 0.4814240004305398,
      "attention_bam_384_attention_center_distance": 0.03773582568279939,
      "attention_bam_384_attention_spatial_variance": 170.0680291588515,
      "attention_bam_384_attention_spatial_std": 13.041013348618714,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 18.03382516921364,
      "attention_bam_384_peak_intensity_mean": 0.2732861042022705,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17281505465507507,
      "attention_bam_16_std_attention": 0.5841394662857056,
      "attention_bam_16_max_attention": 3.254678249359131,
      "attention_bam_16_min_attention": -1.0404597520828247,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.8393713471540947,
      "attention_bam_16_attention_skewness": 1.0993219199295552,
      "attention_bam_16_attention_sparsity": 0.5234375,
      "attention_bam_16_attention_concentration_10": 0.8124134829160217,
      "attention_bam_16_attention_concentration_20": 1.2454379085106972,
      "attention_bam_16_attention_center_y": 0.46046121930516876,
      "attention_bam_16_attention_center_x": 0.4630652467378899,
      "attention_bam_16_attention_center_distance": 0.07651785644366826,
      "attention_bam_16_attention_spatial_variance": 42.10603489066761,
      "attention_bam_16_attention_spatial_std": 6.488916310961916,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.776534552242486,
      "attention_bam_16_peak_intensity_mean": 0.2942447066307068,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 280,
      "phase": "train",
      "loss": 0.00601707911118865,
      "timestamp": 1759543925.6317255,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00601707911118865,
      "ssim": 0.8738605976104736,
      "attention_bam_384_mean_attention": 0.11050865054130554,
      "attention_bam_384_std_attention": 0.4746311902999878,
      "attention_bam_384_max_attention": 5.266130447387695,
      "attention_bam_384_min_attention": -1.4268678426742554,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 4.430793124868322,
      "attention_bam_384_attention_skewness": 1.2354721202136565,
      "attention_bam_384_attention_sparsity": 0.5380783081054688,
      "attention_bam_384_attention_concentration_10": 0.9669656104523373,
      "attention_bam_384_attention_concentration_20": 1.4666296301786468,
      "attention_bam_384_attention_center_y": 0.4888522598014122,
      "attention_bam_384_attention_center_x": 0.49190843430472325,
      "attention_bam_384_attention_center_distance": 0.019480531149647293,
      "attention_bam_384_attention_spatial_variance": 173.24015702523033,
      "attention_bam_384_attention_spatial_std": 13.162072672084376,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 19.463390655496383,
      "attention_bam_384_peak_intensity_mean": 0.23255090415477753,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1801508665084839,
      "attention_bam_16_std_attention": 0.6688416600227356,
      "attention_bam_16_max_attention": 4.9141106605529785,
      "attention_bam_16_min_attention": -1.2207331657409668,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 4.541082358527253,
      "attention_bam_16_attention_skewness": 1.511450745692195,
      "attention_bam_16_attention_sparsity": 0.530517578125,
      "attention_bam_16_attention_concentration_10": 0.8801328732059799,
      "attention_bam_16_attention_concentration_20": 1.3392766747104625,
      "attention_bam_16_attention_center_y": 0.4812449233332817,
      "attention_bam_16_attention_center_x": 0.4887422104107744,
      "attention_bam_16_attention_center_distance": 0.030935116848324846,
      "attention_bam_16_attention_spatial_variance": 44.16226719003998,
      "attention_bam_16_attention_spatial_std": 6.645469674149449,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.05644549347911,
      "attention_bam_16_peak_intensity_mean": 0.23759222030639648,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 281,
      "phase": "train",
      "loss": 0.00874341931194067,
      "timestamp": 1759543925.7786102,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00874341931194067,
      "ssim": 0.8746334314346313,
      "attention_bam_384_mean_attention": 0.1088419035077095,
      "attention_bam_384_std_attention": 0.3828994333744049,
      "attention_bam_384_max_attention": 2.7591774463653564,
      "attention_bam_384_min_attention": -1.162682056427002,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6305410597330283,
      "attention_bam_384_attention_skewness": 0.5630726209257833,
      "attention_bam_384_attention_sparsity": 0.5247268676757812,
      "attention_bam_384_attention_concentration_10": 0.7877817364028358,
      "attention_bam_384_attention_concentration_20": 1.2467831314796631,
      "attention_bam_384_attention_center_y": 0.49138691189073264,
      "attention_bam_384_attention_center_x": 0.48424454019436786,
      "attention_bam_384_attention_center_distance": 0.025393692148440835,
      "attention_bam_384_attention_spatial_variance": 170.53947581224094,
      "attention_bam_384_attention_spatial_std": 13.059076376690694,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 15.373956375823886,
      "attention_bam_384_peak_intensity_mean": 0.32831308245658875,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17721474170684814,
      "attention_bam_16_std_attention": 0.5504648089408875,
      "attention_bam_16_max_attention": 2.6763861179351807,
      "attention_bam_16_min_attention": -1.0326368808746338,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.11390150858227033,
      "attention_bam_16_attention_skewness": 0.6355776870056123,
      "attention_bam_16_attention_sparsity": 0.502197265625,
      "attention_bam_16_attention_concentration_10": 0.7149622288569827,
      "attention_bam_16_attention_concentration_20": 1.1483918679231129,
      "attention_bam_16_attention_center_y": 0.4926957572719144,
      "attention_bam_16_attention_center_x": 0.47088820217696703,
      "attention_bam_16_attention_center_distance": 0.04244640701684746,
      "attention_bam_16_attention_spatial_variance": 42.86561016692998,
      "attention_bam_16_attention_spatial_std": 6.547183376607836,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 7.734654173231434,
      "attention_bam_16_peak_intensity_mean": 0.3330569565296173,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 282,
      "phase": "train",
      "loss": 0.005838240496814251,
      "timestamp": 1759543925.9191248,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005838240496814251,
      "ssim": 0.8795467019081116,
      "attention_bam_384_mean_attention": 0.10930278152227402,
      "attention_bam_384_std_attention": 0.41669920086860657,
      "attention_bam_384_max_attention": 2.8851168155670166,
      "attention_bam_384_min_attention": -1.173710584640503,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6679265789791184,
      "attention_bam_384_attention_skewness": 0.6201991828201177,
      "attention_bam_384_attention_sparsity": 0.5296478271484375,
      "attention_bam_384_attention_concentration_10": 0.854079397039349,
      "attention_bam_384_attention_concentration_20": 1.3425153174949602,
      "attention_bam_384_attention_center_y": 0.48236549645397087,
      "attention_bam_384_attention_center_x": 0.48394544872434764,
      "attention_bam_384_attention_center_distance": 0.03372608284332662,
      "attention_bam_384_attention_spatial_variance": 170.8788712765158,
      "attention_bam_384_attention_spatial_std": 13.072064537651114,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 19.051491346717313,
      "attention_bam_384_peak_intensity_mean": 0.3232164680957794,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19105303287506104,
      "attention_bam_16_std_attention": 0.5839591026306152,
      "attention_bam_16_max_attention": 2.6145684719085693,
      "attention_bam_16_min_attention": -1.0837881565093994,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.19810166974072496,
      "attention_bam_16_attention_skewness": 0.6583220258429175,
      "attention_bam_16_attention_sparsity": 0.48974609375,
      "attention_bam_16_attention_concentration_10": 0.7078157592026201,
      "attention_bam_16_attention_concentration_20": 1.1357862259622786,
      "attention_bam_16_attention_center_y": 0.46478964709212045,
      "attention_bam_16_attention_center_x": 0.47134275179587876,
      "attention_bam_16_attention_center_distance": 0.06420291000461009,
      "attention_bam_16_attention_spatial_variance": 42.71278447163609,
      "attention_bam_16_attention_spatial_std": 6.5355018530818345,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.65724090321784,
      "attention_bam_16_peak_intensity_mean": 0.36229902505874634,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 283,
      "phase": "train",
      "loss": 0.005617022514343262,
      "timestamp": 1759543926.0610194,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005617022514343262,
      "ssim": 0.9029982089996338,
      "attention_bam_384_mean_attention": 0.10860749334096909,
      "attention_bam_384_std_attention": 0.3931719660758972,
      "attention_bam_384_max_attention": 2.905618667602539,
      "attention_bam_384_min_attention": -1.1565375328063965,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8926471000814957,
      "attention_bam_384_attention_skewness": 0.6908624529518469,
      "attention_bam_384_attention_sparsity": 0.5308278401692709,
      "attention_bam_384_attention_concentration_10": 0.8100907106218401,
      "attention_bam_384_attention_concentration_20": 1.2831044560634228,
      "attention_bam_384_attention_center_y": 0.4850987454006492,
      "attention_bam_384_attention_center_x": 0.48534491067975893,
      "attention_bam_384_attention_center_distance": 0.02955736901751973,
      "attention_bam_384_attention_spatial_variance": 172.54394311984203,
      "attention_bam_384_attention_spatial_std": 13.135598316020554,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 19.240455468404253,
      "attention_bam_384_peak_intensity_mean": 0.31264936923980713,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1822628676891327,
      "attention_bam_16_std_attention": 0.5621171593666077,
      "attention_bam_16_max_attention": 2.9108948707580566,
      "attention_bam_16_min_attention": -0.984377384185791,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7297026956683652,
      "attention_bam_16_attention_skewness": 0.7665803251234051,
      "attention_bam_16_attention_sparsity": 0.49560546875,
      "attention_bam_16_attention_concentration_10": 0.712281303586908,
      "attention_bam_16_attention_concentration_20": 1.1385612863207806,
      "attention_bam_16_attention_center_y": 0.4713429855019758,
      "attention_bam_16_attention_center_x": 0.47477758426887084,
      "attention_bam_16_attention_center_distance": 0.05398879023008168,
      "attention_bam_16_attention_spatial_variance": 44.10948392126817,
      "attention_bam_16_attention_spatial_std": 6.641497114451543,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.4775226356551,
      "attention_bam_16_peak_intensity_mean": 0.30379894375801086,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 284,
      "phase": "train",
      "loss": 0.006003931164741516,
      "timestamp": 1759543926.1998408,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006003931164741516,
      "ssim": 0.9010028839111328,
      "attention_bam_384_mean_attention": 0.11045976728200912,
      "attention_bam_384_std_attention": 0.4095330834388733,
      "attention_bam_384_max_attention": 3.2148263454437256,
      "attention_bam_384_min_attention": -1.1917979717254639,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9110861772026899,
      "attention_bam_384_attention_skewness": 0.5946651771332033,
      "attention_bam_384_attention_sparsity": 0.5172780354817709,
      "attention_bam_384_attention_concentration_10": 0.8037445711235353,
      "attention_bam_384_attention_concentration_20": 1.284683023413886,
      "attention_bam_384_attention_center_y": 0.4796642760898941,
      "attention_bam_384_attention_center_x": 0.4791953057822558,
      "attention_bam_384_attention_center_distance": 0.04114309099817108,
      "attention_bam_384_attention_spatial_variance": 169.5946857576649,
      "attention_bam_384_attention_spatial_std": 13.022852443211699,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 16.63343564797573,
      "attention_bam_384_peak_intensity_mean": 0.2976626455783844,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19697806239128113,
      "attention_bam_16_std_attention": 0.572781503200531,
      "attention_bam_16_max_attention": 3.3076558113098145,
      "attention_bam_16_min_attention": -1.124763011932373,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.1467512279378864,
      "attention_bam_16_attention_skewness": 0.738855804633251,
      "attention_bam_16_attention_sparsity": 0.47216796875,
      "attention_bam_16_attention_concentration_10": 0.6608948621800541,
      "attention_bam_16_attention_concentration_20": 1.061442665658174,
      "attention_bam_16_attention_center_y": 0.4585423599239125,
      "attention_bam_16_attention_center_x": 0.45471265404600925,
      "attention_bam_16_attention_center_distance": 0.08682948375102616,
      "attention_bam_16_attention_spatial_variance": 41.57503769456052,
      "attention_bam_16_attention_spatial_std": 6.447870787675613,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 10.410958111950247,
      "attention_bam_16_peak_intensity_mean": 0.2955406904220581,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 285,
      "phase": "train",
      "loss": 0.007609107997268438,
      "timestamp": 1759543926.3387573,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007609107997268438,
      "ssim": 0.8807494640350342,
      "attention_bam_384_mean_attention": 0.11326507478952408,
      "attention_bam_384_std_attention": 0.3938257098197937,
      "attention_bam_384_max_attention": 2.8619794845581055,
      "attention_bam_384_min_attention": -1.1355836391448975,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0428368578410776,
      "attention_bam_384_attention_skewness": 0.6022273007550639,
      "attention_bam_384_attention_sparsity": 0.5174153645833334,
      "attention_bam_384_attention_concentration_10": 0.770049491143028,
      "attention_bam_384_attention_concentration_20": 1.2231927944372956,
      "attention_bam_384_attention_center_y": 0.4896119063067648,
      "attention_bam_384_attention_center_x": 0.4908495003170004,
      "attention_bam_384_attention_center_distance": 0.01957774936135448,
      "attention_bam_384_attention_spatial_variance": 170.33257493071793,
      "attention_bam_384_attention_spatial_std": 13.051152245327534,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 14.331184434452695,
      "attention_bam_384_peak_intensity_mean": 0.31748008728027344,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20664577186107635,
      "attention_bam_16_std_attention": 0.5631198883056641,
      "attention_bam_16_max_attention": 3.0889811515808105,
      "attention_bam_16_min_attention": -1.1254650354385376,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8748254587210775,
      "attention_bam_16_attention_skewness": 0.7173128307776556,
      "attention_bam_16_attention_sparsity": 0.4716796875,
      "attention_bam_16_attention_concentration_10": 0.633800635322089,
      "attention_bam_16_attention_concentration_20": 1.0223291961243137,
      "attention_bam_16_attention_center_y": 0.48278704936918904,
      "attention_bam_16_attention_center_x": 0.4914080649343234,
      "attention_bam_16_attention_center_distance": 0.02720687477795048,
      "attention_bam_16_attention_spatial_variance": 42.30621057933823,
      "attention_bam_16_attention_spatial_std": 6.504322453517986,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.479051443288471,
      "attention_bam_16_peak_intensity_mean": 0.32514938712120056,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 286,
      "phase": "train",
      "loss": 0.007826116867363453,
      "timestamp": 1759543926.476667,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007826116867363453,
      "ssim": 0.8843297958374023,
      "attention_bam_384_mean_attention": 0.10761425644159317,
      "attention_bam_384_std_attention": 0.45888975262641907,
      "attention_bam_384_max_attention": 3.1226367950439453,
      "attention_bam_384_min_attention": -1.264972448348999,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9682315679042159,
      "attention_bam_384_attention_skewness": 0.7225645876936913,
      "attention_bam_384_attention_sparsity": 0.5314127604166666,
      "attention_bam_384_attention_concentration_10": 0.9454185739131283,
      "attention_bam_384_attention_concentration_20": 1.473541573623328,
      "attention_bam_384_attention_center_y": 0.4841283246883489,
      "attention_bam_384_attention_center_x": 0.48705454435796874,
      "attention_bam_384_attention_center_distance": 0.028965320608557905,
      "attention_bam_384_attention_spatial_variance": 169.5550896878302,
      "attention_bam_384_attention_spatial_std": 13.021332101126605,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 15.992493663396635,
      "attention_bam_384_peak_intensity_mean": 0.31523221731185913,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16724538803100586,
      "attention_bam_16_std_attention": 0.6348360180854797,
      "attention_bam_16_max_attention": 3.699218511581421,
      "attention_bam_16_min_attention": -1.0891046524047852,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.1640617017844095,
      "attention_bam_16_attention_skewness": 0.9202128655751506,
      "attention_bam_16_attention_sparsity": 0.516845703125,
      "attention_bam_16_attention_concentration_10": 0.8721282064313769,
      "attention_bam_16_attention_concentration_20": 1.3710117245101925,
      "attention_bam_16_attention_center_y": 0.4680041847820603,
      "attention_bam_16_attention_center_x": 0.48180123267401015,
      "attention_bam_16_attention_center_distance": 0.05205626424641049,
      "attention_bam_16_attention_spatial_variance": 41.852662065839155,
      "attention_bam_16_attention_spatial_std": 6.4693633431613,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 8.497157518955275,
      "attention_bam_16_peak_intensity_mean": 0.2659158706665039,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 287,
      "phase": "train",
      "loss": 0.00612480565905571,
      "timestamp": 1759543926.6137402,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00612480565905571,
      "ssim": 0.8591628670692444,
      "attention_bam_384_mean_attention": 0.10419365018606186,
      "attention_bam_384_std_attention": 0.4071333408355713,
      "attention_bam_384_max_attention": 3.1938793659210205,
      "attention_bam_384_min_attention": -1.1788781881332397,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8730565982054523,
      "attention_bam_384_attention_skewness": 0.9025116262478992,
      "attention_bam_384_attention_sparsity": 0.5404027303059896,
      "attention_bam_384_attention_concentration_10": 0.8972533283193577,
      "attention_bam_384_attention_concentration_20": 1.3681077212739485,
      "attention_bam_384_attention_center_y": 0.4882753905387234,
      "attention_bam_384_attention_center_x": 0.48429316196779015,
      "attention_bam_384_attention_center_distance": 0.02771899089034559,
      "attention_bam_384_attention_spatial_variance": 172.1741568959402,
      "attention_bam_384_attention_spatial_std": 13.121515038132609,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 20.36295208584023,
      "attention_bam_384_peak_intensity_mean": 0.29491549730300903,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17137272655963898,
      "attention_bam_16_std_attention": 0.5992825031280518,
      "attention_bam_16_max_attention": 4.1681318283081055,
      "attention_bam_16_min_attention": -1.1297988891601562,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.886883571839955,
      "attention_bam_16_attention_skewness": 1.117602521244606,
      "attention_bam_16_attention_sparsity": 0.525390625,
      "attention_bam_16_attention_concentration_10": 0.8442301720942117,
      "attention_bam_16_attention_concentration_20": 1.2847972923732691,
      "attention_bam_16_attention_center_y": 0.47878659959914593,
      "attention_bam_16_attention_center_x": 0.46686892601876606,
      "attention_bam_16_attention_center_distance": 0.05563589524249523,
      "attention_bam_16_attention_spatial_variance": 43.52782976856049,
      "attention_bam_16_attention_spatial_std": 6.597562411115221,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.65560249943842,
      "attention_bam_16_peak_intensity_mean": 0.25061169266700745,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 288,
      "phase": "train",
      "loss": 0.010889618657529354,
      "timestamp": 1759543926.7516623,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.010889618657529354,
      "ssim": 0.8610310554504395,
      "attention_bam_384_mean_attention": 0.10566201061010361,
      "attention_bam_384_std_attention": 0.4266342520713806,
      "attention_bam_384_max_attention": 2.794137716293335,
      "attention_bam_384_min_attention": -1.153125286102295,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.47984995265808195,
      "attention_bam_384_attention_skewness": 0.6125327144669791,
      "attention_bam_384_attention_sparsity": 0.5294901529947916,
      "attention_bam_384_attention_concentration_10": 0.8987061837184239,
      "attention_bam_384_attention_concentration_20": 1.4100672922857087,
      "attention_bam_384_attention_center_y": 0.47756534837787634,
      "attention_bam_384_attention_center_x": 0.4818016401703582,
      "attention_bam_384_attention_center_distance": 0.04085324696753431,
      "attention_bam_384_attention_spatial_variance": 173.9482957300791,
      "attention_bam_384_attention_spatial_std": 13.188945967365212,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 19.864307366515476,
      "attention_bam_384_peak_intensity_mean": 0.32433879375457764,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17215004563331604,
      "attention_bam_16_std_attention": 0.6175438761711121,
      "attention_bam_16_max_attention": 3.0980305671691895,
      "attention_bam_16_min_attention": -1.1565607786178589,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6624999036965664,
      "attention_bam_16_attention_skewness": 0.7809930698636441,
      "attention_bam_16_attention_sparsity": 0.50439453125,
      "attention_bam_16_attention_concentration_10": 0.8203433732018068,
      "attention_bam_16_attention_concentration_20": 1.3008160623124478,
      "attention_bam_16_attention_center_y": 0.45102976453353044,
      "attention_bam_16_attention_center_x": 0.4639031774154452,
      "attention_bam_16_attention_center_distance": 0.08603562706626017,
      "attention_bam_16_attention_spatial_variance": 44.69561597019877,
      "attention_bam_16_attention_spatial_std": 6.6854779911535696,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 10.354138306730315,
      "attention_bam_16_peak_intensity_mean": 0.3195241689682007,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 289,
      "phase": "train",
      "loss": 0.006016659550368786,
      "timestamp": 1759543926.892614,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006016659550368786,
      "ssim": 0.9082765579223633,
      "attention_bam_384_mean_attention": 0.10563904047012329,
      "attention_bam_384_std_attention": 0.4387456178665161,
      "attention_bam_384_max_attention": 3.8911473751068115,
      "attention_bam_384_min_attention": -1.3163821697235107,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8950619875336363,
      "attention_bam_384_attention_skewness": 0.7912709273010198,
      "attention_bam_384_attention_sparsity": 0.5279973347981771,
      "attention_bam_384_attention_concentration_10": 0.910298351302878,
      "attention_bam_384_attention_concentration_20": 1.4186308900131193,
      "attention_bam_384_attention_center_y": 0.47992574589846765,
      "attention_bam_384_attention_center_x": 0.48027036687367,
      "attention_bam_384_attention_center_distance": 0.03980537905943033,
      "attention_bam_384_attention_spatial_variance": 171.05287662905974,
      "attention_bam_384_attention_spatial_std": 13.07871846279519,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 17.106996047763342,
      "attention_bam_384_peak_intensity_mean": 0.2725161015987396,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18136492371559143,
      "attention_bam_16_std_attention": 0.6358020305633545,
      "attention_bam_16_max_attention": 3.9344446659088135,
      "attention_bam_16_min_attention": -1.0967316627502441,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.7796572927123364,
      "attention_bam_16_attention_skewness": 0.9798821188787956,
      "attention_bam_16_attention_sparsity": 0.5068359375,
      "attention_bam_16_attention_concentration_10": 0.8099604689455526,
      "attention_bam_16_attention_concentration_20": 1.2705590757810477,
      "attention_bam_16_attention_center_y": 0.4534121994849361,
      "attention_bam_16_attention_center_x": 0.459630302366316,
      "attention_bam_16_attention_center_distance": 0.087179534798787,
      "attention_bam_16_attention_spatial_variance": 42.8752469046986,
      "attention_bam_16_attention_spatial_std": 6.547919280557649,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.010100232928437,
      "attention_bam_16_peak_intensity_mean": 0.2575945556163788,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 290,
      "phase": "train",
      "loss": 0.007052220404148102,
      "timestamp": 1759543927.0715816,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007052220404148102,
      "ssim": 0.8764683604240417,
      "attention_bam_384_mean_attention": 0.10720426589250565,
      "attention_bam_384_std_attention": 0.4140971004962921,
      "attention_bam_384_max_attention": 2.741729259490967,
      "attention_bam_384_min_attention": -1.2117165327072144,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8017471755195658,
      "attention_bam_384_attention_skewness": 0.6499005891120516,
      "attention_bam_384_attention_sparsity": 0.5306065877278646,
      "attention_bam_384_attention_concentration_10": 0.8656219898279331,
      "attention_bam_384_attention_concentration_20": 1.3543689567792287,
      "attention_bam_384_attention_center_y": 0.48433176992093996,
      "attention_bam_384_attention_center_x": 0.483544065337652,
      "attention_bam_384_attention_center_distance": 0.03213382079435399,
      "attention_bam_384_attention_spatial_variance": 170.1512186756267,
      "attention_bam_384_attention_spatial_std": 13.044202492894179,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 17.170353558391042,
      "attention_bam_384_peak_intensity_mean": 0.3394221067428589,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1930904984474182,
      "attention_bam_16_std_attention": 0.5948426127433777,
      "attention_bam_16_max_attention": 3.0393893718719482,
      "attention_bam_16_min_attention": -1.0636056661605835,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6864749679068183,
      "attention_bam_16_attention_skewness": 0.7856024313494433,
      "attention_bam_16_attention_sparsity": 0.4921875,
      "attention_bam_16_attention_concentration_10": 0.7239530936735236,
      "attention_bam_16_attention_concentration_20": 1.1483507901177252,
      "attention_bam_16_attention_center_y": 0.4690870395846885,
      "attention_bam_16_attention_center_x": 0.4688037950100204,
      "attention_bam_16_attention_center_distance": 0.062109811260628436,
      "attention_bam_16_attention_spatial_variance": 42.0043072939947,
      "attention_bam_16_attention_spatial_std": 6.481073004834516,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.261940208527806,
      "attention_bam_16_peak_intensity_mean": 0.3229106664657593,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 291,
      "phase": "train",
      "loss": 0.006305900868028402,
      "timestamp": 1759543927.2089617,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006305900868028402,
      "ssim": 0.8812080025672913,
      "attention_bam_384_mean_attention": 0.10858607292175293,
      "attention_bam_384_std_attention": 0.36082929372787476,
      "attention_bam_384_max_attention": 2.9504318237304688,
      "attention_bam_384_min_attention": -1.0993579626083374,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.38515721798164204,
      "attention_bam_384_attention_skewness": 0.40379595293916215,
      "attention_bam_384_attention_sparsity": 0.5129648844401041,
      "attention_bam_384_attention_concentration_10": 0.7359643065467867,
      "attention_bam_384_attention_concentration_20": 1.1744298957276207,
      "attention_bam_384_attention_center_y": 0.48256236582210443,
      "attention_bam_384_attention_center_x": 0.48465529121444323,
      "attention_bam_384_attention_center_distance": 0.032849084414505514,
      "attention_bam_384_attention_spatial_variance": 170.32210021183727,
      "attention_bam_384_attention_spatial_std": 13.050750944364744,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 17.209827644395503,
      "attention_bam_384_peak_intensity_mean": 0.29973068833351135,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20122724771499634,
      "attention_bam_16_std_attention": 0.5170508027076721,
      "attention_bam_16_max_attention": 2.4253804683685303,
      "attention_bam_16_min_attention": -1.006740927696228,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.14402411028659756,
      "attention_bam_16_attention_skewness": 0.48025783074559186,
      "attention_bam_16_attention_sparsity": 0.44921875,
      "attention_bam_16_attention_concentration_10": 0.5929879832263817,
      "attention_bam_16_attention_concentration_20": 0.9604498830315521,
      "attention_bam_16_attention_center_y": 0.4669484355346107,
      "attention_bam_16_attention_center_x": 0.4719454077399388,
      "attention_bam_16_attention_center_distance": 0.06131013065535043,
      "attention_bam_16_attention_spatial_variance": 42.17562532672028,
      "attention_bam_16_attention_spatial_std": 6.494276351274273,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.37279012966381,
      "attention_bam_16_peak_intensity_mean": 0.3566947281360626,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 292,
      "phase": "train",
      "loss": 0.009067369624972343,
      "timestamp": 1759543927.3526886,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.009067369624972343,
      "ssim": 0.8756670951843262,
      "attention_bam_384_mean_attention": 0.1060701385140419,
      "attention_bam_384_std_attention": 0.40555083751678467,
      "attention_bam_384_max_attention": 3.7971346378326416,
      "attention_bam_384_min_attention": -1.3890721797943115,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2155279724327794,
      "attention_bam_384_attention_skewness": 0.7131400634309571,
      "attention_bam_384_attention_sparsity": 0.5338083902994791,
      "attention_bam_384_attention_concentration_10": 0.8571813096294131,
      "attention_bam_384_attention_concentration_20": 1.338373775564261,
      "attention_bam_384_attention_center_y": 0.47716389132214493,
      "attention_bam_384_attention_center_x": 0.4842174456638362,
      "attention_bam_384_attention_center_distance": 0.03925753127543226,
      "attention_bam_384_attention_spatial_variance": 170.33175708421155,
      "attention_bam_384_attention_spatial_std": 13.051120912941215,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 18.259340357313896,
      "attention_bam_384_peak_intensity_mean": 0.28960275650024414,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18953511118888855,
      "attention_bam_16_std_attention": 0.6001272797584534,
      "attention_bam_16_max_attention": 3.2373015880584717,
      "attention_bam_16_min_attention": -1.0164364576339722,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8598307875726809,
      "attention_bam_16_attention_skewness": 0.7889766671060261,
      "attention_bam_16_attention_sparsity": 0.493408203125,
      "attention_bam_16_attention_concentration_10": 0.7367357454443751,
      "attention_bam_16_attention_concentration_20": 1.1679610323725849,
      "attention_bam_16_attention_center_y": 0.44367012537062267,
      "attention_bam_16_attention_center_x": 0.47031465550847334,
      "attention_bam_16_attention_center_distance": 0.09004748140111393,
      "attention_bam_16_attention_spatial_variance": 42.097349604842925,
      "attention_bam_16_attention_spatial_std": 6.488247036360663,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.719458304801412,
      "attention_bam_16_peak_intensity_mean": 0.28597694635391235,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 293,
      "phase": "train",
      "loss": 0.007823053747415543,
      "timestamp": 1759543927.500681,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007823053747415543,
      "ssim": 0.8416116833686829,
      "attention_bam_384_mean_attention": 0.10196942836046219,
      "attention_bam_384_std_attention": 0.41970327496528625,
      "attention_bam_384_max_attention": 3.1618731021881104,
      "attention_bam_384_min_attention": -1.2330228090286255,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4421141547011649,
      "attention_bam_384_attention_skewness": 0.8064427473315375,
      "attention_bam_384_attention_sparsity": 0.5393218994140625,
      "attention_bam_384_attention_concentration_10": 0.9218250451380072,
      "attention_bam_384_attention_concentration_20": 1.4312329809139115,
      "attention_bam_384_attention_center_y": 0.4800688269224725,
      "attention_bam_384_attention_center_x": 0.4811210429003144,
      "attention_bam_384_attention_center_distance": 0.03882439133890259,
      "attention_bam_384_attention_spatial_variance": 167.91551389769833,
      "attention_bam_384_attention_spatial_std": 12.958221864812252,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 16.767933110188796,
      "attention_bam_384_peak_intensity_mean": 0.30545157194137573,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16684311628341675,
      "attention_bam_16_std_attention": 0.6178342700004578,
      "attention_bam_16_max_attention": 3.3814632892608643,
      "attention_bam_16_min_attention": -1.1266841888427734,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.6855285460973013,
      "attention_bam_16_attention_skewness": 1.0804252537831947,
      "attention_bam_16_attention_sparsity": 0.52587890625,
      "attention_bam_16_attention_concentration_10": 0.8784390190796388,
      "attention_bam_16_attention_concentration_20": 1.3464328443698528,
      "attention_bam_16_attention_center_y": 0.458160301508664,
      "attention_bam_16_attention_center_x": 0.46218628300162456,
      "attention_bam_16_attention_center_distance": 0.07975509467211649,
      "attention_bam_16_attention_spatial_variance": 40.54034313162605,
      "attention_bam_16_attention_spatial_std": 6.367129897499034,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.525150879971466,
      "attention_bam_16_peak_intensity_mean": 0.29399827122688293,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 294,
      "phase": "train",
      "loss": 0.0074171749874949455,
      "timestamp": 1759543927.6436884,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0074171749874949455,
      "ssim": 0.8600530624389648,
      "attention_bam_384_mean_attention": 0.10400574654340744,
      "attention_bam_384_std_attention": 0.4158889055252075,
      "attention_bam_384_max_attention": 3.1198177337646484,
      "attention_bam_384_min_attention": -1.262702226638794,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.287900505167431,
      "attention_bam_384_attention_skewness": 0.7566630484908331,
      "attention_bam_384_attention_sparsity": 0.5349833170572916,
      "attention_bam_384_attention_concentration_10": 0.8854184048402539,
      "attention_bam_384_attention_concentration_20": 1.3888496375346058,
      "attention_bam_384_attention_center_y": 0.4871665164773035,
      "attention_bam_384_attention_center_x": 0.488061340284014,
      "attention_bam_384_attention_center_distance": 0.02478829946331249,
      "attention_bam_384_attention_spatial_variance": 169.71525444827523,
      "attention_bam_384_attention_spatial_std": 13.027480740660307,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 15.669072359857765,
      "attention_bam_384_peak_intensity_mean": 0.31355637311935425,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18360154330730438,
      "attention_bam_16_std_attention": 0.6107455492019653,
      "attention_bam_16_max_attention": 3.689667224884033,
      "attention_bam_16_min_attention": -1.087139368057251,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.4645632248542384,
      "attention_bam_16_attention_skewness": 1.0038297666602178,
      "attention_bam_16_attention_sparsity": 0.509765625,
      "attention_bam_16_attention_concentration_10": 0.7899365415418381,
      "attention_bam_16_attention_concentration_20": 1.22673589965524,
      "attention_bam_16_attention_center_y": 0.47902482971587507,
      "attention_bam_16_attention_center_x": 0.48330449509884693,
      "attention_bam_16_attention_center_distance": 0.037912996514453026,
      "attention_bam_16_attention_spatial_variance": 41.909854900335674,
      "attention_bam_16_attention_spatial_std": 6.473782117150351,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 7.349650023491817,
      "attention_bam_16_peak_intensity_mean": 0.2750545144081116,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 295,
      "phase": "train",
      "loss": 0.006683351006358862,
      "timestamp": 1759543927.7834778,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006683351006358862,
      "ssim": 0.8775516152381897,
      "attention_bam_384_mean_attention": 0.10579606890678406,
      "attention_bam_384_std_attention": 0.39568188786506653,
      "attention_bam_384_max_attention": 3.2237417697906494,
      "attention_bam_384_min_attention": -1.192570447921753,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.3177451826841056,
      "attention_bam_384_attention_skewness": 0.6591264124060036,
      "attention_bam_384_attention_sparsity": 0.5213114420572916,
      "attention_bam_384_attention_concentration_10": 0.8242208924294209,
      "attention_bam_384_attention_concentration_20": 1.2956813853727775,
      "attention_bam_384_attention_center_y": 0.4797765119896668,
      "attention_bam_384_attention_center_x": 0.47985281488627657,
      "attention_bam_384_attention_center_distance": 0.04037074523242615,
      "attention_bam_384_attention_spatial_variance": 170.0085662507307,
      "attention_bam_384_attention_spatial_std": 13.038733306986945,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 17.691982529652652,
      "attention_bam_384_peak_intensity_mean": 0.29514455795288086,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17423099279403687,
      "attention_bam_16_std_attention": 0.5932883024215698,
      "attention_bam_16_max_attention": 3.462345838546753,
      "attention_bam_16_min_attention": -1.118596076965332,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.8675456708783216,
      "attention_bam_16_attention_skewness": 0.9463938624560542,
      "attention_bam_16_attention_sparsity": 0.495849609375,
      "attention_bam_16_attention_concentration_10": 0.7833879725976579,
      "attention_bam_16_attention_concentration_20": 1.2153344501629326,
      "attention_bam_16_attention_center_y": 0.4543730612052837,
      "attention_bam_16_attention_center_x": 0.4545156966152426,
      "attention_bam_16_attention_center_distance": 0.09111135382786756,
      "attention_bam_16_attention_spatial_variance": 41.7340929731085,
      "attention_bam_16_attention_spatial_std": 6.460192951693355,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.43872351617181,
      "attention_bam_16_peak_intensity_mean": 0.27905508875846863,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 296,
      "phase": "train",
      "loss": 0.00709959864616394,
      "timestamp": 1759543927.9226236,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00709959864616394,
      "ssim": 0.8787769675254822,
      "attention_bam_384_mean_attention": 0.10210787504911423,
      "attention_bam_384_std_attention": 0.4269692301750183,
      "attention_bam_384_max_attention": 3.429677963256836,
      "attention_bam_384_min_attention": -1.1733160018920898,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.9852044863410114,
      "attention_bam_384_attention_skewness": 0.9024709104080105,
      "attention_bam_384_attention_sparsity": 0.5408401489257812,
      "attention_bam_384_attention_concentration_10": 0.9479246758892286,
      "attention_bam_384_attention_concentration_20": 1.4467818551606235,
      "attention_bam_384_attention_center_y": 0.48959564351262475,
      "attention_bam_384_attention_center_x": 0.4859052631601287,
      "attention_bam_384_attention_center_distance": 0.024775481448464816,
      "attention_bam_384_attention_spatial_variance": 173.2714986178176,
      "attention_bam_384_attention_spatial_std": 13.163263220714596,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 17.860455794121822,
      "attention_bam_384_peak_intensity_mean": 0.27995938062667847,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17023035883903503,
      "attention_bam_16_std_attention": 0.6166431307792664,
      "attention_bam_16_max_attention": 3.715714454650879,
      "attention_bam_16_min_attention": -1.1226446628570557,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.9906158752001497,
      "attention_bam_16_attention_skewness": 1.1322343223729034,
      "attention_bam_16_attention_sparsity": 0.5263671875,
      "attention_bam_16_attention_concentration_10": 0.8655003875062475,
      "attention_bam_16_attention_concentration_20": 1.325258145882338,
      "attention_bam_16_attention_center_y": 0.48212970147332457,
      "attention_bam_16_attention_center_x": 0.47251842947861444,
      "attention_bam_16_attention_center_distance": 0.04635912612969286,
      "attention_bam_16_attention_spatial_variance": 44.14058971851644,
      "attention_bam_16_attention_spatial_std": 6.643838477756397,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.373897327824187,
      "attention_bam_16_peak_intensity_mean": 0.2793448865413666,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 297,
      "phase": "train",
      "loss": 0.011334876529872417,
      "timestamp": 1759543928.060915,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.011334876529872417,
      "ssim": 0.8496127724647522,
      "attention_bam_384_mean_attention": 0.10807275027036667,
      "attention_bam_384_std_attention": 0.3411467671394348,
      "attention_bam_384_max_attention": 2.8458895683288574,
      "attention_bam_384_min_attention": -1.2088623046875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.877611192954094,
      "attention_bam_384_attention_skewness": 0.5187604675729439,
      "attention_bam_384_attention_sparsity": 0.5175501505533854,
      "attention_bam_384_attention_concentration_10": 0.7108911339768981,
      "attention_bam_384_attention_concentration_20": 1.1236595339680133,
      "attention_bam_384_attention_center_y": 0.4822877738880095,
      "attention_bam_384_attention_center_x": 0.48591062319649597,
      "attention_bam_384_attention_center_distance": 0.03200729581059282,
      "attention_bam_384_attention_spatial_variance": 169.7863818267197,
      "attention_bam_384_attention_spatial_std": 13.030210352358848,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 18.107758384837815,
      "attention_bam_384_peak_intensity_mean": 0.32844051718711853,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1921626776456833,
      "attention_bam_16_std_attention": 0.5244296789169312,
      "attention_bam_16_max_attention": 2.6109795570373535,
      "attention_bam_16_min_attention": -1.0761499404907227,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5228473226988557,
      "attention_bam_16_attention_skewness": 0.5771635283325763,
      "attention_bam_16_attention_sparsity": 0.4599609375,
      "attention_bam_16_attention_concentration_10": 0.6337592439763744,
      "attention_bam_16_attention_concentration_20": 1.0129759885614116,
      "attention_bam_16_attention_center_y": 0.46245478508154136,
      "attention_bam_16_attention_center_x": 0.47623015370905586,
      "attention_bam_16_attention_center_distance": 0.0628434365064222,
      "attention_bam_16_attention_spatial_variance": 41.916188667375636,
      "attention_bam_16_attention_spatial_std": 6.4742712846602,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.564372099106093,
      "attention_bam_16_peak_intensity_mean": 0.35311952233314514,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 298,
      "phase": "train",
      "loss": 0.007933060638606548,
      "timestamp": 1759543928.1970162,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007933060638606548,
      "ssim": 0.8827223181724548,
      "attention_bam_384_mean_attention": 0.10164809972047806,
      "attention_bam_384_std_attention": 0.4466158151626587,
      "attention_bam_384_max_attention": 3.0647268295288086,
      "attention_bam_384_min_attention": -1.2434699535369873,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5279478047380239,
      "attention_bam_384_attention_skewness": 0.642429871706665,
      "attention_bam_384_attention_sparsity": 0.5379079182942709,
      "attention_bam_384_attention_concentration_10": 0.9653261414197204,
      "attention_bam_384_attention_concentration_20": 1.5218889171108696,
      "attention_bam_384_attention_center_y": 0.484276516722976,
      "attention_bam_384_attention_center_x": 0.4849862314172969,
      "attention_bam_384_attention_center_distance": 0.030745444326527975,
      "attention_bam_384_attention_spatial_variance": 171.18506451906552,
      "attention_bam_384_attention_spatial_std": 13.0837710358698,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 19.629015331179563,
      "attention_bam_384_peak_intensity_mean": 0.313821017742157,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16620653867721558,
      "attention_bam_16_std_attention": 0.6458289623260498,
      "attention_bam_16_max_attention": 2.9032411575317383,
      "attention_bam_16_min_attention": -1.1415126323699951,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.3551698375067991,
      "attention_bam_16_attention_skewness": 0.8068114449380022,
      "attention_bam_16_attention_sparsity": 0.5322265625,
      "attention_bam_16_attention_concentration_10": 0.8947786305182244,
      "attention_bam_16_attention_concentration_20": 1.4220834410472474,
      "attention_bam_16_attention_center_y": 0.47048699816719436,
      "attention_bam_16_attention_center_x": 0.47404243225445114,
      "attention_bam_16_attention_center_distance": 0.055584397099329004,
      "attention_bam_16_attention_spatial_variance": 43.07890125289264,
      "attention_bam_16_attention_spatial_std": 6.5634519311786415,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.844058496379885,
      "attention_bam_16_peak_intensity_mean": 0.32871514558792114,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 299,
      "phase": "train",
      "loss": 0.011870298534631729,
      "timestamp": 1759543928.3356974,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.011870298534631729,
      "ssim": 0.8369264602661133,
      "attention_bam_384_mean_attention": 0.10185415297746658,
      "attention_bam_384_std_attention": 0.43510764837265015,
      "attention_bam_384_max_attention": 4.298584461212158,
      "attention_bam_384_min_attention": -1.2533984184265137,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.430468241655377,
      "attention_bam_384_attention_skewness": 1.1302402469588164,
      "attention_bam_384_attention_sparsity": 0.5443700154622396,
      "attention_bam_384_attention_concentration_10": 0.9678254360317394,
      "attention_bam_384_attention_concentration_20": 1.4584158256502397,
      "attention_bam_384_attention_center_y": 0.4789469524295687,
      "attention_bam_384_attention_center_x": 0.482760708653123,
      "attention_bam_384_attention_center_distance": 0.038481787332330396,
      "attention_bam_384_attention_spatial_variance": 168.3331944586463,
      "attention_bam_384_attention_spatial_std": 12.974328285450706,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 17.097736784125185,
      "attention_bam_384_peak_intensity_mean": 0.2448151409626007,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16851533949375153,
      "attention_bam_16_std_attention": 0.6363610625267029,
      "attention_bam_16_max_attention": 4.509824752807617,
      "attention_bam_16_min_attention": -1.22146737575531,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.7510885207922486,
      "attention_bam_16_attention_skewness": 1.437487136890687,
      "attention_bam_16_attention_sparsity": 0.535400390625,
      "attention_bam_16_attention_concentration_10": 0.9047324167361123,
      "attention_bam_16_attention_concentration_20": 1.3559233532623318,
      "attention_bam_16_attention_center_y": 0.45420692586072026,
      "attention_bam_16_attention_center_x": 0.46887935211405457,
      "attention_bam_16_attention_center_distance": 0.07830070707173174,
      "attention_bam_16_attention_spatial_variance": 40.90354555963985,
      "attention_bam_16_attention_spatial_std": 6.395587976069116,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.05399036488387,
      "attention_bam_16_peak_intensity_mean": 0.24105437099933624,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 300,
      "phase": "train",
      "loss": 0.0071727074682712555,
      "timestamp": 1759543928.5173607,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0071727074682712555,
      "ssim": 0.8606340885162354,
      "attention_bam_384_mean_attention": 0.1005764901638031,
      "attention_bam_384_std_attention": 0.4170495569705963,
      "attention_bam_384_max_attention": 3.152742385864258,
      "attention_bam_384_min_attention": -1.2712689638137817,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6483532565964989,
      "attention_bam_384_attention_skewness": 0.6660643869577004,
      "attention_bam_384_attention_sparsity": 0.5429458618164062,
      "attention_bam_384_attention_concentration_10": 0.9307536544773164,
      "attention_bam_384_attention_concentration_20": 1.4545099685793776,
      "attention_bam_384_attention_center_y": 0.48144640234439623,
      "attention_bam_384_attention_center_x": 0.4788150497864685,
      "attention_bam_384_attention_center_distance": 0.03982557222478628,
      "attention_bam_384_attention_spatial_variance": 169.84592163333895,
      "attention_bam_384_attention_spatial_std": 13.032494835346721,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 17.82942403210914,
      "attention_bam_384_peak_intensity_mean": 0.315595805644989,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16370637714862823,
      "attention_bam_16_std_attention": 0.6031689643859863,
      "attention_bam_16_max_attention": 2.946760654449463,
      "attention_bam_16_min_attention": -1.1086440086364746,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.1955877432484021,
      "attention_bam_16_attention_skewness": 0.7281209363545033,
      "attention_bam_16_attention_sparsity": 0.5244140625,
      "attention_bam_16_attention_concentration_10": 0.8326008503856617,
      "attention_bam_16_attention_concentration_20": 1.3477518828280213,
      "attention_bam_16_attention_center_y": 0.45968092374186553,
      "attention_bam_16_attention_center_x": 0.45460083754836345,
      "attention_bam_16_attention_center_distance": 0.08586864225803677,
      "attention_bam_16_attention_spatial_variance": 41.751434615013395,
      "attention_bam_16_attention_spatial_std": 6.461535004549105,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.31438028885099,
      "attention_bam_16_peak_intensity_mean": 0.3305731415748596,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 301,
      "phase": "train",
      "loss": 0.0070223696529865265,
      "timestamp": 1759543931.0811195,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0070223696529865265,
      "ssim": 0.8503623008728027,
      "attention_bam_384_mean_attention": 0.09735561162233353,
      "attention_bam_384_std_attention": 0.43511730432510376,
      "attention_bam_384_max_attention": 3.5294573307037354,
      "attention_bam_384_min_attention": -1.171644687652588,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.863033604689261,
      "attention_bam_384_attention_skewness": 0.9080049621916767,
      "attention_bam_384_attention_sparsity": 0.546844482421875,
      "attention_bam_384_attention_concentration_10": 0.9921144979909424,
      "attention_bam_384_attention_concentration_20": 1.534594057205126,
      "attention_bam_384_attention_center_y": 0.4818824022890206,
      "attention_bam_384_attention_center_x": 0.4838064013481892,
      "attention_bam_384_attention_center_distance": 0.03436509811168347,
      "attention_bam_384_attention_spatial_variance": 173.13249435278226,
      "attention_bam_384_attention_spatial_std": 13.157982153536395,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 19.60772468475614,
      "attention_bam_384_peak_intensity_mean": 0.2735111117362976,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16419623792171478,
      "attention_bam_16_std_attention": 0.6346510648727417,
      "attention_bam_16_max_attention": 3.738159656524658,
      "attention_bam_16_min_attention": -1.0976941585540771,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.4502472977842347,
      "attention_bam_16_attention_skewness": 1.2171117158568925,
      "attention_bam_16_attention_sparsity": 0.535400390625,
      "attention_bam_16_attention_concentration_10": 0.9049012784392718,
      "attention_bam_16_attention_concentration_20": 1.3946915257161632,
      "attention_bam_16_attention_center_y": 0.4624010542249406,
      "attention_bam_16_attention_center_x": 0.4686486717183805,
      "attention_bam_16_attention_center_distance": 0.06923274526432896,
      "attention_bam_16_attention_spatial_variance": 44.44509445606819,
      "attention_bam_16_attention_spatial_std": 6.666715417360201,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.773239626818059,
      "attention_bam_16_peak_intensity_mean": 0.27051863074302673,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 302,
      "phase": "train",
      "loss": 0.007318202406167984,
      "timestamp": 1759543931.217458,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007318202406167984,
      "ssim": 0.8618316650390625,
      "attention_bam_384_mean_attention": 0.10243486613035202,
      "attention_bam_384_std_attention": 0.43933600187301636,
      "attention_bam_384_max_attention": 2.843872308731079,
      "attention_bam_384_min_attention": -1.1271395683288574,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.23884120330272607,
      "attention_bam_384_attention_skewness": 0.5858151277991874,
      "attention_bam_384_attention_sparsity": 0.5320383707682291,
      "attention_bam_384_attention_concentration_10": 0.9400076478228477,
      "attention_bam_384_attention_concentration_20": 1.4853903400988862,
      "attention_bam_384_attention_center_y": 0.4929670188033688,
      "attention_bam_384_attention_center_x": 0.4864198648507077,
      "attention_bam_384_attention_center_distance": 0.021627893803383265,
      "attention_bam_384_attention_spatial_variance": 171.30014162843125,
      "attention_bam_384_attention_spatial_std": 13.088168001230395,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 14.168644185248144,
      "attention_bam_384_peak_intensity_mean": 0.31860315799713135,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18846651911735535,
      "attention_bam_16_std_attention": 0.6448796391487122,
      "attention_bam_16_max_attention": 2.758117437362671,
      "attention_bam_16_min_attention": -1.1027567386627197,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.06186815255482303,
      "attention_bam_16_attention_skewness": 0.6729584321320203,
      "attention_bam_16_attention_sparsity": 0.50048828125,
      "attention_bam_16_attention_concentration_10": 0.7789343800634309,
      "attention_bam_16_attention_concentration_20": 1.2580106190855314,
      "attention_bam_16_attention_center_y": 0.4995175548941519,
      "attention_bam_16_attention_center_x": 0.47736164834983785,
      "attention_bam_16_attention_center_distance": 0.03202273313496385,
      "attention_bam_16_attention_spatial_variance": 43.22112139069152,
      "attention_bam_16_attention_spatial_std": 6.574277252344285,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 7.3133897173176745,
      "attention_bam_16_peak_intensity_mean": 0.3608171045780182,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 303,
      "phase": "train",
      "loss": 0.006533412262797356,
      "timestamp": 1759543931.3503268,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006533412262797356,
      "ssim": 0.8644924163818359,
      "attention_bam_384_mean_attention": 0.10125088691711426,
      "attention_bam_384_std_attention": 0.42313411831855774,
      "attention_bam_384_max_attention": 2.9914045333862305,
      "attention_bam_384_min_attention": -1.1453880071640015,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.414528617620316,
      "attention_bam_384_attention_skewness": 0.5566548375416325,
      "attention_bam_384_attention_sparsity": 0.530487060546875,
      "attention_bam_384_attention_concentration_10": 0.9112502953222555,
      "attention_bam_384_attention_concentration_20": 1.4441809108251982,
      "attention_bam_384_attention_center_y": 0.4883427141651813,
      "attention_bam_384_attention_center_x": 0.48700946399746836,
      "attention_bam_384_attention_center_distance": 0.02468385458828239,
      "attention_bam_384_attention_spatial_variance": 171.63234865391064,
      "attention_bam_384_attention_spatial_std": 13.100852974287996,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 19.176724409571282,
      "attention_bam_384_peak_intensity_mean": 0.3049377202987671,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18135474622249603,
      "attention_bam_16_std_attention": 0.6242120265960693,
      "attention_bam_16_max_attention": 3.2149577140808105,
      "attention_bam_16_min_attention": -1.08748197555542,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.3244363184318808,
      "attention_bam_16_attention_skewness": 0.6892150296772301,
      "attention_bam_16_attention_sparsity": 0.497802734375,
      "attention_bam_16_attention_concentration_10": 0.7838705375535645,
      "attention_bam_16_attention_concentration_20": 1.2541991868537412,
      "attention_bam_16_attention_center_y": 0.4875235477002013,
      "attention_bam_16_attention_center_x": 0.48167925360393093,
      "attention_bam_16_attention_center_distance": 0.03134682154535704,
      "attention_bam_16_attention_spatial_variance": 43.7415135541293,
      "attention_bam_16_attention_spatial_std": 6.613736731540597,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.475344495197712,
      "attention_bam_16_peak_intensity_mean": 0.3141668438911438,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 304,
      "phase": "train",
      "loss": 0.008459458127617836,
      "timestamp": 1759543931.4822683,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008459458127617836,
      "ssim": 0.8879185318946838,
      "attention_bam_384_mean_attention": 0.10287415981292725,
      "attention_bam_384_std_attention": 0.44528326392173767,
      "attention_bam_384_max_attention": 3.9188344478607178,
      "attention_bam_384_min_attention": -1.5046082735061646,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.545352464534777,
      "attention_bam_384_attention_skewness": 0.9827795881451439,
      "attention_bam_384_attention_sparsity": 0.5316899617513021,
      "attention_bam_384_attention_concentration_10": 0.9343183799530546,
      "attention_bam_384_attention_concentration_20": 1.4497113267224786,
      "attention_bam_384_attention_center_y": 0.48595253231500907,
      "attention_bam_384_attention_center_x": 0.48225019364182886,
      "attention_bam_384_attention_center_distance": 0.03201209065692015,
      "attention_bam_384_attention_spatial_variance": 169.9691461775479,
      "attention_bam_384_attention_spatial_std": 13.037221566635582,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 18.847049439753828,
      "attention_bam_384_peak_intensity_mean": 0.2960245609283447,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1879751831293106,
      "attention_bam_16_std_attention": 0.6596384048461914,
      "attention_bam_16_max_attention": 5.175668716430664,
      "attention_bam_16_min_attention": -1.3246890306472778,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 4.937293273500863,
      "attention_bam_16_attention_skewness": 1.4107211370917567,
      "attention_bam_16_attention_sparsity": 0.499755859375,
      "attention_bam_16_attention_concentration_10": 0.8062005892814252,
      "attention_bam_16_attention_concentration_20": 1.2359755813664834,
      "attention_bam_16_attention_center_y": 0.47967587515617116,
      "attention_bam_16_attention_center_x": 0.460162482095442,
      "attention_bam_16_attention_center_distance": 0.0632471008578815,
      "attention_bam_16_attention_spatial_variance": 41.892398983734566,
      "attention_bam_16_attention_spatial_std": 6.472433775924985,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.242456392647803,
      "attention_bam_16_peak_intensity_mean": 0.24329720437526703,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 305,
      "phase": "train",
      "loss": 0.006644390523433685,
      "timestamp": 1759543931.6128054,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006644390523433685,
      "ssim": 0.8703994750976562,
      "attention_bam_384_mean_attention": 0.09862804412841797,
      "attention_bam_384_std_attention": 0.39785540103912354,
      "attention_bam_384_max_attention": 3.9413604736328125,
      "attention_bam_384_min_attention": -1.324613332748413,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.810133519774105,
      "attention_bam_384_attention_skewness": 0.8335587527036354,
      "attention_bam_384_attention_sparsity": 0.5455245971679688,
      "attention_bam_384_attention_concentration_10": 0.9094804871442941,
      "attention_bam_384_attention_concentration_20": 1.404789315792674,
      "attention_bam_384_attention_center_y": 0.48102479671969617,
      "attention_bam_384_attention_center_x": 0.48459914217885663,
      "attention_bam_384_attention_center_distance": 0.03456138773706652,
      "attention_bam_384_attention_spatial_variance": 170.4156023071181,
      "attention_bam_384_attention_spatial_std": 13.054332702483038,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 19.6759918327165,
      "attention_bam_384_peak_intensity_mean": 0.27363017201423645,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18136444687843323,
      "attention_bam_16_std_attention": 0.5869429707527161,
      "attention_bam_16_max_attention": 3.557314157485962,
      "attention_bam_16_min_attention": -1.0560181140899658,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.9694665020192383,
      "attention_bam_16_attention_skewness": 0.8396163692126019,
      "attention_bam_16_attention_sparsity": 0.501708984375,
      "attention_bam_16_attention_concentration_10": 0.7567561749548657,
      "attention_bam_16_attention_concentration_20": 1.1961580989394456,
      "attention_bam_16_attention_center_y": 0.4561224299445076,
      "attention_bam_16_attention_center_x": 0.4700566042237947,
      "attention_bam_16_attention_center_distance": 0.07512453799638456,
      "attention_bam_16_attention_spatial_variance": 42.611192767051215,
      "attention_bam_16_attention_spatial_std": 6.527724930406551,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.67891592643761,
      "attention_bam_16_peak_intensity_mean": 0.2771957814693451,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 306,
      "phase": "train",
      "loss": 0.01116839237511158,
      "timestamp": 1759543931.7452517,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.01116839237511158,
      "ssim": 0.834242582321167,
      "attention_bam_384_mean_attention": 0.10470960289239883,
      "attention_bam_384_std_attention": 0.36978721618652344,
      "attention_bam_384_max_attention": 3.139657735824585,
      "attention_bam_384_min_attention": -1.075124979019165,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9398837914910452,
      "attention_bam_384_attention_skewness": 0.5226372364425178,
      "attention_bam_384_attention_sparsity": 0.5255635579427084,
      "attention_bam_384_attention_concentration_10": 0.7957550813467065,
      "attention_bam_384_attention_concentration_20": 1.2410159600938657,
      "attention_bam_384_attention_center_y": 0.4811556801925007,
      "attention_bam_384_attention_center_x": 0.4834951847177627,
      "attention_bam_384_attention_center_distance": 0.03542646797263548,
      "attention_bam_384_attention_spatial_variance": 171.81922309484364,
      "attention_bam_384_attention_spatial_std": 13.107983181818767,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 19.51679712506312,
      "attention_bam_384_peak_intensity_mean": 0.2809595465660095,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20186293125152588,
      "attention_bam_16_std_attention": 0.5482591390609741,
      "attention_bam_16_max_attention": 2.8371007442474365,
      "attention_bam_16_min_attention": -1.1243139505386353,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7288308869421098,
      "attention_bam_16_attention_skewness": 0.6251783098049898,
      "attention_bam_16_attention_sparsity": 0.45556640625,
      "attention_bam_16_attention_concentration_10": 0.636912709658172,
      "attention_bam_16_attention_concentration_20": 1.0080822086760346,
      "attention_bam_16_attention_center_y": 0.4509800238383371,
      "attention_bam_16_attention_center_x": 0.4655160827658188,
      "attention_bam_16_attention_center_distance": 0.0847596438253944,
      "attention_bam_16_attention_spatial_variance": 42.969525526191966,
      "attention_bam_16_attention_spatial_std": 6.555114455613416,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 10.25270332399685,
      "attention_bam_16_peak_intensity_mean": 0.34545233845710754,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 307,
      "phase": "train",
      "loss": 0.006265030708163977,
      "timestamp": 1759543931.8761683,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006265030708163977,
      "ssim": 0.8647670745849609,
      "attention_bam_384_mean_attention": 0.10078122466802597,
      "attention_bam_384_std_attention": 0.38425275683403015,
      "attention_bam_384_max_attention": 2.6425395011901855,
      "attention_bam_384_min_attention": -1.1941722631454468,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1719619322216692,
      "attention_bam_384_attention_skewness": 0.774184538973679,
      "attention_bam_384_attention_sparsity": 0.5430577596028646,
      "attention_bam_384_attention_concentration_10": 0.8672095629654677,
      "attention_bam_384_attention_concentration_20": 1.3468453824897022,
      "attention_bam_384_attention_center_y": 0.47954457540861045,
      "attention_bam_384_attention_center_x": 0.4881378064304946,
      "attention_bam_384_attention_center_distance": 0.033440575099553525,
      "attention_bam_384_attention_spatial_variance": 171.92527200310533,
      "attention_bam_384_attention_spatial_std": 13.112027760918803,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 17.935677759561408,
      "attention_bam_384_peak_intensity_mean": 0.3421800434589386,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17839846014976501,
      "attention_bam_16_std_attention": 0.5909404754638672,
      "attention_bam_16_max_attention": 3.6711528301239014,
      "attention_bam_16_min_attention": -1.027941107749939,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.0203783756592575,
      "attention_bam_16_attention_skewness": 0.9016228266863511,
      "attention_bam_16_attention_sparsity": 0.507080078125,
      "attention_bam_16_attention_concentration_10": 0.7811042289987472,
      "attention_bam_16_attention_concentration_20": 1.2252346660632025,
      "attention_bam_16_attention_center_y": 0.45374579290028333,
      "attention_bam_16_attention_center_x": 0.4807008784587612,
      "attention_bam_16_attention_center_distance": 0.07087887931798847,
      "attention_bam_16_attention_spatial_variance": 43.59897485453585,
      "attention_bam_16_attention_spatial_std": 6.602951980329393,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.148570376930822,
      "attention_bam_16_peak_intensity_mean": 0.2688736319541931,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 308,
      "phase": "train",
      "loss": 0.006395432166755199,
      "timestamp": 1759543932.0080683,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006395432166755199,
      "ssim": 0.8488602638244629,
      "attention_bam_384_mean_attention": 0.10367768257856369,
      "attention_bam_384_std_attention": 0.34600311517715454,
      "attention_bam_384_max_attention": 2.3665709495544434,
      "attention_bam_384_min_attention": -1.114255666732788,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.40737571125298366,
      "attention_bam_384_attention_skewness": 0.4234327120934373,
      "attention_bam_384_attention_sparsity": 0.5247472127278646,
      "attention_bam_384_attention_concentration_10": 0.7335596089007419,
      "attention_bam_384_attention_concentration_20": 1.1822573905498515,
      "attention_bam_384_attention_center_y": 0.4814603613626854,
      "attention_bam_384_attention_center_x": 0.4872273017583052,
      "attention_bam_384_attention_center_distance": 0.031838970497665355,
      "attention_bam_384_attention_spatial_variance": 170.10879600432503,
      "attention_bam_384_attention_spatial_std": 13.042576279413705,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 17.133141621672053,
      "attention_bam_384_peak_intensity_mean": 0.3510180413722992,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20505475997924805,
      "attention_bam_16_std_attention": 0.5286514759063721,
      "attention_bam_16_max_attention": 2.4953103065490723,
      "attention_bam_16_min_attention": -1.1625702381134033,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.005865449257227429,
      "attention_bam_16_attention_skewness": 0.4361635410100422,
      "attention_bam_16_attention_sparsity": 0.454345703125,
      "attention_bam_16_attention_concentration_10": 0.58933705505413,
      "attention_bam_16_attention_concentration_20": 0.969901007125147,
      "attention_bam_16_attention_center_y": 0.4603203614245724,
      "attention_bam_16_attention_center_x": 0.48145088202775976,
      "attention_bam_16_attention_center_distance": 0.06194422483209631,
      "attention_bam_16_attention_spatial_variance": 42.118878990825735,
      "attention_bam_16_attention_spatial_std": 6.489905930814848,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 8.140903814039142,
      "attention_bam_16_peak_intensity_mean": 0.37442150712013245,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 309,
      "phase": "train",
      "loss": 0.008998104371130466,
      "timestamp": 1759543932.1403768,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008998104371130466,
      "ssim": 0.8342105150222778,
      "attention_bam_384_mean_attention": 0.09871754795312881,
      "attention_bam_384_std_attention": 0.4013669788837433,
      "attention_bam_384_max_attention": 2.4963555335998535,
      "attention_bam_384_min_attention": -1.1830217838287354,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5492882528864946,
      "attention_bam_384_attention_skewness": 0.6016125671414201,
      "attention_bam_384_attention_sparsity": 0.5349070231119791,
      "attention_bam_384_attention_concentration_10": 0.896724782771313,
      "attention_bam_384_attention_concentration_20": 1.4116211815074886,
      "attention_bam_384_attention_center_y": 0.48718677074603883,
      "attention_bam_384_attention_center_x": 0.4853955939049822,
      "attention_bam_384_attention_center_distance": 0.027476081281826156,
      "attention_bam_384_attention_spatial_variance": 170.1971214268151,
      "attention_bam_384_attention_spatial_std": 13.04596188200836,
      "attention_bam_384_num_attention_peaks": 18,
      "attention_bam_384_peak_separation_mean": 16.64718129607899,
      "attention_bam_384_peak_intensity_mean": 0.3540964126586914,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1769881546497345,
      "attention_bam_16_std_attention": 0.5888664722442627,
      "attention_bam_16_max_attention": 2.998115301132202,
      "attention_bam_16_min_attention": -1.1671444177627563,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7076358062592871,
      "attention_bam_16_attention_skewness": 0.7853205169481126,
      "attention_bam_16_attention_sparsity": 0.50244140625,
      "attention_bam_16_attention_concentration_10": 0.7694240374572857,
      "attention_bam_16_attention_concentration_20": 1.2198837058957261,
      "attention_bam_16_attention_center_y": 0.47867853833683793,
      "attention_bam_16_attention_center_x": 0.47604294513916484,
      "attention_bam_16_attention_center_distance": 0.04535515858331343,
      "attention_bam_16_attention_spatial_variance": 42.136439389626105,
      "attention_bam_16_attention_spatial_std": 6.491258690702914,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.08648306028742,
      "attention_bam_16_peak_intensity_mean": 0.33755582571029663,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 310,
      "phase": "train",
      "loss": 0.007873672991991043,
      "timestamp": 1759543932.3261507,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007873672991991043,
      "ssim": 0.8409045934677124,
      "attention_bam_384_mean_attention": 0.09628421068191528,
      "attention_bam_384_std_attention": 0.4457267224788666,
      "attention_bam_384_max_attention": 3.495121479034424,
      "attention_bam_384_min_attention": -1.3103201389312744,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.6337210734411576,
      "attention_bam_384_attention_skewness": 0.843579242060696,
      "attention_bam_384_attention_sparsity": 0.5466766357421875,
      "attention_bam_384_attention_concentration_10": 1.0272946960084928,
      "attention_bam_384_attention_concentration_20": 1.5792685028068671,
      "attention_bam_384_attention_center_y": 0.47876694072806075,
      "attention_bam_384_attention_center_x": 0.4842852845851872,
      "attention_bam_384_attention_center_distance": 0.03735759860093364,
      "attention_bam_384_attention_spatial_variance": 171.41868427795347,
      "attention_bam_384_attention_spatial_std": 13.092695836914316,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 18.234249644251825,
      "attention_bam_384_peak_intensity_mean": 0.29569268226623535,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16046161949634552,
      "attention_bam_16_std_attention": 0.6488566994667053,
      "attention_bam_16_max_attention": 3.6271839141845703,
      "attention_bam_16_min_attention": -1.1818634271621704,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.2310467490983834,
      "attention_bam_16_attention_skewness": 1.1447755866446245,
      "attention_bam_16_attention_sparsity": 0.528564453125,
      "attention_bam_16_attention_concentration_10": 0.9461094348439224,
      "attention_bam_16_attention_concentration_20": 1.4432037563031475,
      "attention_bam_16_attention_center_y": 0.45070943745028624,
      "attention_bam_16_attention_center_x": 0.4667311615615998,
      "attention_bam_16_attention_center_distance": 0.0840996452728264,
      "attention_bam_16_attention_spatial_variance": 43.24729565748099,
      "attention_bam_16_attention_spatial_std": 6.576267608414441,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 11.709650649627612,
      "attention_bam_16_peak_intensity_mean": 0.28233322501182556,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 311,
      "phase": "train",
      "loss": 0.008114340715110302,
      "timestamp": 1759543932.4671662,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008114340715110302,
      "ssim": 0.8753162622451782,
      "attention_bam_384_mean_attention": 0.09869829565286636,
      "attention_bam_384_std_attention": 0.39267241954803467,
      "attention_bam_384_max_attention": 2.6746737957000732,
      "attention_bam_384_min_attention": -1.280332326889038,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.07546961385935314,
      "attention_bam_384_attention_skewness": 0.41435625624137024,
      "attention_bam_384_attention_sparsity": 0.5337931315104166,
      "attention_bam_384_attention_concentration_10": 0.848086056016633,
      "attention_bam_384_attention_concentration_20": 1.374492415726364,
      "attention_bam_384_attention_center_y": 0.4853786450997677,
      "attention_bam_384_attention_center_x": 0.4832878129882804,
      "attention_bam_384_attention_center_distance": 0.03140322320505451,
      "attention_bam_384_attention_spatial_variance": 170.1810875271242,
      "attention_bam_384_attention_spatial_std": 13.045347351723686,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 16.60186073221297,
      "attention_bam_384_peak_intensity_mean": 0.35179707407951355,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17353926599025726,
      "attention_bam_16_std_attention": 0.5780152678489685,
      "attention_bam_16_max_attention": 2.271975517272949,
      "attention_bam_16_min_attention": -1.099057674407959,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.07711213147473517,
      "attention_bam_16_attention_skewness": 0.5849909325509872,
      "attention_bam_16_attention_sparsity": 0.50341796875,
      "attention_bam_16_attention_concentration_10": 0.7495891945153454,
      "attention_bam_16_attention_concentration_20": 1.221438769251948,
      "attention_bam_16_attention_center_y": 0.47347390894676145,
      "attention_bam_16_attention_center_x": 0.468763105819461,
      "attention_bam_16_attention_center_distance": 0.05795475933192878,
      "attention_bam_16_attention_spatial_variance": 42.10729742654793,
      "attention_bam_16_attention_spatial_std": 6.48901359426438,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.271543960594366,
      "attention_bam_16_peak_intensity_mean": 0.39629456400871277,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 312,
      "phase": "train",
      "loss": 0.007012590300291777,
      "timestamp": 1759543932.5960257,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007012590300291777,
      "ssim": 0.8861985206604004,
      "attention_bam_384_mean_attention": 0.09740543365478516,
      "attention_bam_384_std_attention": 0.3890796899795532,
      "attention_bam_384_max_attention": 2.9775187969207764,
      "attention_bam_384_min_attention": -1.2054316997528076,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.1307436349284306,
      "attention_bam_384_attention_skewness": 0.8780187056322958,
      "attention_bam_384_attention_sparsity": 0.5448735555013021,
      "attention_bam_384_attention_concentration_10": 0.893533725943026,
      "attention_bam_384_attention_concentration_20": 1.3740578422442082,
      "attention_bam_384_attention_center_y": 0.48673833637353886,
      "attention_bam_384_attention_center_x": 0.4879393654417095,
      "attention_bam_384_attention_center_distance": 0.02535076441017245,
      "attention_bam_384_attention_spatial_variance": 171.94558471732992,
      "attention_bam_384_attention_spatial_std": 13.11280232129387,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 16.741198987077638,
      "attention_bam_384_peak_intensity_mean": 0.3129202127456665,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1724708527326584,
      "attention_bam_16_std_attention": 0.600608229637146,
      "attention_bam_16_max_attention": 4.856626510620117,
      "attention_bam_16_min_attention": -1.1570100784301758,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.8018121512424976,
      "attention_bam_16_attention_skewness": 1.1780540850050056,
      "attention_bam_16_attention_sparsity": 0.510986328125,
      "attention_bam_16_attention_concentration_10": 0.8236118864027779,
      "attention_bam_16_attention_concentration_20": 1.266621987289665,
      "attention_bam_16_attention_center_y": 0.47568923067973296,
      "attention_bam_16_attention_center_x": 0.4813525353529261,
      "attention_bam_16_attention_center_distance": 0.04332993059553888,
      "attention_bam_16_attention_spatial_variance": 43.90055454597366,
      "attention_bam_16_attention_spatial_std": 6.625749357316021,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 10.977197350873551,
      "attention_bam_16_peak_intensity_mean": 0.22142735123634338,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 313,
      "phase": "train",
      "loss": 0.011203846894204617,
      "timestamp": 1759543932.7274058,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.011203846894204617,
      "ssim": 0.896660566329956,
      "attention_bam_384_mean_attention": 0.10141319036483765,
      "attention_bam_384_std_attention": 0.46897056698799133,
      "attention_bam_384_max_attention": 3.8797810077667236,
      "attention_bam_384_min_attention": -1.2407002449035645,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4155115697715042,
      "attention_bam_384_attention_skewness": 0.7163973900800229,
      "attention_bam_384_attention_sparsity": 0.534332275390625,
      "attention_bam_384_attention_concentration_10": 1.0100965990782087,
      "attention_bam_384_attention_concentration_20": 1.5659468412173823,
      "attention_bam_384_attention_center_y": 0.48657988706391875,
      "attention_bam_384_attention_center_x": 0.48997515226733956,
      "attention_bam_384_attention_center_distance": 0.023689533692337738,
      "attention_bam_384_attention_spatial_variance": 170.54504641125786,
      "attention_bam_384_attention_spatial_std": 13.059289659520454,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 20.80949041803902,
      "attention_bam_384_peak_intensity_mean": 0.26758912205696106,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1837712526321411,
      "attention_bam_16_std_attention": 0.6801888346672058,
      "attention_bam_16_max_attention": 3.8701791763305664,
      "attention_bam_16_min_attention": -1.1595220565795898,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.627419700963114,
      "attention_bam_16_attention_skewness": 0.972572404046093,
      "attention_bam_16_attention_sparsity": 0.5068359375,
      "attention_bam_16_attention_concentration_10": 0.8557543858966415,
      "attention_bam_16_attention_concentration_20": 1.3285553504819982,
      "attention_bam_16_attention_center_y": 0.4757054188288606,
      "attention_bam_16_attention_center_x": 0.49188714289315655,
      "attention_bam_16_attention_center_distance": 0.03622278632897094,
      "attention_bam_16_attention_spatial_variance": 42.91840771866095,
      "attention_bam_16_attention_spatial_std": 6.551214217125017,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 9.513122549566274,
      "attention_bam_16_peak_intensity_mean": 0.2873595654964447,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 314,
      "phase": "train",
      "loss": 0.0069246552884578705,
      "timestamp": 1759543932.8575807,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0069246552884578705,
      "ssim": 0.8690851330757141,
      "attention_bam_384_mean_attention": 0.09348160773515701,
      "attention_bam_384_std_attention": 0.4262956380844116,
      "attention_bam_384_max_attention": 3.6246399879455566,
      "attention_bam_384_min_attention": -1.278911828994751,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 4.1242752989518054,
      "attention_bam_384_attention_skewness": 1.3251860577880277,
      "attention_bam_384_attention_sparsity": 0.5606409708658854,
      "attention_bam_384_attention_concentration_10": 1.043447688016305,
      "attention_bam_384_attention_concentration_20": 1.5423732650011475,
      "attention_bam_384_attention_center_y": 0.4889647312012688,
      "attention_bam_384_attention_center_x": 0.4837068333432957,
      "attention_bam_384_attention_center_distance": 0.02782964021195357,
      "attention_bam_384_attention_spatial_variance": 171.51385482224222,
      "attention_bam_384_attention_spatial_std": 13.096329822596948,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 18.862168361070715,
      "attention_bam_384_peak_intensity_mean": 0.2810586094856262,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1696244180202484,
      "attention_bam_16_std_attention": 0.6364825963973999,
      "attention_bam_16_max_attention": 4.047296524047852,
      "attention_bam_16_min_attention": -1.0451316833496094,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 4.2049369317217105,
      "attention_bam_16_attention_skewness": 1.54623058142017,
      "attention_bam_16_attention_sparsity": 0.535400390625,
      "attention_bam_16_attention_concentration_10": 0.8970474472040738,
      "attention_bam_16_attention_concentration_20": 1.3440711666772776,
      "attention_bam_16_attention_center_y": 0.48550211998313936,
      "attention_bam_16_attention_center_x": 0.4703604356588288,
      "attention_bam_16_attention_center_distance": 0.046662453842842753,
      "attention_bam_16_attention_spatial_variance": 43.23763690006962,
      "attention_bam_16_attention_spatial_std": 6.575533202719732,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.391829329630342,
      "attention_bam_16_peak_intensity_mean": 0.24175667762756348,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 315,
      "phase": "train",
      "loss": 0.007649317383766174,
      "timestamp": 1759543932.9954746,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007649317383766174,
      "ssim": 0.8753081560134888,
      "attention_bam_384_mean_attention": 0.09671030193567276,
      "attention_bam_384_std_attention": 0.4016275703907013,
      "attention_bam_384_max_attention": 3.8165459632873535,
      "attention_bam_384_min_attention": -1.2250139713287354,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.1180975518954366,
      "attention_bam_384_attention_skewness": 0.7714645655272481,
      "attention_bam_384_attention_sparsity": 0.5312728881835938,
      "attention_bam_384_attention_concentration_10": 0.910836247678026,
      "attention_bam_384_attention_concentration_20": 1.4106965481264329,
      "attention_bam_384_attention_center_y": 0.4820048922369313,
      "attention_bam_384_attention_center_x": 0.4836199075749859,
      "attention_bam_384_attention_center_distance": 0.0344131175936287,
      "attention_bam_384_attention_spatial_variance": 169.36651649800828,
      "attention_bam_384_attention_spatial_std": 13.014089153606113,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 15.004061311842012,
      "attention_bam_384_peak_intensity_mean": 0.2662352919578552,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.190434992313385,
      "attention_bam_16_std_attention": 0.598889172077179,
      "attention_bam_16_max_attention": 4.158914089202881,
      "attention_bam_16_min_attention": -1.067198634147644,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.812544620235899,
      "attention_bam_16_attention_skewness": 0.9206601800277174,
      "attention_bam_16_attention_sparsity": 0.4912109375,
      "attention_bam_16_attention_concentration_10": 0.726927084416226,
      "attention_bam_16_attention_concentration_20": 1.1496269603720446,
      "attention_bam_16_attention_center_y": 0.4627373477555487,
      "attention_bam_16_attention_center_x": 0.46913475623322015,
      "attention_bam_16_attention_center_distance": 0.0684276044454817,
      "attention_bam_16_attention_spatial_variance": 41.330883929848426,
      "attention_bam_16_attention_spatial_std": 6.428910011024297,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 10.262552611070426,
      "attention_bam_16_peak_intensity_mean": 0.24415259063243866,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 316,
      "phase": "train",
      "loss": 0.0069442810490727425,
      "timestamp": 1759543933.1372695,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0069442810490727425,
      "ssim": 0.8758020401000977,
      "attention_bam_384_mean_attention": 0.09642928093671799,
      "attention_bam_384_std_attention": 0.36784645915031433,
      "attention_bam_384_max_attention": 3.1968283653259277,
      "attention_bam_384_min_attention": -1.1776516437530518,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1987022746277844,
      "attention_bam_384_attention_skewness": 0.7718616048022384,
      "attention_bam_384_attention_sparsity": 0.54681396484375,
      "attention_bam_384_attention_concentration_10": 0.8715902695495714,
      "attention_bam_384_attention_concentration_20": 1.3463223902113801,
      "attention_bam_384_attention_center_y": 0.48524802388238625,
      "attention_bam_384_attention_center_x": 0.48759675174740896,
      "attention_bam_384_attention_center_distance": 0.027256608981678154,
      "attention_bam_384_attention_spatial_variance": 169.92439549092092,
      "attention_bam_384_attention_spatial_std": 13.035505187407235,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 18.64228343448826,
      "attention_bam_384_peak_intensity_mean": 0.29236268997192383,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1831822693347931,
      "attention_bam_16_std_attention": 0.5537464022636414,
      "attention_bam_16_max_attention": 2.6980340480804443,
      "attention_bam_16_min_attention": -1.0180402994155884,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7181601966173758,
      "attention_bam_16_attention_skewness": 0.8448108181210033,
      "attention_bam_16_attention_sparsity": 0.507080078125,
      "attention_bam_16_attention_concentration_10": 0.7186492579432631,
      "attention_bam_16_attention_concentration_20": 1.1390741545915208,
      "attention_bam_16_attention_center_y": 0.4734282091557869,
      "attention_bam_16_attention_center_x": 0.4816132243391445,
      "attention_bam_16_attention_center_distance": 0.04569756203280945,
      "attention_bam_16_attention_spatial_variance": 42.13612009231072,
      "attention_bam_16_attention_spatial_std": 6.491234096249396,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.490760991641697,
      "attention_bam_16_peak_intensity_mean": 0.33133333921432495,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 317,
      "phase": "train",
      "loss": 0.011572396382689476,
      "timestamp": 1759543933.2820954,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.011572396382689476,
      "ssim": 0.8122907280921936,
      "attention_bam_384_mean_attention": 0.09389214962720871,
      "attention_bam_384_std_attention": 0.4011494815349579,
      "attention_bam_384_max_attention": 3.5551488399505615,
      "attention_bam_384_min_attention": -1.0945457220077515,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.7200562487447497,
      "attention_bam_384_attention_skewness": 0.8104278280415717,
      "attention_bam_384_attention_sparsity": 0.5384648640950521,
      "attention_bam_384_attention_concentration_10": 0.9422653119456987,
      "attention_bam_384_attention_concentration_20": 1.4603703351413646,
      "attention_bam_384_attention_center_y": 0.4836956585580563,
      "attention_bam_384_attention_center_x": 0.48047056610430194,
      "attention_bam_384_attention_center_distance": 0.03597861415179643,
      "attention_bam_384_attention_spatial_variance": 171.56725764980624,
      "attention_bam_384_attention_spatial_std": 13.09836851099427,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 16.240091708971484,
      "attention_bam_384_peak_intensity_mean": 0.25650784373283386,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1757974475622177,
      "attention_bam_16_std_attention": 0.5930270552635193,
      "attention_bam_16_max_attention": 3.752368211746216,
      "attention_bam_16_min_attention": -0.9870695471763611,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.1966026449790776,
      "attention_bam_16_attention_skewness": 1.072723374673734,
      "attention_bam_16_attention_sparsity": 0.509033203125,
      "attention_bam_16_attention_concentration_10": 0.786286274099666,
      "attention_bam_16_attention_concentration_20": 1.2302556111610499,
      "attention_bam_16_attention_center_y": 0.46564311042074635,
      "attention_bam_16_attention_center_x": 0.4559261423177425,
      "attention_bam_16_attention_center_distance": 0.07903038393626742,
      "attention_bam_16_attention_spatial_variance": 43.109430366848635,
      "attention_bam_16_attention_spatial_std": 6.5657772096568,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.872344724309295,
      "attention_bam_16_peak_intensity_mean": 0.24794892966747284,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 318,
      "phase": "train",
      "loss": 0.008895015344023705,
      "timestamp": 1759543933.4183602,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008895015344023705,
      "ssim": 0.8590158820152283,
      "attention_bam_384_mean_attention": 0.0970078706741333,
      "attention_bam_384_std_attention": 0.3615143895149231,
      "attention_bam_384_max_attention": 2.820298671722412,
      "attention_bam_384_min_attention": -1.0505549907684326,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.675045546432941,
      "attention_bam_384_attention_skewness": 0.6017587864744636,
      "attention_bam_384_attention_sparsity": 0.5428466796875,
      "attention_bam_384_attention_concentration_10": 0.8279904460070668,
      "attention_bam_384_attention_concentration_20": 1.3140711257151094,
      "attention_bam_384_attention_center_y": 0.4737477436421734,
      "attention_bam_384_attention_center_x": 0.4784980454292639,
      "attention_bam_384_attention_center_distance": 0.047989895066337565,
      "attention_bam_384_attention_spatial_variance": 171.97298680083273,
      "attention_bam_384_attention_spatial_std": 13.113847139601434,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 18.587067501544038,
      "attention_bam_384_peak_intensity_mean": 0.30140429735183716,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19380563497543335,
      "attention_bam_16_std_attention": 0.5415396690368652,
      "attention_bam_16_max_attention": 3.0574395656585693,
      "attention_bam_16_min_attention": -1.0103960037231445,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.33976907954730606,
      "attention_bam_16_attention_skewness": 0.6882001414253147,
      "attention_bam_16_attention_sparsity": 0.485107421875,
      "attention_bam_16_attention_concentration_10": 0.6468368322539421,
      "attention_bam_16_attention_concentration_20": 1.0566947325101645,
      "attention_bam_16_attention_center_y": 0.4391900072765296,
      "attention_bam_16_attention_center_x": 0.45421777749150377,
      "attention_bam_16_attention_center_distance": 0.10764633865437298,
      "attention_bam_16_attention_spatial_variance": 42.87698686086401,
      "attention_bam_16_attention_spatial_std": 6.54805214249734,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.224671931460255,
      "attention_bam_16_peak_intensity_mean": 0.31693655252456665,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 319,
      "phase": "train",
      "loss": 0.005566577892750502,
      "timestamp": 1759543933.5599625,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005566577892750502,
      "ssim": 0.9093701839447021,
      "attention_bam_384_mean_attention": 0.09281406551599503,
      "attention_bam_384_std_attention": 0.4109036922454834,
      "attention_bam_384_max_attention": 2.5220370292663574,
      "attention_bam_384_min_attention": -1.147373914718628,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7899345471025945,
      "attention_bam_384_attention_skewness": 0.7086524661328013,
      "attention_bam_384_attention_sparsity": 0.5478642781575521,
      "attention_bam_384_attention_concentration_10": 0.9821185340419039,
      "attention_bam_384_attention_concentration_20": 1.5280742633227002,
      "attention_bam_384_attention_center_y": 0.48400126837996627,
      "attention_bam_384_attention_center_x": 0.48687905543643945,
      "attention_bam_384_attention_center_distance": 0.02926153104982364,
      "attention_bam_384_attention_spatial_variance": 168.53783845270118,
      "attention_bam_384_attention_spatial_std": 12.98221238667359,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 15.759959398581637,
      "attention_bam_384_peak_intensity_mean": 0.3402157723903656,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1607854664325714,
      "attention_bam_16_std_attention": 0.6087384223937988,
      "attention_bam_16_max_attention": 2.8442935943603516,
      "attention_bam_16_min_attention": -1.05502450466156,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7090638322575682,
      "attention_bam_16_attention_skewness": 0.8901633150794632,
      "attention_bam_16_attention_sparsity": 0.53515625,
      "attention_bam_16_attention_concentration_10": 0.8736929026672389,
      "attention_bam_16_attention_concentration_20": 1.3794171154354948,
      "attention_bam_16_attention_center_y": 0.466769100887165,
      "attention_bam_16_attention_center_x": 0.4775241610281047,
      "attention_bam_16_attention_center_distance": 0.05673545616874841,
      "attention_bam_16_attention_spatial_variance": 41.30051881561326,
      "attention_bam_16_attention_spatial_std": 6.426547970381398,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 6.048118907460013,
      "attention_bam_16_peak_intensity_mean": 0.31991755962371826,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 320,
      "phase": "train",
      "loss": 0.009501512162387371,
      "timestamp": 1759543933.757881,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.009501512162387371,
      "ssim": 0.855942964553833,
      "attention_bam_384_mean_attention": 0.09432224184274673,
      "attention_bam_384_std_attention": 0.3806054890155792,
      "attention_bam_384_max_attention": 2.535313844680786,
      "attention_bam_384_min_attention": -1.1325438022613525,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5830122419886137,
      "attention_bam_384_attention_skewness": 0.6025779292189064,
      "attention_bam_384_attention_sparsity": 0.5425745646158854,
      "attention_bam_384_attention_concentration_10": 0.8859839735229194,
      "attention_bam_384_attention_concentration_20": 1.4054975213766123,
      "attention_bam_384_attention_center_y": 0.48209806097709934,
      "attention_bam_384_attention_center_x": 0.48394859014632885,
      "attention_bam_384_attention_center_distance": 0.034003740355148714,
      "attention_bam_384_attention_spatial_variance": 170.6222928515414,
      "attention_bam_384_attention_spatial_std": 13.062246853108443,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 19.14678019444598,
      "attention_bam_384_peak_intensity_mean": 0.3417705297470093,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17407235503196716,
      "attention_bam_16_std_attention": 0.5638018250465393,
      "attention_bam_16_max_attention": 2.6516168117523193,
      "attention_bam_16_min_attention": -0.9478774666786194,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.37963695378507145,
      "attention_bam_16_attention_skewness": 0.7031574972073696,
      "attention_bam_16_attention_sparsity": 0.502197265625,
      "attention_bam_16_attention_concentration_10": 0.7496304935145413,
      "attention_bam_16_attention_concentration_20": 1.191393996010272,
      "attention_bam_16_attention_center_y": 0.46297855758452594,
      "attention_bam_16_attention_center_x": 0.46795508170320704,
      "attention_bam_16_attention_center_distance": 0.06924541843574053,
      "attention_bam_16_attention_spatial_variance": 42.5279041723935,
      "attention_bam_16_attention_spatial_std": 6.521342206355491,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.842475957996966,
      "attention_bam_16_peak_intensity_mean": 0.3275522291660309,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 321,
      "phase": "train",
      "loss": 0.007429942488670349,
      "timestamp": 1759543933.9051833,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007429942488670349,
      "ssim": 0.8911676406860352,
      "attention_bam_384_mean_attention": 0.09528674930334091,
      "attention_bam_384_std_attention": 0.38562554121017456,
      "attention_bam_384_max_attention": 2.930536985397339,
      "attention_bam_384_min_attention": -1.2329453229904175,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.7341139545810886,
      "attention_bam_384_attention_skewness": 0.8284246046937016,
      "attention_bam_384_attention_sparsity": 0.5479965209960938,
      "attention_bam_384_attention_concentration_10": 0.9013623817981935,
      "attention_bam_384_attention_concentration_20": 1.4023398754650978,
      "attention_bam_384_attention_center_y": 0.4822116014907052,
      "attention_bam_384_attention_center_x": 0.48338092811819583,
      "attention_bam_384_attention_center_distance": 0.034427334248763895,
      "attention_bam_384_attention_spatial_variance": 172.30248076484824,
      "attention_bam_384_attention_spatial_std": 13.12640395404805,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 18.514444097851467,
      "attention_bam_384_peak_intensity_mean": 0.32092443108558655,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17938515543937683,
      "attention_bam_16_std_attention": 0.5732483267784119,
      "attention_bam_16_max_attention": 3.628350257873535,
      "attention_bam_16_min_attention": -1.0376174449920654,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.009503832673194,
      "attention_bam_16_attention_skewness": 1.0016952480653674,
      "attention_bam_16_attention_sparsity": 0.497802734375,
      "attention_bam_16_attention_concentration_10": 0.7515728505187563,
      "attention_bam_16_attention_concentration_20": 1.1636477273191912,
      "attention_bam_16_attention_center_y": 0.4630887491337735,
      "attention_bam_16_attention_center_x": 0.46652749963171586,
      "attention_bam_16_attention_center_distance": 0.07046770496354039,
      "attention_bam_16_attention_spatial_variance": 43.90066300685409,
      "attention_bam_16_attention_spatial_std": 6.6257575421120025,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.197247968037585,
      "attention_bam_16_peak_intensity_mean": 0.262064665555954,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 322,
      "phase": "train",
      "loss": 0.010180985555052757,
      "timestamp": 1759543934.0445876,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.010180985555052757,
      "ssim": 0.8464313745498657,
      "attention_bam_384_mean_attention": 0.09292592853307724,
      "attention_bam_384_std_attention": 0.4124753475189209,
      "attention_bam_384_max_attention": 3.1134238243103027,
      "attention_bam_384_min_attention": -1.1121301651000977,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.867753864549144,
      "attention_bam_384_attention_skewness": 1.1406371116346947,
      "attention_bam_384_attention_sparsity": 0.5622914632161459,
      "attention_bam_384_attention_concentration_10": 1.024402436116856,
      "attention_bam_384_attention_concentration_20": 1.5273229330469842,
      "attention_bam_384_attention_center_y": 0.4889513724177725,
      "attention_bam_384_attention_center_x": 0.4963852482828458,
      "attention_bam_384_attention_center_distance": 0.01644010957551244,
      "attention_bam_384_attention_spatial_variance": 168.5512668809679,
      "attention_bam_384_attention_spatial_std": 12.98272956203617,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 12.905313878602078,
      "attention_bam_384_peak_intensity_mean": 0.29265302419662476,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16318386793136597,
      "attention_bam_16_std_attention": 0.6259188652038574,
      "attention_bam_16_max_attention": 3.7562713623046875,
      "attention_bam_16_min_attention": -1.0593708753585815,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.063834671165793,
      "attention_bam_16_attention_skewness": 1.345770539597791,
      "attention_bam_16_attention_sparsity": 0.526611328125,
      "attention_bam_16_attention_concentration_10": 0.9181584215635246,
      "attention_bam_16_attention_concentration_20": 1.375321931579985,
      "attention_bam_16_attention_center_y": 0.48177407093067975,
      "attention_bam_16_attention_center_x": 0.49802551385786914,
      "attention_bam_16_attention_center_distance": 0.025926167706213716,
      "attention_bam_16_attention_spatial_variance": 41.57487034383431,
      "attention_bam_16_attention_spatial_std": 6.447857810454129,
      "attention_bam_16_num_attention_peaks": 2,
      "attention_bam_16_peak_separation_mean": 7.491295796283472,
      "attention_bam_16_peak_intensity_mean": 0.2744041681289673,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 323,
      "phase": "train",
      "loss": 0.008075258694589138,
      "timestamp": 1759543934.1811843,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008075258694589138,
      "ssim": 0.8476390838623047,
      "attention_bam_384_mean_attention": 0.09514684230089188,
      "attention_bam_384_std_attention": 0.39939478039741516,
      "attention_bam_384_max_attention": 3.0061354637145996,
      "attention_bam_384_min_attention": -1.1926391124725342,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9079850487806969,
      "attention_bam_384_attention_skewness": 0.6674470530055511,
      "attention_bam_384_attention_sparsity": 0.5394846598307291,
      "attention_bam_384_attention_concentration_10": 0.9244793817363636,
      "attention_bam_384_attention_concentration_20": 1.4493007002129707,
      "attention_bam_384_attention_center_y": 0.48421586061398075,
      "attention_bam_384_attention_center_x": 0.48085203333359133,
      "attention_bam_384_attention_center_distance": 0.035093694123451334,
      "attention_bam_384_attention_spatial_variance": 170.07198784742818,
      "attention_bam_384_attention_spatial_std": 13.041165126146826,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 15.234716044730968,
      "attention_bam_384_peak_intensity_mean": 0.30857256054878235,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17372119426727295,
      "attention_bam_16_std_attention": 0.5739588737487793,
      "attention_bam_16_max_attention": 2.9466335773468018,
      "attention_bam_16_min_attention": -1.0511895418167114,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8778297002077204,
      "attention_bam_16_attention_skewness": 0.7689276036935783,
      "attention_bam_16_attention_sparsity": 0.492431640625,
      "attention_bam_16_attention_concentration_10": 0.7612270025056356,
      "attention_bam_16_attention_concentration_20": 1.2016106730251317,
      "attention_bam_16_attention_center_y": 0.4695364975302883,
      "attention_bam_16_attention_center_x": 0.4619051060588441,
      "attention_bam_16_attention_center_distance": 0.06898182263625753,
      "attention_bam_16_attention_spatial_variance": 42.34065896559687,
      "attention_bam_16_attention_spatial_std": 6.506970029560369,
      "attention_bam_16_num_attention_peaks": 12,
      "attention_bam_16_peak_separation_mean": 7.640661948722642,
      "attention_bam_16_peak_intensity_mean": 0.30986180901527405,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 324,
      "phase": "train",
      "loss": 0.006482596974819899,
      "timestamp": 1759543934.3204715,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006482596974819899,
      "ssim": 0.8684033751487732,
      "attention_bam_384_mean_attention": 0.09400641173124313,
      "attention_bam_384_std_attention": 0.39586517214775085,
      "attention_bam_384_max_attention": 3.731178045272827,
      "attention_bam_384_min_attention": -1.2017889022827148,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.870503819408187,
      "attention_bam_384_attention_skewness": 1.037790299044064,
      "attention_bam_384_attention_sparsity": 0.5571645100911459,
      "attention_bam_384_attention_concentration_10": 0.9606001059915535,
      "attention_bam_384_attention_concentration_20": 1.4564059264531233,
      "attention_bam_384_attention_center_y": 0.48473577648691357,
      "attention_bam_384_attention_center_x": 0.48129660560762166,
      "attention_bam_384_attention_center_distance": 0.03414127945037532,
      "attention_bam_384_attention_spatial_variance": 168.35839114984108,
      "attention_bam_384_attention_spatial_std": 12.975299270145605,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 15.660902555725723,
      "attention_bam_384_peak_intensity_mean": 0.2639843821525574,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1721917986869812,
      "attention_bam_16_std_attention": 0.6230858564376831,
      "attention_bam_16_max_attention": 4.4362030029296875,
      "attention_bam_16_min_attention": -1.205179214477539,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.4866633230509905,
      "attention_bam_16_attention_skewness": 1.2859660703789468,
      "attention_bam_16_attention_sparsity": 0.505126953125,
      "attention_bam_16_attention_concentration_10": 0.8518505665878621,
      "attention_bam_16_attention_concentration_20": 1.2964355970724133,
      "attention_bam_16_attention_center_y": 0.4698127136268323,
      "attention_bam_16_attention_center_x": 0.46167243345376496,
      "attention_bam_16_attention_center_distance": 0.06899673348690807,
      "attention_bam_16_attention_spatial_variance": 41.018491966166174,
      "attention_bam_16_attention_spatial_std": 6.404568054612752,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.052585891648933,
      "attention_bam_16_peak_intensity_mean": 0.2533424198627472,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 325,
      "phase": "train",
      "loss": 0.0052403053268790245,
      "timestamp": 1759543934.46206,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0052403053268790245,
      "ssim": 0.9024872779846191,
      "attention_bam_384_mean_attention": 0.09396479278802872,
      "attention_bam_384_std_attention": 0.4220464527606964,
      "attention_bam_384_max_attention": 3.270840644836426,
      "attention_bam_384_min_attention": -1.3178515434265137,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.197911050879119,
      "attention_bam_384_attention_skewness": 0.7238942988804011,
      "attention_bam_384_attention_sparsity": 0.5400873819986979,
      "attention_bam_384_attention_concentration_10": 0.9809358601918138,
      "attention_bam_384_attention_concentration_20": 1.5272279609071262,
      "attention_bam_384_attention_center_y": 0.4839253724900123,
      "attention_bam_384_attention_center_x": 0.4842643194872622,
      "attention_bam_384_attention_center_distance": 0.031812113755103136,
      "attention_bam_384_attention_spatial_variance": 172.2493764672642,
      "attention_bam_384_attention_spatial_std": 13.124380993679823,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 19.93254035871246,
      "attention_bam_384_peak_intensity_mean": 0.3126530945301056,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.172644704580307,
      "attention_bam_16_std_attention": 0.6424238085746765,
      "attention_bam_16_max_attention": 3.555738925933838,
      "attention_bam_16_min_attention": -1.1410340070724487,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.839090242992616,
      "attention_bam_16_attention_skewness": 1.0211544391311405,
      "attention_bam_16_attention_sparsity": 0.503173828125,
      "attention_bam_16_attention_concentration_10": 0.8630882643484581,
      "attention_bam_16_attention_concentration_20": 1.3286123153724732,
      "attention_bam_16_attention_center_y": 0.4668570736364892,
      "attention_bam_16_attention_center_x": 0.4692447295807019,
      "attention_bam_16_attention_center_distance": 0.0639427904693133,
      "attention_bam_16_attention_spatial_variance": 43.5425702246109,
      "attention_bam_16_attention_spatial_std": 6.59867943035657,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.786336642047123,
      "attention_bam_16_peak_intensity_mean": 0.2812098264694214,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 326,
      "phase": "train",
      "loss": 0.006170285400003195,
      "timestamp": 1759543934.5944455,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006170285400003195,
      "ssim": 0.906389057636261,
      "attention_bam_384_mean_attention": 0.09333812445402145,
      "attention_bam_384_std_attention": 0.3934215307235718,
      "attention_bam_384_max_attention": 2.9647397994995117,
      "attention_bam_384_min_attention": -1.1423496007919312,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8026512567751518,
      "attention_bam_384_attention_skewness": 0.571045733502942,
      "attention_bam_384_attention_sparsity": 0.5375442504882812,
      "attention_bam_384_attention_concentration_10": 0.90747332589495,
      "attention_bam_384_attention_concentration_20": 1.4392308074638127,
      "attention_bam_384_attention_center_y": 0.4784561794298212,
      "attention_bam_384_attention_center_x": 0.4797434684858807,
      "attention_bam_384_attention_center_distance": 0.04182016914701727,
      "attention_bam_384_attention_spatial_variance": 169.5795575259305,
      "attention_bam_384_attention_spatial_std": 13.022271596228153,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 18.771133250208848,
      "attention_bam_384_peak_intensity_mean": 0.3052953779697418,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17431873083114624,
      "attention_bam_16_std_attention": 0.580204427242279,
      "attention_bam_16_max_attention": 2.817138671875,
      "attention_bam_16_min_attention": -1.213789463043213,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6689445822628146,
      "attention_bam_16_attention_skewness": 0.7341548631761677,
      "attention_bam_16_attention_sparsity": 0.49365234375,
      "attention_bam_16_attention_concentration_10": 0.7604590124365941,
      "attention_bam_16_attention_concentration_20": 1.211230028332377,
      "attention_bam_16_attention_center_y": 0.45729912782767496,
      "attention_bam_16_attention_center_x": 0.4594977236493254,
      "attention_bam_16_attention_center_distance": 0.08323219177534204,
      "attention_bam_16_attention_spatial_variance": 41.78270165671221,
      "attention_bam_16_attention_spatial_std": 6.463954026500514,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.59915885315012,
      "attention_bam_16_peak_intensity_mean": 0.35275954008102417,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 327,
      "phase": "train",
      "loss": 0.010269638150930405,
      "timestamp": 1759543934.7324421,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.010269638150930405,
      "ssim": 0.878352165222168,
      "attention_bam_384_mean_attention": 0.09272342920303345,
      "attention_bam_384_std_attention": 0.37386730313301086,
      "attention_bam_384_max_attention": 2.775155544281006,
      "attention_bam_384_min_attention": -1.24443781375885,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2512170745936633,
      "attention_bam_384_attention_skewness": 0.5982990171830613,
      "attention_bam_384_attention_sparsity": 0.5381647745768229,
      "attention_bam_384_attention_concentration_10": 0.8741715365775011,
      "attention_bam_384_attention_concentration_20": 1.382637553693993,
      "attention_bam_384_attention_center_y": 0.47983675332333264,
      "attention_bam_384_attention_center_x": 0.4816882326587157,
      "attention_bam_384_attention_center_distance": 0.03851953633431908,
      "attention_bam_384_attention_spatial_variance": 170.2070488842654,
      "attention_bam_384_attention_spatial_std": 13.046342356548267,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 17.174954969722297,
      "attention_bam_384_peak_intensity_mean": 0.3331241011619568,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17648935317993164,
      "attention_bam_16_std_attention": 0.58632892370224,
      "attention_bam_16_max_attention": 3.2893617153167725,
      "attention_bam_16_min_attention": -1.2125067710876465,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8076757078122285,
      "attention_bam_16_attention_skewness": 0.7288257034265504,
      "attention_bam_16_attention_sparsity": 0.49609375,
      "attention_bam_16_attention_concentration_10": 0.7541767139375579,
      "attention_bam_16_attention_concentration_20": 1.2046244511822555,
      "attention_bam_16_attention_center_y": 0.4559215442521609,
      "attention_bam_16_attention_center_x": 0.46410560744558466,
      "attention_bam_16_attention_center_distance": 0.08039051782349305,
      "attention_bam_16_attention_spatial_variance": 42.13098162977623,
      "attention_bam_16_attention_spatial_std": 6.490838284056708,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.16153868667524,
      "attention_bam_16_peak_intensity_mean": 0.30974194407463074,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 328,
      "phase": "train",
      "loss": 0.005208837799727917,
      "timestamp": 1759543934.870527,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005208837799727917,
      "ssim": 0.900772750377655,
      "attention_bam_384_mean_attention": 0.08812279254198074,
      "attention_bam_384_std_attention": 0.3901391327381134,
      "attention_bam_384_max_attention": 3.6727874279022217,
      "attention_bam_384_min_attention": -1.194007158279419,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.8035378100371497,
      "attention_bam_384_attention_skewness": 0.9862798527932197,
      "attention_bam_384_attention_sparsity": 0.5526707967122396,
      "attention_bam_384_attention_concentration_10": 0.9874828804973877,
      "attention_bam_384_attention_concentration_20": 1.5031116375861417,
      "attention_bam_384_attention_center_y": 0.47949213912384003,
      "attention_bam_384_attention_center_x": 0.4835430235590473,
      "attention_bam_384_attention_center_distance": 0.03718613804347001,
      "attention_bam_384_attention_spatial_variance": 171.57583124651026,
      "attention_bam_384_attention_spatial_std": 13.098695784180586,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 18.775132233260003,
      "attention_bam_384_peak_intensity_mean": 0.2660940885543823,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.15912029147148132,
      "attention_bam_16_std_attention": 0.587425172328949,
      "attention_bam_16_max_attention": 4.437987327575684,
      "attention_bam_16_min_attention": -0.9761785268783569,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.512590934905152,
      "attention_bam_16_attention_skewness": 1.201982556595764,
      "attention_bam_16_attention_sparsity": 0.5068359375,
      "attention_bam_16_attention_concentration_10": 0.8425534879593141,
      "attention_bam_16_attention_concentration_20": 1.2934384628484057,
      "attention_bam_16_attention_center_y": 0.45588687505444053,
      "attention_bam_16_attention_center_x": 0.4663012196620001,
      "attention_bam_16_attention_center_distance": 0.07850573977399752,
      "attention_bam_16_attention_spatial_variance": 43.216743607559565,
      "attention_bam_16_attention_spatial_std": 6.5739442960493335,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 10.012113889706344,
      "attention_bam_16_peak_intensity_mean": 0.2148776650428772,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 329,
      "phase": "train",
      "loss": 0.006177545990794897,
      "timestamp": 1759543935.0066097,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006177545990794897,
      "ssim": 0.882239580154419,
      "attention_bam_384_mean_attention": 0.08891400694847107,
      "attention_bam_384_std_attention": 0.37263697385787964,
      "attention_bam_384_max_attention": 2.645338535308838,
      "attention_bam_384_min_attention": -1.0927612781524658,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.271602191515182,
      "attention_bam_384_attention_skewness": 0.8027398790985455,
      "attention_bam_384_attention_sparsity": 0.55810546875,
      "attention_bam_384_attention_concentration_10": 0.940036715771592,
      "attention_bam_384_attention_concentration_20": 1.4590766400115063,
      "attention_bam_384_attention_center_y": 0.48211743688594283,
      "attention_bam_384_attention_center_x": 0.48599269099207715,
      "attention_bam_384_attention_center_distance": 0.03212446946399814,
      "attention_bam_384_attention_spatial_variance": 167.914707329859,
      "attention_bam_384_attention_spatial_std": 12.95819074291851,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 16.270694658827217,
      "attention_bam_384_peak_intensity_mean": 0.3194180727005005,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16059035062789917,
      "attention_bam_16_std_attention": 0.5793417096138,
      "attention_bam_16_max_attention": 3.1218011379241943,
      "attention_bam_16_min_attention": -1.0868051052093506,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.5058991993425357,
      "attention_bam_16_attention_skewness": 1.018261148796551,
      "attention_bam_16_attention_sparsity": 0.520263671875,
      "attention_bam_16_attention_concentration_10": 0.843873213364207,
      "attention_bam_16_attention_concentration_20": 1.31205463169883,
      "attention_bam_16_attention_center_y": 0.4636398289532189,
      "attention_bam_16_attention_center_x": 0.4750132629661918,
      "attention_bam_16_attention_center_distance": 0.062392292250691664,
      "attention_bam_16_attention_spatial_variance": 40.54538159439949,
      "attention_bam_16_attention_spatial_std": 6.367525547212158,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.24986609118634,
      "attention_bam_16_peak_intensity_mean": 0.298586905002594,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 330,
      "phase": "train",
      "loss": 0.008019557222723961,
      "timestamp": 1759543935.1889968,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008019557222723961,
      "ssim": 0.8900588154792786,
      "attention_bam_384_mean_attention": 0.09124460816383362,
      "attention_bam_384_std_attention": 0.3749200403690338,
      "attention_bam_384_max_attention": 3.071434259414673,
      "attention_bam_384_min_attention": -1.3176020383834839,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1877946461810422,
      "attention_bam_384_attention_skewness": 0.7267012314635477,
      "attention_bam_384_attention_sparsity": 0.5515619913736979,
      "attention_bam_384_attention_concentration_10": 0.9158068120537247,
      "attention_bam_384_attention_concentration_20": 1.4304651407625184,
      "attention_bam_384_attention_center_y": 0.49006075785819875,
      "attention_bam_384_attention_center_x": 0.4879769278150901,
      "attention_bam_384_attention_center_distance": 0.022060951888661185,
      "attention_bam_384_attention_spatial_variance": 171.84521902195024,
      "attention_bam_384_attention_spatial_std": 13.108974750984542,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 17.802732609949594,
      "attention_bam_384_peak_intensity_mean": 0.3224274516105652,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1700635552406311,
      "attention_bam_16_std_attention": 0.5917003750801086,
      "attention_bam_16_max_attention": 3.639392852783203,
      "attention_bam_16_min_attention": -1.042947769165039,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.1160613971778046,
      "attention_bam_16_attention_skewness": 0.905283092171684,
      "attention_bam_16_attention_sparsity": 0.51318359375,
      "attention_bam_16_attention_concentration_10": 0.8138816757109187,
      "attention_bam_16_attention_concentration_20": 1.2725418504629293,
      "attention_bam_16_attention_center_y": 0.49002490898177326,
      "attention_bam_16_attention_center_x": 0.482096622819842,
      "attention_bam_16_attention_center_distance": 0.028983904335920997,
      "attention_bam_16_attention_spatial_variance": 43.621395786371906,
      "attention_bam_16_attention_spatial_std": 6.604649558180351,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 10.530920962837023,
      "attention_bam_16_peak_intensity_mean": 0.26840561628341675,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 331,
      "phase": "train",
      "loss": 0.008668934926390648,
      "timestamp": 1759543935.3309753,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008668934926390648,
      "ssim": 0.8831793069839478,
      "attention_bam_384_mean_attention": 0.09198654443025589,
      "attention_bam_384_std_attention": 0.42207732796669006,
      "attention_bam_384_max_attention": 4.115329265594482,
      "attention_bam_384_min_attention": -1.406167984008789,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.222785614498415,
      "attention_bam_384_attention_skewness": 0.840698957912917,
      "attention_bam_384_attention_sparsity": 0.5444691975911459,
      "attention_bam_384_attention_concentration_10": 0.9973922393983464,
      "attention_bam_384_attention_concentration_20": 1.543752157879083,
      "attention_bam_384_attention_center_y": 0.4819350193750228,
      "attention_bam_384_attention_center_x": 0.48357427072369497,
      "attention_bam_384_attention_center_distance": 0.034529642547795523,
      "attention_bam_384_attention_spatial_variance": 170.86888039555083,
      "attention_bam_384_attention_spatial_std": 13.07168238581212,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 17.01880083117742,
      "attention_bam_384_peak_intensity_mean": 0.2718792259693146,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16673465073108673,
      "attention_bam_16_std_attention": 0.6448925733566284,
      "attention_bam_16_max_attention": 3.745587110519409,
      "attention_bam_16_min_attention": -1.2612749338150024,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.2631258341838176,
      "attention_bam_16_attention_skewness": 1.0829774780770554,
      "attention_bam_16_attention_sparsity": 0.50537109375,
      "attention_bam_16_attention_concentration_10": 0.8949673051254408,
      "attention_bam_16_attention_concentration_20": 1.367269014964108,
      "attention_bam_16_attention_center_y": 0.46098516000493733,
      "attention_bam_16_attention_center_x": 0.467696152796507,
      "attention_bam_16_attention_center_distance": 0.07163373903387933,
      "attention_bam_16_attention_spatial_variance": 42.660341538987375,
      "attention_bam_16_attention_spatial_std": 6.531488462746251,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.707855671498766,
      "attention_bam_16_peak_intensity_mean": 0.288750559091568,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 332,
      "phase": "train",
      "loss": 0.00806097686290741,
      "timestamp": 1759543935.4728467,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00806097686290741,
      "ssim": 0.8739746809005737,
      "attention_bam_384_mean_attention": 0.09164893627166748,
      "attention_bam_384_std_attention": 0.40441328287124634,
      "attention_bam_384_max_attention": 4.184585094451904,
      "attention_bam_384_min_attention": -1.1535589694976807,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.2901093403965387,
      "attention_bam_384_attention_skewness": 1.1337252206233,
      "attention_bam_384_attention_sparsity": 0.5572357177734375,
      "attention_bam_384_attention_concentration_10": 0.9929927146862454,
      "attention_bam_384_attention_concentration_20": 1.5056030533883609,
      "attention_bam_384_attention_center_y": 0.4843955704234548,
      "attention_bam_384_attention_center_x": 0.4883980171624549,
      "attention_bam_384_attention_center_distance": 0.027499244650428085,
      "attention_bam_384_attention_spatial_variance": 171.78095643224378,
      "attention_bam_384_attention_spatial_std": 13.106523430423637,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 16.6498125276844,
      "attention_bam_384_peak_intensity_mean": 0.2372186779975891,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.15928971767425537,
      "attention_bam_16_std_attention": 0.6254889965057373,
      "attention_bam_16_max_attention": 3.9524455070495605,
      "attention_bam_16_min_attention": -1.0327527523040771,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.7706421435310213,
      "attention_bam_16_attention_skewness": 1.4373426511810938,
      "attention_bam_16_attention_sparsity": 0.53173828125,
      "attention_bam_16_attention_concentration_10": 0.9244778550380339,
      "attention_bam_16_attention_concentration_20": 1.387030026493856,
      "attention_bam_16_attention_center_y": 0.46884637484054154,
      "attention_bam_16_attention_center_x": 0.48173871621395914,
      "attention_bam_16_attention_center_distance": 0.05106902869823083,
      "attention_bam_16_attention_spatial_variance": 43.45216794737722,
      "attention_bam_16_attention_spatial_std": 6.5918258432225905,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.969445726308479,
      "attention_bam_16_peak_intensity_mean": 0.2454664558172226,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 333,
      "phase": "train",
      "loss": 0.004555576480925083,
      "timestamp": 1759543935.6096683,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004555576480925083,
      "ssim": 0.9143176078796387,
      "attention_bam_384_mean_attention": 0.08738633990287781,
      "attention_bam_384_std_attention": 0.3996383249759674,
      "attention_bam_384_max_attention": 3.6296141147613525,
      "attention_bam_384_min_attention": -1.2253636121749878,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.4285126881420833,
      "attention_bam_384_attention_skewness": 1.0184863269636832,
      "attention_bam_384_attention_sparsity": 0.5617472330729166,
      "attention_bam_384_attention_concentration_10": 1.0297555975336103,
      "attention_bam_384_attention_concentration_20": 1.568109235877918,
      "attention_bam_384_attention_center_y": 0.4888884280563752,
      "attention_bam_384_attention_center_x": 0.4776463598070448,
      "attention_bam_384_attention_center_distance": 0.03530303842261887,
      "attention_bam_384_attention_spatial_variance": 171.32031626808651,
      "attention_bam_384_attention_spatial_std": 13.088938699072836,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 16.848505148503445,
      "attention_bam_384_peak_intensity_mean": 0.2725059390068054,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1410197913646698,
      "attention_bam_16_std_attention": 0.604537844657898,
      "attention_bam_16_max_attention": 3.94541597366333,
      "attention_bam_16_min_attention": -1.229792833328247,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.535344024082529,
      "attention_bam_16_attention_skewness": 1.3425235036181469,
      "attention_bam_16_attention_sparsity": 0.544189453125,
      "attention_bam_16_attention_concentration_10": 0.9949383315701347,
      "attention_bam_16_attention_concentration_20": 1.4998046213907819,
      "attention_bam_16_attention_center_y": 0.48028040846371567,
      "attention_bam_16_attention_center_x": 0.4549202262273805,
      "attention_bam_16_attention_center_distance": 0.06958517505544481,
      "attention_bam_16_attention_spatial_variance": 42.66207771030172,
      "attention_bam_16_attention_spatial_std": 6.531621369177926,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.860784808378444,
      "attention_bam_16_peak_intensity_mean": 0.26967695355415344,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 334,
      "phase": "train",
      "loss": 0.005239352583885193,
      "timestamp": 1759543935.9686992,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005239352583885193,
      "ssim": 0.904851496219635,
      "attention_bam_384_mean_attention": 0.08903732150793076,
      "attention_bam_384_std_attention": 0.3832722008228302,
      "attention_bam_384_max_attention": 2.8816258907318115,
      "attention_bam_384_min_attention": -1.134177803993225,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0592753694416164,
      "attention_bam_384_attention_skewness": 0.6834204167994993,
      "attention_bam_384_attention_sparsity": 0.5466435750325521,
      "attention_bam_384_attention_concentration_10": 0.9412525564023693,
      "attention_bam_384_attention_concentration_20": 1.4791072869046598,
      "attention_bam_384_attention_center_y": 0.4870297932518147,
      "attention_bam_384_attention_center_x": 0.4878743431889348,
      "attention_bam_384_attention_center_distance": 0.025110070338029825,
      "attention_bam_384_attention_spatial_variance": 171.17179047094558,
      "attention_bam_384_attention_spatial_std": 13.083263754543268,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 17.25927438640002,
      "attention_bam_384_peak_intensity_mean": 0.30748075246810913,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.162319615483284,
      "attention_bam_16_std_attention": 0.5804268717765808,
      "attention_bam_16_max_attention": 3.81874942779541,
      "attention_bam_16_min_attention": -1.0346177816390991,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.615670558091253,
      "attention_bam_16_attention_skewness": 0.943324545185436,
      "attention_bam_16_attention_sparsity": 0.50830078125,
      "attention_bam_16_attention_concentration_10": 0.8253131229458671,
      "attention_bam_16_attention_concentration_20": 1.2891134145918068,
      "attention_bam_16_attention_center_y": 0.47680520192372183,
      "attention_bam_16_attention_center_x": 0.4807430414157055,
      "attention_bam_16_attention_center_distance": 0.04263400313638283,
      "attention_bam_16_attention_spatial_variance": 42.978156176807815,
      "attention_bam_16_attention_spatial_std": 6.555772736818126,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.370675693902186,
      "attention_bam_16_peak_intensity_mean": 0.2484089881181717,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 335,
      "phase": "train",
      "loss": 0.004746016580611467,
      "timestamp": 1759543936.1036563,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004746016580611467,
      "ssim": 0.9147676825523376,
      "attention_bam_384_mean_attention": 0.0891038104891777,
      "attention_bam_384_std_attention": 0.3993186056613922,
      "attention_bam_384_max_attention": 3.502383232116699,
      "attention_bam_384_min_attention": -1.090889573097229,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.3479895990525037,
      "attention_bam_384_attention_skewness": 0.7059854928846768,
      "attention_bam_384_attention_sparsity": 0.5410130818684896,
      "attention_bam_384_attention_concentration_10": 0.9719739699598642,
      "attention_bam_384_attention_concentration_20": 1.5176766598471858,
      "attention_bam_384_attention_center_y": 0.4845126787112122,
      "attention_bam_384_attention_center_x": 0.4855736496973102,
      "attention_bam_384_attention_center_distance": 0.029932480811254467,
      "attention_bam_384_attention_spatial_variance": 168.9946447972368,
      "attention_bam_384_attention_spatial_std": 12.999794029031259,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 19.62407303538866,
      "attention_bam_384_peak_intensity_mean": 0.2615909278392792,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1596144437789917,
      "attention_bam_16_std_attention": 0.5978543162345886,
      "attention_bam_16_max_attention": 3.0186986923217773,
      "attention_bam_16_min_attention": -1.0243602991104126,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.0765437338423514,
      "attention_bam_16_attention_skewness": 0.9277873512362843,
      "attention_bam_16_attention_sparsity": 0.53173828125,
      "attention_bam_16_attention_concentration_10": 0.8762055218049277,
      "attention_bam_16_attention_concentration_20": 1.3664206579159948,
      "attention_bam_16_attention_center_y": 0.4728546184045944,
      "attention_bam_16_attention_center_x": 0.47332659445599745,
      "attention_bam_16_attention_center_distance": 0.05382085665009448,
      "attention_bam_16_attention_spatial_variance": 41.588754270699866,
      "attention_bam_16_attention_spatial_std": 6.448934351557617,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.946710505959805,
      "attention_bam_16_peak_intensity_mean": 0.31240788102149963,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 336,
      "phase": "train",
      "loss": 0.005105280317366123,
      "timestamp": 1759543936.2368996,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005105280317366123,
      "ssim": 0.9027783274650574,
      "attention_bam_384_mean_attention": 0.09129404276609421,
      "attention_bam_384_std_attention": 0.38376331329345703,
      "attention_bam_384_max_attention": 4.16811466217041,
      "attention_bam_384_min_attention": -1.1542398929595947,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.5268840632966443,
      "attention_bam_384_attention_skewness": 0.8193258465704448,
      "attention_bam_384_attention_sparsity": 0.5433883666992188,
      "attention_bam_384_attention_concentration_10": 0.9154080012759205,
      "attention_bam_384_attention_concentration_20": 1.4309540445171016,
      "attention_bam_384_attention_center_y": 0.48080410368279286,
      "attention_bam_384_attention_center_x": 0.4828387088831386,
      "attention_bam_384_attention_center_distance": 0.03641407278013904,
      "attention_bam_384_attention_spatial_variance": 170.4030358131676,
      "attention_bam_384_attention_spatial_std": 13.053851378546012,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 17.918354461264123,
      "attention_bam_384_peak_intensity_mean": 0.2362593412399292,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17544913291931152,
      "attention_bam_16_std_attention": 0.5817890167236328,
      "attention_bam_16_max_attention": 5.181231498718262,
      "attention_bam_16_min_attention": -1.0618184804916382,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 4.122707920033819,
      "attention_bam_16_attention_skewness": 1.1742592905983469,
      "attention_bam_16_attention_sparsity": 0.49853515625,
      "attention_bam_16_attention_concentration_10": 0.7584292832897356,
      "attention_bam_16_attention_concentration_20": 1.1922399430724981,
      "attention_bam_16_attention_center_y": 0.4588078901278783,
      "attention_bam_16_attention_center_x": 0.4655626686525157,
      "attention_bam_16_attention_center_distance": 0.07593049066156979,
      "attention_bam_16_attention_spatial_variance": 42.42150611606662,
      "attention_bam_16_attention_spatial_std": 6.513179416849087,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.140939131517046,
      "attention_bam_16_peak_intensity_mean": 0.20064692199230194,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 337,
      "phase": "train",
      "loss": 0.005771992262452841,
      "timestamp": 1759543936.3748107,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005771992262452841,
      "ssim": 0.8922358751296997,
      "attention_bam_384_mean_attention": 0.09017729014158249,
      "attention_bam_384_std_attention": 0.3768221139907837,
      "attention_bam_384_max_attention": 3.5043320655822754,
      "attention_bam_384_min_attention": -1.129162311553955,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2192499920681552,
      "attention_bam_384_attention_skewness": 0.7079053993316281,
      "attention_bam_384_attention_sparsity": 0.5481923421223959,
      "attention_bam_384_attention_concentration_10": 0.9294118463550788,
      "attention_bam_384_attention_concentration_20": 1.4418441201541332,
      "attention_bam_384_attention_center_y": 0.48041067953502975,
      "attention_bam_384_attention_center_x": 0.48395692069018376,
      "attention_bam_384_attention_center_distance": 0.035808431130680836,
      "attention_bam_384_attention_spatial_variance": 172.0897912141157,
      "attention_bam_384_attention_spatial_std": 13.118299859894792,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 18.44914755397197,
      "attention_bam_384_peak_intensity_mean": 0.2658328711986542,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17965975403785706,
      "attention_bam_16_std_attention": 0.5748655796051025,
      "attention_bam_16_max_attention": 3.136218309402466,
      "attention_bam_16_min_attention": -1.053871989250183,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.9444929312988348,
      "attention_bam_16_attention_skewness": 0.8307752107158544,
      "attention_bam_16_attention_sparsity": 0.495849609375,
      "attention_bam_16_attention_concentration_10": 0.7538388830994998,
      "attention_bam_16_attention_concentration_20": 1.1791399713958697,
      "attention_bam_16_attention_center_y": 0.45611841922193325,
      "attention_bam_16_attention_center_x": 0.4709690204879705,
      "attention_bam_16_attention_center_distance": 0.07440955453447995,
      "attention_bam_16_attention_spatial_variance": 43.5501534955644,
      "attention_bam_16_attention_spatial_std": 6.5992540105351605,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.731773270473274,
      "attention_bam_16_peak_intensity_mean": 0.30948877334594727,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 338,
      "phase": "train",
      "loss": 0.008142921142280102,
      "timestamp": 1759543936.5444856,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008142921142280102,
      "ssim": 0.8912855386734009,
      "attention_bam_384_mean_attention": 0.09109935164451599,
      "attention_bam_384_std_attention": 0.3871390223503113,
      "attention_bam_384_max_attention": 2.9353482723236084,
      "attention_bam_384_min_attention": -1.2247750759124756,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.31990709539749673,
      "attention_bam_384_attention_skewness": 0.49336790903388483,
      "attention_bam_384_attention_sparsity": 0.5396474202473959,
      "attention_bam_384_attention_concentration_10": 0.9024305040987689,
      "attention_bam_384_attention_concentration_20": 1.4549353073446374,
      "attention_bam_384_attention_center_y": 0.4885216642580278,
      "attention_bam_384_attention_center_x": 0.4820481858969193,
      "attention_bam_384_attention_center_distance": 0.03013369612234797,
      "attention_bam_384_attention_spatial_variance": 170.31553976047334,
      "attention_bam_384_attention_spatial_std": 13.050499598117819,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 18.056603219136104,
      "attention_bam_384_peak_intensity_mean": 0.31851622462272644,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18785353004932404,
      "attention_bam_16_std_attention": 0.5773499608039856,
      "attention_bam_16_max_attention": 2.864318609237671,
      "attention_bam_16_min_attention": -1.0907264947891235,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.49524812813721075,
      "attention_bam_16_attention_skewness": 0.7012254296920117,
      "attention_bam_16_attention_sparsity": 0.489013671875,
      "attention_bam_16_attention_concentration_10": 0.7149890172837415,
      "attention_bam_16_attention_concentration_20": 1.1402141586065488,
      "attention_bam_16_attention_center_y": 0.4819244839422642,
      "attention_bam_16_attention_center_x": 0.4650121022527398,
      "attention_bam_16_attention_center_distance": 0.05569339762532356,
      "attention_bam_16_attention_spatial_variance": 42.31971637522125,
      "attention_bam_16_attention_spatial_std": 6.505360587640108,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.454017776906023,
      "attention_bam_16_peak_intensity_mean": 0.33030200004577637,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 339,
      "phase": "train",
      "loss": 0.007110892795026302,
      "timestamp": 1759543936.7309113,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007110892795026302,
      "ssim": 0.844717264175415,
      "attention_bam_384_mean_attention": 0.08951488882303238,
      "attention_bam_384_std_attention": 0.390239953994751,
      "attention_bam_384_max_attention": 3.4499526023864746,
      "attention_bam_384_min_attention": -1.337125301361084,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4443467165683916,
      "attention_bam_384_attention_skewness": 0.7104675840743596,
      "attention_bam_384_attention_sparsity": 0.5474802652994791,
      "attention_bam_384_attention_concentration_10": 0.9517425853944266,
      "attention_bam_384_attention_concentration_20": 1.4868058157348945,
      "attention_bam_384_attention_center_y": 0.4809464431383325,
      "attention_bam_384_attention_center_x": 0.4857234393254037,
      "attention_bam_384_attention_center_distance": 0.03367070577746258,
      "attention_bam_384_attention_spatial_variance": 171.29404014528964,
      "attention_bam_384_attention_spatial_std": 13.087934907589114,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 18.101965903500133,
      "attention_bam_384_peak_intensity_mean": 0.3010588586330414,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16901573538780212,
      "attention_bam_16_std_attention": 0.5922678709030151,
      "attention_bam_16_max_attention": 4.033295631408691,
      "attention_bam_16_min_attention": -1.2403697967529297,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.1020408119489762,
      "attention_bam_16_attention_skewness": 0.8036318174043916,
      "attention_bam_16_attention_sparsity": 0.4970703125,
      "attention_bam_16_attention_concentration_10": 0.798235990189532,
      "attention_bam_16_attention_concentration_20": 1.2629377205138395,
      "attention_bam_16_attention_center_y": 0.4580696035818698,
      "attention_bam_16_attention_center_x": 0.4761606988755843,
      "attention_bam_16_attention_center_distance": 0.06821246838932177,
      "attention_bam_16_attention_spatial_variance": 43.04935504012483,
      "attention_bam_16_attention_spatial_std": 6.561200731582964,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 9.307807947115418,
      "attention_bam_16_peak_intensity_mean": 0.2696245610713959,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 340,
      "phase": "train",
      "loss": 0.007055600639432669,
      "timestamp": 1759543936.9380188,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007055600639432669,
      "ssim": 0.8807241916656494,
      "attention_bam_384_mean_attention": 0.08970112353563309,
      "attention_bam_384_std_attention": 0.3830152750015259,
      "attention_bam_384_max_attention": 3.2290327548980713,
      "attention_bam_384_min_attention": -1.1921241283416748,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8490128167452,
      "attention_bam_384_attention_skewness": 0.6193453744811224,
      "attention_bam_384_attention_sparsity": 0.5438664754231771,
      "attention_bam_384_attention_concentration_10": 0.9221862935178093,
      "attention_bam_384_attention_concentration_20": 1.464889683508653,
      "attention_bam_384_attention_center_y": 0.48796917902769343,
      "attention_bam_384_attention_center_x": 0.4817633635477377,
      "attention_bam_384_attention_center_distance": 0.03089710544240913,
      "attention_bam_384_attention_spatial_variance": 170.84535429490492,
      "attention_bam_384_attention_spatial_std": 13.070782466819074,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 17.703532360758366,
      "attention_bam_384_peak_intensity_mean": 0.2922220528125763,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17846207320690155,
      "attention_bam_16_std_attention": 0.5735647678375244,
      "attention_bam_16_max_attention": 2.8526101112365723,
      "attention_bam_16_min_attention": -1.1711289882659912,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.625042937800782,
      "attention_bam_16_attention_skewness": 0.7394225485425964,
      "attention_bam_16_attention_sparsity": 0.49755859375,
      "attention_bam_16_attention_concentration_10": 0.7415203767111491,
      "attention_bam_16_attention_concentration_20": 1.1825431993644036,
      "attention_bam_16_attention_center_y": 0.4770268928465169,
      "attention_bam_16_attention_center_x": 0.4633566179385839,
      "attention_bam_16_attention_center_distance": 0.06116373273737187,
      "attention_bam_16_attention_spatial_variance": 42.925221553872646,
      "attention_bam_16_attention_spatial_std": 6.5517342401743255,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.129357469079926,
      "attention_bam_16_peak_intensity_mean": 0.34362754225730896,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 341,
      "phase": "train",
      "loss": 0.006475442089140415,
      "timestamp": 1759543937.0970676,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006475442089140415,
      "ssim": 0.8981775641441345,
      "attention_bam_384_mean_attention": 0.08747246116399765,
      "attention_bam_384_std_attention": 0.37558844685554504,
      "attention_bam_384_max_attention": 2.8193395137786865,
      "attention_bam_384_min_attention": -1.1361479759216309,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1188367789487694,
      "attention_bam_384_attention_skewness": 0.6607344274975405,
      "attention_bam_384_attention_sparsity": 0.5499496459960938,
      "attention_bam_384_attention_concentration_10": 0.9429786675379922,
      "attention_bam_384_attention_concentration_20": 1.4707776005854039,
      "attention_bam_384_attention_center_y": 0.4870812753372226,
      "attention_bam_384_attention_center_x": 0.48123014492533783,
      "attention_bam_384_attention_center_distance": 0.03222424262683217,
      "attention_bam_384_attention_spatial_variance": 170.81628694038446,
      "attention_bam_384_attention_spatial_std": 13.069670498539145,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 18.406084193978906,
      "attention_bam_384_peak_intensity_mean": 0.3133202791213989,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17473240196704865,
      "attention_bam_16_std_attention": 0.5814787745475769,
      "attention_bam_16_max_attention": 3.185568332672119,
      "attention_bam_16_min_attention": -1.1582796573638916,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.9676443496703651,
      "attention_bam_16_attention_skewness": 0.7941800808275182,
      "attention_bam_16_attention_sparsity": 0.507080078125,
      "attention_bam_16_attention_concentration_10": 0.7671393191128802,
      "attention_bam_16_attention_concentration_20": 1.2199427379435013,
      "attention_bam_16_attention_center_y": 0.476446720553057,
      "attention_bam_16_attention_center_x": 0.4626167758638361,
      "attention_bam_16_attention_center_distance": 0.06248619718818638,
      "attention_bam_16_attention_spatial_variance": 42.766068312159724,
      "attention_bam_16_attention_spatial_std": 6.539577074410831,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.867082033162584,
      "attention_bam_16_peak_intensity_mean": 0.3099581003189087,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 342,
      "phase": "train",
      "loss": 0.006390205584466457,
      "timestamp": 1759543937.2449794,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006390205584466457,
      "ssim": 0.9044236540794373,
      "attention_bam_384_mean_attention": 0.08803600817918777,
      "attention_bam_384_std_attention": 0.3989402651786804,
      "attention_bam_384_max_attention": 2.615081548690796,
      "attention_bam_384_min_attention": -1.3097190856933594,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6438706627710347,
      "attention_bam_384_attention_skewness": 0.6144448151199694,
      "attention_bam_384_attention_sparsity": 0.5496978759765625,
      "attention_bam_384_attention_concentration_10": 0.9945349777332818,
      "attention_bam_384_attention_concentration_20": 1.560247777164849,
      "attention_bam_384_attention_center_y": 0.4794447785002634,
      "attention_bam_384_attention_center_x": 0.4835747285235307,
      "attention_bam_384_attention_center_distance": 0.037210393009989844,
      "attention_bam_384_attention_spatial_variance": 171.30478089546205,
      "attention_bam_384_attention_spatial_std": 13.088345231367564,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 18.58381573945596,
      "attention_bam_384_peak_intensity_mean": 0.35720986127853394,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17930221557617188,
      "attention_bam_16_std_attention": 0.6132933497428894,
      "attention_bam_16_max_attention": 3.0082552433013916,
      "attention_bam_16_min_attention": -1.0737183094024658,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.560174431450223,
      "attention_bam_16_attention_skewness": 0.7717797647029253,
      "attention_bam_16_attention_sparsity": 0.505615234375,
      "attention_bam_16_attention_concentration_10": 0.7893533723803761,
      "attention_bam_16_attention_concentration_20": 1.254296102093425,
      "attention_bam_16_attention_center_y": 0.45371103329930884,
      "attention_bam_16_attention_center_x": 0.4677348918436883,
      "attention_bam_16_attention_center_distance": 0.07979606058642474,
      "attention_bam_16_attention_spatial_variance": 43.26099278989167,
      "attention_bam_16_attention_spatial_std": 6.577308932222332,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.330281876782035,
      "attention_bam_16_peak_intensity_mean": 0.31002962589263916,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 343,
      "phase": "train",
      "loss": 0.006459344178438187,
      "timestamp": 1759543937.3806837,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006459344178438187,
      "ssim": 0.8918185234069824,
      "attention_bam_384_mean_attention": 0.08523597568273544,
      "attention_bam_384_std_attention": 0.33321306109428406,
      "attention_bam_384_max_attention": 2.67880916595459,
      "attention_bam_384_min_attention": -1.0421905517578125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.020462319310787,
      "attention_bam_384_attention_skewness": 0.6521544284048021,
      "attention_bam_384_attention_sparsity": 0.5533599853515625,
      "attention_bam_384_attention_concentration_10": 0.8682927912312066,
      "attention_bam_384_attention_concentration_20": 1.3605691939072884,
      "attention_bam_384_attention_center_y": 0.48272001837619166,
      "attention_bam_384_attention_center_x": 0.4898859710522137,
      "attention_bam_384_attention_center_distance": 0.028315767567763824,
      "attention_bam_384_attention_spatial_variance": 169.97949841948702,
      "attention_bam_384_attention_spatial_std": 13.037618586976956,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 17.062523909126785,
      "attention_bam_384_peak_intensity_mean": 0.3054323196411133,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17739875614643097,
      "attention_bam_16_std_attention": 0.5204607844352722,
      "attention_bam_16_max_attention": 2.447056770324707,
      "attention_bam_16_min_attention": -0.9808704853057861,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5730062462665919,
      "attention_bam_16_attention_skewness": 0.6954944556768283,
      "attention_bam_16_attention_sparsity": 0.4814453125,
      "attention_bam_16_attention_concentration_10": 0.6850014392982805,
      "attention_bam_16_attention_concentration_20": 1.0846868159516692,
      "attention_bam_16_attention_center_y": 0.4648076401141891,
      "attention_bam_16_attention_center_x": 0.4830476073805666,
      "attention_bam_16_attention_center_distance": 0.05524284224867235,
      "attention_bam_16_attention_spatial_variance": 42.21250036257146,
      "attention_bam_16_attention_spatial_std": 6.497114772156289,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 10.366417523513709,
      "attention_bam_16_peak_intensity_mean": 0.34590572118759155,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 344,
      "phase": "train",
      "loss": 0.006005327217280865,
      "timestamp": 1759543937.5092933,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006005327217280865,
      "ssim": 0.8790727853775024,
      "attention_bam_384_mean_attention": 0.08516023308038712,
      "attention_bam_384_std_attention": 0.40359893441200256,
      "attention_bam_384_max_attention": 3.083557605743408,
      "attention_bam_384_min_attention": -1.2053861618041992,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.025167477536164,
      "attention_bam_384_attention_skewness": 0.9145291256097384,
      "attention_bam_384_attention_sparsity": 0.5613454182942709,
      "attention_bam_384_attention_concentration_10": 1.060910281819127,
      "attention_bam_384_attention_concentration_20": 1.6133028716205489,
      "attention_bam_384_attention_center_y": 0.4898538261450549,
      "attention_bam_384_attention_center_x": 0.4823340638122888,
      "attention_bam_384_attention_center_distance": 0.028810766920825088,
      "attention_bam_384_attention_spatial_variance": 172.81098371716243,
      "attention_bam_384_attention_spatial_std": 13.145759153322505,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 20.963890168774434,
      "attention_bam_384_peak_intensity_mean": 0.3037262558937073,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17257016897201538,
      "attention_bam_16_std_attention": 0.6136147379875183,
      "attention_bam_16_max_attention": 4.040210723876953,
      "attention_bam_16_min_attention": -1.2149899005889893,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.1849937839818674,
      "attention_bam_16_attention_skewness": 1.1129865309524987,
      "attention_bam_16_attention_sparsity": 0.51513671875,
      "attention_bam_16_attention_concentration_10": 0.839467409849873,
      "attention_bam_16_attention_concentration_20": 1.2925370443167914,
      "attention_bam_16_attention_center_y": 0.480875601428125,
      "attention_bam_16_attention_center_x": 0.466649309163932,
      "attention_bam_16_attention_center_distance": 0.05436931487482483,
      "attention_bam_16_attention_spatial_variance": 43.809553294531725,
      "attention_bam_16_attention_spatial_std": 6.61887855263501,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 10.583431822380557,
      "attention_bam_16_peak_intensity_mean": 0.2722387909889221,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 345,
      "phase": "train",
      "loss": 0.005240630358457565,
      "timestamp": 1759543937.6454282,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005240630358457565,
      "ssim": 0.8917165994644165,
      "attention_bam_384_mean_attention": 0.08441802114248276,
      "attention_bam_384_std_attention": 0.36152443289756775,
      "attention_bam_384_max_attention": 2.8993804454803467,
      "attention_bam_384_min_attention": -1.0239542722702026,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6004527759372329,
      "attention_bam_384_attention_skewness": 0.5805092927031584,
      "attention_bam_384_attention_sparsity": 0.5520579020182291,
      "attention_bam_384_attention_concentration_10": 0.9394996067212716,
      "attention_bam_384_attention_concentration_20": 1.4767823327361849,
      "attention_bam_384_attention_center_y": 0.48396697728625987,
      "attention_bam_384_attention_center_x": 0.47925899067661715,
      "attention_bam_384_attention_center_distance": 0.03707417659482031,
      "attention_bam_384_attention_spatial_variance": 170.61760371882238,
      "attention_bam_384_attention_spatial_std": 13.062067360062969,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 17.36882674379051,
      "attention_bam_384_peak_intensity_mean": 0.28403016924858093,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16992057859897614,
      "attention_bam_16_std_attention": 0.5478400588035583,
      "attention_bam_16_max_attention": 2.5288479328155518,
      "attention_bam_16_min_attention": -1.0143399238586426,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6106899550167606,
      "attention_bam_16_attention_skewness": 0.7241465679506599,
      "attention_bam_16_attention_sparsity": 0.507080078125,
      "attention_bam_16_attention_concentration_10": 0.7483630219786458,
      "attention_bam_16_attention_concentration_20": 1.1827971274852798,
      "attention_bam_16_attention_center_y": 0.47078365631740055,
      "attention_bam_16_attention_center_x": 0.45673520943724283,
      "attention_bam_16_attention_center_distance": 0.07383003238004181,
      "attention_bam_16_attention_spatial_variance": 42.53509958042363,
      "attention_bam_16_attention_spatial_std": 6.5218938645476,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.945185072076224,
      "attention_bam_16_peak_intensity_mean": 0.34218931198120117,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 346,
      "phase": "train",
      "loss": 0.007031592540442944,
      "timestamp": 1759543937.78143,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007031592540442944,
      "ssim": 0.8774844408035278,
      "attention_bam_384_mean_attention": 0.0849953219294548,
      "attention_bam_384_std_attention": 0.34248262643814087,
      "attention_bam_384_max_attention": 2.649137258529663,
      "attention_bam_384_min_attention": -1.1319864988327026,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.529450573764242,
      "attention_bam_384_attention_skewness": 0.7042485272546765,
      "attention_bam_384_attention_sparsity": 0.5493952433268229,
      "attention_bam_384_attention_concentration_10": 0.8926868553648379,
      "attention_bam_384_attention_concentration_20": 1.3825729095525048,
      "attention_bam_384_attention_center_y": 0.47683385304506465,
      "attention_bam_384_attention_center_x": 0.4797456925977699,
      "attention_bam_384_attention_center_distance": 0.043517980952284395,
      "attention_bam_384_attention_spatial_variance": 171.88203351448652,
      "attention_bam_384_attention_spatial_std": 13.110378847099977,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 18.621272059779802,
      "attention_bam_384_peak_intensity_mean": 0.3228822648525238,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1591290533542633,
      "attention_bam_16_std_attention": 0.5410990118980408,
      "attention_bam_16_max_attention": 2.9654645919799805,
      "attention_bam_16_min_attention": -1.1015139818191528,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.6356680153149163,
      "attention_bam_16_attention_skewness": 0.8941771485188975,
      "attention_bam_16_attention_sparsity": 0.49560546875,
      "attention_bam_16_attention_concentration_10": 0.7846517969309252,
      "attention_bam_16_attention_concentration_20": 1.2134422139776766,
      "attention_bam_16_attention_center_y": 0.44995382412256396,
      "attention_bam_16_attention_center_x": 0.45931073063819816,
      "attention_bam_16_attention_center_distance": 0.09121662525167795,
      "attention_bam_16_attention_spatial_variance": 43.28894166961276,
      "attention_bam_16_attention_spatial_std": 6.579433233160191,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 10.595741851108844,
      "attention_bam_16_peak_intensity_mean": 0.31735068559646606,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 347,
      "phase": "train",
      "loss": 0.004526897333562374,
      "timestamp": 1759543937.9221659,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004526897333562374,
      "ssim": 0.9045881032943726,
      "attention_bam_384_mean_attention": 0.08330711722373962,
      "attention_bam_384_std_attention": 0.4026254415512085,
      "attention_bam_384_max_attention": 3.25006103515625,
      "attention_bam_384_min_attention": -1.1877224445343018,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.042310871804596,
      "attention_bam_384_attention_skewness": 0.9307526620890939,
      "attention_bam_384_attention_sparsity": 0.5603205362955729,
      "attention_bam_384_attention_concentration_10": 1.0813407490532378,
      "attention_bam_384_attention_concentration_20": 1.6395035564757994,
      "attention_bam_384_attention_center_y": 0.48060894471486626,
      "attention_bam_384_attention_center_x": 0.491368527159883,
      "attention_bam_384_attention_center_distance": 0.03001717336661767,
      "attention_bam_384_attention_spatial_variance": 174.13609350019087,
      "attention_bam_384_attention_spatial_std": 13.19606356078171,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 20.239734458409703,
      "attention_bam_384_peak_intensity_mean": 0.29261770844459534,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16570696234703064,
      "attention_bam_16_std_attention": 0.6013049483299255,
      "attention_bam_16_max_attention": 3.430363178253174,
      "attention_bam_16_min_attention": -1.118168592453003,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.798906646877267,
      "attention_bam_16_attention_skewness": 1.0331478835374839,
      "attention_bam_16_attention_sparsity": 0.51904296875,
      "attention_bam_16_attention_concentration_10": 0.8469132331914178,
      "attention_bam_16_attention_concentration_20": 1.3120161260106007,
      "attention_bam_16_attention_center_y": 0.4607306282828456,
      "attention_bam_16_attention_center_x": 0.4840767147107623,
      "attention_bam_16_attention_center_distance": 0.059927198657412625,
      "attention_bam_16_attention_spatial_variance": 44.71435314869333,
      "attention_bam_16_attention_spatial_std": 6.686879178562547,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 10.443828962468666,
      "attention_bam_16_peak_intensity_mean": 0.2915099263191223,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 348,
      "phase": "train",
      "loss": 0.006842408329248428,
      "timestamp": 1759543938.0692418,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006842408329248428,
      "ssim": 0.84814453125,
      "attention_bam_384_mean_attention": 0.08566652983427048,
      "attention_bam_384_std_attention": 0.3167125880718231,
      "attention_bam_384_max_attention": 2.5335702896118164,
      "attention_bam_384_min_attention": -1.0330312252044678,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8057404313778269,
      "attention_bam_384_attention_skewness": 0.5173824865305285,
      "attention_bam_384_attention_sparsity": 0.5454661051432291,
      "attention_bam_384_attention_concentration_10": 0.8075408695448103,
      "attention_bam_384_attention_concentration_20": 1.2842131507306176,
      "attention_bam_384_attention_center_y": 0.48721942336080887,
      "attention_bam_384_attention_center_x": 0.4828925020938332,
      "attention_bam_384_attention_center_distance": 0.030199656416579936,
      "attention_bam_384_attention_spatial_variance": 168.9147467942724,
      "attention_bam_384_attention_spatial_std": 12.996720616919962,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 17.567148171002604,
      "attention_bam_384_peak_intensity_mean": 0.3181271255016327,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1901615709066391,
      "attention_bam_16_std_attention": 0.5095040202140808,
      "attention_bam_16_max_attention": 2.463226556777954,
      "attention_bam_16_min_attention": -1.0645229816436768,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5046154486057595,
      "attention_bam_16_attention_skewness": 0.5667019761719972,
      "attention_bam_16_attention_sparsity": 0.46435546875,
      "attention_bam_16_attention_concentration_10": 0.6188013393615526,
      "attention_bam_16_attention_concentration_20": 0.9951280124891762,
      "attention_bam_16_attention_center_y": 0.47693616486458756,
      "attention_bam_16_attention_center_x": 0.465688351316551,
      "attention_bam_16_attention_center_distance": 0.05846759318682294,
      "attention_bam_16_attention_spatial_variance": 41.64030845028208,
      "attention_bam_16_attention_spatial_std": 6.452930222021782,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 6.392443131469063,
      "attention_bam_16_peak_intensity_mean": 0.3724822700023651,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 349,
      "phase": "train",
      "loss": 0.007333978544920683,
      "timestamp": 1759543938.2210772,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007333978544920683,
      "ssim": 0.8711585402488708,
      "attention_bam_384_mean_attention": 0.08568909764289856,
      "attention_bam_384_std_attention": 0.38222557306289673,
      "attention_bam_384_max_attention": 2.6589670181274414,
      "attention_bam_384_min_attention": -1.1903412342071533,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8392148280680356,
      "attention_bam_384_attention_skewness": 0.6160634694526652,
      "attention_bam_384_attention_sparsity": 0.547149658203125,
      "attention_bam_384_attention_concentration_10": 0.9685292183966816,
      "attention_bam_384_attention_concentration_20": 1.521784490084871,
      "attention_bam_384_attention_center_y": 0.4802575089219946,
      "attention_bam_384_attention_center_x": 0.4843660609085143,
      "attention_bam_384_attention_center_distance": 0.0356142108007859,
      "attention_bam_384_attention_spatial_variance": 174.48496543685133,
      "attention_bam_384_attention_spatial_std": 13.209275734757426,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 20.004462944177323,
      "attention_bam_384_peak_intensity_mean": 0.34322312474250793,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17290884256362915,
      "attention_bam_16_std_attention": 0.5803070068359375,
      "attention_bam_16_max_attention": 3.179619312286377,
      "attention_bam_16_min_attention": -1.105214238166809,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7896864323614721,
      "attention_bam_16_attention_skewness": 0.7494762765542421,
      "attention_bam_16_attention_sparsity": 0.496337890625,
      "attention_bam_16_attention_concentration_10": 0.763435351216362,
      "attention_bam_16_attention_concentration_20": 1.216758062658604,
      "attention_bam_16_attention_center_y": 0.4608549017867888,
      "attention_bam_16_attention_center_x": 0.4697723509773897,
      "attention_bam_16_attention_center_distance": 0.06994354122513481,
      "attention_bam_16_attention_spatial_variance": 44.652413227176936,
      "attention_bam_16_attention_spatial_std": 6.682246121415832,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.678746904322328,
      "attention_bam_16_peak_intensity_mean": 0.3130894601345062,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 350,
      "phase": "train",
      "loss": 0.0077193863689899445,
      "timestamp": 1759543938.4146345,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0077193863689899445,
      "ssim": 0.8585973978042603,
      "attention_bam_384_mean_attention": 0.08660665899515152,
      "attention_bam_384_std_attention": 0.3515610694885254,
      "attention_bam_384_max_attention": 2.5225625038146973,
      "attention_bam_384_min_attention": -1.0158122777938843,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8612015514586866,
      "attention_bam_384_attention_skewness": 0.5942890726306707,
      "attention_bam_384_attention_sparsity": 0.5477040608723959,
      "attention_bam_384_attention_concentration_10": 0.894834225575183,
      "attention_bam_384_attention_concentration_20": 1.3987892103240267,
      "attention_bam_384_attention_center_y": 0.47924849602472064,
      "attention_bam_384_attention_center_x": 0.48781120953243184,
      "attention_bam_384_attention_center_distance": 0.03403502696629798,
      "attention_bam_384_attention_spatial_variance": 171.77954475096215,
      "attention_bam_384_attention_spatial_std": 13.106469576165892,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 19.06384148351804,
      "attention_bam_384_peak_intensity_mean": 0.31545135378837585,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18590380251407623,
      "attention_bam_16_std_attention": 0.5493387579917908,
      "attention_bam_16_max_attention": 2.5898263454437256,
      "attention_bam_16_min_attention": -1.0939853191375732,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.3309417295661512,
      "attention_bam_16_attention_skewness": 0.6253657093697096,
      "attention_bam_16_attention_sparsity": 0.474853515625,
      "attention_bam_16_attention_concentration_10": 0.6831426266761619,
      "attention_bam_16_attention_concentration_20": 1.0931189704591044,
      "attention_bam_16_attention_center_y": 0.45856832076068266,
      "attention_bam_16_attention_center_x": 0.4776865776948324,
      "attention_bam_16_attention_center_distance": 0.06655032471082963,
      "attention_bam_16_attention_spatial_variance": 43.308539940733866,
      "attention_bam_16_attention_spatial_std": 6.580922423242343,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.786422071680613,
      "attention_bam_16_peak_intensity_mean": 0.3552616536617279,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 351,
      "phase": "train",
      "loss": 0.005702599883079529,
      "timestamp": 1759543938.5665052,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005702599883079529,
      "ssim": 0.8950941562652588,
      "attention_bam_384_mean_attention": 0.08498245477676392,
      "attention_bam_384_std_attention": 0.33109596371650696,
      "attention_bam_384_max_attention": 2.2839913368225098,
      "attention_bam_384_min_attention": -1.0147656202316284,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.776065170828411,
      "attention_bam_384_attention_skewness": 0.5994910560402882,
      "attention_bam_384_attention_sparsity": 0.5518595377604166,
      "attention_bam_384_attention_concentration_10": 0.8617865166093753,
      "attention_bam_384_attention_concentration_20": 1.359125730278014,
      "attention_bam_384_attention_center_y": 0.48377368592658676,
      "attention_bam_384_attention_center_x": 0.47843616727929894,
      "attention_bam_384_attention_center_distance": 0.038165223699473484,
      "attention_bam_384_attention_spatial_variance": 171.57760288543156,
      "attention_bam_384_attention_spatial_std": 13.098763410544965,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 17.771195818612288,
      "attention_bam_384_peak_intensity_mean": 0.3378768861293793,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18202239274978638,
      "attention_bam_16_std_attention": 0.5200337767601013,
      "attention_bam_16_max_attention": 2.4969496726989746,
      "attention_bam_16_min_attention": -0.9683560132980347,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.4818231594210687,
      "attention_bam_16_attention_skewness": 0.6412777914110803,
      "attention_bam_16_attention_sparsity": 0.476806640625,
      "attention_bam_16_attention_concentration_10": 0.6653661272365763,
      "attention_bam_16_attention_concentration_20": 1.0628411086398308,
      "attention_bam_16_attention_center_y": 0.46876299618907824,
      "attention_bam_16_attention_center_x": 0.4563072652017148,
      "attention_bam_16_attention_center_distance": 0.07595795522836071,
      "attention_bam_16_attention_spatial_variance": 43.03382944166034,
      "attention_bam_16_attention_spatial_std": 6.560017487908119,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.557106279686845,
      "attention_bam_16_peak_intensity_mean": 0.34192293882369995,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 352,
      "phase": "train",
      "loss": 0.006950882729142904,
      "timestamp": 1759543938.713397,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006950882729142904,
      "ssim": 0.8868863582611084,
      "attention_bam_384_mean_attention": 0.08407794684171677,
      "attention_bam_384_std_attention": 0.3613116443157196,
      "attention_bam_384_max_attention": 2.956057548522949,
      "attention_bam_384_min_attention": -1.065475583076477,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0476988368573865,
      "attention_bam_384_attention_skewness": 0.6761427905627443,
      "attention_bam_384_attention_sparsity": 0.5537516276041666,
      "attention_bam_384_attention_concentration_10": 0.9480340608320129,
      "attention_bam_384_attention_concentration_20": 1.4772742874361802,
      "attention_bam_384_attention_center_y": 0.48614823077073294,
      "attention_bam_384_attention_center_x": 0.4822761554920108,
      "attention_bam_384_attention_center_distance": 0.03181214154766222,
      "attention_bam_384_attention_spatial_variance": 170.25358475913544,
      "attention_bam_384_attention_spatial_std": 13.04812571824534,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 17.77558122229063,
      "attention_bam_384_peak_intensity_mean": 0.2902357578277588,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17330940067768097,
      "attention_bam_16_std_attention": 0.5674704909324646,
      "attention_bam_16_max_attention": 3.452763557434082,
      "attention_bam_16_min_attention": -1.0769882202148438,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7571443347051825,
      "attention_bam_16_attention_skewness": 0.7302944381887462,
      "attention_bam_16_attention_sparsity": 0.498046875,
      "attention_bam_16_attention_concentration_10": 0.7518591693854422,
      "attention_bam_16_attention_concentration_20": 1.1968343499309546,
      "attention_bam_16_attention_center_y": 0.47315536076606457,
      "attention_bam_16_attention_center_x": 0.4664450300313417,
      "attention_bam_16_attention_center_distance": 0.060771221235017256,
      "attention_bam_16_attention_spatial_variance": 42.315908606021246,
      "attention_bam_16_attention_spatial_std": 6.5050679170951975,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.407985690297492,
      "attention_bam_16_peak_intensity_mean": 0.282260924577713,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 353,
      "phase": "train",
      "loss": 0.005286471452564001,
      "timestamp": 1759543938.855519,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005286471452564001,
      "ssim": 0.9123960733413696,
      "attention_bam_384_mean_attention": 0.08567920327186584,
      "attention_bam_384_std_attention": 0.3752945363521576,
      "attention_bam_384_max_attention": 3.576300621032715,
      "attention_bam_384_min_attention": -1.2655446529388428,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.039383961969201,
      "attention_bam_384_attention_skewness": 0.9171405529419397,
      "attention_bam_384_attention_sparsity": 0.5485967000325521,
      "attention_bam_384_attention_concentration_10": 0.9574598733340302,
      "attention_bam_384_attention_concentration_20": 1.471682023051591,
      "attention_bam_384_attention_center_y": 0.48882576807309175,
      "attention_bam_384_attention_center_x": 0.48108279374541624,
      "attention_bam_384_attention_center_distance": 0.031071663992609043,
      "attention_bam_384_attention_spatial_variance": 171.58638932504124,
      "attention_bam_384_attention_spatial_std": 13.099098798201394,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 19.351585289477697,
      "attention_bam_384_peak_intensity_mean": 0.28094321489334106,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17739005386829376,
      "attention_bam_16_std_attention": 0.5715633630752563,
      "attention_bam_16_max_attention": 3.826792001724243,
      "attention_bam_16_min_attention": -1.1187251806259155,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.3834247692889274,
      "attention_bam_16_attention_skewness": 1.1388253686520817,
      "attention_bam_16_attention_sparsity": 0.490234375,
      "attention_bam_16_attention_concentration_10": 0.7427801967986162,
      "attention_bam_16_attention_concentration_20": 1.1521155332996404,
      "attention_bam_16_attention_center_y": 0.4804287070370028,
      "attention_bam_16_attention_center_x": 0.46089167401850434,
      "attention_bam_16_attention_center_distance": 0.06184653053031176,
      "attention_bam_16_attention_spatial_variance": 43.18998676627469,
      "attention_bam_16_attention_spatial_std": 6.571908913418893,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 9.429397976416034,
      "attention_bam_16_peak_intensity_mean": 0.2617272734642029,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 354,
      "phase": "train",
      "loss": 0.008351600728929043,
      "timestamp": 1759543938.9934757,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008351600728929043,
      "ssim": 0.9020216464996338,
      "attention_bam_384_mean_attention": 0.08545640856027603,
      "attention_bam_384_std_attention": 0.31360486149787903,
      "attention_bam_384_max_attention": 3.2466049194335938,
      "attention_bam_384_min_attention": -0.9763290882110596,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5149057835152568,
      "attention_bam_384_attention_skewness": 0.614854359364817,
      "attention_bam_384_attention_sparsity": 0.5475031534830729,
      "attention_bam_384_attention_concentration_10": 0.8077638089425524,
      "attention_bam_384_attention_concentration_20": 1.2731510694083066,
      "attention_bam_384_attention_center_y": 0.47810642344385934,
      "attention_bam_384_attention_center_x": 0.49013722253945946,
      "attention_bam_384_attention_center_distance": 0.03395888907652129,
      "attention_bam_384_attention_spatial_variance": 172.12065350591692,
      "attention_bam_384_attention_spatial_std": 13.119476114003826,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 16.43199226539832,
      "attention_bam_384_peak_intensity_mean": 0.25550249218940735,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20263531804084778,
      "attention_bam_16_std_attention": 0.4995884895324707,
      "attention_bam_16_max_attention": 2.4317853450775146,
      "attention_bam_16_min_attention": -1.0735976696014404,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.4747000591960586,
      "attention_bam_16_attention_skewness": 0.5431659863775131,
      "attention_bam_16_attention_sparsity": 0.449951171875,
      "attention_bam_16_attention_concentration_10": 0.5750435007114532,
      "attention_bam_16_attention_concentration_20": 0.93088081103543,
      "attention_bam_16_attention_center_y": 0.45456669536797883,
      "attention_bam_16_attention_center_x": 0.4852232969663978,
      "attention_bam_16_attention_center_distance": 0.06756531835682125,
      "attention_bam_16_attention_spatial_variance": 43.661745560239964,
      "attention_bam_16_attention_spatial_std": 6.607703501235506,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.874124911736208,
      "attention_bam_16_peak_intensity_mean": 0.3747045695781708,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 355,
      "phase": "train",
      "loss": 0.006188246887177229,
      "timestamp": 1759543939.1317217,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006188246887177229,
      "ssim": 0.8771512508392334,
      "attention_bam_384_mean_attention": 0.08640573173761368,
      "attention_bam_384_std_attention": 0.3758440613746643,
      "attention_bam_384_max_attention": 3.6593017578125,
      "attention_bam_384_min_attention": -1.107723355293274,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.002746118117921,
      "attention_bam_384_attention_skewness": 0.6667624227423831,
      "attention_bam_384_attention_sparsity": 0.5510381062825521,
      "attention_bam_384_attention_concentration_10": 0.9567873159061353,
      "attention_bam_384_attention_concentration_20": 1.4943631130594464,
      "attention_bam_384_attention_center_y": 0.4861143720168669,
      "attention_bam_384_attention_center_x": 0.4837489047138885,
      "attention_bam_384_attention_center_distance": 0.03022941489623127,
      "attention_bam_384_attention_spatial_variance": 171.7661784802834,
      "attention_bam_384_attention_spatial_std": 13.105959655068506,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 19.30523831908913,
      "attention_bam_384_peak_intensity_mean": 0.25345540046691895,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18194162845611572,
      "attention_bam_16_std_attention": 0.570575475692749,
      "attention_bam_16_max_attention": 3.2424139976501465,
      "attention_bam_16_min_attention": -1.1225757598876953,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7769491381503224,
      "attention_bam_16_attention_skewness": 0.7720745008453701,
      "attention_bam_16_attention_sparsity": 0.49560546875,
      "attention_bam_16_attention_concentration_10": 0.7324387529492469,
      "attention_bam_16_attention_concentration_20": 1.1631308734987942,
      "attention_bam_16_attention_center_y": 0.4740044492072481,
      "attention_bam_16_attention_center_x": 0.4696812511547105,
      "attention_bam_16_attention_center_distance": 0.05647999986831245,
      "attention_bam_16_attention_spatial_variance": 43.37862029406901,
      "attention_bam_16_attention_spatial_std": 6.586244779392048,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 10.707400784790032,
      "attention_bam_16_peak_intensity_mean": 0.30683672428131104,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 356,
      "phase": "train",
      "loss": 0.005966677330434322,
      "timestamp": 1759543939.2683105,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005966677330434322,
      "ssim": 0.8762794733047485,
      "attention_bam_384_mean_attention": 0.08410823345184326,
      "attention_bam_384_std_attention": 0.3432444930076599,
      "attention_bam_384_max_attention": 2.5183894634246826,
      "attention_bam_384_min_attention": -1.1885676383972168,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8505646254397754,
      "attention_bam_384_attention_skewness": 0.611276777892882,
      "attention_bam_384_attention_sparsity": 0.5561726888020834,
      "attention_bam_384_attention_concentration_10": 0.9060634879687035,
      "attention_bam_384_attention_concentration_20": 1.4171791502901483,
      "attention_bam_384_attention_center_y": 0.4758804948523778,
      "attention_bam_384_attention_center_x": 0.4869228829757148,
      "attention_bam_384_attention_center_distance": 0.03880107004279709,
      "attention_bam_384_attention_spatial_variance": 172.43537795323374,
      "attention_bam_384_attention_spatial_std": 13.131465186841632,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 16.486091353848767,
      "attention_bam_384_peak_intensity_mean": 0.34474900364875793,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18396683037281036,
      "attention_bam_16_std_attention": 0.5596998333930969,
      "attention_bam_16_max_attention": 2.5467936992645264,
      "attention_bam_16_min_attention": -1.1687921285629272,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.47813901716745155,
      "attention_bam_16_attention_skewness": 0.6824648362661876,
      "attention_bam_16_attention_sparsity": 0.492431640625,
      "attention_bam_16_attention_concentration_10": 0.705790509398485,
      "attention_bam_16_attention_concentration_20": 1.1208689915170664,
      "attention_bam_16_attention_center_y": 0.4474229690696108,
      "attention_bam_16_attention_center_x": 0.4770610555584176,
      "attention_bam_16_attention_center_distance": 0.0811238479554453,
      "attention_bam_16_attention_spatial_variance": 43.68948708619945,
      "attention_bam_16_attention_spatial_std": 6.609802348497226,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.917202133072882,
      "attention_bam_16_peak_intensity_mean": 0.37184327840805054,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 357,
      "phase": "train",
      "loss": 0.004834512248635292,
      "timestamp": 1759543939.4329498,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004834512248635292,
      "ssim": 0.9081484079360962,
      "attention_bam_384_mean_attention": 0.08271602541208267,
      "attention_bam_384_std_attention": 0.3572976589202881,
      "attention_bam_384_max_attention": 3.4523236751556396,
      "attention_bam_384_min_attention": -1.1883896589279175,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.0810857257921596,
      "attention_bam_384_attention_skewness": 0.8730629018779154,
      "attention_bam_384_attention_sparsity": 0.5648854573567709,
      "attention_bam_384_attention_concentration_10": 0.9734395184125499,
      "attention_bam_384_attention_concentration_20": 1.4853384412209591,
      "attention_bam_384_attention_center_y": 0.48718335452655737,
      "attention_bam_384_attention_center_x": 0.48098936197389053,
      "attention_bam_384_attention_center_distance": 0.032424396967458836,
      "attention_bam_384_attention_spatial_variance": 172.65976855837383,
      "attention_bam_384_attention_spatial_std": 13.1400064139396,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 18.39404367568687,
      "attention_bam_384_peak_intensity_mean": 0.28139474987983704,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17631679773330688,
      "attention_bam_16_std_attention": 0.571293830871582,
      "attention_bam_16_max_attention": 2.9135069847106934,
      "attention_bam_16_min_attention": -1.1201226711273193,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.124707798483887,
      "attention_bam_16_attention_skewness": 0.8812778903096075,
      "attention_bam_16_attention_sparsity": 0.50390625,
      "attention_bam_16_attention_concentration_10": 0.7655898793209306,
      "attention_bam_16_attention_concentration_20": 1.2009032809690023,
      "attention_bam_16_attention_center_y": 0.4755370885674123,
      "attention_bam_16_attention_center_x": 0.4615074482795644,
      "attention_bam_16_attention_center_distance": 0.06449977633618646,
      "attention_bam_16_attention_spatial_variance": 44.05449461538993,
      "attention_bam_16_attention_spatial_std": 6.637355995830714,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.650004028864368,
      "attention_bam_16_peak_intensity_mean": 0.3304544687271118,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 358,
      "phase": "train",
      "loss": 0.006828116253018379,
      "timestamp": 1759543939.6074011,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006828116253018379,
      "ssim": 0.9141057133674622,
      "attention_bam_384_mean_attention": 0.08567731827497482,
      "attention_bam_384_std_attention": 0.3455471694469452,
      "attention_bam_384_max_attention": 2.418905735015869,
      "attention_bam_384_min_attention": -1.0121911764144897,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6248780675299339,
      "attention_bam_384_attention_skewness": 0.4928387895615956,
      "attention_bam_384_attention_sparsity": 0.5425440470377604,
      "attention_bam_384_attention_concentration_10": 0.8713137978846425,
      "attention_bam_384_attention_concentration_20": 1.3832567246027316,
      "attention_bam_384_attention_center_y": 0.4844856740311744,
      "attention_bam_384_attention_center_x": 0.48224069213694365,
      "attention_bam_384_attention_center_distance": 0.03334928263221841,
      "attention_bam_384_attention_spatial_variance": 170.10657536454673,
      "attention_bam_384_attention_spatial_std": 13.042491148724109,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 16.068999750932125,
      "attention_bam_384_peak_intensity_mean": 0.3241845667362213,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1843881607055664,
      "attention_bam_16_std_attention": 0.5574651956558228,
      "attention_bam_16_max_attention": 2.3705639839172363,
      "attention_bam_16_min_attention": -1.0846490859985352,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.0436646102295466,
      "attention_bam_16_attention_skewness": 0.5096644094933689,
      "attention_bam_16_attention_sparsity": 0.469970703125,
      "attention_bam_16_attention_concentration_10": 0.6771842027762104,
      "attention_bam_16_attention_concentration_20": 1.0994559595396074,
      "attention_bam_16_attention_center_y": 0.4696452759773596,
      "attention_bam_16_attention_center_x": 0.46665786405507054,
      "attention_bam_16_attention_center_distance": 0.06376687697952313,
      "attention_bam_16_attention_spatial_variance": 42.287735898050805,
      "attention_bam_16_attention_spatial_std": 6.502902113522147,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.145965360718636,
      "attention_bam_16_peak_intensity_mean": 0.3810949921607971,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 359,
      "phase": "train",
      "loss": 0.0052306801080703735,
      "timestamp": 1759543939.9917634,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0052306801080703735,
      "ssim": 0.9076330065727234,
      "attention_bam_384_mean_attention": 0.08387303352355957,
      "attention_bam_384_std_attention": 0.3845202326774597,
      "attention_bam_384_max_attention": 3.4945292472839355,
      "attention_bam_384_min_attention": -1.2889069318771362,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.3965649455132318,
      "attention_bam_384_attention_skewness": 0.7632769598221282,
      "attention_bam_384_attention_sparsity": 0.5597050984700521,
      "attention_bam_384_attention_concentration_10": 1.0203994202961373,
      "attention_bam_384_attention_concentration_20": 1.5739284296358484,
      "attention_bam_384_attention_center_y": 0.4785180016556632,
      "attention_bam_384_attention_center_x": 0.48395696303801217,
      "attention_bam_384_attention_center_distance": 0.03791715410812884,
      "attention_bam_384_attention_spatial_variance": 169.40496355952416,
      "attention_bam_384_attention_spatial_std": 13.015566202033785,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 15.320664618006061,
      "attention_bam_384_peak_intensity_mean": 0.2880384027957916,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1711275279521942,
      "attention_bam_16_std_attention": 0.5981063842773438,
      "attention_bam_16_max_attention": 3.165821075439453,
      "attention_bam_16_min_attention": -1.0735785961151123,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7296893284092416,
      "attention_bam_16_attention_skewness": 0.7820056170254984,
      "attention_bam_16_attention_sparsity": 0.496826171875,
      "attention_bam_16_attention_concentration_10": 0.8083603574682479,
      "attention_bam_16_attention_concentration_20": 1.2701963589015537,
      "attention_bam_16_attention_center_y": 0.45280810160077806,
      "attention_bam_16_attention_center_x": 0.46991758770440956,
      "attention_bam_16_attention_center_distance": 0.07914577441713963,
      "attention_bam_16_attention_spatial_variance": 41.66946251943288,
      "attention_bam_16_attention_spatial_std": 6.455188805870272,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 7.401485340418871,
      "attention_bam_16_peak_intensity_mean": 0.29500341415405273,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 360,
      "phase": "train",
      "loss": 0.006844577845185995,
      "timestamp": 1759543940.163899,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006844577845185995,
      "ssim": 0.8692513704299927,
      "attention_bam_384_mean_attention": 0.08237548917531967,
      "attention_bam_384_std_attention": 0.378484308719635,
      "attention_bam_384_max_attention": 3.1849892139434814,
      "attention_bam_384_min_attention": -1.2563406229019165,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1730128264943955,
      "attention_bam_384_attention_skewness": 0.7336057478839317,
      "attention_bam_384_attention_sparsity": 0.5591481526692709,
      "attention_bam_384_attention_concentration_10": 1.0120895105070764,
      "attention_bam_384_attention_concentration_20": 1.5703326088156317,
      "attention_bam_384_attention_center_y": 0.4884322344284491,
      "attention_bam_384_attention_center_x": 0.4788990988273849,
      "attention_bam_384_attention_center_distance": 0.0340311983513607,
      "attention_bam_384_attention_spatial_variance": 171.8441508226577,
      "attention_bam_384_attention_spatial_std": 13.108934007868744,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 17.806408082833034,
      "attention_bam_384_peak_intensity_mean": 0.3049580454826355,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16940176486968994,
      "attention_bam_16_std_attention": 0.5804910659790039,
      "attention_bam_16_max_attention": 2.7588441371917725,
      "attention_bam_16_min_attention": -1.0844449996948242,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5454059134515306,
      "attention_bam_16_attention_skewness": 0.7638820895116,
      "attention_bam_16_attention_sparsity": 0.507568359375,
      "attention_bam_16_attention_concentration_10": 0.7980945360517472,
      "attention_bam_16_attention_concentration_20": 1.2581481409626247,
      "attention_bam_16_attention_center_y": 0.48025044657821486,
      "attention_bam_16_attention_center_x": 0.4563724038504998,
      "attention_bam_16_attention_center_distance": 0.06772609550452215,
      "attention_bam_16_attention_spatial_variance": 43.46688339278048,
      "attention_bam_16_attention_spatial_std": 6.592941937616354,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.0878753326377,
      "attention_bam_16_peak_intensity_mean": 0.32726430892944336,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 361,
      "phase": "train",
      "loss": 0.011831550858914852,
      "timestamp": 1759543940.3030024,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.011831550858914852,
      "ssim": 0.8813445568084717,
      "attention_bam_384_mean_attention": 0.08499836176633835,
      "attention_bam_384_std_attention": 0.340641051530838,
      "attention_bam_384_max_attention": 2.851144313812256,
      "attention_bam_384_min_attention": -1.244269609451294,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": -0.04150698504477912,
      "attention_bam_384_attention_skewness": 0.31266852704160103,
      "attention_bam_384_attention_sparsity": 0.5280507405598959,
      "attention_bam_384_attention_concentration_10": 0.8328621943228248,
      "attention_bam_384_attention_concentration_20": 1.357758892220044,
      "attention_bam_384_attention_center_y": 0.4803174418894302,
      "attention_bam_384_attention_center_x": 0.48363666409099587,
      "attention_bam_384_attention_center_distance": 0.036198393772289415,
      "attention_bam_384_attention_spatial_variance": 170.11450266865978,
      "attention_bam_384_attention_spatial_std": 13.042795048173524,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 15.927246244399326,
      "attention_bam_384_peak_intensity_mean": 0.32707855105400085,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17930343747138977,
      "attention_bam_16_std_attention": 0.544884204864502,
      "attention_bam_16_max_attention": 2.210548162460327,
      "attention_bam_16_min_attention": -1.1842095851898193,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.24126087387404693,
      "attention_bam_16_attention_skewness": 0.4038033433724849,
      "attention_bam_16_attention_sparsity": 0.46923828125,
      "attention_bam_16_attention_concentration_10": 0.6620602766502971,
      "attention_bam_16_attention_concentration_20": 1.0987311401554896,
      "attention_bam_16_attention_center_y": 0.45761831303809336,
      "attention_bam_16_attention_center_x": 0.4686955288700585,
      "attention_bam_16_attention_center_distance": 0.07451412352651526,
      "attention_bam_16_attention_spatial_variance": 42.273752703005016,
      "attention_bam_16_attention_spatial_std": 6.501826874271955,
      "attention_bam_16_num_attention_peaks": 11,
      "attention_bam_16_peak_separation_mean": 7.463940926371968,
      "attention_bam_16_peak_intensity_mean": 0.411963552236557,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 362,
      "phase": "train",
      "loss": 0.0058774324133992195,
      "timestamp": 1759543940.4362562,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0058774324133992195,
      "ssim": 0.8662694692611694,
      "attention_bam_384_mean_attention": 0.08237143605947495,
      "attention_bam_384_std_attention": 0.3868829607963562,
      "attention_bam_384_max_attention": 3.027933120727539,
      "attention_bam_384_min_attention": -1.1688138246536255,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8463544834502827,
      "attention_bam_384_attention_skewness": 0.6350059680880822,
      "attention_bam_384_attention_sparsity": 0.5594965616861979,
      "attention_bam_384_attention_concentration_10": 1.0308243205421757,
      "attention_bam_384_attention_concentration_20": 1.6072639645967335,
      "attention_bam_384_attention_center_y": 0.47572694292440537,
      "attention_bam_384_attention_center_x": 0.4892665395332325,
      "attention_bam_384_attention_center_distance": 0.03753367750132498,
      "attention_bam_384_attention_spatial_variance": 171.85145409251118,
      "attention_bam_384_attention_spatial_std": 13.10921256569254,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 19.619555096000365,
      "attention_bam_384_peak_intensity_mean": 0.2984011471271515,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16991060972213745,
      "attention_bam_16_std_attention": 0.6051156520843506,
      "attention_bam_16_max_attention": 2.7262532711029053,
      "attention_bam_16_min_attention": -1.2042111158370972,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.9116713938568473,
      "attention_bam_16_attention_skewness": 0.8617489791522475,
      "attention_bam_16_attention_sparsity": 0.50537109375,
      "attention_bam_16_attention_concentration_10": 0.8348677325956022,
      "attention_bam_16_attention_concentration_20": 1.2968909997508897,
      "attention_bam_16_attention_center_y": 0.44620996444545585,
      "attention_bam_16_attention_center_x": 0.48093488594434847,
      "attention_bam_16_attention_center_distance": 0.08070745317396807,
      "attention_bam_16_attention_spatial_variance": 43.326488120490325,
      "attention_bam_16_attention_spatial_std": 6.582285934270124,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 10.695350578526416,
      "attention_bam_16_peak_intensity_mean": 0.3469561040401459,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 363,
      "phase": "train",
      "loss": 0.007756564766168594,
      "timestamp": 1759543940.5722666,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007756564766168594,
      "ssim": 0.8643455505371094,
      "attention_bam_384_mean_attention": 0.08245506137609482,
      "attention_bam_384_std_attention": 0.3711036741733551,
      "attention_bam_384_max_attention": 2.910922050476074,
      "attention_bam_384_min_attention": -1.061651349067688,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.317424058937961,
      "attention_bam_384_attention_skewness": 0.664933819391797,
      "attention_bam_384_attention_sparsity": 0.5495885213216146,
      "attention_bam_384_attention_concentration_10": 0.9779886589456259,
      "attention_bam_384_attention_concentration_20": 1.521642283614796,
      "attention_bam_384_attention_center_y": 0.4895832748009133,
      "attention_bam_384_attention_center_x": 0.4836416532009675,
      "attention_bam_384_attention_center_distance": 0.027426398738102816,
      "attention_bam_384_attention_spatial_variance": 171.2692992040714,
      "attention_bam_384_attention_spatial_std": 13.086989692212315,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 20.03878248639904,
      "attention_bam_384_peak_intensity_mean": 0.2906757593154907,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1857522577047348,
      "attention_bam_16_std_attention": 0.5831208229064941,
      "attention_bam_16_max_attention": 3.39943265914917,
      "attention_bam_16_min_attention": -1.0071675777435303,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.6611108700454738,
      "attention_bam_16_attention_skewness": 0.9324589826248121,
      "attention_bam_16_attention_sparsity": 0.498779296875,
      "attention_bam_16_attention_concentration_10": 0.7332820028232732,
      "attention_bam_16_attention_concentration_20": 1.1557607670158676,
      "attention_bam_16_attention_center_y": 0.484179922510756,
      "attention_bam_16_attention_center_x": 0.46975218253772366,
      "attention_bam_16_attention_center_distance": 0.04827432677929076,
      "attention_bam_16_attention_spatial_variance": 43.119975263907016,
      "attention_bam_16_attention_spatial_std": 6.566580180269408,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.276064972597934,
      "attention_bam_16_peak_intensity_mean": 0.28000161051750183,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 364,
      "phase": "train",
      "loss": 0.005786431487649679,
      "timestamp": 1759543940.7094607,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005786431487649679,
      "ssim": 0.9056477546691895,
      "attention_bam_384_mean_attention": 0.07878029346466064,
      "attention_bam_384_std_attention": 0.4304857850074768,
      "attention_bam_384_max_attention": 3.3183510303497314,
      "attention_bam_384_min_attention": -1.1731544733047485,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.1117356421491413,
      "attention_bam_384_attention_skewness": 0.9770184931499769,
      "attention_bam_384_attention_sparsity": 0.5675710042317709,
      "attention_bam_384_attention_concentration_10": 1.2225920282296157,
      "attention_bam_384_attention_concentration_20": 1.8384418515144343,
      "attention_bam_384_attention_center_y": 0.4864203190811466,
      "attention_bam_384_attention_center_x": 0.484047937338415,
      "attention_bam_384_attention_center_distance": 0.02962688093664285,
      "attention_bam_384_attention_spatial_variance": 172.16762384934128,
      "attention_bam_384_attention_spatial_std": 13.121266091705529,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 17.80422678243021,
      "attention_bam_384_peak_intensity_mean": 0.2873988151550293,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1592068374156952,
      "attention_bam_16_std_attention": 0.6492524743080139,
      "attention_bam_16_max_attention": 3.7312145233154297,
      "attention_bam_16_min_attention": -1.1601530313491821,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.989624133046128,
      "attention_bam_16_attention_skewness": 1.1739629881018832,
      "attention_bam_16_attention_sparsity": 0.541015625,
      "attention_bam_16_attention_concentration_10": 0.9675825682472392,
      "attention_bam_16_attention_concentration_20": 1.476179850766239,
      "attention_bam_16_attention_center_y": 0.4764534918904192,
      "attention_bam_16_attention_center_x": 0.47117012174133205,
      "attention_bam_16_attention_center_distance": 0.05264218697136679,
      "attention_bam_16_attention_spatial_variance": 43.45825094644728,
      "attention_bam_16_attention_spatial_std": 6.592287231791958,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.686501133903722,
      "attention_bam_16_peak_intensity_mean": 0.28815820813179016,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 365,
      "phase": "train",
      "loss": 0.005899567157030106,
      "timestamp": 1759543940.8508742,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005899567157030106,
      "ssim": 0.9165538549423218,
      "attention_bam_384_mean_attention": 0.0808212012052536,
      "attention_bam_384_std_attention": 0.4326598346233368,
      "attention_bam_384_max_attention": 3.0845611095428467,
      "attention_bam_384_min_attention": -1.3603768348693848,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9801225738147781,
      "attention_bam_384_attention_skewness": 0.7019931085323766,
      "attention_bam_384_attention_sparsity": 0.5561040242513021,
      "attention_bam_384_attention_concentration_10": 1.1610604999905083,
      "attention_bam_384_attention_concentration_20": 1.8011467565560217,
      "attention_bam_384_attention_center_y": 0.4835281735109831,
      "attention_bam_384_attention_center_x": 0.4788380678695047,
      "attention_bam_384_attention_center_distance": 0.03792488469013366,
      "attention_bam_384_attention_spatial_variance": 173.01984699152908,
      "attention_bam_384_attention_spatial_std": 13.153700885740449,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 19.446442218675042,
      "attention_bam_384_peak_intensity_mean": 0.3288656175136566,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17207147181034088,
      "attention_bam_16_std_attention": 0.6634077429771423,
      "attention_bam_16_max_attention": 3.4620535373687744,
      "attention_bam_16_min_attention": -1.2381843328475952,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.9324538555478847,
      "attention_bam_16_attention_skewness": 0.9063809749403416,
      "attention_bam_16_attention_sparsity": 0.530029296875,
      "attention_bam_16_attention_concentration_10": 0.8901324362046331,
      "attention_bam_16_attention_concentration_20": 1.405112837618549,
      "attention_bam_16_attention_center_y": 0.4642431957613419,
      "attention_bam_16_attention_center_x": 0.4569377016173608,
      "attention_bam_16_attention_center_distance": 0.07915694020560887,
      "attention_bam_16_attention_spatial_variance": 43.733346496773294,
      "attention_bam_16_attention_spatial_std": 6.613119271325242,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 10.219229290775942,
      "attention_bam_16_peak_intensity_mean": 0.3049774169921875,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 366,
      "phase": "train",
      "loss": 0.007221630774438381,
      "timestamp": 1759543940.9907699,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007221630774438381,
      "ssim": 0.8809969425201416,
      "attention_bam_384_mean_attention": 0.07847640663385391,
      "attention_bam_384_std_attention": 0.39564013481140137,
      "attention_bam_384_max_attention": 2.7443323135375977,
      "attention_bam_384_min_attention": -1.155454158782959,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.3796873205926179,
      "attention_bam_384_attention_skewness": 0.517387503982789,
      "attention_bam_384_attention_sparsity": 0.5537567138671875,
      "attention_bam_384_attention_concentration_10": 1.074558837341959,
      "attention_bam_384_attention_concentration_20": 1.7012880498910015,
      "attention_bam_384_attention_center_y": 0.48293908366083504,
      "attention_bam_384_attention_center_x": 0.4864220497715957,
      "attention_bam_384_attention_center_distance": 0.030836199465466233,
      "attention_bam_384_attention_spatial_variance": 170.11917397031638,
      "attention_bam_384_attention_spatial_std": 13.042974122887632,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 17.320875801233218,
      "attention_bam_384_peak_intensity_mean": 0.31805598735809326,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16505354642868042,
      "attention_bam_16_std_attention": 0.626713216304779,
      "attention_bam_16_max_attention": 2.6714365482330322,
      "attention_bam_16_min_attention": -1.2878100872039795,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.2180160514818632,
      "attention_bam_16_attention_skewness": 0.6896103040384912,
      "attention_bam_16_attention_sparsity": 0.515380859375,
      "attention_bam_16_attention_concentration_10": 0.8650620282927535,
      "attention_bam_16_attention_concentration_20": 1.3757209370651493,
      "attention_bam_16_attention_center_y": 0.46867149442473893,
      "attention_bam_16_attention_center_x": 0.47357928072584454,
      "attention_bam_16_attention_center_distance": 0.0579573924282812,
      "attention_bam_16_attention_spatial_variance": 42.45679250776124,
      "attention_bam_16_attention_spatial_std": 6.515887699136722,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.084839118722021,
      "attention_bam_16_peak_intensity_mean": 0.37071579694747925,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 367,
      "phase": "train",
      "loss": 0.008600625209510326,
      "timestamp": 1759543941.127609,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008600625209510326,
      "ssim": 0.880416750907898,
      "attention_bam_384_mean_attention": 0.0783391147851944,
      "attention_bam_384_std_attention": 0.35904359817504883,
      "attention_bam_384_max_attention": 2.7824923992156982,
      "attention_bam_384_min_attention": -1.1858654022216797,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7522311362000549,
      "attention_bam_384_attention_skewness": 0.5734738511771162,
      "attention_bam_384_attention_sparsity": 0.5556106567382812,
      "attention_bam_384_attention_concentration_10": 0.9819201385867382,
      "attention_bam_384_attention_concentration_20": 1.5587787453090656,
      "attention_bam_384_attention_center_y": 0.4835795281697305,
      "attention_bam_384_attention_center_x": 0.4810747043087387,
      "attention_bam_384_attention_center_distance": 0.035434410172326763,
      "attention_bam_384_attention_spatial_variance": 171.10604886560276,
      "attention_bam_384_attention_spatial_std": 13.08075108186081,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 18.356359233932796,
      "attention_bam_384_peak_intensity_mean": 0.3226074278354645,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16888542473316193,
      "attention_bam_16_std_attention": 0.5772483944892883,
      "attention_bam_16_max_attention": 3.3284785747528076,
      "attention_bam_16_min_attention": -1.0761423110961914,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7842319937423654,
      "attention_bam_16_attention_skewness": 0.7690614916259957,
      "attention_bam_16_attention_sparsity": 0.499755859375,
      "attention_bam_16_attention_concentration_10": 0.7838432237735745,
      "attention_bam_16_attention_concentration_20": 1.2385887091151775,
      "attention_bam_16_attention_center_y": 0.4630023168572216,
      "attention_bam_16_attention_center_x": 0.46073787857526055,
      "attention_bam_16_attention_center_distance": 0.0762934169729527,
      "attention_bam_16_attention_spatial_variance": 42.96106258303218,
      "attention_bam_16_attention_spatial_std": 6.554468901675572,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 9.021508582947925,
      "attention_bam_16_peak_intensity_mean": 0.2884542644023895,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 368,
      "phase": "train",
      "loss": 0.005334790330380201,
      "timestamp": 1759543941.264313,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005334790330380201,
      "ssim": 0.8895823359489441,
      "attention_bam_384_mean_attention": 0.07770901173353195,
      "attention_bam_384_std_attention": 0.3643878698348999,
      "attention_bam_384_max_attention": 2.581942081451416,
      "attention_bam_384_min_attention": -1.023937702178955,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7397968800027246,
      "attention_bam_384_attention_skewness": 0.5677382499186597,
      "attention_bam_384_attention_sparsity": 0.5520273844401041,
      "attention_bam_384_attention_concentration_10": 1.0110576680305725,
      "attention_bam_384_attention_concentration_20": 1.5842767830257602,
      "attention_bam_384_attention_center_y": 0.48436844726932143,
      "attention_bam_384_attention_center_x": 0.48059719206540363,
      "attention_bam_384_attention_center_distance": 0.035236753440656826,
      "attention_bam_384_attention_spatial_variance": 171.30699360595065,
      "attention_bam_384_attention_spatial_std": 13.088429760897625,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 17.12151678203481,
      "attention_bam_384_peak_intensity_mean": 0.3094184696674347,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17766189575195312,
      "attention_bam_16_std_attention": 0.569835901260376,
      "attention_bam_16_max_attention": 3.3356406688690186,
      "attention_bam_16_min_attention": -1.1362870931625366,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.45937169318854343,
      "attention_bam_16_attention_skewness": 0.6616221268015281,
      "attention_bam_16_attention_sparsity": 0.500244140625,
      "attention_bam_16_attention_concentration_10": 0.7293620364703414,
      "attention_bam_16_attention_concentration_20": 1.181318340277499,
      "attention_bam_16_attention_center_y": 0.469418575694776,
      "attention_bam_16_attention_center_x": 0.4621221673850373,
      "attention_bam_16_attention_center_distance": 0.06884698564415548,
      "attention_bam_16_attention_spatial_variance": 42.97904707116905,
      "attention_bam_16_attention_spatial_std": 6.555840683784884,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.544358827603444,
      "attention_bam_16_peak_intensity_mean": 0.29718446731567383,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 369,
      "phase": "train",
      "loss": 0.010672328993678093,
      "timestamp": 1759543941.4217095,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.010672328993678093,
      "ssim": 0.8658046126365662,
      "attention_bam_384_mean_attention": 0.08053294569253922,
      "attention_bam_384_std_attention": 0.3631778955459595,
      "attention_bam_384_max_attention": 2.4150843620300293,
      "attention_bam_384_min_attention": -1.0934576988220215,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9410407929179501,
      "attention_bam_384_attention_skewness": 0.6234060383096421,
      "attention_bam_384_attention_sparsity": 0.5572331746419271,
      "attention_bam_384_attention_concentration_10": 0.9919385314251605,
      "attention_bam_384_attention_concentration_20": 1.5367580306757018,
      "attention_bam_384_attention_center_y": 0.4877903321901924,
      "attention_bam_384_attention_center_x": 0.48824627061709913,
      "attention_bam_384_attention_center_distance": 0.02396773424553597,
      "attention_bam_384_attention_spatial_variance": 170.25264582956893,
      "attention_bam_384_attention_spatial_std": 13.048089738715355,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 18.24005403407166,
      "attention_bam_384_peak_intensity_mean": 0.3366090953350067,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19504840672016144,
      "attention_bam_16_std_attention": 0.5684558749198914,
      "attention_bam_16_max_attention": 2.9852521419525146,
      "attention_bam_16_min_attention": -1.153244137763977,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6409185101982016,
      "attention_bam_16_attention_skewness": 0.7362842871336104,
      "attention_bam_16_attention_sparsity": 0.487548828125,
      "attention_bam_16_attention_concentration_10": 0.6870347073368506,
      "attention_bam_16_attention_concentration_20": 1.0937273505901575,
      "attention_bam_16_attention_center_y": 0.47618477590090336,
      "attention_bam_16_attention_center_x": 0.4806858543645964,
      "attention_bam_16_attention_center_distance": 0.04336360502808258,
      "attention_bam_16_attention_spatial_variance": 42.44563759117919,
      "attention_bam_16_attention_spatial_std": 6.515031664633656,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.268242612926569,
      "attention_bam_16_peak_intensity_mean": 0.32414722442626953,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 370,
      "phase": "train",
      "loss": 0.00636272132396698,
      "timestamp": 1759543941.6546993,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00636272132396698,
      "ssim": 0.8561660051345825,
      "attention_bam_384_mean_attention": 0.07753352075815201,
      "attention_bam_384_std_attention": 0.36422812938690186,
      "attention_bam_384_max_attention": 3.040663719177246,
      "attention_bam_384_min_attention": -1.1377779245376587,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.013264317637315,
      "attention_bam_384_attention_skewness": 0.9287858256182123,
      "attention_bam_384_attention_sparsity": 0.5730361938476562,
      "attention_bam_384_attention_concentration_10": 1.0538708364531377,
      "attention_bam_384_attention_concentration_20": 1.6071309894143564,
      "attention_bam_384_attention_center_y": 0.48381469807803373,
      "attention_bam_384_attention_center_x": 0.4791500009574077,
      "attention_bam_384_attention_center_distance": 0.03732791069377727,
      "attention_bam_384_attention_spatial_variance": 171.91118394264808,
      "attention_bam_384_attention_spatial_std": 13.111490530929277,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 20.11811633836815,
      "attention_bam_384_peak_intensity_mean": 0.2979460656642914,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1771538257598877,
      "attention_bam_16_std_attention": 0.5675135850906372,
      "attention_bam_16_max_attention": 3.3752622604370117,
      "attention_bam_16_min_attention": -0.9802488088607788,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.8746286357949398,
      "attention_bam_16_attention_skewness": 1.0620311989134446,
      "attention_bam_16_attention_sparsity": 0.511474609375,
      "attention_bam_16_attention_concentration_10": 0.762432254372518,
      "attention_bam_16_attention_concentration_20": 1.1826170836551746,
      "attention_bam_16_attention_center_y": 0.46794084487624094,
      "attention_bam_16_attention_center_x": 0.4555188353998528,
      "attention_bam_16_attention_center_distance": 0.07754177495304886,
      "attention_bam_16_attention_spatial_variance": 43.357528290707315,
      "attention_bam_16_attention_spatial_std": 6.584643368528573,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.662938537722036,
      "attention_bam_16_peak_intensity_mean": 0.2763056755065918,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 371,
      "phase": "train",
      "loss": 0.009895386174321175,
      "timestamp": 1759543941.8314946,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.009895386174321175,
      "ssim": 0.8280746936798096,
      "attention_bam_384_mean_attention": 0.07897496968507767,
      "attention_bam_384_std_attention": 0.3756662607192993,
      "attention_bam_384_max_attention": 2.475174903869629,
      "attention_bam_384_min_attention": -1.0138428211212158,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6287806746618632,
      "attention_bam_384_attention_skewness": 0.6301709514749574,
      "attention_bam_384_attention_sparsity": 0.5581614176432291,
      "attention_bam_384_attention_concentration_10": 1.0261035353859225,
      "attention_bam_384_attention_concentration_20": 1.6155075780374404,
      "attention_bam_384_attention_center_y": 0.4823854474797098,
      "attention_bam_384_attention_center_x": 0.49094527521595227,
      "attention_bam_384_attention_center_distance": 0.028009302076449895,
      "attention_bam_384_attention_spatial_variance": 169.6065331153595,
      "attention_bam_384_attention_spatial_std": 13.023307303268226,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 14.519354142154027,
      "attention_bam_384_peak_intensity_mean": 0.3160082697868347,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17592331767082214,
      "attention_bam_16_std_attention": 0.5791336297988892,
      "attention_bam_16_max_attention": 2.687924385070801,
      "attention_bam_16_min_attention": -1.158364176750183,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6836266678989271,
      "attention_bam_16_attention_skewness": 0.8028028788078037,
      "attention_bam_16_attention_sparsity": 0.504150390625,
      "attention_bam_16_attention_concentration_10": 0.7665918403852817,
      "attention_bam_16_attention_concentration_20": 1.2144756900848177,
      "attention_bam_16_attention_center_y": 0.46647214737422504,
      "attention_bam_16_attention_center_x": 0.48264468954060913,
      "attention_bam_16_attention_center_distance": 0.05339145442554504,
      "attention_bam_16_attention_spatial_variance": 42.05565726672209,
      "attention_bam_16_attention_spatial_std": 6.485033328111899,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.170119871725834,
      "attention_bam_16_peak_intensity_mean": 0.35036346316337585,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 372,
      "phase": "train",
      "loss": 0.004438498523086309,
      "timestamp": 1759543942.0029626,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004438498523086309,
      "ssim": 0.9088386297225952,
      "attention_bam_384_mean_attention": 0.07553009688854218,
      "attention_bam_384_std_attention": 0.35631367564201355,
      "attention_bam_384_max_attention": 2.7624993324279785,
      "attention_bam_384_min_attention": -1.0882874727249146,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.85479552321938,
      "attention_bam_384_attention_skewness": 0.8730691583328739,
      "attention_bam_384_attention_sparsity": 0.5721206665039062,
      "attention_bam_384_attention_concentration_10": 1.0514321872425347,
      "attention_bam_384_attention_concentration_20": 1.6083472963717251,
      "attention_bam_384_attention_center_y": 0.48675262345968,
      "attention_bam_384_attention_center_x": 0.48203977287717975,
      "attention_bam_384_attention_center_distance": 0.031561455717514314,
      "attention_bam_384_attention_spatial_variance": 171.5602748452967,
      "attention_bam_384_attention_spatial_std": 13.0981019558292,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 16.996490597649423,
      "attention_bam_384_peak_intensity_mean": 0.3080998659133911,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16964609920978546,
      "attention_bam_16_std_attention": 0.5705799460411072,
      "attention_bam_16_max_attention": 3.5466721057891846,
      "attention_bam_16_min_attention": -0.9974924921989441,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.839432276289199,
      "attention_bam_16_attention_skewness": 1.0459915241095736,
      "attention_bam_16_attention_sparsity": 0.507080078125,
      "attention_bam_16_attention_concentration_10": 0.8037336238154504,
      "attention_bam_16_attention_concentration_20": 1.2319988911311983,
      "attention_bam_16_attention_center_y": 0.4750254093419509,
      "attention_bam_16_attention_center_x": 0.4661082591858709,
      "attention_bam_16_attention_center_distance": 0.05953789169846739,
      "attention_bam_16_attention_spatial_variance": 43.32950277108529,
      "attention_bam_16_attention_spatial_std": 6.5825149275246835,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.348471668280876,
      "attention_bam_16_peak_intensity_mean": 0.2701873183250427,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 373,
      "phase": "train",
      "loss": 0.009561968967318535,
      "timestamp": 1759543942.165823,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.009561968967318535,
      "ssim": 0.8523014783859253,
      "attention_bam_384_mean_attention": 0.07694701850414276,
      "attention_bam_384_std_attention": 0.37439781427383423,
      "attention_bam_384_max_attention": 3.338263511657715,
      "attention_bam_384_min_attention": -1.2287981510162354,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.3205689686116697,
      "attention_bam_384_attention_skewness": 0.6896906328658123,
      "attention_bam_384_attention_sparsity": 0.5620015462239584,
      "attention_bam_384_attention_concentration_10": 1.0567753980393861,
      "attention_bam_384_attention_concentration_20": 1.639465200260169,
      "attention_bam_384_attention_center_y": 0.48253308940724626,
      "attention_bam_384_attention_center_x": 0.47785437683262727,
      "attention_bam_384_attention_center_distance": 0.039887882649409415,
      "attention_bam_384_attention_spatial_variance": 171.8253518639036,
      "attention_bam_384_attention_spatial_std": 13.108216959750994,
      "attention_bam_384_num_attention_peaks": 21,
      "attention_bam_384_peak_separation_mean": 19.414248772423164,
      "attention_bam_384_peak_intensity_mean": 0.29290154576301575,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17020952701568604,
      "attention_bam_16_std_attention": 0.5910495519638062,
      "attention_bam_16_max_attention": 3.1030688285827637,
      "attention_bam_16_min_attention": -1.0930655002593994,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6007064902051704,
      "attention_bam_16_attention_skewness": 0.7086223060609075,
      "attention_bam_16_attention_sparsity": 0.49951171875,
      "attention_bam_16_attention_concentration_10": 0.7872222778512696,
      "attention_bam_16_attention_concentration_20": 1.2524712481286866,
      "attention_bam_16_attention_center_y": 0.4631871037323126,
      "attention_bam_16_attention_center_x": 0.45176140394946973,
      "attention_bam_16_attention_center_distance": 0.08581551701809817,
      "attention_bam_16_attention_spatial_variance": 43.428367579760824,
      "attention_bam_16_attention_spatial_std": 6.590020301923267,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 10.251006657437255,
      "attention_bam_16_peak_intensity_mean": 0.30696550011634827,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 374,
      "phase": "train",
      "loss": 0.006348118185997009,
      "timestamp": 1759543942.3196187,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006348118185997009,
      "ssim": 0.8911930322647095,
      "attention_bam_384_mean_attention": 0.07826673239469528,
      "attention_bam_384_std_attention": 0.3535018861293793,
      "attention_bam_384_max_attention": 2.774848222732544,
      "attention_bam_384_min_attention": -1.0728893280029297,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.9455827988796406,
      "attention_bam_384_attention_skewness": 0.8700999931416582,
      "attention_bam_384_attention_sparsity": 0.5681076049804688,
      "attention_bam_384_attention_concentration_10": 1.0069481363248707,
      "attention_bam_384_attention_concentration_20": 1.5376176249862128,
      "attention_bam_384_attention_center_y": 0.48729139785282655,
      "attention_bam_384_attention_center_x": 0.47721625552360314,
      "attention_bam_384_attention_center_distance": 0.0368946495010018,
      "attention_bam_384_attention_spatial_variance": 169.84911183149603,
      "attention_bam_384_attention_spatial_std": 13.032617228764758,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 20.971315285776328,
      "attention_bam_384_peak_intensity_mean": 0.30344894528388977,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18592306971549988,
      "attention_bam_16_std_attention": 0.5479030609130859,
      "attention_bam_16_max_attention": 3.1009814739227295,
      "attention_bam_16_min_attention": -0.9817640781402588,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.3901311271156782,
      "attention_bam_16_attention_skewness": 0.9364540304495481,
      "attention_bam_16_attention_sparsity": 0.48291015625,
      "attention_bam_16_attention_concentration_10": 0.7101076324939698,
      "attention_bam_16_attention_concentration_20": 1.1007575005750263,
      "attention_bam_16_attention_center_y": 0.47348315518681494,
      "attention_bam_16_attention_center_x": 0.4497755160475652,
      "attention_bam_16_attention_center_distance": 0.0803198835548822,
      "attention_bam_16_attention_spatial_variance": 41.90992716082581,
      "attention_bam_16_attention_spatial_std": 6.473787698158305,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.622108158577621,
      "attention_bam_16_peak_intensity_mean": 0.2969110906124115,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 375,
      "phase": "train",
      "loss": 0.015465393662452698,
      "timestamp": 1759543942.4657006,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.015465393662452698,
      "ssim": 0.8567320108413696,
      "attention_bam_384_mean_attention": 0.07401291280984879,
      "attention_bam_384_std_attention": 0.38315141201019287,
      "attention_bam_384_max_attention": 2.9520254135131836,
      "attention_bam_384_min_attention": -1.088369607925415,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1136821216431159,
      "attention_bam_384_attention_skewness": 0.6897745252649318,
      "attention_bam_384_attention_sparsity": 0.5599746704101562,
      "attention_bam_384_attention_concentration_10": 1.1106408146637226,
      "attention_bam_384_attention_concentration_20": 1.7280005787615598,
      "attention_bam_384_attention_center_y": 0.48497196809558335,
      "attention_bam_384_attention_center_x": 0.482937129312537,
      "attention_bam_384_attention_center_distance": 0.03215535100157509,
      "attention_bam_384_attention_spatial_variance": 172.09260793804447,
      "attention_bam_384_attention_spatial_std": 13.118407218029347,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 18.54808528724509,
      "attention_bam_384_peak_intensity_mean": 0.28937122225761414,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.15734368562698364,
      "attention_bam_16_std_attention": 0.6332917213439941,
      "attention_bam_16_max_attention": 3.300593376159668,
      "attention_bam_16_min_attention": -1.1329450607299805,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.9133011472500909,
      "attention_bam_16_attention_skewness": 0.8570060749707067,
      "attention_bam_16_attention_sparsity": 0.51318359375,
      "attention_bam_16_attention_concentration_10": 0.9267687682470226,
      "attention_bam_16_attention_concentration_20": 1.4331045018906057,
      "attention_bam_16_attention_center_y": 0.4689725453059565,
      "attention_bam_16_attention_center_x": 0.4665069781442716,
      "attention_bam_16_attention_center_distance": 0.06456756860559675,
      "attention_bam_16_attention_spatial_variance": 43.667160559648735,
      "attention_bam_16_attention_spatial_std": 6.608113237501968,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.552850994021359,
      "attention_bam_16_peak_intensity_mean": 0.29297342896461487,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 376,
      "phase": "train",
      "loss": 0.004731006920337677,
      "timestamp": 1759543942.5982022,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004731006920337677,
      "ssim": 0.9050285816192627,
      "attention_bam_384_mean_attention": 0.07804384082555771,
      "attention_bam_384_std_attention": 0.3771914839744568,
      "attention_bam_384_max_attention": 3.408421516418457,
      "attention_bam_384_min_attention": -1.2715489864349365,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9081913508210473,
      "attention_bam_384_attention_skewness": 0.646701465281464,
      "attention_bam_384_attention_sparsity": 0.5603561401367188,
      "attention_bam_384_attention_concentration_10": 1.0486410615475499,
      "attention_bam_384_attention_concentration_20": 1.644072119035371,
      "attention_bam_384_attention_center_y": 0.48469251790182694,
      "attention_bam_384_attention_center_x": 0.4871340153925254,
      "attention_bam_384_attention_center_distance": 0.028279058262455015,
      "attention_bam_384_attention_spatial_variance": 171.90657839291072,
      "attention_bam_384_attention_spatial_std": 13.111314899464153,
      "attention_bam_384_num_attention_peaks": 18,
      "attention_bam_384_peak_separation_mean": 19.920833524831984,
      "attention_bam_384_peak_intensity_mean": 0.2932051122188568,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17466501891613007,
      "attention_bam_16_std_attention": 0.5920640826225281,
      "attention_bam_16_max_attention": 3.2277424335479736,
      "attention_bam_16_min_attention": -1.1034060716629028,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5527196446393434,
      "attention_bam_16_attention_skewness": 0.7256859593248132,
      "attention_bam_16_attention_sparsity": 0.50244140625,
      "attention_bam_16_attention_concentration_10": 0.7824790721202644,
      "attention_bam_16_attention_concentration_20": 1.2375715678211765,
      "attention_bam_16_attention_center_y": 0.4684081631829468,
      "attention_bam_16_attention_center_x": 0.48020035909147485,
      "attention_bam_16_attention_center_distance": 0.05272703165515503,
      "attention_bam_16_attention_spatial_variance": 43.62729472117387,
      "attention_bam_16_attention_spatial_std": 6.605096117481854,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.138149569027972,
      "attention_bam_16_peak_intensity_mean": 0.3039076626300812,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 377,
      "phase": "train",
      "loss": 0.006971587426960468,
      "timestamp": 1759543942.7346282,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006971587426960468,
      "ssim": 0.8925967216491699,
      "attention_bam_384_mean_attention": 0.07653418183326721,
      "attention_bam_384_std_attention": 0.3844338059425354,
      "attention_bam_384_max_attention": 2.9697909355163574,
      "attention_bam_384_min_attention": -1.1418430805206299,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9895781239945554,
      "attention_bam_384_attention_skewness": 0.6494884706998936,
      "attention_bam_384_attention_sparsity": 0.5581232706705729,
      "attention_bam_384_attention_concentration_10": 1.0835403961714338,
      "attention_bam_384_attention_concentration_20": 1.6936869230644787,
      "attention_bam_384_attention_center_y": 0.48367375954843045,
      "attention_bam_384_attention_center_x": 0.48709490862871885,
      "attention_bam_384_attention_center_distance": 0.02943085151957317,
      "attention_bam_384_attention_spatial_variance": 170.7624427356626,
      "attention_bam_384_attention_spatial_std": 13.067610444747066,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 17.957863244506946,
      "attention_bam_384_peak_intensity_mean": 0.3006608784198761,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16852475702762604,
      "attention_bam_16_std_attention": 0.6125759482383728,
      "attention_bam_16_max_attention": 3.411003828048706,
      "attention_bam_16_min_attention": -1.183749794960022,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7549209417342198,
      "attention_bam_16_attention_skewness": 0.8102433944375655,
      "attention_bam_16_attention_sparsity": 0.511962890625,
      "attention_bam_16_attention_concentration_10": 0.844330056873547,
      "attention_bam_16_attention_concentration_20": 1.3250882332854441,
      "attention_bam_16_attention_center_y": 0.46629558360614193,
      "attention_bam_16_attention_center_x": 0.4768857214014444,
      "attention_bam_16_attention_center_distance": 0.05779718954382147,
      "attention_bam_16_attention_spatial_variance": 42.86432731892002,
      "attention_bam_16_attention_spatial_std": 6.54708540641712,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.346646351423788,
      "attention_bam_16_peak_intensity_mean": 0.3046891391277313,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 378,
      "phase": "train",
      "loss": 0.006746209226548672,
      "timestamp": 1759543942.9084034,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006746209226548672,
      "ssim": 0.8739376068115234,
      "attention_bam_384_mean_attention": 0.08086196333169937,
      "attention_bam_384_std_attention": 0.38800889253616333,
      "attention_bam_384_max_attention": 3.1277809143066406,
      "attention_bam_384_min_attention": -1.2431570291519165,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8439397586956314,
      "attention_bam_384_attention_skewness": 0.8470950953857577,
      "attention_bam_384_attention_sparsity": 0.5602900187174479,
      "attention_bam_384_attention_concentration_10": 1.0719355799929342,
      "attention_bam_384_attention_concentration_20": 1.619854047346785,
      "attention_bam_384_attention_center_y": 0.48726810791968705,
      "attention_bam_384_attention_center_x": 0.48502763730369153,
      "attention_bam_384_attention_center_distance": 0.027794701676921985,
      "attention_bam_384_attention_spatial_variance": 169.42421966084876,
      "attention_bam_384_attention_spatial_std": 13.016305914538455,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 17.825784941412653,
      "attention_bam_384_peak_intensity_mean": 0.3065609633922577,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1844722330570221,
      "attention_bam_16_std_attention": 0.6035844087600708,
      "attention_bam_16_max_attention": 3.3139753341674805,
      "attention_bam_16_min_attention": -1.161865234375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.5444438272146686,
      "attention_bam_16_attention_skewness": 1.009854458718796,
      "attention_bam_16_attention_sparsity": 0.506103515625,
      "attention_bam_16_attention_concentration_10": 0.7846043715578953,
      "attention_bam_16_attention_concentration_20": 1.2065844450951575,
      "attention_bam_16_attention_center_y": 0.4749117527510309,
      "attention_bam_16_attention_center_x": 0.47357915547206786,
      "attention_bam_16_attention_center_distance": 0.05152632677757198,
      "attention_bam_16_attention_spatial_variance": 41.859010087413466,
      "attention_bam_16_attention_spatial_std": 6.469853946374173,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.009212577674901,
      "attention_bam_16_peak_intensity_mean": 0.31003811955451965,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 379,
      "phase": "train",
      "loss": 0.00573860015720129,
      "timestamp": 1759543943.0985324,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00573860015720129,
      "ssim": 0.8906640410423279,
      "attention_bam_384_mean_attention": 0.07613474875688553,
      "attention_bam_384_std_attention": 0.37108364701271057,
      "attention_bam_384_max_attention": 3.1604576110839844,
      "attention_bam_384_min_attention": -1.0018352270126343,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7107575786881517,
      "attention_bam_384_attention_skewness": 0.6388891617705419,
      "attention_bam_384_attention_sparsity": 0.5658594767252604,
      "attention_bam_384_attention_concentration_10": 1.0682328034730366,
      "attention_bam_384_attention_concentration_20": 1.6650736726040647,
      "attention_bam_384_attention_center_y": 0.4851864061487248,
      "attention_bam_384_attention_center_x": 0.4792721502713241,
      "attention_bam_384_attention_center_distance": 0.03603016284073964,
      "attention_bam_384_attention_spatial_variance": 172.72662222070116,
      "attention_bam_384_attention_spatial_std": 13.142550065367876,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 17.43807302599072,
      "attention_bam_384_peak_intensity_mean": 0.2604508399963379,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.172396719455719,
      "attention_bam_16_std_attention": 0.5662845969200134,
      "attention_bam_16_max_attention": 2.884165048599243,
      "attention_bam_16_min_attention": -0.9893968105316162,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.376290598571007,
      "attention_bam_16_attention_skewness": 0.7042590269811978,
      "attention_bam_16_attention_sparsity": 0.50390625,
      "attention_bam_16_attention_concentration_10": 0.7660803357176641,
      "attention_bam_16_attention_concentration_20": 1.211849449061559,
      "attention_bam_16_attention_center_y": 0.47212732098086985,
      "attention_bam_16_attention_center_x": 0.4561211724264506,
      "attention_bam_16_attention_center_distance": 0.07351513782797031,
      "attention_bam_16_attention_spatial_variance": 43.90931148273984,
      "attention_bam_16_attention_spatial_std": 6.626410150506822,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.531596401352093,
      "attention_bam_16_peak_intensity_mean": 0.30166274309158325,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 380,
      "phase": "train",
      "loss": 0.005609977524727583,
      "timestamp": 1759543943.3030148,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005609977524727583,
      "ssim": 0.8899269104003906,
      "attention_bam_384_mean_attention": 0.07575662434101105,
      "attention_bam_384_std_attention": 0.3674870431423187,
      "attention_bam_384_max_attention": 3.3146204948425293,
      "attention_bam_384_min_attention": -1.1793441772460938,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.1374520982049097,
      "attention_bam_384_attention_skewness": 0.9166950941764872,
      "attention_bam_384_attention_sparsity": 0.5716044108072916,
      "attention_bam_384_attention_concentration_10": 1.0790601228452805,
      "attention_bam_384_attention_concentration_20": 1.642397764515861,
      "attention_bam_384_attention_center_y": 0.48567643208883793,
      "attention_bam_384_attention_center_x": 0.47737313429803574,
      "attention_bam_384_attention_center_distance": 0.03787188004840526,
      "attention_bam_384_attention_spatial_variance": 170.70699482980822,
      "attention_bam_384_attention_spatial_std": 13.06548869464163,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 20.020232234130443,
      "attention_bam_384_peak_intensity_mean": 0.2794254422187805,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16999492049217224,
      "attention_bam_16_std_attention": 0.5936526656150818,
      "attention_bam_16_max_attention": 3.380885124206543,
      "attention_bam_16_min_attention": -1.0818593502044678,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.9323464439620999,
      "attention_bam_16_attention_skewness": 1.069406023703205,
      "attention_bam_16_attention_sparsity": 0.515625,
      "attention_bam_16_attention_concentration_10": 0.825037609013125,
      "attention_bam_16_attention_concentration_20": 1.271322138877687,
      "attention_bam_16_attention_center_y": 0.4725295212527551,
      "attention_bam_16_attention_center_x": 0.4496057661361616,
      "attention_bam_16_attention_center_distance": 0.0811690336190603,
      "attention_bam_16_attention_spatial_variance": 42.70729395624841,
      "attention_bam_16_attention_spatial_std": 6.535081786500335,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.915435836792653,
      "attention_bam_16_peak_intensity_mean": 0.28154513239860535,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 381,
      "phase": "train",
      "loss": 0.006278488785028458,
      "timestamp": 1759543943.4670038,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006278488785028458,
      "ssim": 0.9011147618293762,
      "attention_bam_384_mean_attention": 0.07818055897951126,
      "attention_bam_384_std_attention": 0.33978328108787537,
      "attention_bam_384_max_attention": 2.8672921657562256,
      "attention_bam_384_min_attention": -1.0625547170639038,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.576256589310833,
      "attention_bam_384_attention_skewness": 0.7388283638056153,
      "attention_bam_384_attention_sparsity": 0.5598805745442709,
      "attention_bam_384_attention_concentration_10": 0.9587678389051397,
      "attention_bam_384_attention_concentration_20": 1.4779869534758125,
      "attention_bam_384_attention_center_y": 0.4886514920314179,
      "attention_bam_384_attention_center_x": 0.48391584740229,
      "attention_bam_384_attention_center_distance": 0.027838412235592507,
      "attention_bam_384_attention_spatial_variance": 172.99878250875955,
      "attention_bam_384_attention_spatial_std": 13.152900155812008,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 19.45743685518996,
      "attention_bam_384_peak_intensity_mean": 0.2909590005874634,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18868911266326904,
      "attention_bam_16_std_attention": 0.5427435040473938,
      "attention_bam_16_max_attention": 3.188417434692383,
      "attention_bam_16_min_attention": -0.9700373411178589,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.6308041664410613,
      "attention_bam_16_attention_skewness": 0.9265063157037147,
      "attention_bam_16_attention_sparsity": 0.47607421875,
      "attention_bam_16_attention_concentration_10": 0.689914767064667,
      "attention_bam_16_attention_concentration_20": 1.068325410846031,
      "attention_bam_16_attention_center_y": 0.47963094706436266,
      "attention_bam_16_attention_center_x": 0.46518849861974315,
      "attention_bam_16_attention_center_distance": 0.057039266226739285,
      "attention_bam_16_attention_spatial_variance": 44.225872694596305,
      "attention_bam_16_attention_spatial_std": 6.650253581225027,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.151850675668733,
      "attention_bam_16_peak_intensity_mean": 0.2824012339115143,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 382,
      "phase": "train",
      "loss": 0.006530970335006714,
      "timestamp": 1759543943.6053815,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006530970335006714,
      "ssim": 0.8892432451248169,
      "attention_bam_384_mean_attention": 0.0734432116150856,
      "attention_bam_384_std_attention": 0.378315269947052,
      "attention_bam_384_max_attention": 2.611027956008911,
      "attention_bam_384_min_attention": -1.0577949285507202,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4214936236460884,
      "attention_bam_384_attention_skewness": 0.8831487796789671,
      "attention_bam_384_attention_sparsity": 0.5788192749023438,
      "attention_bam_384_attention_concentration_10": 1.155420046648906,
      "attention_bam_384_attention_concentration_20": 1.7574806885825391,
      "attention_bam_384_attention_center_y": 0.4911975065505058,
      "attention_bam_384_attention_center_x": 0.488196576258431,
      "attention_bam_384_attention_center_distance": 0.020823289987483867,
      "attention_bam_384_attention_spatial_variance": 167.9915112607324,
      "attention_bam_384_attention_spatial_std": 12.961153932452635,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 13.679226048523322,
      "attention_bam_384_peak_intensity_mean": 0.31111273169517517,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16411620378494263,
      "attention_bam_16_std_attention": 0.5914339423179626,
      "attention_bam_16_max_attention": 2.6632537841796875,
      "attention_bam_16_min_attention": -1.1503714323043823,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7050122627142312,
      "attention_bam_16_attention_skewness": 0.8973462598904086,
      "attention_bam_16_attention_sparsity": 0.5341796875,
      "attention_bam_16_attention_concentration_10": 0.8544474621006736,
      "attention_bam_16_attention_concentration_20": 1.336730178126292,
      "attention_bam_16_attention_center_y": 0.4828174100076441,
      "attention_bam_16_attention_center_x": 0.47828171121973007,
      "attention_bam_16_attention_center_distance": 0.03916440900584631,
      "attention_bam_16_attention_spatial_variance": 41.41300043356494,
      "attention_bam_16_attention_spatial_std": 6.435293344795165,
      "attention_bam_16_num_attention_peaks": 2,
      "attention_bam_16_peak_separation_mean": 10.182494782714107,
      "attention_bam_16_peak_intensity_mean": 0.3551188111305237,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 383,
      "phase": "train",
      "loss": 0.005465355701744556,
      "timestamp": 1759543943.7431357,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005465355701744556,
      "ssim": 0.9032974243164062,
      "attention_bam_384_mean_attention": 0.07670231908559799,
      "attention_bam_384_std_attention": 0.31785568594932556,
      "attention_bam_384_max_attention": 2.480591297149658,
      "attention_bam_384_min_attention": -0.9850309491157532,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.14358023874771053,
      "attention_bam_384_attention_skewness": 0.38682524341603874,
      "attention_bam_384_attention_sparsity": 0.5549290974934896,
      "attention_bam_384_attention_concentration_10": 0.8794989734955477,
      "attention_bam_384_attention_concentration_20": 1.4188694537832705,
      "attention_bam_384_attention_center_y": 0.4814672878099995,
      "attention_bam_384_attention_center_x": 0.4846827322272585,
      "attention_bam_384_attention_center_distance": 0.034002356187160306,
      "attention_bam_384_attention_spatial_variance": 170.7461349509559,
      "attention_bam_384_attention_spatial_std": 13.06698645254352,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 17.21484000402742,
      "attention_bam_384_peak_intensity_mean": 0.30867740511894226,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18257474899291992,
      "attention_bam_16_std_attention": 0.5025569200515747,
      "attention_bam_16_max_attention": 2.3145318031311035,
      "attention_bam_16_min_attention": -0.9809005856513977,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.02569614531649167,
      "attention_bam_16_attention_skewness": 0.4361028877547284,
      "attention_bam_16_attention_sparsity": 0.46435546875,
      "attention_bam_16_attention_concentration_10": 0.6271187305178529,
      "attention_bam_16_attention_concentration_20": 1.021245579622111,
      "attention_bam_16_attention_center_y": 0.46123434012653736,
      "attention_bam_16_attention_center_x": 0.4692350298850224,
      "attention_bam_16_attention_center_distance": 0.0699894245097137,
      "attention_bam_16_attention_spatial_variance": 42.76563041669476,
      "attention_bam_16_attention_spatial_std": 6.539543593913474,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.505865610043754,
      "attention_bam_16_peak_intensity_mean": 0.3659125566482544,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 384,
      "phase": "train",
      "loss": 0.005843363236635923,
      "timestamp": 1759543943.8764877,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005843363236635923,
      "ssim": 0.8951961994171143,
      "attention_bam_384_mean_attention": 0.07392700016498566,
      "attention_bam_384_std_attention": 0.38168737292289734,
      "attention_bam_384_max_attention": 2.8607871532440186,
      "attention_bam_384_min_attention": -1.3147624731063843,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.084026326590166,
      "attention_bam_384_attention_skewness": 0.9290106931571885,
      "attention_bam_384_attention_sparsity": 0.5754318237304688,
      "attention_bam_384_attention_concentration_10": 1.152918563149288,
      "attention_bam_384_attention_concentration_20": 1.7382855114906395,
      "attention_bam_384_attention_center_y": 0.4803533682717949,
      "attention_bam_384_attention_center_x": 0.48995921307927254,
      "attention_bam_384_attention_center_distance": 0.03120280565113227,
      "attention_bam_384_attention_spatial_variance": 171.0937603138825,
      "attention_bam_384_attention_spatial_std": 13.080281354538307,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 17.07531598159022,
      "attention_bam_384_peak_intensity_mean": 0.33495834469795227,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16133838891983032,
      "attention_bam_16_std_attention": 0.6211271286010742,
      "attention_bam_16_max_attention": 3.139643907546997,
      "attention_bam_16_min_attention": -1.1703437566757202,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.4965299097315814,
      "attention_bam_16_attention_skewness": 1.0284569011901155,
      "attention_bam_16_attention_sparsity": 0.52783203125,
      "attention_bam_16_attention_concentration_10": 0.9027993847970143,
      "attention_bam_16_attention_concentration_20": 1.3864960549278538,
      "attention_bam_16_attention_center_y": 0.45546507081291754,
      "attention_bam_16_attention_center_x": 0.48750488065786474,
      "attention_bam_16_attention_center_distance": 0.06541388117322885,
      "attention_bam_16_attention_spatial_variance": 43.10265053157104,
      "attention_bam_16_attention_spatial_std": 6.56526088830985,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.283852213491217,
      "attention_bam_16_peak_intensity_mean": 0.30528613924980164,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 385,
      "phase": "train",
      "loss": 0.007143436931073666,
      "timestamp": 1759543944.206457,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007143436931073666,
      "ssim": 0.8746391534805298,
      "attention_bam_384_mean_attention": 0.06995999068021774,
      "attention_bam_384_std_attention": 0.3504413068294525,
      "attention_bam_384_max_attention": 3.122953414916992,
      "attention_bam_384_min_attention": -1.0528059005737305,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5634836883862704,
      "attention_bam_384_attention_skewness": 0.848547072403863,
      "attention_bam_384_attention_sparsity": 0.5774154663085938,
      "attention_bam_384_attention_concentration_10": 1.1116727486338334,
      "attention_bam_384_attention_concentration_20": 1.6980117440021045,
      "attention_bam_384_attention_center_y": 0.48885942030660606,
      "attention_bam_384_attention_center_x": 0.488352428792086,
      "attention_bam_384_attention_center_distance": 0.022793789985357336,
      "attention_bam_384_attention_spatial_variance": 170.83283695083904,
      "attention_bam_384_attention_spatial_std": 13.070303628869492,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 19.987011192837286,
      "attention_bam_384_peak_intensity_mean": 0.26634901762008667,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16103588044643402,
      "attention_bam_16_std_attention": 0.5534308552742004,
      "attention_bam_16_max_attention": 2.7876040935516357,
      "attention_bam_16_min_attention": -1.1051239967346191,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.1053741516573679,
      "attention_bam_16_attention_skewness": 0.9091241335408722,
      "attention_bam_16_attention_sparsity": 0.51708984375,
      "attention_bam_16_attention_concentration_10": 0.8136789940780329,
      "attention_bam_16_attention_concentration_20": 1.2594267477128025,
      "attention_bam_16_attention_center_y": 0.4790487893047553,
      "attention_bam_16_attention_center_x": 0.4791345429496193,
      "attention_bam_16_attention_center_distance": 0.04181675567324218,
      "attention_bam_16_attention_spatial_variance": 42.65184243069056,
      "attention_bam_16_attention_spatial_std": 6.53083780465344,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.969767671444949,
      "attention_bam_16_peak_intensity_mean": 0.32868435978889465,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 386,
      "phase": "train",
      "loss": 0.005081228446215391,
      "timestamp": 1759543944.341228,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005081228446215391,
      "ssim": 0.8938370943069458,
      "attention_bam_384_mean_attention": 0.0707005187869072,
      "attention_bam_384_std_attention": 0.35541778802871704,
      "attention_bam_384_max_attention": 3.0556888580322266,
      "attention_bam_384_min_attention": -1.088330626487732,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.4596493736139893,
      "attention_bam_384_attention_skewness": 0.9754767927563364,
      "attention_bam_384_attention_sparsity": 0.5783233642578125,
      "attention_bam_384_attention_concentration_10": 1.117863741292037,
      "attention_bam_384_attention_concentration_20": 1.685082803060875,
      "attention_bam_384_attention_center_y": 0.49084525961670084,
      "attention_bam_384_attention_center_x": 0.4853584916771777,
      "attention_bam_384_attention_center_distance": 0.024420607586744563,
      "attention_bam_384_attention_spatial_variance": 173.63743738912046,
      "attention_bam_384_attention_spatial_std": 13.177155891508624,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 20.65078044724417,
      "attention_bam_384_peak_intensity_mean": 0.28516772389411926,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16363468766212463,
      "attention_bam_16_std_attention": 0.5673214197158813,
      "attention_bam_16_max_attention": 3.205228567123413,
      "attention_bam_16_min_attention": -1.096735954284668,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.644340162727235,
      "attention_bam_16_attention_skewness": 1.0173617371670893,
      "attention_bam_16_attention_sparsity": 0.51025390625,
      "attention_bam_16_attention_concentration_10": 0.8201242872103227,
      "attention_bam_16_attention_concentration_20": 1.260370366506659,
      "attention_bam_16_attention_center_y": 0.48658429629115013,
      "attention_bam_16_attention_center_x": 0.47120547999365353,
      "attention_bam_16_attention_center_distance": 0.04492450307793142,
      "attention_bam_16_attention_spatial_variance": 44.38765895809156,
      "attention_bam_16_attention_spatial_std": 6.662406393945926,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 11.154685899128326,
      "attention_bam_16_peak_intensity_mean": 0.3062683343887329,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 387,
      "phase": "train",
      "loss": 0.005136109888553619,
      "timestamp": 1759543944.4754517,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005136109888553619,
      "ssim": 0.9001578688621521,
      "attention_bam_384_mean_attention": 0.07218224555253983,
      "attention_bam_384_std_attention": 0.3888779580593109,
      "attention_bam_384_max_attention": 3.2876014709472656,
      "attention_bam_384_min_attention": -1.1084246635437012,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.79531816698848,
      "attention_bam_384_attention_skewness": 0.8945184757316479,
      "attention_bam_384_attention_sparsity": 0.5799357096354166,
      "attention_bam_384_attention_concentration_10": 1.2048634598211607,
      "attention_bam_384_attention_concentration_20": 1.8113706893496229,
      "attention_bam_384_attention_center_y": 0.4884323506962541,
      "attention_bam_384_attention_center_x": 0.486539393307908,
      "attention_bam_384_attention_center_distance": 0.025099738760937084,
      "attention_bam_384_attention_spatial_variance": 170.9599594917489,
      "attention_bam_384_attention_spatial_std": 13.075165753891952,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 15.325106955542905,
      "attention_bam_384_peak_intensity_mean": 0.2715282440185547,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16545820236206055,
      "attention_bam_16_std_attention": 0.6080968976020813,
      "attention_bam_16_max_attention": 3.352168321609497,
      "attention_bam_16_min_attention": -1.1346019506454468,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.2380767375398998,
      "attention_bam_16_attention_skewness": 0.9296518744416821,
      "attention_bam_16_attention_sparsity": 0.522216796875,
      "attention_bam_16_attention_concentration_10": 0.8661155836767106,
      "attention_bam_16_attention_concentration_20": 1.3403102493815044,
      "attention_bam_16_attention_center_y": 0.4790380138953246,
      "attention_bam_16_attention_center_x": 0.4750520663370784,
      "attention_bam_16_attention_center_distance": 0.0460826269976472,
      "attention_bam_16_attention_spatial_variance": 42.89598421675986,
      "attention_bam_16_attention_spatial_std": 6.549502593079864,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.160283193464707,
      "attention_bam_16_peak_intensity_mean": 0.2952892780303955,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 388,
      "phase": "train",
      "loss": 0.006555397063493729,
      "timestamp": 1759543944.6099665,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006555397063493729,
      "ssim": 0.8903377652168274,
      "attention_bam_384_mean_attention": 0.07377100735902786,
      "attention_bam_384_std_attention": 0.3384827673435211,
      "attention_bam_384_max_attention": 2.6784634590148926,
      "attention_bam_384_min_attention": -1.0420693159103394,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8644132584018007,
      "attention_bam_384_attention_skewness": 0.6180708930752231,
      "attention_bam_384_attention_sparsity": 0.5646692911783854,
      "attention_bam_384_attention_concentration_10": 0.9908937921495182,
      "attention_bam_384_attention_concentration_20": 1.5605641666278625,
      "attention_bam_384_attention_center_y": 0.48397713695836914,
      "attention_bam_384_attention_center_x": 0.4810020181447546,
      "attention_bam_384_attention_center_distance": 0.03514699004532521,
      "attention_bam_384_attention_spatial_variance": 170.37033339523984,
      "attention_bam_384_attention_spatial_std": 13.052598721911275,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 17.162101264668514,
      "attention_bam_384_peak_intensity_mean": 0.3022288680076599,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16792377829551697,
      "attention_bam_16_std_attention": 0.548581063747406,
      "attention_bam_16_max_attention": 2.7476866245269775,
      "attention_bam_16_min_attention": -1.1563200950622559,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6698742917198506,
      "attention_bam_16_attention_skewness": 0.6934671341061732,
      "attention_bam_16_attention_sparsity": 0.496337890625,
      "attention_bam_16_attention_concentration_10": 0.7422547118252313,
      "attention_bam_16_attention_concentration_20": 1.1890201535449885,
      "attention_bam_16_attention_center_y": 0.4681420054679689,
      "attention_bam_16_attention_center_x": 0.46087333147464626,
      "attention_bam_16_attention_center_distance": 0.07135584076297931,
      "attention_bam_16_attention_spatial_variance": 42.45037133084306,
      "attention_bam_16_attention_spatial_std": 6.515394948185648,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.532522229000456,
      "attention_bam_16_peak_intensity_mean": 0.34564128518104553,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 389,
      "phase": "train",
      "loss": 0.005376184359192848,
      "timestamp": 1759543944.74796,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005376184359192848,
      "ssim": 0.9168763756752014,
      "attention_bam_384_mean_attention": 0.0744004026055336,
      "attention_bam_384_std_attention": 0.33808812499046326,
      "attention_bam_384_max_attention": 2.9626474380493164,
      "attention_bam_384_min_attention": -1.0940263271331787,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5649211662012927,
      "attention_bam_384_attention_skewness": 0.470909035488416,
      "attention_bam_384_attention_sparsity": 0.55670166015625,
      "attention_bam_384_attention_concentration_10": 0.965490647435576,
      "attention_bam_384_attention_concentration_20": 1.5386397290027707,
      "attention_bam_384_attention_center_y": 0.48367532351550696,
      "attention_bam_384_attention_center_x": 0.4843939759455965,
      "attention_bam_384_attention_center_distance": 0.03193878673681829,
      "attention_bam_384_attention_spatial_variance": 172.36703752546518,
      "attention_bam_384_attention_spatial_std": 13.1288627658859,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 19.733787204859038,
      "attention_bam_384_peak_intensity_mean": 0.2915005385875702,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17698080837726593,
      "attention_bam_16_std_attention": 0.5447340607643127,
      "attention_bam_16_max_attention": 2.5262508392333984,
      "attention_bam_16_min_attention": -1.0810482501983643,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.028399831310860435,
      "attention_bam_16_attention_skewness": 0.48479155664280776,
      "attention_bam_16_attention_sparsity": 0.474609375,
      "attention_bam_16_attention_concentration_10": 0.6909212029460011,
      "attention_bam_16_attention_concentration_20": 1.1269780594761711,
      "attention_bam_16_attention_center_y": 0.4661969159367464,
      "attention_bam_16_attention_center_x": 0.4706258850341777,
      "attention_bam_16_attention_center_distance": 0.0633322527976502,
      "attention_bam_16_attention_spatial_variance": 43.91391585565318,
      "attention_bam_16_attention_spatial_std": 6.62675756729135,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.163675929266354,
      "attention_bam_16_peak_intensity_mean": 0.3632839620113373,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 390,
      "phase": "train",
      "loss": 0.007864909246563911,
      "timestamp": 1759543944.9569366,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007864909246563911,
      "ssim": 0.8912276029586792,
      "attention_bam_384_mean_attention": 0.07289600372314453,
      "attention_bam_384_std_attention": 0.33460211753845215,
      "attention_bam_384_max_attention": 2.58815860748291,
      "attention_bam_384_min_attention": -1.1371023654937744,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.151975867448801,
      "attention_bam_384_attention_skewness": 0.9242932185461431,
      "attention_bam_384_attention_sparsity": 0.5724461873372396,
      "attention_bam_384_attention_concentration_10": 1.0175664817645842,
      "attention_bam_384_attention_concentration_20": 1.5510998164059984,
      "attention_bam_384_attention_center_y": 0.4813478337595983,
      "attention_bam_384_attention_center_x": 0.4789254226333609,
      "attention_bam_384_attention_center_distance": 0.03980053056535901,
      "attention_bam_384_attention_spatial_variance": 171.6449115730883,
      "attention_bam_384_attention_spatial_std": 13.101332435026917,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 18.883205788430807,
      "attention_bam_384_peak_intensity_mean": 0.3279290199279785,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1584806591272354,
      "attention_bam_16_std_attention": 0.5533305406570435,
      "attention_bam_16_max_attention": 3.123699426651001,
      "attention_bam_16_min_attention": -1.006387710571289,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.5352935003106953,
      "attention_bam_16_attention_skewness": 0.964503830779138,
      "attention_bam_16_attention_sparsity": 0.5087890625,
      "attention_bam_16_attention_concentration_10": 0.814552867814382,
      "attention_bam_16_attention_concentration_20": 1.2605335153715984,
      "attention_bam_16_attention_center_y": 0.45991956056344885,
      "attention_bam_16_attention_center_x": 0.45300750362262243,
      "attention_bam_16_attention_center_distance": 0.08734685273328271,
      "attention_bam_16_attention_spatial_variance": 43.20045142717511,
      "attention_bam_16_attention_spatial_std": 6.572705031201013,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 8.83408674876462,
      "attention_bam_16_peak_intensity_mean": 0.2930105924606323,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 391,
      "phase": "train",
      "loss": 0.0054550389759242535,
      "timestamp": 1759543945.1331913,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0054550389759242535,
      "ssim": 0.8777284026145935,
      "attention_bam_384_mean_attention": 0.07227246463298798,
      "attention_bam_384_std_attention": 0.35643064975738525,
      "attention_bam_384_max_attention": 2.93994140625,
      "attention_bam_384_min_attention": -1.1852986812591553,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5853535542876083,
      "attention_bam_384_attention_skewness": 0.8210861698659864,
      "attention_bam_384_attention_sparsity": 0.5741856892903646,
      "attention_bam_384_attention_concentration_10": 1.0878562598649169,
      "attention_bam_384_attention_concentration_20": 1.6734453950955768,
      "attention_bam_384_attention_center_y": 0.4842966035662954,
      "attention_bam_384_attention_center_x": 0.4825643546352329,
      "attention_bam_384_attention_center_distance": 0.033184285101234626,
      "attention_bam_384_attention_spatial_variance": 170.45086565615762,
      "attention_bam_384_attention_spatial_std": 13.055683270367645,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 18.529542497358918,
      "attention_bam_384_peak_intensity_mean": 0.309338241815567,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.15883542597293854,
      "attention_bam_16_std_attention": 0.5843397378921509,
      "attention_bam_16_max_attention": 3.2556228637695312,
      "attention_bam_16_min_attention": -0.9821115136146545,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.9252697925288897,
      "attention_bam_16_attention_skewness": 0.8281935542484855,
      "attention_bam_16_attention_sparsity": 0.515380859375,
      "attention_bam_16_attention_concentration_10": 0.8390143222691748,
      "attention_bam_16_attention_concentration_20": 1.3209932391945944,
      "attention_bam_16_attention_center_y": 0.46834618313440324,
      "attention_bam_16_attention_center_x": 0.46527427061766446,
      "attention_bam_16_attention_center_distance": 0.06645058921177358,
      "attention_bam_16_attention_spatial_variance": 42.46794147133888,
      "attention_bam_16_attention_spatial_std": 6.516743164444866,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 8.435216292372296,
      "attention_bam_16_peak_intensity_mean": 0.2759203612804413,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 392,
      "phase": "train",
      "loss": 0.004088889807462692,
      "timestamp": 1759543945.3123584,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004088889807462692,
      "ssim": 0.9265896081924438,
      "attention_bam_384_mean_attention": 0.07241282612085342,
      "attention_bam_384_std_attention": 0.36592909693717957,
      "attention_bam_384_max_attention": 3.0635628700256348,
      "attention_bam_384_min_attention": -1.1309512853622437,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1643530261329644,
      "attention_bam_384_attention_skewness": 0.7157427808050466,
      "attention_bam_384_attention_sparsity": 0.5667190551757812,
      "attention_bam_384_attention_concentration_10": 1.0993288325433095,
      "attention_bam_384_attention_concentration_20": 1.7071089067572178,
      "attention_bam_384_attention_center_y": 0.486266746272505,
      "attention_bam_384_attention_center_x": 0.48244152043891136,
      "attention_bam_384_attention_center_distance": 0.03152467168555203,
      "attention_bam_384_attention_spatial_variance": 171.432997736304,
      "attention_bam_384_attention_spatial_std": 13.09324244548706,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 16.903702061596658,
      "attention_bam_384_peak_intensity_mean": 0.2879815399646759,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1594620943069458,
      "attention_bam_16_std_attention": 0.5931137204170227,
      "attention_bam_16_max_attention": 2.9191555976867676,
      "attention_bam_16_min_attention": -1.146378993988037,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6553684686945509,
      "attention_bam_16_attention_skewness": 0.7589277321024048,
      "attention_bam_16_attention_sparsity": 0.512451171875,
      "attention_bam_16_attention_concentration_10": 0.842761079928637,
      "attention_bam_16_attention_concentration_20": 1.337534341537386,
      "attention_bam_16_attention_center_y": 0.47383581198826613,
      "attention_bam_16_attention_center_x": 0.4651049202619074,
      "attention_bam_16_attention_center_distance": 0.06168032626763898,
      "attention_bam_16_attention_spatial_variance": 43.00302678823726,
      "attention_bam_16_attention_spatial_std": 6.557669310680225,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.825814830211199,
      "attention_bam_16_peak_intensity_mean": 0.32860153913497925,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 393,
      "phase": "train",
      "loss": 0.006012014113366604,
      "timestamp": 1759543945.4826164,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006012014113366604,
      "ssim": 0.8961381912231445,
      "attention_bam_384_mean_attention": 0.0737304836511612,
      "attention_bam_384_std_attention": 0.34317201375961304,
      "attention_bam_384_max_attention": 2.4878733158111572,
      "attention_bam_384_min_attention": -1.1292173862457275,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6552797797730432,
      "attention_bam_384_attention_skewness": 0.6195448869062495,
      "attention_bam_384_attention_sparsity": 0.5640665690104166,
      "attention_bam_384_attention_concentration_10": 1.0103809596755642,
      "attention_bam_384_attention_concentration_20": 1.584435283782894,
      "attention_bam_384_attention_center_y": 0.4789479755504668,
      "attention_bam_384_attention_center_x": 0.47858979330521073,
      "attention_bam_384_attention_center_distance": 0.04246374180727229,
      "attention_bam_384_attention_spatial_variance": 168.88745708174338,
      "attention_bam_384_attention_spatial_std": 12.995670705344276,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 16.47410322025717,
      "attention_bam_384_peak_intensity_mean": 0.3319104313850403,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1634809523820877,
      "attention_bam_16_std_attention": 0.5642662048339844,
      "attention_bam_16_max_attention": 2.2429933547973633,
      "attention_bam_16_min_attention": -1.1145081520080566,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.0797817342784155,
      "attention_bam_16_attention_skewness": 0.6520110750372073,
      "attention_bam_16_attention_sparsity": 0.51318359375,
      "attention_bam_16_attention_concentration_10": 0.7905818428267042,
      "attention_bam_16_attention_concentration_20": 1.2673609867114788,
      "attention_bam_16_attention_center_y": 0.45490984186366074,
      "attention_bam_16_attention_center_x": 0.4554426747592676,
      "attention_bam_16_attention_center_distance": 0.08964906684811048,
      "attention_bam_16_attention_spatial_variance": 41.51874582751325,
      "attention_bam_16_attention_spatial_std": 6.443504157483973,
      "attention_bam_16_num_attention_peaks": 2,
      "attention_bam_16_peak_separation_mean": 9.988969610970337,
      "attention_bam_16_peak_intensity_mean": 0.38014698028564453,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 394,
      "phase": "train",
      "loss": 0.004676739685237408,
      "timestamp": 1759543945.6387656,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004676739685237408,
      "ssim": 0.9123719930648804,
      "attention_bam_384_mean_attention": 0.0686466172337532,
      "attention_bam_384_std_attention": 0.34087592363357544,
      "attention_bam_384_max_attention": 2.6645467281341553,
      "attention_bam_384_min_attention": -1.0570592880249023,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.7019373021595774,
      "attention_bam_384_attention_skewness": 0.9016968947637032,
      "attention_bam_384_attention_sparsity": 0.5827204386393229,
      "attention_bam_384_attention_concentration_10": 1.1060247938006336,
      "attention_bam_384_attention_concentration_20": 1.6906904942618366,
      "attention_bam_384_attention_center_y": 0.4758751750059721,
      "attention_bam_384_attention_center_x": 0.48426185215675954,
      "attention_bam_384_attention_center_distance": 0.04073564725220817,
      "attention_bam_384_attention_spatial_variance": 172.62166931257053,
      "attention_bam_384_attention_spatial_std": 13.138556591672106,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 21.460516393549263,
      "attention_bam_384_peak_intensity_mean": 0.3054474890232086,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1446576863527298,
      "attention_bam_16_std_attention": 0.5622380375862122,
      "attention_bam_16_max_attention": 2.8608198165893555,
      "attention_bam_16_min_attention": -1.1163520812988281,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.0861011336464799,
      "attention_bam_16_attention_skewness": 0.9372004608529922,
      "attention_bam_16_attention_sparsity": 0.5390625,
      "attention_bam_16_attention_concentration_10": 0.8936593648696759,
      "attention_bam_16_attention_concentration_20": 1.407264643413448,
      "attention_bam_16_attention_center_y": 0.4488807651979268,
      "attention_bam_16_attention_center_x": 0.4681054600519227,
      "attention_bam_16_attention_center_distance": 0.08521077215057953,
      "attention_bam_16_attention_spatial_variance": 43.55238740428652,
      "attention_bam_16_attention_spatial_std": 6.599423263004618,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 10.478608419655245,
      "attention_bam_16_peak_intensity_mean": 0.32742395997047424,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 395,
      "phase": "train",
      "loss": 0.006535936146974564,
      "timestamp": 1759543945.7867901,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006535936146974564,
      "ssim": 0.9011385440826416,
      "attention_bam_384_mean_attention": 0.07621961086988449,
      "attention_bam_384_std_attention": 0.3150485157966614,
      "attention_bam_384_max_attention": 2.127408742904663,
      "attention_bam_384_min_attention": -0.9474049806594849,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8172018438497752,
      "attention_bam_384_attention_skewness": 0.5620703867360745,
      "attention_bam_384_attention_sparsity": 0.5583572387695312,
      "attention_bam_384_attention_concentration_10": 0.9064980240509964,
      "attention_bam_384_attention_concentration_20": 1.4143107144625915,
      "attention_bam_384_attention_center_y": 0.4809016584381581,
      "attention_bam_384_attention_center_x": 0.48835488693079776,
      "attention_bam_384_attention_center_distance": 0.03163401045733163,
      "attention_bam_384_attention_spatial_variance": 170.66124606328012,
      "attention_bam_384_attention_spatial_std": 13.063737828940083,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 14.43653851871349,
      "attention_bam_384_peak_intensity_mean": 0.33156365156173706,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17955712974071503,
      "attention_bam_16_std_attention": 0.5241329669952393,
      "attention_bam_16_max_attention": 2.5093231201171875,
      "attention_bam_16_min_attention": -1.0255835056304932,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.36939054893042034,
      "attention_bam_16_attention_skewness": 0.6057320609989736,
      "attention_bam_16_attention_sparsity": 0.47412109375,
      "attention_bam_16_attention_concentration_10": 0.6797641054275357,
      "attention_bam_16_attention_concentration_20": 1.078852934144399,
      "attention_bam_16_attention_center_y": 0.4600805332460536,
      "attention_bam_16_attention_center_x": 0.47889800117120146,
      "attention_bam_16_attention_center_distance": 0.06385699931080457,
      "attention_bam_16_attention_spatial_variance": 42.42697094171251,
      "attention_bam_16_attention_spatial_std": 6.513598923921592,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 7.83814576994045,
      "attention_bam_16_peak_intensity_mean": 0.3369206488132477,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 396,
      "phase": "train",
      "loss": 0.0055431886576116085,
      "timestamp": 1759543945.9310884,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0055431886576116085,
      "ssim": 0.9045227766036987,
      "attention_bam_384_mean_attention": 0.07585857063531876,
      "attention_bam_384_std_attention": 0.3309554159641266,
      "attention_bam_384_max_attention": 2.2906126976013184,
      "attention_bam_384_min_attention": -1.095337152481079,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9256633186711212,
      "attention_bam_384_attention_skewness": 0.6282191381101221,
      "attention_bam_384_attention_sparsity": 0.5646794637044271,
      "attention_bam_384_attention_concentration_10": 0.9435320619982709,
      "attention_bam_384_attention_concentration_20": 1.4935873645619098,
      "attention_bam_384_attention_center_y": 0.4846324852250886,
      "attention_bam_384_attention_center_x": 0.476694967613181,
      "attention_bam_384_attention_center_distance": 0.03947872958715372,
      "attention_bam_384_attention_spatial_variance": 170.6563121921971,
      "attention_bam_384_attention_spatial_std": 13.06354898916053,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 18.66411603342948,
      "attention_bam_384_peak_intensity_mean": 0.35174450278282166,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17452314496040344,
      "attention_bam_16_std_attention": 0.5480206608772278,
      "attention_bam_16_max_attention": 2.429302215576172,
      "attention_bam_16_min_attention": -1.0948923826217651,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.39826546296924237,
      "attention_bam_16_attention_skewness": 0.6193487385724926,
      "attention_bam_16_attention_sparsity": 0.48681640625,
      "attention_bam_16_attention_concentration_10": 0.7149113092825653,
      "attention_bam_16_attention_concentration_20": 1.1488470421328267,
      "attention_bam_16_attention_center_y": 0.46968934486240393,
      "attention_bam_16_attention_center_x": 0.446005087572912,
      "attention_bam_16_attention_center_distance": 0.08756924554750005,
      "attention_bam_16_attention_spatial_variance": 42.63045124766192,
      "attention_bam_16_attention_spatial_std": 6.529199893376057,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.118748175804154,
      "attention_bam_16_peak_intensity_mean": 0.3758782148361206,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 397,
      "phase": "train",
      "loss": 0.005491956137120724,
      "timestamp": 1759543946.0753448,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005491956137120724,
      "ssim": 0.9142385721206665,
      "attention_bam_384_mean_attention": 0.07182154804468155,
      "attention_bam_384_std_attention": 0.356730192899704,
      "attention_bam_384_max_attention": 2.3168020248413086,
      "attention_bam_384_min_attention": -1.024713397026062,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.3473613572798637,
      "attention_bam_384_attention_skewness": 0.5634337837861,
      "attention_bam_384_attention_sparsity": 0.5614802042643229,
      "attention_bam_384_attention_concentration_10": 1.0583361019687823,
      "attention_bam_384_attention_concentration_20": 1.679614522902824,
      "attention_bam_384_attention_center_y": 0.4909218756408265,
      "attention_bam_384_attention_center_x": 0.481317462079102,
      "attention_bam_384_attention_center_distance": 0.029375144767180693,
      "attention_bam_384_attention_spatial_variance": 169.7088389165301,
      "attention_bam_384_attention_spatial_std": 13.027234507620184,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 19.798360151295647,
      "attention_bam_384_peak_intensity_mean": 0.330497682094574,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.15379725396633148,
      "attention_bam_16_std_attention": 0.5793054699897766,
      "attention_bam_16_max_attention": 2.3132591247558594,
      "attention_bam_16_min_attention": -1.0193759202957153,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.10220297007341772,
      "attention_bam_16_attention_skewness": 0.5844973797176916,
      "attention_bam_16_attention_sparsity": 0.516357421875,
      "attention_bam_16_attention_concentration_10": 0.8334445772866641,
      "attention_bam_16_attention_concentration_20": 1.356448631377325,
      "attention_bam_16_attention_center_y": 0.48812084803834643,
      "attention_bam_16_attention_center_x": 0.46160048237746915,
      "attention_bam_16_attention_center_distance": 0.05684429971371123,
      "attention_bam_16_attention_spatial_variance": 41.787311739626894,
      "attention_bam_16_attention_spatial_std": 6.464310615961063,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 11.079040654949258,
      "attention_bam_16_peak_intensity_mean": 0.3632911145687103,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 398,
      "phase": "train",
      "loss": 0.005101893097162247,
      "timestamp": 1759543946.2203155,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005101893097162247,
      "ssim": 0.9107556343078613,
      "attention_bam_384_mean_attention": 0.07195476442575455,
      "attention_bam_384_std_attention": 0.3352133631706238,
      "attention_bam_384_max_attention": 2.3449912071228027,
      "attention_bam_384_min_attention": -1.0264170169830322,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.25217388802862883,
      "attention_bam_384_attention_skewness": 0.4974026289674871,
      "attention_bam_384_attention_sparsity": 0.5678532918294271,
      "attention_bam_384_attention_concentration_10": 0.9967848480299426,
      "attention_bam_384_attention_concentration_20": 1.5921129373206102,
      "attention_bam_384_attention_center_y": 0.48805513293714636,
      "attention_bam_384_attention_center_x": 0.4932460036463977,
      "attention_bam_384_attention_center_distance": 0.019405994738416206,
      "attention_bam_384_attention_spatial_variance": 170.95743971110835,
      "attention_bam_384_attention_spatial_std": 13.07506939603413,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 17.08561258353049,
      "attention_bam_384_peak_intensity_mean": 0.3288954794406891,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1571393758058548,
      "attention_bam_16_std_attention": 0.544708788394928,
      "attention_bam_16_max_attention": 2.426205635070801,
      "attention_bam_16_min_attention": -0.9657952189445496,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.008210659085490679,
      "attention_bam_16_attention_skewness": 0.5848959079287622,
      "attention_bam_16_attention_sparsity": 0.506591796875,
      "attention_bam_16_attention_concentration_10": 0.7813332201601721,
      "attention_bam_16_attention_concentration_20": 1.2617792800392273,
      "attention_bam_16_attention_center_y": 0.4787663006695983,
      "attention_bam_16_attention_center_x": 0.49204396849988047,
      "attention_bam_16_attention_center_distance": 0.03206769166886809,
      "attention_bam_16_attention_spatial_variance": 42.86419331194549,
      "attention_bam_16_attention_spatial_std": 6.547075172315153,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.7789893167388,
      "attention_bam_16_peak_intensity_mean": 0.3351368010044098,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 399,
      "phase": "train",
      "loss": 0.007560409605503082,
      "timestamp": 1759543946.3592937,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007560409605503082,
      "ssim": 0.8719730973243713,
      "attention_bam_384_mean_attention": 0.06803945451974869,
      "attention_bam_384_std_attention": 0.3610355854034424,
      "attention_bam_384_max_attention": 2.797825813293457,
      "attention_bam_384_min_attention": -1.073253870010376,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2379959218910237,
      "attention_bam_384_attention_skewness": 0.7688834718129419,
      "attention_bam_384_attention_sparsity": 0.5756098429361979,
      "attention_bam_384_attention_concentration_10": 1.1502975729860576,
      "attention_bam_384_attention_concentration_20": 1.784160520338135,
      "attention_bam_384_attention_center_y": 0.48097994085510304,
      "attention_bam_384_attention_center_x": 0.482835122062456,
      "attention_bam_384_attention_center_distance": 0.036232462916179556,
      "attention_bam_384_attention_spatial_variance": 171.31111158180406,
      "attention_bam_384_attention_spatial_std": 13.088587073546329,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 18.14438215775142,
      "attention_bam_384_peak_intensity_mean": 0.298132985830307,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13852067291736603,
      "attention_bam_16_std_attention": 0.5813579559326172,
      "attention_bam_16_max_attention": 2.6654233932495117,
      "attention_bam_16_min_attention": -1.0331162214279175,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.49589444759645174,
      "attention_bam_16_attention_skewness": 0.7396756483596327,
      "attention_bam_16_attention_sparsity": 0.525634765625,
      "attention_bam_16_attention_concentration_10": 0.935164235218913,
      "attention_bam_16_attention_concentration_20": 1.487404696527612,
      "attention_bam_16_attention_center_y": 0.46191669160394155,
      "attention_bam_16_attention_center_x": 0.46210067622730644,
      "attention_bam_16_attention_center_distance": 0.07598285491894537,
      "attention_bam_16_attention_spatial_variance": 43.236112657275456,
      "attention_bam_16_attention_spatial_std": 6.5754172990978645,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 8.938762830542538,
      "attention_bam_16_peak_intensity_mean": 0.3196173310279846,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 400,
      "phase": "train",
      "loss": 0.005502568557858467,
      "timestamp": 1759543946.5528505,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005502568557858467,
      "ssim": 0.9102948904037476,
      "attention_bam_384_mean_attention": 0.06985162943601608,
      "attention_bam_384_std_attention": 0.37580910325050354,
      "attention_bam_384_max_attention": 2.3953285217285156,
      "attention_bam_384_min_attention": -1.004521369934082,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.660948897996545,
      "attention_bam_384_attention_skewness": 0.670288434887504,
      "attention_bam_384_attention_sparsity": 0.5653839111328125,
      "attention_bam_384_attention_concentration_10": 1.149982756155989,
      "attention_bam_384_attention_concentration_20": 1.8041105056599458,
      "attention_bam_384_attention_center_y": 0.47756396479724056,
      "attention_bam_384_attention_center_x": 0.4941513136209783,
      "attention_bam_384_attention_center_distance": 0.032789718143943075,
      "attention_bam_384_attention_spatial_variance": 168.57488130694637,
      "attention_bam_384_attention_spatial_std": 12.98363898554432,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 15.176310612513978,
      "attention_bam_384_peak_intensity_mean": 0.31812721490859985,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.15966522693634033,
      "attention_bam_16_std_attention": 0.6050500869750977,
      "attention_bam_16_max_attention": 2.643094778060913,
      "attention_bam_16_min_attention": -1.013293981552124,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.1588317806386339,
      "attention_bam_16_attention_skewness": 0.7194822380319246,
      "attention_bam_16_attention_sparsity": 0.51904296875,
      "attention_bam_16_attention_concentration_10": 0.8621590651884156,
      "attention_bam_16_attention_concentration_20": 1.3831029760817772,
      "attention_bam_16_attention_center_y": 0.4474363690646756,
      "attention_bam_16_attention_center_x": 0.4936207902624609,
      "attention_bam_16_attention_center_distance": 0.07488163478424474,
      "attention_bam_16_attention_spatial_variance": 41.231953973879094,
      "attention_bam_16_attention_spatial_std": 6.421211254419146,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 7.1781245134470835,
      "attention_bam_16_peak_intensity_mean": 0.3366173207759857,
      "attention_bam_16_peak_coverage": 0.1015625
    }
  ],
  "summary": {
    "total_batches": 403,
    "latest_batch": 400,
    "latest_metrics": {
      "batch_idx": 400,
      "phase": "train",
      "loss": 0.005502568557858467,
      "timestamp": 1759543946.5528505,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005502568557858467,
      "ssim": 0.9102948904037476,
      "attention_bam_384_mean_attention": 0.06985162943601608,
      "attention_bam_384_std_attention": 0.37580910325050354,
      "attention_bam_384_max_attention": 2.3953285217285156,
      "attention_bam_384_min_attention": -1.004521369934082,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.660948897996545,
      "attention_bam_384_attention_skewness": 0.670288434887504,
      "attention_bam_384_attention_sparsity": 0.5653839111328125,
      "attention_bam_384_attention_concentration_10": 1.149982756155989,
      "attention_bam_384_attention_concentration_20": 1.8041105056599458,
      "attention_bam_384_attention_center_y": 0.47756396479724056,
      "attention_bam_384_attention_center_x": 0.4941513136209783,
      "attention_bam_384_attention_center_distance": 0.032789718143943075,
      "attention_bam_384_attention_spatial_variance": 168.57488130694637,
      "attention_bam_384_attention_spatial_std": 12.98363898554432,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 15.176310612513978,
      "attention_bam_384_peak_intensity_mean": 0.31812721490859985,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.15966522693634033,
      "attention_bam_16_std_attention": 0.6050500869750977,
      "attention_bam_16_max_attention": 2.643094778060913,
      "attention_bam_16_min_attention": -1.013293981552124,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.1588317806386339,
      "attention_bam_16_attention_skewness": 0.7194822380319246,
      "attention_bam_16_attention_sparsity": 0.51904296875,
      "attention_bam_16_attention_concentration_10": 0.8621590651884156,
      "attention_bam_16_attention_concentration_20": 1.3831029760817772,
      "attention_bam_16_attention_center_y": 0.4474363690646756,
      "attention_bam_16_attention_center_x": 0.4936207902624609,
      "attention_bam_16_attention_center_distance": 0.07488163478424474,
      "attention_bam_16_attention_spatial_variance": 41.231953973879094,
      "attention_bam_16_attention_spatial_std": 6.421211254419146,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 7.1781245134470835,
      "attention_bam_16_peak_intensity_mean": 0.3366173207759857,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    "loss_mean": 0.059146840391084365,
    "loss_std": 0.09908896222326607,
    "loss_min": 0.004088889807462692,
    "loss_max": 0.4267430305480957,
    "mse_mean": 0.059146840391084365,
    "mse_std": 0.09908896222326607,
    "mse_min": 0.004088889807462692,
    "mse_max": 0.4267430305480957,
    "ssim_mean": 0.6933549796148402,
    "ssim_std": 0.2537664455466461,
    "ssim_min": 0.00020899297669529915,
    "ssim_max": 0.9265896081924438,
    "attention_bam_384_mean_attention_mean": 0.14629034738220442,
    "attention_bam_384_mean_attention_std": 0.05117925918102076,
    "attention_bam_384_mean_attention_min": 0.0018816147930920124,
    "attention_bam_384_mean_attention_max": 0.24939437210559845,
    "attention_bam_384_std_attention_mean": 0.4694220004395279,
    "attention_bam_384_std_attention_std": 0.07580602058656048,
    "attention_bam_384_std_attention_min": 0.2580847144126892,
    "attention_bam_384_std_attention_max": 0.6589744091033936,
    "attention_bam_384_max_attention_mean": 3.998983047736194,
    "attention_bam_384_max_attention_std": 1.0425758431192598,
    "attention_bam_384_max_attention_min": 1.0809073448181152,
    "attention_bam_384_max_attention_max": 7.411942481994629,
    "attention_bam_384_min_attention_mean": -1.3728642762446817,
    "attention_bam_384_min_attention_std": 0.20142732531865165,
    "attention_bam_384_min_attention_min": -1.7483779191970825,
    "attention_bam_384_min_attention_max": -0.7371022701263428,
    "attention_bam_384_attention_entropy_mean": NaN,
    "attention_bam_384_attention_entropy_std": NaN,
    "attention_bam_384_attention_entropy_min": NaN,
    "attention_bam_384_attention_entropy_max": NaN,
    "attention_bam_384_attention_kurtosis_mean": 1.4546385274441966,
    "attention_bam_384_attention_kurtosis_std": 0.8163522200021206,
    "attention_bam_384_attention_kurtosis_min": -0.04150698504477912,
    "attention_bam_384_attention_kurtosis_max": 5.548939854860967,
    "attention_bam_384_attention_skewness_mean": 0.7015752385796553,
    "attention_bam_384_attention_skewness_std": 0.1690933917134987,
    "attention_bam_384_attention_skewness_min": 0.31266852704160103,
    "attention_bam_384_attention_skewness_max": 1.4774391747647857,
    "attention_bam_384_attention_sparsity_mean": 0.49834390392571665,
    "attention_bam_384_attention_sparsity_std": 0.04702514635267705,
    "attention_bam_384_attention_sparsity_min": 0.383392333984375,
    "attention_bam_384_attention_sparsity_max": 0.6638692220052084,
    "attention_bam_384_attention_concentration_10_mean": 0.8680009153956433,
    "attention_bam_384_attention_concentration_10_std": 1.4030358947881365,
    "attention_bam_384_attention_concentration_10_min": 0.4702837100852991,
    "attention_bam_384_attention_concentration_10_max": 26.154394441386547,
    "attention_bam_384_attention_concentration_20_mean": 1.3581862650780256,
    "attention_bam_384_attention_concentration_20_std": 2.126820905197161,
    "attention_bam_384_attention_concentration_20_min": 0.7411019232731788,
    "attention_bam_384_attention_concentration_20_max": 39.71070953916689,
    "attention_bam_384_attention_center_y_mean": 0.4839019112552026,
    "attention_bam_384_attention_center_y_std": 0.003879099051381151,
    "attention_bam_384_attention_center_y_min": 0.4730053084834942,
    "attention_bam_384_attention_center_y_max": 0.4948224063987425,
    "attention_bam_384_attention_center_x_mean": 0.48389780945607314,
    "attention_bam_384_attention_center_x_std": 0.0038240297632938314,
    "attention_bam_384_attention_center_x_min": 0.47365256965061986,
    "attention_bam_384_attention_center_x_max": 0.4963852482828458,
    "attention_bam_384_attention_center_distance_mean": 0.03267009654096334,
    "attention_bam_384_attention_center_distance_std": 0.005365464315431393,
    "attention_bam_384_attention_center_distance_min": 0.01644010957551244,
    "attention_bam_384_attention_center_distance_max": 0.047989895066337565,
    "attention_bam_384_attention_spatial_variance_mean": 170.64315942302144,
    "attention_bam_384_attention_spatial_variance_std": 1.3001518929646874,
    "attention_bam_384_attention_spatial_variance_min": 165.6335767446653,
    "attention_bam_384_attention_spatial_variance_max": 174.48496543685133,
    "attention_bam_384_attention_spatial_std_mean": 13.0629510107218,
    "attention_bam_384_attention_spatial_std_std": 0.049764038870040356,
    "attention_bam_384_attention_spatial_std_min": 12.869870890753539,
    "attention_bam_384_attention_spatial_std_max": 13.209275734757426,
    "attention_bam_384_num_attention_peaks_mean": 11.56575682382134,
    "attention_bam_384_num_attention_peaks_std": 3.842356062349307,
    "attention_bam_384_num_attention_peaks_min": 3.0,
    "attention_bam_384_num_attention_peaks_max": 27.0,
    "attention_bam_384_peak_separation_mean_mean": 17.490946401280066,
    "attention_bam_384_peak_separation_mean_std": 1.7033329828494472,
    "attention_bam_384_peak_separation_mean_min": 10.676092112277066,
    "attention_bam_384_peak_separation_mean_max": 23.121545967567652,
    "attention_bam_384_peak_intensity_mean_mean": 0.29041448405599474,
    "attention_bam_384_peak_intensity_mean_std": 0.029615327595879096,
    "attention_bam_384_peak_intensity_mean_min": 0.20472685992717743,
    "attention_bam_384_peak_intensity_mean_max": 0.4080160856246948,
    "attention_bam_384_peak_coverage_mean": 0.1005859375,
    "attention_bam_384_peak_coverage_std": 0.0,
    "attention_bam_384_peak_coverage_min": 0.1005859375,
    "attention_bam_384_peak_coverage_max": 0.1005859375,
    "attention_bam_16_mean_attention_mean": 0.19913598427331772,
    "attention_bam_16_mean_attention_std": 0.03389654268490772,
    "attention_bam_16_mean_attention_min": -0.04029373079538345,
    "attention_bam_16_mean_attention_max": 0.2840683162212372,
    "attention_bam_16_std_attention_mean": 0.5896049246524758,
    "attention_bam_16_std_attention_std": 0.05988815204811685,
    "attention_bam_16_std_attention_min": 0.15093879401683807,
    "attention_bam_16_std_attention_max": 0.7584808468818665,
    "attention_bam_16_max_attention_mean": 3.0445567135035843,
    "attention_bam_16_max_attention_std": 0.6677319867458703,
    "attention_bam_16_max_attention_min": 0.3069092631340027,
    "attention_bam_16_max_attention_max": 5.8794450759887695,
    "attention_bam_16_min_attention_mean": -1.1109500410539046,
    "attention_bam_16_min_attention_std": 0.10656727523777389,
    "attention_bam_16_min_attention_min": -1.4626561403274536,
    "attention_bam_16_min_attention_max": -0.4374985098838806,
    "attention_bam_16_attention_entropy_mean": NaN,
    "attention_bam_16_attention_entropy_std": NaN,
    "attention_bam_16_attention_entropy_min": NaN,
    "attention_bam_16_attention_entropy_max": NaN,
    "attention_bam_16_attention_kurtosis_mean": 0.9385777739833823,
    "attention_bam_16_attention_kurtosis_std": 1.1254539960195513,
    "attention_bam_16_attention_kurtosis_min": -0.5841703410821704,
    "attention_bam_16_attention_kurtosis_max": 7.531336645250047,
    "attention_bam_16_attention_skewness_mean": 0.7350049022765464,
    "attention_bam_16_attention_skewness_std": 0.3067157248075126,
    "attention_bam_16_attention_skewness_min": -0.2805927456680973,
    "attention_bam_16_attention_skewness_max": 2.0136314147787924,
    "attention_bam_16_attention_sparsity_mean": 0.4767242507366625,
    "attention_bam_16_attention_sparsity_std": 0.04819686743621786,
    "attention_bam_16_attention_sparsity_min": 0.2958984375,
    "attention_bam_16_attention_sparsity_max": 0.831298828125,
    "attention_bam_16_attention_concentration_10_mean": 0.6964422673290203,
    "attention_bam_16_attention_concentration_10_std": 0.1534173716117685,
    "attention_bam_16_attention_concentration_10_min": -0.6226609355982947,
    "attention_bam_16_attention_concentration_10_max": 0.9949383315701347,
    "attention_bam_16_attention_concentration_20_mean": 1.1038389280740608,
    "attention_bam_16_attention_concentration_20_std": 0.22745824218066177,
    "attention_bam_16_attention_concentration_20_min": -1.0122358604732702,
    "attention_bam_16_attention_concentration_20_max": 1.4998046213907819,
    "attention_bam_16_attention_center_y_mean": 0.4689619388053948,
    "attention_bam_16_attention_center_y_std": 0.011235496353224492,
    "attention_bam_16_attention_center_y_min": 0.4391900072765296,
    "attention_bam_16_attention_center_y_max": 0.49980089724886084,
    "attention_bam_16_attention_center_x_mean": 0.46957512263502577,
    "attention_bam_16_attention_center_x_std": 0.01072977346297026,
    "attention_bam_16_attention_center_x_min": 0.44081755511950904,
    "attention_bam_16_attention_center_x_max": 0.49802551385786914,
    "attention_bam_16_attention_center_distance_mean": 0.06344709025281732,
    "attention_bam_16_attention_center_distance_std": 0.015318250545265312,
    "attention_bam_16_attention_center_distance_min": 0.024165491295484707,
    "attention_bam_16_attention_center_distance_max": 0.10764633865437298,
    "attention_bam_16_attention_spatial_variance_mean": 42.32846215465362,
    "attention_bam_16_attention_spatial_variance_std": 0.9935655733261183,
    "attention_bam_16_attention_spatial_variance_min": 39.47168520702132,
    "attention_bam_16_attention_spatial_variance_max": 45.066126391784685,
    "attention_bam_16_attention_spatial_std_mean": 6.505586261169822,
    "attention_bam_16_attention_spatial_std_std": 0.0763151672788452,
    "attention_bam_16_attention_spatial_std_min": 6.282649537179463,
    "attention_bam_16_attention_spatial_std_max": 6.7131308933898115,
    "attention_bam_16_num_attention_peaks_mean": 5.883374689826303,
    "attention_bam_16_num_attention_peaks_std": 2.1157538736312556,
    "attention_bam_16_num_attention_peaks_min": 1.0,
    "attention_bam_16_num_attention_peaks_max": 18.0,
    "attention_bam_16_peak_separation_mean_mean": 8.90619087288125,
    "attention_bam_16_peak_separation_mean_std": 1.1916363455964258,
    "attention_bam_16_peak_separation_mean_min": 0.0,
    "attention_bam_16_peak_separation_mean_max": 12.60121261607643,
    "attention_bam_16_peak_intensity_mean_mean": 0.33171449442655215,
    "attention_bam_16_peak_intensity_mean_std": 0.05200685927387288,
    "attention_bam_16_peak_intensity_mean_min": 0.20064692199230194,
    "attention_bam_16_peak_intensity_mean_max": 0.5501440763473511,
    "attention_bam_16_peak_coverage_mean": 0.1015625,
    "attention_bam_16_peak_coverage_std": 0.0,
    "attention_bam_16_peak_coverage_min": 0.1015625,
    "attention_bam_16_peak_coverage_max": 0.1015625
  },
  "metadata": {
    "created_at": "2025-10-04T09:12:28.549931",
    "total_batches": 403,
    "device": "cuda:0"
  }
}