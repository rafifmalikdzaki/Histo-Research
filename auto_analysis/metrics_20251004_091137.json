{
  "batch_metrics": [
    {
      "batch_idx": 0,
      "phase": "val",
      "loss": 0.39310094714164734,
      "timestamp": 1759543874.6647391,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.39310094714164734,
      "ssim": 0.00020899297669529915,
      "attention_bam_384_mean_attention": 0.0018816147930920124,
      "attention_bam_384_std_attention": 0.2580847144126892,
      "attention_bam_384_max_attention": 1.1563959121704102,
      "attention_bam_384_min_attention": -0.7739594578742981,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.29628766882657454,
      "attention_bam_384_attention_skewness": 0.35071835586104816,
      "attention_bam_384_attention_sparsity": 0.6638692220052084,
      "attention_bam_384_attention_concentration_10": 26.154394441386547,
      "attention_bam_384_attention_concentration_20": 39.71070953916689,
      "attention_bam_384_attention_center_y": 0.48400760045313507,
      "attention_bam_384_attention_center_x": 0.48398210923841173,
      "attention_bam_384_attention_center_distance": 0.03201030045834436,
      "attention_bam_384_attention_spatial_variance": 170.69224720301509,
      "attention_bam_384_attention_spatial_std": 13.064924309119249,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 17.863983381061118,
      "attention_bam_384_peak_intensity_mean": 0.40234407782554626,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": -0.04029373079538345,
      "attention_bam_16_std_attention": 0.15093879401683807,
      "attention_bam_16_max_attention": 0.3247266113758087,
      "attention_bam_16_min_attention": -0.4810439944267273,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.41239729777566936,
      "attention_bam_16_attention_skewness": -0.2805927456680973,
      "attention_bam_16_attention_sparsity": 0.830322265625,
      "attention_bam_16_attention_concentration_10": -0.5440104284007552,
      "attention_bam_16_attention_concentration_20": -0.882576852360917,
      "attention_bam_16_attention_center_y": 0.4711564547432987,
      "attention_bam_16_attention_center_x": 0.47221550214925223,
      "attention_bam_16_attention_center_distance": 0.05663794529806997,
      "attention_bam_16_attention_spatial_variance": 42.06734573472946,
      "attention_bam_16_attention_spatial_std": 6.485934453471563,
      "attention_bam_16_num_attention_peaks": 18,
      "attention_bam_16_peak_separation_mean": 8.800793652546577,
      "attention_bam_16_peak_intensity_mean": 0.5501440763473511,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 1,
      "phase": "val",
      "loss": 0.3988092541694641,
      "timestamp": 1759543877.1654897,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3988092541694641,
      "ssim": 0.00020980967383366078,
      "attention_bam_384_mean_attention": 0.003926893230527639,
      "attention_bam_384_std_attention": 0.2596164047718048,
      "attention_bam_384_max_attention": 1.0809073448181152,
      "attention_bam_384_min_attention": -0.7371022701263428,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.269354234067654,
      "attention_bam_384_attention_skewness": 0.341876143137591,
      "attention_bam_384_attention_sparsity": 0.6605555216471354,
      "attention_bam_384_attention_concentration_10": 12.632917790780986,
      "attention_bam_384_attention_concentration_20": 19.18165441550895,
      "attention_bam_384_attention_center_y": 0.4844054206493133,
      "attention_bam_384_attention_center_x": 0.4839248103666182,
      "attention_bam_384_attention_center_distance": 0.03167341556807693,
      "attention_bam_384_attention_spatial_variance": 170.61314475370582,
      "attention_bam_384_attention_spatial_std": 13.06189667520402,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 16.142337763011763,
      "attention_bam_384_peak_intensity_mean": 0.4080160856246948,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": -0.036860883235931396,
      "attention_bam_16_std_attention": 0.15095260739326477,
      "attention_bam_16_max_attention": 0.3069092631340027,
      "attention_bam_16_min_attention": -0.4374985098838806,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.32570253323161236,
      "attention_bam_16_attention_skewness": -0.16595645827933456,
      "attention_bam_16_attention_sparsity": 0.831298828125,
      "attention_bam_16_attention_concentration_10": -0.6226609355982947,
      "attention_bam_16_attention_concentration_20": -1.0122358604732702,
      "attention_bam_16_attention_center_y": 0.47149141224763363,
      "attention_bam_16_attention_center_x": 0.47264896803862655,
      "attention_bam_16_attention_center_distance": 0.0558716122013039,
      "attention_bam_16_attention_spatial_variance": 42.043367512307526,
      "attention_bam_16_attention_spatial_std": 6.48408571136344,
      "attention_bam_16_num_attention_peaks": 17,
      "attention_bam_16_peak_separation_mean": 8.3456757218609,
      "attention_bam_16_peak_intensity_mean": 0.5413674116134644,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 0,
      "phase": "train",
      "loss": 0.4267430305480957,
      "timestamp": 1759543879.178167,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.4267430305480957,
      "ssim": 0.013403704389929771,
      "attention_bam_384_mean_attention": 0.24239784479141235,
      "attention_bam_384_std_attention": 0.6487302780151367,
      "attention_bam_384_max_attention": 5.856725692749023,
      "attention_bam_384_min_attention": -1.6646728515625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.534694363536178,
      "attention_bam_384_attention_skewness": 0.8736138847268147,
      "attention_bam_384_attention_sparsity": 0.44314320882161456,
      "attention_bam_384_attention_concentration_10": 0.6289784835318324,
      "attention_bam_384_attention_concentration_20": 0.9852027202974504,
      "attention_bam_384_attention_center_y": 0.48145715175717607,
      "attention_bam_384_attention_center_x": 0.4796577473827837,
      "attention_bam_384_attention_center_distance": 0.03892671222949714,
      "attention_bam_384_attention_spatial_variance": 172.18567549909645,
      "attention_bam_384_attention_spatial_std": 13.121953951264135,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 16.118103884420577,
      "attention_bam_384_peak_intensity_mean": 0.25419673323631287,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24812737107276917,
      "attention_bam_16_std_attention": 0.6378040313720703,
      "attention_bam_16_max_attention": 2.6941933631896973,
      "attention_bam_16_min_attention": -1.4626561403274536,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.057724874247045754,
      "attention_bam_16_attention_skewness": 0.29631591064328877,
      "attention_bam_16_attention_sparsity": 0.42822265625,
      "attention_bam_16_attention_concentration_10": 0.5793263280121307,
      "attention_bam_16_attention_concentration_20": 0.9474033221807019,
      "attention_bam_16_attention_center_y": 0.47220440114735296,
      "attention_bam_16_attention_center_x": 0.47425617897689026,
      "attention_bam_16_attention_center_distance": 0.0535787203364765,
      "attention_bam_16_attention_spatial_variance": 42.152301583435985,
      "attention_bam_16_attention_spatial_std": 6.492480387605032,
      "attention_bam_16_num_attention_peaks": 16,
      "attention_bam_16_peak_separation_mean": 8.706385823308292,
      "attention_bam_16_peak_intensity_mean": 0.4145677089691162,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 1,
      "phase": "train",
      "loss": 0.4258974492549896,
      "timestamp": 1759543881.86557,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.4258974492549896,
      "ssim": 0.016951894387602806,
      "attention_bam_384_mean_attention": 0.23801599442958832,
      "attention_bam_384_std_attention": 0.6105653047561646,
      "attention_bam_384_max_attention": 6.410161972045898,
      "attention_bam_384_min_attention": -1.6058658361434937,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.8801130887282147,
      "attention_bam_384_attention_skewness": 0.8517456241730891,
      "attention_bam_384_attention_sparsity": 0.4327392578125,
      "attention_bam_384_attention_concentration_10": 0.602700960797322,
      "attention_bam_384_attention_concentration_20": 0.9465016636006941,
      "attention_bam_384_attention_center_y": 0.4831309653333237,
      "attention_bam_384_attention_center_x": 0.48135246804384146,
      "attention_bam_384_attention_center_distance": 0.035561067999751624,
      "attention_bam_384_attention_spatial_variance": 171.8650237608112,
      "attention_bam_384_attention_spatial_std": 13.109730117771731,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 18.838892293518576,
      "attention_bam_384_peak_intensity_mean": 0.23134875297546387,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.26207786798477173,
      "attention_bam_16_std_attention": 0.5612547993659973,
      "attention_bam_16_max_attention": 2.8337326049804688,
      "attention_bam_16_min_attention": -1.3532273769378662,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.35006465682651333,
      "attention_bam_16_attention_skewness": 0.23969473808477748,
      "attention_bam_16_attention_sparsity": 0.39111328125,
      "attention_bam_16_attention_concentration_10": 0.49805301963152987,
      "attention_bam_16_attention_concentration_20": 0.8111083920389983,
      "attention_bam_16_attention_center_y": 0.47047880310943996,
      "attention_bam_16_attention_center_x": 0.4703908916705262,
      "attention_bam_16_attention_center_distance": 0.05913037057076041,
      "attention_bam_16_attention_spatial_variance": 42.37733068420165,
      "attention_bam_16_attention_spatial_std": 6.509787299459304,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.661368812411373,
      "attention_bam_16_peak_intensity_mean": 0.3919750452041626,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 2,
      "phase": "train",
      "loss": 0.33748167753219604,
      "timestamp": 1759543881.9946542,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.33748167753219604,
      "ssim": 0.05069499462842941,
      "attention_bam_384_mean_attention": 0.23700594902038574,
      "attention_bam_384_std_attention": 0.5310591459274292,
      "attention_bam_384_max_attention": 6.873517036437988,
      "attention_bam_384_min_attention": -1.6581459045410156,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.437382566087492,
      "attention_bam_384_attention_skewness": 0.8839038748113122,
      "attention_bam_384_attention_sparsity": 0.42022959391276044,
      "attention_bam_384_attention_concentration_10": 0.5434455817384087,
      "attention_bam_384_attention_concentration_20": 0.8552389574897019,
      "attention_bam_384_attention_center_y": 0.4835491628551401,
      "attention_bam_384_attention_center_x": 0.48364742432732055,
      "attention_bam_384_attention_center_distance": 0.03280355998660541,
      "attention_bam_384_attention_spatial_variance": 170.34239707407292,
      "attention_bam_384_attention_spatial_std": 13.051528534009835,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 18.544440013949153,
      "attention_bam_384_peak_intensity_mean": 0.2235737442970276,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2488078773021698,
      "attention_bam_16_std_attention": 0.5053659081459045,
      "attention_bam_16_max_attention": 2.4671218395233154,
      "attention_bam_16_min_attention": -0.9959535598754883,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.21039486840208,
      "attention_bam_16_attention_skewness": 0.7890960858175331,
      "attention_bam_16_attention_sparsity": 0.41748046875,
      "attention_bam_16_attention_concentration_10": 0.51635614180398,
      "attention_bam_16_attention_concentration_20": 0.8131302024317816,
      "attention_bam_16_attention_center_y": 0.46112155971991997,
      "attention_bam_16_attention_center_x": 0.47599809430865186,
      "attention_bam_16_attention_center_distance": 0.06461616818456692,
      "attention_bam_16_attention_spatial_variance": 40.405388046731694,
      "attention_bam_16_attention_spatial_std": 6.3565232672217675,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 7.887368513961374,
      "attention_bam_16_peak_intensity_mean": 0.3847465515136719,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 3,
      "phase": "train",
      "loss": 0.3694000840187073,
      "timestamp": 1759543882.120746,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3694000840187073,
      "ssim": 0.03965817019343376,
      "attention_bam_384_mean_attention": 0.23552292585372925,
      "attention_bam_384_std_attention": 0.6589744091033936,
      "attention_bam_384_max_attention": 5.477872371673584,
      "attention_bam_384_min_attention": -1.6044543981552124,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8762540201223352,
      "attention_bam_384_attention_skewness": 0.8538069973476711,
      "attention_bam_384_attention_sparsity": 0.4516398111979167,
      "attention_bam_384_attention_concentration_10": 0.6602692180538312,
      "attention_bam_384_attention_concentration_20": 1.0320847607740138,
      "attention_bam_384_attention_center_y": 0.4835124320287507,
      "attention_bam_384_attention_center_x": 0.48053814288385477,
      "attention_bam_384_attention_center_distance": 0.03607225471233585,
      "attention_bam_384_attention_spatial_variance": 170.49564287395665,
      "attention_bam_384_attention_spatial_std": 13.05739801315548,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 17.120951669398693,
      "attention_bam_384_peak_intensity_mean": 0.2602115273475647,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22047415375709534,
      "attention_bam_16_std_attention": 0.6282044053077698,
      "attention_bam_16_max_attention": 3.381847858428955,
      "attention_bam_16_min_attention": -1.1512823104858398,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.4569991340566188,
      "attention_bam_16_attention_skewness": 0.9141609711832295,
      "attention_bam_16_attention_sparsity": 0.4697265625,
      "attention_bam_16_attention_concentration_10": 0.6871251039917099,
      "attention_bam_16_attention_concentration_20": 1.06797902372266,
      "attention_bam_16_attention_center_y": 0.46410635935593303,
      "attention_bam_16_attention_center_x": 0.46132778619777604,
      "attention_bam_16_attention_center_distance": 0.07461760595262136,
      "attention_bam_16_attention_spatial_variance": 41.189074232676774,
      "attention_bam_16_attention_spatial_std": 6.41787147212195,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.910703804257718,
      "attention_bam_16_peak_intensity_mean": 0.3195565640926361,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 4,
      "phase": "train",
      "loss": 0.2841787040233612,
      "timestamp": 1759543882.249333,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.2841787040233612,
      "ssim": 0.04546130448579788,
      "attention_bam_384_mean_attention": 0.2303868979215622,
      "attention_bam_384_std_attention": 0.6338685750961304,
      "attention_bam_384_max_attention": 4.968445301055908,
      "attention_bam_384_min_attention": -1.6243762969970703,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.9175126379528553,
      "attention_bam_384_attention_skewness": 0.8813600324128805,
      "attention_bam_384_attention_sparsity": 0.458160400390625,
      "attention_bam_384_attention_concentration_10": 0.6536228525755953,
      "attention_bam_384_attention_concentration_20": 1.02240777484709,
      "attention_bam_384_attention_center_y": 0.4816905937513723,
      "attention_bam_384_attention_center_x": 0.4876451887867133,
      "attention_bam_384_attention_center_distance": 0.03123702025780441,
      "attention_bam_384_attention_spatial_variance": 171.3986565666615,
      "attention_bam_384_attention_spatial_std": 13.091930971658133,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 17.036638592722543,
      "attention_bam_384_peak_intensity_mean": 0.28282609581947327,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23555819690227509,
      "attention_bam_16_std_attention": 0.6394479274749756,
      "attention_bam_16_max_attention": 3.883251667022705,
      "attention_bam_16_min_attention": -1.0876038074493408,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.470514919654436,
      "attention_bam_16_attention_skewness": 1.1381923226463966,
      "attention_bam_16_attention_sparsity": 0.476318359375,
      "attention_bam_16_attention_concentration_10": 0.6623125329233661,
      "attention_bam_16_attention_concentration_20": 1.0233418519820787,
      "attention_bam_16_attention_center_y": 0.4615513722101179,
      "attention_bam_16_attention_center_x": 0.4875011312058462,
      "attention_bam_16_attention_center_distance": 0.057175496500832715,
      "attention_bam_16_attention_spatial_variance": 42.27590186755082,
      "attention_bam_16_attention_spatial_std": 6.501992146069605,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.904307463219222,
      "attention_bam_16_peak_intensity_mean": 0.2717783749103546,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 5,
      "phase": "train",
      "loss": 0.3167078197002411,
      "timestamp": 1759543882.3743033,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3167078197002411,
      "ssim": 0.05054883658885956,
      "attention_bam_384_mean_attention": 0.23328012228012085,
      "attention_bam_384_std_attention": 0.6209129095077515,
      "attention_bam_384_max_attention": 4.539158821105957,
      "attention_bam_384_min_attention": -1.5950757265090942,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.081839269070775,
      "attention_bam_384_attention_skewness": 0.6767320896327925,
      "attention_bam_384_attention_sparsity": 0.44707489013671875,
      "attention_bam_384_attention_concentration_10": 0.6239182589633429,
      "attention_bam_384_attention_concentration_20": 0.9942715387713794,
      "attention_bam_384_attention_center_y": 0.48250350932976205,
      "attention_bam_384_attention_center_x": 0.4787702256864887,
      "attention_bam_384_attention_center_distance": 0.03890579656494256,
      "attention_bam_384_attention_spatial_variance": 170.2881742921341,
      "attention_bam_384_attention_spatial_std": 13.049451110760717,
      "attention_bam_384_num_attention_peaks": 18,
      "attention_bam_384_peak_separation_mean": 16.575853145951577,
      "attention_bam_384_peak_intensity_mean": 0.29979491233825684,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.25082606077194214,
      "attention_bam_16_std_attention": 0.6373257040977478,
      "attention_bam_16_max_attention": 3.089731216430664,
      "attention_bam_16_min_attention": -1.224957823753357,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6696717360298168,
      "attention_bam_16_attention_skewness": 0.7356083365628369,
      "attention_bam_16_attention_sparsity": 0.45361328125,
      "attention_bam_16_attention_concentration_10": 0.6174369909090285,
      "attention_bam_16_attention_concentration_20": 0.9765555065143628,
      "attention_bam_16_attention_center_y": 0.4692406954458638,
      "attention_bam_16_attention_center_x": 0.4579268037869964,
      "attention_bam_16_attention_center_distance": 0.07370601951309005,
      "attention_bam_16_attention_spatial_variance": 41.110453610452275,
      "attention_bam_16_attention_spatial_std": 6.41174341427137,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.50284960867109,
      "attention_bam_16_peak_intensity_mean": 0.3481826186180115,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 6,
      "phase": "train",
      "loss": 0.3431699275970459,
      "timestamp": 1759543882.5003688,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3431699275970459,
      "ssim": 0.0595417320728302,
      "attention_bam_384_mean_attention": 0.2292398363351822,
      "attention_bam_384_std_attention": 0.6126567721366882,
      "attention_bam_384_max_attention": 4.780694007873535,
      "attention_bam_384_min_attention": -1.5935810804367065,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1106878861842606,
      "attention_bam_384_attention_skewness": 0.6327801681825788,
      "attention_bam_384_attention_sparsity": 0.444976806640625,
      "attention_bam_384_attention_concentration_10": 0.6200170930555069,
      "attention_bam_384_attention_concentration_20": 0.9891956322830404,
      "attention_bam_384_attention_center_y": 0.48440284475299944,
      "attention_bam_384_attention_center_x": 0.4877753152872934,
      "attention_bam_384_attention_center_distance": 0.028025494397927026,
      "attention_bam_384_attention_spatial_variance": 171.97883619786361,
      "attention_bam_384_attention_spatial_std": 13.114070161390154,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 17.704303608796547,
      "attention_bam_384_peak_intensity_mean": 0.28822392225265503,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2242298126220703,
      "attention_bam_16_std_attention": 0.6087504625320435,
      "attention_bam_16_max_attention": 2.355156421661377,
      "attention_bam_16_min_attention": -1.2386834621429443,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.11594419740688666,
      "attention_bam_16_attention_skewness": 0.47741291848688544,
      "attention_bam_16_attention_sparsity": 0.4638671875,
      "attention_bam_16_attention_concentration_10": 0.6218324954636661,
      "attention_bam_16_attention_concentration_20": 1.0162044199283713,
      "attention_bam_16_attention_center_y": 0.47499854866071384,
      "attention_bam_16_attention_center_x": 0.48640738335096384,
      "attention_bam_16_attention_center_distance": 0.0402450443269317,
      "attention_bam_16_attention_spatial_variance": 42.888893088114585,
      "attention_bam_16_attention_spatial_std": 6.548961222065266,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.199931508556464,
      "attention_bam_16_peak_intensity_mean": 0.43915703892707825,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 7,
      "phase": "train",
      "loss": 0.3647286891937256,
      "timestamp": 1759543882.6266258,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3647286891937256,
      "ssim": 0.07457921653985977,
      "attention_bam_384_mean_attention": 0.24724024534225464,
      "attention_bam_384_std_attention": 0.5537768602371216,
      "attention_bam_384_max_attention": 5.831225395202637,
      "attention_bam_384_min_attention": -1.492278814315796,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5127739494927663,
      "attention_bam_384_attention_skewness": 0.579157955451498,
      "attention_bam_384_attention_sparsity": 0.40803273518880206,
      "attention_bam_384_attention_concentration_10": 0.5329632516337234,
      "attention_bam_384_attention_concentration_20": 0.848878363877663,
      "attention_bam_384_attention_center_y": 0.48004151507879855,
      "attention_bam_384_attention_center_x": 0.48552158005331,
      "attention_bam_384_attention_center_distance": 0.034870209764282664,
      "attention_bam_384_attention_spatial_variance": 170.54754252383495,
      "attention_bam_384_attention_spatial_std": 13.059385227637438,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 17.625875102183358,
      "attention_bam_384_peak_intensity_mean": 0.2399333119392395,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.26392143964767456,
      "attention_bam_16_std_attention": 0.5027231574058533,
      "attention_bam_16_max_attention": 2.8186798095703125,
      "attention_bam_16_min_attention": -1.115267038345337,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8858798948740518,
      "attention_bam_16_attention_skewness": 0.4400892100158408,
      "attention_bam_16_attention_sparsity": 0.3759765625,
      "attention_bam_16_attention_concentration_10": 0.45712043744341835,
      "attention_bam_16_attention_concentration_20": 0.7453255709734443,
      "attention_bam_16_attention_center_y": 0.45739053846664146,
      "attention_bam_16_attention_center_x": 0.4746216382737524,
      "attention_bam_16_attention_center_distance": 0.07013740023797616,
      "attention_bam_16_attention_spatial_variance": 41.36406140800173,
      "attention_bam_16_attention_spatial_std": 6.4314898280259865,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.612880260028183,
      "attention_bam_16_peak_intensity_mean": 0.36339637637138367,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 8,
      "phase": "train",
      "loss": 0.34880995750427246,
      "timestamp": 1759543882.7533433,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.34880995750427246,
      "ssim": 0.08510035276412964,
      "attention_bam_384_mean_attention": 0.2321234941482544,
      "attention_bam_384_std_attention": 0.5946976542472839,
      "attention_bam_384_max_attention": 4.739882469177246,
      "attention_bam_384_min_attention": -1.5611920356750488,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.001334573188144,
      "attention_bam_384_attention_skewness": 0.7939721453756098,
      "attention_bam_384_attention_sparsity": 0.4349314371744792,
      "attention_bam_384_attention_concentration_10": 0.6071412369839749,
      "attention_bam_384_attention_concentration_20": 0.9496737953898068,
      "attention_bam_384_attention_center_y": 0.4840661221728107,
      "attention_bam_384_attention_center_x": 0.4783472037658916,
      "attention_bam_384_attention_center_distance": 0.03801925952376276,
      "attention_bam_384_attention_spatial_variance": 172.20422518793748,
      "attention_bam_384_attention_spatial_std": 13.122660751080074,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 15.773369234384738,
      "attention_bam_384_peak_intensity_mean": 0.2878284454345703,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2522990107536316,
      "attention_bam_16_std_attention": 0.607127845287323,
      "attention_bam_16_max_attention": 2.6932742595672607,
      "attention_bam_16_min_attention": -1.2775815725326538,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.21938135286012184,
      "attention_bam_16_attention_skewness": 0.39832400593630485,
      "attention_bam_16_attention_sparsity": 0.4111328125,
      "attention_bam_16_attention_concentration_10": 0.550753802079542,
      "attention_bam_16_attention_concentration_20": 0.8952913799635778,
      "attention_bam_16_attention_center_y": 0.47189869478173546,
      "attention_bam_16_attention_center_x": 0.45458711918542427,
      "attention_bam_16_attention_center_distance": 0.07552500379144542,
      "attention_bam_16_attention_spatial_variance": 42.562479616131576,
      "attention_bam_16_attention_spatial_std": 6.523992613126687,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.336883473956902,
      "attention_bam_16_peak_intensity_mean": 0.4106374979019165,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 9,
      "phase": "train",
      "loss": 0.3215574622154236,
      "timestamp": 1759543882.8792298,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3215574622154236,
      "ssim": 0.11707844585180283,
      "attention_bam_384_mean_attention": 0.2436491996049881,
      "attention_bam_384_std_attention": 0.5774238109588623,
      "attention_bam_384_max_attention": 5.903816223144531,
      "attention_bam_384_min_attention": -1.5801115036010742,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.105912195538444,
      "attention_bam_384_attention_skewness": 0.6702603264680402,
      "attention_bam_384_attention_sparsity": 0.41610463460286456,
      "attention_bam_384_attention_concentration_10": 0.557890532587264,
      "attention_bam_384_attention_concentration_20": 0.887278641758147,
      "attention_bam_384_attention_center_y": 0.48574233106287523,
      "attention_bam_384_attention_center_x": 0.48389681282127645,
      "attention_bam_384_attention_center_distance": 0.030416895332484515,
      "attention_bam_384_attention_spatial_variance": 169.64268409988748,
      "attention_bam_384_attention_spatial_std": 13.024695163415053,
      "attention_bam_384_num_attention_peaks": 27,
      "attention_bam_384_peak_separation_mean": 16.44021374647472,
      "attention_bam_384_peak_intensity_mean": 0.24458596110343933,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2561837434768677,
      "attention_bam_16_std_attention": 0.4674566984176636,
      "attention_bam_16_max_attention": 2.612687587738037,
      "attention_bam_16_min_attention": -1.1911619901657104,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.492367459380072,
      "attention_bam_16_attention_skewness": 0.285479177845714,
      "attention_bam_16_attention_sparsity": 0.373291015625,
      "attention_bam_16_attention_concentration_10": 0.4354928397720274,
      "attention_bam_16_attention_concentration_20": 0.7196677563012349,
      "attention_bam_16_attention_center_y": 0.4762971678631048,
      "attention_bam_16_attention_center_x": 0.47395586595993117,
      "attention_bam_16_attention_center_distance": 0.04980203146874443,
      "attention_bam_16_attention_spatial_variance": 41.09223854302123,
      "attention_bam_16_attention_spatial_std": 6.410322811139953,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 8.487033192896051,
      "attention_bam_16_peak_intensity_mean": 0.3893619775772095,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 10,
      "phase": "train",
      "loss": 0.38763195276260376,
      "timestamp": 1759543883.0696948,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.38763195276260376,
      "ssim": 0.10068527609109879,
      "attention_bam_384_mean_attention": 0.24192099273204803,
      "attention_bam_384_std_attention": 0.520797073841095,
      "attention_bam_384_max_attention": 5.182400703430176,
      "attention_bam_384_min_attention": -1.5303912162780762,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.3522756766521784,
      "attention_bam_384_attention_skewness": 0.6291289146520442,
      "attention_bam_384_attention_sparsity": 0.39889272054036456,
      "attention_bam_384_attention_concentration_10": 0.5115074535888168,
      "attention_bam_384_attention_concentration_20": 0.8164498818275525,
      "attention_bam_384_attention_center_y": 0.48000354813973395,
      "attention_bam_384_attention_center_x": 0.483614752794765,
      "attention_bam_384_attention_center_distance": 0.03656048175220339,
      "attention_bam_384_attention_spatial_variance": 169.8854043228108,
      "attention_bam_384_attention_spatial_std": 13.0340095259598,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 17.11817919812654,
      "attention_bam_384_peak_intensity_mean": 0.2640001177787781,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.27161967754364014,
      "attention_bam_16_std_attention": 0.4287073612213135,
      "attention_bam_16_max_attention": 2.820946216583252,
      "attention_bam_16_min_attention": -0.8940313458442688,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.14366590756552,
      "attention_bam_16_attention_skewness": 0.40890267903522476,
      "attention_bam_16_attention_sparsity": 0.3388671875,
      "attention_bam_16_attention_concentration_10": 0.3956453907801618,
      "attention_bam_16_attention_concentration_20": 0.6460059881153832,
      "attention_bam_16_attention_center_y": 0.45746119858992706,
      "attention_bam_16_attention_center_x": 0.47613443509192327,
      "attention_bam_16_attention_center_distance": 0.06897992191626845,
      "attention_bam_16_attention_spatial_variance": 40.84303328243487,
      "attention_bam_16_attention_spatial_std": 6.390855442148169,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.102340382672143,
      "attention_bam_16_peak_intensity_mean": 0.32119429111480713,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 11,
      "phase": "train",
      "loss": 0.36072465777397156,
      "timestamp": 1759543883.1953259,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.36072465777397156,
      "ssim": 0.1153055727481842,
      "attention_bam_384_mean_attention": 0.24331124126911163,
      "attention_bam_384_std_attention": 0.5324074029922485,
      "attention_bam_384_max_attention": 4.447498798370361,
      "attention_bam_384_min_attention": -1.5496420860290527,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5914399228261482,
      "attention_bam_384_attention_skewness": 0.5342982535306167,
      "attention_bam_384_attention_sparsity": 0.4000905354817708,
      "attention_bam_384_attention_concentration_10": 0.5161232134947481,
      "attention_bam_384_attention_concentration_20": 0.8278675539690613,
      "attention_bam_384_attention_center_y": 0.48405214614557435,
      "attention_bam_384_attention_center_x": 0.48459361764633535,
      "attention_bam_384_attention_center_distance": 0.031358911326429324,
      "attention_bam_384_attention_spatial_variance": 170.16261703253406,
      "attention_bam_384_attention_spatial_std": 13.044639398332713,
      "attention_bam_384_num_attention_peaks": 23,
      "attention_bam_384_peak_separation_mean": 17.373226302864786,
      "attention_bam_384_peak_intensity_mean": 0.3019752502441406,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2840683162212372,
      "attention_bam_16_std_attention": 0.44030794501304626,
      "attention_bam_16_max_attention": 2.489126443862915,
      "attention_bam_16_min_attention": -1.0888934135437012,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7817367879798276,
      "attention_bam_16_attention_skewness": 0.27987445353659424,
      "attention_bam_16_attention_sparsity": 0.327392578125,
      "attention_bam_16_attention_concentration_10": 0.3849497327372972,
      "attention_bam_16_attention_concentration_20": 0.6365239188421787,
      "attention_bam_16_attention_center_y": 0.4701250232974842,
      "attention_bam_16_attention_center_x": 0.4734886352153608,
      "attention_bam_16_attention_center_distance": 0.056486577090846486,
      "attention_bam_16_attention_spatial_variance": 41.21738928309028,
      "attention_bam_16_attention_spatial_std": 6.42007704650733,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.163053014619617,
      "attention_bam_16_peak_intensity_mean": 0.39459094405174255,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 12,
      "phase": "train",
      "loss": 0.35813724994659424,
      "timestamp": 1759543883.3238165,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.35813724994659424,
      "ssim": 0.10156375169754028,
      "attention_bam_384_mean_attention": 0.24812430143356323,
      "attention_bam_384_std_attention": 0.5178822875022888,
      "attention_bam_384_max_attention": 5.037986755371094,
      "attention_bam_384_min_attention": -1.5095083713531494,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.6555095870230998,
      "attention_bam_384_attention_skewness": 0.4841366846496449,
      "attention_bam_384_attention_sparsity": 0.39477284749348956,
      "attention_bam_384_attention_concentration_10": 0.4924454928751976,
      "attention_bam_384_attention_concentration_20": 0.7968639160571246,
      "attention_bam_384_attention_center_y": 0.48346307279316636,
      "attention_bam_384_attention_center_x": 0.48358932139867844,
      "attention_bam_384_attention_center_distance": 0.032947847686912356,
      "attention_bam_384_attention_spatial_variance": 169.90669361103127,
      "attention_bam_384_attention_spatial_std": 13.034826182616754,
      "attention_bam_384_num_attention_peaks": 18,
      "attention_bam_384_peak_separation_mean": 18.13803428484876,
      "attention_bam_384_peak_intensity_mean": 0.26977038383483887,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.27662530541419983,
      "attention_bam_16_std_attention": 0.4218468964099884,
      "attention_bam_16_max_attention": 1.8904609680175781,
      "attention_bam_16_min_attention": -0.9937756061553955,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.38636291159957503,
      "attention_bam_16_attention_skewness": 0.09539915780083039,
      "attention_bam_16_attention_sparsity": 0.323974609375,
      "attention_bam_16_attention_concentration_10": 0.37742626727405143,
      "attention_bam_16_attention_concentration_20": 0.6274303881487461,
      "attention_bam_16_attention_center_y": 0.4698672816463975,
      "attention_bam_16_attention_center_x": 0.4723383461835007,
      "attention_bam_16_attention_center_distance": 0.05784717464563647,
      "attention_bam_16_attention_spatial_variance": 41.00717373499204,
      "attention_bam_16_attention_spatial_std": 6.403684387521924,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.311395103274617,
      "attention_bam_16_peak_intensity_mean": 0.45308810472488403,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 13,
      "phase": "train",
      "loss": 0.30160364508628845,
      "timestamp": 1759543883.4532905,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.30160364508628845,
      "ssim": 0.14988897740840912,
      "attention_bam_384_mean_attention": 0.24462682008743286,
      "attention_bam_384_std_attention": 0.505047082901001,
      "attention_bam_384_max_attention": 4.478602409362793,
      "attention_bam_384_min_attention": -1.5382227897644043,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.6244130012394713,
      "attention_bam_384_attention_skewness": 0.552588399993684,
      "attention_bam_384_attention_sparsity": 0.3999176025390625,
      "attention_bam_384_attention_concentration_10": 0.49416932636831123,
      "attention_bam_384_attention_concentration_20": 0.7942155559187902,
      "attention_bam_384_attention_center_y": 0.485339603252443,
      "attention_bam_384_attention_center_x": 0.48462274785504056,
      "attention_bam_384_attention_center_distance": 0.030046201634331048,
      "attention_bam_384_attention_spatial_variance": 169.76282785800362,
      "attention_bam_384_attention_spatial_std": 13.02930649950348,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 16.775108218075673,
      "attention_bam_384_peak_intensity_mean": 0.3006961941719055,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2739356756210327,
      "attention_bam_16_std_attention": 0.48051154613494873,
      "attention_bam_16_max_attention": 2.624657154083252,
      "attention_bam_16_min_attention": -1.0009033679962158,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.2632208449951339,
      "attention_bam_16_attention_skewness": 0.6284168797102117,
      "attention_bam_16_attention_sparsity": 0.364501953125,
      "attention_bam_16_attention_concentration_10": 0.44628975137758664,
      "attention_bam_16_attention_concentration_20": 0.7119617840096796,
      "attention_bam_16_attention_center_y": 0.4770072215283947,
      "attention_bam_16_attention_center_x": 0.4743550427360136,
      "attention_bam_16_attention_center_distance": 0.04870999271024387,
      "attention_bam_16_attention_spatial_variance": 41.273493308656256,
      "attention_bam_16_attention_spatial_std": 6.424444980592195,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.144120862044737,
      "attention_bam_16_peak_intensity_mean": 0.37458229064941406,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 14,
      "phase": "train",
      "loss": 0.341573566198349,
      "timestamp": 1759543883.581628,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.341573566198349,
      "ssim": 0.13122831284999847,
      "attention_bam_384_mean_attention": 0.24939437210559845,
      "attention_bam_384_std_attention": 0.5101507902145386,
      "attention_bam_384_max_attention": 5.507732391357422,
      "attention_bam_384_min_attention": -1.525538444519043,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.29832872509278,
      "attention_bam_384_attention_skewness": 0.5881572962306213,
      "attention_bam_384_attention_sparsity": 0.383392333984375,
      "attention_bam_384_attention_concentration_10": 0.4921117265740076,
      "attention_bam_384_attention_concentration_20": 0.7847028822306913,
      "attention_bam_384_attention_center_y": 0.4854532320544044,
      "attention_bam_384_attention_center_x": 0.48147876313613747,
      "attention_bam_384_attention_center_distance": 0.03330599563532994,
      "attention_bam_384_attention_spatial_variance": 170.4282227519543,
      "attention_bam_384_attention_spatial_std": 13.054816074995246,
      "attention_bam_384_num_attention_peaks": 19,
      "attention_bam_384_peak_separation_mean": 16.92599069821228,
      "attention_bam_384_peak_intensity_mean": 0.25287604331970215,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.28108105063438416,
      "attention_bam_16_std_attention": 0.3759230077266693,
      "attention_bam_16_max_attention": 1.9568712711334229,
      "attention_bam_16_min_attention": -0.9256015419960022,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.900098955844518,
      "attention_bam_16_attention_skewness": 0.14517596459879994,
      "attention_bam_16_attention_sparsity": 0.2958984375,
      "attention_bam_16_attention_concentration_10": 0.3404037156249144,
      "attention_bam_16_attention_concentration_20": 0.5686716821161197,
      "attention_bam_16_attention_center_y": 0.4778454861089005,
      "attention_bam_16_attention_center_x": 0.4674434641787734,
      "attention_bam_16_attention_center_distance": 0.05569112156223344,
      "attention_bam_16_attention_spatial_variance": 41.484764528823455,
      "attention_bam_16_attention_spatial_std": 6.440866752916369,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 7.918046226826746,
      "attention_bam_16_peak_intensity_mean": 0.42545974254608154,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 15,
      "phase": "train",
      "loss": 0.2972705662250519,
      "timestamp": 1759543883.7111256,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.2972705662250519,
      "ssim": 0.1321229338645935,
      "attention_bam_384_mean_attention": 0.23019124567508698,
      "attention_bam_384_std_attention": 0.5812958478927612,
      "attention_bam_384_max_attention": 4.507612228393555,
      "attention_bam_384_min_attention": -1.5198017358779907,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0820045325307666,
      "attention_bam_384_attention_skewness": 0.6004787296170498,
      "attention_bam_384_attention_sparsity": 0.43539683024088544,
      "attention_bam_384_attention_concentration_10": 0.5892610029168412,
      "attention_bam_384_attention_concentration_20": 0.9420739251701783,
      "attention_bam_384_attention_center_y": 0.4849998011329899,
      "attention_bam_384_attention_center_x": 0.4802051216846823,
      "attention_bam_384_attention_center_distance": 0.03512387147135363,
      "attention_bam_384_attention_spatial_variance": 169.10993625830812,
      "attention_bam_384_attention_spatial_std": 13.004227630209652,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 15.546397406952842,
      "attention_bam_384_peak_intensity_mean": 0.2916646897792816,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2505493462085724,
      "attention_bam_16_std_attention": 0.5893527865409851,
      "attention_bam_16_max_attention": 2.54319429397583,
      "attention_bam_16_min_attention": -1.0245498418807983,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.009594412390050877,
      "attention_bam_16_attention_skewness": 0.45949619741914255,
      "attention_bam_16_attention_sparsity": 0.427734375,
      "attention_bam_16_attention_concentration_10": 0.5466390612291792,
      "attention_bam_16_attention_concentration_20": 0.8919518175214005,
      "attention_bam_16_attention_center_y": 0.47530738773702885,
      "attention_bam_16_attention_center_x": 0.4594955921125957,
      "attention_bam_16_attention_center_distance": 0.06708699067149534,
      "attention_bam_16_attention_spatial_variance": 40.586950211197,
      "attention_bam_16_attention_spatial_std": 6.370788821739189,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 7.5354273289990505,
      "attention_bam_16_peak_intensity_mean": 0.3725915253162384,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 16,
      "phase": "train",
      "loss": 0.3406209945678711,
      "timestamp": 1759543883.8376465,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3406209945678711,
      "ssim": 0.13283100724220276,
      "attention_bam_384_mean_attention": 0.24769681692123413,
      "attention_bam_384_std_attention": 0.5169138312339783,
      "attention_bam_384_max_attention": 5.178227424621582,
      "attention_bam_384_min_attention": -1.477972149848938,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.0588064308560723,
      "attention_bam_384_attention_skewness": 0.6246698299528917,
      "attention_bam_384_attention_sparsity": 0.39482371012369794,
      "attention_bam_384_attention_concentration_10": 0.49839464043798887,
      "attention_bam_384_attention_concentration_20": 0.7987254981935877,
      "attention_bam_384_attention_center_y": 0.4813568885865073,
      "attention_bam_384_attention_center_x": 0.48198689947217555,
      "attention_bam_384_attention_center_distance": 0.03666162554501397,
      "attention_bam_384_attention_spatial_variance": 171.04658647888172,
      "attention_bam_384_attention_spatial_std": 13.078477987857827,
      "attention_bam_384_num_attention_peaks": 21,
      "attention_bam_384_peak_separation_mean": 17.82685500225831,
      "attention_bam_384_peak_intensity_mean": 0.262633740901947,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.26532644033432007,
      "attention_bam_16_std_attention": 0.44830161333084106,
      "attention_bam_16_max_attention": 2.6386399269104004,
      "attention_bam_16_min_attention": -1.0195412635803223,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.0130331849498742,
      "attention_bam_16_attention_skewness": 0.4117404905912027,
      "attention_bam_16_attention_sparsity": 0.363037109375,
      "attention_bam_16_attention_concentration_10": 0.41334526879579153,
      "attention_bam_16_attention_concentration_20": 0.6828478386364568,
      "attention_bam_16_attention_center_y": 0.4582589991037514,
      "attention_bam_16_attention_center_x": 0.46843980201747054,
      "attention_bam_16_attention_center_distance": 0.0740048275792476,
      "attention_bam_16_attention_spatial_variance": 41.9677828089898,
      "attention_bam_16_attention_spatial_std": 6.478254611312356,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.216136486028663,
      "attention_bam_16_peak_intensity_mean": 0.3671351969242096,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 17,
      "phase": "train",
      "loss": 0.25327640771865845,
      "timestamp": 1759543883.965058,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.25327640771865845,
      "ssim": 0.18626511096954346,
      "attention_bam_384_mean_attention": 0.24724841117858887,
      "attention_bam_384_std_attention": 0.5230613946914673,
      "attention_bam_384_max_attention": 5.113018035888672,
      "attention_bam_384_min_attention": -1.5443896055221558,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.9109137643319292,
      "attention_bam_384_attention_skewness": 0.5864068210501148,
      "attention_bam_384_attention_sparsity": 0.40058644612630206,
      "attention_bam_384_attention_concentration_10": 0.5068126115961492,
      "attention_bam_384_attention_concentration_20": 0.8097147958682658,
      "attention_bam_384_attention_center_y": 0.4857368260144303,
      "attention_bam_384_attention_center_x": 0.4858405925613969,
      "attention_bam_384_attention_center_distance": 0.028422770841527795,
      "attention_bam_384_attention_spatial_variance": 171.64787471398188,
      "attention_bam_384_attention_spatial_std": 13.101445520017318,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 16.667766326738025,
      "attention_bam_384_peak_intensity_mean": 0.2714223861694336,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.26922571659088135,
      "attention_bam_16_std_attention": 0.45761919021606445,
      "attention_bam_16_max_attention": 2.574228286743164,
      "attention_bam_16_min_attention": -1.1886112689971924,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7152834132218313,
      "attention_bam_16_attention_skewness": 0.3861988332908884,
      "attention_bam_16_attention_sparsity": 0.364990234375,
      "attention_bam_16_attention_concentration_10": 0.42120415894915175,
      "attention_bam_16_attention_concentration_20": 0.693256794871923,
      "attention_bam_16_attention_center_y": 0.4787025006577269,
      "attention_bam_16_attention_center_x": 0.4797755614931721,
      "attention_bam_16_attention_center_distance": 0.0415358012117399,
      "attention_bam_16_attention_spatial_variance": 42.6692391562414,
      "attention_bam_16_attention_spatial_std": 6.532169559667095,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 12.60121261607643,
      "attention_bam_16_peak_intensity_mean": 0.4154205620288849,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 18,
      "phase": "train",
      "loss": 0.2974157929420471,
      "timestamp": 1759543884.0907073,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.2974157929420471,
      "ssim": 0.17002645134925842,
      "attention_bam_384_mean_attention": 0.24347329139709473,
      "attention_bam_384_std_attention": 0.543117344379425,
      "attention_bam_384_max_attention": 4.7456793785095215,
      "attention_bam_384_min_attention": -1.5721999406814575,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4989398846542983,
      "attention_bam_384_attention_skewness": 0.5926946859594868,
      "attention_bam_384_attention_sparsity": 0.4093221028645833,
      "attention_bam_384_attention_concentration_10": 0.5335870868385457,
      "attention_bam_384_attention_concentration_20": 0.8481611357606481,
      "attention_bam_384_attention_center_y": 0.4825666858262354,
      "attention_bam_384_attention_center_x": 0.48204163493485436,
      "attention_bam_384_attention_center_distance": 0.03539557370333824,
      "attention_bam_384_attention_spatial_variance": 170.41996978900573,
      "attention_bam_384_attention_spatial_std": 13.054499982343472,
      "attention_bam_384_num_attention_peaks": 19,
      "attention_bam_384_peak_separation_mean": 17.09156051766111,
      "attention_bam_384_peak_intensity_mean": 0.2907749116420746,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.27091631293296814,
      "attention_bam_16_std_attention": 0.4776909649372101,
      "attention_bam_16_max_attention": 2.7158210277557373,
      "attention_bam_16_min_attention": -1.0187315940856934,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8961516080158192,
      "attention_bam_16_attention_skewness": 0.5140608176948319,
      "attention_bam_16_attention_sparsity": 0.372802734375,
      "attention_bam_16_attention_concentration_10": 0.4372712913951695,
      "attention_bam_16_attention_concentration_20": 0.7184015124390691,
      "attention_bam_16_attention_center_y": 0.46803501918187407,
      "attention_bam_16_attention_center_x": 0.4659490014471433,
      "attention_bam_16_attention_center_distance": 0.06604892885050911,
      "attention_bam_16_attention_spatial_variance": 41.15139821891463,
      "attention_bam_16_attention_spatial_std": 6.414935558438185,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.106464610164595,
      "attention_bam_16_peak_intensity_mean": 0.35517948865890503,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 19,
      "phase": "train",
      "loss": 0.30042576789855957,
      "timestamp": 1759543884.218199,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.30042576789855957,
      "ssim": 0.12989182770252228,
      "attention_bam_384_mean_attention": 0.2309279888868332,
      "attention_bam_384_std_attention": 0.601518988609314,
      "attention_bam_384_max_attention": 4.401276588439941,
      "attention_bam_384_min_attention": -1.5509144067764282,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8193421654043447,
      "attention_bam_384_attention_skewness": 0.576364447572193,
      "attention_bam_384_attention_sparsity": 0.44059499104817706,
      "attention_bam_384_attention_concentration_10": 0.607371634104973,
      "attention_bam_384_attention_concentration_20": 0.9716277727598361,
      "attention_bam_384_attention_center_y": 0.48476648958039964,
      "attention_bam_384_attention_center_x": 0.4839753292946488,
      "attention_bam_384_attention_center_distance": 0.03126819185431141,
      "attention_bam_384_attention_spatial_variance": 169.683155586202,
      "attention_bam_384_attention_spatial_std": 13.026248715044634,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 19.618445011341457,
      "attention_bam_384_peak_intensity_mean": 0.2991619408130646,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2587593197822571,
      "attention_bam_16_std_attention": 0.6484429240226746,
      "attention_bam_16_max_attention": 3.207200765609741,
      "attention_bam_16_min_attention": -1.2363499402999878,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7288747890062237,
      "attention_bam_16_attention_skewness": 0.7034970187815729,
      "attention_bam_16_attention_sparsity": 0.4423828125,
      "attention_bam_16_attention_concentration_10": 0.6016990224672865,
      "attention_bam_16_attention_concentration_20": 0.9568454879724596,
      "attention_bam_16_attention_center_y": 0.47288579703909545,
      "attention_bam_16_attention_center_x": 0.46926428317563557,
      "attention_bam_16_attention_center_distance": 0.057963165733293825,
      "attention_bam_16_attention_spatial_variance": 40.726513744909816,
      "attention_bam_16_attention_spatial_std": 6.381732816791206,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 7.302959822359776,
      "attention_bam_16_peak_intensity_mean": 0.3446008265018463,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 20,
      "phase": "train",
      "loss": 0.27689290046691895,
      "timestamp": 1759543884.3836858,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.27689290046691895,
      "ssim": 0.16104765236377716,
      "attention_bam_384_mean_attention": 0.24132554233074188,
      "attention_bam_384_std_attention": 0.507631242275238,
      "attention_bam_384_max_attention": 4.227688789367676,
      "attention_bam_384_min_attention": -1.548990249633789,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5139443252308,
      "attention_bam_384_attention_skewness": 0.5635329078315346,
      "attention_bam_384_attention_sparsity": 0.3985544840494792,
      "attention_bam_384_attention_concentration_10": 0.5042365946140157,
      "attention_bam_384_attention_concentration_20": 0.8089751028953451,
      "attention_bam_384_attention_center_y": 0.48646767277823644,
      "attention_bam_384_attention_center_x": 0.48413756933847096,
      "attention_bam_384_attention_center_distance": 0.029486966155530467,
      "attention_bam_384_attention_spatial_variance": 170.09996250977127,
      "attention_bam_384_attention_spatial_std": 13.042237634308435,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 17.7508214542985,
      "attention_bam_384_peak_intensity_mean": 0.31122544407844543,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.27319836616516113,
      "attention_bam_16_std_attention": 0.4694349765777588,
      "attention_bam_16_max_attention": 2.610577344894409,
      "attention_bam_16_min_attention": -0.9233575463294983,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5167063051073186,
      "attention_bam_16_attention_skewness": 0.4384630039831073,
      "attention_bam_16_attention_sparsity": 0.364990234375,
      "attention_bam_16_attention_concentration_10": 0.43035525409410713,
      "attention_bam_16_attention_concentration_20": 0.7046563461809464,
      "attention_bam_16_attention_center_y": 0.4828027185949577,
      "attention_bam_16_attention_center_x": 0.47606298977104106,
      "attention_bam_16_attention_center_distance": 0.04168277693305709,
      "attention_bam_16_attention_spatial_variance": 41.02404633843575,
      "attention_bam_16_attention_spatial_std": 6.405001665763699,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.620085563002856,
      "attention_bam_16_peak_intensity_mean": 0.340448260307312,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 21,
      "phase": "train",
      "loss": 0.29836198687553406,
      "timestamp": 1759543884.5192096,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.29836198687553406,
      "ssim": 0.12883025407791138,
      "attention_bam_384_mean_attention": 0.2312128096818924,
      "attention_bam_384_std_attention": 0.5849518775939941,
      "attention_bam_384_max_attention": 5.1537981033325195,
      "attention_bam_384_min_attention": -1.5392740964889526,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.120743428625123,
      "attention_bam_384_attention_skewness": 0.5775211500668797,
      "attention_bam_384_attention_sparsity": 0.43449656168619794,
      "attention_bam_384_attention_concentration_10": 0.5878649744330566,
      "attention_bam_384_attention_concentration_20": 0.940477199135574,
      "attention_bam_384_attention_center_y": 0.48120668183664195,
      "attention_bam_384_attention_center_x": 0.4823454692381788,
      "attention_bam_384_attention_center_distance": 0.03646563489120394,
      "attention_bam_384_attention_spatial_variance": 170.36095969889737,
      "attention_bam_384_attention_spatial_std": 13.052239643022855,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 16.27526214615358,
      "attention_bam_384_peak_intensity_mean": 0.26849067211151123,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23785558342933655,
      "attention_bam_16_std_attention": 0.5795230269432068,
      "attention_bam_16_max_attention": 2.4573287963867188,
      "attention_bam_16_min_attention": -0.9439109563827515,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.08069079695644232,
      "attention_bam_16_attention_skewness": 0.4652122244022203,
      "attention_bam_16_attention_sparsity": 0.438720703125,
      "attention_bam_16_attention_concentration_10": 0.5653230647462262,
      "attention_bam_16_attention_concentration_20": 0.9284275531037032,
      "attention_bam_16_attention_center_y": 0.4653557790583511,
      "attention_bam_16_attention_center_x": 0.4669125534842563,
      "attention_bam_16_attention_center_distance": 0.06774955588911238,
      "attention_bam_16_attention_spatial_variance": 41.25463494664093,
      "attention_bam_16_attention_spatial_std": 6.422977109303826,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.958949818581255,
      "attention_bam_16_peak_intensity_mean": 0.3622314929962158,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 22,
      "phase": "train",
      "loss": 0.2959652841091156,
      "timestamp": 1759543884.6464934,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.2959652841091156,
      "ssim": 0.13940651714801788,
      "attention_bam_384_mean_attention": 0.2311651110649109,
      "attention_bam_384_std_attention": 0.5790621638298035,
      "attention_bam_384_max_attention": 5.222625732421875,
      "attention_bam_384_min_attention": -1.5429470539093018,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4497406464740328,
      "attention_bam_384_attention_skewness": 0.6715887548826126,
      "attention_bam_384_attention_sparsity": 0.441009521484375,
      "attention_bam_384_attention_concentration_10": 0.585242693096004,
      "attention_bam_384_attention_concentration_20": 0.9368893867005028,
      "attention_bam_384_attention_center_y": 0.4862137083927066,
      "attention_bam_384_attention_center_x": 0.4863040389166058,
      "attention_bam_384_attention_center_distance": 0.02748240114251944,
      "attention_bam_384_attention_spatial_variance": 171.1626186065503,
      "attention_bam_384_attention_spatial_std": 13.082913230872943,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 19.210810940305862,
      "attention_bam_384_peak_intensity_mean": 0.26372361183166504,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24717825651168823,
      "attention_bam_16_std_attention": 0.6150215864181519,
      "attention_bam_16_max_attention": 3.127889394760132,
      "attention_bam_16_min_attention": -0.9996352195739746,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8437714795426032,
      "attention_bam_16_attention_skewness": 0.7702646273684834,
      "attention_bam_16_attention_sparsity": 0.456298828125,
      "attention_bam_16_attention_concentration_10": 0.5999311423746551,
      "attention_bam_16_attention_concentration_20": 0.9561645473954881,
      "attention_bam_16_attention_center_y": 0.4842440765734046,
      "attention_bam_16_attention_center_x": 0.4854250404870712,
      "attention_bam_16_attention_center_distance": 0.030353865250681036,
      "attention_bam_16_attention_spatial_variance": 42.47582281079355,
      "attention_bam_16_attention_spatial_std": 6.517347835645536,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.17011408891607,
      "attention_bam_16_peak_intensity_mean": 0.3068714141845703,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 23,
      "phase": "train",
      "loss": 0.292339950799942,
      "timestamp": 1759543884.7847028,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.292339950799942,
      "ssim": 0.1663302779197693,
      "attention_bam_384_mean_attention": 0.22213225066661835,
      "attention_bam_384_std_attention": 0.5884943008422852,
      "attention_bam_384_max_attention": 4.689919471740723,
      "attention_bam_384_min_attention": -1.5907788276672363,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.3482915341740638,
      "attention_bam_384_attention_skewness": 0.6861836554938453,
      "attention_bam_384_attention_sparsity": 0.4459075927734375,
      "attention_bam_384_attention_concentration_10": 0.616714676785363,
      "attention_bam_384_attention_concentration_20": 0.9794926460708904,
      "attention_bam_384_attention_center_y": 0.4795444094605786,
      "attention_bam_384_attention_center_x": 0.4807348863974725,
      "attention_bam_384_attention_center_distance": 0.03973854014517282,
      "attention_bam_384_attention_spatial_variance": 170.91987935498815,
      "attention_bam_384_attention_spatial_std": 13.0736329822658,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 14.737760244414646,
      "attention_bam_384_peak_intensity_mean": 0.2922031879425049,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23241651058197021,
      "attention_bam_16_std_attention": 0.5974450707435608,
      "attention_bam_16_max_attention": 2.544224977493286,
      "attention_bam_16_min_attention": -1.0452451705932617,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.19207946888771765,
      "attention_bam_16_attention_skewness": 0.5576885413135743,
      "attention_bam_16_attention_sparsity": 0.450927734375,
      "attention_bam_16_attention_concentration_10": 0.5949399405266972,
      "attention_bam_16_attention_concentration_20": 0.9736118156429332,
      "attention_bam_16_attention_center_y": 0.4554098355720841,
      "attention_bam_16_attention_center_x": 0.4610646514742628,
      "attention_bam_16_attention_center_distance": 0.08371671432311716,
      "attention_bam_16_attention_spatial_variance": 41.78035681378815,
      "attention_bam_16_attention_spatial_std": 6.463772645583085,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.538119646702851,
      "attention_bam_16_peak_intensity_mean": 0.3657669126987457,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 24,
      "phase": "train",
      "loss": 0.31093689799308777,
      "timestamp": 1759543884.925554,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.31093689799308777,
      "ssim": 0.143528014421463,
      "attention_bam_384_mean_attention": 0.21615241467952728,
      "attention_bam_384_std_attention": 0.5957567095756531,
      "attention_bam_384_max_attention": 4.934524059295654,
      "attention_bam_384_min_attention": -1.6253445148468018,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8319870392905502,
      "attention_bam_384_attention_skewness": 0.7971601442120995,
      "attention_bam_384_attention_sparsity": 0.45293426513671875,
      "attention_bam_384_attention_concentration_10": 0.6473613163043539,
      "attention_bam_384_attention_concentration_20": 1.0122639245311034,
      "attention_bam_384_attention_center_y": 0.48546375789580964,
      "attention_bam_384_attention_center_x": 0.47849990708065715,
      "attention_bam_384_attention_center_distance": 0.03670303339104311,
      "attention_bam_384_attention_spatial_variance": 171.94839136003833,
      "attention_bam_384_attention_spatial_std": 13.112909340037334,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 20.114357570110396,
      "attention_bam_384_peak_intensity_mean": 0.2813744843006134,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2205199897289276,
      "attention_bam_16_std_attention": 0.6211221218109131,
      "attention_bam_16_max_attention": 2.8261966705322266,
      "attention_bam_16_min_attention": -1.0182257890701294,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.3893197427401911,
      "attention_bam_16_attention_skewness": 0.6576204467635086,
      "attention_bam_16_attention_sparsity": 0.465087890625,
      "attention_bam_16_attention_concentration_10": 0.6537767877233728,
      "attention_bam_16_attention_concentration_20": 1.0469468362484797,
      "attention_bam_16_attention_center_y": 0.48200880084335357,
      "attention_bam_16_attention_center_x": 0.45289220089300253,
      "attention_bam_16_attention_center_distance": 0.07131378525641935,
      "attention_bam_16_attention_spatial_variance": 43.242565576568566,
      "attention_bam_16_attention_spatial_std": 6.5759079659442135,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 10.876919233871009,
      "attention_bam_16_peak_intensity_mean": 0.3275264799594879,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 25,
      "phase": "train",
      "loss": 0.29102063179016113,
      "timestamp": 1759543885.0572486,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.29102063179016113,
      "ssim": 0.1589268147945404,
      "attention_bam_384_mean_attention": 0.21622376143932343,
      "attention_bam_384_std_attention": 0.5595305562019348,
      "attention_bam_384_max_attention": 4.313748359680176,
      "attention_bam_384_min_attention": -1.5844690799713135,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2699847640940858,
      "attention_bam_384_attention_skewness": 0.6197716685217126,
      "attention_bam_384_attention_sparsity": 0.4427998860677083,
      "attention_bam_384_attention_concentration_10": 0.6053437696465799,
      "attention_bam_384_attention_concentration_20": 0.9615775136364202,
      "attention_bam_384_attention_center_y": 0.48640053160490376,
      "attention_bam_384_attention_center_x": 0.48373297289579975,
      "attention_bam_384_attention_center_distance": 0.029985386822184133,
      "attention_bam_384_attention_spatial_variance": 170.39530936598,
      "attention_bam_384_attention_spatial_std": 13.053555430072683,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 19.893386667887594,
      "attention_bam_384_peak_intensity_mean": 0.3065706491470337,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24058689177036285,
      "attention_bam_16_std_attention": 0.5700751543045044,
      "attention_bam_16_max_attention": 2.467022180557251,
      "attention_bam_16_min_attention": -1.0670111179351807,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.14906680630187585,
      "attention_bam_16_attention_skewness": 0.5375802712023859,
      "attention_bam_16_attention_sparsity": 0.439697265625,
      "attention_bam_16_attention_concentration_10": 0.5671934363378278,
      "attention_bam_16_attention_concentration_20": 0.9134217661495392,
      "attention_bam_16_attention_center_y": 0.4807716253088755,
      "attention_bam_16_attention_center_x": 0.4780575973532759,
      "attention_bam_16_attention_center_distance": 0.041260136383032976,
      "attention_bam_16_attention_spatial_variance": 41.35513353145004,
      "attention_bam_16_attention_spatial_std": 6.430795715263395,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.439655324762466,
      "attention_bam_16_peak_intensity_mean": 0.3724057674407959,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 26,
      "phase": "train",
      "loss": 0.3356815278530121,
      "timestamp": 1759543885.1894681,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3356815278530121,
      "ssim": 0.14035765826702118,
      "attention_bam_384_mean_attention": 0.227347269654274,
      "attention_bam_384_std_attention": 0.5898676514625549,
      "attention_bam_384_max_attention": 5.590204238891602,
      "attention_bam_384_min_attention": -1.6020255088806152,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.339068714768131,
      "attention_bam_384_attention_skewness": 0.60216228087812,
      "attention_bam_384_attention_sparsity": 0.4375864664713542,
      "attention_bam_384_attention_concentration_10": 0.5976692429965765,
      "attention_bam_384_attention_concentration_20": 0.960311159114173,
      "attention_bam_384_attention_center_y": 0.48598162057361116,
      "attention_bam_384_attention_center_x": 0.47967997260580614,
      "attention_bam_384_attention_center_distance": 0.03491184541220904,
      "attention_bam_384_attention_spatial_variance": 170.71576509162185,
      "attention_bam_384_attention_spatial_std": 13.065824317341093,
      "attention_bam_384_num_attention_peaks": 20,
      "attention_bam_384_peak_separation_mean": 16.704901066454127,
      "attention_bam_384_peak_intensity_mean": 0.25527212023735046,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2416812926530838,
      "attention_bam_16_std_attention": 0.5803108215332031,
      "attention_bam_16_max_attention": 2.499664545059204,
      "attention_bam_16_min_attention": -1.1769309043884277,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.05555342777076078,
      "attention_bam_16_attention_skewness": 0.45759787944555164,
      "attention_bam_16_attention_sparsity": 0.43603515625,
      "attention_bam_16_attention_concentration_10": 0.5637281114875413,
      "attention_bam_16_attention_concentration_20": 0.9169840575969072,
      "attention_bam_16_attention_center_y": 0.48155646543541486,
      "attention_bam_16_attention_center_x": 0.4628581148090053,
      "attention_bam_16_attention_center_distance": 0.05864611841846105,
      "attention_bam_16_attention_spatial_variance": 41.67606740880721,
      "attention_bam_16_attention_spatial_std": 6.4557003809662055,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 8.323418297636358,
      "attention_bam_16_peak_intensity_mean": 0.39098891615867615,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 27,
      "phase": "train",
      "loss": 0.30597537755966187,
      "timestamp": 1759543885.3223212,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.30597537755966187,
      "ssim": 0.19406452775001526,
      "attention_bam_384_mean_attention": 0.22170227766036987,
      "attention_bam_384_std_attention": 0.5370602011680603,
      "attention_bam_384_max_attention": 4.518752098083496,
      "attention_bam_384_min_attention": -1.622511863708496,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.030300890152077,
      "attention_bam_384_attention_skewness": 0.7326143373846111,
      "attention_bam_384_attention_sparsity": 0.43034617106119794,
      "attention_bam_384_attention_concentration_10": 0.5779879467400431,
      "attention_bam_384_attention_concentration_20": 0.9073373719970773,
      "attention_bam_384_attention_center_y": 0.48634152793768093,
      "attention_bam_384_attention_center_x": 0.48355151773063015,
      "attention_bam_384_attention_center_distance": 0.030235953037499073,
      "attention_bam_384_attention_spatial_variance": 169.91211528737205,
      "attention_bam_384_attention_spatial_std": 13.035034149835283,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 18.119759668156068,
      "attention_bam_384_peak_intensity_mean": 0.3020004332065582,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24427729845046997,
      "attention_bam_16_std_attention": 0.554815411567688,
      "attention_bam_16_max_attention": 2.8572299480438232,
      "attention_bam_16_min_attention": -1.0810456275939941,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.9075325760979345,
      "attention_bam_16_attention_skewness": 0.6976666796770126,
      "attention_bam_16_attention_sparsity": 0.42431640625,
      "attention_bam_16_attention_concentration_10": 0.5505929541829849,
      "attention_bam_16_attention_concentration_20": 0.8793044445489826,
      "attention_bam_16_attention_center_y": 0.481603383750984,
      "attention_bam_16_attention_center_x": 0.47110592959364544,
      "attention_bam_16_attention_center_distance": 0.048441775237101574,
      "attention_bam_16_attention_spatial_variance": 41.32756804565733,
      "attention_bam_16_attention_spatial_std": 6.428652117330454,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.802201120638433,
      "attention_bam_16_peak_intensity_mean": 0.34488141536712646,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 28,
      "phase": "train",
      "loss": 0.28691303730010986,
      "timestamp": 1759543885.455693,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.28691303730010986,
      "ssim": 0.16142484545707703,
      "attention_bam_384_mean_attention": 0.22218656539916992,
      "attention_bam_384_std_attention": 0.5818865895271301,
      "attention_bam_384_max_attention": 5.667741775512695,
      "attention_bam_384_min_attention": -1.6151950359344482,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4712806390457098,
      "attention_bam_384_attention_skewness": 0.5865356965658145,
      "attention_bam_384_attention_sparsity": 0.4362843831380208,
      "attention_bam_384_attention_concentration_10": 0.5963627343463729,
      "attention_bam_384_attention_concentration_20": 0.9615368519546756,
      "attention_bam_384_attention_center_y": 0.48809905793181046,
      "attention_bam_384_attention_center_x": 0.48121151050882155,
      "attention_bam_384_attention_center_distance": 0.03145281416568401,
      "attention_bam_384_attention_spatial_variance": 171.20730682282547,
      "attention_bam_384_attention_spatial_std": 13.084621004172245,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 17.64744371333968,
      "attention_bam_384_peak_intensity_mean": 0.2533702850341797,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2149694859981537,
      "attention_bam_16_std_attention": 0.6139112710952759,
      "attention_bam_16_max_attention": 2.321500539779663,
      "attention_bam_16_min_attention": -1.1593317985534668,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.4782488894355934,
      "attention_bam_16_attention_skewness": 0.2680721119903088,
      "attention_bam_16_attention_sparsity": 0.44677734375,
      "attention_bam_16_attention_concentration_10": 0.6182416241090584,
      "attention_bam_16_attention_concentration_20": 1.0271841305914984,
      "attention_bam_16_attention_center_y": 0.49191437181592323,
      "attention_bam_16_attention_center_x": 0.4599169502052379,
      "attention_bam_16_attention_center_distance": 0.057827817942241545,
      "attention_bam_16_attention_spatial_variance": 42.53204175496788,
      "attention_bam_16_attention_spatial_std": 6.521659432611295,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.95209736419586,
      "attention_bam_16_peak_intensity_mean": 0.4144841730594635,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 29,
      "phase": "train",
      "loss": 0.26490646600723267,
      "timestamp": 1759543885.5835576,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.26490646600723267,
      "ssim": 0.21171525120735168,
      "attention_bam_384_mean_attention": 0.2364654541015625,
      "attention_bam_384_std_attention": 0.5169011354446411,
      "attention_bam_384_max_attention": 4.945559501647949,
      "attention_bam_384_min_attention": -1.611642837524414,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.414296086998382,
      "attention_bam_384_attention_skewness": 0.5859224446227671,
      "attention_bam_384_attention_sparsity": 0.39877065022786456,
      "attention_bam_384_attention_concentration_10": 0.5123886545244766,
      "attention_bam_384_attention_concentration_20": 0.8210438243422575,
      "attention_bam_384_attention_center_y": 0.483482027909863,
      "attention_bam_384_attention_center_x": 0.48489862091947433,
      "attention_bam_384_attention_center_distance": 0.03165106797895714,
      "attention_bam_384_attention_spatial_variance": 170.84295331973493,
      "attention_bam_384_attention_spatial_std": 13.070690621376322,
      "attention_bam_384_num_attention_peaks": 22,
      "attention_bam_384_peak_separation_mean": 17.39973128916825,
      "attention_bam_384_peak_intensity_mean": 0.28293561935424805,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2639024555683136,
      "attention_bam_16_std_attention": 0.44963252544403076,
      "attention_bam_16_max_attention": 2.038027763366699,
      "attention_bam_16_min_attention": -1.0252678394317627,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.09694927010072796,
      "attention_bam_16_attention_skewness": 0.005952850582026436,
      "attention_bam_16_attention_sparsity": 0.3466796875,
      "attention_bam_16_attention_concentration_10": 0.3937613557443519,
      "attention_bam_16_attention_concentration_20": 0.6682494838786359,
      "attention_bam_16_attention_center_y": 0.4727337034620337,
      "attention_bam_16_attention_center_x": 0.47849725315696323,
      "attention_bam_16_attention_center_distance": 0.04910843203955999,
      "attention_bam_16_attention_spatial_variance": 42.12185141012284,
      "attention_bam_16_attention_spatial_std": 6.490134930039809,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 8.389349523664121,
      "attention_bam_16_peak_intensity_mean": 0.4294973313808441,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 30,
      "phase": "train",
      "loss": 0.3020942509174347,
      "timestamp": 1759543885.7526467,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3020942509174347,
      "ssim": 0.17036043107509613,
      "attention_bam_384_mean_attention": 0.2337094396352768,
      "attention_bam_384_std_attention": 0.4925580620765686,
      "attention_bam_384_max_attention": 5.252037048339844,
      "attention_bam_384_min_attention": -1.6291651725769043,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.58055299459581,
      "attention_bam_384_attention_skewness": 0.6557225003331142,
      "attention_bam_384_attention_sparsity": 0.40692138671875,
      "attention_bam_384_attention_concentration_10": 0.5011098802250347,
      "attention_bam_384_attention_concentration_20": 0.8057389534165675,
      "attention_bam_384_attention_center_y": 0.48699479627964976,
      "attention_bam_384_attention_center_x": 0.4842224047630533,
      "attention_bam_384_attention_center_distance": 0.02891601062625118,
      "attention_bam_384_attention_spatial_variance": 170.34436297489867,
      "attention_bam_384_attention_spatial_std": 13.051603846841916,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 15.722986467884713,
      "attention_bam_384_peak_intensity_mean": 0.2722119092941284,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2635646462440491,
      "attention_bam_16_std_attention": 0.43870529532432556,
      "attention_bam_16_max_attention": 2.2576403617858887,
      "attention_bam_16_min_attention": -0.9359070062637329,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.07531559353170358,
      "attention_bam_16_attention_skewness": 0.2891027923002997,
      "attention_bam_16_attention_sparsity": 0.375,
      "attention_bam_16_attention_concentration_10": 0.4084907531395052,
      "attention_bam_16_attention_concentration_20": 0.6878535401499556,
      "attention_bam_16_attention_center_y": 0.4857220578051647,
      "attention_bam_16_attention_center_x": 0.4730118542577001,
      "attention_bam_16_attention_center_distance": 0.04317915339435637,
      "attention_bam_16_attention_spatial_variance": 41.26727829845637,
      "attention_bam_16_attention_spatial_std": 6.423961262216356,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.668472886786978,
      "attention_bam_16_peak_intensity_mean": 0.38154563307762146,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 31,
      "phase": "train",
      "loss": 0.21787279844284058,
      "timestamp": 1759543885.8813806,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.21787279844284058,
      "ssim": 0.22583094239234924,
      "attention_bam_384_mean_attention": 0.22570741176605225,
      "attention_bam_384_std_attention": 0.5528326630592346,
      "attention_bam_384_max_attention": 5.928731918334961,
      "attention_bam_384_min_attention": -1.542466640472412,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.3347267171505077,
      "attention_bam_384_attention_skewness": 0.5428709865719916,
      "attention_bam_384_attention_sparsity": 0.42875417073567706,
      "attention_bam_384_attention_concentration_10": 0.5606651663443388,
      "attention_bam_384_attention_concentration_20": 0.9110173512392126,
      "attention_bam_384_attention_center_y": 0.4812839631393476,
      "attention_bam_384_attention_center_x": 0.4792057571724197,
      "attention_bam_384_attention_center_distance": 0.0395648978399205,
      "attention_bam_384_attention_spatial_variance": 170.12817197390828,
      "attention_bam_384_attention_spatial_std": 13.043319055129652,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 15.742029598686647,
      "attention_bam_384_peak_intensity_mean": 0.2377193719148636,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24231381714344025,
      "attention_bam_16_std_attention": 0.5490895509719849,
      "attention_bam_16_max_attention": 2.3561995029449463,
      "attention_bam_16_min_attention": -1.125166654586792,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.09091130172355255,
      "attention_bam_16_attention_skewness": 0.44658727505483714,
      "attention_bam_16_attention_sparsity": 0.423828125,
      "attention_bam_16_attention_concentration_10": 0.5329705520471741,
      "attention_bam_16_attention_concentration_20": 0.8752789811124312,
      "attention_bam_16_attention_center_y": 0.46327712327425835,
      "attention_bam_16_attention_center_x": 0.4557349659254822,
      "attention_bam_16_attention_center_distance": 0.08133834171695709,
      "attention_bam_16_attention_spatial_variance": 41.336798173426345,
      "attention_bam_16_attention_spatial_std": 6.4293699670672515,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.208000829755116,
      "attention_bam_16_peak_intensity_mean": 0.4094815254211426,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 32,
      "phase": "train",
      "loss": 0.2503387928009033,
      "timestamp": 1759543886.0137608,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.2503387928009033,
      "ssim": 0.21875518560409546,
      "attention_bam_384_mean_attention": 0.21799390017986298,
      "attention_bam_384_std_attention": 0.6210964322090149,
      "attention_bam_384_max_attention": 4.952032089233398,
      "attention_bam_384_min_attention": -1.6348559856414795,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.205084030827601,
      "attention_bam_384_attention_skewness": 1.1188193510331117,
      "attention_bam_384_attention_sparsity": 0.46062978108723956,
      "attention_bam_384_attention_concentration_10": 0.6864583021933593,
      "attention_bam_384_attention_concentration_20": 1.0397153953446803,
      "attention_bam_384_attention_center_y": 0.4788064751145566,
      "attention_bam_384_attention_center_x": 0.47484888282326265,
      "attention_bam_384_attention_center_distance": 0.046513314057544455,
      "attention_bam_384_attention_spatial_variance": 170.27144541609326,
      "attention_bam_384_attention_spatial_std": 13.048810114952753,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 14.056577568320922,
      "attention_bam_384_peak_intensity_mean": 0.2862311601638794,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2377633899450302,
      "attention_bam_16_std_attention": 0.7150695323944092,
      "attention_bam_16_max_attention": 4.082350730895996,
      "attention_bam_16_min_attention": -1.2297980785369873,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.7766449556298234,
      "attention_bam_16_attention_skewness": 1.2561722685461798,
      "attention_bam_16_attention_sparsity": 0.488525390625,
      "attention_bam_16_attention_concentration_10": 0.7412832176045877,
      "attention_bam_16_attention_concentration_20": 1.1219953132339848,
      "attention_bam_16_attention_center_y": 0.4527947378476442,
      "attention_bam_16_attention_center_x": 0.4481796290942535,
      "attention_bam_16_attention_center_distance": 0.09913311874123373,
      "attention_bam_16_attention_spatial_variance": 40.938194490122704,
      "attention_bam_16_attention_spatial_std": 6.39829621775381,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 7.117094512809319,
      "attention_bam_16_peak_intensity_mean": 0.29533472657203674,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 33,
      "phase": "train",
      "loss": 0.24428290128707886,
      "timestamp": 1759543886.142257,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.24428290128707886,
      "ssim": 0.22591455280780792,
      "attention_bam_384_mean_attention": 0.20671193301677704,
      "attention_bam_384_std_attention": 0.5395390391349792,
      "attention_bam_384_max_attention": 4.292047500610352,
      "attention_bam_384_min_attention": -1.6421823501586914,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.2235236804487464,
      "attention_bam_384_attention_skewness": 0.7403625595584061,
      "attention_bam_384_attention_sparsity": 0.442047119140625,
      "attention_bam_384_attention_concentration_10": 0.6093531217151787,
      "attention_bam_384_attention_concentration_20": 0.9571700797911041,
      "attention_bam_384_attention_center_y": 0.48439470860962647,
      "attention_bam_384_attention_center_x": 0.4839652162241953,
      "attention_bam_384_attention_center_distance": 0.0316429900646344,
      "attention_bam_384_attention_spatial_variance": 171.48831715284157,
      "attention_bam_384_attention_spatial_std": 13.095354792934844,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 20.844470961474045,
      "attention_bam_384_peak_intensity_mean": 0.31291463971138,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23821523785591125,
      "attention_bam_16_std_attention": 0.5911238193511963,
      "attention_bam_16_max_attention": 2.424424648284912,
      "attention_bam_16_min_attention": -1.1198607683181763,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.1093022154125256,
      "attention_bam_16_attention_skewness": 0.5050546361067412,
      "attention_bam_16_attention_sparsity": 0.450439453125,
      "attention_bam_16_attention_concentration_10": 0.5789782961083647,
      "attention_bam_16_attention_concentration_20": 0.9395937309936998,
      "attention_bam_16_attention_center_y": 0.474470198213707,
      "attention_bam_16_attention_center_x": 0.4726701302767751,
      "attention_bam_16_attention_center_distance": 0.052890312124922324,
      "attention_bam_16_attention_spatial_variance": 43.08416584503805,
      "attention_bam_16_attention_spatial_std": 6.56385297253359,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.267599191836704,
      "attention_bam_16_peak_intensity_mean": 0.38697630167007446,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 34,
      "phase": "train",
      "loss": 0.19831185042858124,
      "timestamp": 1759543886.2694435,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.19831185042858124,
      "ssim": 0.2389984279870987,
      "attention_bam_384_mean_attention": 0.21794486045837402,
      "attention_bam_384_std_attention": 0.5283489227294922,
      "attention_bam_384_max_attention": 5.722368240356445,
      "attention_bam_384_min_attention": -1.591370701789856,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.0797550918821397,
      "attention_bam_384_attention_skewness": 0.6207271984999225,
      "attention_bam_384_attention_sparsity": 0.42224375406901044,
      "attention_bam_384_attention_concentration_10": 0.567150817118343,
      "attention_bam_384_attention_concentration_20": 0.9005000581610331,
      "attention_bam_384_attention_center_y": 0.4852092474458066,
      "attention_bam_384_attention_center_x": 0.48064905961575505,
      "attention_bam_384_attention_center_distance": 0.03444489090921845,
      "attention_bam_384_attention_spatial_variance": 170.9346849415136,
      "attention_bam_384_attention_spatial_std": 13.074199208422426,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 16.75860867550525,
      "attention_bam_384_peak_intensity_mean": 0.24868886172771454,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23239950835704803,
      "attention_bam_16_std_attention": 0.5335832834243774,
      "attention_bam_16_max_attention": 2.5675549507141113,
      "attention_bam_16_min_attention": -1.03937828540802,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.34320456769434315,
      "attention_bam_16_attention_skewness": 0.4745627968568583,
      "attention_bam_16_attention_sparsity": 0.42431640625,
      "attention_bam_16_attention_concentration_10": 0.5390501335953277,
      "attention_bam_16_attention_concentration_20": 0.8754813633370876,
      "attention_bam_16_attention_center_y": 0.47871701708772085,
      "attention_bam_16_attention_center_x": 0.454767903667098,
      "attention_bam_16_attention_center_distance": 0.07069523180969549,
      "attention_bam_16_attention_spatial_variance": 41.94578602335785,
      "attention_bam_16_attention_spatial_std": 6.476556648664308,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 8.025132040137212,
      "attention_bam_16_peak_intensity_mean": 0.36239925026893616,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 35,
      "phase": "train",
      "loss": 0.2605200409889221,
      "timestamp": 1759543886.3977544,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.2605200409889221,
      "ssim": 0.2079371213912964,
      "attention_bam_384_mean_attention": 0.22766314446926117,
      "attention_bam_384_std_attention": 0.5356962084770203,
      "attention_bam_384_max_attention": 4.747298717498779,
      "attention_bam_384_min_attention": -1.6275405883789062,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9395882567154588,
      "attention_bam_384_attention_skewness": 0.45507969565399975,
      "attention_bam_384_attention_sparsity": 0.41879526774088544,
      "attention_bam_384_attention_concentration_10": 0.5459006510445943,
      "attention_bam_384_attention_concentration_20": 0.8830221087785798,
      "attention_bam_384_attention_center_y": 0.4862686858764546,
      "attention_bam_384_attention_center_x": 0.48233422334285947,
      "attention_bam_384_attention_center_distance": 0.03164265009317166,
      "attention_bam_384_attention_spatial_variance": 170.41019733365957,
      "attention_bam_384_attention_spatial_std": 13.054125682467577,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 18.029154310030584,
      "attention_bam_384_peak_intensity_mean": 0.2923210561275482,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.25620946288108826,
      "attention_bam_16_std_attention": 0.5473846197128296,
      "attention_bam_16_max_attention": 2.1846871376037598,
      "attention_bam_16_min_attention": -1.0939794778823853,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.023214624215838864,
      "attention_bam_16_attention_skewness": 0.30932232422143474,
      "attention_bam_16_attention_sparsity": 0.4013671875,
      "attention_bam_16_attention_concentration_10": 0.5029064333484746,
      "attention_bam_16_attention_concentration_20": 0.8201013543890812,
      "attention_bam_16_attention_center_y": 0.4803994421478508,
      "attention_bam_16_attention_center_x": 0.4669242776613444,
      "attention_bam_16_attention_center_distance": 0.05437251651964045,
      "attention_bam_16_attention_spatial_variance": 41.78859471078374,
      "attention_bam_16_attention_spatial_std": 6.464409850155213,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.219188280786781,
      "attention_bam_16_peak_intensity_mean": 0.41315728425979614,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 36,
      "phase": "train",
      "loss": 0.2320100963115692,
      "timestamp": 1759543886.5254416,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.2320100963115692,
      "ssim": 0.22538501024246216,
      "attention_bam_384_mean_attention": 0.2355656772851944,
      "attention_bam_384_std_attention": 0.5231867432594299,
      "attention_bam_384_max_attention": 5.290745258331299,
      "attention_bam_384_min_attention": -1.5880557298660278,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.934096465030395,
      "attention_bam_384_attention_skewness": 0.5720078421734823,
      "attention_bam_384_attention_sparsity": 0.4121042887369792,
      "attention_bam_384_attention_concentration_10": 0.5185422078471935,
      "attention_bam_384_attention_concentration_20": 0.8391722147910827,
      "attention_bam_384_attention_center_y": 0.4837810871668948,
      "attention_bam_384_attention_center_x": 0.4837501118437962,
      "attention_bam_384_attention_center_distance": 0.032468815764576275,
      "attention_bam_384_attention_spatial_variance": 168.8863494252955,
      "attention_bam_384_attention_spatial_std": 12.995628088911113,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 15.240854660552138,
      "attention_bam_384_peak_intensity_mean": 0.2668587565422058,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2751716077327728,
      "attention_bam_16_std_attention": 0.4861895442008972,
      "attention_bam_16_max_attention": 2.0748538970947266,
      "attention_bam_16_min_attention": -1.0498344898223877,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.26206878755058893,
      "attention_bam_16_attention_skewness": 0.331621166107437,
      "attention_bam_16_attention_sparsity": 0.376953125,
      "attention_bam_16_attention_concentration_10": 0.42759901277906104,
      "attention_bam_16_attention_concentration_20": 0.7112742922860809,
      "attention_bam_16_attention_center_y": 0.47371917707957906,
      "attention_bam_16_attention_center_x": 0.4730659323088918,
      "attention_bam_16_attention_center_distance": 0.05321889994661144,
      "attention_bam_16_attention_spatial_variance": 40.53969485761468,
      "attention_bam_16_attention_spatial_std": 6.367078989427937,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.313205955317857,
      "attention_bam_16_peak_intensity_mean": 0.4490419924259186,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 37,
      "phase": "train",
      "loss": 0.23838186264038086,
      "timestamp": 1759543886.6555977,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.23838186264038086,
      "ssim": 0.23413622379302979,
      "attention_bam_384_mean_attention": 0.2283911108970642,
      "attention_bam_384_std_attention": 0.5848062634468079,
      "attention_bam_384_max_attention": 5.267142295837402,
      "attention_bam_384_min_attention": -1.6233408451080322,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8046863275042213,
      "attention_bam_384_attention_skewness": 0.506774832000831,
      "attention_bam_384_attention_sparsity": 0.44130706787109375,
      "attention_bam_384_attention_concentration_10": 0.5817515348227293,
      "attention_bam_384_attention_concentration_20": 0.9485187904169526,
      "attention_bam_384_attention_center_y": 0.4839635119735641,
      "attention_bam_384_attention_center_x": 0.4903953521509151,
      "attention_bam_384_attention_center_distance": 0.026435514314155247,
      "attention_bam_384_attention_spatial_variance": 170.32333971593167,
      "attention_bam_384_attention_spatial_std": 13.050798432124054,
      "attention_bam_384_num_attention_peaks": 26,
      "attention_bam_384_peak_separation_mean": 15.345491187642198,
      "attention_bam_384_peak_intensity_mean": 0.2696146070957184,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.25875866413116455,
      "attention_bam_16_std_attention": 0.5958693027496338,
      "attention_bam_16_max_attention": 2.3669371604919434,
      "attention_bam_16_min_attention": -1.1310365200042725,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.3175069205350418,
      "attention_bam_16_attention_skewness": 0.3538629085854442,
      "attention_bam_16_attention_sparsity": 0.432861328125,
      "attention_bam_16_attention_concentration_10": 0.5277936078268659,
      "attention_bam_16_attention_concentration_20": 0.8838243017480677,
      "attention_bam_16_attention_center_y": 0.47539770240015905,
      "attention_bam_16_attention_center_x": 0.4951061975999892,
      "attention_bam_16_attention_center_distance": 0.035474564102226575,
      "attention_bam_16_attention_spatial_variance": 41.6719037635998,
      "attention_bam_16_attention_spatial_std": 6.455377894716916,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 7.70842382238601,
      "attention_bam_16_peak_intensity_mean": 0.403571754693985,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 38,
      "phase": "train",
      "loss": 0.2889630198478699,
      "timestamp": 1759543886.7836964,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.2889630198478699,
      "ssim": 0.22962580621242523,
      "attention_bam_384_mean_attention": 0.22620785236358643,
      "attention_bam_384_std_attention": 0.5495300889015198,
      "attention_bam_384_max_attention": 5.142239093780518,
      "attention_bam_384_min_attention": -1.6721932888031006,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.100240984508506,
      "attention_bam_384_attention_skewness": 0.6607252630975764,
      "attention_bam_384_attention_sparsity": 0.4318796793619792,
      "attention_bam_384_attention_concentration_10": 0.5650419036145086,
      "attention_bam_384_attention_concentration_20": 0.9045591139679983,
      "attention_bam_384_attention_center_y": 0.48682516881256205,
      "attention_bam_384_attention_center_x": 0.4805234815042005,
      "attention_bam_384_attention_center_distance": 0.03325390050910444,
      "attention_bam_384_attention_spatial_variance": 170.39489721039857,
      "attention_bam_384_attention_spatial_std": 13.053539642962692,
      "attention_bam_384_num_attention_peaks": 20,
      "attention_bam_384_peak_separation_mean": 17.357947814153626,
      "attention_bam_384_peak_intensity_mean": 0.2795321047306061,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.254856675863266,
      "attention_bam_16_std_attention": 0.5198972821235657,
      "attention_bam_16_max_attention": 1.9171342849731445,
      "attention_bam_16_min_attention": -1.152980089187622,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.3180335361915785,
      "attention_bam_16_attention_skewness": 0.29202979823748737,
      "attention_bam_16_attention_sparsity": 0.41015625,
      "attention_bam_16_attention_concentration_10": 0.4759074092890083,
      "attention_bam_16_attention_concentration_20": 0.7995046757998624,
      "attention_bam_16_attention_center_y": 0.4848417101890606,
      "attention_bam_16_attention_center_x": 0.4557425590369721,
      "attention_bam_16_attention_center_distance": 0.06615882149174562,
      "attention_bam_16_attention_spatial_variance": 41.47404772368933,
      "attention_bam_16_attention_spatial_std": 6.440034761062189,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 9.261856469282037,
      "attention_bam_16_peak_intensity_mean": 0.4676327705383301,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 39,
      "phase": "train",
      "loss": 0.2680726945400238,
      "timestamp": 1759543886.91344,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.2680726945400238,
      "ssim": 0.23713000118732452,
      "attention_bam_384_mean_attention": 0.21623878180980682,
      "attention_bam_384_std_attention": 0.6116053462028503,
      "attention_bam_384_max_attention": 5.754106521606445,
      "attention_bam_384_min_attention": -1.69685697555542,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8830247087667153,
      "attention_bam_384_attention_skewness": 0.7280841022993836,
      "attention_bam_384_attention_sparsity": 0.4540812174479167,
      "attention_bam_384_attention_concentration_10": 0.6487254188711962,
      "attention_bam_384_attention_concentration_20": 1.030744729665118,
      "attention_bam_384_attention_center_y": 0.4820419313136003,
      "attention_bam_384_attention_center_x": 0.4800221363635516,
      "attention_bam_384_attention_center_distance": 0.03798966350000948,
      "attention_bam_384_attention_spatial_variance": 170.02599887028435,
      "attention_bam_384_attention_spatial_std": 13.039401783451737,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 17.468626575240936,
      "attention_bam_384_peak_intensity_mean": 0.25783783197402954,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2260163426399231,
      "attention_bam_16_std_attention": 0.6412940621376038,
      "attention_bam_16_max_attention": 2.2788639068603516,
      "attention_bam_16_min_attention": -1.0855107307434082,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.3082457417641917,
      "attention_bam_16_attention_skewness": 0.4484007935795763,
      "attention_bam_16_attention_sparsity": 0.46630859375,
      "attention_bam_16_attention_concentration_10": 0.6507781667552349,
      "attention_bam_16_attention_concentration_20": 1.0649356197594573,
      "attention_bam_16_attention_center_y": 0.4618024711218646,
      "attention_bam_16_attention_center_x": 0.45360532005135995,
      "attention_bam_16_attention_center_distance": 0.0849884408603044,
      "attention_bam_16_attention_spatial_variance": 40.81019514557617,
      "attention_bam_16_attention_spatial_std": 6.38828577519636,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 6.482148793870536,
      "attention_bam_16_peak_intensity_mean": 0.40469643473625183,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 40,
      "phase": "train",
      "loss": 0.20632950961589813,
      "timestamp": 1759543887.080663,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.20632950961589813,
      "ssim": 0.2691352963447571,
      "attention_bam_384_mean_attention": 0.23177647590637207,
      "attention_bam_384_std_attention": 0.5208592414855957,
      "attention_bam_384_max_attention": 4.732554912567139,
      "attention_bam_384_min_attention": -1.5615198612213135,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2790315950493198,
      "attention_bam_384_attention_skewness": 0.4802896307652563,
      "attention_bam_384_attention_sparsity": 0.4076131184895833,
      "attention_bam_384_attention_concentration_10": 0.5248717349986035,
      "attention_bam_384_attention_concentration_20": 0.8434985254195739,
      "attention_bam_384_attention_center_y": 0.48926220670341414,
      "attention_bam_384_attention_center_x": 0.4798316144941069,
      "attention_bam_384_attention_center_distance": 0.032312968876119195,
      "attention_bam_384_attention_spatial_variance": 169.77427523916563,
      "attention_bam_384_attention_spatial_std": 13.029745785669252,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 16.568369997662728,
      "attention_bam_384_peak_intensity_mean": 0.2873612344264984,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2593216300010681,
      "attention_bam_16_std_attention": 0.5020548105239868,
      "attention_bam_16_max_attention": 2.2338013648986816,
      "attention_bam_16_min_attention": -1.142506718635559,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.08516063149162578,
      "attention_bam_16_attention_skewness": 0.2502222976065376,
      "attention_bam_16_attention_sparsity": 0.395263671875,
      "attention_bam_16_attention_concentration_10": 0.4521995910955556,
      "attention_bam_16_attention_concentration_20": 0.7513528298281597,
      "attention_bam_16_attention_center_y": 0.4849272172848713,
      "attention_bam_16_attention_center_x": 0.45888589608039126,
      "attention_bam_16_attention_center_distance": 0.061928318560895354,
      "attention_bam_16_attention_spatial_variance": 41.30650667652969,
      "attention_bam_16_attention_spatial_std": 6.427013822649652,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 7.397915805165652,
      "attention_bam_16_peak_intensity_mean": 0.43067213892936707,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 41,
      "phase": "train",
      "loss": 0.22675108909606934,
      "timestamp": 1759543887.2196364,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.22675108909606934,
      "ssim": 0.24016980826854706,
      "attention_bam_384_mean_attention": 0.21978534758090973,
      "attention_bam_384_std_attention": 0.5584614872932434,
      "attention_bam_384_max_attention": 5.049464225769043,
      "attention_bam_384_min_attention": -1.6354448795318604,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.3019204710211536,
      "attention_bam_384_attention_skewness": 0.5833373456615342,
      "attention_bam_384_attention_sparsity": 0.43923695882161456,
      "attention_bam_384_attention_concentration_10": 0.5853543146504449,
      "attention_bam_384_attention_concentration_20": 0.9432660477939969,
      "attention_bam_384_attention_center_y": 0.48152726607506086,
      "attention_bam_384_attention_center_x": 0.485198297963291,
      "attention_bam_384_attention_center_distance": 0.03347632840814872,
      "attention_bam_384_attention_spatial_variance": 172.19200921498052,
      "attention_bam_384_attention_spatial_std": 13.12219528946969,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 16.981791254298482,
      "attention_bam_384_peak_intensity_mean": 0.28114941716194153,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23281627893447876,
      "attention_bam_16_std_attention": 0.5845001935958862,
      "attention_bam_16_max_attention": 2.165127754211426,
      "attention_bam_16_min_attention": -1.1348919868469238,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.33028284613511616,
      "attention_bam_16_attention_skewness": 0.2572706171198683,
      "attention_bam_16_attention_sparsity": 0.437255859375,
      "attention_bam_16_attention_concentration_10": 0.5602849353334953,
      "attention_bam_16_attention_concentration_20": 0.9296787974533393,
      "attention_bam_16_attention_center_y": 0.46385771229616746,
      "attention_bam_16_attention_center_x": 0.46982657712571296,
      "attention_bam_16_attention_center_distance": 0.06658378794296932,
      "attention_bam_16_attention_spatial_variance": 43.33339766618157,
      "attention_bam_16_attention_spatial_std": 6.5828107724726195,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.397377393562788,
      "attention_bam_16_peak_intensity_mean": 0.4347938597202301,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 42,
      "phase": "train",
      "loss": 0.24152283370494843,
      "timestamp": 1759543887.3450298,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.24152283370494843,
      "ssim": 0.26487648487091064,
      "attention_bam_384_mean_attention": 0.2217838168144226,
      "attention_bam_384_std_attention": 0.5682394504547119,
      "attention_bam_384_max_attention": 4.584859848022461,
      "attention_bam_384_min_attention": -1.6161856651306152,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2081361029117277,
      "attention_bam_384_attention_skewness": 0.6081567239974875,
      "attention_bam_384_attention_sparsity": 0.4341684977213542,
      "attention_bam_384_attention_concentration_10": 0.6032547997826008,
      "attention_bam_384_attention_concentration_20": 0.9473665303649584,
      "attention_bam_384_attention_center_y": 0.48481826997242616,
      "attention_bam_384_attention_center_x": 0.47786747571475274,
      "attention_bam_384_attention_center_distance": 0.0379561209258058,
      "attention_bam_384_attention_spatial_variance": 170.66395072848212,
      "attention_bam_384_attention_spatial_std": 13.063841346574986,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 18.308330829943724,
      "attention_bam_384_peak_intensity_mean": 0.2970249354839325,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24293583631515503,
      "attention_bam_16_std_attention": 0.6057959794998169,
      "attention_bam_16_max_attention": 2.8300094604492188,
      "attention_bam_16_min_attention": -1.2900885343551636,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6205496236863866,
      "attention_bam_16_attention_skewness": 0.6054870643685979,
      "attention_bam_16_attention_sparsity": 0.42822265625,
      "attention_bam_16_attention_concentration_10": 0.5940121502854956,
      "attention_bam_16_attention_concentration_20": 0.9444184031111823,
      "attention_bam_16_attention_center_y": 0.4739802099584787,
      "attention_bam_16_attention_center_x": 0.45011550494164454,
      "attention_bam_16_attention_center_distance": 0.07956748482931882,
      "attention_bam_16_attention_spatial_variance": 41.82532734193377,
      "attention_bam_16_attention_spatial_std": 6.467250369510506,
      "attention_bam_16_num_attention_peaks": 2,
      "attention_bam_16_peak_separation_mean": 8.613516245204034,
      "attention_bam_16_peak_intensity_mean": 0.37644073367118835,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 43,
      "phase": "train",
      "loss": 0.2179861068725586,
      "timestamp": 1759543887.4716516,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.2179861068725586,
      "ssim": 0.2778950333595276,
      "attention_bam_384_mean_attention": 0.22322244942188263,
      "attention_bam_384_std_attention": 0.5780821442604065,
      "attention_bam_384_max_attention": 5.404193878173828,
      "attention_bam_384_min_attention": -1.6288421154022217,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.865460934159504,
      "attention_bam_384_attention_skewness": 0.7255545400844741,
      "attention_bam_384_attention_sparsity": 0.4413909912109375,
      "attention_bam_384_attention_concentration_10": 0.6098824279577494,
      "attention_bam_384_attention_concentration_20": 0.9615873534086644,
      "attention_bam_384_attention_center_y": 0.48502390602654916,
      "attention_bam_384_attention_center_x": 0.47499291477260164,
      "attention_bam_384_attention_center_distance": 0.04122226830905829,
      "attention_bam_384_attention_spatial_variance": 171.0321270984746,
      "attention_bam_384_attention_spatial_std": 13.077925183241973,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 16.69185212676989,
      "attention_bam_384_peak_intensity_mean": 0.2649221122264862,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24962781369686127,
      "attention_bam_16_std_attention": 0.5911195278167725,
      "attention_bam_16_max_attention": 2.4490230083465576,
      "attention_bam_16_min_attention": -1.1694793701171875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.15909614801518446,
      "attention_bam_16_attention_skewness": 0.5620629083512534,
      "attention_bam_16_attention_sparsity": 0.437744140625,
      "attention_bam_16_attention_concentration_10": 0.5727591398323626,
      "attention_bam_16_attention_concentration_20": 0.9166725116475363,
      "attention_bam_16_attention_center_y": 0.47580703411049174,
      "attention_bam_16_attention_center_x": 0.4446634812230204,
      "attention_bam_16_attention_center_distance": 0.08540995151486652,
      "attention_bam_16_attention_spatial_variance": 41.997759390571936,
      "attention_bam_16_attention_spatial_std": 6.480567829331928,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 7.301520674936229,
      "attention_bam_16_peak_intensity_mean": 0.38898035883903503,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 44,
      "phase": "train",
      "loss": 0.22746527194976807,
      "timestamp": 1759543887.6005228,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.22746527194976807,
      "ssim": 0.25375422835350037,
      "attention_bam_384_mean_attention": 0.2195112556219101,
      "attention_bam_384_std_attention": 0.5865639448165894,
      "attention_bam_384_max_attention": 5.658783912658691,
      "attention_bam_384_min_attention": -1.6080029010772705,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0966538632476865,
      "attention_bam_384_attention_skewness": 0.5686459151165985,
      "attention_bam_384_attention_sparsity": 0.44067637125651044,
      "attention_bam_384_attention_concentration_10": 0.6111120262792975,
      "attention_bam_384_attention_concentration_20": 0.9816468738399294,
      "attention_bam_384_attention_center_y": 0.4780488102653145,
      "attention_bam_384_attention_center_x": 0.4845986616311254,
      "attention_bam_384_attention_center_distance": 0.037922445973874924,
      "attention_bam_384_attention_spatial_variance": 170.23177320917696,
      "attention_bam_384_attention_spatial_std": 13.047289879863058,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 15.566248835057372,
      "attention_bam_384_peak_intensity_mean": 0.2543160319328308,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23721404373645782,
      "attention_bam_16_std_attention": 0.6194597482681274,
      "attention_bam_16_max_attention": 2.5603630542755127,
      "attention_bam_16_min_attention": -1.1490602493286133,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.05486194315063475,
      "attention_bam_16_attention_skewness": 0.45255541231017204,
      "attention_bam_16_attention_sparsity": 0.4501953125,
      "attention_bam_16_attention_concentration_10": 0.5975920219372115,
      "attention_bam_16_attention_concentration_20": 0.9770009293728614,
      "attention_bam_16_attention_center_y": 0.45180512317039034,
      "attention_bam_16_attention_center_x": 0.4741262204577075,
      "attention_bam_16_attention_center_distance": 0.07735888598505536,
      "attention_bam_16_attention_spatial_variance": 41.85293379010512,
      "attention_bam_16_attention_spatial_std": 6.469384343977804,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.171489906532212,
      "attention_bam_16_peak_intensity_mean": 0.3851636052131653,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 45,
      "phase": "train",
      "loss": 0.201954185962677,
      "timestamp": 1759543887.7226925,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.201954185962677,
      "ssim": 0.2877354919910431,
      "attention_bam_384_mean_attention": 0.2169194370508194,
      "attention_bam_384_std_attention": 0.5979010462760925,
      "attention_bam_384_max_attention": 5.1048359870910645,
      "attention_bam_384_min_attention": -1.6191970109939575,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5522961312372718,
      "attention_bam_384_attention_skewness": 0.6526588805385922,
      "attention_bam_384_attention_sparsity": 0.44954172770182294,
      "attention_bam_384_attention_concentration_10": 0.6273968752085859,
      "attention_bam_384_attention_concentration_20": 1.004224983291103,
      "attention_bam_384_attention_center_y": 0.4862991096966862,
      "attention_bam_384_attention_center_x": 0.4828867374573833,
      "attention_bam_384_attention_center_distance": 0.031002520863825416,
      "attention_bam_384_attention_spatial_variance": 170.09144581573838,
      "attention_bam_384_attention_spatial_std": 13.041911125894792,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 17.096335339941444,
      "attention_bam_384_peak_intensity_mean": 0.2746352255344391,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2521512508392334,
      "attention_bam_16_std_attention": 0.628609299659729,
      "attention_bam_16_max_attention": 2.6603214740753174,
      "attention_bam_16_min_attention": -1.2926708459854126,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.15761909490733528,
      "attention_bam_16_attention_skewness": 0.3853628763731341,
      "attention_bam_16_attention_sparsity": 0.43994140625,
      "attention_bam_16_attention_concentration_10": 0.5596551126601568,
      "attention_bam_16_attention_concentration_20": 0.9330217549283292,
      "attention_bam_16_attention_center_y": 0.47408689892320055,
      "attention_bam_16_attention_center_x": 0.47087479031127194,
      "attention_bam_16_attention_center_distance": 0.05513196254132087,
      "attention_bam_16_attention_spatial_variance": 41.19353380118267,
      "attention_bam_16_attention_spatial_std": 6.418218896328066,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.27745536108274,
      "attention_bam_16_peak_intensity_mean": 0.39888226985931396,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 46,
      "phase": "train",
      "loss": 0.1932862251996994,
      "timestamp": 1759543887.8502433,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.1932862251996994,
      "ssim": 0.32851600646972656,
      "attention_bam_384_mean_attention": 0.21869464218616486,
      "attention_bam_384_std_attention": 0.5682958960533142,
      "attention_bam_384_max_attention": 4.823041915893555,
      "attention_bam_384_min_attention": -1.6328338384628296,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.3402294018451864,
      "attention_bam_384_attention_skewness": 0.6173595917720495,
      "attention_bam_384_attention_sparsity": 0.4404551188151042,
      "attention_bam_384_attention_concentration_10": 0.6008157160244965,
      "attention_bam_384_attention_concentration_20": 0.959372548777232,
      "attention_bam_384_attention_center_y": 0.4837609212697618,
      "attention_bam_384_attention_center_x": 0.4867325267070155,
      "attention_bam_384_attention_center_distance": 0.02965580973728191,
      "attention_bam_384_attention_spatial_variance": 170.8427813087271,
      "attention_bam_384_attention_spatial_std": 13.070684041347151,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 17.41842648903043,
      "attention_bam_384_peak_intensity_mean": 0.288838654756546,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2435303032398224,
      "attention_bam_16_std_attention": 0.5995962023735046,
      "attention_bam_16_max_attention": 2.4487905502319336,
      "attention_bam_16_min_attention": -1.035926103591919,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.23308775087920308,
      "attention_bam_16_attention_skewness": 0.3137625767137986,
      "attention_bam_16_attention_sparsity": 0.42578125,
      "attention_bam_16_attention_concentration_10": 0.5571270024215027,
      "attention_bam_16_attention_concentration_20": 0.9213596220244091,
      "attention_bam_16_attention_center_y": 0.472918565175789,
      "attention_bam_16_attention_center_x": 0.4774437661107188,
      "attention_bam_16_attention_center_distance": 0.0498435111003618,
      "attention_bam_16_attention_spatial_variance": 42.5855168842801,
      "attention_bam_16_attention_spatial_std": 6.5257579547727715,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.018042342581968,
      "attention_bam_16_peak_intensity_mean": 0.38524129986763,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 47,
      "phase": "train",
      "loss": 0.21877416968345642,
      "timestamp": 1759543887.9779463,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.21877416968345642,
      "ssim": 0.2989337146282196,
      "attention_bam_384_mean_attention": 0.20950108766555786,
      "attention_bam_384_std_attention": 0.5510633587837219,
      "attention_bam_384_max_attention": 4.409530162811279,
      "attention_bam_384_min_attention": -1.6228246688842773,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0787332210096716,
      "attention_bam_384_attention_skewness": 0.5756811230451302,
      "attention_bam_384_attention_sparsity": 0.44528452555338544,
      "attention_bam_384_attention_concentration_10": 0.6031518696651136,
      "attention_bam_384_attention_concentration_20": 0.9682422221557196,
      "attention_bam_384_attention_center_y": 0.4843526070515367,
      "attention_bam_384_attention_center_x": 0.48569832223061804,
      "attention_bam_384_attention_center_distance": 0.02997928928786847,
      "attention_bam_384_attention_spatial_variance": 170.05204042900178,
      "attention_bam_384_attention_spatial_std": 13.040400317053223,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 18.974060618548283,
      "attention_bam_384_peak_intensity_mean": 0.30575141310691833,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23592066764831543,
      "attention_bam_16_std_attention": 0.6000331044197083,
      "attention_bam_16_max_attention": 2.7070281505584717,
      "attention_bam_16_min_attention": -1.1612765789031982,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5179661029994498,
      "attention_bam_16_attention_skewness": 0.5950583306905527,
      "attention_bam_16_attention_sparsity": 0.44140625,
      "attention_bam_16_attention_concentration_10": 0.5995556697457871,
      "attention_bam_16_attention_concentration_20": 0.9589542132827436,
      "attention_bam_16_attention_center_y": 0.47289446628346693,
      "attention_bam_16_attention_center_x": 0.47670036699212176,
      "attention_bam_16_attention_center_distance": 0.050548646991980306,
      "attention_bam_16_attention_spatial_variance": 41.4858907823962,
      "attention_bam_16_attention_spatial_std": 6.440954182603397,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.332167661314656,
      "attention_bam_16_peak_intensity_mean": 0.38060012459754944,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 48,
      "phase": "train",
      "loss": 0.17469635605812073,
      "timestamp": 1759543888.302214,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.17469635605812073,
      "ssim": 0.27606481313705444,
      "attention_bam_384_mean_attention": 0.22378522157669067,
      "attention_bam_384_std_attention": 0.5560377240180969,
      "attention_bam_384_max_attention": 4.513160705566406,
      "attention_bam_384_min_attention": -1.607234239578247,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1204240130612702,
      "attention_bam_384_attention_skewness": 0.5356035713556936,
      "attention_bam_384_attention_sparsity": 0.4262593587239583,
      "attention_bam_384_attention_concentration_10": 0.577190093753383,
      "attention_bam_384_attention_concentration_20": 0.9254882971769927,
      "attention_bam_384_attention_center_y": 0.4797906211581428,
      "attention_bam_384_attention_center_x": 0.4896435719403289,
      "attention_bam_384_attention_center_distance": 0.03211462580597344,
      "attention_bam_384_attention_spatial_variance": 169.13849657363141,
      "attention_bam_384_attention_spatial_std": 13.005325700405638,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 15.775449188604838,
      "attention_bam_384_peak_intensity_mean": 0.30079203844070435,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2581324875354767,
      "attention_bam_16_std_attention": 0.5643094778060913,
      "attention_bam_16_max_attention": 2.714266777038574,
      "attention_bam_16_min_attention": -1.1618061065673828,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.1762964713309576,
      "attention_bam_16_attention_skewness": 0.3497533222159321,
      "attention_bam_16_attention_sparsity": 0.388427734375,
      "attention_bam_16_attention_concentration_10": 0.5170010606672418,
      "attention_bam_16_attention_concentration_20": 0.833755085289804,
      "attention_bam_16_attention_center_y": 0.4587763999722974,
      "attention_bam_16_attention_center_x": 0.489127025181608,
      "attention_bam_16_attention_center_distance": 0.06029273224270712,
      "attention_bam_16_attention_spatial_variance": 40.99498165833969,
      "attention_bam_16_attention_spatial_std": 6.402732358793369,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.895055189776379,
      "attention_bam_16_peak_intensity_mean": 0.3825609087944031,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 49,
      "phase": "train",
      "loss": 0.18336626887321472,
      "timestamp": 1759543888.4286363,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.18336626887321472,
      "ssim": 0.3371489346027374,
      "attention_bam_384_mean_attention": 0.215324267745018,
      "attention_bam_384_std_attention": 0.5656055212020874,
      "attention_bam_384_max_attention": 5.282240867614746,
      "attention_bam_384_min_attention": -1.6547415256500244,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0641128553029287,
      "attention_bam_384_attention_skewness": 0.535067956861508,
      "attention_bam_384_attention_sparsity": 0.4379221598307292,
      "attention_bam_384_attention_concentration_10": 0.598693809759909,
      "attention_bam_384_attention_concentration_20": 0.9666028304170667,
      "attention_bam_384_attention_center_y": 0.4855280568536936,
      "attention_bam_384_attention_center_x": 0.48172219389920706,
      "attention_bam_384_attention_center_distance": 0.03297014814307355,
      "attention_bam_384_attention_spatial_variance": 170.45858626207894,
      "attention_bam_384_attention_spatial_std": 13.055978946907004,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 17.76112786755904,
      "attention_bam_384_peak_intensity_mean": 0.26997968554496765,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2338845133781433,
      "attention_bam_16_std_attention": 0.5859747529029846,
      "attention_bam_16_max_attention": 2.2361364364624023,
      "attention_bam_16_min_attention": -1.1390143632888794,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.03309594343779931,
      "attention_bam_16_attention_skewness": 0.420212264862497,
      "attention_bam_16_attention_sparsity": 0.434326171875,
      "attention_bam_16_attention_concentration_10": 0.5795238244444825,
      "attention_bam_16_attention_concentration_20": 0.9409940567154358,
      "attention_bam_16_attention_center_y": 0.4786856836454099,
      "attention_bam_16_attention_center_x": 0.4663322608924569,
      "attention_bam_16_attention_center_distance": 0.05635275926300564,
      "attention_bam_16_attention_spatial_variance": 41.988458015365254,
      "attention_bam_16_attention_spatial_std": 6.4798501537740245,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.216190348293198,
      "attention_bam_16_peak_intensity_mean": 0.4079855978488922,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 50,
      "phase": "train",
      "loss": 0.21537809073925018,
      "timestamp": 1759543888.6206334,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.21537809073925018,
      "ssim": 0.2911420464515686,
      "attention_bam_384_mean_attention": 0.20731614530086517,
      "attention_bam_384_std_attention": 0.6580814123153687,
      "attention_bam_384_max_attention": 5.832986354827881,
      "attention_bam_384_min_attention": -1.7347540855407715,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.213193756606766,
      "attention_bam_384_attention_skewness": 0.9077229977440746,
      "attention_bam_384_attention_sparsity": 0.4718983968098958,
      "attention_bam_384_attention_concentration_10": 0.7299575458980953,
      "attention_bam_384_attention_concentration_20": 1.1404837940983767,
      "attention_bam_384_attention_center_y": 0.48057263448985926,
      "attention_bam_384_attention_center_x": 0.477998579928088,
      "attention_bam_384_attention_center_distance": 0.04150867417408894,
      "attention_bam_384_attention_spatial_variance": 171.70246334060968,
      "attention_bam_384_attention_spatial_std": 13.103528659891948,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 20.560977110878117,
      "attention_bam_384_peak_intensity_mean": 0.2599378228187561,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2300647497177124,
      "attention_bam_16_std_attention": 0.7584808468818665,
      "attention_bam_16_max_attention": 4.281631946563721,
      "attention_bam_16_min_attention": -1.3536972999572754,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.4607218287773867,
      "attention_bam_16_attention_skewness": 0.9059022734949265,
      "attention_bam_16_attention_sparsity": 0.487060546875,
      "attention_bam_16_attention_concentration_10": 0.7491192653720682,
      "attention_bam_16_attention_concentration_20": 1.1860208930489509,
      "attention_bam_16_attention_center_y": 0.46003511975035294,
      "attention_bam_16_attention_center_x": 0.4528982051502863,
      "attention_bam_16_attention_center_distance": 0.08735869426030986,
      "attention_bam_16_attention_spatial_variance": 42.32526619468175,
      "attention_bam_16_attention_spatial_std": 6.505787131061218,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.117053105867818,
      "attention_bam_16_peak_intensity_mean": 0.2868344187736511,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 51,
      "phase": "train",
      "loss": 0.13767674565315247,
      "timestamp": 1759543888.7611783,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.13767674565315247,
      "ssim": 0.36909326910972595,
      "attention_bam_384_mean_attention": 0.2092844843864441,
      "attention_bam_384_std_attention": 0.5707380175590515,
      "attention_bam_384_max_attention": 5.160214900970459,
      "attention_bam_384_min_attention": -1.6421761512756348,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9481463046287657,
      "attention_bam_384_attention_skewness": 0.5745269329246484,
      "attention_bam_384_attention_sparsity": 0.4488423665364583,
      "attention_bam_384_attention_concentration_10": 0.6246584155722152,
      "attention_bam_384_attention_concentration_20": 1.0026669810879796,
      "attention_bam_384_attention_center_y": 0.4803689960370547,
      "attention_bam_384_attention_center_x": 0.47817234918432155,
      "attention_bam_384_attention_center_distance": 0.041516807601846326,
      "attention_bam_384_attention_spatial_variance": 169.83037028826223,
      "attention_bam_384_attention_spatial_std": 13.031898184388268,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 15.709390432273542,
      "attention_bam_384_peak_intensity_mean": 0.27702271938323975,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23479336500167847,
      "attention_bam_16_std_attention": 0.6376686692237854,
      "attention_bam_16_max_attention": 2.549048900604248,
      "attention_bam_16_min_attention": -1.0491633415222168,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.3050355837177774,
      "attention_bam_16_attention_skewness": 0.388929624689484,
      "attention_bam_16_attention_sparsity": 0.44091796875,
      "attention_bam_16_attention_concentration_10": 0.6099573032794438,
      "attention_bam_16_attention_concentration_20": 1.0032888832822537,
      "attention_bam_16_attention_center_y": 0.45939444066208807,
      "attention_bam_16_attention_center_x": 0.4505031157131625,
      "attention_bam_16_attention_center_distance": 0.09054007955871554,
      "attention_bam_16_attention_spatial_variance": 41.0253228944342,
      "attention_bam_16_attention_spatial_std": 6.405101318045968,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.509321923966093,
      "attention_bam_16_peak_intensity_mean": 0.37643739581108093,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 52,
      "phase": "train",
      "loss": 0.1911657303571701,
      "timestamp": 1759543888.9060936,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.1911657303571701,
      "ssim": 0.3318321704864502,
      "attention_bam_384_mean_attention": 0.2109827846288681,
      "attention_bam_384_std_attention": 0.5515671968460083,
      "attention_bam_384_max_attention": 4.708316326141357,
      "attention_bam_384_min_attention": -1.63358473777771,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.127975480915782,
      "attention_bam_384_attention_skewness": 0.5842638868644643,
      "attention_bam_384_attention_sparsity": 0.4411366780598958,
      "attention_bam_384_attention_concentration_10": 0.6028478278454034,
      "attention_bam_384_attention_concentration_20": 0.9648249274349581,
      "attention_bam_384_attention_center_y": 0.4795636911494219,
      "attention_bam_384_attention_center_x": 0.48770021830031496,
      "attention_bam_384_attention_center_distance": 0.03373210190000394,
      "attention_bam_384_attention_spatial_variance": 170.10844452215312,
      "attention_bam_384_attention_spatial_std": 13.042562804991706,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 14.467713764645,
      "attention_bam_384_peak_intensity_mean": 0.2959420382976532,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23898504674434662,
      "attention_bam_16_std_attention": 0.6141867637634277,
      "attention_bam_16_max_attention": 2.8625926971435547,
      "attention_bam_16_min_attention": -1.2333275079727173,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.3976137383948024,
      "attention_bam_16_attention_skewness": 0.5558567528795305,
      "attention_bam_16_attention_sparsity": 0.43359375,
      "attention_bam_16_attention_concentration_10": 0.5940827465183606,
      "attention_bam_16_attention_concentration_20": 0.9590198038749106,
      "attention_bam_16_attention_center_y": 0.45907597416897605,
      "attention_bam_16_attention_center_x": 0.4808985996586693,
      "attention_bam_16_attention_center_distance": 0.06386923179776163,
      "attention_bam_16_attention_spatial_variance": 41.89676368156782,
      "attention_bam_16_attention_spatial_std": 6.472770943079001,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.102292807192809,
      "attention_bam_16_peak_intensity_mean": 0.3672121465206146,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 53,
      "phase": "train",
      "loss": 0.17484644055366516,
      "timestamp": 1759543889.0375593,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.17484644055366516,
      "ssim": 0.3378574848175049,
      "attention_bam_384_mean_attention": 0.2175879031419754,
      "attention_bam_384_std_attention": 0.5948794484138489,
      "attention_bam_384_max_attention": 5.534738063812256,
      "attention_bam_384_min_attention": -1.6719194650650024,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.652872923481624,
      "attention_bam_384_attention_skewness": 0.6576921766996981,
      "attention_bam_384_attention_sparsity": 0.44371795654296875,
      "attention_bam_384_attention_concentration_10": 0.6272122194850447,
      "attention_bam_384_attention_concentration_20": 0.9965733642645845,
      "attention_bam_384_attention_center_y": 0.48089116467265935,
      "attention_bam_384_attention_center_x": 0.48005694535051563,
      "attention_bam_384_attention_center_distance": 0.03906079918075773,
      "attention_bam_384_attention_spatial_variance": 171.57673865167703,
      "attention_bam_384_attention_spatial_std": 13.098730421368211,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 16.519796138346923,
      "attention_bam_384_peak_intensity_mean": 0.2632811963558197,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24614375829696655,
      "attention_bam_16_std_attention": 0.6506559252738953,
      "attention_bam_16_max_attention": 2.6810526847839355,
      "attention_bam_16_min_attention": -1.1628999710083008,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.22848471522390001,
      "attention_bam_16_attention_skewness": 0.5294834685478591,
      "attention_bam_16_attention_sparsity": 0.437255859375,
      "attention_bam_16_attention_concentration_10": 0.6168889678787188,
      "attention_bam_16_attention_concentration_20": 0.9871863109394101,
      "attention_bam_16_attention_center_y": 0.461945979955498,
      "attention_bam_16_attention_center_x": 0.45410969974331283,
      "attention_bam_16_attention_center_distance": 0.08430928892116527,
      "attention_bam_16_attention_spatial_variance": 42.62939621288438,
      "attention_bam_16_attention_spatial_std": 6.529119099303089,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 10.699570967526961,
      "attention_bam_16_peak_intensity_mean": 0.3839751183986664,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 54,
      "phase": "train",
      "loss": 0.16401001811027527,
      "timestamp": 1759543889.1686745,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.16401001811027527,
      "ssim": 0.31631478667259216,
      "attention_bam_384_mean_attention": 0.23395782709121704,
      "attention_bam_384_std_attention": 0.5039607882499695,
      "attention_bam_384_max_attention": 6.086740493774414,
      "attention_bam_384_min_attention": -1.6212210655212402,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.0766687422668424,
      "attention_bam_384_attention_skewness": 0.5616832261984743,
      "attention_bam_384_attention_sparsity": 0.41947174072265625,
      "attention_bam_384_attention_concentration_10": 0.504112018165145,
      "attention_bam_384_attention_concentration_20": 0.8257395471590374,
      "attention_bam_384_attention_center_y": 0.4791364060388429,
      "attention_bam_384_attention_center_x": 0.4868435576721526,
      "attention_bam_384_attention_center_distance": 0.034882130889669176,
      "attention_bam_384_attention_spatial_variance": 169.2634755568226,
      "attention_bam_384_attention_spatial_std": 13.010129728669988,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 15.465894495919565,
      "attention_bam_384_peak_intensity_mean": 0.24441561102867126,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.27353519201278687,
      "attention_bam_16_std_attention": 0.4792853593826294,
      "attention_bam_16_max_attention": 1.6352365016937256,
      "attention_bam_16_min_attention": -0.8757575154304504,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.40416626056661187,
      "attention_bam_16_attention_skewness": 0.21304086389064555,
      "attention_bam_16_attention_sparsity": 0.384765625,
      "attention_bam_16_attention_concentration_10": 0.41969438190805974,
      "attention_bam_16_attention_concentration_20": 0.7147328083360643,
      "attention_bam_16_attention_center_y": 0.4519503565213673,
      "attention_bam_16_attention_center_x": 0.48032684416101146,
      "attention_bam_16_attention_center_distance": 0.07342753297079836,
      "attention_bam_16_attention_spatial_variance": 40.3827107328896,
      "attention_bam_16_attention_spatial_std": 6.354739234059066,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 6.148782730323421,
      "attention_bam_16_peak_intensity_mean": 0.496286004781723,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 55,
      "phase": "train",
      "loss": 0.1858994960784912,
      "timestamp": 1759543889.300625,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.1858994960784912,
      "ssim": 0.31313443183898926,
      "attention_bam_384_mean_attention": 0.20454515516757965,
      "attention_bam_384_std_attention": 0.5623360872268677,
      "attention_bam_384_max_attention": 5.570217132568359,
      "attention_bam_384_min_attention": -1.6638240814208984,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.6426724350377961,
      "attention_bam_384_attention_skewness": 0.6752236489242972,
      "attention_bam_384_attention_sparsity": 0.4576873779296875,
      "attention_bam_384_attention_concentration_10": 0.633029806912825,
      "attention_bam_384_attention_concentration_20": 1.008295309562341,
      "attention_bam_384_attention_center_y": 0.47944301495727487,
      "attention_bam_384_attention_center_x": 0.48220184886255374,
      "attention_bam_384_attention_center_distance": 0.03845422780288805,
      "attention_bam_384_attention_spatial_variance": 170.85489298074754,
      "attention_bam_384_attention_spatial_std": 13.071147347526441,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 17.896189509667522,
      "attention_bam_384_peak_intensity_mean": 0.2598431408405304,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22502174973487854,
      "attention_bam_16_std_attention": 0.5784091353416443,
      "attention_bam_16_max_attention": 2.2579104900360107,
      "attention_bam_16_min_attention": -0.9883726835250854,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.1614880399019598,
      "attention_bam_16_attention_skewness": 0.47720182960122653,
      "attention_bam_16_attention_sparsity": 0.4599609375,
      "attention_bam_16_attention_concentration_10": 0.5920221993857476,
      "attention_bam_16_attention_concentration_20": 0.9775325452842145,
      "attention_bam_16_attention_center_y": 0.45880016915858174,
      "attention_bam_16_attention_center_x": 0.4624593813061813,
      "attention_bam_16_attention_center_distance": 0.07882542880665055,
      "attention_bam_16_attention_spatial_variance": 42.06900358790179,
      "attention_bam_16_attention_spatial_std": 6.486062255937865,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.982078222408571,
      "attention_bam_16_peak_intensity_mean": 0.3836973011493683,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 56,
      "phase": "train",
      "loss": 0.19472068548202515,
      "timestamp": 1759543889.4296877,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.19472068548202515,
      "ssim": 0.3355256915092468,
      "attention_bam_384_mean_attention": 0.20474748313426971,
      "attention_bam_384_std_attention": 0.5514143109321594,
      "attention_bam_384_max_attention": 5.652107238769531,
      "attention_bam_384_min_attention": -1.6282145977020264,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5781041221772334,
      "attention_bam_384_attention_skewness": 0.5481704004420285,
      "attention_bam_384_attention_sparsity": 0.44143931070963544,
      "attention_bam_384_attention_concentration_10": 0.6033133701001786,
      "attention_bam_384_attention_concentration_20": 0.9764761319392598,
      "attention_bam_384_attention_center_y": 0.4820507336232506,
      "attention_bam_384_attention_center_x": 0.4903309078354736,
      "attention_bam_384_attention_center_distance": 0.02883288077003791,
      "attention_bam_384_attention_spatial_variance": 171.64253383852682,
      "attention_bam_384_attention_spatial_std": 13.101241690714923,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 16.81544479486104,
      "attention_bam_384_peak_intensity_mean": 0.2522509694099426,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22686001658439636,
      "attention_bam_16_std_attention": 0.5776309370994568,
      "attention_bam_16_max_attention": 2.5307321548461914,
      "attention_bam_16_min_attention": -1.0157206058502197,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.11742333394801063,
      "attention_bam_16_attention_skewness": 0.3350767083932012,
      "attention_bam_16_attention_sparsity": 0.43896484375,
      "attention_bam_16_attention_concentration_10": 0.5694800253060069,
      "attention_bam_16_attention_concentration_20": 0.9422146857314481,
      "attention_bam_16_attention_center_y": 0.4623605270969322,
      "attention_bam_16_attention_center_x": 0.48952103722545515,
      "attention_bam_16_attention_center_distance": 0.05525465738290432,
      "attention_bam_16_attention_spatial_variance": 42.458639761598015,
      "attention_bam_16_attention_spatial_std": 6.516029447569894,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 8.612837140765828,
      "attention_bam_16_peak_intensity_mean": 0.35801127552986145,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 57,
      "phase": "train",
      "loss": 0.1658623218536377,
      "timestamp": 1759543889.5602407,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.1658623218536377,
      "ssim": 0.30894070863723755,
      "attention_bam_384_mean_attention": 0.20077712833881378,
      "attention_bam_384_std_attention": 0.5312519669532776,
      "attention_bam_384_max_attention": 4.970900058746338,
      "attention_bam_384_min_attention": -1.5987014770507812,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2797566999736496,
      "attention_bam_384_attention_skewness": 0.5393340044945065,
      "attention_bam_384_attention_sparsity": 0.4481862386067708,
      "attention_bam_384_attention_concentration_10": 0.5994962715145651,
      "attention_bam_384_attention_concentration_20": 0.970308677184175,
      "attention_bam_384_attention_center_y": 0.4865006821157008,
      "attention_bam_384_attention_center_x": 0.4875777459524826,
      "attention_bam_384_attention_center_distance": 0.02594393875117742,
      "attention_bam_384_attention_spatial_variance": 169.1463825080124,
      "attention_bam_384_attention_spatial_std": 13.005628877836411,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 18.734084003308435,
      "attention_bam_384_peak_intensity_mean": 0.2763108015060425,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23564758896827698,
      "attention_bam_16_std_attention": 0.5902009010314941,
      "attention_bam_16_max_attention": 2.2332983016967773,
      "attention_bam_16_min_attention": -1.0402394533157349,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.26716999627326876,
      "attention_bam_16_attention_skewness": 0.38223889809699557,
      "attention_bam_16_attention_sparsity": 0.44921875,
      "attention_bam_16_attention_concentration_10": 0.5689336097568721,
      "attention_bam_16_attention_concentration_20": 0.9454054820295219,
      "attention_bam_16_attention_center_y": 0.48713415956758865,
      "attention_bam_16_attention_center_x": 0.4833300569840824,
      "attention_bam_16_attention_center_distance": 0.029779753195290627,
      "attention_bam_16_attention_spatial_variance": 40.85366632796779,
      "attention_bam_16_attention_spatial_std": 6.391687283336677,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 6.91432551545319,
      "attention_bam_16_peak_intensity_mean": 0.4088817536830902,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 58,
      "phase": "train",
      "loss": 0.15661858022212982,
      "timestamp": 1759543889.6880462,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.15661858022212982,
      "ssim": 0.33754152059555054,
      "attention_bam_384_mean_attention": 0.20382829010486603,
      "attention_bam_384_std_attention": 0.5030319094657898,
      "attention_bam_384_max_attention": 4.762381553649902,
      "attention_bam_384_min_attention": -1.5881736278533936,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9367608424708096,
      "attention_bam_384_attention_skewness": 0.46972788383129643,
      "attention_bam_384_attention_sparsity": 0.4392140706380208,
      "attention_bam_384_attention_concentration_10": 0.5678074910512134,
      "attention_bam_384_attention_concentration_20": 0.9194860246802299,
      "attention_bam_384_attention_center_y": 0.4813510598570135,
      "attention_bam_384_attention_center_x": 0.48638804088985627,
      "attention_bam_384_attention_center_distance": 0.032651750313663706,
      "attention_bam_384_attention_spatial_variance": 169.63169409282068,
      "attention_bam_384_attention_spatial_std": 13.024273265438678,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 17.724423323795268,
      "attention_bam_384_peak_intensity_mean": 0.28303343057632446,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24619464576244354,
      "attention_bam_16_std_attention": 0.5641090869903564,
      "attention_bam_16_max_attention": 2.074225902557373,
      "attention_bam_16_min_attention": -1.0279585123062134,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.23594817546170654,
      "attention_bam_16_attention_skewness": 0.36868502487163696,
      "attention_bam_16_attention_sparsity": 0.434326171875,
      "attention_bam_16_attention_concentration_10": 0.5337495943952832,
      "attention_bam_16_attention_concentration_20": 0.8823487185936482,
      "attention_bam_16_attention_center_y": 0.4604516279182991,
      "attention_bam_16_attention_center_x": 0.48040637146745746,
      "attention_bam_16_attention_center_distance": 0.06241769001467334,
      "attention_bam_16_attention_spatial_variance": 41.0473038277435,
      "attention_bam_16_attention_spatial_std": 6.406816980977644,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 8.333721114302994,
      "attention_bam_16_peak_intensity_mean": 0.42081424593925476,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 59,
      "phase": "train",
      "loss": 0.1549050658941269,
      "timestamp": 1759543889.8172648,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.1549050658941269,
      "ssim": 0.35179415345191956,
      "attention_bam_384_mean_attention": 0.2145875096321106,
      "attention_bam_384_std_attention": 0.5446670651435852,
      "attention_bam_384_max_attention": 5.145356178283691,
      "attention_bam_384_min_attention": -1.6404484510421753,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.575800354003336,
      "attention_bam_384_attention_skewness": 0.5627826580166607,
      "attention_bam_384_attention_sparsity": 0.44131215413411456,
      "attention_bam_384_attention_concentration_10": 0.5808617214893045,
      "attention_bam_384_attention_concentration_20": 0.9399623704103393,
      "attention_bam_384_attention_center_y": 0.48277953085630215,
      "attention_bam_384_attention_center_x": 0.4804489081159582,
      "attention_bam_384_attention_center_distance": 0.03684534574101036,
      "attention_bam_384_attention_spatial_variance": 169.69928132415924,
      "attention_bam_384_attention_spatial_std": 13.026867671246194,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 16.835845771390712,
      "attention_bam_384_peak_intensity_mean": 0.2748323082923889,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24927473068237305,
      "attention_bam_16_std_attention": 0.550190806388855,
      "attention_bam_16_max_attention": 2.1488146781921387,
      "attention_bam_16_min_attention": -1.1727216243743896,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.2244003686824474,
      "attention_bam_16_attention_skewness": 0.30066948862904463,
      "attention_bam_16_attention_sparsity": 0.41259765625,
      "attention_bam_16_attention_concentration_10": 0.5097199134554978,
      "attention_bam_16_attention_concentration_20": 0.8432352510691812,
      "attention_bam_16_attention_center_y": 0.4672889943401844,
      "attention_bam_16_attention_center_x": 0.46249260398662995,
      "attention_bam_16_attention_center_distance": 0.07038202394049572,
      "attention_bam_16_attention_spatial_variance": 41.33597278469357,
      "attention_bam_16_attention_spatial_std": 6.42930577781875,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.345157838512332,
      "attention_bam_16_peak_intensity_mean": 0.4352724850177765,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 60,
      "phase": "train",
      "loss": 0.15707820653915405,
      "timestamp": 1759543889.9876466,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.15707820653915405,
      "ssim": 0.39389801025390625,
      "attention_bam_384_mean_attention": 0.21094006299972534,
      "attention_bam_384_std_attention": 0.5291146039962769,
      "attention_bam_384_max_attention": 5.080113410949707,
      "attention_bam_384_min_attention": -1.6072943210601807,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5009053050696348,
      "attention_bam_384_attention_skewness": 0.5767443025420907,
      "attention_bam_384_attention_sparsity": 0.4353383382161458,
      "attention_bam_384_attention_concentration_10": 0.5765043311357424,
      "attention_bam_384_attention_concentration_20": 0.9284835839557866,
      "attention_bam_384_attention_center_y": 0.4854841547410833,
      "attention_bam_384_attention_center_x": 0.48262576711756655,
      "attention_bam_384_attention_center_distance": 0.03201792409991147,
      "attention_bam_384_attention_spatial_variance": 170.3235055165059,
      "attention_bam_384_attention_spatial_std": 13.050804784246292,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 18.43200299027942,
      "attention_bam_384_peak_intensity_mean": 0.27449727058410645,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2352849841117859,
      "attention_bam_16_std_attention": 0.5607309341430664,
      "attention_bam_16_max_attention": 2.4928839206695557,
      "attention_bam_16_min_attention": -1.202850580215454,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.09116525357824612,
      "attention_bam_16_attention_skewness": 0.35424330018258227,
      "attention_bam_16_attention_sparsity": 0.42578125,
      "attention_bam_16_attention_concentration_10": 0.5419449808641938,
      "attention_bam_16_attention_concentration_20": 0.8899954324585473,
      "attention_bam_16_attention_center_y": 0.4781047962264992,
      "attention_bam_16_attention_center_x": 0.4680086822511628,
      "attention_bam_16_attention_center_distance": 0.05482416181922325,
      "attention_bam_16_attention_spatial_variance": 41.73192690283798,
      "attention_bam_16_attention_spatial_std": 6.4600253020276925,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.482604641161661,
      "attention_bam_16_peak_intensity_mean": 0.3991970121860504,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 61,
      "phase": "train",
      "loss": 0.11353062093257904,
      "timestamp": 1759543890.1258812,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.11353062093257904,
      "ssim": 0.3071877360343933,
      "attention_bam_384_mean_attention": 0.21604900062084198,
      "attention_bam_384_std_attention": 0.48516008257865906,
      "attention_bam_384_max_attention": 5.109823703765869,
      "attention_bam_384_min_attention": -1.5677331686019897,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.2549916070690808,
      "attention_bam_384_attention_skewness": 0.6774015020869443,
      "attention_bam_384_attention_sparsity": 0.42863210042317706,
      "attention_bam_384_attention_concentration_10": 0.529162454058213,
      "attention_bam_384_attention_concentration_20": 0.8501662022297485,
      "attention_bam_384_attention_center_y": 0.48020224292359476,
      "attention_bam_384_attention_center_x": 0.480088356591782,
      "attention_bam_384_attention_center_distance": 0.03970956379695916,
      "attention_bam_384_attention_spatial_variance": 170.03706015071776,
      "attention_bam_384_attention_spatial_std": 13.039825924862562,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 16.74305869871085,
      "attention_bam_384_peak_intensity_mean": 0.26920032501220703,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2587539255619049,
      "attention_bam_16_std_attention": 0.47801974415779114,
      "attention_bam_16_max_attention": 2.784224033355713,
      "attention_bam_16_min_attention": -0.9836270213127136,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.015967105759804312,
      "attention_bam_16_attention_skewness": 0.3925537810435487,
      "attention_bam_16_attention_sparsity": 0.402099609375,
      "attention_bam_16_attention_concentration_10": 0.44800371235860237,
      "attention_bam_16_attention_concentration_20": 0.7480088607368363,
      "attention_bam_16_attention_center_y": 0.4624268023889731,
      "attention_bam_16_attention_center_x": 0.45872867416126645,
      "attention_bam_16_attention_center_distance": 0.07893120441503719,
      "attention_bam_16_attention_spatial_variance": 41.0147928237676,
      "attention_bam_16_attention_spatial_std": 6.404279258727526,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 7.506588559788867,
      "attention_bam_16_peak_intensity_mean": 0.3456994891166687,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 62,
      "phase": "train",
      "loss": 0.14304064214229584,
      "timestamp": 1759543890.2545388,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.14304064214229584,
      "ssim": 0.3468208312988281,
      "attention_bam_384_mean_attention": 0.2016938477754593,
      "attention_bam_384_std_attention": 0.5412432551383972,
      "attention_bam_384_max_attention": 5.287590980529785,
      "attention_bam_384_min_attention": -1.5843007564544678,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2025621666811697,
      "attention_bam_384_attention_skewness": 0.5315894370838025,
      "attention_bam_384_attention_sparsity": 0.44082387288411456,
      "attention_bam_384_attention_concentration_10": 0.6083244250354646,
      "attention_bam_384_attention_concentration_20": 0.9804558579231325,
      "attention_bam_384_attention_center_y": 0.4874826649655523,
      "attention_bam_384_attention_center_x": 0.4855714817325829,
      "attention_bam_384_attention_center_distance": 0.027013545334065282,
      "attention_bam_384_attention_spatial_variance": 170.74211118938354,
      "attention_bam_384_attention_spatial_std": 13.066832484936183,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 16.53524018982025,
      "attention_bam_384_peak_intensity_mean": 0.261453241109848,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22818008065223694,
      "attention_bam_16_std_attention": 0.5792118310928345,
      "attention_bam_16_max_attention": 2.3040835857391357,
      "attention_bam_16_min_attention": -1.0603572130203247,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.0831107227878185,
      "attention_bam_16_attention_skewness": 0.35217640308758663,
      "attention_bam_16_attention_sparsity": 0.430908203125,
      "attention_bam_16_attention_concentration_10": 0.574521517986584,
      "attention_bam_16_attention_concentration_20": 0.9377560340177337,
      "attention_bam_16_attention_center_y": 0.4813280237444168,
      "attention_bam_16_attention_center_x": 0.47725372238153224,
      "attention_bam_16_attention_center_distance": 0.04161816533163061,
      "attention_bam_16_attention_spatial_variance": 42.10450473219017,
      "attention_bam_16_attention_spatial_std": 6.488798404341914,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.82714501885612,
      "attention_bam_16_peak_intensity_mean": 0.3883568346500397,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 63,
      "phase": "train",
      "loss": 0.11710494011640549,
      "timestamp": 1759543890.3863225,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.11710494011640549,
      "ssim": 0.4097574055194855,
      "attention_bam_384_mean_attention": 0.21411161124706268,
      "attention_bam_384_std_attention": 0.527942419052124,
      "attention_bam_384_max_attention": 4.8740129470825195,
      "attention_bam_384_min_attention": -1.5787067413330078,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2932459892631787,
      "attention_bam_384_attention_skewness": 0.596402510441007,
      "attention_bam_384_attention_sparsity": 0.446380615234375,
      "attention_bam_384_attention_concentration_10": 0.5719136572885549,
      "attention_bam_384_attention_concentration_20": 0.9206157049677887,
      "attention_bam_384_attention_center_y": 0.48271178862647407,
      "attention_bam_384_attention_center_x": 0.4803236882847356,
      "attention_bam_384_attention_center_distance": 0.037041584610055835,
      "attention_bam_384_attention_spatial_variance": 169.12986699844495,
      "attention_bam_384_attention_spatial_std": 13.004993925352098,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 17.058462944832137,
      "attention_bam_384_peak_intensity_mean": 0.2789416015148163,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24821464717388153,
      "attention_bam_16_std_attention": 0.5368967056274414,
      "attention_bam_16_max_attention": 2.3709659576416016,
      "attention_bam_16_min_attention": -1.2028172016143799,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.48542988107439244,
      "attention_bam_16_attention_skewness": 0.5044323353477415,
      "attention_bam_16_attention_sparsity": 0.418212890625,
      "attention_bam_16_attention_concentration_10": 0.5144710132735403,
      "attention_bam_16_attention_concentration_20": 0.8367479612435929,
      "attention_bam_16_attention_center_y": 0.46997086357256324,
      "attention_bam_16_attention_center_x": 0.45919019699818064,
      "attention_bam_16_attention_center_distance": 0.07165457494989295,
      "attention_bam_16_attention_spatial_variance": 40.95330773983202,
      "attention_bam_16_attention_spatial_std": 6.399477145816838,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.549283492541583,
      "attention_bam_16_peak_intensity_mean": 0.4115794599056244,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 64,
      "phase": "train",
      "loss": 0.13942019641399384,
      "timestamp": 1759543890.5154047,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.13942019641399384,
      "ssim": 0.4026842713356018,
      "attention_bam_384_mean_attention": 0.21155627071857452,
      "attention_bam_384_std_attention": 0.539480447769165,
      "attention_bam_384_max_attention": 4.662264823913574,
      "attention_bam_384_min_attention": -1.5923089981079102,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8564679487260727,
      "attention_bam_384_attention_skewness": 0.5738672482601315,
      "attention_bam_384_attention_sparsity": 0.45234934488932294,
      "attention_bam_384_attention_concentration_10": 0.5930010548482868,
      "attention_bam_384_attention_concentration_20": 0.9548455030325743,
      "attention_bam_384_attention_center_y": 0.48570204117706794,
      "attention_bam_384_attention_center_x": 0.4817849452323581,
      "attention_bam_384_attention_center_distance": 0.032748125036113275,
      "attention_bam_384_attention_spatial_variance": 169.7853634791312,
      "attention_bam_384_attention_spatial_std": 13.03017127589393,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 16.485919386302307,
      "attention_bam_384_peak_intensity_mean": 0.29164278507232666,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23896808922290802,
      "attention_bam_16_std_attention": 0.5760939121246338,
      "attention_bam_16_max_attention": 2.4459035396575928,
      "attention_bam_16_min_attention": -0.9887725114822388,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.14350060459090974,
      "attention_bam_16_attention_skewness": 0.5311916489582564,
      "attention_bam_16_attention_sparsity": 0.439697265625,
      "attention_bam_16_attention_concentration_10": 0.5580548506987095,
      "attention_bam_16_attention_concentration_20": 0.9153925667603501,
      "attention_bam_16_attention_center_y": 0.4789242632476081,
      "attention_bam_16_attention_center_x": 0.46334466373241534,
      "attention_bam_16_attention_center_distance": 0.05979632691973361,
      "attention_bam_16_attention_spatial_variance": 41.389870124342345,
      "attention_bam_16_attention_spatial_std": 6.433495948886759,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 9.612143302855765,
      "attention_bam_16_peak_intensity_mean": 0.3646821081638336,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 65,
      "phase": "train",
      "loss": 0.13059592247009277,
      "timestamp": 1759543890.6451635,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.13059592247009277,
      "ssim": 0.37299486994743347,
      "attention_bam_384_mean_attention": 0.20298437774181366,
      "attention_bam_384_std_attention": 0.5240222215652466,
      "attention_bam_384_max_attention": 4.456543922424316,
      "attention_bam_384_min_attention": -1.593395471572876,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.6102564593768216,
      "attention_bam_384_attention_skewness": 0.6313593693658008,
      "attention_bam_384_attention_sparsity": 0.44271087646484375,
      "attention_bam_384_attention_concentration_10": 0.5945609461834566,
      "attention_bam_384_attention_concentration_20": 0.9502197319677942,
      "attention_bam_384_attention_center_y": 0.484470702396529,
      "attention_bam_384_attention_center_x": 0.4819748637396219,
      "attention_bam_384_attention_center_distance": 0.033647128295364745,
      "attention_bam_384_attention_spatial_variance": 170.66992238064168,
      "attention_bam_384_attention_spatial_std": 13.064069901092909,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 17.043694419063247,
      "attention_bam_384_peak_intensity_mean": 0.2978850305080414,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21464410424232483,
      "attention_bam_16_std_attention": 0.5479816198348999,
      "attention_bam_16_max_attention": 2.8313560485839844,
      "attention_bam_16_min_attention": -1.027978539466858,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5857210713935905,
      "attention_bam_16_attention_skewness": 0.49530882446624247,
      "attention_bam_16_attention_sparsity": 0.435302734375,
      "attention_bam_16_attention_concentration_10": 0.5847152026220794,
      "attention_bam_16_attention_concentration_20": 0.9442368167333353,
      "attention_bam_16_attention_center_y": 0.4748814619957356,
      "attention_bam_16_attention_center_x": 0.4715407583990777,
      "attention_bam_16_attention_center_distance": 0.053681829029408816,
      "attention_bam_16_attention_spatial_variance": 42.30567197865459,
      "attention_bam_16_attention_spatial_std": 6.504281050097281,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.006587198845152,
      "attention_bam_16_peak_intensity_mean": 0.3264297842979431,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 66,
      "phase": "train",
      "loss": 0.16074232757091522,
      "timestamp": 1759543890.7750251,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.16074232757091522,
      "ssim": 0.36747193336486816,
      "attention_bam_384_mean_attention": 0.20270727574825287,
      "attention_bam_384_std_attention": 0.5856889486312866,
      "attention_bam_384_max_attention": 5.601900100708008,
      "attention_bam_384_min_attention": -1.6935887336730957,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.7048513015170794,
      "attention_bam_384_attention_skewness": 0.6908221302627051,
      "attention_bam_384_attention_sparsity": 0.45873769124348956,
      "attention_bam_384_attention_concentration_10": 0.660128245854328,
      "attention_bam_384_attention_concentration_20": 1.0498233242907273,
      "attention_bam_384_attention_center_y": 0.4848194807107984,
      "attention_bam_384_attention_center_x": 0.48222693547738094,
      "attention_bam_384_attention_center_distance": 0.03305540767907734,
      "attention_bam_384_attention_spatial_variance": 170.57227451816948,
      "attention_bam_384_attention_spatial_std": 13.06033209831088,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 15.692513284861453,
      "attention_bam_384_peak_intensity_mean": 0.2618721127510071,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2308451384305954,
      "attention_bam_16_std_attention": 0.6210359930992126,
      "attention_bam_16_max_attention": 2.6269419193267822,
      "attention_bam_16_min_attention": -1.1083056926727295,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.1255094246168218,
      "attention_bam_16_attention_skewness": 0.6122489444629965,
      "attention_bam_16_attention_sparsity": 0.4638671875,
      "attention_bam_16_attention_concentration_10": 0.6346600498068823,
      "attention_bam_16_attention_concentration_20": 1.0227887027539764,
      "attention_bam_16_attention_center_y": 0.4726130636719491,
      "attention_bam_16_attention_center_x": 0.46405112769512613,
      "attention_bam_16_attention_center_distance": 0.0639119034519993,
      "attention_bam_16_attention_spatial_variance": 42.071629192042764,
      "attention_bam_16_attention_spatial_std": 6.486264656336709,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 8.571051616165706,
      "attention_bam_16_peak_intensity_mean": 0.3720695674419403,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 67,
      "phase": "train",
      "loss": 0.13932204246520996,
      "timestamp": 1759543890.9065704,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.13932204246520996,
      "ssim": 0.3864298462867737,
      "attention_bam_384_mean_attention": 0.20917899906635284,
      "attention_bam_384_std_attention": 0.559612512588501,
      "attention_bam_384_max_attention": 5.000951290130615,
      "attention_bam_384_min_attention": -1.697650671005249,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.6255334510256567,
      "attention_bam_384_attention_skewness": 0.835185993018009,
      "attention_bam_384_attention_sparsity": 0.44555918375651044,
      "attention_bam_384_attention_concentration_10": 0.6121535583440647,
      "attention_bam_384_attention_concentration_20": 0.9702857738799412,
      "attention_bam_384_attention_center_y": 0.4755026919551683,
      "attention_bam_384_attention_center_x": 0.47946383801473036,
      "attention_bam_384_attention_center_distance": 0.04520734565374546,
      "attention_bam_384_attention_spatial_variance": 172.09134832813083,
      "attention_bam_384_attention_spatial_std": 13.118359208686536,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 18.41138683682925,
      "attention_bam_384_peak_intensity_mean": 0.28912562131881714,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2310781031847,
      "attention_bam_16_std_attention": 0.6188189387321472,
      "attention_bam_16_max_attention": 3.7262158393859863,
      "attention_bam_16_min_attention": -1.1711714267730713,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.6992122828160046,
      "attention_bam_16_attention_skewness": 0.7412975401477824,
      "attention_bam_16_attention_sparsity": 0.434326171875,
      "attention_bam_16_attention_concentration_10": 0.6068812744621657,
      "attention_bam_16_attention_concentration_20": 0.9781698259997048,
      "attention_bam_16_attention_center_y": 0.44570562423575644,
      "attention_bam_16_attention_center_x": 0.45267697229161286,
      "attention_bam_16_attention_center_distance": 0.10185625352542332,
      "attention_bam_16_attention_spatial_variance": 43.03512315666501,
      "attention_bam_16_attention_spatial_std": 6.560116093230745,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 10.136587933476152,
      "attention_bam_16_peak_intensity_mean": 0.3122994303703308,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 68,
      "phase": "train",
      "loss": 0.11577676981687546,
      "timestamp": 1759543891.0366147,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.11577676981687546,
      "ssim": 0.4141920804977417,
      "attention_bam_384_mean_attention": 0.1997838020324707,
      "attention_bam_384_std_attention": 0.5299570560455322,
      "attention_bam_384_max_attention": 5.498289108276367,
      "attention_bam_384_min_attention": -1.6759636402130127,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.0088112863067025,
      "attention_bam_384_attention_skewness": 0.6392695443208471,
      "attention_bam_384_attention_sparsity": 0.44899749755859375,
      "attention_bam_384_attention_concentration_10": 0.6018431003769529,
      "attention_bam_384_attention_concentration_20": 0.9678539434542113,
      "attention_bam_384_attention_center_y": 0.47755092782394554,
      "attention_bam_384_attention_center_x": 0.47984920447889695,
      "attention_bam_384_attention_center_distance": 0.04266181903526874,
      "attention_bam_384_attention_spatial_variance": 172.351689953156,
      "attention_bam_384_attention_spatial_std": 13.128278255474173,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 18.501197434518474,
      "attention_bam_384_peak_intensity_mean": 0.2670666575431824,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20792827010154724,
      "attention_bam_16_std_attention": 0.5274553894996643,
      "attention_bam_16_max_attention": 2.233051300048828,
      "attention_bam_16_min_attention": -1.062178373336792,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.34791420670350615,
      "attention_bam_16_attention_skewness": 0.1669415754166634,
      "attention_bam_16_attention_sparsity": 0.427978515625,
      "attention_bam_16_attention_concentration_10": 0.5477372878923034,
      "attention_bam_16_attention_concentration_20": 0.9224760513671775,
      "attention_bam_16_attention_center_y": 0.4547744200398721,
      "attention_bam_16_attention_center_x": 0.4546847622471538,
      "attention_bam_16_attention_center_distance": 0.09054086210465301,
      "attention_bam_16_attention_spatial_variance": 43.42371548227817,
      "attention_bam_16_attention_spatial_std": 6.5896673271325445,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.921331495463603,
      "attention_bam_16_peak_intensity_mean": 0.4038902223110199,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 69,
      "phase": "train",
      "loss": 0.1375133991241455,
      "timestamp": 1759543891.1674047,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.1375133991241455,
      "ssim": 0.42756301164627075,
      "attention_bam_384_mean_attention": 0.1786058098077774,
      "attention_bam_384_std_attention": 0.5668291449546814,
      "attention_bam_384_max_attention": 5.79689884185791,
      "attention_bam_384_min_attention": -1.6420589685440063,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.550768683399826,
      "attention_bam_384_attention_skewness": 0.8885510407943003,
      "attention_bam_384_attention_sparsity": 0.47380320231119794,
      "attention_bam_384_attention_concentration_10": 0.7322517596868647,
      "attention_bam_384_attention_concentration_20": 1.1302681732347988,
      "attention_bam_384_attention_center_y": 0.48251633231655255,
      "attention_bam_384_attention_center_x": 0.4851617823358305,
      "attention_bam_384_attention_center_distance": 0.03242996574510975,
      "attention_bam_384_attention_spatial_variance": 170.5032675778161,
      "attention_bam_384_attention_spatial_std": 13.05768997862241,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 19.81062922403865,
      "attention_bam_384_peak_intensity_mean": 0.24792508780956268,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22220410406589508,
      "attention_bam_16_std_attention": 0.6424652338027954,
      "attention_bam_16_max_attention": 3.032526731491089,
      "attention_bam_16_min_attention": -1.3568023443222046,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.273852005242511,
      "attention_bam_16_attention_skewness": 0.8770632331185487,
      "attention_bam_16_attention_sparsity": 0.470703125,
      "attention_bam_16_attention_concentration_10": 0.6946685743122128,
      "attention_bam_16_attention_concentration_20": 1.075294471873493,
      "attention_bam_16_attention_center_y": 0.46618229847311,
      "attention_bam_16_attention_center_x": 0.4698612495155987,
      "attention_bam_16_attention_center_distance": 0.06406217631836773,
      "attention_bam_16_attention_spatial_variance": 41.966984159342594,
      "attention_bam_16_attention_spatial_std": 6.478192970214965,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.565958334266007,
      "attention_bam_16_peak_intensity_mean": 0.38007310032844543,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 70,
      "phase": "train",
      "loss": 0.10200232267379761,
      "timestamp": 1759543891.3681507,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.10200232267379761,
      "ssim": 0.4096519947052002,
      "attention_bam_384_mean_attention": 0.1885831207036972,
      "attention_bam_384_std_attention": 0.5088109970092773,
      "attention_bam_384_max_attention": 5.91633415222168,
      "attention_bam_384_min_attention": -1.633140206336975,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.402797495195042,
      "attention_bam_384_attention_skewness": 0.7186125017951274,
      "attention_bam_384_attention_sparsity": 0.44916534423828125,
      "attention_bam_384_attention_concentration_10": 0.6228788439244863,
      "attention_bam_384_attention_concentration_20": 0.9813863671823921,
      "attention_bam_384_attention_center_y": 0.481043897803974,
      "attention_bam_384_attention_center_x": 0.4887081369096616,
      "attention_bam_384_attention_center_distance": 0.031203845356530303,
      "attention_bam_384_attention_spatial_variance": 171.0069618033788,
      "attention_bam_384_attention_spatial_std": 13.076963019117963,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 17.331581877329427,
      "attention_bam_384_peak_intensity_mean": 0.2431548535823822,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23200905323028564,
      "attention_bam_16_std_attention": 0.5449327230453491,
      "attention_bam_16_max_attention": 2.4886536598205566,
      "attention_bam_16_min_attention": -1.1039608716964722,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5828931029294613,
      "attention_bam_16_attention_skewness": 0.5778826965479009,
      "attention_bam_16_attention_sparsity": 0.42724609375,
      "attention_bam_16_attention_concentration_10": 0.568399312923149,
      "attention_bam_16_attention_concentration_20": 0.8970232495192656,
      "attention_bam_16_attention_center_y": 0.466551115955846,
      "attention_bam_16_attention_center_x": 0.48230406314778657,
      "attention_bam_16_attention_center_distance": 0.05351586727087186,
      "attention_bam_16_attention_spatial_variance": 42.326636177858596,
      "attention_bam_16_attention_spatial_std": 6.50589241978828,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.772877907838978,
      "attention_bam_16_peak_intensity_mean": 0.38305968046188354,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 71,
      "phase": "train",
      "loss": 0.13298079371452332,
      "timestamp": 1759543891.5380595,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.13298079371452332,
      "ssim": 0.4155440330505371,
      "attention_bam_384_mean_attention": 0.18453079462051392,
      "attention_bam_384_std_attention": 0.5412961840629578,
      "attention_bam_384_max_attention": 5.912436485290527,
      "attention_bam_384_min_attention": -1.726932406425476,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.0289064528946517,
      "attention_bam_384_attention_skewness": 0.6558294963939312,
      "attention_bam_384_attention_sparsity": 0.4609476725260417,
      "attention_bam_384_attention_concentration_10": 0.6551617137388509,
      "attention_bam_384_attention_concentration_20": 1.0471811277210374,
      "attention_bam_384_attention_center_y": 0.4784451401975904,
      "attention_bam_384_attention_center_x": 0.48520754773239083,
      "attention_bam_384_attention_center_distance": 0.03697103258474206,
      "attention_bam_384_attention_spatial_variance": 170.51858850289995,
      "attention_bam_384_attention_spatial_std": 13.05827662836486,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 16.673435181981375,
      "attention_bam_384_peak_intensity_mean": 0.25036489963531494,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23491977155208588,
      "attention_bam_16_std_attention": 0.6061755418777466,
      "attention_bam_16_max_attention": 2.532808780670166,
      "attention_bam_16_min_attention": -1.1000186204910278,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.03236303670521501,
      "attention_bam_16_attention_skewness": 0.4052351981400986,
      "attention_bam_16_attention_sparsity": 0.434814453125,
      "attention_bam_16_attention_concentration_10": 0.5831183608849125,
      "attention_bam_16_attention_concentration_20": 0.956228462440806,
      "attention_bam_16_attention_center_y": 0.4547926597685565,
      "attention_bam_16_attention_center_x": 0.47832526237585987,
      "attention_bam_16_attention_center_distance": 0.07090130974639053,
      "attention_bam_16_attention_spatial_variance": 41.57433336392701,
      "attention_bam_16_attention_spatial_std": 6.447816170140632,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.2886676043837,
      "attention_bam_16_peak_intensity_mean": 0.37665003538131714,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 72,
      "phase": "train",
      "loss": 0.1431681513786316,
      "timestamp": 1759543891.6770008,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.1431681513786316,
      "ssim": 0.3943381905555725,
      "attention_bam_384_mean_attention": 0.17437994480133057,
      "attention_bam_384_std_attention": 0.5595401525497437,
      "attention_bam_384_max_attention": 5.694760322570801,
      "attention_bam_384_min_attention": -1.6873753070831299,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.6624695391386872,
      "attention_bam_384_attention_skewness": 0.645097321803035,
      "attention_bam_384_attention_sparsity": 0.47427622477213544,
      "attention_bam_384_attention_concentration_10": 0.7116341549282702,
      "attention_bam_384_attention_concentration_20": 1.138657920912054,
      "attention_bam_384_attention_center_y": 0.48425416923597026,
      "attention_bam_384_attention_center_x": 0.4782901023550599,
      "attention_bam_384_attention_center_distance": 0.03792758474259178,
      "attention_bam_384_attention_spatial_variance": 170.27373961031526,
      "attention_bam_384_attention_spatial_std": 13.048898022833777,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 18.335899636185943,
      "attention_bam_384_peak_intensity_mean": 0.2534812390804291,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21599966287612915,
      "attention_bam_16_std_attention": 0.6447221636772156,
      "attention_bam_16_max_attention": 2.663745641708374,
      "attention_bam_16_min_attention": -1.1022684574127197,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.10994355697587554,
      "attention_bam_16_attention_skewness": 0.5170971960458619,
      "attention_bam_16_attention_sparsity": 0.46435546875,
      "attention_bam_16_attention_concentration_10": 0.6814905627134522,
      "attention_bam_16_attention_concentration_20": 1.1009304133878053,
      "attention_bam_16_attention_center_y": 0.47388894330147113,
      "attention_bam_16_attention_center_x": 0.4471035977899022,
      "attention_bam_16_attention_center_distance": 0.08342441667385186,
      "attention_bam_16_attention_spatial_variance": 41.5110304279273,
      "attention_bam_16_attention_spatial_std": 6.442905433725324,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.47675366060541,
      "attention_bam_16_peak_intensity_mean": 0.3609986901283264,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 73,
      "phase": "train",
      "loss": 0.10593005269765854,
      "timestamp": 1759543891.8078556,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.10593005269765854,
      "ssim": 0.41601577401161194,
      "attention_bam_384_mean_attention": 0.19253261387348175,
      "attention_bam_384_std_attention": 0.6290463805198669,
      "attention_bam_384_max_attention": 5.1023454666137695,
      "attention_bam_384_min_attention": -1.7229784727096558,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.697754493427916,
      "attention_bam_384_attention_skewness": 0.8022996696774274,
      "attention_bam_384_attention_sparsity": 0.4758249918619792,
      "attention_bam_384_attention_concentration_10": 0.7379520465643467,
      "attention_bam_384_attention_concentration_20": 1.1592908052888293,
      "attention_bam_384_attention_center_y": 0.4784160597907817,
      "attention_bam_384_attention_center_x": 0.4834462329261702,
      "attention_bam_384_attention_center_distance": 0.03846800434880188,
      "attention_bam_384_attention_spatial_variance": 173.57168946436312,
      "attention_bam_384_attention_spatial_std": 13.174660886123904,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 19.008690067479375,
      "attention_bam_384_peak_intensity_mean": 0.28300562500953674,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2251504361629486,
      "attention_bam_16_std_attention": 0.7343723773956299,
      "attention_bam_16_max_attention": 3.4434776306152344,
      "attention_bam_16_min_attention": -1.140854001045227,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.9341595941211183,
      "attention_bam_16_attention_skewness": 0.8044133099642008,
      "attention_bam_16_attention_sparsity": 0.471435546875,
      "attention_bam_16_attention_concentration_10": 0.7493718889709928,
      "attention_bam_16_attention_concentration_20": 1.172694560197058,
      "attention_bam_16_attention_center_y": 0.44955668315965175,
      "attention_bam_16_attention_center_x": 0.4626751577427786,
      "attention_bam_16_attention_center_distance": 0.08874313565997338,
      "attention_bam_16_attention_spatial_variance": 44.74752906971685,
      "attention_bam_16_attention_spatial_std": 6.689359391579798,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.901304936748181,
      "attention_bam_16_peak_intensity_mean": 0.321146696805954,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 74,
      "phase": "train",
      "loss": 0.11617612838745117,
      "timestamp": 1759543891.9383862,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.11617612838745117,
      "ssim": 0.34339630603790283,
      "attention_bam_384_mean_attention": 0.16831915080547333,
      "attention_bam_384_std_attention": 0.5072980523109436,
      "attention_bam_384_max_attention": 5.418515205383301,
      "attention_bam_384_min_attention": -1.6489791870117188,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.032197185292663,
      "attention_bam_384_attention_skewness": 0.653613222106997,
      "attention_bam_384_attention_sparsity": 0.4703216552734375,
      "attention_bam_384_attention_concentration_10": 0.6710144149162445,
      "attention_bam_384_attention_concentration_20": 1.0729428762312792,
      "attention_bam_384_attention_center_y": 0.486796156901043,
      "attention_bam_384_attention_center_x": 0.48461353860193557,
      "attention_bam_384_attention_center_distance": 0.028673495320103593,
      "attention_bam_384_attention_spatial_variance": 172.94335909295862,
      "attention_bam_384_attention_spatial_std": 13.150793097488783,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 21.302898129549778,
      "attention_bam_384_peak_intensity_mean": 0.2637166678905487,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21337881684303284,
      "attention_bam_16_std_attention": 0.5771364569664001,
      "attention_bam_16_max_attention": 2.5673742294311523,
      "attention_bam_16_min_attention": -1.1021085977554321,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.11638400436848517,
      "attention_bam_16_attention_skewness": 0.5339058339400604,
      "attention_bam_16_attention_sparsity": 0.45166015625,
      "attention_bam_16_attention_concentration_10": 0.6170605204959423,
      "attention_bam_16_attention_concentration_20": 1.0023441979101229,
      "attention_bam_16_attention_center_y": 0.48361540669423586,
      "attention_bam_16_attention_center_x": 0.465311427716153,
      "attention_bam_16_attention_center_distance": 0.05425406795599695,
      "attention_bam_16_attention_spatial_variance": 44.448065428127265,
      "attention_bam_16_attention_spatial_std": 6.6669382349116795,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.900742483544887,
      "attention_bam_16_peak_intensity_mean": 0.39157867431640625,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 75,
      "phase": "train",
      "loss": 0.10228870809078217,
      "timestamp": 1759543892.0684907,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.10228870809078217,
      "ssim": 0.4136846363544464,
      "attention_bam_384_mean_attention": 0.20044982433319092,
      "attention_bam_384_std_attention": 0.5110326409339905,
      "attention_bam_384_max_attention": 5.027342796325684,
      "attention_bam_384_min_attention": -1.5682073831558228,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0985955480469256,
      "attention_bam_384_attention_skewness": 0.46312265234280353,
      "attention_bam_384_attention_sparsity": 0.44041188557942706,
      "attention_bam_384_attention_concentration_10": 0.5775521683580446,
      "attention_bam_384_attention_concentration_20": 0.9359041606822899,
      "attention_bam_384_attention_center_y": 0.4909521004143252,
      "attention_bam_384_attention_center_x": 0.48400612879357385,
      "attention_bam_384_attention_center_distance": 0.025987243142749937,
      "attention_bam_384_attention_spatial_variance": 170.83659656108003,
      "attention_bam_384_attention_spatial_std": 13.070447450683547,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 14.138651087944508,
      "attention_bam_384_peak_intensity_mean": 0.2717214822769165,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2519083619117737,
      "attention_bam_16_std_attention": 0.5653866529464722,
      "attention_bam_16_max_attention": 2.476820230484009,
      "attention_bam_16_min_attention": -1.1862894296646118,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.015950049555982115,
      "attention_bam_16_attention_skewness": 0.2907356689421112,
      "attention_bam_16_attention_sparsity": 0.41259765625,
      "attention_bam_16_attention_concentration_10": 0.5172074009472578,
      "attention_bam_16_attention_concentration_20": 0.8502064798119158,
      "attention_bam_16_attention_center_y": 0.4938104027186415,
      "attention_bam_16_attention_center_x": 0.47329502814119756,
      "attention_bam_16_attention_center_distance": 0.038767683358303225,
      "attention_bam_16_attention_spatial_variance": 42.383388086097526,
      "attention_bam_16_attention_spatial_std": 6.510252536276725,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 6.067357419481231,
      "attention_bam_16_peak_intensity_mean": 0.425223171710968,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 76,
      "phase": "train",
      "loss": 0.09586694836616516,
      "timestamp": 1759543892.1978245,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.09586694836616516,
      "ssim": 0.4727137088775635,
      "attention_bam_384_mean_attention": 0.2049913853406906,
      "attention_bam_384_std_attention": 0.4509098529815674,
      "attention_bam_384_max_attention": 4.674900054931641,
      "attention_bam_384_min_attention": -1.6272480487823486,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.460639876421201,
      "attention_bam_384_attention_skewness": 0.49371327341580945,
      "attention_bam_384_attention_sparsity": 0.40956878662109375,
      "attention_bam_384_attention_concentration_10": 0.5088090161679163,
      "attention_bam_384_attention_concentration_20": 0.8226976083671524,
      "attention_bam_384_attention_center_y": 0.4810328149367796,
      "attention_bam_384_attention_center_x": 0.48360981496803374,
      "attention_bam_384_attention_center_distance": 0.03545115723370799,
      "attention_bam_384_attention_spatial_variance": 170.41531958767757,
      "attention_bam_384_attention_spatial_std": 13.054321873911244,
      "attention_bam_384_num_attention_peaks": 19,
      "attention_bam_384_peak_separation_mean": 17.72625346315736,
      "attention_bam_384_peak_intensity_mean": 0.29347220063209534,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2589622735977173,
      "attention_bam_16_std_attention": 0.44466373324394226,
      "attention_bam_16_max_attention": 2.2191011905670166,
      "attention_bam_16_min_attention": -1.0539392232894897,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.007872129583769372,
      "attention_bam_16_attention_skewness": -0.0024004899527185096,
      "attention_bam_16_attention_sparsity": 0.343017578125,
      "attention_bam_16_attention_concentration_10": 0.4049870576894546,
      "attention_bam_16_attention_concentration_20": 0.6774306701532989,
      "attention_bam_16_attention_center_y": 0.46021017906513634,
      "attention_bam_16_attention_center_x": 0.4679259731006788,
      "attention_bam_16_attention_center_distance": 0.07227687114930882,
      "attention_bam_16_attention_spatial_variance": 42.19878478388444,
      "attention_bam_16_attention_spatial_std": 6.496059173366914,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.704853340593948,
      "attention_bam_16_peak_intensity_mean": 0.41541895270347595,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 77,
      "phase": "train",
      "loss": 0.08364953845739365,
      "timestamp": 1759543892.3293464,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.08364953845739365,
      "ssim": 0.49321597814559937,
      "attention_bam_384_mean_attention": 0.1887327879667282,
      "attention_bam_384_std_attention": 0.5005728602409363,
      "attention_bam_384_max_attention": 5.09230375289917,
      "attention_bam_384_min_attention": -1.5994162559509277,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8145222999580337,
      "attention_bam_384_attention_skewness": 0.6543581222170243,
      "attention_bam_384_attention_sparsity": 0.45232899983723956,
      "attention_bam_384_attention_concentration_10": 0.6061386857378812,
      "attention_bam_384_attention_concentration_20": 0.9684298688566361,
      "attention_bam_384_attention_center_y": 0.4825072737350755,
      "attention_bam_384_attention_center_x": 0.4765909250004129,
      "attention_bam_384_attention_center_distance": 0.04132747910327638,
      "attention_bam_384_attention_spatial_variance": 171.72005474051898,
      "attention_bam_384_attention_spatial_std": 13.104199889368255,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 16.798662473893124,
      "attention_bam_384_peak_intensity_mean": 0.2708131670951843,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2367222011089325,
      "attention_bam_16_std_attention": 0.5758397579193115,
      "attention_bam_16_max_attention": 2.9336817264556885,
      "attention_bam_16_min_attention": -1.046679139137268,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.1628703178244031,
      "attention_bam_16_attention_skewness": 0.4103051102202257,
      "attention_bam_16_attention_sparsity": 0.4345703125,
      "attention_bam_16_attention_concentration_10": 0.5628450881520745,
      "attention_bam_16_attention_concentration_20": 0.9236918706114255,
      "attention_bam_16_attention_center_y": 0.465961423378862,
      "attention_bam_16_attention_center_x": 0.4419615538746422,
      "attention_bam_16_attention_center_distance": 0.0951534122040733,
      "attention_bam_16_attention_spatial_variance": 42.75390369283524,
      "attention_bam_16_attention_spatial_std": 6.5386469313486595,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 7.1428574410284185,
      "attention_bam_16_peak_intensity_mean": 0.34462472796440125,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 78,
      "phase": "train",
      "loss": 0.060246698558330536,
      "timestamp": 1759543892.4562118,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.060246698558330536,
      "ssim": 0.49308881163597107,
      "attention_bam_384_mean_attention": 0.18907113373279572,
      "attention_bam_384_std_attention": 0.5650099515914917,
      "attention_bam_384_max_attention": 5.527416706085205,
      "attention_bam_384_min_attention": -1.6419658660888672,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7391883233352865,
      "attention_bam_384_attention_skewness": 0.46411946562032913,
      "attention_bam_384_attention_sparsity": 0.4557342529296875,
      "attention_bam_384_attention_concentration_10": 0.659541950400184,
      "attention_bam_384_attention_concentration_20": 1.0742419660155034,
      "attention_bam_384_attention_center_y": 0.4838673051987581,
      "attention_bam_384_attention_center_x": 0.4832777642673094,
      "attention_bam_384_attention_center_distance": 0.032860219398223506,
      "attention_bam_384_attention_spatial_variance": 170.92267629665147,
      "attention_bam_384_attention_spatial_std": 13.073739950628186,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 18.96829818741721,
      "attention_bam_384_peak_intensity_mean": 0.25711679458618164,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2186567783355713,
      "attention_bam_16_std_attention": 0.640129566192627,
      "attention_bam_16_max_attention": 2.5969223976135254,
      "attention_bam_16_min_attention": -1.1393948793411255,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.039738856312999005,
      "attention_bam_16_attention_skewness": 0.4124729933599267,
      "attention_bam_16_attention_sparsity": 0.441650390625,
      "attention_bam_16_attention_concentration_10": 0.6560190101909823,
      "attention_bam_16_attention_concentration_20": 1.0666612919989984,
      "attention_bam_16_attention_center_y": 0.47098600769418886,
      "attention_bam_16_attention_center_x": 0.46628167438658635,
      "attention_bam_16_attention_center_distance": 0.06290846098409744,
      "attention_bam_16_attention_spatial_variance": 42.74766928812799,
      "attention_bam_16_attention_spatial_std": 6.538170178890114,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.096532927367917,
      "attention_bam_16_peak_intensity_mean": 0.37218987941741943,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 79,
      "phase": "train",
      "loss": 0.06384425610303879,
      "timestamp": 1759543892.5848343,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.06384425610303879,
      "ssim": 0.4928283095359802,
      "attention_bam_384_mean_attention": 0.18266242742538452,
      "attention_bam_384_std_attention": 0.5235061645507812,
      "attention_bam_384_max_attention": 4.720354080200195,
      "attention_bam_384_min_attention": -1.6281105279922485,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2540538741981022,
      "attention_bam_384_attention_skewness": 0.5030740716871287,
      "attention_bam_384_attention_sparsity": 0.45863596598307294,
      "attention_bam_384_attention_concentration_10": 0.6307776922481156,
      "attention_bam_384_attention_concentration_20": 1.0257699266050404,
      "attention_bam_384_attention_center_y": 0.4882215667446747,
      "attention_bam_384_attention_center_x": 0.48228092950223744,
      "attention_bam_384_attention_center_distance": 0.030089764015519698,
      "attention_bam_384_attention_spatial_variance": 170.63558674961925,
      "attention_bam_384_attention_spatial_std": 13.062755710401204,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 14.790928479448688,
      "attention_bam_384_peak_intensity_mean": 0.2887001931667328,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22964677214622498,
      "attention_bam_16_std_attention": 0.5893468260765076,
      "attention_bam_16_max_attention": 2.292074680328369,
      "attention_bam_16_min_attention": -1.0079749822616577,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.4617728327996513,
      "attention_bam_16_attention_skewness": 0.28655603568265087,
      "attention_bam_16_attention_sparsity": 0.44482421875,
      "attention_bam_16_attention_concentration_10": 0.5701453229101768,
      "attention_bam_16_attention_concentration_20": 0.9551436624398322,
      "attention_bam_16_attention_center_y": 0.48844776808169393,
      "attention_bam_16_attention_center_x": 0.4621694442906268,
      "attention_bam_16_attention_center_distance": 0.05593934228384026,
      "attention_bam_16_attention_spatial_variance": 42.308769355087904,
      "attention_bam_16_attention_spatial_std": 6.504519148644879,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 10.780069586359375,
      "attention_bam_16_peak_intensity_mean": 0.37757301330566406,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 80,
      "phase": "train",
      "loss": 0.08325887471437454,
      "timestamp": 1759543892.758876,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.08325887471437454,
      "ssim": 0.4976925253868103,
      "attention_bam_384_mean_attention": 0.19448083639144897,
      "attention_bam_384_std_attention": 0.5132721662521362,
      "attention_bam_384_max_attention": 4.289984226226807,
      "attention_bam_384_min_attention": -1.6011719703674316,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2612468561347132,
      "attention_bam_384_attention_skewness": 0.6044955157854439,
      "attention_bam_384_attention_sparsity": 0.4544423421223958,
      "attention_bam_384_attention_concentration_10": 0.6080180897234043,
      "attention_bam_384_attention_concentration_20": 0.9718264448193819,
      "attention_bam_384_attention_center_y": 0.4803279036366359,
      "attention_bam_384_attention_center_x": 0.4842815347753927,
      "attention_bam_384_attention_center_distance": 0.03561071536340351,
      "attention_bam_384_attention_spatial_variance": 170.05265957871362,
      "attention_bam_384_attention_spatial_std": 13.040424056705886,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 18.440982706268805,
      "attention_bam_384_peak_intensity_mean": 0.30657708644866943,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24684260785579681,
      "attention_bam_16_std_attention": 0.5892136096954346,
      "attention_bam_16_max_attention": 2.935710906982422,
      "attention_bam_16_min_attention": -1.0426582098007202,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.07463017394895077,
      "attention_bam_16_attention_skewness": 0.4422543765120728,
      "attention_bam_16_attention_sparsity": 0.438232421875,
      "attention_bam_16_attention_concentration_10": 0.5514411517448253,
      "attention_bam_16_attention_concentration_20": 0.9110429875516937,
      "attention_bam_16_attention_center_y": 0.4573505811247969,
      "attention_bam_16_attention_center_x": 0.4698922661922038,
      "attention_bam_16_attention_center_distance": 0.07383019118807219,
      "attention_bam_16_attention_spatial_variance": 41.659941183858,
      "attention_bam_16_attention_spatial_std": 6.4544512689970786,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.956621605910435,
      "attention_bam_16_peak_intensity_mean": 0.33668380975723267,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 81,
      "phase": "train",
      "loss": 0.09463455528020859,
      "timestamp": 1759543892.8959284,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.09463455528020859,
      "ssim": 0.5149726867675781,
      "attention_bam_384_mean_attention": 0.20070761442184448,
      "attention_bam_384_std_attention": 0.4930904805660248,
      "attention_bam_384_max_attention": 5.023857116699219,
      "attention_bam_384_min_attention": -1.6635560989379883,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.3796886916721016,
      "attention_bam_384_attention_skewness": 0.6544589715873053,
      "attention_bam_384_attention_sparsity": 0.43000539143880206,
      "attention_bam_384_attention_concentration_10": 0.5718642301061101,
      "attention_bam_384_attention_concentration_20": 0.9082011434430536,
      "attention_bam_384_attention_center_y": 0.48168429628422416,
      "attention_bam_384_attention_center_x": 0.4791907960917954,
      "attention_bam_384_attention_center_distance": 0.03920428471219245,
      "attention_bam_384_attention_spatial_variance": 170.00462371059177,
      "attention_bam_384_attention_spatial_std": 13.038582120406796,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 16.021856099836253,
      "attention_bam_384_peak_intensity_mean": 0.2807266414165497,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2362278699874878,
      "attention_bam_16_std_attention": 0.5004534721374512,
      "attention_bam_16_max_attention": 2.010982036590576,
      "attention_bam_16_min_attention": -0.9938292503356934,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.1266854475172865,
      "attention_bam_16_attention_skewness": 0.23040417726596832,
      "attention_bam_16_attention_sparsity": 0.38818359375,
      "attention_bam_16_attention_concentration_10": 0.4907467262894857,
      "attention_bam_16_attention_concentration_20": 0.8047099523892888,
      "attention_bam_16_attention_center_y": 0.46614764342749754,
      "attention_bam_16_attention_center_x": 0.45393414277319444,
      "attention_bam_16_attention_center_distance": 0.08084609140276708,
      "attention_bam_16_attention_spatial_variance": 41.48679672933894,
      "attention_bam_16_attention_spatial_std": 6.441024509295003,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 8.27903613693555,
      "attention_bam_16_peak_intensity_mean": 0.41423916816711426,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 82,
      "phase": "train",
      "loss": 0.0779833272099495,
      "timestamp": 1759543893.0267515,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0779833272099495,
      "ssim": 0.48057088255882263,
      "attention_bam_384_mean_attention": 0.1918247789144516,
      "attention_bam_384_std_attention": 0.5491883158683777,
      "attention_bam_384_max_attention": 4.624741077423096,
      "attention_bam_384_min_attention": -1.6354137659072876,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2678475757278687,
      "attention_bam_384_attention_skewness": 0.6434452045677801,
      "attention_bam_384_attention_sparsity": 0.46433258056640625,
      "attention_bam_384_attention_concentration_10": 0.6512200025333535,
      "attention_bam_384_attention_concentration_20": 1.0452528711713351,
      "attention_bam_384_attention_center_y": 0.48299208408116223,
      "attention_bam_384_attention_center_x": 0.48090229218992653,
      "attention_bam_384_attention_center_distance": 0.03616605169219323,
      "attention_bam_384_attention_spatial_variance": 169.47161754210643,
      "attention_bam_384_attention_spatial_std": 13.018126498928577,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 14.876020319700705,
      "attention_bam_384_peak_intensity_mean": 0.29276278614997864,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22748494148254395,
      "attention_bam_16_std_attention": 0.6163967251777649,
      "attention_bam_16_max_attention": 2.5491878986358643,
      "attention_bam_16_min_attention": -0.981217622756958,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.021136614623777472,
      "attention_bam_16_attention_skewness": 0.5781905643461712,
      "attention_bam_16_attention_sparsity": 0.46337890625,
      "attention_bam_16_attention_concentration_10": 0.6303247502135905,
      "attention_bam_16_attention_concentration_20": 1.025063774630273,
      "attention_bam_16_attention_center_y": 0.46696986620431546,
      "attention_bam_16_attention_center_x": 0.4610478706021566,
      "attention_bam_16_attention_center_distance": 0.07222545428292104,
      "attention_bam_16_attention_spatial_variance": 41.11790901645595,
      "attention_bam_16_attention_spatial_std": 6.412324774717509,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 7.447195927169501,
      "attention_bam_16_peak_intensity_mean": 0.3525165915489197,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 83,
      "phase": "train",
      "loss": 0.10675238072872162,
      "timestamp": 1759543893.155548,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.10675238072872162,
      "ssim": 0.40902137756347656,
      "attention_bam_384_mean_attention": 0.1810203343629837,
      "attention_bam_384_std_attention": 0.5185955762863159,
      "attention_bam_384_max_attention": 5.710108757019043,
      "attention_bam_384_min_attention": -1.6255205869674683,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1672606274616442,
      "attention_bam_384_attention_skewness": 0.5468200032681478,
      "attention_bam_384_attention_sparsity": 0.463714599609375,
      "attention_bam_384_attention_concentration_10": 0.637998718479401,
      "attention_bam_384_attention_concentration_20": 1.034040635483002,
      "attention_bam_384_attention_center_y": 0.484901253273808,
      "attention_bam_384_attention_center_x": 0.48433569846082886,
      "attention_bam_384_attention_center_distance": 0.030768246469754262,
      "attention_bam_384_attention_spatial_variance": 169.53140740356056,
      "attention_bam_384_attention_spatial_std": 13.020422704488537,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 18.877473631661363,
      "attention_bam_384_peak_intensity_mean": 0.24764196574687958,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2092425376176834,
      "attention_bam_16_std_attention": 0.5748314261436462,
      "attention_bam_16_max_attention": 2.2136876583099365,
      "attention_bam_16_min_attention": -1.1121151447296143,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.3839861722384148,
      "attention_bam_16_attention_skewness": 0.36300143672158336,
      "attention_bam_16_attention_sparsity": 0.459716796875,
      "attention_bam_16_attention_concentration_10": 0.606622732363009,
      "attention_bam_16_attention_concentration_20": 1.0116787253347965,
      "attention_bam_16_attention_center_y": 0.4689143688386893,
      "attention_bam_16_attention_center_x": 0.4697064227653998,
      "attention_bam_16_attention_center_distance": 0.0613843186223605,
      "attention_bam_16_attention_spatial_variance": 41.511834155002894,
      "attention_bam_16_attention_spatial_std": 6.442967806454018,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.703652162358392,
      "attention_bam_16_peak_intensity_mean": 0.39565494656562805,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 84,
      "phase": "train",
      "loss": 0.09296214580535889,
      "timestamp": 1759543893.2840226,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.09296214580535889,
      "ssim": 0.4591371417045593,
      "attention_bam_384_mean_attention": 0.2097277045249939,
      "attention_bam_384_std_attention": 0.4723827540874481,
      "attention_bam_384_max_attention": 4.880828857421875,
      "attention_bam_384_min_attention": -1.541947841644287,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8002055420796061,
      "attention_bam_384_attention_skewness": 0.5490570511958179,
      "attention_bam_384_attention_sparsity": 0.41172027587890625,
      "attention_bam_384_attention_concentration_10": 0.5352485391874884,
      "attention_bam_384_attention_concentration_20": 0.8512076753743613,
      "attention_bam_384_attention_center_y": 0.4814901343010799,
      "attention_bam_384_attention_center_x": 0.48503093201802594,
      "attention_bam_384_attention_center_distance": 0.03366565384604968,
      "attention_bam_384_attention_spatial_variance": 170.0877208831512,
      "attention_bam_384_attention_spatial_std": 13.041768318872682,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 15.969351368941103,
      "attention_bam_384_peak_intensity_mean": 0.27411824464797974,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.25460657477378845,
      "attention_bam_16_std_attention": 0.46578824520111084,
      "attention_bam_16_max_attention": 1.9584729671478271,
      "attention_bam_16_min_attention": -1.0333985090255737,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.4104617903157015,
      "attention_bam_16_attention_skewness": 0.20449470901644254,
      "attention_bam_16_attention_sparsity": 0.34716796875,
      "attention_bam_16_attention_concentration_10": 0.4444787473098233,
      "attention_bam_16_attention_concentration_20": 0.7121940205094214,
      "attention_bam_16_attention_center_y": 0.4617302451437313,
      "attention_bam_16_attention_center_x": 0.471026707541915,
      "attention_bam_16_attention_center_distance": 0.0678826312486578,
      "attention_bam_16_attention_spatial_variance": 41.57124196219422,
      "attention_bam_16_attention_spatial_std": 6.447576440973323,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 6.911923388049601,
      "attention_bam_16_peak_intensity_mean": 0.4492246210575104,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 85,
      "phase": "train",
      "loss": 0.10111957043409348,
      "timestamp": 1759543893.411089,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.10111957043409348,
      "ssim": 0.4746168255805969,
      "attention_bam_384_mean_attention": 0.18112637102603912,
      "attention_bam_384_std_attention": 0.5508099794387817,
      "attention_bam_384_max_attention": 4.452502727508545,
      "attention_bam_384_min_attention": -1.6099839210510254,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8159977636685847,
      "attention_bam_384_attention_skewness": 0.5492047210069659,
      "attention_bam_384_attention_sparsity": 0.46432749430338544,
      "attention_bam_384_attention_concentration_10": 0.6780088037049683,
      "attention_bam_384_attention_concentration_20": 1.0857151883271556,
      "attention_bam_384_attention_center_y": 0.4884108696271942,
      "attention_bam_384_attention_center_x": 0.48541658060267445,
      "attention_bam_384_attention_center_distance": 0.026343274819816184,
      "attention_bam_384_attention_spatial_variance": 170.016142424925,
      "attention_bam_384_attention_spatial_std": 13.039023829448467,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 13.076116372764108,
      "attention_bam_384_peak_intensity_mean": 0.298215389251709,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22505784034729004,
      "attention_bam_16_std_attention": 0.675399124622345,
      "attention_bam_16_max_attention": 2.884866237640381,
      "attention_bam_16_min_attention": -1.3552292585372925,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.24440224104583264,
      "attention_bam_16_attention_skewness": 0.6060306727983286,
      "attention_bam_16_attention_sparsity": 0.4658203125,
      "attention_bam_16_attention_concentration_10": 0.6906287044622902,
      "attention_bam_16_attention_concentration_20": 1.0992154336765438,
      "attention_bam_16_attention_center_y": 0.4843107347394633,
      "attention_bam_16_attention_center_x": 0.4732631064643782,
      "attention_bam_16_attention_center_distance": 0.0438409516400057,
      "attention_bam_16_attention_spatial_variance": 42.23519194613883,
      "attention_bam_16_attention_spatial_std": 6.498860819108133,
      "attention_bam_16_num_attention_peaks": 2,
      "attention_bam_16_peak_separation_mean": 10.67359150218686,
      "attention_bam_16_peak_intensity_mean": 0.3833422064781189,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 86,
      "phase": "train",
      "loss": 0.08100821822881699,
      "timestamp": 1759543893.5439758,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.08100821822881699,
      "ssim": 0.49844276905059814,
      "attention_bam_384_mean_attention": 0.1987227350473404,
      "attention_bam_384_std_attention": 0.5286148190498352,
      "attention_bam_384_max_attention": 5.313092231750488,
      "attention_bam_384_min_attention": -1.578941822052002,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1780533836683267,
      "attention_bam_384_attention_skewness": 0.540165744771926,
      "attention_bam_384_attention_sparsity": 0.44416554768880206,
      "attention_bam_384_attention_concentration_10": 0.6070108376857831,
      "attention_bam_384_attention_concentration_20": 0.9776564647841195,
      "attention_bam_384_attention_center_y": 0.4833604861913687,
      "attention_bam_384_attention_center_x": 0.4805280194343193,
      "attention_bam_384_attention_center_distance": 0.03622240872548042,
      "attention_bam_384_attention_spatial_variance": 171.4186887822949,
      "attention_bam_384_attention_spatial_std": 13.092696008931656,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 17.149456733508806,
      "attention_bam_384_peak_intensity_mean": 0.25983038544654846,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2254011332988739,
      "attention_bam_16_std_attention": 0.5914055109024048,
      "attention_bam_16_max_attention": 2.2609457969665527,
      "attention_bam_16_min_attention": -1.1631311178207397,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.10440851251754024,
      "attention_bam_16_attention_skewness": 0.28338236480303003,
      "attention_bam_16_attention_sparsity": 0.428955078125,
      "attention_bam_16_attention_concentration_10": 0.5875210079470085,
      "attention_bam_16_attention_concentration_20": 0.9642225844038133,
      "attention_bam_16_attention_center_y": 0.4679821389493054,
      "attention_bam_16_attention_center_x": 0.4602864138938068,
      "attention_bam_16_attention_center_distance": 0.07214308487548349,
      "attention_bam_16_attention_spatial_variance": 42.89828152123903,
      "attention_bam_16_attention_spatial_std": 6.549677970804292,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.266626333327965,
      "attention_bam_16_peak_intensity_mean": 0.41235747933387756,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 87,
      "phase": "train",
      "loss": 0.05698442459106445,
      "timestamp": 1759543893.6832342,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.05698442459106445,
      "ssim": 0.5218861699104309,
      "attention_bam_384_mean_attention": 0.1938149780035019,
      "attention_bam_384_std_attention": 0.5615091323852539,
      "attention_bam_384_max_attention": 5.84591007232666,
      "attention_bam_384_min_attention": -1.5966639518737793,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8499046198037776,
      "attention_bam_384_attention_skewness": 0.6733144630902748,
      "attention_bam_384_attention_sparsity": 0.443817138671875,
      "attention_bam_384_attention_concentration_10": 0.6578271900220428,
      "attention_bam_384_attention_concentration_20": 1.0348211235087996,
      "attention_bam_384_attention_center_y": 0.4790166027229624,
      "attention_bam_384_attention_center_x": 0.4849154863607543,
      "attention_bam_384_attention_center_distance": 0.03654710694483427,
      "attention_bam_384_attention_spatial_variance": 169.56562377088093,
      "attention_bam_384_attention_spatial_std": 13.021736588139115,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 16.706629631609687,
      "attention_bam_384_peak_intensity_mean": 0.2419014722108841,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22490042448043823,
      "attention_bam_16_std_attention": 0.622229278087616,
      "attention_bam_16_max_attention": 3.367877960205078,
      "attention_bam_16_min_attention": -1.1587200164794922,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6711529821035804,
      "attention_bam_16_attention_skewness": 0.4823639694369112,
      "attention_bam_16_attention_sparsity": 0.419189453125,
      "attention_bam_16_attention_concentration_10": 0.6270938112723631,
      "attention_bam_16_attention_concentration_20": 0.9964365818534507,
      "attention_bam_16_attention_center_y": 0.4533528594790052,
      "attention_bam_16_attention_center_x": 0.47488396932462423,
      "attention_bam_16_attention_center_distance": 0.07492357059926935,
      "attention_bam_16_attention_spatial_variance": 41.43930431418879,
      "attention_bam_16_attention_spatial_std": 6.437336740779434,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.066440015816887,
      "attention_bam_16_peak_intensity_mean": 0.3122766613960266,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 88,
      "phase": "train",
      "loss": 0.06989113986492157,
      "timestamp": 1759543893.8119287,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.06989113986492157,
      "ssim": 0.5508337616920471,
      "attention_bam_384_mean_attention": 0.19070939719676971,
      "attention_bam_384_std_attention": 0.5458773374557495,
      "attention_bam_384_max_attention": 5.02385950088501,
      "attention_bam_384_min_attention": -1.5774145126342773,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7246186076568764,
      "attention_bam_384_attention_skewness": 0.4626945938364674,
      "attention_bam_384_attention_sparsity": 0.45542653401692706,
      "attention_bam_384_attention_concentration_10": 0.6378345003988224,
      "attention_bam_384_attention_concentration_20": 1.0341858152306045,
      "attention_bam_384_attention_center_y": 0.4888400351060427,
      "attention_bam_384_attention_center_x": 0.48031775989852904,
      "attention_bam_384_attention_center_distance": 0.03199798093149977,
      "attention_bam_384_attention_spatial_variance": 170.79852773302932,
      "attention_bam_384_attention_spatial_std": 13.06899107555856,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 17.09632432635136,
      "attention_bam_384_peak_intensity_mean": 0.26988065242767334,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2307218313217163,
      "attention_bam_16_std_attention": 0.6092807054519653,
      "attention_bam_16_max_attention": 2.6415340900421143,
      "attention_bam_16_min_attention": -1.1162047386169434,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.45328581015247504,
      "attention_bam_16_attention_skewness": 0.23212934325211115,
      "attention_bam_16_attention_sparsity": 0.432861328125,
      "attention_bam_16_attention_concentration_10": 0.5725438338090787,
      "attention_bam_16_attention_concentration_20": 0.960505777760725,
      "attention_bam_16_attention_center_y": 0.48374963034340046,
      "attention_bam_16_attention_center_x": 0.4583316581593204,
      "attention_bam_16_attention_center_distance": 0.06325069526460336,
      "attention_bam_16_attention_spatial_variance": 42.33185965471846,
      "attention_bam_16_attention_spatial_std": 6.506293849398324,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.714460443360412,
      "attention_bam_16_peak_intensity_mean": 0.3690241873264313,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 89,
      "phase": "train",
      "loss": 0.04552658647298813,
      "timestamp": 1759543893.9403017,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.04552658647298813,
      "ssim": 0.5432523488998413,
      "attention_bam_384_mean_attention": 0.185505673289299,
      "attention_bam_384_std_attention": 0.5994012355804443,
      "attention_bam_384_max_attention": 5.244689464569092,
      "attention_bam_384_min_attention": -1.52577543258667,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8563355580355818,
      "attention_bam_384_attention_skewness": 0.8939709179805483,
      "attention_bam_384_attention_sparsity": 0.4834391276041667,
      "attention_bam_384_attention_concentration_10": 0.73965679483959,
      "attention_bam_384_attention_concentration_20": 1.1524962604983466,
      "attention_bam_384_attention_center_y": 0.48506810193959227,
      "attention_bam_384_attention_center_x": 0.4814137642531219,
      "attention_bam_384_attention_center_distance": 0.03371675366712929,
      "attention_bam_384_attention_spatial_variance": 167.7767104802668,
      "attention_bam_384_attention_spatial_std": 12.952864952598972,
      "attention_bam_384_num_attention_peaks": 3,
      "attention_bam_384_peak_separation_mean": 20.603727489878196,
      "attention_bam_384_peak_intensity_mean": 0.2554689943790436,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21689221262931824,
      "attention_bam_16_std_attention": 0.7376825213432312,
      "attention_bam_16_max_attention": 3.573336124420166,
      "attention_bam_16_min_attention": -1.221166729927063,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.5604038433374514,
      "attention_bam_16_attention_skewness": 1.0490949516972563,
      "attention_bam_16_attention_sparsity": 0.490966796875,
      "attention_bam_16_attention_concentration_10": 0.8076213691194588,
      "attention_bam_16_attention_concentration_20": 1.2337929797688592,
      "attention_bam_16_attention_center_y": 0.47131759708145576,
      "attention_bam_16_attention_center_x": 0.4621610366308909,
      "attention_bam_16_attention_center_distance": 0.06714860216014171,
      "attention_bam_16_attention_spatial_variance": 40.055511059999354,
      "attention_bam_16_attention_spatial_std": 6.328942333439242,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 10.454402603310248,
      "attention_bam_16_peak_intensity_mean": 0.30826666951179504,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 90,
      "phase": "train",
      "loss": 0.06336280703544617,
      "timestamp": 1759543894.1082695,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.06336280703544617,
      "ssim": 0.520622968673706,
      "attention_bam_384_mean_attention": 0.18826361000537872,
      "attention_bam_384_std_attention": 0.5208513140678406,
      "attention_bam_384_max_attention": 5.285727500915527,
      "attention_bam_384_min_attention": -1.5079671144485474,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2302630151451934,
      "attention_bam_384_attention_skewness": 0.5511290651872318,
      "attention_bam_384_attention_sparsity": 0.45332082112630206,
      "attention_bam_384_attention_concentration_10": 0.6309910340411773,
      "attention_bam_384_attention_concentration_20": 1.0104745674634317,
      "attention_bam_384_attention_center_y": 0.4850974772689807,
      "attention_bam_384_attention_center_x": 0.48645019408774576,
      "attention_bam_384_attention_center_distance": 0.028484466784839284,
      "attention_bam_384_attention_spatial_variance": 170.03227522243878,
      "attention_bam_384_attention_spatial_std": 13.039642449946195,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 16.618626392677175,
      "attention_bam_384_peak_intensity_mean": 0.25064727663993835,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2179812788963318,
      "attention_bam_16_std_attention": 0.5715456008911133,
      "attention_bam_16_max_attention": 2.433363199234009,
      "attention_bam_16_min_attention": -1.0605459213256836,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.14158057477609542,
      "attention_bam_16_attention_skewness": 0.48717701279123576,
      "attention_bam_16_attention_sparsity": 0.44580078125,
      "attention_bam_16_attention_concentration_10": 0.6092572459291166,
      "attention_bam_16_attention_concentration_20": 0.9881813389062604,
      "attention_bam_16_attention_center_y": 0.4760516723351316,
      "attention_bam_16_attention_center_x": 0.47911379933809217,
      "attention_bam_16_attention_center_distance": 0.04493897586802304,
      "attention_bam_16_attention_spatial_variance": 41.79016037409244,
      "attention_bam_16_attention_spatial_std": 6.464530947724857,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.585729187407773,
      "attention_bam_16_peak_intensity_mean": 0.37316185235977173,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 91,
      "phase": "train",
      "loss": 0.08710753172636032,
      "timestamp": 1759543894.236427,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.08710753172636032,
      "ssim": 0.501352071762085,
      "attention_bam_384_mean_attention": 0.19819127023220062,
      "attention_bam_384_std_attention": 0.5461499094963074,
      "attention_bam_384_max_attention": 4.700160026550293,
      "attention_bam_384_min_attention": -1.5380427837371826,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.389205773403627,
      "attention_bam_384_attention_skewness": 0.7000641948452275,
      "attention_bam_384_attention_sparsity": 0.45965830485026044,
      "attention_bam_384_attention_concentration_10": 0.6432923824893341,
      "attention_bam_384_attention_concentration_20": 1.0157990346748411,
      "attention_bam_384_attention_center_y": 0.4892241994476647,
      "attention_bam_384_attention_center_x": 0.48511236295468246,
      "attention_bam_384_attention_center_distance": 0.025990752753116658,
      "attention_bam_384_attention_spatial_variance": 171.30460406872862,
      "attention_bam_384_attention_spatial_std": 13.088338476243981,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 17.26121961109617,
      "attention_bam_384_peak_intensity_mean": 0.28235694766044617,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2337483912706375,
      "attention_bam_16_std_attention": 0.6012226939201355,
      "attention_bam_16_max_attention": 3.0991415977478027,
      "attention_bam_16_min_attention": -1.1236199140548706,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.31553485970512263,
      "attention_bam_16_attention_skewness": 0.5407557936773546,
      "attention_bam_16_attention_sparsity": 0.4443359375,
      "attention_bam_16_attention_concentration_10": 0.599827151709127,
      "attention_bam_16_attention_concentration_20": 0.966203360070293,
      "attention_bam_16_attention_center_y": 0.485451532852787,
      "attention_bam_16_attention_center_x": 0.47233716525255287,
      "attention_bam_16_attention_center_distance": 0.044201590980373164,
      "attention_bam_16_attention_spatial_variance": 42.792419364076885,
      "attention_bam_16_attention_spatial_std": 6.541591500856415,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.648285204264583,
      "attention_bam_16_peak_intensity_mean": 0.33525317907333374,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 92,
      "phase": "train",
      "loss": 0.053917743265628815,
      "timestamp": 1759543894.3646472,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.053917743265628815,
      "ssim": 0.5272382497787476,
      "attention_bam_384_mean_attention": 0.19981642067432404,
      "attention_bam_384_std_attention": 0.5206329822540283,
      "attention_bam_384_max_attention": 4.344592571258545,
      "attention_bam_384_min_attention": -1.4740962982177734,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7270693938851611,
      "attention_bam_384_attention_skewness": 0.5171267784812194,
      "attention_bam_384_attention_sparsity": 0.45008595784505206,
      "attention_bam_384_attention_concentration_10": 0.5971722436608637,
      "attention_bam_384_attention_concentration_20": 0.96793436272309,
      "attention_bam_384_attention_center_y": 0.4808429332826123,
      "attention_bam_384_attention_center_x": 0.48382117434619526,
      "attention_bam_384_attention_center_distance": 0.03546117890738135,
      "attention_bam_384_attention_spatial_variance": 170.38151290964814,
      "attention_bam_384_attention_spatial_std": 13.05302696349196,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 16.51704790385862,
      "attention_bam_384_peak_intensity_mean": 0.29000839591026306,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23829466104507446,
      "attention_bam_16_std_attention": 0.5540207624435425,
      "attention_bam_16_max_attention": 2.362051248550415,
      "attention_bam_16_min_attention": -1.1470146179199219,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.10319527819428975,
      "attention_bam_16_attention_skewness": 0.34341525256973277,
      "attention_bam_16_attention_sparsity": 0.4248046875,
      "attention_bam_16_attention_concentration_10": 0.531584666124775,
      "attention_bam_16_attention_concentration_20": 0.8818528430061222,
      "attention_bam_16_attention_center_y": 0.4639118971567538,
      "attention_bam_16_attention_center_x": 0.47148897525716543,
      "attention_bam_16_attention_center_distance": 0.06504198180731026,
      "attention_bam_16_attention_spatial_variance": 41.83970999679665,
      "attention_bam_16_attention_spatial_std": 6.46836223450702,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.32345756619776,
      "attention_bam_16_peak_intensity_mean": 0.3977319300174713,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 93,
      "phase": "train",
      "loss": 0.04614986479282379,
      "timestamp": 1759543894.4946685,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.04614986479282379,
      "ssim": 0.6140308976173401,
      "attention_bam_384_mean_attention": 0.20472872257232666,
      "attention_bam_384_std_attention": 0.5215386748313904,
      "attention_bam_384_max_attention": 4.644651889801025,
      "attention_bam_384_min_attention": -1.4527274370193481,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8310762360395203,
      "attention_bam_384_attention_skewness": 0.5915288407047299,
      "attention_bam_384_attention_sparsity": 0.4532877604166667,
      "attention_bam_384_attention_concentration_10": 0.5905694632956622,
      "attention_bam_384_attention_concentration_20": 0.9533871864012541,
      "attention_bam_384_attention_center_y": 0.48274308203701616,
      "attention_bam_384_attention_center_x": 0.4739270384573591,
      "attention_bam_384_attention_center_distance": 0.044217655776514986,
      "attention_bam_384_attention_spatial_variance": 168.38407449396234,
      "attention_bam_384_attention_spatial_std": 12.976288933819344,
      "attention_bam_384_num_attention_peaks": 4,
      "attention_bam_384_peak_separation_mean": 13.140418798268934,
      "attention_bam_384_peak_intensity_mean": 0.27378201484680176,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24346205592155457,
      "attention_bam_16_std_attention": 0.5767073631286621,
      "attention_bam_16_max_attention": 2.493480682373047,
      "attention_bam_16_min_attention": -1.062589406967163,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.0678912044390998,
      "attention_bam_16_attention_skewness": 0.4457590210072839,
      "attention_bam_16_attention_sparsity": 0.43994140625,
      "attention_bam_16_attention_concentration_10": 0.5456624374993557,
      "attention_bam_16_attention_concentration_20": 0.894742418218643,
      "attention_bam_16_attention_center_y": 0.4691259369791295,
      "attention_bam_16_attention_center_x": 0.44641344287296725,
      "attention_bam_16_attention_center_distance": 0.08746115563089052,
      "attention_bam_16_attention_spatial_variance": 40.271786917029594,
      "attention_bam_16_attention_spatial_std": 6.346005587535327,
      "attention_bam_16_num_attention_peaks": 2,
      "attention_bam_16_peak_separation_mean": 4.233323162097244,
      "attention_bam_16_peak_intensity_mean": 0.3823208808898926,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 94,
      "phase": "train",
      "loss": 0.05720360204577446,
      "timestamp": 1759543894.6262105,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.05720360204577446,
      "ssim": 0.5562981963157654,
      "attention_bam_384_mean_attention": 0.19766074419021606,
      "attention_bam_384_std_attention": 0.5704951286315918,
      "attention_bam_384_max_attention": 5.292250633239746,
      "attention_bam_384_min_attention": -1.5687477588653564,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0381794575729417,
      "attention_bam_384_attention_skewness": 0.6518020947172193,
      "attention_bam_384_attention_sparsity": 0.46315765380859375,
      "attention_bam_384_attention_concentration_10": 0.663915221763479,
      "attention_bam_384_attention_concentration_20": 1.058574525779444,
      "attention_bam_384_attention_center_y": 0.4794872142889754,
      "attention_bam_384_attention_center_x": 0.4882043918033233,
      "attention_bam_384_attention_center_distance": 0.033463734111898555,
      "attention_bam_384_attention_spatial_variance": 169.43772589719023,
      "attention_bam_384_attention_spatial_std": 13.01682472407116,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 14.435656619025476,
      "attention_bam_384_peak_intensity_mean": 0.2583702802658081,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22208955883979797,
      "attention_bam_16_std_attention": 0.6176315546035767,
      "attention_bam_16_max_attention": 2.4934144020080566,
      "attention_bam_16_min_attention": -1.0302672386169434,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.02686769435705383,
      "attention_bam_16_attention_skewness": 0.49920420958415895,
      "attention_bam_16_attention_sparsity": 0.4453125,
      "attention_bam_16_attention_concentration_10": 0.634337432087571,
      "attention_bam_16_attention_concentration_20": 1.0249757483996815,
      "attention_bam_16_attention_center_y": 0.4577557379499103,
      "attention_bam_16_attention_center_x": 0.48648071540126586,
      "attention_bam_16_attention_center_distance": 0.06272716687717081,
      "attention_bam_16_attention_spatial_variance": 41.37588107918374,
      "attention_bam_16_attention_spatial_std": 6.43240865299957,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 8.899215317091132,
      "attention_bam_16_peak_intensity_mean": 0.3668612539768219,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 95,
      "phase": "train",
      "loss": 0.04292255640029907,
      "timestamp": 1759543894.753903,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.04292255640029907,
      "ssim": 0.4471227824687958,
      "attention_bam_384_mean_attention": 0.2152259796857834,
      "attention_bam_384_std_attention": 0.4033755362033844,
      "attention_bam_384_max_attention": 5.035792827606201,
      "attention_bam_384_min_attention": -1.5089378356933594,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.6381226374450524,
      "attention_bam_384_attention_skewness": 0.7931450219629571,
      "attention_bam_384_attention_sparsity": 0.39102935791015625,
      "attention_bam_384_attention_concentration_10": 0.4702837100852991,
      "attention_bam_384_attention_concentration_20": 0.7411019232731788,
      "attention_bam_384_attention_center_y": 0.48373099216478466,
      "attention_bam_384_attention_center_x": 0.4875765092416759,
      "attention_bam_384_attention_center_distance": 0.028949049675748004,
      "attention_bam_384_attention_spatial_variance": 169.61696175880456,
      "attention_bam_384_attention_spatial_std": 13.023707680948792,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 14.906508861936492,
      "attention_bam_384_peak_intensity_mean": 0.26440849900245667,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.26178687810897827,
      "attention_bam_16_std_attention": 0.37161460518836975,
      "attention_bam_16_max_attention": 2.643282413482666,
      "attention_bam_16_min_attention": -0.9439424276351929,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.691459654380509,
      "attention_bam_16_attention_skewness": 0.5851429931387492,
      "attention_bam_16_attention_sparsity": 0.3466796875,
      "attention_bam_16_attention_concentration_10": 0.37843486704617757,
      "attention_bam_16_attention_concentration_20": 0.6148158436027822,
      "attention_bam_16_attention_center_y": 0.4719914877635676,
      "attention_bam_16_attention_center_x": 0.4807320696508491,
      "attention_bam_16_attention_center_distance": 0.048077643403938074,
      "attention_bam_16_attention_spatial_variance": 41.491169801600975,
      "attention_bam_16_attention_spatial_std": 6.441363970588914,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 5.457889266112063,
      "attention_bam_16_peak_intensity_mean": 0.3454344868659973,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 96,
      "phase": "train",
      "loss": 0.04527075216174126,
      "timestamp": 1759543894.8820972,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.04527075216174126,
      "ssim": 0.5658904314041138,
      "attention_bam_384_mean_attention": 0.202057883143425,
      "attention_bam_384_std_attention": 0.5238495469093323,
      "attention_bam_384_max_attention": 4.857700347900391,
      "attention_bam_384_min_attention": -1.585749626159668,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.235151931190086,
      "attention_bam_384_attention_skewness": 0.6233325727209018,
      "attention_bam_384_attention_sparsity": 0.45453135172526044,
      "attention_bam_384_attention_concentration_10": 0.6029743047771757,
      "attention_bam_384_attention_concentration_20": 0.9682962654717517,
      "attention_bam_384_attention_center_y": 0.47790456635609657,
      "attention_bam_384_attention_center_x": 0.4811982755764121,
      "attention_bam_384_attention_center_distance": 0.04102957541122456,
      "attention_bam_384_attention_spatial_variance": 171.05675867804598,
      "attention_bam_384_attention_spatial_std": 13.07886687286196,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 16.286076609931076,
      "attention_bam_384_peak_intensity_mean": 0.28031373023986816,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24006369709968567,
      "attention_bam_16_std_attention": 0.5717806220054626,
      "attention_bam_16_max_attention": 2.2304506301879883,
      "attention_bam_16_min_attention": -1.0005919933319092,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.31786259866469946,
      "attention_bam_16_attention_skewness": 0.32337634920569913,
      "attention_bam_16_attention_sparsity": 0.432373046875,
      "attention_bam_16_attention_concentration_10": 0.5418008811891367,
      "attention_bam_16_attention_concentration_20": 0.9028881464194419,
      "attention_bam_16_attention_center_y": 0.4508944821510073,
      "attention_bam_16_attention_center_x": 0.4597411923777582,
      "attention_bam_16_attention_center_distance": 0.08980115226858078,
      "attention_bam_16_attention_spatial_variance": 42.219593444327955,
      "attention_bam_16_attention_spatial_std": 6.4976606131997965,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 7.892674790898096,
      "attention_bam_16_peak_intensity_mean": 0.40128204226493835,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 97,
      "phase": "train",
      "loss": 0.0482923686504364,
      "timestamp": 1759543895.010589,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0482923686504364,
      "ssim": 0.5717211961746216,
      "attention_bam_384_mean_attention": 0.2046075016260147,
      "attention_bam_384_std_attention": 0.4853082001209259,
      "attention_bam_384_max_attention": 4.994378089904785,
      "attention_bam_384_min_attention": -1.5139350891113281,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.6492075797432504,
      "attention_bam_384_attention_skewness": 0.5812250474763444,
      "attention_bam_384_attention_sparsity": 0.4324849446614583,
      "attention_bam_384_attention_concentration_10": 0.5562017289761543,
      "attention_bam_384_attention_concentration_20": 0.8940403659539317,
      "attention_bam_384_attention_center_y": 0.48284896613316314,
      "attention_bam_384_attention_center_x": 0.48450403376035134,
      "attention_bam_384_attention_center_distance": 0.03268892572115872,
      "attention_bam_384_attention_spatial_variance": 170.42894207585627,
      "attention_bam_384_attention_spatial_std": 13.054843625101615,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 17.50309862075634,
      "attention_bam_384_peak_intensity_mean": 0.2656165659427643,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24332723021507263,
      "attention_bam_16_std_attention": 0.48471179604530334,
      "attention_bam_16_max_attention": 2.1905550956726074,
      "attention_bam_16_min_attention": -0.9031440019607544,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.048386751353392654,
      "attention_bam_16_attention_skewness": 0.28021733039206,
      "attention_bam_16_attention_sparsity": 0.395263671875,
      "attention_bam_16_attention_concentration_10": 0.4672357807771576,
      "attention_bam_16_attention_concentration_20": 0.7698001287660339,
      "attention_bam_16_attention_center_y": 0.46574337058793525,
      "attention_bam_16_attention_center_x": 0.4747755674977644,
      "attention_bam_16_attention_center_distance": 0.060162923029643094,
      "attention_bam_16_attention_spatial_variance": 41.953696880188915,
      "attention_bam_16_attention_spatial_std": 6.477167350021838,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.481776212491969,
      "attention_bam_16_peak_intensity_mean": 0.381286084651947,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 98,
      "phase": "train",
      "loss": 0.049247682094573975,
      "timestamp": 1759543895.141603,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.049247682094573975,
      "ssim": 0.5240183472633362,
      "attention_bam_384_mean_attention": 0.19770844280719757,
      "attention_bam_384_std_attention": 0.5408373475074768,
      "attention_bam_384_max_attention": 4.816963195800781,
      "attention_bam_384_min_attention": -1.5159029960632324,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0035590167465642,
      "attention_bam_384_attention_skewness": 0.6668340328612868,
      "attention_bam_384_attention_sparsity": 0.46226755777994794,
      "attention_bam_384_attention_concentration_10": 0.6334304660278282,
      "attention_bam_384_attention_concentration_20": 1.0126254749273946,
      "attention_bam_384_attention_center_y": 0.4856074611241307,
      "attention_bam_384_attention_center_x": 0.48508162103248115,
      "attention_bam_384_attention_center_distance": 0.029315634269512822,
      "attention_bam_384_attention_spatial_variance": 170.01359902114297,
      "attention_bam_384_attention_spatial_std": 13.038926298631454,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 16.480264780367786,
      "attention_bam_384_peak_intensity_mean": 0.2754080593585968,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22817859053611755,
      "attention_bam_16_std_attention": 0.6352635025978088,
      "attention_bam_16_max_attention": 2.8091797828674316,
      "attention_bam_16_min_attention": -1.1285350322723389,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.14715108216411643,
      "attention_bam_16_attention_skewness": 0.5670695639357156,
      "attention_bam_16_attention_sparsity": 0.453369140625,
      "attention_bam_16_attention_concentration_10": 0.6444950716344481,
      "attention_bam_16_attention_concentration_20": 1.03992730005393,
      "attention_bam_16_attention_center_y": 0.47649938412795495,
      "attention_bam_16_attention_center_x": 0.47509347272014474,
      "attention_bam_16_attention_center_distance": 0.0484275551211826,
      "attention_bam_16_attention_spatial_variance": 41.910513240886864,
      "attention_bam_16_attention_spatial_std": 6.473832963622622,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.409359280072232,
      "attention_bam_16_peak_intensity_mean": 0.35592490434646606,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 99,
      "phase": "train",
      "loss": 0.04676174744963646,
      "timestamp": 1759543895.26985,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.04676174744963646,
      "ssim": 0.5311862826347351,
      "attention_bam_384_mean_attention": 0.18921451270580292,
      "attention_bam_384_std_attention": 0.5192182660102844,
      "attention_bam_384_max_attention": 4.673749923706055,
      "attention_bam_384_min_attention": -1.489107370376587,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2240279559629244,
      "attention_bam_384_attention_skewness": 0.5998436956191098,
      "attention_bam_384_attention_sparsity": 0.4550577799479167,
      "attention_bam_384_attention_concentration_10": 0.6245453604239124,
      "attention_bam_384_attention_concentration_20": 1.0013978086575848,
      "attention_bam_384_attention_center_y": 0.4840180646394935,
      "attention_bam_384_attention_center_x": 0.4866847624965803,
      "attention_bam_384_attention_center_distance": 0.02941828708949188,
      "attention_bam_384_attention_spatial_variance": 168.82727176242105,
      "attention_bam_384_attention_spatial_std": 12.993354907891227,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 16.663025683096002,
      "attention_bam_384_peak_intensity_mean": 0.2739536464214325,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22107011079788208,
      "attention_bam_16_std_attention": 0.5919705629348755,
      "attention_bam_16_max_attention": 2.9546499252319336,
      "attention_bam_16_min_attention": -1.1306917667388916,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.757652167125253,
      "attention_bam_16_attention_skewness": 0.6318310398442819,
      "attention_bam_16_attention_sparsity": 0.44677734375,
      "attention_bam_16_attention_concentration_10": 0.6177989889768252,
      "attention_bam_16_attention_concentration_20": 0.991782560024378,
      "attention_bam_16_attention_center_y": 0.47203747096907334,
      "attention_bam_16_attention_center_x": 0.47970416302561025,
      "attention_bam_16_attention_center_distance": 0.0488635657376009,
      "attention_bam_16_attention_spatial_variance": 40.87317100066558,
      "attention_bam_16_attention_spatial_std": 6.3932128856049815,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.843195594818651,
      "attention_bam_16_peak_intensity_mean": 0.336359441280365,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 100,
      "phase": "train",
      "loss": 0.04336698353290558,
      "timestamp": 1759543895.645121,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.04336698353290558,
      "ssim": 0.5929754972457886,
      "attention_bam_384_mean_attention": 0.1902947872877121,
      "attention_bam_384_std_attention": 0.5476369261741638,
      "attention_bam_384_max_attention": 4.7972259521484375,
      "attention_bam_384_min_attention": -1.6384613513946533,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7837278214734011,
      "attention_bam_384_attention_skewness": 0.5046946992049592,
      "attention_bam_384_attention_sparsity": 0.45286814371744794,
      "attention_bam_384_attention_concentration_10": 0.6389820784413185,
      "attention_bam_384_attention_concentration_20": 1.0330790313064704,
      "attention_bam_384_attention_center_y": 0.4810554522538573,
      "attention_bam_384_attention_center_x": 0.4830312318869551,
      "attention_bam_384_attention_center_distance": 0.03596762379085302,
      "attention_bam_384_attention_spatial_variance": 170.87901011331732,
      "attention_bam_384_attention_spatial_std": 13.07206984808899,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 18.060838785571864,
      "attention_bam_384_peak_intensity_mean": 0.2844005823135376,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21897898614406586,
      "attention_bam_16_std_attention": 0.61314457654953,
      "attention_bam_16_max_attention": 2.3962109088897705,
      "attention_bam_16_min_attention": -1.0099741220474243,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.19995886710754984,
      "attention_bam_16_attention_skewness": 0.3849270835801891,
      "attention_bam_16_attention_sparsity": 0.438720703125,
      "attention_bam_16_attention_concentration_10": 0.6238774487048242,
      "attention_bam_16_attention_concentration_20": 1.0151204819942798,
      "attention_bam_16_attention_center_y": 0.4609671468595275,
      "attention_bam_16_attention_center_x": 0.46808192687262484,
      "attention_bam_16_attention_center_distance": 0.07130676007855302,
      "attention_bam_16_attention_spatial_variance": 42.363408404328716,
      "attention_bam_16_attention_spatial_std": 6.508717877149747,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.534965282616854,
      "attention_bam_16_peak_intensity_mean": 0.36926040053367615,
      "attention_bam_16_peak_coverage": 0.1015625
    }
  ],
  "summary": {
    "total_batches": 103,
    "latest_batch": 100,
    "latest_metrics": {
      "batch_idx": 100,
      "phase": "train",
      "loss": 0.04336698353290558,
      "timestamp": 1759543895.645121,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.04336698353290558,
      "ssim": 0.5929754972457886,
      "attention_bam_384_mean_attention": 0.1902947872877121,
      "attention_bam_384_std_attention": 0.5476369261741638,
      "attention_bam_384_max_attention": 4.7972259521484375,
      "attention_bam_384_min_attention": -1.6384613513946533,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7837278214734011,
      "attention_bam_384_attention_skewness": 0.5046946992049592,
      "attention_bam_384_attention_sparsity": 0.45286814371744794,
      "attention_bam_384_attention_concentration_10": 0.6389820784413185,
      "attention_bam_384_attention_concentration_20": 1.0330790313064704,
      "attention_bam_384_attention_center_y": 0.4810554522538573,
      "attention_bam_384_attention_center_x": 0.4830312318869551,
      "attention_bam_384_attention_center_distance": 0.03596762379085302,
      "attention_bam_384_attention_spatial_variance": 170.87901011331732,
      "attention_bam_384_attention_spatial_std": 13.07206984808899,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 18.060838785571864,
      "attention_bam_384_peak_intensity_mean": 0.2844005823135376,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21897898614406586,
      "attention_bam_16_std_attention": 0.61314457654953,
      "attention_bam_16_max_attention": 2.3962109088897705,
      "attention_bam_16_min_attention": -1.0099741220474243,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.19995886710754984,
      "attention_bam_16_attention_skewness": 0.3849270835801891,
      "attention_bam_16_attention_sparsity": 0.438720703125,
      "attention_bam_16_attention_concentration_10": 0.6238774487048242,
      "attention_bam_16_attention_concentration_20": 1.0151204819942798,
      "attention_bam_16_attention_center_y": 0.4609671468595275,
      "attention_bam_16_attention_center_x": 0.46808192687262484,
      "attention_bam_16_attention_center_distance": 0.07130676007855302,
      "attention_bam_16_attention_spatial_variance": 42.363408404328716,
      "attention_bam_16_attention_spatial_std": 6.508717877149747,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.534965282616854,
      "attention_bam_16_peak_intensity_mean": 0.36926040053367615,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    "loss_mean": 0.20015851158684897,
    "loss_std": 0.10752261039740744,
    "loss_min": 0.04292255640029907,
    "loss_max": 0.4267430305480957,
    "mse_mean": 0.20015851158684897,
    "mse_std": 0.10752261039740744,
    "mse_min": 0.04292255640029907,
    "mse_max": 0.4267430305480957,
    "ssim_mean": 0.3002594118225513,
    "ssim_std": 0.1626428642508021,
    "ssim_min": 0.00020899297669529915,
    "ssim_max": 0.6140308976173401,
    "attention_bam_384_mean_attention_mean": 0.21018278951422104,
    "attention_bam_384_mean_attention_std": 0.035105626232417746,
    "attention_bam_384_mean_attention_min": 0.0018816147930920124,
    "attention_bam_384_mean_attention_max": 0.24939437210559845,
    "attention_bam_384_std_attention_mean": 0.5440257151150009,
    "attention_bam_384_std_attention_std": 0.058645164763065485,
    "attention_bam_384_std_attention_min": 0.2580847144126892,
    "attention_bam_384_std_attention_max": 0.6589744091033936,
    "attention_bam_384_max_attention_mean": 5.040064445977072,
    "attention_bam_384_max_attention_std": 0.7505789658693877,
    "attention_bam_384_max_attention_min": 1.0809073448181152,
    "attention_bam_384_max_attention_max": 6.873517036437988,
    "attention_bam_384_min_attention_mean": -1.5826977612902817,
    "attention_bam_384_min_attention_std": 0.1300523436584978,
    "attention_bam_384_min_attention_min": -1.7347540855407715,
    "attention_bam_384_min_attention_max": -0.7371022701263428,
    "attention_bam_384_attention_entropy_mean": NaN,
    "attention_bam_384_attention_entropy_std": NaN,
    "attention_bam_384_attention_entropy_min": NaN,
    "attention_bam_384_attention_entropy_max": NaN,
    "attention_bam_384_attention_kurtosis_mean": 1.5978665733102788,
    "attention_bam_384_attention_kurtosis_std": 0.622763758548456,
    "attention_bam_384_attention_kurtosis_min": 0.269354234067654,
    "attention_bam_384_attention_kurtosis_max": 3.6381226374450524,
    "attention_bam_384_attention_skewness_mean": 0.6285426042127834,
    "attention_bam_384_attention_skewness_std": 0.12357839860323604,
    "attention_bam_384_attention_skewness_min": 0.341876143137591,
    "attention_bam_384_attention_skewness_max": 1.1188193510331117,
    "attention_bam_384_attention_sparsity_mean": 0.44326063730184306,
    "attention_bam_384_attention_sparsity_std": 0.03744229951136653,
    "attention_bam_384_attention_sparsity_min": 0.383392333984375,
    "attention_bam_384_attention_sparsity_max": 0.6638692220052084,
    "attention_bam_384_attention_concentration_10_mean": 0.9624202502402023,
    "attention_bam_384_attention_concentration_10_std": 2.7735105568034673,
    "attention_bam_384_attention_concentration_10_min": 0.4702837100852991,
    "attention_bam_384_attention_concentration_10_max": 26.154394441386547,
    "attention_bam_384_attention_concentration_20_mean": 1.5071001207185313,
    "attention_bam_384_attention_concentration_20_std": 4.205018639515798,
    "attention_bam_384_attention_concentration_20_min": 0.7411019232731788,
    "attention_bam_384_attention_concentration_20_max": 39.71070953916689,
    "attention_bam_384_attention_center_y_mean": 0.4833662125478815,
    "attention_bam_384_attention_center_y_std": 0.0029504477269581618,
    "attention_bam_384_attention_center_y_min": 0.4755026919551683,
    "attention_bam_384_attention_center_y_max": 0.4909521004143252,
    "attention_bam_384_attention_center_x_mean": 0.48291202683060186,
    "attention_bam_384_attention_center_x_std": 0.0032815637194135807,
    "attention_bam_384_attention_center_x_min": 0.4739270384573591,
    "attention_bam_384_attention_center_x_max": 0.4903953521509151,
    "attention_bam_384_attention_center_distance_mean": 0.03400351969436252,
    "attention_bam_384_attention_center_distance_std": 0.004459441538010431,
    "attention_bam_384_attention_center_distance_min": 0.02594393875117742,
    "attention_bam_384_attention_center_distance_max": 0.046513314057544455,
    "attention_bam_384_attention_spatial_variance_mean": 170.4966191132445,
    "attention_bam_384_attention_spatial_variance_std": 0.9382250251598777,
    "attention_bam_384_attention_spatial_variance_min": 167.7767104802668,
    "attention_bam_384_attention_spatial_variance_max": 173.57168946436312,
    "attention_bam_384_attention_spatial_std_mean": 13.057386495873063,
    "attention_bam_384_attention_spatial_std_std": 0.03591003130444715,
    "attention_bam_384_attention_spatial_std_min": 12.952864952598972,
    "attention_bam_384_attention_spatial_std_max": 13.174660886123904,
    "attention_bam_384_num_attention_peaks_mean": 12.757281553398059,
    "attention_bam_384_num_attention_peaks_std": 4.3711756829625426,
    "attention_bam_384_num_attention_peaks_min": 3.0,
    "attention_bam_384_num_attention_peaks_max": 27.0,
    "attention_bam_384_peak_separation_mean_mean": 17.103295002096935,
    "attention_bam_384_peak_separation_mean_std": 1.5712389081782883,
    "attention_bam_384_peak_separation_mean_min": 13.076116372764108,
    "attention_bam_384_peak_separation_mean_max": 21.302898129549778,
    "attention_bam_384_peak_intensity_mean_mean": 0.2759431387903621,
    "attention_bam_384_peak_intensity_mean_std": 0.02640148187962386,
    "attention_bam_384_peak_intensity_mean_min": 0.2235737442970276,
    "attention_bam_384_peak_intensity_mean_max": 0.4080160856246948,
    "attention_bam_384_peak_coverage_mean": 0.1005859375,
    "attention_bam_384_peak_coverage_std": 0.0,
    "attention_bam_384_peak_coverage_min": 0.1005859375,
    "attention_bam_384_peak_coverage_max": 0.1005859375,
    "attention_bam_16_mean_attention_mean": 0.23632217690493296,
    "attention_bam_16_mean_attention_std": 0.0426119879404263,
    "attention_bam_16_mean_attention_min": -0.04029373079538345,
    "attention_bam_16_mean_attention_max": 0.2840683162212372,
    "attention_bam_16_std_attention_mean": 0.5611799681938968,
    "attention_bam_16_std_attention_std": 0.09327572924709464,
    "attention_bam_16_std_attention_min": 0.15093879401683807,
    "attention_bam_16_std_attention_max": 0.7584808468818665,
    "attention_bam_16_max_attention_mean": 2.553469655293863,
    "attention_bam_16_max_attention_std": 0.5453397481628004,
    "attention_bam_16_max_attention_min": 0.3069092631340027,
    "attention_bam_16_max_attention_max": 4.281631946563721,
    "attention_bam_16_min_attention_mean": -1.0900469549651284,
    "attention_bam_16_min_attention_std": 0.1405882983613691,
    "attention_bam_16_min_attention_min": -1.4626561403274536,
    "attention_bam_16_min_attention_max": -0.4374985098838806,
    "attention_bam_16_attention_entropy_mean": NaN,
    "attention_bam_16_attention_entropy_std": NaN,
    "attention_bam_16_attention_entropy_min": NaN,
    "attention_bam_16_attention_entropy_max": NaN,
    "attention_bam_16_attention_kurtosis_mean": 0.30747356685500754,
    "attention_bam_16_attention_kurtosis_std": 0.6057294229080604,
    "attention_bam_16_attention_kurtosis_min": -0.4782488894355934,
    "attention_bam_16_attention_kurtosis_max": 2.7766449556298234,
    "attention_bam_16_attention_skewness_mean": 0.44986542058703544,
    "attention_bam_16_attention_skewness_std": 0.2324248983496741,
    "attention_bam_16_attention_skewness_min": -0.2805927456680973,
    "attention_bam_16_attention_skewness_max": 1.2561722685461798,
    "attention_bam_16_attention_sparsity_mean": 0.4314889259708738,
    "attention_bam_16_attention_sparsity_std": 0.06842576436906873,
    "attention_bam_16_attention_sparsity_min": 0.2958984375,
    "attention_bam_16_attention_sparsity_max": 0.831298828125,
    "attention_bam_16_attention_concentration_10_mean": 0.5332098015002605,
    "attention_bam_16_attention_concentration_10_std": 0.18166454281168726,
    "attention_bam_16_attention_concentration_10_min": -0.6226609355982947,
    "attention_bam_16_attention_concentration_10_max": 0.8076213691194588,
    "attention_bam_16_attention_concentration_20_mean": 0.8668005265594433,
    "attention_bam_16_attention_concentration_20_std": 0.2895354016558856,
    "attention_bam_16_attention_concentration_20_min": -1.0122358604732702,
    "attention_bam_16_attention_concentration_20_max": 1.2337929797688592,
    "attention_bam_16_attention_center_y_mean": 0.4698848443947997,
    "attention_bam_16_attention_center_y_std": 0.010311295539577247,
    "attention_bam_16_attention_center_y_min": 0.44570562423575644,
    "attention_bam_16_attention_center_y_max": 0.4938104027186415,
    "attention_bam_16_attention_center_x_mean": 0.46815879086826007,
    "attention_bam_16_attention_center_x_std": 0.010957046106789813,
    "attention_bam_16_attention_center_x_min": 0.4419615538746422,
    "attention_bam_16_attention_center_x_max": 0.4951061975999892,
    "attention_bam_16_attention_center_distance_mean": 0.06370270687180275,
    "attention_bam_16_attention_center_distance_std": 0.015302701685908601,
    "attention_bam_16_attention_center_distance_min": 0.029779753195290627,
    "attention_bam_16_attention_center_distance_max": 0.10185625352542332,
    "attention_bam_16_attention_spatial_variance_mean": 41.79493875630686,
    "attention_bam_16_attention_spatial_variance_std": 0.815237756666656,
    "attention_bam_16_attention_spatial_variance_min": 40.055511059999354,
    "attention_bam_16_attention_spatial_variance_max": 44.74752906971685,
    "attention_bam_16_attention_spatial_std_mean": 6.464598036596971,
    "attention_bam_16_attention_spatial_std_std": 0.06284365114826602,
    "attention_bam_16_attention_spatial_std_min": 6.328942333439242,
    "attention_bam_16_attention_spatial_std_max": 6.689359391579798,
    "attention_bam_16_num_attention_peaks_mean": 5.854368932038835,
    "attention_bam_16_num_attention_peaks_std": 2.6398446440856462,
    "attention_bam_16_num_attention_peaks_min": 2.0,
    "attention_bam_16_num_attention_peaks_max": 18.0,
    "attention_bam_16_peak_separation_mean_mean": 8.694954982838029,
    "attention_bam_16_peak_separation_mean_std": 1.1766032433320643,
    "attention_bam_16_peak_separation_mean_min": 4.233323162097244,
    "attention_bam_16_peak_separation_mean_max": 12.60121261607643,
    "attention_bam_16_peak_intensity_mean_mean": 0.38269514973881175,
    "attention_bam_16_peak_intensity_mean_std": 0.04547798409550131,
    "attention_bam_16_peak_intensity_mean_min": 0.2717783749103546,
    "attention_bam_16_peak_intensity_mean_max": 0.5501440763473511,
    "attention_bam_16_peak_coverage_mean": 0.1015625,
    "attention_bam_16_peak_coverage_std": 0.0,
    "attention_bam_16_peak_coverage_min": 0.1015625,
    "attention_bam_16_peak_coverage_max": 0.1015625
  },
  "metadata": {
    "created_at": "2025-10-04T09:11:37.756123",
    "total_batches": 103,
    "device": "cuda:0"
  }
}