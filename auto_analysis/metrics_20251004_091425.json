{
  "batch_metrics": [
    {
      "batch_idx": 0,
      "phase": "val",
      "loss": 0.39310094714164734,
      "timestamp": 1759543874.6647391,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.39310094714164734,
      "ssim": 0.00020899297669529915,
      "attention_bam_384_mean_attention": 0.0018816147930920124,
      "attention_bam_384_std_attention": 0.2580847144126892,
      "attention_bam_384_max_attention": 1.1563959121704102,
      "attention_bam_384_min_attention": -0.7739594578742981,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.29628766882657454,
      "attention_bam_384_attention_skewness": 0.35071835586104816,
      "attention_bam_384_attention_sparsity": 0.6638692220052084,
      "attention_bam_384_attention_concentration_10": 26.154394441386547,
      "attention_bam_384_attention_concentration_20": 39.71070953916689,
      "attention_bam_384_attention_center_y": 0.48400760045313507,
      "attention_bam_384_attention_center_x": 0.48398210923841173,
      "attention_bam_384_attention_center_distance": 0.03201030045834436,
      "attention_bam_384_attention_spatial_variance": 170.69224720301509,
      "attention_bam_384_attention_spatial_std": 13.064924309119249,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 17.863983381061118,
      "attention_bam_384_peak_intensity_mean": 0.40234407782554626,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": -0.04029373079538345,
      "attention_bam_16_std_attention": 0.15093879401683807,
      "attention_bam_16_max_attention": 0.3247266113758087,
      "attention_bam_16_min_attention": -0.4810439944267273,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.41239729777566936,
      "attention_bam_16_attention_skewness": -0.2805927456680973,
      "attention_bam_16_attention_sparsity": 0.830322265625,
      "attention_bam_16_attention_concentration_10": -0.5440104284007552,
      "attention_bam_16_attention_concentration_20": -0.882576852360917,
      "attention_bam_16_attention_center_y": 0.4711564547432987,
      "attention_bam_16_attention_center_x": 0.47221550214925223,
      "attention_bam_16_attention_center_distance": 0.05663794529806997,
      "attention_bam_16_attention_spatial_variance": 42.06734573472946,
      "attention_bam_16_attention_spatial_std": 6.485934453471563,
      "attention_bam_16_num_attention_peaks": 18,
      "attention_bam_16_peak_separation_mean": 8.800793652546577,
      "attention_bam_16_peak_intensity_mean": 0.5501440763473511,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 1,
      "phase": "val",
      "loss": 0.3988092541694641,
      "timestamp": 1759543877.1654897,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3988092541694641,
      "ssim": 0.00020980967383366078,
      "attention_bam_384_mean_attention": 0.003926893230527639,
      "attention_bam_384_std_attention": 0.2596164047718048,
      "attention_bam_384_max_attention": 1.0809073448181152,
      "attention_bam_384_min_attention": -0.7371022701263428,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.269354234067654,
      "attention_bam_384_attention_skewness": 0.341876143137591,
      "attention_bam_384_attention_sparsity": 0.6605555216471354,
      "attention_bam_384_attention_concentration_10": 12.632917790780986,
      "attention_bam_384_attention_concentration_20": 19.18165441550895,
      "attention_bam_384_attention_center_y": 0.4844054206493133,
      "attention_bam_384_attention_center_x": 0.4839248103666182,
      "attention_bam_384_attention_center_distance": 0.03167341556807693,
      "attention_bam_384_attention_spatial_variance": 170.61314475370582,
      "attention_bam_384_attention_spatial_std": 13.06189667520402,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 16.142337763011763,
      "attention_bam_384_peak_intensity_mean": 0.4080160856246948,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": -0.036860883235931396,
      "attention_bam_16_std_attention": 0.15095260739326477,
      "attention_bam_16_max_attention": 0.3069092631340027,
      "attention_bam_16_min_attention": -0.4374985098838806,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.32570253323161236,
      "attention_bam_16_attention_skewness": -0.16595645827933456,
      "attention_bam_16_attention_sparsity": 0.831298828125,
      "attention_bam_16_attention_concentration_10": -0.6226609355982947,
      "attention_bam_16_attention_concentration_20": -1.0122358604732702,
      "attention_bam_16_attention_center_y": 0.47149141224763363,
      "attention_bam_16_attention_center_x": 0.47264896803862655,
      "attention_bam_16_attention_center_distance": 0.0558716122013039,
      "attention_bam_16_attention_spatial_variance": 42.043367512307526,
      "attention_bam_16_attention_spatial_std": 6.48408571136344,
      "attention_bam_16_num_attention_peaks": 17,
      "attention_bam_16_peak_separation_mean": 8.3456757218609,
      "attention_bam_16_peak_intensity_mean": 0.5413674116134644,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 0,
      "phase": "train",
      "loss": 0.4267430305480957,
      "timestamp": 1759543879.178167,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.4267430305480957,
      "ssim": 0.013403704389929771,
      "attention_bam_384_mean_attention": 0.24239784479141235,
      "attention_bam_384_std_attention": 0.6487302780151367,
      "attention_bam_384_max_attention": 5.856725692749023,
      "attention_bam_384_min_attention": -1.6646728515625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.534694363536178,
      "attention_bam_384_attention_skewness": 0.8736138847268147,
      "attention_bam_384_attention_sparsity": 0.44314320882161456,
      "attention_bam_384_attention_concentration_10": 0.6289784835318324,
      "attention_bam_384_attention_concentration_20": 0.9852027202974504,
      "attention_bam_384_attention_center_y": 0.48145715175717607,
      "attention_bam_384_attention_center_x": 0.4796577473827837,
      "attention_bam_384_attention_center_distance": 0.03892671222949714,
      "attention_bam_384_attention_spatial_variance": 172.18567549909645,
      "attention_bam_384_attention_spatial_std": 13.121953951264135,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 16.118103884420577,
      "attention_bam_384_peak_intensity_mean": 0.25419673323631287,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24812737107276917,
      "attention_bam_16_std_attention": 0.6378040313720703,
      "attention_bam_16_max_attention": 2.6941933631896973,
      "attention_bam_16_min_attention": -1.4626561403274536,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.057724874247045754,
      "attention_bam_16_attention_skewness": 0.29631591064328877,
      "attention_bam_16_attention_sparsity": 0.42822265625,
      "attention_bam_16_attention_concentration_10": 0.5793263280121307,
      "attention_bam_16_attention_concentration_20": 0.9474033221807019,
      "attention_bam_16_attention_center_y": 0.47220440114735296,
      "attention_bam_16_attention_center_x": 0.47425617897689026,
      "attention_bam_16_attention_center_distance": 0.0535787203364765,
      "attention_bam_16_attention_spatial_variance": 42.152301583435985,
      "attention_bam_16_attention_spatial_std": 6.492480387605032,
      "attention_bam_16_num_attention_peaks": 16,
      "attention_bam_16_peak_separation_mean": 8.706385823308292,
      "attention_bam_16_peak_intensity_mean": 0.4145677089691162,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 1,
      "phase": "train",
      "loss": 0.4258974492549896,
      "timestamp": 1759543881.86557,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.4258974492549896,
      "ssim": 0.016951894387602806,
      "attention_bam_384_mean_attention": 0.23801599442958832,
      "attention_bam_384_std_attention": 0.6105653047561646,
      "attention_bam_384_max_attention": 6.410161972045898,
      "attention_bam_384_min_attention": -1.6058658361434937,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.8801130887282147,
      "attention_bam_384_attention_skewness": 0.8517456241730891,
      "attention_bam_384_attention_sparsity": 0.4327392578125,
      "attention_bam_384_attention_concentration_10": 0.602700960797322,
      "attention_bam_384_attention_concentration_20": 0.9465016636006941,
      "attention_bam_384_attention_center_y": 0.4831309653333237,
      "attention_bam_384_attention_center_x": 0.48135246804384146,
      "attention_bam_384_attention_center_distance": 0.035561067999751624,
      "attention_bam_384_attention_spatial_variance": 171.8650237608112,
      "attention_bam_384_attention_spatial_std": 13.109730117771731,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 18.838892293518576,
      "attention_bam_384_peak_intensity_mean": 0.23134875297546387,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.26207786798477173,
      "attention_bam_16_std_attention": 0.5612547993659973,
      "attention_bam_16_max_attention": 2.8337326049804688,
      "attention_bam_16_min_attention": -1.3532273769378662,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.35006465682651333,
      "attention_bam_16_attention_skewness": 0.23969473808477748,
      "attention_bam_16_attention_sparsity": 0.39111328125,
      "attention_bam_16_attention_concentration_10": 0.49805301963152987,
      "attention_bam_16_attention_concentration_20": 0.8111083920389983,
      "attention_bam_16_attention_center_y": 0.47047880310943996,
      "attention_bam_16_attention_center_x": 0.4703908916705262,
      "attention_bam_16_attention_center_distance": 0.05913037057076041,
      "attention_bam_16_attention_spatial_variance": 42.37733068420165,
      "attention_bam_16_attention_spatial_std": 6.509787299459304,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.661368812411373,
      "attention_bam_16_peak_intensity_mean": 0.3919750452041626,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 2,
      "phase": "train",
      "loss": 0.33748167753219604,
      "timestamp": 1759543881.9946542,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.33748167753219604,
      "ssim": 0.05069499462842941,
      "attention_bam_384_mean_attention": 0.23700594902038574,
      "attention_bam_384_std_attention": 0.5310591459274292,
      "attention_bam_384_max_attention": 6.873517036437988,
      "attention_bam_384_min_attention": -1.6581459045410156,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.437382566087492,
      "attention_bam_384_attention_skewness": 0.8839038748113122,
      "attention_bam_384_attention_sparsity": 0.42022959391276044,
      "attention_bam_384_attention_concentration_10": 0.5434455817384087,
      "attention_bam_384_attention_concentration_20": 0.8552389574897019,
      "attention_bam_384_attention_center_y": 0.4835491628551401,
      "attention_bam_384_attention_center_x": 0.48364742432732055,
      "attention_bam_384_attention_center_distance": 0.03280355998660541,
      "attention_bam_384_attention_spatial_variance": 170.34239707407292,
      "attention_bam_384_attention_spatial_std": 13.051528534009835,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 18.544440013949153,
      "attention_bam_384_peak_intensity_mean": 0.2235737442970276,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2488078773021698,
      "attention_bam_16_std_attention": 0.5053659081459045,
      "attention_bam_16_max_attention": 2.4671218395233154,
      "attention_bam_16_min_attention": -0.9959535598754883,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.21039486840208,
      "attention_bam_16_attention_skewness": 0.7890960858175331,
      "attention_bam_16_attention_sparsity": 0.41748046875,
      "attention_bam_16_attention_concentration_10": 0.51635614180398,
      "attention_bam_16_attention_concentration_20": 0.8131302024317816,
      "attention_bam_16_attention_center_y": 0.46112155971991997,
      "attention_bam_16_attention_center_x": 0.47599809430865186,
      "attention_bam_16_attention_center_distance": 0.06461616818456692,
      "attention_bam_16_attention_spatial_variance": 40.405388046731694,
      "attention_bam_16_attention_spatial_std": 6.3565232672217675,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 7.887368513961374,
      "attention_bam_16_peak_intensity_mean": 0.3847465515136719,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 3,
      "phase": "train",
      "loss": 0.3694000840187073,
      "timestamp": 1759543882.120746,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3694000840187073,
      "ssim": 0.03965817019343376,
      "attention_bam_384_mean_attention": 0.23552292585372925,
      "attention_bam_384_std_attention": 0.6589744091033936,
      "attention_bam_384_max_attention": 5.477872371673584,
      "attention_bam_384_min_attention": -1.6044543981552124,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8762540201223352,
      "attention_bam_384_attention_skewness": 0.8538069973476711,
      "attention_bam_384_attention_sparsity": 0.4516398111979167,
      "attention_bam_384_attention_concentration_10": 0.6602692180538312,
      "attention_bam_384_attention_concentration_20": 1.0320847607740138,
      "attention_bam_384_attention_center_y": 0.4835124320287507,
      "attention_bam_384_attention_center_x": 0.48053814288385477,
      "attention_bam_384_attention_center_distance": 0.03607225471233585,
      "attention_bam_384_attention_spatial_variance": 170.49564287395665,
      "attention_bam_384_attention_spatial_std": 13.05739801315548,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 17.120951669398693,
      "attention_bam_384_peak_intensity_mean": 0.2602115273475647,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22047415375709534,
      "attention_bam_16_std_attention": 0.6282044053077698,
      "attention_bam_16_max_attention": 3.381847858428955,
      "attention_bam_16_min_attention": -1.1512823104858398,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.4569991340566188,
      "attention_bam_16_attention_skewness": 0.9141609711832295,
      "attention_bam_16_attention_sparsity": 0.4697265625,
      "attention_bam_16_attention_concentration_10": 0.6871251039917099,
      "attention_bam_16_attention_concentration_20": 1.06797902372266,
      "attention_bam_16_attention_center_y": 0.46410635935593303,
      "attention_bam_16_attention_center_x": 0.46132778619777604,
      "attention_bam_16_attention_center_distance": 0.07461760595262136,
      "attention_bam_16_attention_spatial_variance": 41.189074232676774,
      "attention_bam_16_attention_spatial_std": 6.41787147212195,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.910703804257718,
      "attention_bam_16_peak_intensity_mean": 0.3195565640926361,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 4,
      "phase": "train",
      "loss": 0.2841787040233612,
      "timestamp": 1759543882.249333,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.2841787040233612,
      "ssim": 0.04546130448579788,
      "attention_bam_384_mean_attention": 0.2303868979215622,
      "attention_bam_384_std_attention": 0.6338685750961304,
      "attention_bam_384_max_attention": 4.968445301055908,
      "attention_bam_384_min_attention": -1.6243762969970703,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.9175126379528553,
      "attention_bam_384_attention_skewness": 0.8813600324128805,
      "attention_bam_384_attention_sparsity": 0.458160400390625,
      "attention_bam_384_attention_concentration_10": 0.6536228525755953,
      "attention_bam_384_attention_concentration_20": 1.02240777484709,
      "attention_bam_384_attention_center_y": 0.4816905937513723,
      "attention_bam_384_attention_center_x": 0.4876451887867133,
      "attention_bam_384_attention_center_distance": 0.03123702025780441,
      "attention_bam_384_attention_spatial_variance": 171.3986565666615,
      "attention_bam_384_attention_spatial_std": 13.091930971658133,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 17.036638592722543,
      "attention_bam_384_peak_intensity_mean": 0.28282609581947327,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23555819690227509,
      "attention_bam_16_std_attention": 0.6394479274749756,
      "attention_bam_16_max_attention": 3.883251667022705,
      "attention_bam_16_min_attention": -1.0876038074493408,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.470514919654436,
      "attention_bam_16_attention_skewness": 1.1381923226463966,
      "attention_bam_16_attention_sparsity": 0.476318359375,
      "attention_bam_16_attention_concentration_10": 0.6623125329233661,
      "attention_bam_16_attention_concentration_20": 1.0233418519820787,
      "attention_bam_16_attention_center_y": 0.4615513722101179,
      "attention_bam_16_attention_center_x": 0.4875011312058462,
      "attention_bam_16_attention_center_distance": 0.057175496500832715,
      "attention_bam_16_attention_spatial_variance": 42.27590186755082,
      "attention_bam_16_attention_spatial_std": 6.501992146069605,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.904307463219222,
      "attention_bam_16_peak_intensity_mean": 0.2717783749103546,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 5,
      "phase": "train",
      "loss": 0.3167078197002411,
      "timestamp": 1759543882.3743033,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3167078197002411,
      "ssim": 0.05054883658885956,
      "attention_bam_384_mean_attention": 0.23328012228012085,
      "attention_bam_384_std_attention": 0.6209129095077515,
      "attention_bam_384_max_attention": 4.539158821105957,
      "attention_bam_384_min_attention": -1.5950757265090942,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.081839269070775,
      "attention_bam_384_attention_skewness": 0.6767320896327925,
      "attention_bam_384_attention_sparsity": 0.44707489013671875,
      "attention_bam_384_attention_concentration_10": 0.6239182589633429,
      "attention_bam_384_attention_concentration_20": 0.9942715387713794,
      "attention_bam_384_attention_center_y": 0.48250350932976205,
      "attention_bam_384_attention_center_x": 0.4787702256864887,
      "attention_bam_384_attention_center_distance": 0.03890579656494256,
      "attention_bam_384_attention_spatial_variance": 170.2881742921341,
      "attention_bam_384_attention_spatial_std": 13.049451110760717,
      "attention_bam_384_num_attention_peaks": 18,
      "attention_bam_384_peak_separation_mean": 16.575853145951577,
      "attention_bam_384_peak_intensity_mean": 0.29979491233825684,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.25082606077194214,
      "attention_bam_16_std_attention": 0.6373257040977478,
      "attention_bam_16_max_attention": 3.089731216430664,
      "attention_bam_16_min_attention": -1.224957823753357,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6696717360298168,
      "attention_bam_16_attention_skewness": 0.7356083365628369,
      "attention_bam_16_attention_sparsity": 0.45361328125,
      "attention_bam_16_attention_concentration_10": 0.6174369909090285,
      "attention_bam_16_attention_concentration_20": 0.9765555065143628,
      "attention_bam_16_attention_center_y": 0.4692406954458638,
      "attention_bam_16_attention_center_x": 0.4579268037869964,
      "attention_bam_16_attention_center_distance": 0.07370601951309005,
      "attention_bam_16_attention_spatial_variance": 41.110453610452275,
      "attention_bam_16_attention_spatial_std": 6.41174341427137,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.50284960867109,
      "attention_bam_16_peak_intensity_mean": 0.3481826186180115,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 6,
      "phase": "train",
      "loss": 0.3431699275970459,
      "timestamp": 1759543882.5003688,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3431699275970459,
      "ssim": 0.0595417320728302,
      "attention_bam_384_mean_attention": 0.2292398363351822,
      "attention_bam_384_std_attention": 0.6126567721366882,
      "attention_bam_384_max_attention": 4.780694007873535,
      "attention_bam_384_min_attention": -1.5935810804367065,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1106878861842606,
      "attention_bam_384_attention_skewness": 0.6327801681825788,
      "attention_bam_384_attention_sparsity": 0.444976806640625,
      "attention_bam_384_attention_concentration_10": 0.6200170930555069,
      "attention_bam_384_attention_concentration_20": 0.9891956322830404,
      "attention_bam_384_attention_center_y": 0.48440284475299944,
      "attention_bam_384_attention_center_x": 0.4877753152872934,
      "attention_bam_384_attention_center_distance": 0.028025494397927026,
      "attention_bam_384_attention_spatial_variance": 171.97883619786361,
      "attention_bam_384_attention_spatial_std": 13.114070161390154,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 17.704303608796547,
      "attention_bam_384_peak_intensity_mean": 0.28822392225265503,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2242298126220703,
      "attention_bam_16_std_attention": 0.6087504625320435,
      "attention_bam_16_max_attention": 2.355156421661377,
      "attention_bam_16_min_attention": -1.2386834621429443,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.11594419740688666,
      "attention_bam_16_attention_skewness": 0.47741291848688544,
      "attention_bam_16_attention_sparsity": 0.4638671875,
      "attention_bam_16_attention_concentration_10": 0.6218324954636661,
      "attention_bam_16_attention_concentration_20": 1.0162044199283713,
      "attention_bam_16_attention_center_y": 0.47499854866071384,
      "attention_bam_16_attention_center_x": 0.48640738335096384,
      "attention_bam_16_attention_center_distance": 0.0402450443269317,
      "attention_bam_16_attention_spatial_variance": 42.888893088114585,
      "attention_bam_16_attention_spatial_std": 6.548961222065266,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.199931508556464,
      "attention_bam_16_peak_intensity_mean": 0.43915703892707825,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 7,
      "phase": "train",
      "loss": 0.3647286891937256,
      "timestamp": 1759543882.6266258,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3647286891937256,
      "ssim": 0.07457921653985977,
      "attention_bam_384_mean_attention": 0.24724024534225464,
      "attention_bam_384_std_attention": 0.5537768602371216,
      "attention_bam_384_max_attention": 5.831225395202637,
      "attention_bam_384_min_attention": -1.492278814315796,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5127739494927663,
      "attention_bam_384_attention_skewness": 0.579157955451498,
      "attention_bam_384_attention_sparsity": 0.40803273518880206,
      "attention_bam_384_attention_concentration_10": 0.5329632516337234,
      "attention_bam_384_attention_concentration_20": 0.848878363877663,
      "attention_bam_384_attention_center_y": 0.48004151507879855,
      "attention_bam_384_attention_center_x": 0.48552158005331,
      "attention_bam_384_attention_center_distance": 0.034870209764282664,
      "attention_bam_384_attention_spatial_variance": 170.54754252383495,
      "attention_bam_384_attention_spatial_std": 13.059385227637438,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 17.625875102183358,
      "attention_bam_384_peak_intensity_mean": 0.2399333119392395,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.26392143964767456,
      "attention_bam_16_std_attention": 0.5027231574058533,
      "attention_bam_16_max_attention": 2.8186798095703125,
      "attention_bam_16_min_attention": -1.115267038345337,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8858798948740518,
      "attention_bam_16_attention_skewness": 0.4400892100158408,
      "attention_bam_16_attention_sparsity": 0.3759765625,
      "attention_bam_16_attention_concentration_10": 0.45712043744341835,
      "attention_bam_16_attention_concentration_20": 0.7453255709734443,
      "attention_bam_16_attention_center_y": 0.45739053846664146,
      "attention_bam_16_attention_center_x": 0.4746216382737524,
      "attention_bam_16_attention_center_distance": 0.07013740023797616,
      "attention_bam_16_attention_spatial_variance": 41.36406140800173,
      "attention_bam_16_attention_spatial_std": 6.4314898280259865,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.612880260028183,
      "attention_bam_16_peak_intensity_mean": 0.36339637637138367,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 8,
      "phase": "train",
      "loss": 0.34880995750427246,
      "timestamp": 1759543882.7533433,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.34880995750427246,
      "ssim": 0.08510035276412964,
      "attention_bam_384_mean_attention": 0.2321234941482544,
      "attention_bam_384_std_attention": 0.5946976542472839,
      "attention_bam_384_max_attention": 4.739882469177246,
      "attention_bam_384_min_attention": -1.5611920356750488,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.001334573188144,
      "attention_bam_384_attention_skewness": 0.7939721453756098,
      "attention_bam_384_attention_sparsity": 0.4349314371744792,
      "attention_bam_384_attention_concentration_10": 0.6071412369839749,
      "attention_bam_384_attention_concentration_20": 0.9496737953898068,
      "attention_bam_384_attention_center_y": 0.4840661221728107,
      "attention_bam_384_attention_center_x": 0.4783472037658916,
      "attention_bam_384_attention_center_distance": 0.03801925952376276,
      "attention_bam_384_attention_spatial_variance": 172.20422518793748,
      "attention_bam_384_attention_spatial_std": 13.122660751080074,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 15.773369234384738,
      "attention_bam_384_peak_intensity_mean": 0.2878284454345703,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2522990107536316,
      "attention_bam_16_std_attention": 0.607127845287323,
      "attention_bam_16_max_attention": 2.6932742595672607,
      "attention_bam_16_min_attention": -1.2775815725326538,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.21938135286012184,
      "attention_bam_16_attention_skewness": 0.39832400593630485,
      "attention_bam_16_attention_sparsity": 0.4111328125,
      "attention_bam_16_attention_concentration_10": 0.550753802079542,
      "attention_bam_16_attention_concentration_20": 0.8952913799635778,
      "attention_bam_16_attention_center_y": 0.47189869478173546,
      "attention_bam_16_attention_center_x": 0.45458711918542427,
      "attention_bam_16_attention_center_distance": 0.07552500379144542,
      "attention_bam_16_attention_spatial_variance": 42.562479616131576,
      "attention_bam_16_attention_spatial_std": 6.523992613126687,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.336883473956902,
      "attention_bam_16_peak_intensity_mean": 0.4106374979019165,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 9,
      "phase": "train",
      "loss": 0.3215574622154236,
      "timestamp": 1759543882.8792298,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3215574622154236,
      "ssim": 0.11707844585180283,
      "attention_bam_384_mean_attention": 0.2436491996049881,
      "attention_bam_384_std_attention": 0.5774238109588623,
      "attention_bam_384_max_attention": 5.903816223144531,
      "attention_bam_384_min_attention": -1.5801115036010742,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.105912195538444,
      "attention_bam_384_attention_skewness": 0.6702603264680402,
      "attention_bam_384_attention_sparsity": 0.41610463460286456,
      "attention_bam_384_attention_concentration_10": 0.557890532587264,
      "attention_bam_384_attention_concentration_20": 0.887278641758147,
      "attention_bam_384_attention_center_y": 0.48574233106287523,
      "attention_bam_384_attention_center_x": 0.48389681282127645,
      "attention_bam_384_attention_center_distance": 0.030416895332484515,
      "attention_bam_384_attention_spatial_variance": 169.64268409988748,
      "attention_bam_384_attention_spatial_std": 13.024695163415053,
      "attention_bam_384_num_attention_peaks": 27,
      "attention_bam_384_peak_separation_mean": 16.44021374647472,
      "attention_bam_384_peak_intensity_mean": 0.24458596110343933,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2561837434768677,
      "attention_bam_16_std_attention": 0.4674566984176636,
      "attention_bam_16_max_attention": 2.612687587738037,
      "attention_bam_16_min_attention": -1.1911619901657104,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.492367459380072,
      "attention_bam_16_attention_skewness": 0.285479177845714,
      "attention_bam_16_attention_sparsity": 0.373291015625,
      "attention_bam_16_attention_concentration_10": 0.4354928397720274,
      "attention_bam_16_attention_concentration_20": 0.7196677563012349,
      "attention_bam_16_attention_center_y": 0.4762971678631048,
      "attention_bam_16_attention_center_x": 0.47395586595993117,
      "attention_bam_16_attention_center_distance": 0.04980203146874443,
      "attention_bam_16_attention_spatial_variance": 41.09223854302123,
      "attention_bam_16_attention_spatial_std": 6.410322811139953,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 8.487033192896051,
      "attention_bam_16_peak_intensity_mean": 0.3893619775772095,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 10,
      "phase": "train",
      "loss": 0.38763195276260376,
      "timestamp": 1759543883.0696948,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.38763195276260376,
      "ssim": 0.10068527609109879,
      "attention_bam_384_mean_attention": 0.24192099273204803,
      "attention_bam_384_std_attention": 0.520797073841095,
      "attention_bam_384_max_attention": 5.182400703430176,
      "attention_bam_384_min_attention": -1.5303912162780762,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.3522756766521784,
      "attention_bam_384_attention_skewness": 0.6291289146520442,
      "attention_bam_384_attention_sparsity": 0.39889272054036456,
      "attention_bam_384_attention_concentration_10": 0.5115074535888168,
      "attention_bam_384_attention_concentration_20": 0.8164498818275525,
      "attention_bam_384_attention_center_y": 0.48000354813973395,
      "attention_bam_384_attention_center_x": 0.483614752794765,
      "attention_bam_384_attention_center_distance": 0.03656048175220339,
      "attention_bam_384_attention_spatial_variance": 169.8854043228108,
      "attention_bam_384_attention_spatial_std": 13.0340095259598,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 17.11817919812654,
      "attention_bam_384_peak_intensity_mean": 0.2640001177787781,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.27161967754364014,
      "attention_bam_16_std_attention": 0.4287073612213135,
      "attention_bam_16_max_attention": 2.820946216583252,
      "attention_bam_16_min_attention": -0.8940313458442688,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.14366590756552,
      "attention_bam_16_attention_skewness": 0.40890267903522476,
      "attention_bam_16_attention_sparsity": 0.3388671875,
      "attention_bam_16_attention_concentration_10": 0.3956453907801618,
      "attention_bam_16_attention_concentration_20": 0.6460059881153832,
      "attention_bam_16_attention_center_y": 0.45746119858992706,
      "attention_bam_16_attention_center_x": 0.47613443509192327,
      "attention_bam_16_attention_center_distance": 0.06897992191626845,
      "attention_bam_16_attention_spatial_variance": 40.84303328243487,
      "attention_bam_16_attention_spatial_std": 6.390855442148169,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.102340382672143,
      "attention_bam_16_peak_intensity_mean": 0.32119429111480713,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 11,
      "phase": "train",
      "loss": 0.36072465777397156,
      "timestamp": 1759543883.1953259,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.36072465777397156,
      "ssim": 0.1153055727481842,
      "attention_bam_384_mean_attention": 0.24331124126911163,
      "attention_bam_384_std_attention": 0.5324074029922485,
      "attention_bam_384_max_attention": 4.447498798370361,
      "attention_bam_384_min_attention": -1.5496420860290527,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5914399228261482,
      "attention_bam_384_attention_skewness": 0.5342982535306167,
      "attention_bam_384_attention_sparsity": 0.4000905354817708,
      "attention_bam_384_attention_concentration_10": 0.5161232134947481,
      "attention_bam_384_attention_concentration_20": 0.8278675539690613,
      "attention_bam_384_attention_center_y": 0.48405214614557435,
      "attention_bam_384_attention_center_x": 0.48459361764633535,
      "attention_bam_384_attention_center_distance": 0.031358911326429324,
      "attention_bam_384_attention_spatial_variance": 170.16261703253406,
      "attention_bam_384_attention_spatial_std": 13.044639398332713,
      "attention_bam_384_num_attention_peaks": 23,
      "attention_bam_384_peak_separation_mean": 17.373226302864786,
      "attention_bam_384_peak_intensity_mean": 0.3019752502441406,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2840683162212372,
      "attention_bam_16_std_attention": 0.44030794501304626,
      "attention_bam_16_max_attention": 2.489126443862915,
      "attention_bam_16_min_attention": -1.0888934135437012,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7817367879798276,
      "attention_bam_16_attention_skewness": 0.27987445353659424,
      "attention_bam_16_attention_sparsity": 0.327392578125,
      "attention_bam_16_attention_concentration_10": 0.3849497327372972,
      "attention_bam_16_attention_concentration_20": 0.6365239188421787,
      "attention_bam_16_attention_center_y": 0.4701250232974842,
      "attention_bam_16_attention_center_x": 0.4734886352153608,
      "attention_bam_16_attention_center_distance": 0.056486577090846486,
      "attention_bam_16_attention_spatial_variance": 41.21738928309028,
      "attention_bam_16_attention_spatial_std": 6.42007704650733,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.163053014619617,
      "attention_bam_16_peak_intensity_mean": 0.39459094405174255,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 12,
      "phase": "train",
      "loss": 0.35813724994659424,
      "timestamp": 1759543883.3238165,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.35813724994659424,
      "ssim": 0.10156375169754028,
      "attention_bam_384_mean_attention": 0.24812430143356323,
      "attention_bam_384_std_attention": 0.5178822875022888,
      "attention_bam_384_max_attention": 5.037986755371094,
      "attention_bam_384_min_attention": -1.5095083713531494,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.6555095870230998,
      "attention_bam_384_attention_skewness": 0.4841366846496449,
      "attention_bam_384_attention_sparsity": 0.39477284749348956,
      "attention_bam_384_attention_concentration_10": 0.4924454928751976,
      "attention_bam_384_attention_concentration_20": 0.7968639160571246,
      "attention_bam_384_attention_center_y": 0.48346307279316636,
      "attention_bam_384_attention_center_x": 0.48358932139867844,
      "attention_bam_384_attention_center_distance": 0.032947847686912356,
      "attention_bam_384_attention_spatial_variance": 169.90669361103127,
      "attention_bam_384_attention_spatial_std": 13.034826182616754,
      "attention_bam_384_num_attention_peaks": 18,
      "attention_bam_384_peak_separation_mean": 18.13803428484876,
      "attention_bam_384_peak_intensity_mean": 0.26977038383483887,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.27662530541419983,
      "attention_bam_16_std_attention": 0.4218468964099884,
      "attention_bam_16_max_attention": 1.8904609680175781,
      "attention_bam_16_min_attention": -0.9937756061553955,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.38636291159957503,
      "attention_bam_16_attention_skewness": 0.09539915780083039,
      "attention_bam_16_attention_sparsity": 0.323974609375,
      "attention_bam_16_attention_concentration_10": 0.37742626727405143,
      "attention_bam_16_attention_concentration_20": 0.6274303881487461,
      "attention_bam_16_attention_center_y": 0.4698672816463975,
      "attention_bam_16_attention_center_x": 0.4723383461835007,
      "attention_bam_16_attention_center_distance": 0.05784717464563647,
      "attention_bam_16_attention_spatial_variance": 41.00717373499204,
      "attention_bam_16_attention_spatial_std": 6.403684387521924,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.311395103274617,
      "attention_bam_16_peak_intensity_mean": 0.45308810472488403,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 13,
      "phase": "train",
      "loss": 0.30160364508628845,
      "timestamp": 1759543883.4532905,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.30160364508628845,
      "ssim": 0.14988897740840912,
      "attention_bam_384_mean_attention": 0.24462682008743286,
      "attention_bam_384_std_attention": 0.505047082901001,
      "attention_bam_384_max_attention": 4.478602409362793,
      "attention_bam_384_min_attention": -1.5382227897644043,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.6244130012394713,
      "attention_bam_384_attention_skewness": 0.552588399993684,
      "attention_bam_384_attention_sparsity": 0.3999176025390625,
      "attention_bam_384_attention_concentration_10": 0.49416932636831123,
      "attention_bam_384_attention_concentration_20": 0.7942155559187902,
      "attention_bam_384_attention_center_y": 0.485339603252443,
      "attention_bam_384_attention_center_x": 0.48462274785504056,
      "attention_bam_384_attention_center_distance": 0.030046201634331048,
      "attention_bam_384_attention_spatial_variance": 169.76282785800362,
      "attention_bam_384_attention_spatial_std": 13.02930649950348,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 16.775108218075673,
      "attention_bam_384_peak_intensity_mean": 0.3006961941719055,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2739356756210327,
      "attention_bam_16_std_attention": 0.48051154613494873,
      "attention_bam_16_max_attention": 2.624657154083252,
      "attention_bam_16_min_attention": -1.0009033679962158,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.2632208449951339,
      "attention_bam_16_attention_skewness": 0.6284168797102117,
      "attention_bam_16_attention_sparsity": 0.364501953125,
      "attention_bam_16_attention_concentration_10": 0.44628975137758664,
      "attention_bam_16_attention_concentration_20": 0.7119617840096796,
      "attention_bam_16_attention_center_y": 0.4770072215283947,
      "attention_bam_16_attention_center_x": 0.4743550427360136,
      "attention_bam_16_attention_center_distance": 0.04870999271024387,
      "attention_bam_16_attention_spatial_variance": 41.273493308656256,
      "attention_bam_16_attention_spatial_std": 6.424444980592195,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.144120862044737,
      "attention_bam_16_peak_intensity_mean": 0.37458229064941406,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 14,
      "phase": "train",
      "loss": 0.341573566198349,
      "timestamp": 1759543883.581628,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.341573566198349,
      "ssim": 0.13122831284999847,
      "attention_bam_384_mean_attention": 0.24939437210559845,
      "attention_bam_384_std_attention": 0.5101507902145386,
      "attention_bam_384_max_attention": 5.507732391357422,
      "attention_bam_384_min_attention": -1.525538444519043,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.29832872509278,
      "attention_bam_384_attention_skewness": 0.5881572962306213,
      "attention_bam_384_attention_sparsity": 0.383392333984375,
      "attention_bam_384_attention_concentration_10": 0.4921117265740076,
      "attention_bam_384_attention_concentration_20": 0.7847028822306913,
      "attention_bam_384_attention_center_y": 0.4854532320544044,
      "attention_bam_384_attention_center_x": 0.48147876313613747,
      "attention_bam_384_attention_center_distance": 0.03330599563532994,
      "attention_bam_384_attention_spatial_variance": 170.4282227519543,
      "attention_bam_384_attention_spatial_std": 13.054816074995246,
      "attention_bam_384_num_attention_peaks": 19,
      "attention_bam_384_peak_separation_mean": 16.92599069821228,
      "attention_bam_384_peak_intensity_mean": 0.25287604331970215,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.28108105063438416,
      "attention_bam_16_std_attention": 0.3759230077266693,
      "attention_bam_16_max_attention": 1.9568712711334229,
      "attention_bam_16_min_attention": -0.9256015419960022,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.900098955844518,
      "attention_bam_16_attention_skewness": 0.14517596459879994,
      "attention_bam_16_attention_sparsity": 0.2958984375,
      "attention_bam_16_attention_concentration_10": 0.3404037156249144,
      "attention_bam_16_attention_concentration_20": 0.5686716821161197,
      "attention_bam_16_attention_center_y": 0.4778454861089005,
      "attention_bam_16_attention_center_x": 0.4674434641787734,
      "attention_bam_16_attention_center_distance": 0.05569112156223344,
      "attention_bam_16_attention_spatial_variance": 41.484764528823455,
      "attention_bam_16_attention_spatial_std": 6.440866752916369,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 7.918046226826746,
      "attention_bam_16_peak_intensity_mean": 0.42545974254608154,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 15,
      "phase": "train",
      "loss": 0.2972705662250519,
      "timestamp": 1759543883.7111256,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.2972705662250519,
      "ssim": 0.1321229338645935,
      "attention_bam_384_mean_attention": 0.23019124567508698,
      "attention_bam_384_std_attention": 0.5812958478927612,
      "attention_bam_384_max_attention": 4.507612228393555,
      "attention_bam_384_min_attention": -1.5198017358779907,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0820045325307666,
      "attention_bam_384_attention_skewness": 0.6004787296170498,
      "attention_bam_384_attention_sparsity": 0.43539683024088544,
      "attention_bam_384_attention_concentration_10": 0.5892610029168412,
      "attention_bam_384_attention_concentration_20": 0.9420739251701783,
      "attention_bam_384_attention_center_y": 0.4849998011329899,
      "attention_bam_384_attention_center_x": 0.4802051216846823,
      "attention_bam_384_attention_center_distance": 0.03512387147135363,
      "attention_bam_384_attention_spatial_variance": 169.10993625830812,
      "attention_bam_384_attention_spatial_std": 13.004227630209652,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 15.546397406952842,
      "attention_bam_384_peak_intensity_mean": 0.2916646897792816,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2505493462085724,
      "attention_bam_16_std_attention": 0.5893527865409851,
      "attention_bam_16_max_attention": 2.54319429397583,
      "attention_bam_16_min_attention": -1.0245498418807983,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.009594412390050877,
      "attention_bam_16_attention_skewness": 0.45949619741914255,
      "attention_bam_16_attention_sparsity": 0.427734375,
      "attention_bam_16_attention_concentration_10": 0.5466390612291792,
      "attention_bam_16_attention_concentration_20": 0.8919518175214005,
      "attention_bam_16_attention_center_y": 0.47530738773702885,
      "attention_bam_16_attention_center_x": 0.4594955921125957,
      "attention_bam_16_attention_center_distance": 0.06708699067149534,
      "attention_bam_16_attention_spatial_variance": 40.586950211197,
      "attention_bam_16_attention_spatial_std": 6.370788821739189,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 7.5354273289990505,
      "attention_bam_16_peak_intensity_mean": 0.3725915253162384,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 16,
      "phase": "train",
      "loss": 0.3406209945678711,
      "timestamp": 1759543883.8376465,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3406209945678711,
      "ssim": 0.13283100724220276,
      "attention_bam_384_mean_attention": 0.24769681692123413,
      "attention_bam_384_std_attention": 0.5169138312339783,
      "attention_bam_384_max_attention": 5.178227424621582,
      "attention_bam_384_min_attention": -1.477972149848938,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.0588064308560723,
      "attention_bam_384_attention_skewness": 0.6246698299528917,
      "attention_bam_384_attention_sparsity": 0.39482371012369794,
      "attention_bam_384_attention_concentration_10": 0.49839464043798887,
      "attention_bam_384_attention_concentration_20": 0.7987254981935877,
      "attention_bam_384_attention_center_y": 0.4813568885865073,
      "attention_bam_384_attention_center_x": 0.48198689947217555,
      "attention_bam_384_attention_center_distance": 0.03666162554501397,
      "attention_bam_384_attention_spatial_variance": 171.04658647888172,
      "attention_bam_384_attention_spatial_std": 13.078477987857827,
      "attention_bam_384_num_attention_peaks": 21,
      "attention_bam_384_peak_separation_mean": 17.82685500225831,
      "attention_bam_384_peak_intensity_mean": 0.262633740901947,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.26532644033432007,
      "attention_bam_16_std_attention": 0.44830161333084106,
      "attention_bam_16_max_attention": 2.6386399269104004,
      "attention_bam_16_min_attention": -1.0195412635803223,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.0130331849498742,
      "attention_bam_16_attention_skewness": 0.4117404905912027,
      "attention_bam_16_attention_sparsity": 0.363037109375,
      "attention_bam_16_attention_concentration_10": 0.41334526879579153,
      "attention_bam_16_attention_concentration_20": 0.6828478386364568,
      "attention_bam_16_attention_center_y": 0.4582589991037514,
      "attention_bam_16_attention_center_x": 0.46843980201747054,
      "attention_bam_16_attention_center_distance": 0.0740048275792476,
      "attention_bam_16_attention_spatial_variance": 41.9677828089898,
      "attention_bam_16_attention_spatial_std": 6.478254611312356,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.216136486028663,
      "attention_bam_16_peak_intensity_mean": 0.3671351969242096,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 17,
      "phase": "train",
      "loss": 0.25327640771865845,
      "timestamp": 1759543883.965058,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.25327640771865845,
      "ssim": 0.18626511096954346,
      "attention_bam_384_mean_attention": 0.24724841117858887,
      "attention_bam_384_std_attention": 0.5230613946914673,
      "attention_bam_384_max_attention": 5.113018035888672,
      "attention_bam_384_min_attention": -1.5443896055221558,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.9109137643319292,
      "attention_bam_384_attention_skewness": 0.5864068210501148,
      "attention_bam_384_attention_sparsity": 0.40058644612630206,
      "attention_bam_384_attention_concentration_10": 0.5068126115961492,
      "attention_bam_384_attention_concentration_20": 0.8097147958682658,
      "attention_bam_384_attention_center_y": 0.4857368260144303,
      "attention_bam_384_attention_center_x": 0.4858405925613969,
      "attention_bam_384_attention_center_distance": 0.028422770841527795,
      "attention_bam_384_attention_spatial_variance": 171.64787471398188,
      "attention_bam_384_attention_spatial_std": 13.101445520017318,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 16.667766326738025,
      "attention_bam_384_peak_intensity_mean": 0.2714223861694336,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.26922571659088135,
      "attention_bam_16_std_attention": 0.45761919021606445,
      "attention_bam_16_max_attention": 2.574228286743164,
      "attention_bam_16_min_attention": -1.1886112689971924,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7152834132218313,
      "attention_bam_16_attention_skewness": 0.3861988332908884,
      "attention_bam_16_attention_sparsity": 0.364990234375,
      "attention_bam_16_attention_concentration_10": 0.42120415894915175,
      "attention_bam_16_attention_concentration_20": 0.693256794871923,
      "attention_bam_16_attention_center_y": 0.4787025006577269,
      "attention_bam_16_attention_center_x": 0.4797755614931721,
      "attention_bam_16_attention_center_distance": 0.0415358012117399,
      "attention_bam_16_attention_spatial_variance": 42.6692391562414,
      "attention_bam_16_attention_spatial_std": 6.532169559667095,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 12.60121261607643,
      "attention_bam_16_peak_intensity_mean": 0.4154205620288849,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 18,
      "phase": "train",
      "loss": 0.2974157929420471,
      "timestamp": 1759543884.0907073,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.2974157929420471,
      "ssim": 0.17002645134925842,
      "attention_bam_384_mean_attention": 0.24347329139709473,
      "attention_bam_384_std_attention": 0.543117344379425,
      "attention_bam_384_max_attention": 4.7456793785095215,
      "attention_bam_384_min_attention": -1.5721999406814575,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4989398846542983,
      "attention_bam_384_attention_skewness": 0.5926946859594868,
      "attention_bam_384_attention_sparsity": 0.4093221028645833,
      "attention_bam_384_attention_concentration_10": 0.5335870868385457,
      "attention_bam_384_attention_concentration_20": 0.8481611357606481,
      "attention_bam_384_attention_center_y": 0.4825666858262354,
      "attention_bam_384_attention_center_x": 0.48204163493485436,
      "attention_bam_384_attention_center_distance": 0.03539557370333824,
      "attention_bam_384_attention_spatial_variance": 170.41996978900573,
      "attention_bam_384_attention_spatial_std": 13.054499982343472,
      "attention_bam_384_num_attention_peaks": 19,
      "attention_bam_384_peak_separation_mean": 17.09156051766111,
      "attention_bam_384_peak_intensity_mean": 0.2907749116420746,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.27091631293296814,
      "attention_bam_16_std_attention": 0.4776909649372101,
      "attention_bam_16_max_attention": 2.7158210277557373,
      "attention_bam_16_min_attention": -1.0187315940856934,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8961516080158192,
      "attention_bam_16_attention_skewness": 0.5140608176948319,
      "attention_bam_16_attention_sparsity": 0.372802734375,
      "attention_bam_16_attention_concentration_10": 0.4372712913951695,
      "attention_bam_16_attention_concentration_20": 0.7184015124390691,
      "attention_bam_16_attention_center_y": 0.46803501918187407,
      "attention_bam_16_attention_center_x": 0.4659490014471433,
      "attention_bam_16_attention_center_distance": 0.06604892885050911,
      "attention_bam_16_attention_spatial_variance": 41.15139821891463,
      "attention_bam_16_attention_spatial_std": 6.414935558438185,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.106464610164595,
      "attention_bam_16_peak_intensity_mean": 0.35517948865890503,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 19,
      "phase": "train",
      "loss": 0.30042576789855957,
      "timestamp": 1759543884.218199,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.30042576789855957,
      "ssim": 0.12989182770252228,
      "attention_bam_384_mean_attention": 0.2309279888868332,
      "attention_bam_384_std_attention": 0.601518988609314,
      "attention_bam_384_max_attention": 4.401276588439941,
      "attention_bam_384_min_attention": -1.5509144067764282,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8193421654043447,
      "attention_bam_384_attention_skewness": 0.576364447572193,
      "attention_bam_384_attention_sparsity": 0.44059499104817706,
      "attention_bam_384_attention_concentration_10": 0.607371634104973,
      "attention_bam_384_attention_concentration_20": 0.9716277727598361,
      "attention_bam_384_attention_center_y": 0.48476648958039964,
      "attention_bam_384_attention_center_x": 0.4839753292946488,
      "attention_bam_384_attention_center_distance": 0.03126819185431141,
      "attention_bam_384_attention_spatial_variance": 169.683155586202,
      "attention_bam_384_attention_spatial_std": 13.026248715044634,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 19.618445011341457,
      "attention_bam_384_peak_intensity_mean": 0.2991619408130646,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2587593197822571,
      "attention_bam_16_std_attention": 0.6484429240226746,
      "attention_bam_16_max_attention": 3.207200765609741,
      "attention_bam_16_min_attention": -1.2363499402999878,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7288747890062237,
      "attention_bam_16_attention_skewness": 0.7034970187815729,
      "attention_bam_16_attention_sparsity": 0.4423828125,
      "attention_bam_16_attention_concentration_10": 0.6016990224672865,
      "attention_bam_16_attention_concentration_20": 0.9568454879724596,
      "attention_bam_16_attention_center_y": 0.47288579703909545,
      "attention_bam_16_attention_center_x": 0.46926428317563557,
      "attention_bam_16_attention_center_distance": 0.057963165733293825,
      "attention_bam_16_attention_spatial_variance": 40.726513744909816,
      "attention_bam_16_attention_spatial_std": 6.381732816791206,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 7.302959822359776,
      "attention_bam_16_peak_intensity_mean": 0.3446008265018463,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 20,
      "phase": "train",
      "loss": 0.27689290046691895,
      "timestamp": 1759543884.3836858,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.27689290046691895,
      "ssim": 0.16104765236377716,
      "attention_bam_384_mean_attention": 0.24132554233074188,
      "attention_bam_384_std_attention": 0.507631242275238,
      "attention_bam_384_max_attention": 4.227688789367676,
      "attention_bam_384_min_attention": -1.548990249633789,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5139443252308,
      "attention_bam_384_attention_skewness": 0.5635329078315346,
      "attention_bam_384_attention_sparsity": 0.3985544840494792,
      "attention_bam_384_attention_concentration_10": 0.5042365946140157,
      "attention_bam_384_attention_concentration_20": 0.8089751028953451,
      "attention_bam_384_attention_center_y": 0.48646767277823644,
      "attention_bam_384_attention_center_x": 0.48413756933847096,
      "attention_bam_384_attention_center_distance": 0.029486966155530467,
      "attention_bam_384_attention_spatial_variance": 170.09996250977127,
      "attention_bam_384_attention_spatial_std": 13.042237634308435,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 17.7508214542985,
      "attention_bam_384_peak_intensity_mean": 0.31122544407844543,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.27319836616516113,
      "attention_bam_16_std_attention": 0.4694349765777588,
      "attention_bam_16_max_attention": 2.610577344894409,
      "attention_bam_16_min_attention": -0.9233575463294983,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5167063051073186,
      "attention_bam_16_attention_skewness": 0.4384630039831073,
      "attention_bam_16_attention_sparsity": 0.364990234375,
      "attention_bam_16_attention_concentration_10": 0.43035525409410713,
      "attention_bam_16_attention_concentration_20": 0.7046563461809464,
      "attention_bam_16_attention_center_y": 0.4828027185949577,
      "attention_bam_16_attention_center_x": 0.47606298977104106,
      "attention_bam_16_attention_center_distance": 0.04168277693305709,
      "attention_bam_16_attention_spatial_variance": 41.02404633843575,
      "attention_bam_16_attention_spatial_std": 6.405001665763699,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.620085563002856,
      "attention_bam_16_peak_intensity_mean": 0.340448260307312,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 21,
      "phase": "train",
      "loss": 0.29836198687553406,
      "timestamp": 1759543884.5192096,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.29836198687553406,
      "ssim": 0.12883025407791138,
      "attention_bam_384_mean_attention": 0.2312128096818924,
      "attention_bam_384_std_attention": 0.5849518775939941,
      "attention_bam_384_max_attention": 5.1537981033325195,
      "attention_bam_384_min_attention": -1.5392740964889526,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.120743428625123,
      "attention_bam_384_attention_skewness": 0.5775211500668797,
      "attention_bam_384_attention_sparsity": 0.43449656168619794,
      "attention_bam_384_attention_concentration_10": 0.5878649744330566,
      "attention_bam_384_attention_concentration_20": 0.940477199135574,
      "attention_bam_384_attention_center_y": 0.48120668183664195,
      "attention_bam_384_attention_center_x": 0.4823454692381788,
      "attention_bam_384_attention_center_distance": 0.03646563489120394,
      "attention_bam_384_attention_spatial_variance": 170.36095969889737,
      "attention_bam_384_attention_spatial_std": 13.052239643022855,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 16.27526214615358,
      "attention_bam_384_peak_intensity_mean": 0.26849067211151123,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23785558342933655,
      "attention_bam_16_std_attention": 0.5795230269432068,
      "attention_bam_16_max_attention": 2.4573287963867188,
      "attention_bam_16_min_attention": -0.9439109563827515,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.08069079695644232,
      "attention_bam_16_attention_skewness": 0.4652122244022203,
      "attention_bam_16_attention_sparsity": 0.438720703125,
      "attention_bam_16_attention_concentration_10": 0.5653230647462262,
      "attention_bam_16_attention_concentration_20": 0.9284275531037032,
      "attention_bam_16_attention_center_y": 0.4653557790583511,
      "attention_bam_16_attention_center_x": 0.4669125534842563,
      "attention_bam_16_attention_center_distance": 0.06774955588911238,
      "attention_bam_16_attention_spatial_variance": 41.25463494664093,
      "attention_bam_16_attention_spatial_std": 6.422977109303826,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.958949818581255,
      "attention_bam_16_peak_intensity_mean": 0.3622314929962158,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 22,
      "phase": "train",
      "loss": 0.2959652841091156,
      "timestamp": 1759543884.6464934,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.2959652841091156,
      "ssim": 0.13940651714801788,
      "attention_bam_384_mean_attention": 0.2311651110649109,
      "attention_bam_384_std_attention": 0.5790621638298035,
      "attention_bam_384_max_attention": 5.222625732421875,
      "attention_bam_384_min_attention": -1.5429470539093018,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4497406464740328,
      "attention_bam_384_attention_skewness": 0.6715887548826126,
      "attention_bam_384_attention_sparsity": 0.441009521484375,
      "attention_bam_384_attention_concentration_10": 0.585242693096004,
      "attention_bam_384_attention_concentration_20": 0.9368893867005028,
      "attention_bam_384_attention_center_y": 0.4862137083927066,
      "attention_bam_384_attention_center_x": 0.4863040389166058,
      "attention_bam_384_attention_center_distance": 0.02748240114251944,
      "attention_bam_384_attention_spatial_variance": 171.1626186065503,
      "attention_bam_384_attention_spatial_std": 13.082913230872943,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 19.210810940305862,
      "attention_bam_384_peak_intensity_mean": 0.26372361183166504,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24717825651168823,
      "attention_bam_16_std_attention": 0.6150215864181519,
      "attention_bam_16_max_attention": 3.127889394760132,
      "attention_bam_16_min_attention": -0.9996352195739746,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8437714795426032,
      "attention_bam_16_attention_skewness": 0.7702646273684834,
      "attention_bam_16_attention_sparsity": 0.456298828125,
      "attention_bam_16_attention_concentration_10": 0.5999311423746551,
      "attention_bam_16_attention_concentration_20": 0.9561645473954881,
      "attention_bam_16_attention_center_y": 0.4842440765734046,
      "attention_bam_16_attention_center_x": 0.4854250404870712,
      "attention_bam_16_attention_center_distance": 0.030353865250681036,
      "attention_bam_16_attention_spatial_variance": 42.47582281079355,
      "attention_bam_16_attention_spatial_std": 6.517347835645536,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.17011408891607,
      "attention_bam_16_peak_intensity_mean": 0.3068714141845703,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 23,
      "phase": "train",
      "loss": 0.292339950799942,
      "timestamp": 1759543884.7847028,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.292339950799942,
      "ssim": 0.1663302779197693,
      "attention_bam_384_mean_attention": 0.22213225066661835,
      "attention_bam_384_std_attention": 0.5884943008422852,
      "attention_bam_384_max_attention": 4.689919471740723,
      "attention_bam_384_min_attention": -1.5907788276672363,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.3482915341740638,
      "attention_bam_384_attention_skewness": 0.6861836554938453,
      "attention_bam_384_attention_sparsity": 0.4459075927734375,
      "attention_bam_384_attention_concentration_10": 0.616714676785363,
      "attention_bam_384_attention_concentration_20": 0.9794926460708904,
      "attention_bam_384_attention_center_y": 0.4795444094605786,
      "attention_bam_384_attention_center_x": 0.4807348863974725,
      "attention_bam_384_attention_center_distance": 0.03973854014517282,
      "attention_bam_384_attention_spatial_variance": 170.91987935498815,
      "attention_bam_384_attention_spatial_std": 13.0736329822658,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 14.737760244414646,
      "attention_bam_384_peak_intensity_mean": 0.2922031879425049,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23241651058197021,
      "attention_bam_16_std_attention": 0.5974450707435608,
      "attention_bam_16_max_attention": 2.544224977493286,
      "attention_bam_16_min_attention": -1.0452451705932617,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.19207946888771765,
      "attention_bam_16_attention_skewness": 0.5576885413135743,
      "attention_bam_16_attention_sparsity": 0.450927734375,
      "attention_bam_16_attention_concentration_10": 0.5949399405266972,
      "attention_bam_16_attention_concentration_20": 0.9736118156429332,
      "attention_bam_16_attention_center_y": 0.4554098355720841,
      "attention_bam_16_attention_center_x": 0.4610646514742628,
      "attention_bam_16_attention_center_distance": 0.08371671432311716,
      "attention_bam_16_attention_spatial_variance": 41.78035681378815,
      "attention_bam_16_attention_spatial_std": 6.463772645583085,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.538119646702851,
      "attention_bam_16_peak_intensity_mean": 0.3657669126987457,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 24,
      "phase": "train",
      "loss": 0.31093689799308777,
      "timestamp": 1759543884.925554,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.31093689799308777,
      "ssim": 0.143528014421463,
      "attention_bam_384_mean_attention": 0.21615241467952728,
      "attention_bam_384_std_attention": 0.5957567095756531,
      "attention_bam_384_max_attention": 4.934524059295654,
      "attention_bam_384_min_attention": -1.6253445148468018,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8319870392905502,
      "attention_bam_384_attention_skewness": 0.7971601442120995,
      "attention_bam_384_attention_sparsity": 0.45293426513671875,
      "attention_bam_384_attention_concentration_10": 0.6473613163043539,
      "attention_bam_384_attention_concentration_20": 1.0122639245311034,
      "attention_bam_384_attention_center_y": 0.48546375789580964,
      "attention_bam_384_attention_center_x": 0.47849990708065715,
      "attention_bam_384_attention_center_distance": 0.03670303339104311,
      "attention_bam_384_attention_spatial_variance": 171.94839136003833,
      "attention_bam_384_attention_spatial_std": 13.112909340037334,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 20.114357570110396,
      "attention_bam_384_peak_intensity_mean": 0.2813744843006134,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2205199897289276,
      "attention_bam_16_std_attention": 0.6211221218109131,
      "attention_bam_16_max_attention": 2.8261966705322266,
      "attention_bam_16_min_attention": -1.0182257890701294,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.3893197427401911,
      "attention_bam_16_attention_skewness": 0.6576204467635086,
      "attention_bam_16_attention_sparsity": 0.465087890625,
      "attention_bam_16_attention_concentration_10": 0.6537767877233728,
      "attention_bam_16_attention_concentration_20": 1.0469468362484797,
      "attention_bam_16_attention_center_y": 0.48200880084335357,
      "attention_bam_16_attention_center_x": 0.45289220089300253,
      "attention_bam_16_attention_center_distance": 0.07131378525641935,
      "attention_bam_16_attention_spatial_variance": 43.242565576568566,
      "attention_bam_16_attention_spatial_std": 6.5759079659442135,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 10.876919233871009,
      "attention_bam_16_peak_intensity_mean": 0.3275264799594879,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 25,
      "phase": "train",
      "loss": 0.29102063179016113,
      "timestamp": 1759543885.0572486,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.29102063179016113,
      "ssim": 0.1589268147945404,
      "attention_bam_384_mean_attention": 0.21622376143932343,
      "attention_bam_384_std_attention": 0.5595305562019348,
      "attention_bam_384_max_attention": 4.313748359680176,
      "attention_bam_384_min_attention": -1.5844690799713135,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2699847640940858,
      "attention_bam_384_attention_skewness": 0.6197716685217126,
      "attention_bam_384_attention_sparsity": 0.4427998860677083,
      "attention_bam_384_attention_concentration_10": 0.6053437696465799,
      "attention_bam_384_attention_concentration_20": 0.9615775136364202,
      "attention_bam_384_attention_center_y": 0.48640053160490376,
      "attention_bam_384_attention_center_x": 0.48373297289579975,
      "attention_bam_384_attention_center_distance": 0.029985386822184133,
      "attention_bam_384_attention_spatial_variance": 170.39530936598,
      "attention_bam_384_attention_spatial_std": 13.053555430072683,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 19.893386667887594,
      "attention_bam_384_peak_intensity_mean": 0.3065706491470337,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24058689177036285,
      "attention_bam_16_std_attention": 0.5700751543045044,
      "attention_bam_16_max_attention": 2.467022180557251,
      "attention_bam_16_min_attention": -1.0670111179351807,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.14906680630187585,
      "attention_bam_16_attention_skewness": 0.5375802712023859,
      "attention_bam_16_attention_sparsity": 0.439697265625,
      "attention_bam_16_attention_concentration_10": 0.5671934363378278,
      "attention_bam_16_attention_concentration_20": 0.9134217661495392,
      "attention_bam_16_attention_center_y": 0.4807716253088755,
      "attention_bam_16_attention_center_x": 0.4780575973532759,
      "attention_bam_16_attention_center_distance": 0.041260136383032976,
      "attention_bam_16_attention_spatial_variance": 41.35513353145004,
      "attention_bam_16_attention_spatial_std": 6.430795715263395,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.439655324762466,
      "attention_bam_16_peak_intensity_mean": 0.3724057674407959,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 26,
      "phase": "train",
      "loss": 0.3356815278530121,
      "timestamp": 1759543885.1894681,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3356815278530121,
      "ssim": 0.14035765826702118,
      "attention_bam_384_mean_attention": 0.227347269654274,
      "attention_bam_384_std_attention": 0.5898676514625549,
      "attention_bam_384_max_attention": 5.590204238891602,
      "attention_bam_384_min_attention": -1.6020255088806152,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.339068714768131,
      "attention_bam_384_attention_skewness": 0.60216228087812,
      "attention_bam_384_attention_sparsity": 0.4375864664713542,
      "attention_bam_384_attention_concentration_10": 0.5976692429965765,
      "attention_bam_384_attention_concentration_20": 0.960311159114173,
      "attention_bam_384_attention_center_y": 0.48598162057361116,
      "attention_bam_384_attention_center_x": 0.47967997260580614,
      "attention_bam_384_attention_center_distance": 0.03491184541220904,
      "attention_bam_384_attention_spatial_variance": 170.71576509162185,
      "attention_bam_384_attention_spatial_std": 13.065824317341093,
      "attention_bam_384_num_attention_peaks": 20,
      "attention_bam_384_peak_separation_mean": 16.704901066454127,
      "attention_bam_384_peak_intensity_mean": 0.25527212023735046,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2416812926530838,
      "attention_bam_16_std_attention": 0.5803108215332031,
      "attention_bam_16_max_attention": 2.499664545059204,
      "attention_bam_16_min_attention": -1.1769309043884277,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.05555342777076078,
      "attention_bam_16_attention_skewness": 0.45759787944555164,
      "attention_bam_16_attention_sparsity": 0.43603515625,
      "attention_bam_16_attention_concentration_10": 0.5637281114875413,
      "attention_bam_16_attention_concentration_20": 0.9169840575969072,
      "attention_bam_16_attention_center_y": 0.48155646543541486,
      "attention_bam_16_attention_center_x": 0.4628581148090053,
      "attention_bam_16_attention_center_distance": 0.05864611841846105,
      "attention_bam_16_attention_spatial_variance": 41.67606740880721,
      "attention_bam_16_attention_spatial_std": 6.4557003809662055,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 8.323418297636358,
      "attention_bam_16_peak_intensity_mean": 0.39098891615867615,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 27,
      "phase": "train",
      "loss": 0.30597537755966187,
      "timestamp": 1759543885.3223212,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.30597537755966187,
      "ssim": 0.19406452775001526,
      "attention_bam_384_mean_attention": 0.22170227766036987,
      "attention_bam_384_std_attention": 0.5370602011680603,
      "attention_bam_384_max_attention": 4.518752098083496,
      "attention_bam_384_min_attention": -1.622511863708496,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.030300890152077,
      "attention_bam_384_attention_skewness": 0.7326143373846111,
      "attention_bam_384_attention_sparsity": 0.43034617106119794,
      "attention_bam_384_attention_concentration_10": 0.5779879467400431,
      "attention_bam_384_attention_concentration_20": 0.9073373719970773,
      "attention_bam_384_attention_center_y": 0.48634152793768093,
      "attention_bam_384_attention_center_x": 0.48355151773063015,
      "attention_bam_384_attention_center_distance": 0.030235953037499073,
      "attention_bam_384_attention_spatial_variance": 169.91211528737205,
      "attention_bam_384_attention_spatial_std": 13.035034149835283,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 18.119759668156068,
      "attention_bam_384_peak_intensity_mean": 0.3020004332065582,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24427729845046997,
      "attention_bam_16_std_attention": 0.554815411567688,
      "attention_bam_16_max_attention": 2.8572299480438232,
      "attention_bam_16_min_attention": -1.0810456275939941,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.9075325760979345,
      "attention_bam_16_attention_skewness": 0.6976666796770126,
      "attention_bam_16_attention_sparsity": 0.42431640625,
      "attention_bam_16_attention_concentration_10": 0.5505929541829849,
      "attention_bam_16_attention_concentration_20": 0.8793044445489826,
      "attention_bam_16_attention_center_y": 0.481603383750984,
      "attention_bam_16_attention_center_x": 0.47110592959364544,
      "attention_bam_16_attention_center_distance": 0.048441775237101574,
      "attention_bam_16_attention_spatial_variance": 41.32756804565733,
      "attention_bam_16_attention_spatial_std": 6.428652117330454,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.802201120638433,
      "attention_bam_16_peak_intensity_mean": 0.34488141536712646,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 28,
      "phase": "train",
      "loss": 0.28691303730010986,
      "timestamp": 1759543885.455693,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.28691303730010986,
      "ssim": 0.16142484545707703,
      "attention_bam_384_mean_attention": 0.22218656539916992,
      "attention_bam_384_std_attention": 0.5818865895271301,
      "attention_bam_384_max_attention": 5.667741775512695,
      "attention_bam_384_min_attention": -1.6151950359344482,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4712806390457098,
      "attention_bam_384_attention_skewness": 0.5865356965658145,
      "attention_bam_384_attention_sparsity": 0.4362843831380208,
      "attention_bam_384_attention_concentration_10": 0.5963627343463729,
      "attention_bam_384_attention_concentration_20": 0.9615368519546756,
      "attention_bam_384_attention_center_y": 0.48809905793181046,
      "attention_bam_384_attention_center_x": 0.48121151050882155,
      "attention_bam_384_attention_center_distance": 0.03145281416568401,
      "attention_bam_384_attention_spatial_variance": 171.20730682282547,
      "attention_bam_384_attention_spatial_std": 13.084621004172245,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 17.64744371333968,
      "attention_bam_384_peak_intensity_mean": 0.2533702850341797,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2149694859981537,
      "attention_bam_16_std_attention": 0.6139112710952759,
      "attention_bam_16_max_attention": 2.321500539779663,
      "attention_bam_16_min_attention": -1.1593317985534668,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.4782488894355934,
      "attention_bam_16_attention_skewness": 0.2680721119903088,
      "attention_bam_16_attention_sparsity": 0.44677734375,
      "attention_bam_16_attention_concentration_10": 0.6182416241090584,
      "attention_bam_16_attention_concentration_20": 1.0271841305914984,
      "attention_bam_16_attention_center_y": 0.49191437181592323,
      "attention_bam_16_attention_center_x": 0.4599169502052379,
      "attention_bam_16_attention_center_distance": 0.057827817942241545,
      "attention_bam_16_attention_spatial_variance": 42.53204175496788,
      "attention_bam_16_attention_spatial_std": 6.521659432611295,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.95209736419586,
      "attention_bam_16_peak_intensity_mean": 0.4144841730594635,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 29,
      "phase": "train",
      "loss": 0.26490646600723267,
      "timestamp": 1759543885.5835576,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.26490646600723267,
      "ssim": 0.21171525120735168,
      "attention_bam_384_mean_attention": 0.2364654541015625,
      "attention_bam_384_std_attention": 0.5169011354446411,
      "attention_bam_384_max_attention": 4.945559501647949,
      "attention_bam_384_min_attention": -1.611642837524414,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.414296086998382,
      "attention_bam_384_attention_skewness": 0.5859224446227671,
      "attention_bam_384_attention_sparsity": 0.39877065022786456,
      "attention_bam_384_attention_concentration_10": 0.5123886545244766,
      "attention_bam_384_attention_concentration_20": 0.8210438243422575,
      "attention_bam_384_attention_center_y": 0.483482027909863,
      "attention_bam_384_attention_center_x": 0.48489862091947433,
      "attention_bam_384_attention_center_distance": 0.03165106797895714,
      "attention_bam_384_attention_spatial_variance": 170.84295331973493,
      "attention_bam_384_attention_spatial_std": 13.070690621376322,
      "attention_bam_384_num_attention_peaks": 22,
      "attention_bam_384_peak_separation_mean": 17.39973128916825,
      "attention_bam_384_peak_intensity_mean": 0.28293561935424805,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2639024555683136,
      "attention_bam_16_std_attention": 0.44963252544403076,
      "attention_bam_16_max_attention": 2.038027763366699,
      "attention_bam_16_min_attention": -1.0252678394317627,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.09694927010072796,
      "attention_bam_16_attention_skewness": 0.005952850582026436,
      "attention_bam_16_attention_sparsity": 0.3466796875,
      "attention_bam_16_attention_concentration_10": 0.3937613557443519,
      "attention_bam_16_attention_concentration_20": 0.6682494838786359,
      "attention_bam_16_attention_center_y": 0.4727337034620337,
      "attention_bam_16_attention_center_x": 0.47849725315696323,
      "attention_bam_16_attention_center_distance": 0.04910843203955999,
      "attention_bam_16_attention_spatial_variance": 42.12185141012284,
      "attention_bam_16_attention_spatial_std": 6.490134930039809,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 8.389349523664121,
      "attention_bam_16_peak_intensity_mean": 0.4294973313808441,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 30,
      "phase": "train",
      "loss": 0.3020942509174347,
      "timestamp": 1759543885.7526467,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.3020942509174347,
      "ssim": 0.17036043107509613,
      "attention_bam_384_mean_attention": 0.2337094396352768,
      "attention_bam_384_std_attention": 0.4925580620765686,
      "attention_bam_384_max_attention": 5.252037048339844,
      "attention_bam_384_min_attention": -1.6291651725769043,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.58055299459581,
      "attention_bam_384_attention_skewness": 0.6557225003331142,
      "attention_bam_384_attention_sparsity": 0.40692138671875,
      "attention_bam_384_attention_concentration_10": 0.5011098802250347,
      "attention_bam_384_attention_concentration_20": 0.8057389534165675,
      "attention_bam_384_attention_center_y": 0.48699479627964976,
      "attention_bam_384_attention_center_x": 0.4842224047630533,
      "attention_bam_384_attention_center_distance": 0.02891601062625118,
      "attention_bam_384_attention_spatial_variance": 170.34436297489867,
      "attention_bam_384_attention_spatial_std": 13.051603846841916,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 15.722986467884713,
      "attention_bam_384_peak_intensity_mean": 0.2722119092941284,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2635646462440491,
      "attention_bam_16_std_attention": 0.43870529532432556,
      "attention_bam_16_max_attention": 2.2576403617858887,
      "attention_bam_16_min_attention": -0.9359070062637329,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.07531559353170358,
      "attention_bam_16_attention_skewness": 0.2891027923002997,
      "attention_bam_16_attention_sparsity": 0.375,
      "attention_bam_16_attention_concentration_10": 0.4084907531395052,
      "attention_bam_16_attention_concentration_20": 0.6878535401499556,
      "attention_bam_16_attention_center_y": 0.4857220578051647,
      "attention_bam_16_attention_center_x": 0.4730118542577001,
      "attention_bam_16_attention_center_distance": 0.04317915339435637,
      "attention_bam_16_attention_spatial_variance": 41.26727829845637,
      "attention_bam_16_attention_spatial_std": 6.423961262216356,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.668472886786978,
      "attention_bam_16_peak_intensity_mean": 0.38154563307762146,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 31,
      "phase": "train",
      "loss": 0.21787279844284058,
      "timestamp": 1759543885.8813806,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.21787279844284058,
      "ssim": 0.22583094239234924,
      "attention_bam_384_mean_attention": 0.22570741176605225,
      "attention_bam_384_std_attention": 0.5528326630592346,
      "attention_bam_384_max_attention": 5.928731918334961,
      "attention_bam_384_min_attention": -1.542466640472412,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.3347267171505077,
      "attention_bam_384_attention_skewness": 0.5428709865719916,
      "attention_bam_384_attention_sparsity": 0.42875417073567706,
      "attention_bam_384_attention_concentration_10": 0.5606651663443388,
      "attention_bam_384_attention_concentration_20": 0.9110173512392126,
      "attention_bam_384_attention_center_y": 0.4812839631393476,
      "attention_bam_384_attention_center_x": 0.4792057571724197,
      "attention_bam_384_attention_center_distance": 0.0395648978399205,
      "attention_bam_384_attention_spatial_variance": 170.12817197390828,
      "attention_bam_384_attention_spatial_std": 13.043319055129652,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 15.742029598686647,
      "attention_bam_384_peak_intensity_mean": 0.2377193719148636,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24231381714344025,
      "attention_bam_16_std_attention": 0.5490895509719849,
      "attention_bam_16_max_attention": 2.3561995029449463,
      "attention_bam_16_min_attention": -1.125166654586792,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.09091130172355255,
      "attention_bam_16_attention_skewness": 0.44658727505483714,
      "attention_bam_16_attention_sparsity": 0.423828125,
      "attention_bam_16_attention_concentration_10": 0.5329705520471741,
      "attention_bam_16_attention_concentration_20": 0.8752789811124312,
      "attention_bam_16_attention_center_y": 0.46327712327425835,
      "attention_bam_16_attention_center_x": 0.4557349659254822,
      "attention_bam_16_attention_center_distance": 0.08133834171695709,
      "attention_bam_16_attention_spatial_variance": 41.336798173426345,
      "attention_bam_16_attention_spatial_std": 6.4293699670672515,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.208000829755116,
      "attention_bam_16_peak_intensity_mean": 0.4094815254211426,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 32,
      "phase": "train",
      "loss": 0.2503387928009033,
      "timestamp": 1759543886.0137608,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.2503387928009033,
      "ssim": 0.21875518560409546,
      "attention_bam_384_mean_attention": 0.21799390017986298,
      "attention_bam_384_std_attention": 0.6210964322090149,
      "attention_bam_384_max_attention": 4.952032089233398,
      "attention_bam_384_min_attention": -1.6348559856414795,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.205084030827601,
      "attention_bam_384_attention_skewness": 1.1188193510331117,
      "attention_bam_384_attention_sparsity": 0.46062978108723956,
      "attention_bam_384_attention_concentration_10": 0.6864583021933593,
      "attention_bam_384_attention_concentration_20": 1.0397153953446803,
      "attention_bam_384_attention_center_y": 0.4788064751145566,
      "attention_bam_384_attention_center_x": 0.47484888282326265,
      "attention_bam_384_attention_center_distance": 0.046513314057544455,
      "attention_bam_384_attention_spatial_variance": 170.27144541609326,
      "attention_bam_384_attention_spatial_std": 13.048810114952753,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 14.056577568320922,
      "attention_bam_384_peak_intensity_mean": 0.2862311601638794,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2377633899450302,
      "attention_bam_16_std_attention": 0.7150695323944092,
      "attention_bam_16_max_attention": 4.082350730895996,
      "attention_bam_16_min_attention": -1.2297980785369873,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.7766449556298234,
      "attention_bam_16_attention_skewness": 1.2561722685461798,
      "attention_bam_16_attention_sparsity": 0.488525390625,
      "attention_bam_16_attention_concentration_10": 0.7412832176045877,
      "attention_bam_16_attention_concentration_20": 1.1219953132339848,
      "attention_bam_16_attention_center_y": 0.4527947378476442,
      "attention_bam_16_attention_center_x": 0.4481796290942535,
      "attention_bam_16_attention_center_distance": 0.09913311874123373,
      "attention_bam_16_attention_spatial_variance": 40.938194490122704,
      "attention_bam_16_attention_spatial_std": 6.39829621775381,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 7.117094512809319,
      "attention_bam_16_peak_intensity_mean": 0.29533472657203674,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 33,
      "phase": "train",
      "loss": 0.24428290128707886,
      "timestamp": 1759543886.142257,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.24428290128707886,
      "ssim": 0.22591455280780792,
      "attention_bam_384_mean_attention": 0.20671193301677704,
      "attention_bam_384_std_attention": 0.5395390391349792,
      "attention_bam_384_max_attention": 4.292047500610352,
      "attention_bam_384_min_attention": -1.6421823501586914,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.2235236804487464,
      "attention_bam_384_attention_skewness": 0.7403625595584061,
      "attention_bam_384_attention_sparsity": 0.442047119140625,
      "attention_bam_384_attention_concentration_10": 0.6093531217151787,
      "attention_bam_384_attention_concentration_20": 0.9571700797911041,
      "attention_bam_384_attention_center_y": 0.48439470860962647,
      "attention_bam_384_attention_center_x": 0.4839652162241953,
      "attention_bam_384_attention_center_distance": 0.0316429900646344,
      "attention_bam_384_attention_spatial_variance": 171.48831715284157,
      "attention_bam_384_attention_spatial_std": 13.095354792934844,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 20.844470961474045,
      "attention_bam_384_peak_intensity_mean": 0.31291463971138,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23821523785591125,
      "attention_bam_16_std_attention": 0.5911238193511963,
      "attention_bam_16_max_attention": 2.424424648284912,
      "attention_bam_16_min_attention": -1.1198607683181763,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.1093022154125256,
      "attention_bam_16_attention_skewness": 0.5050546361067412,
      "attention_bam_16_attention_sparsity": 0.450439453125,
      "attention_bam_16_attention_concentration_10": 0.5789782961083647,
      "attention_bam_16_attention_concentration_20": 0.9395937309936998,
      "attention_bam_16_attention_center_y": 0.474470198213707,
      "attention_bam_16_attention_center_x": 0.4726701302767751,
      "attention_bam_16_attention_center_distance": 0.052890312124922324,
      "attention_bam_16_attention_spatial_variance": 43.08416584503805,
      "attention_bam_16_attention_spatial_std": 6.56385297253359,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.267599191836704,
      "attention_bam_16_peak_intensity_mean": 0.38697630167007446,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 34,
      "phase": "train",
      "loss": 0.19831185042858124,
      "timestamp": 1759543886.2694435,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.19831185042858124,
      "ssim": 0.2389984279870987,
      "attention_bam_384_mean_attention": 0.21794486045837402,
      "attention_bam_384_std_attention": 0.5283489227294922,
      "attention_bam_384_max_attention": 5.722368240356445,
      "attention_bam_384_min_attention": -1.591370701789856,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.0797550918821397,
      "attention_bam_384_attention_skewness": 0.6207271984999225,
      "attention_bam_384_attention_sparsity": 0.42224375406901044,
      "attention_bam_384_attention_concentration_10": 0.567150817118343,
      "attention_bam_384_attention_concentration_20": 0.9005000581610331,
      "attention_bam_384_attention_center_y": 0.4852092474458066,
      "attention_bam_384_attention_center_x": 0.48064905961575505,
      "attention_bam_384_attention_center_distance": 0.03444489090921845,
      "attention_bam_384_attention_spatial_variance": 170.9346849415136,
      "attention_bam_384_attention_spatial_std": 13.074199208422426,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 16.75860867550525,
      "attention_bam_384_peak_intensity_mean": 0.24868886172771454,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23239950835704803,
      "attention_bam_16_std_attention": 0.5335832834243774,
      "attention_bam_16_max_attention": 2.5675549507141113,
      "attention_bam_16_min_attention": -1.03937828540802,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.34320456769434315,
      "attention_bam_16_attention_skewness": 0.4745627968568583,
      "attention_bam_16_attention_sparsity": 0.42431640625,
      "attention_bam_16_attention_concentration_10": 0.5390501335953277,
      "attention_bam_16_attention_concentration_20": 0.8754813633370876,
      "attention_bam_16_attention_center_y": 0.47871701708772085,
      "attention_bam_16_attention_center_x": 0.454767903667098,
      "attention_bam_16_attention_center_distance": 0.07069523180969549,
      "attention_bam_16_attention_spatial_variance": 41.94578602335785,
      "attention_bam_16_attention_spatial_std": 6.476556648664308,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 8.025132040137212,
      "attention_bam_16_peak_intensity_mean": 0.36239925026893616,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 35,
      "phase": "train",
      "loss": 0.2605200409889221,
      "timestamp": 1759543886.3977544,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.2605200409889221,
      "ssim": 0.2079371213912964,
      "attention_bam_384_mean_attention": 0.22766314446926117,
      "attention_bam_384_std_attention": 0.5356962084770203,
      "attention_bam_384_max_attention": 4.747298717498779,
      "attention_bam_384_min_attention": -1.6275405883789062,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9395882567154588,
      "attention_bam_384_attention_skewness": 0.45507969565399975,
      "attention_bam_384_attention_sparsity": 0.41879526774088544,
      "attention_bam_384_attention_concentration_10": 0.5459006510445943,
      "attention_bam_384_attention_concentration_20": 0.8830221087785798,
      "attention_bam_384_attention_center_y": 0.4862686858764546,
      "attention_bam_384_attention_center_x": 0.48233422334285947,
      "attention_bam_384_attention_center_distance": 0.03164265009317166,
      "attention_bam_384_attention_spatial_variance": 170.41019733365957,
      "attention_bam_384_attention_spatial_std": 13.054125682467577,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 18.029154310030584,
      "attention_bam_384_peak_intensity_mean": 0.2923210561275482,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.25620946288108826,
      "attention_bam_16_std_attention": 0.5473846197128296,
      "attention_bam_16_max_attention": 2.1846871376037598,
      "attention_bam_16_min_attention": -1.0939794778823853,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.023214624215838864,
      "attention_bam_16_attention_skewness": 0.30932232422143474,
      "attention_bam_16_attention_sparsity": 0.4013671875,
      "attention_bam_16_attention_concentration_10": 0.5029064333484746,
      "attention_bam_16_attention_concentration_20": 0.8201013543890812,
      "attention_bam_16_attention_center_y": 0.4803994421478508,
      "attention_bam_16_attention_center_x": 0.4669242776613444,
      "attention_bam_16_attention_center_distance": 0.05437251651964045,
      "attention_bam_16_attention_spatial_variance": 41.78859471078374,
      "attention_bam_16_attention_spatial_std": 6.464409850155213,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.219188280786781,
      "attention_bam_16_peak_intensity_mean": 0.41315728425979614,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 36,
      "phase": "train",
      "loss": 0.2320100963115692,
      "timestamp": 1759543886.5254416,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.2320100963115692,
      "ssim": 0.22538501024246216,
      "attention_bam_384_mean_attention": 0.2355656772851944,
      "attention_bam_384_std_attention": 0.5231867432594299,
      "attention_bam_384_max_attention": 5.290745258331299,
      "attention_bam_384_min_attention": -1.5880557298660278,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.934096465030395,
      "attention_bam_384_attention_skewness": 0.5720078421734823,
      "attention_bam_384_attention_sparsity": 0.4121042887369792,
      "attention_bam_384_attention_concentration_10": 0.5185422078471935,
      "attention_bam_384_attention_concentration_20": 0.8391722147910827,
      "attention_bam_384_attention_center_y": 0.4837810871668948,
      "attention_bam_384_attention_center_x": 0.4837501118437962,
      "attention_bam_384_attention_center_distance": 0.032468815764576275,
      "attention_bam_384_attention_spatial_variance": 168.8863494252955,
      "attention_bam_384_attention_spatial_std": 12.995628088911113,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 15.240854660552138,
      "attention_bam_384_peak_intensity_mean": 0.2668587565422058,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2751716077327728,
      "attention_bam_16_std_attention": 0.4861895442008972,
      "attention_bam_16_max_attention": 2.0748538970947266,
      "attention_bam_16_min_attention": -1.0498344898223877,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.26206878755058893,
      "attention_bam_16_attention_skewness": 0.331621166107437,
      "attention_bam_16_attention_sparsity": 0.376953125,
      "attention_bam_16_attention_concentration_10": 0.42759901277906104,
      "attention_bam_16_attention_concentration_20": 0.7112742922860809,
      "attention_bam_16_attention_center_y": 0.47371917707957906,
      "attention_bam_16_attention_center_x": 0.4730659323088918,
      "attention_bam_16_attention_center_distance": 0.05321889994661144,
      "attention_bam_16_attention_spatial_variance": 40.53969485761468,
      "attention_bam_16_attention_spatial_std": 6.367078989427937,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.313205955317857,
      "attention_bam_16_peak_intensity_mean": 0.4490419924259186,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 37,
      "phase": "train",
      "loss": 0.23838186264038086,
      "timestamp": 1759543886.6555977,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.23838186264038086,
      "ssim": 0.23413622379302979,
      "attention_bam_384_mean_attention": 0.2283911108970642,
      "attention_bam_384_std_attention": 0.5848062634468079,
      "attention_bam_384_max_attention": 5.267142295837402,
      "attention_bam_384_min_attention": -1.6233408451080322,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8046863275042213,
      "attention_bam_384_attention_skewness": 0.506774832000831,
      "attention_bam_384_attention_sparsity": 0.44130706787109375,
      "attention_bam_384_attention_concentration_10": 0.5817515348227293,
      "attention_bam_384_attention_concentration_20": 0.9485187904169526,
      "attention_bam_384_attention_center_y": 0.4839635119735641,
      "attention_bam_384_attention_center_x": 0.4903953521509151,
      "attention_bam_384_attention_center_distance": 0.026435514314155247,
      "attention_bam_384_attention_spatial_variance": 170.32333971593167,
      "attention_bam_384_attention_spatial_std": 13.050798432124054,
      "attention_bam_384_num_attention_peaks": 26,
      "attention_bam_384_peak_separation_mean": 15.345491187642198,
      "attention_bam_384_peak_intensity_mean": 0.2696146070957184,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.25875866413116455,
      "attention_bam_16_std_attention": 0.5958693027496338,
      "attention_bam_16_max_attention": 2.3669371604919434,
      "attention_bam_16_min_attention": -1.1310365200042725,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.3175069205350418,
      "attention_bam_16_attention_skewness": 0.3538629085854442,
      "attention_bam_16_attention_sparsity": 0.432861328125,
      "attention_bam_16_attention_concentration_10": 0.5277936078268659,
      "attention_bam_16_attention_concentration_20": 0.8838243017480677,
      "attention_bam_16_attention_center_y": 0.47539770240015905,
      "attention_bam_16_attention_center_x": 0.4951061975999892,
      "attention_bam_16_attention_center_distance": 0.035474564102226575,
      "attention_bam_16_attention_spatial_variance": 41.6719037635998,
      "attention_bam_16_attention_spatial_std": 6.455377894716916,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 7.70842382238601,
      "attention_bam_16_peak_intensity_mean": 0.403571754693985,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 38,
      "phase": "train",
      "loss": 0.2889630198478699,
      "timestamp": 1759543886.7836964,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.2889630198478699,
      "ssim": 0.22962580621242523,
      "attention_bam_384_mean_attention": 0.22620785236358643,
      "attention_bam_384_std_attention": 0.5495300889015198,
      "attention_bam_384_max_attention": 5.142239093780518,
      "attention_bam_384_min_attention": -1.6721932888031006,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.100240984508506,
      "attention_bam_384_attention_skewness": 0.6607252630975764,
      "attention_bam_384_attention_sparsity": 0.4318796793619792,
      "attention_bam_384_attention_concentration_10": 0.5650419036145086,
      "attention_bam_384_attention_concentration_20": 0.9045591139679983,
      "attention_bam_384_attention_center_y": 0.48682516881256205,
      "attention_bam_384_attention_center_x": 0.4805234815042005,
      "attention_bam_384_attention_center_distance": 0.03325390050910444,
      "attention_bam_384_attention_spatial_variance": 170.39489721039857,
      "attention_bam_384_attention_spatial_std": 13.053539642962692,
      "attention_bam_384_num_attention_peaks": 20,
      "attention_bam_384_peak_separation_mean": 17.357947814153626,
      "attention_bam_384_peak_intensity_mean": 0.2795321047306061,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.254856675863266,
      "attention_bam_16_std_attention": 0.5198972821235657,
      "attention_bam_16_max_attention": 1.9171342849731445,
      "attention_bam_16_min_attention": -1.152980089187622,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.3180335361915785,
      "attention_bam_16_attention_skewness": 0.29202979823748737,
      "attention_bam_16_attention_sparsity": 0.41015625,
      "attention_bam_16_attention_concentration_10": 0.4759074092890083,
      "attention_bam_16_attention_concentration_20": 0.7995046757998624,
      "attention_bam_16_attention_center_y": 0.4848417101890606,
      "attention_bam_16_attention_center_x": 0.4557425590369721,
      "attention_bam_16_attention_center_distance": 0.06615882149174562,
      "attention_bam_16_attention_spatial_variance": 41.47404772368933,
      "attention_bam_16_attention_spatial_std": 6.440034761062189,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 9.261856469282037,
      "attention_bam_16_peak_intensity_mean": 0.4676327705383301,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 39,
      "phase": "train",
      "loss": 0.2680726945400238,
      "timestamp": 1759543886.91344,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.2680726945400238,
      "ssim": 0.23713000118732452,
      "attention_bam_384_mean_attention": 0.21623878180980682,
      "attention_bam_384_std_attention": 0.6116053462028503,
      "attention_bam_384_max_attention": 5.754106521606445,
      "attention_bam_384_min_attention": -1.69685697555542,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8830247087667153,
      "attention_bam_384_attention_skewness": 0.7280841022993836,
      "attention_bam_384_attention_sparsity": 0.4540812174479167,
      "attention_bam_384_attention_concentration_10": 0.6487254188711962,
      "attention_bam_384_attention_concentration_20": 1.030744729665118,
      "attention_bam_384_attention_center_y": 0.4820419313136003,
      "attention_bam_384_attention_center_x": 0.4800221363635516,
      "attention_bam_384_attention_center_distance": 0.03798966350000948,
      "attention_bam_384_attention_spatial_variance": 170.02599887028435,
      "attention_bam_384_attention_spatial_std": 13.039401783451737,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 17.468626575240936,
      "attention_bam_384_peak_intensity_mean": 0.25783783197402954,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2260163426399231,
      "attention_bam_16_std_attention": 0.6412940621376038,
      "attention_bam_16_max_attention": 2.2788639068603516,
      "attention_bam_16_min_attention": -1.0855107307434082,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.3082457417641917,
      "attention_bam_16_attention_skewness": 0.4484007935795763,
      "attention_bam_16_attention_sparsity": 0.46630859375,
      "attention_bam_16_attention_concentration_10": 0.6507781667552349,
      "attention_bam_16_attention_concentration_20": 1.0649356197594573,
      "attention_bam_16_attention_center_y": 0.4618024711218646,
      "attention_bam_16_attention_center_x": 0.45360532005135995,
      "attention_bam_16_attention_center_distance": 0.0849884408603044,
      "attention_bam_16_attention_spatial_variance": 40.81019514557617,
      "attention_bam_16_attention_spatial_std": 6.38828577519636,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 6.482148793870536,
      "attention_bam_16_peak_intensity_mean": 0.40469643473625183,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 40,
      "phase": "train",
      "loss": 0.20632950961589813,
      "timestamp": 1759543887.080663,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.20632950961589813,
      "ssim": 0.2691352963447571,
      "attention_bam_384_mean_attention": 0.23177647590637207,
      "attention_bam_384_std_attention": 0.5208592414855957,
      "attention_bam_384_max_attention": 4.732554912567139,
      "attention_bam_384_min_attention": -1.5615198612213135,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2790315950493198,
      "attention_bam_384_attention_skewness": 0.4802896307652563,
      "attention_bam_384_attention_sparsity": 0.4076131184895833,
      "attention_bam_384_attention_concentration_10": 0.5248717349986035,
      "attention_bam_384_attention_concentration_20": 0.8434985254195739,
      "attention_bam_384_attention_center_y": 0.48926220670341414,
      "attention_bam_384_attention_center_x": 0.4798316144941069,
      "attention_bam_384_attention_center_distance": 0.032312968876119195,
      "attention_bam_384_attention_spatial_variance": 169.77427523916563,
      "attention_bam_384_attention_spatial_std": 13.029745785669252,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 16.568369997662728,
      "attention_bam_384_peak_intensity_mean": 0.2873612344264984,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2593216300010681,
      "attention_bam_16_std_attention": 0.5020548105239868,
      "attention_bam_16_max_attention": 2.2338013648986816,
      "attention_bam_16_min_attention": -1.142506718635559,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.08516063149162578,
      "attention_bam_16_attention_skewness": 0.2502222976065376,
      "attention_bam_16_attention_sparsity": 0.395263671875,
      "attention_bam_16_attention_concentration_10": 0.4521995910955556,
      "attention_bam_16_attention_concentration_20": 0.7513528298281597,
      "attention_bam_16_attention_center_y": 0.4849272172848713,
      "attention_bam_16_attention_center_x": 0.45888589608039126,
      "attention_bam_16_attention_center_distance": 0.061928318560895354,
      "attention_bam_16_attention_spatial_variance": 41.30650667652969,
      "attention_bam_16_attention_spatial_std": 6.427013822649652,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 7.397915805165652,
      "attention_bam_16_peak_intensity_mean": 0.43067213892936707,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 41,
      "phase": "train",
      "loss": 0.22675108909606934,
      "timestamp": 1759543887.2196364,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.22675108909606934,
      "ssim": 0.24016980826854706,
      "attention_bam_384_mean_attention": 0.21978534758090973,
      "attention_bam_384_std_attention": 0.5584614872932434,
      "attention_bam_384_max_attention": 5.049464225769043,
      "attention_bam_384_min_attention": -1.6354448795318604,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.3019204710211536,
      "attention_bam_384_attention_skewness": 0.5833373456615342,
      "attention_bam_384_attention_sparsity": 0.43923695882161456,
      "attention_bam_384_attention_concentration_10": 0.5853543146504449,
      "attention_bam_384_attention_concentration_20": 0.9432660477939969,
      "attention_bam_384_attention_center_y": 0.48152726607506086,
      "attention_bam_384_attention_center_x": 0.485198297963291,
      "attention_bam_384_attention_center_distance": 0.03347632840814872,
      "attention_bam_384_attention_spatial_variance": 172.19200921498052,
      "attention_bam_384_attention_spatial_std": 13.12219528946969,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 16.981791254298482,
      "attention_bam_384_peak_intensity_mean": 0.28114941716194153,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23281627893447876,
      "attention_bam_16_std_attention": 0.5845001935958862,
      "attention_bam_16_max_attention": 2.165127754211426,
      "attention_bam_16_min_attention": -1.1348919868469238,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.33028284613511616,
      "attention_bam_16_attention_skewness": 0.2572706171198683,
      "attention_bam_16_attention_sparsity": 0.437255859375,
      "attention_bam_16_attention_concentration_10": 0.5602849353334953,
      "attention_bam_16_attention_concentration_20": 0.9296787974533393,
      "attention_bam_16_attention_center_y": 0.46385771229616746,
      "attention_bam_16_attention_center_x": 0.46982657712571296,
      "attention_bam_16_attention_center_distance": 0.06658378794296932,
      "attention_bam_16_attention_spatial_variance": 43.33339766618157,
      "attention_bam_16_attention_spatial_std": 6.5828107724726195,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.397377393562788,
      "attention_bam_16_peak_intensity_mean": 0.4347938597202301,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 42,
      "phase": "train",
      "loss": 0.24152283370494843,
      "timestamp": 1759543887.3450298,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.24152283370494843,
      "ssim": 0.26487648487091064,
      "attention_bam_384_mean_attention": 0.2217838168144226,
      "attention_bam_384_std_attention": 0.5682394504547119,
      "attention_bam_384_max_attention": 4.584859848022461,
      "attention_bam_384_min_attention": -1.6161856651306152,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2081361029117277,
      "attention_bam_384_attention_skewness": 0.6081567239974875,
      "attention_bam_384_attention_sparsity": 0.4341684977213542,
      "attention_bam_384_attention_concentration_10": 0.6032547997826008,
      "attention_bam_384_attention_concentration_20": 0.9473665303649584,
      "attention_bam_384_attention_center_y": 0.48481826997242616,
      "attention_bam_384_attention_center_x": 0.47786747571475274,
      "attention_bam_384_attention_center_distance": 0.0379561209258058,
      "attention_bam_384_attention_spatial_variance": 170.66395072848212,
      "attention_bam_384_attention_spatial_std": 13.063841346574986,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 18.308330829943724,
      "attention_bam_384_peak_intensity_mean": 0.2970249354839325,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24293583631515503,
      "attention_bam_16_std_attention": 0.6057959794998169,
      "attention_bam_16_max_attention": 2.8300094604492188,
      "attention_bam_16_min_attention": -1.2900885343551636,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6205496236863866,
      "attention_bam_16_attention_skewness": 0.6054870643685979,
      "attention_bam_16_attention_sparsity": 0.42822265625,
      "attention_bam_16_attention_concentration_10": 0.5940121502854956,
      "attention_bam_16_attention_concentration_20": 0.9444184031111823,
      "attention_bam_16_attention_center_y": 0.4739802099584787,
      "attention_bam_16_attention_center_x": 0.45011550494164454,
      "attention_bam_16_attention_center_distance": 0.07956748482931882,
      "attention_bam_16_attention_spatial_variance": 41.82532734193377,
      "attention_bam_16_attention_spatial_std": 6.467250369510506,
      "attention_bam_16_num_attention_peaks": 2,
      "attention_bam_16_peak_separation_mean": 8.613516245204034,
      "attention_bam_16_peak_intensity_mean": 0.37644073367118835,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 43,
      "phase": "train",
      "loss": 0.2179861068725586,
      "timestamp": 1759543887.4716516,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.2179861068725586,
      "ssim": 0.2778950333595276,
      "attention_bam_384_mean_attention": 0.22322244942188263,
      "attention_bam_384_std_attention": 0.5780821442604065,
      "attention_bam_384_max_attention": 5.404193878173828,
      "attention_bam_384_min_attention": -1.6288421154022217,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.865460934159504,
      "attention_bam_384_attention_skewness": 0.7255545400844741,
      "attention_bam_384_attention_sparsity": 0.4413909912109375,
      "attention_bam_384_attention_concentration_10": 0.6098824279577494,
      "attention_bam_384_attention_concentration_20": 0.9615873534086644,
      "attention_bam_384_attention_center_y": 0.48502390602654916,
      "attention_bam_384_attention_center_x": 0.47499291477260164,
      "attention_bam_384_attention_center_distance": 0.04122226830905829,
      "attention_bam_384_attention_spatial_variance": 171.0321270984746,
      "attention_bam_384_attention_spatial_std": 13.077925183241973,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 16.69185212676989,
      "attention_bam_384_peak_intensity_mean": 0.2649221122264862,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24962781369686127,
      "attention_bam_16_std_attention": 0.5911195278167725,
      "attention_bam_16_max_attention": 2.4490230083465576,
      "attention_bam_16_min_attention": -1.1694793701171875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.15909614801518446,
      "attention_bam_16_attention_skewness": 0.5620629083512534,
      "attention_bam_16_attention_sparsity": 0.437744140625,
      "attention_bam_16_attention_concentration_10": 0.5727591398323626,
      "attention_bam_16_attention_concentration_20": 0.9166725116475363,
      "attention_bam_16_attention_center_y": 0.47580703411049174,
      "attention_bam_16_attention_center_x": 0.4446634812230204,
      "attention_bam_16_attention_center_distance": 0.08540995151486652,
      "attention_bam_16_attention_spatial_variance": 41.997759390571936,
      "attention_bam_16_attention_spatial_std": 6.480567829331928,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 7.301520674936229,
      "attention_bam_16_peak_intensity_mean": 0.38898035883903503,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 44,
      "phase": "train",
      "loss": 0.22746527194976807,
      "timestamp": 1759543887.6005228,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.22746527194976807,
      "ssim": 0.25375422835350037,
      "attention_bam_384_mean_attention": 0.2195112556219101,
      "attention_bam_384_std_attention": 0.5865639448165894,
      "attention_bam_384_max_attention": 5.658783912658691,
      "attention_bam_384_min_attention": -1.6080029010772705,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0966538632476865,
      "attention_bam_384_attention_skewness": 0.5686459151165985,
      "attention_bam_384_attention_sparsity": 0.44067637125651044,
      "attention_bam_384_attention_concentration_10": 0.6111120262792975,
      "attention_bam_384_attention_concentration_20": 0.9816468738399294,
      "attention_bam_384_attention_center_y": 0.4780488102653145,
      "attention_bam_384_attention_center_x": 0.4845986616311254,
      "attention_bam_384_attention_center_distance": 0.037922445973874924,
      "attention_bam_384_attention_spatial_variance": 170.23177320917696,
      "attention_bam_384_attention_spatial_std": 13.047289879863058,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 15.566248835057372,
      "attention_bam_384_peak_intensity_mean": 0.2543160319328308,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23721404373645782,
      "attention_bam_16_std_attention": 0.6194597482681274,
      "attention_bam_16_max_attention": 2.5603630542755127,
      "attention_bam_16_min_attention": -1.1490602493286133,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.05486194315063475,
      "attention_bam_16_attention_skewness": 0.45255541231017204,
      "attention_bam_16_attention_sparsity": 0.4501953125,
      "attention_bam_16_attention_concentration_10": 0.5975920219372115,
      "attention_bam_16_attention_concentration_20": 0.9770009293728614,
      "attention_bam_16_attention_center_y": 0.45180512317039034,
      "attention_bam_16_attention_center_x": 0.4741262204577075,
      "attention_bam_16_attention_center_distance": 0.07735888598505536,
      "attention_bam_16_attention_spatial_variance": 41.85293379010512,
      "attention_bam_16_attention_spatial_std": 6.469384343977804,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.171489906532212,
      "attention_bam_16_peak_intensity_mean": 0.3851636052131653,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 45,
      "phase": "train",
      "loss": 0.201954185962677,
      "timestamp": 1759543887.7226925,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.201954185962677,
      "ssim": 0.2877354919910431,
      "attention_bam_384_mean_attention": 0.2169194370508194,
      "attention_bam_384_std_attention": 0.5979010462760925,
      "attention_bam_384_max_attention": 5.1048359870910645,
      "attention_bam_384_min_attention": -1.6191970109939575,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5522961312372718,
      "attention_bam_384_attention_skewness": 0.6526588805385922,
      "attention_bam_384_attention_sparsity": 0.44954172770182294,
      "attention_bam_384_attention_concentration_10": 0.6273968752085859,
      "attention_bam_384_attention_concentration_20": 1.004224983291103,
      "attention_bam_384_attention_center_y": 0.4862991096966862,
      "attention_bam_384_attention_center_x": 0.4828867374573833,
      "attention_bam_384_attention_center_distance": 0.031002520863825416,
      "attention_bam_384_attention_spatial_variance": 170.09144581573838,
      "attention_bam_384_attention_spatial_std": 13.041911125894792,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 17.096335339941444,
      "attention_bam_384_peak_intensity_mean": 0.2746352255344391,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2521512508392334,
      "attention_bam_16_std_attention": 0.628609299659729,
      "attention_bam_16_max_attention": 2.6603214740753174,
      "attention_bam_16_min_attention": -1.2926708459854126,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.15761909490733528,
      "attention_bam_16_attention_skewness": 0.3853628763731341,
      "attention_bam_16_attention_sparsity": 0.43994140625,
      "attention_bam_16_attention_concentration_10": 0.5596551126601568,
      "attention_bam_16_attention_concentration_20": 0.9330217549283292,
      "attention_bam_16_attention_center_y": 0.47408689892320055,
      "attention_bam_16_attention_center_x": 0.47087479031127194,
      "attention_bam_16_attention_center_distance": 0.05513196254132087,
      "attention_bam_16_attention_spatial_variance": 41.19353380118267,
      "attention_bam_16_attention_spatial_std": 6.418218896328066,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.27745536108274,
      "attention_bam_16_peak_intensity_mean": 0.39888226985931396,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 46,
      "phase": "train",
      "loss": 0.1932862251996994,
      "timestamp": 1759543887.8502433,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.1932862251996994,
      "ssim": 0.32851600646972656,
      "attention_bam_384_mean_attention": 0.21869464218616486,
      "attention_bam_384_std_attention": 0.5682958960533142,
      "attention_bam_384_max_attention": 4.823041915893555,
      "attention_bam_384_min_attention": -1.6328338384628296,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.3402294018451864,
      "attention_bam_384_attention_skewness": 0.6173595917720495,
      "attention_bam_384_attention_sparsity": 0.4404551188151042,
      "attention_bam_384_attention_concentration_10": 0.6008157160244965,
      "attention_bam_384_attention_concentration_20": 0.959372548777232,
      "attention_bam_384_attention_center_y": 0.4837609212697618,
      "attention_bam_384_attention_center_x": 0.4867325267070155,
      "attention_bam_384_attention_center_distance": 0.02965580973728191,
      "attention_bam_384_attention_spatial_variance": 170.8427813087271,
      "attention_bam_384_attention_spatial_std": 13.070684041347151,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 17.41842648903043,
      "attention_bam_384_peak_intensity_mean": 0.288838654756546,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2435303032398224,
      "attention_bam_16_std_attention": 0.5995962023735046,
      "attention_bam_16_max_attention": 2.4487905502319336,
      "attention_bam_16_min_attention": -1.035926103591919,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.23308775087920308,
      "attention_bam_16_attention_skewness": 0.3137625767137986,
      "attention_bam_16_attention_sparsity": 0.42578125,
      "attention_bam_16_attention_concentration_10": 0.5571270024215027,
      "attention_bam_16_attention_concentration_20": 0.9213596220244091,
      "attention_bam_16_attention_center_y": 0.472918565175789,
      "attention_bam_16_attention_center_x": 0.4774437661107188,
      "attention_bam_16_attention_center_distance": 0.0498435111003618,
      "attention_bam_16_attention_spatial_variance": 42.5855168842801,
      "attention_bam_16_attention_spatial_std": 6.5257579547727715,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.018042342581968,
      "attention_bam_16_peak_intensity_mean": 0.38524129986763,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 47,
      "phase": "train",
      "loss": 0.21877416968345642,
      "timestamp": 1759543887.9779463,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.21877416968345642,
      "ssim": 0.2989337146282196,
      "attention_bam_384_mean_attention": 0.20950108766555786,
      "attention_bam_384_std_attention": 0.5510633587837219,
      "attention_bam_384_max_attention": 4.409530162811279,
      "attention_bam_384_min_attention": -1.6228246688842773,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0787332210096716,
      "attention_bam_384_attention_skewness": 0.5756811230451302,
      "attention_bam_384_attention_sparsity": 0.44528452555338544,
      "attention_bam_384_attention_concentration_10": 0.6031518696651136,
      "attention_bam_384_attention_concentration_20": 0.9682422221557196,
      "attention_bam_384_attention_center_y": 0.4843526070515367,
      "attention_bam_384_attention_center_x": 0.48569832223061804,
      "attention_bam_384_attention_center_distance": 0.02997928928786847,
      "attention_bam_384_attention_spatial_variance": 170.05204042900178,
      "attention_bam_384_attention_spatial_std": 13.040400317053223,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 18.974060618548283,
      "attention_bam_384_peak_intensity_mean": 0.30575141310691833,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23592066764831543,
      "attention_bam_16_std_attention": 0.6000331044197083,
      "attention_bam_16_max_attention": 2.7070281505584717,
      "attention_bam_16_min_attention": -1.1612765789031982,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5179661029994498,
      "attention_bam_16_attention_skewness": 0.5950583306905527,
      "attention_bam_16_attention_sparsity": 0.44140625,
      "attention_bam_16_attention_concentration_10": 0.5995556697457871,
      "attention_bam_16_attention_concentration_20": 0.9589542132827436,
      "attention_bam_16_attention_center_y": 0.47289446628346693,
      "attention_bam_16_attention_center_x": 0.47670036699212176,
      "attention_bam_16_attention_center_distance": 0.050548646991980306,
      "attention_bam_16_attention_spatial_variance": 41.4858907823962,
      "attention_bam_16_attention_spatial_std": 6.440954182603397,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.332167661314656,
      "attention_bam_16_peak_intensity_mean": 0.38060012459754944,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 48,
      "phase": "train",
      "loss": 0.17469635605812073,
      "timestamp": 1759543888.302214,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.17469635605812073,
      "ssim": 0.27606481313705444,
      "attention_bam_384_mean_attention": 0.22378522157669067,
      "attention_bam_384_std_attention": 0.5560377240180969,
      "attention_bam_384_max_attention": 4.513160705566406,
      "attention_bam_384_min_attention": -1.607234239578247,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1204240130612702,
      "attention_bam_384_attention_skewness": 0.5356035713556936,
      "attention_bam_384_attention_sparsity": 0.4262593587239583,
      "attention_bam_384_attention_concentration_10": 0.577190093753383,
      "attention_bam_384_attention_concentration_20": 0.9254882971769927,
      "attention_bam_384_attention_center_y": 0.4797906211581428,
      "attention_bam_384_attention_center_x": 0.4896435719403289,
      "attention_bam_384_attention_center_distance": 0.03211462580597344,
      "attention_bam_384_attention_spatial_variance": 169.13849657363141,
      "attention_bam_384_attention_spatial_std": 13.005325700405638,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 15.775449188604838,
      "attention_bam_384_peak_intensity_mean": 0.30079203844070435,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2581324875354767,
      "attention_bam_16_std_attention": 0.5643094778060913,
      "attention_bam_16_max_attention": 2.714266777038574,
      "attention_bam_16_min_attention": -1.1618061065673828,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.1762964713309576,
      "attention_bam_16_attention_skewness": 0.3497533222159321,
      "attention_bam_16_attention_sparsity": 0.388427734375,
      "attention_bam_16_attention_concentration_10": 0.5170010606672418,
      "attention_bam_16_attention_concentration_20": 0.833755085289804,
      "attention_bam_16_attention_center_y": 0.4587763999722974,
      "attention_bam_16_attention_center_x": 0.489127025181608,
      "attention_bam_16_attention_center_distance": 0.06029273224270712,
      "attention_bam_16_attention_spatial_variance": 40.99498165833969,
      "attention_bam_16_attention_spatial_std": 6.402732358793369,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.895055189776379,
      "attention_bam_16_peak_intensity_mean": 0.3825609087944031,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 49,
      "phase": "train",
      "loss": 0.18336626887321472,
      "timestamp": 1759543888.4286363,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.18336626887321472,
      "ssim": 0.3371489346027374,
      "attention_bam_384_mean_attention": 0.215324267745018,
      "attention_bam_384_std_attention": 0.5656055212020874,
      "attention_bam_384_max_attention": 5.282240867614746,
      "attention_bam_384_min_attention": -1.6547415256500244,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0641128553029287,
      "attention_bam_384_attention_skewness": 0.535067956861508,
      "attention_bam_384_attention_sparsity": 0.4379221598307292,
      "attention_bam_384_attention_concentration_10": 0.598693809759909,
      "attention_bam_384_attention_concentration_20": 0.9666028304170667,
      "attention_bam_384_attention_center_y": 0.4855280568536936,
      "attention_bam_384_attention_center_x": 0.48172219389920706,
      "attention_bam_384_attention_center_distance": 0.03297014814307355,
      "attention_bam_384_attention_spatial_variance": 170.45858626207894,
      "attention_bam_384_attention_spatial_std": 13.055978946907004,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 17.76112786755904,
      "attention_bam_384_peak_intensity_mean": 0.26997968554496765,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2338845133781433,
      "attention_bam_16_std_attention": 0.5859747529029846,
      "attention_bam_16_max_attention": 2.2361364364624023,
      "attention_bam_16_min_attention": -1.1390143632888794,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.03309594343779931,
      "attention_bam_16_attention_skewness": 0.420212264862497,
      "attention_bam_16_attention_sparsity": 0.434326171875,
      "attention_bam_16_attention_concentration_10": 0.5795238244444825,
      "attention_bam_16_attention_concentration_20": 0.9409940567154358,
      "attention_bam_16_attention_center_y": 0.4786856836454099,
      "attention_bam_16_attention_center_x": 0.4663322608924569,
      "attention_bam_16_attention_center_distance": 0.05635275926300564,
      "attention_bam_16_attention_spatial_variance": 41.988458015365254,
      "attention_bam_16_attention_spatial_std": 6.4798501537740245,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.216190348293198,
      "attention_bam_16_peak_intensity_mean": 0.4079855978488922,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 50,
      "phase": "train",
      "loss": 0.21537809073925018,
      "timestamp": 1759543888.6206334,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.21537809073925018,
      "ssim": 0.2911420464515686,
      "attention_bam_384_mean_attention": 0.20731614530086517,
      "attention_bam_384_std_attention": 0.6580814123153687,
      "attention_bam_384_max_attention": 5.832986354827881,
      "attention_bam_384_min_attention": -1.7347540855407715,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.213193756606766,
      "attention_bam_384_attention_skewness": 0.9077229977440746,
      "attention_bam_384_attention_sparsity": 0.4718983968098958,
      "attention_bam_384_attention_concentration_10": 0.7299575458980953,
      "attention_bam_384_attention_concentration_20": 1.1404837940983767,
      "attention_bam_384_attention_center_y": 0.48057263448985926,
      "attention_bam_384_attention_center_x": 0.477998579928088,
      "attention_bam_384_attention_center_distance": 0.04150867417408894,
      "attention_bam_384_attention_spatial_variance": 171.70246334060968,
      "attention_bam_384_attention_spatial_std": 13.103528659891948,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 20.560977110878117,
      "attention_bam_384_peak_intensity_mean": 0.2599378228187561,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2300647497177124,
      "attention_bam_16_std_attention": 0.7584808468818665,
      "attention_bam_16_max_attention": 4.281631946563721,
      "attention_bam_16_min_attention": -1.3536972999572754,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.4607218287773867,
      "attention_bam_16_attention_skewness": 0.9059022734949265,
      "attention_bam_16_attention_sparsity": 0.487060546875,
      "attention_bam_16_attention_concentration_10": 0.7491192653720682,
      "attention_bam_16_attention_concentration_20": 1.1860208930489509,
      "attention_bam_16_attention_center_y": 0.46003511975035294,
      "attention_bam_16_attention_center_x": 0.4528982051502863,
      "attention_bam_16_attention_center_distance": 0.08735869426030986,
      "attention_bam_16_attention_spatial_variance": 42.32526619468175,
      "attention_bam_16_attention_spatial_std": 6.505787131061218,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.117053105867818,
      "attention_bam_16_peak_intensity_mean": 0.2868344187736511,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 51,
      "phase": "train",
      "loss": 0.13767674565315247,
      "timestamp": 1759543888.7611783,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.13767674565315247,
      "ssim": 0.36909326910972595,
      "attention_bam_384_mean_attention": 0.2092844843864441,
      "attention_bam_384_std_attention": 0.5707380175590515,
      "attention_bam_384_max_attention": 5.160214900970459,
      "attention_bam_384_min_attention": -1.6421761512756348,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9481463046287657,
      "attention_bam_384_attention_skewness": 0.5745269329246484,
      "attention_bam_384_attention_sparsity": 0.4488423665364583,
      "attention_bam_384_attention_concentration_10": 0.6246584155722152,
      "attention_bam_384_attention_concentration_20": 1.0026669810879796,
      "attention_bam_384_attention_center_y": 0.4803689960370547,
      "attention_bam_384_attention_center_x": 0.47817234918432155,
      "attention_bam_384_attention_center_distance": 0.041516807601846326,
      "attention_bam_384_attention_spatial_variance": 169.83037028826223,
      "attention_bam_384_attention_spatial_std": 13.031898184388268,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 15.709390432273542,
      "attention_bam_384_peak_intensity_mean": 0.27702271938323975,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23479336500167847,
      "attention_bam_16_std_attention": 0.6376686692237854,
      "attention_bam_16_max_attention": 2.549048900604248,
      "attention_bam_16_min_attention": -1.0491633415222168,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.3050355837177774,
      "attention_bam_16_attention_skewness": 0.388929624689484,
      "attention_bam_16_attention_sparsity": 0.44091796875,
      "attention_bam_16_attention_concentration_10": 0.6099573032794438,
      "attention_bam_16_attention_concentration_20": 1.0032888832822537,
      "attention_bam_16_attention_center_y": 0.45939444066208807,
      "attention_bam_16_attention_center_x": 0.4505031157131625,
      "attention_bam_16_attention_center_distance": 0.09054007955871554,
      "attention_bam_16_attention_spatial_variance": 41.0253228944342,
      "attention_bam_16_attention_spatial_std": 6.405101318045968,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.509321923966093,
      "attention_bam_16_peak_intensity_mean": 0.37643739581108093,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 52,
      "phase": "train",
      "loss": 0.1911657303571701,
      "timestamp": 1759543888.9060936,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.1911657303571701,
      "ssim": 0.3318321704864502,
      "attention_bam_384_mean_attention": 0.2109827846288681,
      "attention_bam_384_std_attention": 0.5515671968460083,
      "attention_bam_384_max_attention": 4.708316326141357,
      "attention_bam_384_min_attention": -1.63358473777771,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.127975480915782,
      "attention_bam_384_attention_skewness": 0.5842638868644643,
      "attention_bam_384_attention_sparsity": 0.4411366780598958,
      "attention_bam_384_attention_concentration_10": 0.6028478278454034,
      "attention_bam_384_attention_concentration_20": 0.9648249274349581,
      "attention_bam_384_attention_center_y": 0.4795636911494219,
      "attention_bam_384_attention_center_x": 0.48770021830031496,
      "attention_bam_384_attention_center_distance": 0.03373210190000394,
      "attention_bam_384_attention_spatial_variance": 170.10844452215312,
      "attention_bam_384_attention_spatial_std": 13.042562804991706,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 14.467713764645,
      "attention_bam_384_peak_intensity_mean": 0.2959420382976532,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23898504674434662,
      "attention_bam_16_std_attention": 0.6141867637634277,
      "attention_bam_16_max_attention": 2.8625926971435547,
      "attention_bam_16_min_attention": -1.2333275079727173,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.3976137383948024,
      "attention_bam_16_attention_skewness": 0.5558567528795305,
      "attention_bam_16_attention_sparsity": 0.43359375,
      "attention_bam_16_attention_concentration_10": 0.5940827465183606,
      "attention_bam_16_attention_concentration_20": 0.9590198038749106,
      "attention_bam_16_attention_center_y": 0.45907597416897605,
      "attention_bam_16_attention_center_x": 0.4808985996586693,
      "attention_bam_16_attention_center_distance": 0.06386923179776163,
      "attention_bam_16_attention_spatial_variance": 41.89676368156782,
      "attention_bam_16_attention_spatial_std": 6.472770943079001,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.102292807192809,
      "attention_bam_16_peak_intensity_mean": 0.3672121465206146,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 53,
      "phase": "train",
      "loss": 0.17484644055366516,
      "timestamp": 1759543889.0375593,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.17484644055366516,
      "ssim": 0.3378574848175049,
      "attention_bam_384_mean_attention": 0.2175879031419754,
      "attention_bam_384_std_attention": 0.5948794484138489,
      "attention_bam_384_max_attention": 5.534738063812256,
      "attention_bam_384_min_attention": -1.6719194650650024,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.652872923481624,
      "attention_bam_384_attention_skewness": 0.6576921766996981,
      "attention_bam_384_attention_sparsity": 0.44371795654296875,
      "attention_bam_384_attention_concentration_10": 0.6272122194850447,
      "attention_bam_384_attention_concentration_20": 0.9965733642645845,
      "attention_bam_384_attention_center_y": 0.48089116467265935,
      "attention_bam_384_attention_center_x": 0.48005694535051563,
      "attention_bam_384_attention_center_distance": 0.03906079918075773,
      "attention_bam_384_attention_spatial_variance": 171.57673865167703,
      "attention_bam_384_attention_spatial_std": 13.098730421368211,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 16.519796138346923,
      "attention_bam_384_peak_intensity_mean": 0.2632811963558197,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24614375829696655,
      "attention_bam_16_std_attention": 0.6506559252738953,
      "attention_bam_16_max_attention": 2.6810526847839355,
      "attention_bam_16_min_attention": -1.1628999710083008,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.22848471522390001,
      "attention_bam_16_attention_skewness": 0.5294834685478591,
      "attention_bam_16_attention_sparsity": 0.437255859375,
      "attention_bam_16_attention_concentration_10": 0.6168889678787188,
      "attention_bam_16_attention_concentration_20": 0.9871863109394101,
      "attention_bam_16_attention_center_y": 0.461945979955498,
      "attention_bam_16_attention_center_x": 0.45410969974331283,
      "attention_bam_16_attention_center_distance": 0.08430928892116527,
      "attention_bam_16_attention_spatial_variance": 42.62939621288438,
      "attention_bam_16_attention_spatial_std": 6.529119099303089,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 10.699570967526961,
      "attention_bam_16_peak_intensity_mean": 0.3839751183986664,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 54,
      "phase": "train",
      "loss": 0.16401001811027527,
      "timestamp": 1759543889.1686745,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.16401001811027527,
      "ssim": 0.31631478667259216,
      "attention_bam_384_mean_attention": 0.23395782709121704,
      "attention_bam_384_std_attention": 0.5039607882499695,
      "attention_bam_384_max_attention": 6.086740493774414,
      "attention_bam_384_min_attention": -1.6212210655212402,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.0766687422668424,
      "attention_bam_384_attention_skewness": 0.5616832261984743,
      "attention_bam_384_attention_sparsity": 0.41947174072265625,
      "attention_bam_384_attention_concentration_10": 0.504112018165145,
      "attention_bam_384_attention_concentration_20": 0.8257395471590374,
      "attention_bam_384_attention_center_y": 0.4791364060388429,
      "attention_bam_384_attention_center_x": 0.4868435576721526,
      "attention_bam_384_attention_center_distance": 0.034882130889669176,
      "attention_bam_384_attention_spatial_variance": 169.2634755568226,
      "attention_bam_384_attention_spatial_std": 13.010129728669988,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 15.465894495919565,
      "attention_bam_384_peak_intensity_mean": 0.24441561102867126,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.27353519201278687,
      "attention_bam_16_std_attention": 0.4792853593826294,
      "attention_bam_16_max_attention": 1.6352365016937256,
      "attention_bam_16_min_attention": -0.8757575154304504,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.40416626056661187,
      "attention_bam_16_attention_skewness": 0.21304086389064555,
      "attention_bam_16_attention_sparsity": 0.384765625,
      "attention_bam_16_attention_concentration_10": 0.41969438190805974,
      "attention_bam_16_attention_concentration_20": 0.7147328083360643,
      "attention_bam_16_attention_center_y": 0.4519503565213673,
      "attention_bam_16_attention_center_x": 0.48032684416101146,
      "attention_bam_16_attention_center_distance": 0.07342753297079836,
      "attention_bam_16_attention_spatial_variance": 40.3827107328896,
      "attention_bam_16_attention_spatial_std": 6.354739234059066,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 6.148782730323421,
      "attention_bam_16_peak_intensity_mean": 0.496286004781723,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 55,
      "phase": "train",
      "loss": 0.1858994960784912,
      "timestamp": 1759543889.300625,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.1858994960784912,
      "ssim": 0.31313443183898926,
      "attention_bam_384_mean_attention": 0.20454515516757965,
      "attention_bam_384_std_attention": 0.5623360872268677,
      "attention_bam_384_max_attention": 5.570217132568359,
      "attention_bam_384_min_attention": -1.6638240814208984,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.6426724350377961,
      "attention_bam_384_attention_skewness": 0.6752236489242972,
      "attention_bam_384_attention_sparsity": 0.4576873779296875,
      "attention_bam_384_attention_concentration_10": 0.633029806912825,
      "attention_bam_384_attention_concentration_20": 1.008295309562341,
      "attention_bam_384_attention_center_y": 0.47944301495727487,
      "attention_bam_384_attention_center_x": 0.48220184886255374,
      "attention_bam_384_attention_center_distance": 0.03845422780288805,
      "attention_bam_384_attention_spatial_variance": 170.85489298074754,
      "attention_bam_384_attention_spatial_std": 13.071147347526441,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 17.896189509667522,
      "attention_bam_384_peak_intensity_mean": 0.2598431408405304,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22502174973487854,
      "attention_bam_16_std_attention": 0.5784091353416443,
      "attention_bam_16_max_attention": 2.2579104900360107,
      "attention_bam_16_min_attention": -0.9883726835250854,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.1614880399019598,
      "attention_bam_16_attention_skewness": 0.47720182960122653,
      "attention_bam_16_attention_sparsity": 0.4599609375,
      "attention_bam_16_attention_concentration_10": 0.5920221993857476,
      "attention_bam_16_attention_concentration_20": 0.9775325452842145,
      "attention_bam_16_attention_center_y": 0.45880016915858174,
      "attention_bam_16_attention_center_x": 0.4624593813061813,
      "attention_bam_16_attention_center_distance": 0.07882542880665055,
      "attention_bam_16_attention_spatial_variance": 42.06900358790179,
      "attention_bam_16_attention_spatial_std": 6.486062255937865,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.982078222408571,
      "attention_bam_16_peak_intensity_mean": 0.3836973011493683,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 56,
      "phase": "train",
      "loss": 0.19472068548202515,
      "timestamp": 1759543889.4296877,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.19472068548202515,
      "ssim": 0.3355256915092468,
      "attention_bam_384_mean_attention": 0.20474748313426971,
      "attention_bam_384_std_attention": 0.5514143109321594,
      "attention_bam_384_max_attention": 5.652107238769531,
      "attention_bam_384_min_attention": -1.6282145977020264,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5781041221772334,
      "attention_bam_384_attention_skewness": 0.5481704004420285,
      "attention_bam_384_attention_sparsity": 0.44143931070963544,
      "attention_bam_384_attention_concentration_10": 0.6033133701001786,
      "attention_bam_384_attention_concentration_20": 0.9764761319392598,
      "attention_bam_384_attention_center_y": 0.4820507336232506,
      "attention_bam_384_attention_center_x": 0.4903309078354736,
      "attention_bam_384_attention_center_distance": 0.02883288077003791,
      "attention_bam_384_attention_spatial_variance": 171.64253383852682,
      "attention_bam_384_attention_spatial_std": 13.101241690714923,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 16.81544479486104,
      "attention_bam_384_peak_intensity_mean": 0.2522509694099426,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22686001658439636,
      "attention_bam_16_std_attention": 0.5776309370994568,
      "attention_bam_16_max_attention": 2.5307321548461914,
      "attention_bam_16_min_attention": -1.0157206058502197,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.11742333394801063,
      "attention_bam_16_attention_skewness": 0.3350767083932012,
      "attention_bam_16_attention_sparsity": 0.43896484375,
      "attention_bam_16_attention_concentration_10": 0.5694800253060069,
      "attention_bam_16_attention_concentration_20": 0.9422146857314481,
      "attention_bam_16_attention_center_y": 0.4623605270969322,
      "attention_bam_16_attention_center_x": 0.48952103722545515,
      "attention_bam_16_attention_center_distance": 0.05525465738290432,
      "attention_bam_16_attention_spatial_variance": 42.458639761598015,
      "attention_bam_16_attention_spatial_std": 6.516029447569894,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 8.612837140765828,
      "attention_bam_16_peak_intensity_mean": 0.35801127552986145,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 57,
      "phase": "train",
      "loss": 0.1658623218536377,
      "timestamp": 1759543889.5602407,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.1658623218536377,
      "ssim": 0.30894070863723755,
      "attention_bam_384_mean_attention": 0.20077712833881378,
      "attention_bam_384_std_attention": 0.5312519669532776,
      "attention_bam_384_max_attention": 4.970900058746338,
      "attention_bam_384_min_attention": -1.5987014770507812,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2797566999736496,
      "attention_bam_384_attention_skewness": 0.5393340044945065,
      "attention_bam_384_attention_sparsity": 0.4481862386067708,
      "attention_bam_384_attention_concentration_10": 0.5994962715145651,
      "attention_bam_384_attention_concentration_20": 0.970308677184175,
      "attention_bam_384_attention_center_y": 0.4865006821157008,
      "attention_bam_384_attention_center_x": 0.4875777459524826,
      "attention_bam_384_attention_center_distance": 0.02594393875117742,
      "attention_bam_384_attention_spatial_variance": 169.1463825080124,
      "attention_bam_384_attention_spatial_std": 13.005628877836411,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 18.734084003308435,
      "attention_bam_384_peak_intensity_mean": 0.2763108015060425,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23564758896827698,
      "attention_bam_16_std_attention": 0.5902009010314941,
      "attention_bam_16_max_attention": 2.2332983016967773,
      "attention_bam_16_min_attention": -1.0402394533157349,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.26716999627326876,
      "attention_bam_16_attention_skewness": 0.38223889809699557,
      "attention_bam_16_attention_sparsity": 0.44921875,
      "attention_bam_16_attention_concentration_10": 0.5689336097568721,
      "attention_bam_16_attention_concentration_20": 0.9454054820295219,
      "attention_bam_16_attention_center_y": 0.48713415956758865,
      "attention_bam_16_attention_center_x": 0.4833300569840824,
      "attention_bam_16_attention_center_distance": 0.029779753195290627,
      "attention_bam_16_attention_spatial_variance": 40.85366632796779,
      "attention_bam_16_attention_spatial_std": 6.391687283336677,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 6.91432551545319,
      "attention_bam_16_peak_intensity_mean": 0.4088817536830902,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 58,
      "phase": "train",
      "loss": 0.15661858022212982,
      "timestamp": 1759543889.6880462,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.15661858022212982,
      "ssim": 0.33754152059555054,
      "attention_bam_384_mean_attention": 0.20382829010486603,
      "attention_bam_384_std_attention": 0.5030319094657898,
      "attention_bam_384_max_attention": 4.762381553649902,
      "attention_bam_384_min_attention": -1.5881736278533936,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9367608424708096,
      "attention_bam_384_attention_skewness": 0.46972788383129643,
      "attention_bam_384_attention_sparsity": 0.4392140706380208,
      "attention_bam_384_attention_concentration_10": 0.5678074910512134,
      "attention_bam_384_attention_concentration_20": 0.9194860246802299,
      "attention_bam_384_attention_center_y": 0.4813510598570135,
      "attention_bam_384_attention_center_x": 0.48638804088985627,
      "attention_bam_384_attention_center_distance": 0.032651750313663706,
      "attention_bam_384_attention_spatial_variance": 169.63169409282068,
      "attention_bam_384_attention_spatial_std": 13.024273265438678,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 17.724423323795268,
      "attention_bam_384_peak_intensity_mean": 0.28303343057632446,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24619464576244354,
      "attention_bam_16_std_attention": 0.5641090869903564,
      "attention_bam_16_max_attention": 2.074225902557373,
      "attention_bam_16_min_attention": -1.0279585123062134,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.23594817546170654,
      "attention_bam_16_attention_skewness": 0.36868502487163696,
      "attention_bam_16_attention_sparsity": 0.434326171875,
      "attention_bam_16_attention_concentration_10": 0.5337495943952832,
      "attention_bam_16_attention_concentration_20": 0.8823487185936482,
      "attention_bam_16_attention_center_y": 0.4604516279182991,
      "attention_bam_16_attention_center_x": 0.48040637146745746,
      "attention_bam_16_attention_center_distance": 0.06241769001467334,
      "attention_bam_16_attention_spatial_variance": 41.0473038277435,
      "attention_bam_16_attention_spatial_std": 6.406816980977644,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 8.333721114302994,
      "attention_bam_16_peak_intensity_mean": 0.42081424593925476,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 59,
      "phase": "train",
      "loss": 0.1549050658941269,
      "timestamp": 1759543889.8172648,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.1549050658941269,
      "ssim": 0.35179415345191956,
      "attention_bam_384_mean_attention": 0.2145875096321106,
      "attention_bam_384_std_attention": 0.5446670651435852,
      "attention_bam_384_max_attention": 5.145356178283691,
      "attention_bam_384_min_attention": -1.6404484510421753,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.575800354003336,
      "attention_bam_384_attention_skewness": 0.5627826580166607,
      "attention_bam_384_attention_sparsity": 0.44131215413411456,
      "attention_bam_384_attention_concentration_10": 0.5808617214893045,
      "attention_bam_384_attention_concentration_20": 0.9399623704103393,
      "attention_bam_384_attention_center_y": 0.48277953085630215,
      "attention_bam_384_attention_center_x": 0.4804489081159582,
      "attention_bam_384_attention_center_distance": 0.03684534574101036,
      "attention_bam_384_attention_spatial_variance": 169.69928132415924,
      "attention_bam_384_attention_spatial_std": 13.026867671246194,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 16.835845771390712,
      "attention_bam_384_peak_intensity_mean": 0.2748323082923889,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24927473068237305,
      "attention_bam_16_std_attention": 0.550190806388855,
      "attention_bam_16_max_attention": 2.1488146781921387,
      "attention_bam_16_min_attention": -1.1727216243743896,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.2244003686824474,
      "attention_bam_16_attention_skewness": 0.30066948862904463,
      "attention_bam_16_attention_sparsity": 0.41259765625,
      "attention_bam_16_attention_concentration_10": 0.5097199134554978,
      "attention_bam_16_attention_concentration_20": 0.8432352510691812,
      "attention_bam_16_attention_center_y": 0.4672889943401844,
      "attention_bam_16_attention_center_x": 0.46249260398662995,
      "attention_bam_16_attention_center_distance": 0.07038202394049572,
      "attention_bam_16_attention_spatial_variance": 41.33597278469357,
      "attention_bam_16_attention_spatial_std": 6.42930577781875,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.345157838512332,
      "attention_bam_16_peak_intensity_mean": 0.4352724850177765,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 60,
      "phase": "train",
      "loss": 0.15707820653915405,
      "timestamp": 1759543889.9876466,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.15707820653915405,
      "ssim": 0.39389801025390625,
      "attention_bam_384_mean_attention": 0.21094006299972534,
      "attention_bam_384_std_attention": 0.5291146039962769,
      "attention_bam_384_max_attention": 5.080113410949707,
      "attention_bam_384_min_attention": -1.6072943210601807,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5009053050696348,
      "attention_bam_384_attention_skewness": 0.5767443025420907,
      "attention_bam_384_attention_sparsity": 0.4353383382161458,
      "attention_bam_384_attention_concentration_10": 0.5765043311357424,
      "attention_bam_384_attention_concentration_20": 0.9284835839557866,
      "attention_bam_384_attention_center_y": 0.4854841547410833,
      "attention_bam_384_attention_center_x": 0.48262576711756655,
      "attention_bam_384_attention_center_distance": 0.03201792409991147,
      "attention_bam_384_attention_spatial_variance": 170.3235055165059,
      "attention_bam_384_attention_spatial_std": 13.050804784246292,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 18.43200299027942,
      "attention_bam_384_peak_intensity_mean": 0.27449727058410645,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2352849841117859,
      "attention_bam_16_std_attention": 0.5607309341430664,
      "attention_bam_16_max_attention": 2.4928839206695557,
      "attention_bam_16_min_attention": -1.202850580215454,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.09116525357824612,
      "attention_bam_16_attention_skewness": 0.35424330018258227,
      "attention_bam_16_attention_sparsity": 0.42578125,
      "attention_bam_16_attention_concentration_10": 0.5419449808641938,
      "attention_bam_16_attention_concentration_20": 0.8899954324585473,
      "attention_bam_16_attention_center_y": 0.4781047962264992,
      "attention_bam_16_attention_center_x": 0.4680086822511628,
      "attention_bam_16_attention_center_distance": 0.05482416181922325,
      "attention_bam_16_attention_spatial_variance": 41.73192690283798,
      "attention_bam_16_attention_spatial_std": 6.4600253020276925,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.482604641161661,
      "attention_bam_16_peak_intensity_mean": 0.3991970121860504,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 61,
      "phase": "train",
      "loss": 0.11353062093257904,
      "timestamp": 1759543890.1258812,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.11353062093257904,
      "ssim": 0.3071877360343933,
      "attention_bam_384_mean_attention": 0.21604900062084198,
      "attention_bam_384_std_attention": 0.48516008257865906,
      "attention_bam_384_max_attention": 5.109823703765869,
      "attention_bam_384_min_attention": -1.5677331686019897,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.2549916070690808,
      "attention_bam_384_attention_skewness": 0.6774015020869443,
      "attention_bam_384_attention_sparsity": 0.42863210042317706,
      "attention_bam_384_attention_concentration_10": 0.529162454058213,
      "attention_bam_384_attention_concentration_20": 0.8501662022297485,
      "attention_bam_384_attention_center_y": 0.48020224292359476,
      "attention_bam_384_attention_center_x": 0.480088356591782,
      "attention_bam_384_attention_center_distance": 0.03970956379695916,
      "attention_bam_384_attention_spatial_variance": 170.03706015071776,
      "attention_bam_384_attention_spatial_std": 13.039825924862562,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 16.74305869871085,
      "attention_bam_384_peak_intensity_mean": 0.26920032501220703,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2587539255619049,
      "attention_bam_16_std_attention": 0.47801974415779114,
      "attention_bam_16_max_attention": 2.784224033355713,
      "attention_bam_16_min_attention": -0.9836270213127136,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.015967105759804312,
      "attention_bam_16_attention_skewness": 0.3925537810435487,
      "attention_bam_16_attention_sparsity": 0.402099609375,
      "attention_bam_16_attention_concentration_10": 0.44800371235860237,
      "attention_bam_16_attention_concentration_20": 0.7480088607368363,
      "attention_bam_16_attention_center_y": 0.4624268023889731,
      "attention_bam_16_attention_center_x": 0.45872867416126645,
      "attention_bam_16_attention_center_distance": 0.07893120441503719,
      "attention_bam_16_attention_spatial_variance": 41.0147928237676,
      "attention_bam_16_attention_spatial_std": 6.404279258727526,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 7.506588559788867,
      "attention_bam_16_peak_intensity_mean": 0.3456994891166687,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 62,
      "phase": "train",
      "loss": 0.14304064214229584,
      "timestamp": 1759543890.2545388,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.14304064214229584,
      "ssim": 0.3468208312988281,
      "attention_bam_384_mean_attention": 0.2016938477754593,
      "attention_bam_384_std_attention": 0.5412432551383972,
      "attention_bam_384_max_attention": 5.287590980529785,
      "attention_bam_384_min_attention": -1.5843007564544678,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2025621666811697,
      "attention_bam_384_attention_skewness": 0.5315894370838025,
      "attention_bam_384_attention_sparsity": 0.44082387288411456,
      "attention_bam_384_attention_concentration_10": 0.6083244250354646,
      "attention_bam_384_attention_concentration_20": 0.9804558579231325,
      "attention_bam_384_attention_center_y": 0.4874826649655523,
      "attention_bam_384_attention_center_x": 0.4855714817325829,
      "attention_bam_384_attention_center_distance": 0.027013545334065282,
      "attention_bam_384_attention_spatial_variance": 170.74211118938354,
      "attention_bam_384_attention_spatial_std": 13.066832484936183,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 16.53524018982025,
      "attention_bam_384_peak_intensity_mean": 0.261453241109848,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22818008065223694,
      "attention_bam_16_std_attention": 0.5792118310928345,
      "attention_bam_16_max_attention": 2.3040835857391357,
      "attention_bam_16_min_attention": -1.0603572130203247,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.0831107227878185,
      "attention_bam_16_attention_skewness": 0.35217640308758663,
      "attention_bam_16_attention_sparsity": 0.430908203125,
      "attention_bam_16_attention_concentration_10": 0.574521517986584,
      "attention_bam_16_attention_concentration_20": 0.9377560340177337,
      "attention_bam_16_attention_center_y": 0.4813280237444168,
      "attention_bam_16_attention_center_x": 0.47725372238153224,
      "attention_bam_16_attention_center_distance": 0.04161816533163061,
      "attention_bam_16_attention_spatial_variance": 42.10450473219017,
      "attention_bam_16_attention_spatial_std": 6.488798404341914,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.82714501885612,
      "attention_bam_16_peak_intensity_mean": 0.3883568346500397,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 63,
      "phase": "train",
      "loss": 0.11710494011640549,
      "timestamp": 1759543890.3863225,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.11710494011640549,
      "ssim": 0.4097574055194855,
      "attention_bam_384_mean_attention": 0.21411161124706268,
      "attention_bam_384_std_attention": 0.527942419052124,
      "attention_bam_384_max_attention": 4.8740129470825195,
      "attention_bam_384_min_attention": -1.5787067413330078,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2932459892631787,
      "attention_bam_384_attention_skewness": 0.596402510441007,
      "attention_bam_384_attention_sparsity": 0.446380615234375,
      "attention_bam_384_attention_concentration_10": 0.5719136572885549,
      "attention_bam_384_attention_concentration_20": 0.9206157049677887,
      "attention_bam_384_attention_center_y": 0.48271178862647407,
      "attention_bam_384_attention_center_x": 0.4803236882847356,
      "attention_bam_384_attention_center_distance": 0.037041584610055835,
      "attention_bam_384_attention_spatial_variance": 169.12986699844495,
      "attention_bam_384_attention_spatial_std": 13.004993925352098,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 17.058462944832137,
      "attention_bam_384_peak_intensity_mean": 0.2789416015148163,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24821464717388153,
      "attention_bam_16_std_attention": 0.5368967056274414,
      "attention_bam_16_max_attention": 2.3709659576416016,
      "attention_bam_16_min_attention": -1.2028172016143799,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.48542988107439244,
      "attention_bam_16_attention_skewness": 0.5044323353477415,
      "attention_bam_16_attention_sparsity": 0.418212890625,
      "attention_bam_16_attention_concentration_10": 0.5144710132735403,
      "attention_bam_16_attention_concentration_20": 0.8367479612435929,
      "attention_bam_16_attention_center_y": 0.46997086357256324,
      "attention_bam_16_attention_center_x": 0.45919019699818064,
      "attention_bam_16_attention_center_distance": 0.07165457494989295,
      "attention_bam_16_attention_spatial_variance": 40.95330773983202,
      "attention_bam_16_attention_spatial_std": 6.399477145816838,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.549283492541583,
      "attention_bam_16_peak_intensity_mean": 0.4115794599056244,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 64,
      "phase": "train",
      "loss": 0.13942019641399384,
      "timestamp": 1759543890.5154047,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.13942019641399384,
      "ssim": 0.4026842713356018,
      "attention_bam_384_mean_attention": 0.21155627071857452,
      "attention_bam_384_std_attention": 0.539480447769165,
      "attention_bam_384_max_attention": 4.662264823913574,
      "attention_bam_384_min_attention": -1.5923089981079102,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8564679487260727,
      "attention_bam_384_attention_skewness": 0.5738672482601315,
      "attention_bam_384_attention_sparsity": 0.45234934488932294,
      "attention_bam_384_attention_concentration_10": 0.5930010548482868,
      "attention_bam_384_attention_concentration_20": 0.9548455030325743,
      "attention_bam_384_attention_center_y": 0.48570204117706794,
      "attention_bam_384_attention_center_x": 0.4817849452323581,
      "attention_bam_384_attention_center_distance": 0.032748125036113275,
      "attention_bam_384_attention_spatial_variance": 169.7853634791312,
      "attention_bam_384_attention_spatial_std": 13.03017127589393,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 16.485919386302307,
      "attention_bam_384_peak_intensity_mean": 0.29164278507232666,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23896808922290802,
      "attention_bam_16_std_attention": 0.5760939121246338,
      "attention_bam_16_max_attention": 2.4459035396575928,
      "attention_bam_16_min_attention": -0.9887725114822388,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.14350060459090974,
      "attention_bam_16_attention_skewness": 0.5311916489582564,
      "attention_bam_16_attention_sparsity": 0.439697265625,
      "attention_bam_16_attention_concentration_10": 0.5580548506987095,
      "attention_bam_16_attention_concentration_20": 0.9153925667603501,
      "attention_bam_16_attention_center_y": 0.4789242632476081,
      "attention_bam_16_attention_center_x": 0.46334466373241534,
      "attention_bam_16_attention_center_distance": 0.05979632691973361,
      "attention_bam_16_attention_spatial_variance": 41.389870124342345,
      "attention_bam_16_attention_spatial_std": 6.433495948886759,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 9.612143302855765,
      "attention_bam_16_peak_intensity_mean": 0.3646821081638336,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 65,
      "phase": "train",
      "loss": 0.13059592247009277,
      "timestamp": 1759543890.6451635,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.13059592247009277,
      "ssim": 0.37299486994743347,
      "attention_bam_384_mean_attention": 0.20298437774181366,
      "attention_bam_384_std_attention": 0.5240222215652466,
      "attention_bam_384_max_attention": 4.456543922424316,
      "attention_bam_384_min_attention": -1.593395471572876,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.6102564593768216,
      "attention_bam_384_attention_skewness": 0.6313593693658008,
      "attention_bam_384_attention_sparsity": 0.44271087646484375,
      "attention_bam_384_attention_concentration_10": 0.5945609461834566,
      "attention_bam_384_attention_concentration_20": 0.9502197319677942,
      "attention_bam_384_attention_center_y": 0.484470702396529,
      "attention_bam_384_attention_center_x": 0.4819748637396219,
      "attention_bam_384_attention_center_distance": 0.033647128295364745,
      "attention_bam_384_attention_spatial_variance": 170.66992238064168,
      "attention_bam_384_attention_spatial_std": 13.064069901092909,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 17.043694419063247,
      "attention_bam_384_peak_intensity_mean": 0.2978850305080414,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21464410424232483,
      "attention_bam_16_std_attention": 0.5479816198348999,
      "attention_bam_16_max_attention": 2.8313560485839844,
      "attention_bam_16_min_attention": -1.027978539466858,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5857210713935905,
      "attention_bam_16_attention_skewness": 0.49530882446624247,
      "attention_bam_16_attention_sparsity": 0.435302734375,
      "attention_bam_16_attention_concentration_10": 0.5847152026220794,
      "attention_bam_16_attention_concentration_20": 0.9442368167333353,
      "attention_bam_16_attention_center_y": 0.4748814619957356,
      "attention_bam_16_attention_center_x": 0.4715407583990777,
      "attention_bam_16_attention_center_distance": 0.053681829029408816,
      "attention_bam_16_attention_spatial_variance": 42.30567197865459,
      "attention_bam_16_attention_spatial_std": 6.504281050097281,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.006587198845152,
      "attention_bam_16_peak_intensity_mean": 0.3264297842979431,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 66,
      "phase": "train",
      "loss": 0.16074232757091522,
      "timestamp": 1759543890.7750251,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.16074232757091522,
      "ssim": 0.36747193336486816,
      "attention_bam_384_mean_attention": 0.20270727574825287,
      "attention_bam_384_std_attention": 0.5856889486312866,
      "attention_bam_384_max_attention": 5.601900100708008,
      "attention_bam_384_min_attention": -1.6935887336730957,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.7048513015170794,
      "attention_bam_384_attention_skewness": 0.6908221302627051,
      "attention_bam_384_attention_sparsity": 0.45873769124348956,
      "attention_bam_384_attention_concentration_10": 0.660128245854328,
      "attention_bam_384_attention_concentration_20": 1.0498233242907273,
      "attention_bam_384_attention_center_y": 0.4848194807107984,
      "attention_bam_384_attention_center_x": 0.48222693547738094,
      "attention_bam_384_attention_center_distance": 0.03305540767907734,
      "attention_bam_384_attention_spatial_variance": 170.57227451816948,
      "attention_bam_384_attention_spatial_std": 13.06033209831088,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 15.692513284861453,
      "attention_bam_384_peak_intensity_mean": 0.2618721127510071,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2308451384305954,
      "attention_bam_16_std_attention": 0.6210359930992126,
      "attention_bam_16_max_attention": 2.6269419193267822,
      "attention_bam_16_min_attention": -1.1083056926727295,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.1255094246168218,
      "attention_bam_16_attention_skewness": 0.6122489444629965,
      "attention_bam_16_attention_sparsity": 0.4638671875,
      "attention_bam_16_attention_concentration_10": 0.6346600498068823,
      "attention_bam_16_attention_concentration_20": 1.0227887027539764,
      "attention_bam_16_attention_center_y": 0.4726130636719491,
      "attention_bam_16_attention_center_x": 0.46405112769512613,
      "attention_bam_16_attention_center_distance": 0.0639119034519993,
      "attention_bam_16_attention_spatial_variance": 42.071629192042764,
      "attention_bam_16_attention_spatial_std": 6.486264656336709,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 8.571051616165706,
      "attention_bam_16_peak_intensity_mean": 0.3720695674419403,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 67,
      "phase": "train",
      "loss": 0.13932204246520996,
      "timestamp": 1759543890.9065704,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.13932204246520996,
      "ssim": 0.3864298462867737,
      "attention_bam_384_mean_attention": 0.20917899906635284,
      "attention_bam_384_std_attention": 0.559612512588501,
      "attention_bam_384_max_attention": 5.000951290130615,
      "attention_bam_384_min_attention": -1.697650671005249,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.6255334510256567,
      "attention_bam_384_attention_skewness": 0.835185993018009,
      "attention_bam_384_attention_sparsity": 0.44555918375651044,
      "attention_bam_384_attention_concentration_10": 0.6121535583440647,
      "attention_bam_384_attention_concentration_20": 0.9702857738799412,
      "attention_bam_384_attention_center_y": 0.4755026919551683,
      "attention_bam_384_attention_center_x": 0.47946383801473036,
      "attention_bam_384_attention_center_distance": 0.04520734565374546,
      "attention_bam_384_attention_spatial_variance": 172.09134832813083,
      "attention_bam_384_attention_spatial_std": 13.118359208686536,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 18.41138683682925,
      "attention_bam_384_peak_intensity_mean": 0.28912562131881714,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2310781031847,
      "attention_bam_16_std_attention": 0.6188189387321472,
      "attention_bam_16_max_attention": 3.7262158393859863,
      "attention_bam_16_min_attention": -1.1711714267730713,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.6992122828160046,
      "attention_bam_16_attention_skewness": 0.7412975401477824,
      "attention_bam_16_attention_sparsity": 0.434326171875,
      "attention_bam_16_attention_concentration_10": 0.6068812744621657,
      "attention_bam_16_attention_concentration_20": 0.9781698259997048,
      "attention_bam_16_attention_center_y": 0.44570562423575644,
      "attention_bam_16_attention_center_x": 0.45267697229161286,
      "attention_bam_16_attention_center_distance": 0.10185625352542332,
      "attention_bam_16_attention_spatial_variance": 43.03512315666501,
      "attention_bam_16_attention_spatial_std": 6.560116093230745,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 10.136587933476152,
      "attention_bam_16_peak_intensity_mean": 0.3122994303703308,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 68,
      "phase": "train",
      "loss": 0.11577676981687546,
      "timestamp": 1759543891.0366147,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.11577676981687546,
      "ssim": 0.4141920804977417,
      "attention_bam_384_mean_attention": 0.1997838020324707,
      "attention_bam_384_std_attention": 0.5299570560455322,
      "attention_bam_384_max_attention": 5.498289108276367,
      "attention_bam_384_min_attention": -1.6759636402130127,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.0088112863067025,
      "attention_bam_384_attention_skewness": 0.6392695443208471,
      "attention_bam_384_attention_sparsity": 0.44899749755859375,
      "attention_bam_384_attention_concentration_10": 0.6018431003769529,
      "attention_bam_384_attention_concentration_20": 0.9678539434542113,
      "attention_bam_384_attention_center_y": 0.47755092782394554,
      "attention_bam_384_attention_center_x": 0.47984920447889695,
      "attention_bam_384_attention_center_distance": 0.04266181903526874,
      "attention_bam_384_attention_spatial_variance": 172.351689953156,
      "attention_bam_384_attention_spatial_std": 13.128278255474173,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 18.501197434518474,
      "attention_bam_384_peak_intensity_mean": 0.2670666575431824,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20792827010154724,
      "attention_bam_16_std_attention": 0.5274553894996643,
      "attention_bam_16_max_attention": 2.233051300048828,
      "attention_bam_16_min_attention": -1.062178373336792,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.34791420670350615,
      "attention_bam_16_attention_skewness": 0.1669415754166634,
      "attention_bam_16_attention_sparsity": 0.427978515625,
      "attention_bam_16_attention_concentration_10": 0.5477372878923034,
      "attention_bam_16_attention_concentration_20": 0.9224760513671775,
      "attention_bam_16_attention_center_y": 0.4547744200398721,
      "attention_bam_16_attention_center_x": 0.4546847622471538,
      "attention_bam_16_attention_center_distance": 0.09054086210465301,
      "attention_bam_16_attention_spatial_variance": 43.42371548227817,
      "attention_bam_16_attention_spatial_std": 6.5896673271325445,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.921331495463603,
      "attention_bam_16_peak_intensity_mean": 0.4038902223110199,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 69,
      "phase": "train",
      "loss": 0.1375133991241455,
      "timestamp": 1759543891.1674047,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.1375133991241455,
      "ssim": 0.42756301164627075,
      "attention_bam_384_mean_attention": 0.1786058098077774,
      "attention_bam_384_std_attention": 0.5668291449546814,
      "attention_bam_384_max_attention": 5.79689884185791,
      "attention_bam_384_min_attention": -1.6420589685440063,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.550768683399826,
      "attention_bam_384_attention_skewness": 0.8885510407943003,
      "attention_bam_384_attention_sparsity": 0.47380320231119794,
      "attention_bam_384_attention_concentration_10": 0.7322517596868647,
      "attention_bam_384_attention_concentration_20": 1.1302681732347988,
      "attention_bam_384_attention_center_y": 0.48251633231655255,
      "attention_bam_384_attention_center_x": 0.4851617823358305,
      "attention_bam_384_attention_center_distance": 0.03242996574510975,
      "attention_bam_384_attention_spatial_variance": 170.5032675778161,
      "attention_bam_384_attention_spatial_std": 13.05768997862241,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 19.81062922403865,
      "attention_bam_384_peak_intensity_mean": 0.24792508780956268,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22220410406589508,
      "attention_bam_16_std_attention": 0.6424652338027954,
      "attention_bam_16_max_attention": 3.032526731491089,
      "attention_bam_16_min_attention": -1.3568023443222046,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.273852005242511,
      "attention_bam_16_attention_skewness": 0.8770632331185487,
      "attention_bam_16_attention_sparsity": 0.470703125,
      "attention_bam_16_attention_concentration_10": 0.6946685743122128,
      "attention_bam_16_attention_concentration_20": 1.075294471873493,
      "attention_bam_16_attention_center_y": 0.46618229847311,
      "attention_bam_16_attention_center_x": 0.4698612495155987,
      "attention_bam_16_attention_center_distance": 0.06406217631836773,
      "attention_bam_16_attention_spatial_variance": 41.966984159342594,
      "attention_bam_16_attention_spatial_std": 6.478192970214965,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.565958334266007,
      "attention_bam_16_peak_intensity_mean": 0.38007310032844543,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 70,
      "phase": "train",
      "loss": 0.10200232267379761,
      "timestamp": 1759543891.3681507,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.10200232267379761,
      "ssim": 0.4096519947052002,
      "attention_bam_384_mean_attention": 0.1885831207036972,
      "attention_bam_384_std_attention": 0.5088109970092773,
      "attention_bam_384_max_attention": 5.91633415222168,
      "attention_bam_384_min_attention": -1.633140206336975,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.402797495195042,
      "attention_bam_384_attention_skewness": 0.7186125017951274,
      "attention_bam_384_attention_sparsity": 0.44916534423828125,
      "attention_bam_384_attention_concentration_10": 0.6228788439244863,
      "attention_bam_384_attention_concentration_20": 0.9813863671823921,
      "attention_bam_384_attention_center_y": 0.481043897803974,
      "attention_bam_384_attention_center_x": 0.4887081369096616,
      "attention_bam_384_attention_center_distance": 0.031203845356530303,
      "attention_bam_384_attention_spatial_variance": 171.0069618033788,
      "attention_bam_384_attention_spatial_std": 13.076963019117963,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 17.331581877329427,
      "attention_bam_384_peak_intensity_mean": 0.2431548535823822,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23200905323028564,
      "attention_bam_16_std_attention": 0.5449327230453491,
      "attention_bam_16_max_attention": 2.4886536598205566,
      "attention_bam_16_min_attention": -1.1039608716964722,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5828931029294613,
      "attention_bam_16_attention_skewness": 0.5778826965479009,
      "attention_bam_16_attention_sparsity": 0.42724609375,
      "attention_bam_16_attention_concentration_10": 0.568399312923149,
      "attention_bam_16_attention_concentration_20": 0.8970232495192656,
      "attention_bam_16_attention_center_y": 0.466551115955846,
      "attention_bam_16_attention_center_x": 0.48230406314778657,
      "attention_bam_16_attention_center_distance": 0.05351586727087186,
      "attention_bam_16_attention_spatial_variance": 42.326636177858596,
      "attention_bam_16_attention_spatial_std": 6.50589241978828,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.772877907838978,
      "attention_bam_16_peak_intensity_mean": 0.38305968046188354,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 71,
      "phase": "train",
      "loss": 0.13298079371452332,
      "timestamp": 1759543891.5380595,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.13298079371452332,
      "ssim": 0.4155440330505371,
      "attention_bam_384_mean_attention": 0.18453079462051392,
      "attention_bam_384_std_attention": 0.5412961840629578,
      "attention_bam_384_max_attention": 5.912436485290527,
      "attention_bam_384_min_attention": -1.726932406425476,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.0289064528946517,
      "attention_bam_384_attention_skewness": 0.6558294963939312,
      "attention_bam_384_attention_sparsity": 0.4609476725260417,
      "attention_bam_384_attention_concentration_10": 0.6551617137388509,
      "attention_bam_384_attention_concentration_20": 1.0471811277210374,
      "attention_bam_384_attention_center_y": 0.4784451401975904,
      "attention_bam_384_attention_center_x": 0.48520754773239083,
      "attention_bam_384_attention_center_distance": 0.03697103258474206,
      "attention_bam_384_attention_spatial_variance": 170.51858850289995,
      "attention_bam_384_attention_spatial_std": 13.05827662836486,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 16.673435181981375,
      "attention_bam_384_peak_intensity_mean": 0.25036489963531494,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23491977155208588,
      "attention_bam_16_std_attention": 0.6061755418777466,
      "attention_bam_16_max_attention": 2.532808780670166,
      "attention_bam_16_min_attention": -1.1000186204910278,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.03236303670521501,
      "attention_bam_16_attention_skewness": 0.4052351981400986,
      "attention_bam_16_attention_sparsity": 0.434814453125,
      "attention_bam_16_attention_concentration_10": 0.5831183608849125,
      "attention_bam_16_attention_concentration_20": 0.956228462440806,
      "attention_bam_16_attention_center_y": 0.4547926597685565,
      "attention_bam_16_attention_center_x": 0.47832526237585987,
      "attention_bam_16_attention_center_distance": 0.07090130974639053,
      "attention_bam_16_attention_spatial_variance": 41.57433336392701,
      "attention_bam_16_attention_spatial_std": 6.447816170140632,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.2886676043837,
      "attention_bam_16_peak_intensity_mean": 0.37665003538131714,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 72,
      "phase": "train",
      "loss": 0.1431681513786316,
      "timestamp": 1759543891.6770008,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.1431681513786316,
      "ssim": 0.3943381905555725,
      "attention_bam_384_mean_attention": 0.17437994480133057,
      "attention_bam_384_std_attention": 0.5595401525497437,
      "attention_bam_384_max_attention": 5.694760322570801,
      "attention_bam_384_min_attention": -1.6873753070831299,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.6624695391386872,
      "attention_bam_384_attention_skewness": 0.645097321803035,
      "attention_bam_384_attention_sparsity": 0.47427622477213544,
      "attention_bam_384_attention_concentration_10": 0.7116341549282702,
      "attention_bam_384_attention_concentration_20": 1.138657920912054,
      "attention_bam_384_attention_center_y": 0.48425416923597026,
      "attention_bam_384_attention_center_x": 0.4782901023550599,
      "attention_bam_384_attention_center_distance": 0.03792758474259178,
      "attention_bam_384_attention_spatial_variance": 170.27373961031526,
      "attention_bam_384_attention_spatial_std": 13.048898022833777,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 18.335899636185943,
      "attention_bam_384_peak_intensity_mean": 0.2534812390804291,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21599966287612915,
      "attention_bam_16_std_attention": 0.6447221636772156,
      "attention_bam_16_max_attention": 2.663745641708374,
      "attention_bam_16_min_attention": -1.1022684574127197,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.10994355697587554,
      "attention_bam_16_attention_skewness": 0.5170971960458619,
      "attention_bam_16_attention_sparsity": 0.46435546875,
      "attention_bam_16_attention_concentration_10": 0.6814905627134522,
      "attention_bam_16_attention_concentration_20": 1.1009304133878053,
      "attention_bam_16_attention_center_y": 0.47388894330147113,
      "attention_bam_16_attention_center_x": 0.4471035977899022,
      "attention_bam_16_attention_center_distance": 0.08342441667385186,
      "attention_bam_16_attention_spatial_variance": 41.5110304279273,
      "attention_bam_16_attention_spatial_std": 6.442905433725324,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.47675366060541,
      "attention_bam_16_peak_intensity_mean": 0.3609986901283264,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 73,
      "phase": "train",
      "loss": 0.10593005269765854,
      "timestamp": 1759543891.8078556,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.10593005269765854,
      "ssim": 0.41601577401161194,
      "attention_bam_384_mean_attention": 0.19253261387348175,
      "attention_bam_384_std_attention": 0.6290463805198669,
      "attention_bam_384_max_attention": 5.1023454666137695,
      "attention_bam_384_min_attention": -1.7229784727096558,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.697754493427916,
      "attention_bam_384_attention_skewness": 0.8022996696774274,
      "attention_bam_384_attention_sparsity": 0.4758249918619792,
      "attention_bam_384_attention_concentration_10": 0.7379520465643467,
      "attention_bam_384_attention_concentration_20": 1.1592908052888293,
      "attention_bam_384_attention_center_y": 0.4784160597907817,
      "attention_bam_384_attention_center_x": 0.4834462329261702,
      "attention_bam_384_attention_center_distance": 0.03846800434880188,
      "attention_bam_384_attention_spatial_variance": 173.57168946436312,
      "attention_bam_384_attention_spatial_std": 13.174660886123904,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 19.008690067479375,
      "attention_bam_384_peak_intensity_mean": 0.28300562500953674,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2251504361629486,
      "attention_bam_16_std_attention": 0.7343723773956299,
      "attention_bam_16_max_attention": 3.4434776306152344,
      "attention_bam_16_min_attention": -1.140854001045227,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.9341595941211183,
      "attention_bam_16_attention_skewness": 0.8044133099642008,
      "attention_bam_16_attention_sparsity": 0.471435546875,
      "attention_bam_16_attention_concentration_10": 0.7493718889709928,
      "attention_bam_16_attention_concentration_20": 1.172694560197058,
      "attention_bam_16_attention_center_y": 0.44955668315965175,
      "attention_bam_16_attention_center_x": 0.4626751577427786,
      "attention_bam_16_attention_center_distance": 0.08874313565997338,
      "attention_bam_16_attention_spatial_variance": 44.74752906971685,
      "attention_bam_16_attention_spatial_std": 6.689359391579798,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.901304936748181,
      "attention_bam_16_peak_intensity_mean": 0.321146696805954,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 74,
      "phase": "train",
      "loss": 0.11617612838745117,
      "timestamp": 1759543891.9383862,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.11617612838745117,
      "ssim": 0.34339630603790283,
      "attention_bam_384_mean_attention": 0.16831915080547333,
      "attention_bam_384_std_attention": 0.5072980523109436,
      "attention_bam_384_max_attention": 5.418515205383301,
      "attention_bam_384_min_attention": -1.6489791870117188,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.032197185292663,
      "attention_bam_384_attention_skewness": 0.653613222106997,
      "attention_bam_384_attention_sparsity": 0.4703216552734375,
      "attention_bam_384_attention_concentration_10": 0.6710144149162445,
      "attention_bam_384_attention_concentration_20": 1.0729428762312792,
      "attention_bam_384_attention_center_y": 0.486796156901043,
      "attention_bam_384_attention_center_x": 0.48461353860193557,
      "attention_bam_384_attention_center_distance": 0.028673495320103593,
      "attention_bam_384_attention_spatial_variance": 172.94335909295862,
      "attention_bam_384_attention_spatial_std": 13.150793097488783,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 21.302898129549778,
      "attention_bam_384_peak_intensity_mean": 0.2637166678905487,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21337881684303284,
      "attention_bam_16_std_attention": 0.5771364569664001,
      "attention_bam_16_max_attention": 2.5673742294311523,
      "attention_bam_16_min_attention": -1.1021085977554321,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.11638400436848517,
      "attention_bam_16_attention_skewness": 0.5339058339400604,
      "attention_bam_16_attention_sparsity": 0.45166015625,
      "attention_bam_16_attention_concentration_10": 0.6170605204959423,
      "attention_bam_16_attention_concentration_20": 1.0023441979101229,
      "attention_bam_16_attention_center_y": 0.48361540669423586,
      "attention_bam_16_attention_center_x": 0.465311427716153,
      "attention_bam_16_attention_center_distance": 0.05425406795599695,
      "attention_bam_16_attention_spatial_variance": 44.448065428127265,
      "attention_bam_16_attention_spatial_std": 6.6669382349116795,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.900742483544887,
      "attention_bam_16_peak_intensity_mean": 0.39157867431640625,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 75,
      "phase": "train",
      "loss": 0.10228870809078217,
      "timestamp": 1759543892.0684907,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.10228870809078217,
      "ssim": 0.4136846363544464,
      "attention_bam_384_mean_attention": 0.20044982433319092,
      "attention_bam_384_std_attention": 0.5110326409339905,
      "attention_bam_384_max_attention": 5.027342796325684,
      "attention_bam_384_min_attention": -1.5682073831558228,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0985955480469256,
      "attention_bam_384_attention_skewness": 0.46312265234280353,
      "attention_bam_384_attention_sparsity": 0.44041188557942706,
      "attention_bam_384_attention_concentration_10": 0.5775521683580446,
      "attention_bam_384_attention_concentration_20": 0.9359041606822899,
      "attention_bam_384_attention_center_y": 0.4909521004143252,
      "attention_bam_384_attention_center_x": 0.48400612879357385,
      "attention_bam_384_attention_center_distance": 0.025987243142749937,
      "attention_bam_384_attention_spatial_variance": 170.83659656108003,
      "attention_bam_384_attention_spatial_std": 13.070447450683547,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 14.138651087944508,
      "attention_bam_384_peak_intensity_mean": 0.2717214822769165,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2519083619117737,
      "attention_bam_16_std_attention": 0.5653866529464722,
      "attention_bam_16_max_attention": 2.476820230484009,
      "attention_bam_16_min_attention": -1.1862894296646118,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.015950049555982115,
      "attention_bam_16_attention_skewness": 0.2907356689421112,
      "attention_bam_16_attention_sparsity": 0.41259765625,
      "attention_bam_16_attention_concentration_10": 0.5172074009472578,
      "attention_bam_16_attention_concentration_20": 0.8502064798119158,
      "attention_bam_16_attention_center_y": 0.4938104027186415,
      "attention_bam_16_attention_center_x": 0.47329502814119756,
      "attention_bam_16_attention_center_distance": 0.038767683358303225,
      "attention_bam_16_attention_spatial_variance": 42.383388086097526,
      "attention_bam_16_attention_spatial_std": 6.510252536276725,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 6.067357419481231,
      "attention_bam_16_peak_intensity_mean": 0.425223171710968,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 76,
      "phase": "train",
      "loss": 0.09586694836616516,
      "timestamp": 1759543892.1978245,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.09586694836616516,
      "ssim": 0.4727137088775635,
      "attention_bam_384_mean_attention": 0.2049913853406906,
      "attention_bam_384_std_attention": 0.4509098529815674,
      "attention_bam_384_max_attention": 4.674900054931641,
      "attention_bam_384_min_attention": -1.6272480487823486,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.460639876421201,
      "attention_bam_384_attention_skewness": 0.49371327341580945,
      "attention_bam_384_attention_sparsity": 0.40956878662109375,
      "attention_bam_384_attention_concentration_10": 0.5088090161679163,
      "attention_bam_384_attention_concentration_20": 0.8226976083671524,
      "attention_bam_384_attention_center_y": 0.4810328149367796,
      "attention_bam_384_attention_center_x": 0.48360981496803374,
      "attention_bam_384_attention_center_distance": 0.03545115723370799,
      "attention_bam_384_attention_spatial_variance": 170.41531958767757,
      "attention_bam_384_attention_spatial_std": 13.054321873911244,
      "attention_bam_384_num_attention_peaks": 19,
      "attention_bam_384_peak_separation_mean": 17.72625346315736,
      "attention_bam_384_peak_intensity_mean": 0.29347220063209534,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2589622735977173,
      "attention_bam_16_std_attention": 0.44466373324394226,
      "attention_bam_16_max_attention": 2.2191011905670166,
      "attention_bam_16_min_attention": -1.0539392232894897,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.007872129583769372,
      "attention_bam_16_attention_skewness": -0.0024004899527185096,
      "attention_bam_16_attention_sparsity": 0.343017578125,
      "attention_bam_16_attention_concentration_10": 0.4049870576894546,
      "attention_bam_16_attention_concentration_20": 0.6774306701532989,
      "attention_bam_16_attention_center_y": 0.46021017906513634,
      "attention_bam_16_attention_center_x": 0.4679259731006788,
      "attention_bam_16_attention_center_distance": 0.07227687114930882,
      "attention_bam_16_attention_spatial_variance": 42.19878478388444,
      "attention_bam_16_attention_spatial_std": 6.496059173366914,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.704853340593948,
      "attention_bam_16_peak_intensity_mean": 0.41541895270347595,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 77,
      "phase": "train",
      "loss": 0.08364953845739365,
      "timestamp": 1759543892.3293464,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.08364953845739365,
      "ssim": 0.49321597814559937,
      "attention_bam_384_mean_attention": 0.1887327879667282,
      "attention_bam_384_std_attention": 0.5005728602409363,
      "attention_bam_384_max_attention": 5.09230375289917,
      "attention_bam_384_min_attention": -1.5994162559509277,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8145222999580337,
      "attention_bam_384_attention_skewness": 0.6543581222170243,
      "attention_bam_384_attention_sparsity": 0.45232899983723956,
      "attention_bam_384_attention_concentration_10": 0.6061386857378812,
      "attention_bam_384_attention_concentration_20": 0.9684298688566361,
      "attention_bam_384_attention_center_y": 0.4825072737350755,
      "attention_bam_384_attention_center_x": 0.4765909250004129,
      "attention_bam_384_attention_center_distance": 0.04132747910327638,
      "attention_bam_384_attention_spatial_variance": 171.72005474051898,
      "attention_bam_384_attention_spatial_std": 13.104199889368255,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 16.798662473893124,
      "attention_bam_384_peak_intensity_mean": 0.2708131670951843,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2367222011089325,
      "attention_bam_16_std_attention": 0.5758397579193115,
      "attention_bam_16_max_attention": 2.9336817264556885,
      "attention_bam_16_min_attention": -1.046679139137268,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.1628703178244031,
      "attention_bam_16_attention_skewness": 0.4103051102202257,
      "attention_bam_16_attention_sparsity": 0.4345703125,
      "attention_bam_16_attention_concentration_10": 0.5628450881520745,
      "attention_bam_16_attention_concentration_20": 0.9236918706114255,
      "attention_bam_16_attention_center_y": 0.465961423378862,
      "attention_bam_16_attention_center_x": 0.4419615538746422,
      "attention_bam_16_attention_center_distance": 0.0951534122040733,
      "attention_bam_16_attention_spatial_variance": 42.75390369283524,
      "attention_bam_16_attention_spatial_std": 6.5386469313486595,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 7.1428574410284185,
      "attention_bam_16_peak_intensity_mean": 0.34462472796440125,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 78,
      "phase": "train",
      "loss": 0.060246698558330536,
      "timestamp": 1759543892.4562118,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.060246698558330536,
      "ssim": 0.49308881163597107,
      "attention_bam_384_mean_attention": 0.18907113373279572,
      "attention_bam_384_std_attention": 0.5650099515914917,
      "attention_bam_384_max_attention": 5.527416706085205,
      "attention_bam_384_min_attention": -1.6419658660888672,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7391883233352865,
      "attention_bam_384_attention_skewness": 0.46411946562032913,
      "attention_bam_384_attention_sparsity": 0.4557342529296875,
      "attention_bam_384_attention_concentration_10": 0.659541950400184,
      "attention_bam_384_attention_concentration_20": 1.0742419660155034,
      "attention_bam_384_attention_center_y": 0.4838673051987581,
      "attention_bam_384_attention_center_x": 0.4832777642673094,
      "attention_bam_384_attention_center_distance": 0.032860219398223506,
      "attention_bam_384_attention_spatial_variance": 170.92267629665147,
      "attention_bam_384_attention_spatial_std": 13.073739950628186,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 18.96829818741721,
      "attention_bam_384_peak_intensity_mean": 0.25711679458618164,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2186567783355713,
      "attention_bam_16_std_attention": 0.640129566192627,
      "attention_bam_16_max_attention": 2.5969223976135254,
      "attention_bam_16_min_attention": -1.1393948793411255,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.039738856312999005,
      "attention_bam_16_attention_skewness": 0.4124729933599267,
      "attention_bam_16_attention_sparsity": 0.441650390625,
      "attention_bam_16_attention_concentration_10": 0.6560190101909823,
      "attention_bam_16_attention_concentration_20": 1.0666612919989984,
      "attention_bam_16_attention_center_y": 0.47098600769418886,
      "attention_bam_16_attention_center_x": 0.46628167438658635,
      "attention_bam_16_attention_center_distance": 0.06290846098409744,
      "attention_bam_16_attention_spatial_variance": 42.74766928812799,
      "attention_bam_16_attention_spatial_std": 6.538170178890114,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.096532927367917,
      "attention_bam_16_peak_intensity_mean": 0.37218987941741943,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 79,
      "phase": "train",
      "loss": 0.06384425610303879,
      "timestamp": 1759543892.5848343,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.06384425610303879,
      "ssim": 0.4928283095359802,
      "attention_bam_384_mean_attention": 0.18266242742538452,
      "attention_bam_384_std_attention": 0.5235061645507812,
      "attention_bam_384_max_attention": 4.720354080200195,
      "attention_bam_384_min_attention": -1.6281105279922485,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2540538741981022,
      "attention_bam_384_attention_skewness": 0.5030740716871287,
      "attention_bam_384_attention_sparsity": 0.45863596598307294,
      "attention_bam_384_attention_concentration_10": 0.6307776922481156,
      "attention_bam_384_attention_concentration_20": 1.0257699266050404,
      "attention_bam_384_attention_center_y": 0.4882215667446747,
      "attention_bam_384_attention_center_x": 0.48228092950223744,
      "attention_bam_384_attention_center_distance": 0.030089764015519698,
      "attention_bam_384_attention_spatial_variance": 170.63558674961925,
      "attention_bam_384_attention_spatial_std": 13.062755710401204,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 14.790928479448688,
      "attention_bam_384_peak_intensity_mean": 0.2887001931667328,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22964677214622498,
      "attention_bam_16_std_attention": 0.5893468260765076,
      "attention_bam_16_max_attention": 2.292074680328369,
      "attention_bam_16_min_attention": -1.0079749822616577,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.4617728327996513,
      "attention_bam_16_attention_skewness": 0.28655603568265087,
      "attention_bam_16_attention_sparsity": 0.44482421875,
      "attention_bam_16_attention_concentration_10": 0.5701453229101768,
      "attention_bam_16_attention_concentration_20": 0.9551436624398322,
      "attention_bam_16_attention_center_y": 0.48844776808169393,
      "attention_bam_16_attention_center_x": 0.4621694442906268,
      "attention_bam_16_attention_center_distance": 0.05593934228384026,
      "attention_bam_16_attention_spatial_variance": 42.308769355087904,
      "attention_bam_16_attention_spatial_std": 6.504519148644879,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 10.780069586359375,
      "attention_bam_16_peak_intensity_mean": 0.37757301330566406,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 80,
      "phase": "train",
      "loss": 0.08325887471437454,
      "timestamp": 1759543892.758876,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.08325887471437454,
      "ssim": 0.4976925253868103,
      "attention_bam_384_mean_attention": 0.19448083639144897,
      "attention_bam_384_std_attention": 0.5132721662521362,
      "attention_bam_384_max_attention": 4.289984226226807,
      "attention_bam_384_min_attention": -1.6011719703674316,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2612468561347132,
      "attention_bam_384_attention_skewness": 0.6044955157854439,
      "attention_bam_384_attention_sparsity": 0.4544423421223958,
      "attention_bam_384_attention_concentration_10": 0.6080180897234043,
      "attention_bam_384_attention_concentration_20": 0.9718264448193819,
      "attention_bam_384_attention_center_y": 0.4803279036366359,
      "attention_bam_384_attention_center_x": 0.4842815347753927,
      "attention_bam_384_attention_center_distance": 0.03561071536340351,
      "attention_bam_384_attention_spatial_variance": 170.05265957871362,
      "attention_bam_384_attention_spatial_std": 13.040424056705886,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 18.440982706268805,
      "attention_bam_384_peak_intensity_mean": 0.30657708644866943,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24684260785579681,
      "attention_bam_16_std_attention": 0.5892136096954346,
      "attention_bam_16_max_attention": 2.935710906982422,
      "attention_bam_16_min_attention": -1.0426582098007202,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.07463017394895077,
      "attention_bam_16_attention_skewness": 0.4422543765120728,
      "attention_bam_16_attention_sparsity": 0.438232421875,
      "attention_bam_16_attention_concentration_10": 0.5514411517448253,
      "attention_bam_16_attention_concentration_20": 0.9110429875516937,
      "attention_bam_16_attention_center_y": 0.4573505811247969,
      "attention_bam_16_attention_center_x": 0.4698922661922038,
      "attention_bam_16_attention_center_distance": 0.07383019118807219,
      "attention_bam_16_attention_spatial_variance": 41.659941183858,
      "attention_bam_16_attention_spatial_std": 6.4544512689970786,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.956621605910435,
      "attention_bam_16_peak_intensity_mean": 0.33668380975723267,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 81,
      "phase": "train",
      "loss": 0.09463455528020859,
      "timestamp": 1759543892.8959284,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.09463455528020859,
      "ssim": 0.5149726867675781,
      "attention_bam_384_mean_attention": 0.20070761442184448,
      "attention_bam_384_std_attention": 0.4930904805660248,
      "attention_bam_384_max_attention": 5.023857116699219,
      "attention_bam_384_min_attention": -1.6635560989379883,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.3796886916721016,
      "attention_bam_384_attention_skewness": 0.6544589715873053,
      "attention_bam_384_attention_sparsity": 0.43000539143880206,
      "attention_bam_384_attention_concentration_10": 0.5718642301061101,
      "attention_bam_384_attention_concentration_20": 0.9082011434430536,
      "attention_bam_384_attention_center_y": 0.48168429628422416,
      "attention_bam_384_attention_center_x": 0.4791907960917954,
      "attention_bam_384_attention_center_distance": 0.03920428471219245,
      "attention_bam_384_attention_spatial_variance": 170.00462371059177,
      "attention_bam_384_attention_spatial_std": 13.038582120406796,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 16.021856099836253,
      "attention_bam_384_peak_intensity_mean": 0.2807266414165497,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2362278699874878,
      "attention_bam_16_std_attention": 0.5004534721374512,
      "attention_bam_16_max_attention": 2.010982036590576,
      "attention_bam_16_min_attention": -0.9938292503356934,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.1266854475172865,
      "attention_bam_16_attention_skewness": 0.23040417726596832,
      "attention_bam_16_attention_sparsity": 0.38818359375,
      "attention_bam_16_attention_concentration_10": 0.4907467262894857,
      "attention_bam_16_attention_concentration_20": 0.8047099523892888,
      "attention_bam_16_attention_center_y": 0.46614764342749754,
      "attention_bam_16_attention_center_x": 0.45393414277319444,
      "attention_bam_16_attention_center_distance": 0.08084609140276708,
      "attention_bam_16_attention_spatial_variance": 41.48679672933894,
      "attention_bam_16_attention_spatial_std": 6.441024509295003,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 8.27903613693555,
      "attention_bam_16_peak_intensity_mean": 0.41423916816711426,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 82,
      "phase": "train",
      "loss": 0.0779833272099495,
      "timestamp": 1759543893.0267515,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0779833272099495,
      "ssim": 0.48057088255882263,
      "attention_bam_384_mean_attention": 0.1918247789144516,
      "attention_bam_384_std_attention": 0.5491883158683777,
      "attention_bam_384_max_attention": 4.624741077423096,
      "attention_bam_384_min_attention": -1.6354137659072876,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2678475757278687,
      "attention_bam_384_attention_skewness": 0.6434452045677801,
      "attention_bam_384_attention_sparsity": 0.46433258056640625,
      "attention_bam_384_attention_concentration_10": 0.6512200025333535,
      "attention_bam_384_attention_concentration_20": 1.0452528711713351,
      "attention_bam_384_attention_center_y": 0.48299208408116223,
      "attention_bam_384_attention_center_x": 0.48090229218992653,
      "attention_bam_384_attention_center_distance": 0.03616605169219323,
      "attention_bam_384_attention_spatial_variance": 169.47161754210643,
      "attention_bam_384_attention_spatial_std": 13.018126498928577,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 14.876020319700705,
      "attention_bam_384_peak_intensity_mean": 0.29276278614997864,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22748494148254395,
      "attention_bam_16_std_attention": 0.6163967251777649,
      "attention_bam_16_max_attention": 2.5491878986358643,
      "attention_bam_16_min_attention": -0.981217622756958,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.021136614623777472,
      "attention_bam_16_attention_skewness": 0.5781905643461712,
      "attention_bam_16_attention_sparsity": 0.46337890625,
      "attention_bam_16_attention_concentration_10": 0.6303247502135905,
      "attention_bam_16_attention_concentration_20": 1.025063774630273,
      "attention_bam_16_attention_center_y": 0.46696986620431546,
      "attention_bam_16_attention_center_x": 0.4610478706021566,
      "attention_bam_16_attention_center_distance": 0.07222545428292104,
      "attention_bam_16_attention_spatial_variance": 41.11790901645595,
      "attention_bam_16_attention_spatial_std": 6.412324774717509,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 7.447195927169501,
      "attention_bam_16_peak_intensity_mean": 0.3525165915489197,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 83,
      "phase": "train",
      "loss": 0.10675238072872162,
      "timestamp": 1759543893.155548,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.10675238072872162,
      "ssim": 0.40902137756347656,
      "attention_bam_384_mean_attention": 0.1810203343629837,
      "attention_bam_384_std_attention": 0.5185955762863159,
      "attention_bam_384_max_attention": 5.710108757019043,
      "attention_bam_384_min_attention": -1.6255205869674683,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1672606274616442,
      "attention_bam_384_attention_skewness": 0.5468200032681478,
      "attention_bam_384_attention_sparsity": 0.463714599609375,
      "attention_bam_384_attention_concentration_10": 0.637998718479401,
      "attention_bam_384_attention_concentration_20": 1.034040635483002,
      "attention_bam_384_attention_center_y": 0.484901253273808,
      "attention_bam_384_attention_center_x": 0.48433569846082886,
      "attention_bam_384_attention_center_distance": 0.030768246469754262,
      "attention_bam_384_attention_spatial_variance": 169.53140740356056,
      "attention_bam_384_attention_spatial_std": 13.020422704488537,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 18.877473631661363,
      "attention_bam_384_peak_intensity_mean": 0.24764196574687958,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2092425376176834,
      "attention_bam_16_std_attention": 0.5748314261436462,
      "attention_bam_16_max_attention": 2.2136876583099365,
      "attention_bam_16_min_attention": -1.1121151447296143,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.3839861722384148,
      "attention_bam_16_attention_skewness": 0.36300143672158336,
      "attention_bam_16_attention_sparsity": 0.459716796875,
      "attention_bam_16_attention_concentration_10": 0.606622732363009,
      "attention_bam_16_attention_concentration_20": 1.0116787253347965,
      "attention_bam_16_attention_center_y": 0.4689143688386893,
      "attention_bam_16_attention_center_x": 0.4697064227653998,
      "attention_bam_16_attention_center_distance": 0.0613843186223605,
      "attention_bam_16_attention_spatial_variance": 41.511834155002894,
      "attention_bam_16_attention_spatial_std": 6.442967806454018,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.703652162358392,
      "attention_bam_16_peak_intensity_mean": 0.39565494656562805,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 84,
      "phase": "train",
      "loss": 0.09296214580535889,
      "timestamp": 1759543893.2840226,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.09296214580535889,
      "ssim": 0.4591371417045593,
      "attention_bam_384_mean_attention": 0.2097277045249939,
      "attention_bam_384_std_attention": 0.4723827540874481,
      "attention_bam_384_max_attention": 4.880828857421875,
      "attention_bam_384_min_attention": -1.541947841644287,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8002055420796061,
      "attention_bam_384_attention_skewness": 0.5490570511958179,
      "attention_bam_384_attention_sparsity": 0.41172027587890625,
      "attention_bam_384_attention_concentration_10": 0.5352485391874884,
      "attention_bam_384_attention_concentration_20": 0.8512076753743613,
      "attention_bam_384_attention_center_y": 0.4814901343010799,
      "attention_bam_384_attention_center_x": 0.48503093201802594,
      "attention_bam_384_attention_center_distance": 0.03366565384604968,
      "attention_bam_384_attention_spatial_variance": 170.0877208831512,
      "attention_bam_384_attention_spatial_std": 13.041768318872682,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 15.969351368941103,
      "attention_bam_384_peak_intensity_mean": 0.27411824464797974,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.25460657477378845,
      "attention_bam_16_std_attention": 0.46578824520111084,
      "attention_bam_16_max_attention": 1.9584729671478271,
      "attention_bam_16_min_attention": -1.0333985090255737,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.4104617903157015,
      "attention_bam_16_attention_skewness": 0.20449470901644254,
      "attention_bam_16_attention_sparsity": 0.34716796875,
      "attention_bam_16_attention_concentration_10": 0.4444787473098233,
      "attention_bam_16_attention_concentration_20": 0.7121940205094214,
      "attention_bam_16_attention_center_y": 0.4617302451437313,
      "attention_bam_16_attention_center_x": 0.471026707541915,
      "attention_bam_16_attention_center_distance": 0.0678826312486578,
      "attention_bam_16_attention_spatial_variance": 41.57124196219422,
      "attention_bam_16_attention_spatial_std": 6.447576440973323,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 6.911923388049601,
      "attention_bam_16_peak_intensity_mean": 0.4492246210575104,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 85,
      "phase": "train",
      "loss": 0.10111957043409348,
      "timestamp": 1759543893.411089,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.10111957043409348,
      "ssim": 0.4746168255805969,
      "attention_bam_384_mean_attention": 0.18112637102603912,
      "attention_bam_384_std_attention": 0.5508099794387817,
      "attention_bam_384_max_attention": 4.452502727508545,
      "attention_bam_384_min_attention": -1.6099839210510254,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8159977636685847,
      "attention_bam_384_attention_skewness": 0.5492047210069659,
      "attention_bam_384_attention_sparsity": 0.46432749430338544,
      "attention_bam_384_attention_concentration_10": 0.6780088037049683,
      "attention_bam_384_attention_concentration_20": 1.0857151883271556,
      "attention_bam_384_attention_center_y": 0.4884108696271942,
      "attention_bam_384_attention_center_x": 0.48541658060267445,
      "attention_bam_384_attention_center_distance": 0.026343274819816184,
      "attention_bam_384_attention_spatial_variance": 170.016142424925,
      "attention_bam_384_attention_spatial_std": 13.039023829448467,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 13.076116372764108,
      "attention_bam_384_peak_intensity_mean": 0.298215389251709,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22505784034729004,
      "attention_bam_16_std_attention": 0.675399124622345,
      "attention_bam_16_max_attention": 2.884866237640381,
      "attention_bam_16_min_attention": -1.3552292585372925,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.24440224104583264,
      "attention_bam_16_attention_skewness": 0.6060306727983286,
      "attention_bam_16_attention_sparsity": 0.4658203125,
      "attention_bam_16_attention_concentration_10": 0.6906287044622902,
      "attention_bam_16_attention_concentration_20": 1.0992154336765438,
      "attention_bam_16_attention_center_y": 0.4843107347394633,
      "attention_bam_16_attention_center_x": 0.4732631064643782,
      "attention_bam_16_attention_center_distance": 0.0438409516400057,
      "attention_bam_16_attention_spatial_variance": 42.23519194613883,
      "attention_bam_16_attention_spatial_std": 6.498860819108133,
      "attention_bam_16_num_attention_peaks": 2,
      "attention_bam_16_peak_separation_mean": 10.67359150218686,
      "attention_bam_16_peak_intensity_mean": 0.3833422064781189,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 86,
      "phase": "train",
      "loss": 0.08100821822881699,
      "timestamp": 1759543893.5439758,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.08100821822881699,
      "ssim": 0.49844276905059814,
      "attention_bam_384_mean_attention": 0.1987227350473404,
      "attention_bam_384_std_attention": 0.5286148190498352,
      "attention_bam_384_max_attention": 5.313092231750488,
      "attention_bam_384_min_attention": -1.578941822052002,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1780533836683267,
      "attention_bam_384_attention_skewness": 0.540165744771926,
      "attention_bam_384_attention_sparsity": 0.44416554768880206,
      "attention_bam_384_attention_concentration_10": 0.6070108376857831,
      "attention_bam_384_attention_concentration_20": 0.9776564647841195,
      "attention_bam_384_attention_center_y": 0.4833604861913687,
      "attention_bam_384_attention_center_x": 0.4805280194343193,
      "attention_bam_384_attention_center_distance": 0.03622240872548042,
      "attention_bam_384_attention_spatial_variance": 171.4186887822949,
      "attention_bam_384_attention_spatial_std": 13.092696008931656,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 17.149456733508806,
      "attention_bam_384_peak_intensity_mean": 0.25983038544654846,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2254011332988739,
      "attention_bam_16_std_attention": 0.5914055109024048,
      "attention_bam_16_max_attention": 2.2609457969665527,
      "attention_bam_16_min_attention": -1.1631311178207397,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.10440851251754024,
      "attention_bam_16_attention_skewness": 0.28338236480303003,
      "attention_bam_16_attention_sparsity": 0.428955078125,
      "attention_bam_16_attention_concentration_10": 0.5875210079470085,
      "attention_bam_16_attention_concentration_20": 0.9642225844038133,
      "attention_bam_16_attention_center_y": 0.4679821389493054,
      "attention_bam_16_attention_center_x": 0.4602864138938068,
      "attention_bam_16_attention_center_distance": 0.07214308487548349,
      "attention_bam_16_attention_spatial_variance": 42.89828152123903,
      "attention_bam_16_attention_spatial_std": 6.549677970804292,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.266626333327965,
      "attention_bam_16_peak_intensity_mean": 0.41235747933387756,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 87,
      "phase": "train",
      "loss": 0.05698442459106445,
      "timestamp": 1759543893.6832342,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.05698442459106445,
      "ssim": 0.5218861699104309,
      "attention_bam_384_mean_attention": 0.1938149780035019,
      "attention_bam_384_std_attention": 0.5615091323852539,
      "attention_bam_384_max_attention": 5.84591007232666,
      "attention_bam_384_min_attention": -1.5966639518737793,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8499046198037776,
      "attention_bam_384_attention_skewness": 0.6733144630902748,
      "attention_bam_384_attention_sparsity": 0.443817138671875,
      "attention_bam_384_attention_concentration_10": 0.6578271900220428,
      "attention_bam_384_attention_concentration_20": 1.0348211235087996,
      "attention_bam_384_attention_center_y": 0.4790166027229624,
      "attention_bam_384_attention_center_x": 0.4849154863607543,
      "attention_bam_384_attention_center_distance": 0.03654710694483427,
      "attention_bam_384_attention_spatial_variance": 169.56562377088093,
      "attention_bam_384_attention_spatial_std": 13.021736588139115,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 16.706629631609687,
      "attention_bam_384_peak_intensity_mean": 0.2419014722108841,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22490042448043823,
      "attention_bam_16_std_attention": 0.622229278087616,
      "attention_bam_16_max_attention": 3.367877960205078,
      "attention_bam_16_min_attention": -1.1587200164794922,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6711529821035804,
      "attention_bam_16_attention_skewness": 0.4823639694369112,
      "attention_bam_16_attention_sparsity": 0.419189453125,
      "attention_bam_16_attention_concentration_10": 0.6270938112723631,
      "attention_bam_16_attention_concentration_20": 0.9964365818534507,
      "attention_bam_16_attention_center_y": 0.4533528594790052,
      "attention_bam_16_attention_center_x": 0.47488396932462423,
      "attention_bam_16_attention_center_distance": 0.07492357059926935,
      "attention_bam_16_attention_spatial_variance": 41.43930431418879,
      "attention_bam_16_attention_spatial_std": 6.437336740779434,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.066440015816887,
      "attention_bam_16_peak_intensity_mean": 0.3122766613960266,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 88,
      "phase": "train",
      "loss": 0.06989113986492157,
      "timestamp": 1759543893.8119287,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.06989113986492157,
      "ssim": 0.5508337616920471,
      "attention_bam_384_mean_attention": 0.19070939719676971,
      "attention_bam_384_std_attention": 0.5458773374557495,
      "attention_bam_384_max_attention": 5.02385950088501,
      "attention_bam_384_min_attention": -1.5774145126342773,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7246186076568764,
      "attention_bam_384_attention_skewness": 0.4626945938364674,
      "attention_bam_384_attention_sparsity": 0.45542653401692706,
      "attention_bam_384_attention_concentration_10": 0.6378345003988224,
      "attention_bam_384_attention_concentration_20": 1.0341858152306045,
      "attention_bam_384_attention_center_y": 0.4888400351060427,
      "attention_bam_384_attention_center_x": 0.48031775989852904,
      "attention_bam_384_attention_center_distance": 0.03199798093149977,
      "attention_bam_384_attention_spatial_variance": 170.79852773302932,
      "attention_bam_384_attention_spatial_std": 13.06899107555856,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 17.09632432635136,
      "attention_bam_384_peak_intensity_mean": 0.26988065242767334,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2307218313217163,
      "attention_bam_16_std_attention": 0.6092807054519653,
      "attention_bam_16_max_attention": 2.6415340900421143,
      "attention_bam_16_min_attention": -1.1162047386169434,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.45328581015247504,
      "attention_bam_16_attention_skewness": 0.23212934325211115,
      "attention_bam_16_attention_sparsity": 0.432861328125,
      "attention_bam_16_attention_concentration_10": 0.5725438338090787,
      "attention_bam_16_attention_concentration_20": 0.960505777760725,
      "attention_bam_16_attention_center_y": 0.48374963034340046,
      "attention_bam_16_attention_center_x": 0.4583316581593204,
      "attention_bam_16_attention_center_distance": 0.06325069526460336,
      "attention_bam_16_attention_spatial_variance": 42.33185965471846,
      "attention_bam_16_attention_spatial_std": 6.506293849398324,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.714460443360412,
      "attention_bam_16_peak_intensity_mean": 0.3690241873264313,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 89,
      "phase": "train",
      "loss": 0.04552658647298813,
      "timestamp": 1759543893.9403017,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.04552658647298813,
      "ssim": 0.5432523488998413,
      "attention_bam_384_mean_attention": 0.185505673289299,
      "attention_bam_384_std_attention": 0.5994012355804443,
      "attention_bam_384_max_attention": 5.244689464569092,
      "attention_bam_384_min_attention": -1.52577543258667,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8563355580355818,
      "attention_bam_384_attention_skewness": 0.8939709179805483,
      "attention_bam_384_attention_sparsity": 0.4834391276041667,
      "attention_bam_384_attention_concentration_10": 0.73965679483959,
      "attention_bam_384_attention_concentration_20": 1.1524962604983466,
      "attention_bam_384_attention_center_y": 0.48506810193959227,
      "attention_bam_384_attention_center_x": 0.4814137642531219,
      "attention_bam_384_attention_center_distance": 0.03371675366712929,
      "attention_bam_384_attention_spatial_variance": 167.7767104802668,
      "attention_bam_384_attention_spatial_std": 12.952864952598972,
      "attention_bam_384_num_attention_peaks": 3,
      "attention_bam_384_peak_separation_mean": 20.603727489878196,
      "attention_bam_384_peak_intensity_mean": 0.2554689943790436,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21689221262931824,
      "attention_bam_16_std_attention": 0.7376825213432312,
      "attention_bam_16_max_attention": 3.573336124420166,
      "attention_bam_16_min_attention": -1.221166729927063,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.5604038433374514,
      "attention_bam_16_attention_skewness": 1.0490949516972563,
      "attention_bam_16_attention_sparsity": 0.490966796875,
      "attention_bam_16_attention_concentration_10": 0.8076213691194588,
      "attention_bam_16_attention_concentration_20": 1.2337929797688592,
      "attention_bam_16_attention_center_y": 0.47131759708145576,
      "attention_bam_16_attention_center_x": 0.4621610366308909,
      "attention_bam_16_attention_center_distance": 0.06714860216014171,
      "attention_bam_16_attention_spatial_variance": 40.055511059999354,
      "attention_bam_16_attention_spatial_std": 6.328942333439242,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 10.454402603310248,
      "attention_bam_16_peak_intensity_mean": 0.30826666951179504,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 90,
      "phase": "train",
      "loss": 0.06336280703544617,
      "timestamp": 1759543894.1082695,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.06336280703544617,
      "ssim": 0.520622968673706,
      "attention_bam_384_mean_attention": 0.18826361000537872,
      "attention_bam_384_std_attention": 0.5208513140678406,
      "attention_bam_384_max_attention": 5.285727500915527,
      "attention_bam_384_min_attention": -1.5079671144485474,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2302630151451934,
      "attention_bam_384_attention_skewness": 0.5511290651872318,
      "attention_bam_384_attention_sparsity": 0.45332082112630206,
      "attention_bam_384_attention_concentration_10": 0.6309910340411773,
      "attention_bam_384_attention_concentration_20": 1.0104745674634317,
      "attention_bam_384_attention_center_y": 0.4850974772689807,
      "attention_bam_384_attention_center_x": 0.48645019408774576,
      "attention_bam_384_attention_center_distance": 0.028484466784839284,
      "attention_bam_384_attention_spatial_variance": 170.03227522243878,
      "attention_bam_384_attention_spatial_std": 13.039642449946195,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 16.618626392677175,
      "attention_bam_384_peak_intensity_mean": 0.25064727663993835,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2179812788963318,
      "attention_bam_16_std_attention": 0.5715456008911133,
      "attention_bam_16_max_attention": 2.433363199234009,
      "attention_bam_16_min_attention": -1.0605459213256836,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.14158057477609542,
      "attention_bam_16_attention_skewness": 0.48717701279123576,
      "attention_bam_16_attention_sparsity": 0.44580078125,
      "attention_bam_16_attention_concentration_10": 0.6092572459291166,
      "attention_bam_16_attention_concentration_20": 0.9881813389062604,
      "attention_bam_16_attention_center_y": 0.4760516723351316,
      "attention_bam_16_attention_center_x": 0.47911379933809217,
      "attention_bam_16_attention_center_distance": 0.04493897586802304,
      "attention_bam_16_attention_spatial_variance": 41.79016037409244,
      "attention_bam_16_attention_spatial_std": 6.464530947724857,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.585729187407773,
      "attention_bam_16_peak_intensity_mean": 0.37316185235977173,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 91,
      "phase": "train",
      "loss": 0.08710753172636032,
      "timestamp": 1759543894.236427,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.08710753172636032,
      "ssim": 0.501352071762085,
      "attention_bam_384_mean_attention": 0.19819127023220062,
      "attention_bam_384_std_attention": 0.5461499094963074,
      "attention_bam_384_max_attention": 4.700160026550293,
      "attention_bam_384_min_attention": -1.5380427837371826,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.389205773403627,
      "attention_bam_384_attention_skewness": 0.7000641948452275,
      "attention_bam_384_attention_sparsity": 0.45965830485026044,
      "attention_bam_384_attention_concentration_10": 0.6432923824893341,
      "attention_bam_384_attention_concentration_20": 1.0157990346748411,
      "attention_bam_384_attention_center_y": 0.4892241994476647,
      "attention_bam_384_attention_center_x": 0.48511236295468246,
      "attention_bam_384_attention_center_distance": 0.025990752753116658,
      "attention_bam_384_attention_spatial_variance": 171.30460406872862,
      "attention_bam_384_attention_spatial_std": 13.088338476243981,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 17.26121961109617,
      "attention_bam_384_peak_intensity_mean": 0.28235694766044617,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2337483912706375,
      "attention_bam_16_std_attention": 0.6012226939201355,
      "attention_bam_16_max_attention": 3.0991415977478027,
      "attention_bam_16_min_attention": -1.1236199140548706,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.31553485970512263,
      "attention_bam_16_attention_skewness": 0.5407557936773546,
      "attention_bam_16_attention_sparsity": 0.4443359375,
      "attention_bam_16_attention_concentration_10": 0.599827151709127,
      "attention_bam_16_attention_concentration_20": 0.966203360070293,
      "attention_bam_16_attention_center_y": 0.485451532852787,
      "attention_bam_16_attention_center_x": 0.47233716525255287,
      "attention_bam_16_attention_center_distance": 0.044201590980373164,
      "attention_bam_16_attention_spatial_variance": 42.792419364076885,
      "attention_bam_16_attention_spatial_std": 6.541591500856415,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.648285204264583,
      "attention_bam_16_peak_intensity_mean": 0.33525317907333374,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 92,
      "phase": "train",
      "loss": 0.053917743265628815,
      "timestamp": 1759543894.3646472,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.053917743265628815,
      "ssim": 0.5272382497787476,
      "attention_bam_384_mean_attention": 0.19981642067432404,
      "attention_bam_384_std_attention": 0.5206329822540283,
      "attention_bam_384_max_attention": 4.344592571258545,
      "attention_bam_384_min_attention": -1.4740962982177734,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7270693938851611,
      "attention_bam_384_attention_skewness": 0.5171267784812194,
      "attention_bam_384_attention_sparsity": 0.45008595784505206,
      "attention_bam_384_attention_concentration_10": 0.5971722436608637,
      "attention_bam_384_attention_concentration_20": 0.96793436272309,
      "attention_bam_384_attention_center_y": 0.4808429332826123,
      "attention_bam_384_attention_center_x": 0.48382117434619526,
      "attention_bam_384_attention_center_distance": 0.03546117890738135,
      "attention_bam_384_attention_spatial_variance": 170.38151290964814,
      "attention_bam_384_attention_spatial_std": 13.05302696349196,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 16.51704790385862,
      "attention_bam_384_peak_intensity_mean": 0.29000839591026306,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.23829466104507446,
      "attention_bam_16_std_attention": 0.5540207624435425,
      "attention_bam_16_max_attention": 2.362051248550415,
      "attention_bam_16_min_attention": -1.1470146179199219,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.10319527819428975,
      "attention_bam_16_attention_skewness": 0.34341525256973277,
      "attention_bam_16_attention_sparsity": 0.4248046875,
      "attention_bam_16_attention_concentration_10": 0.531584666124775,
      "attention_bam_16_attention_concentration_20": 0.8818528430061222,
      "attention_bam_16_attention_center_y": 0.4639118971567538,
      "attention_bam_16_attention_center_x": 0.47148897525716543,
      "attention_bam_16_attention_center_distance": 0.06504198180731026,
      "attention_bam_16_attention_spatial_variance": 41.83970999679665,
      "attention_bam_16_attention_spatial_std": 6.46836223450702,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.32345756619776,
      "attention_bam_16_peak_intensity_mean": 0.3977319300174713,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 93,
      "phase": "train",
      "loss": 0.04614986479282379,
      "timestamp": 1759543894.4946685,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.04614986479282379,
      "ssim": 0.6140308976173401,
      "attention_bam_384_mean_attention": 0.20472872257232666,
      "attention_bam_384_std_attention": 0.5215386748313904,
      "attention_bam_384_max_attention": 4.644651889801025,
      "attention_bam_384_min_attention": -1.4527274370193481,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8310762360395203,
      "attention_bam_384_attention_skewness": 0.5915288407047299,
      "attention_bam_384_attention_sparsity": 0.4532877604166667,
      "attention_bam_384_attention_concentration_10": 0.5905694632956622,
      "attention_bam_384_attention_concentration_20": 0.9533871864012541,
      "attention_bam_384_attention_center_y": 0.48274308203701616,
      "attention_bam_384_attention_center_x": 0.4739270384573591,
      "attention_bam_384_attention_center_distance": 0.044217655776514986,
      "attention_bam_384_attention_spatial_variance": 168.38407449396234,
      "attention_bam_384_attention_spatial_std": 12.976288933819344,
      "attention_bam_384_num_attention_peaks": 4,
      "attention_bam_384_peak_separation_mean": 13.140418798268934,
      "attention_bam_384_peak_intensity_mean": 0.27378201484680176,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24346205592155457,
      "attention_bam_16_std_attention": 0.5767073631286621,
      "attention_bam_16_max_attention": 2.493480682373047,
      "attention_bam_16_min_attention": -1.062589406967163,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.0678912044390998,
      "attention_bam_16_attention_skewness": 0.4457590210072839,
      "attention_bam_16_attention_sparsity": 0.43994140625,
      "attention_bam_16_attention_concentration_10": 0.5456624374993557,
      "attention_bam_16_attention_concentration_20": 0.894742418218643,
      "attention_bam_16_attention_center_y": 0.4691259369791295,
      "attention_bam_16_attention_center_x": 0.44641344287296725,
      "attention_bam_16_attention_center_distance": 0.08746115563089052,
      "attention_bam_16_attention_spatial_variance": 40.271786917029594,
      "attention_bam_16_attention_spatial_std": 6.346005587535327,
      "attention_bam_16_num_attention_peaks": 2,
      "attention_bam_16_peak_separation_mean": 4.233323162097244,
      "attention_bam_16_peak_intensity_mean": 0.3823208808898926,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 94,
      "phase": "train",
      "loss": 0.05720360204577446,
      "timestamp": 1759543894.6262105,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.05720360204577446,
      "ssim": 0.5562981963157654,
      "attention_bam_384_mean_attention": 0.19766074419021606,
      "attention_bam_384_std_attention": 0.5704951286315918,
      "attention_bam_384_max_attention": 5.292250633239746,
      "attention_bam_384_min_attention": -1.5687477588653564,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0381794575729417,
      "attention_bam_384_attention_skewness": 0.6518020947172193,
      "attention_bam_384_attention_sparsity": 0.46315765380859375,
      "attention_bam_384_attention_concentration_10": 0.663915221763479,
      "attention_bam_384_attention_concentration_20": 1.058574525779444,
      "attention_bam_384_attention_center_y": 0.4794872142889754,
      "attention_bam_384_attention_center_x": 0.4882043918033233,
      "attention_bam_384_attention_center_distance": 0.033463734111898555,
      "attention_bam_384_attention_spatial_variance": 169.43772589719023,
      "attention_bam_384_attention_spatial_std": 13.01682472407116,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 14.435656619025476,
      "attention_bam_384_peak_intensity_mean": 0.2583702802658081,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22208955883979797,
      "attention_bam_16_std_attention": 0.6176315546035767,
      "attention_bam_16_max_attention": 2.4934144020080566,
      "attention_bam_16_min_attention": -1.0302672386169434,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.02686769435705383,
      "attention_bam_16_attention_skewness": 0.49920420958415895,
      "attention_bam_16_attention_sparsity": 0.4453125,
      "attention_bam_16_attention_concentration_10": 0.634337432087571,
      "attention_bam_16_attention_concentration_20": 1.0249757483996815,
      "attention_bam_16_attention_center_y": 0.4577557379499103,
      "attention_bam_16_attention_center_x": 0.48648071540126586,
      "attention_bam_16_attention_center_distance": 0.06272716687717081,
      "attention_bam_16_attention_spatial_variance": 41.37588107918374,
      "attention_bam_16_attention_spatial_std": 6.43240865299957,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 8.899215317091132,
      "attention_bam_16_peak_intensity_mean": 0.3668612539768219,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 95,
      "phase": "train",
      "loss": 0.04292255640029907,
      "timestamp": 1759543894.753903,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.04292255640029907,
      "ssim": 0.4471227824687958,
      "attention_bam_384_mean_attention": 0.2152259796857834,
      "attention_bam_384_std_attention": 0.4033755362033844,
      "attention_bam_384_max_attention": 5.035792827606201,
      "attention_bam_384_min_attention": -1.5089378356933594,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.6381226374450524,
      "attention_bam_384_attention_skewness": 0.7931450219629571,
      "attention_bam_384_attention_sparsity": 0.39102935791015625,
      "attention_bam_384_attention_concentration_10": 0.4702837100852991,
      "attention_bam_384_attention_concentration_20": 0.7411019232731788,
      "attention_bam_384_attention_center_y": 0.48373099216478466,
      "attention_bam_384_attention_center_x": 0.4875765092416759,
      "attention_bam_384_attention_center_distance": 0.028949049675748004,
      "attention_bam_384_attention_spatial_variance": 169.61696175880456,
      "attention_bam_384_attention_spatial_std": 13.023707680948792,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 14.906508861936492,
      "attention_bam_384_peak_intensity_mean": 0.26440849900245667,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.26178687810897827,
      "attention_bam_16_std_attention": 0.37161460518836975,
      "attention_bam_16_max_attention": 2.643282413482666,
      "attention_bam_16_min_attention": -0.9439424276351929,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.691459654380509,
      "attention_bam_16_attention_skewness": 0.5851429931387492,
      "attention_bam_16_attention_sparsity": 0.3466796875,
      "attention_bam_16_attention_concentration_10": 0.37843486704617757,
      "attention_bam_16_attention_concentration_20": 0.6148158436027822,
      "attention_bam_16_attention_center_y": 0.4719914877635676,
      "attention_bam_16_attention_center_x": 0.4807320696508491,
      "attention_bam_16_attention_center_distance": 0.048077643403938074,
      "attention_bam_16_attention_spatial_variance": 41.491169801600975,
      "attention_bam_16_attention_spatial_std": 6.441363970588914,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 5.457889266112063,
      "attention_bam_16_peak_intensity_mean": 0.3454344868659973,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 96,
      "phase": "train",
      "loss": 0.04527075216174126,
      "timestamp": 1759543894.8820972,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.04527075216174126,
      "ssim": 0.5658904314041138,
      "attention_bam_384_mean_attention": 0.202057883143425,
      "attention_bam_384_std_attention": 0.5238495469093323,
      "attention_bam_384_max_attention": 4.857700347900391,
      "attention_bam_384_min_attention": -1.585749626159668,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.235151931190086,
      "attention_bam_384_attention_skewness": 0.6233325727209018,
      "attention_bam_384_attention_sparsity": 0.45453135172526044,
      "attention_bam_384_attention_concentration_10": 0.6029743047771757,
      "attention_bam_384_attention_concentration_20": 0.9682962654717517,
      "attention_bam_384_attention_center_y": 0.47790456635609657,
      "attention_bam_384_attention_center_x": 0.4811982755764121,
      "attention_bam_384_attention_center_distance": 0.04102957541122456,
      "attention_bam_384_attention_spatial_variance": 171.05675867804598,
      "attention_bam_384_attention_spatial_std": 13.07886687286196,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 16.286076609931076,
      "attention_bam_384_peak_intensity_mean": 0.28031373023986816,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24006369709968567,
      "attention_bam_16_std_attention": 0.5717806220054626,
      "attention_bam_16_max_attention": 2.2304506301879883,
      "attention_bam_16_min_attention": -1.0005919933319092,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.31786259866469946,
      "attention_bam_16_attention_skewness": 0.32337634920569913,
      "attention_bam_16_attention_sparsity": 0.432373046875,
      "attention_bam_16_attention_concentration_10": 0.5418008811891367,
      "attention_bam_16_attention_concentration_20": 0.9028881464194419,
      "attention_bam_16_attention_center_y": 0.4508944821510073,
      "attention_bam_16_attention_center_x": 0.4597411923777582,
      "attention_bam_16_attention_center_distance": 0.08980115226858078,
      "attention_bam_16_attention_spatial_variance": 42.219593444327955,
      "attention_bam_16_attention_spatial_std": 6.4976606131997965,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 7.892674790898096,
      "attention_bam_16_peak_intensity_mean": 0.40128204226493835,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 97,
      "phase": "train",
      "loss": 0.0482923686504364,
      "timestamp": 1759543895.010589,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0482923686504364,
      "ssim": 0.5717211961746216,
      "attention_bam_384_mean_attention": 0.2046075016260147,
      "attention_bam_384_std_attention": 0.4853082001209259,
      "attention_bam_384_max_attention": 4.994378089904785,
      "attention_bam_384_min_attention": -1.5139350891113281,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.6492075797432504,
      "attention_bam_384_attention_skewness": 0.5812250474763444,
      "attention_bam_384_attention_sparsity": 0.4324849446614583,
      "attention_bam_384_attention_concentration_10": 0.5562017289761543,
      "attention_bam_384_attention_concentration_20": 0.8940403659539317,
      "attention_bam_384_attention_center_y": 0.48284896613316314,
      "attention_bam_384_attention_center_x": 0.48450403376035134,
      "attention_bam_384_attention_center_distance": 0.03268892572115872,
      "attention_bam_384_attention_spatial_variance": 170.42894207585627,
      "attention_bam_384_attention_spatial_std": 13.054843625101615,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 17.50309862075634,
      "attention_bam_384_peak_intensity_mean": 0.2656165659427643,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.24332723021507263,
      "attention_bam_16_std_attention": 0.48471179604530334,
      "attention_bam_16_max_attention": 2.1905550956726074,
      "attention_bam_16_min_attention": -0.9031440019607544,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.048386751353392654,
      "attention_bam_16_attention_skewness": 0.28021733039206,
      "attention_bam_16_attention_sparsity": 0.395263671875,
      "attention_bam_16_attention_concentration_10": 0.4672357807771576,
      "attention_bam_16_attention_concentration_20": 0.7698001287660339,
      "attention_bam_16_attention_center_y": 0.46574337058793525,
      "attention_bam_16_attention_center_x": 0.4747755674977644,
      "attention_bam_16_attention_center_distance": 0.060162923029643094,
      "attention_bam_16_attention_spatial_variance": 41.953696880188915,
      "attention_bam_16_attention_spatial_std": 6.477167350021838,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.481776212491969,
      "attention_bam_16_peak_intensity_mean": 0.381286084651947,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 98,
      "phase": "train",
      "loss": 0.049247682094573975,
      "timestamp": 1759543895.141603,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.049247682094573975,
      "ssim": 0.5240183472633362,
      "attention_bam_384_mean_attention": 0.19770844280719757,
      "attention_bam_384_std_attention": 0.5408373475074768,
      "attention_bam_384_max_attention": 4.816963195800781,
      "attention_bam_384_min_attention": -1.5159029960632324,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0035590167465642,
      "attention_bam_384_attention_skewness": 0.6668340328612868,
      "attention_bam_384_attention_sparsity": 0.46226755777994794,
      "attention_bam_384_attention_concentration_10": 0.6334304660278282,
      "attention_bam_384_attention_concentration_20": 1.0126254749273946,
      "attention_bam_384_attention_center_y": 0.4856074611241307,
      "attention_bam_384_attention_center_x": 0.48508162103248115,
      "attention_bam_384_attention_center_distance": 0.029315634269512822,
      "attention_bam_384_attention_spatial_variance": 170.01359902114297,
      "attention_bam_384_attention_spatial_std": 13.038926298631454,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 16.480264780367786,
      "attention_bam_384_peak_intensity_mean": 0.2754080593585968,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22817859053611755,
      "attention_bam_16_std_attention": 0.6352635025978088,
      "attention_bam_16_max_attention": 2.8091797828674316,
      "attention_bam_16_min_attention": -1.1285350322723389,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.14715108216411643,
      "attention_bam_16_attention_skewness": 0.5670695639357156,
      "attention_bam_16_attention_sparsity": 0.453369140625,
      "attention_bam_16_attention_concentration_10": 0.6444950716344481,
      "attention_bam_16_attention_concentration_20": 1.03992730005393,
      "attention_bam_16_attention_center_y": 0.47649938412795495,
      "attention_bam_16_attention_center_x": 0.47509347272014474,
      "attention_bam_16_attention_center_distance": 0.0484275551211826,
      "attention_bam_16_attention_spatial_variance": 41.910513240886864,
      "attention_bam_16_attention_spatial_std": 6.473832963622622,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.409359280072232,
      "attention_bam_16_peak_intensity_mean": 0.35592490434646606,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 99,
      "phase": "train",
      "loss": 0.04676174744963646,
      "timestamp": 1759543895.26985,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.04676174744963646,
      "ssim": 0.5311862826347351,
      "attention_bam_384_mean_attention": 0.18921451270580292,
      "attention_bam_384_std_attention": 0.5192182660102844,
      "attention_bam_384_max_attention": 4.673749923706055,
      "attention_bam_384_min_attention": -1.489107370376587,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2240279559629244,
      "attention_bam_384_attention_skewness": 0.5998436956191098,
      "attention_bam_384_attention_sparsity": 0.4550577799479167,
      "attention_bam_384_attention_concentration_10": 0.6245453604239124,
      "attention_bam_384_attention_concentration_20": 1.0013978086575848,
      "attention_bam_384_attention_center_y": 0.4840180646394935,
      "attention_bam_384_attention_center_x": 0.4866847624965803,
      "attention_bam_384_attention_center_distance": 0.02941828708949188,
      "attention_bam_384_attention_spatial_variance": 168.82727176242105,
      "attention_bam_384_attention_spatial_std": 12.993354907891227,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 16.663025683096002,
      "attention_bam_384_peak_intensity_mean": 0.2739536464214325,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22107011079788208,
      "attention_bam_16_std_attention": 0.5919705629348755,
      "attention_bam_16_max_attention": 2.9546499252319336,
      "attention_bam_16_min_attention": -1.1306917667388916,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.757652167125253,
      "attention_bam_16_attention_skewness": 0.6318310398442819,
      "attention_bam_16_attention_sparsity": 0.44677734375,
      "attention_bam_16_attention_concentration_10": 0.6177989889768252,
      "attention_bam_16_attention_concentration_20": 0.991782560024378,
      "attention_bam_16_attention_center_y": 0.47203747096907334,
      "attention_bam_16_attention_center_x": 0.47970416302561025,
      "attention_bam_16_attention_center_distance": 0.0488635657376009,
      "attention_bam_16_attention_spatial_variance": 40.87317100066558,
      "attention_bam_16_attention_spatial_std": 6.3932128856049815,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.843195594818651,
      "attention_bam_16_peak_intensity_mean": 0.336359441280365,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 100,
      "phase": "train",
      "loss": 0.04336698353290558,
      "timestamp": 1759543895.645121,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.04336698353290558,
      "ssim": 0.5929754972457886,
      "attention_bam_384_mean_attention": 0.1902947872877121,
      "attention_bam_384_std_attention": 0.5476369261741638,
      "attention_bam_384_max_attention": 4.7972259521484375,
      "attention_bam_384_min_attention": -1.6384613513946533,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7837278214734011,
      "attention_bam_384_attention_skewness": 0.5046946992049592,
      "attention_bam_384_attention_sparsity": 0.45286814371744794,
      "attention_bam_384_attention_concentration_10": 0.6389820784413185,
      "attention_bam_384_attention_concentration_20": 1.0330790313064704,
      "attention_bam_384_attention_center_y": 0.4810554522538573,
      "attention_bam_384_attention_center_x": 0.4830312318869551,
      "attention_bam_384_attention_center_distance": 0.03596762379085302,
      "attention_bam_384_attention_spatial_variance": 170.87901011331732,
      "attention_bam_384_attention_spatial_std": 13.07206984808899,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 18.060838785571864,
      "attention_bam_384_peak_intensity_mean": 0.2844005823135376,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21897898614406586,
      "attention_bam_16_std_attention": 0.61314457654953,
      "attention_bam_16_max_attention": 2.3962109088897705,
      "attention_bam_16_min_attention": -1.0099741220474243,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.19995886710754984,
      "attention_bam_16_attention_skewness": 0.3849270835801891,
      "attention_bam_16_attention_sparsity": 0.438720703125,
      "attention_bam_16_attention_concentration_10": 0.6238774487048242,
      "attention_bam_16_attention_concentration_20": 1.0151204819942798,
      "attention_bam_16_attention_center_y": 0.4609671468595275,
      "attention_bam_16_attention_center_x": 0.46808192687262484,
      "attention_bam_16_attention_center_distance": 0.07130676007855302,
      "attention_bam_16_attention_spatial_variance": 42.363408404328716,
      "attention_bam_16_attention_spatial_std": 6.508717877149747,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.534965282616854,
      "attention_bam_16_peak_intensity_mean": 0.36926040053367615,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 101,
      "phase": "train",
      "loss": 0.042137689888477325,
      "timestamp": 1759543897.9028838,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.042137689888477325,
      "ssim": 0.5923938155174255,
      "attention_bam_384_mean_attention": 0.18481862545013428,
      "attention_bam_384_std_attention": 0.5254484415054321,
      "attention_bam_384_max_attention": 4.687544345855713,
      "attention_bam_384_min_attention": -1.5943883657455444,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.428054387586708,
      "attention_bam_384_attention_skewness": 0.6692068022990094,
      "attention_bam_384_attention_sparsity": 0.4607594807942708,
      "attention_bam_384_attention_concentration_10": 0.6459690400984854,
      "attention_bam_384_attention_concentration_20": 1.0300564617542813,
      "attention_bam_384_attention_center_y": 0.482491946618982,
      "attention_bam_384_attention_center_x": 0.481252765378526,
      "attention_bam_384_attention_center_distance": 0.03627645900980881,
      "attention_bam_384_attention_spatial_variance": 170.02710576047656,
      "attention_bam_384_attention_spatial_std": 13.039444227438398,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 17.777384966295184,
      "attention_bam_384_peak_intensity_mean": 0.28449249267578125,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2261243462562561,
      "attention_bam_16_std_attention": 0.6062214374542236,
      "attention_bam_16_max_attention": 2.7912487983703613,
      "attention_bam_16_min_attention": -1.1270520687103271,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5727499555533919,
      "attention_bam_16_attention_skewness": 0.5802636773414834,
      "attention_bam_16_attention_sparsity": 0.435791015625,
      "attention_bam_16_attention_concentration_10": 0.6171072217116588,
      "attention_bam_16_attention_concentration_20": 0.9927074544069182,
      "attention_bam_16_attention_center_y": 0.46905543270062894,
      "attention_bam_16_attention_center_x": 0.4616136430057036,
      "attention_bam_16_attention_center_distance": 0.06972917106403706,
      "attention_bam_16_attention_spatial_variance": 41.89832133583619,
      "attention_bam_16_attention_spatial_std": 6.472891265565658,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 7.739757261379198,
      "attention_bam_16_peak_intensity_mean": 0.3498072624206543,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 102,
      "phase": "train",
      "loss": 0.04071524366736412,
      "timestamp": 1759543898.0383797,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.04071524366736412,
      "ssim": 0.6253974437713623,
      "attention_bam_384_mean_attention": 0.18805915117263794,
      "attention_bam_384_std_attention": 0.5306676030158997,
      "attention_bam_384_max_attention": 7.007475852966309,
      "attention_bam_384_min_attention": -1.5912740230560303,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.5055865813824267,
      "attention_bam_384_attention_skewness": 0.6750921950683332,
      "attention_bam_384_attention_sparsity": 0.46517181396484375,
      "attention_bam_384_attention_concentration_10": 0.6229335764099014,
      "attention_bam_384_attention_concentration_20": 1.0170960813079886,
      "attention_bam_384_attention_center_y": 0.4829349917533819,
      "attention_bam_384_attention_center_x": 0.4875451379417736,
      "attention_bam_384_attention_center_distance": 0.02987768717108441,
      "attention_bam_384_attention_spatial_variance": 171.3667528888628,
      "attention_bam_384_attention_spatial_std": 13.090712466816418,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 17.40550002640533,
      "attention_bam_384_peak_intensity_mean": 0.2087377905845642,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22032994031906128,
      "attention_bam_16_std_attention": 0.5878260135650635,
      "attention_bam_16_max_attention": 2.3355112075805664,
      "attention_bam_16_min_attention": -1.1926541328430176,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.5592412723956599,
      "attention_bam_16_attention_skewness": 0.25733393282113315,
      "attention_bam_16_attention_sparsity": 0.45263671875,
      "attention_bam_16_attention_concentration_10": 0.577418089912155,
      "attention_bam_16_attention_concentration_20": 0.9774722083319819,
      "attention_bam_16_attention_center_y": 0.46679930008039155,
      "attention_bam_16_attention_center_x": 0.48467108240199025,
      "attention_bam_16_attention_center_distance": 0.05171580396510261,
      "attention_bam_16_attention_spatial_variance": 42.542207666564174,
      "attention_bam_16_attention_spatial_std": 6.522438782124687,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.950889401516797,
      "attention_bam_16_peak_intensity_mean": 0.41080835461616516,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 103,
      "phase": "train",
      "loss": 0.04832009598612785,
      "timestamp": 1759543898.1685774,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.04832009598612785,
      "ssim": 0.6086645126342773,
      "attention_bam_384_mean_attention": 0.17682047188282013,
      "attention_bam_384_std_attention": 0.5830510854721069,
      "attention_bam_384_max_attention": 4.641313552856445,
      "attention_bam_384_min_attention": -1.672898769378662,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.02324160700329,
      "attention_bam_384_attention_skewness": 0.737579741255548,
      "attention_bam_384_attention_sparsity": 0.49156443277994794,
      "attention_bam_384_attention_concentration_10": 0.7572254396961674,
      "attention_bam_384_attention_concentration_20": 1.193146686628293,
      "attention_bam_384_attention_center_y": 0.48217345654320193,
      "attention_bam_384_attention_center_x": 0.4905181587151206,
      "attention_bam_384_attention_center_distance": 0.028554893302856283,
      "attention_bam_384_attention_spatial_variance": 169.29171268324774,
      "attention_bam_384_attention_spatial_std": 13.011214881141873,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 15.004692244205273,
      "attention_bam_384_peak_intensity_mean": 0.29287979006767273,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20385265350341797,
      "attention_bam_16_std_attention": 0.7017507553100586,
      "attention_bam_16_max_attention": 3.4124410152435303,
      "attention_bam_16_min_attention": -1.211066722869873,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.2515447391194434,
      "attention_bam_16_attention_skewness": 0.7816075947104634,
      "attention_bam_16_attention_sparsity": 0.510009765625,
      "attention_bam_16_attention_concentration_10": 0.8015077132602659,
      "attention_bam_16_attention_concentration_20": 1.2813501438409383,
      "attention_bam_16_attention_center_y": 0.4631263048208851,
      "attention_bam_16_attention_center_x": 0.4914502715910652,
      "attention_bam_16_attention_center_distance": 0.05353068749845879,
      "attention_bam_16_attention_spatial_variance": 41.072466975072295,
      "attention_bam_16_attention_spatial_std": 6.408780459266201,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 7.353218451538588,
      "attention_bam_16_peak_intensity_mean": 0.3065744936466217,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 104,
      "phase": "train",
      "loss": 0.03118988871574402,
      "timestamp": 1759543898.2997985,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.03118988871574402,
      "ssim": 0.5589684247970581,
      "attention_bam_384_mean_attention": 0.19625715911388397,
      "attention_bam_384_std_attention": 0.5272821187973022,
      "attention_bam_384_max_attention": 5.172338962554932,
      "attention_bam_384_min_attention": -1.6112682819366455,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.192599067721762,
      "attention_bam_384_attention_skewness": 0.5747814891239115,
      "attention_bam_384_attention_sparsity": 0.44959259033203125,
      "attention_bam_384_attention_concentration_10": 0.6144722293480055,
      "attention_bam_384_attention_concentration_20": 0.9865417365106812,
      "attention_bam_384_attention_center_y": 0.4815250716069528,
      "attention_bam_384_attention_center_x": 0.48838446108726985,
      "attention_bam_384_attention_center_distance": 0.03086239534972521,
      "attention_bam_384_attention_spatial_variance": 170.71637959962288,
      "attention_bam_384_attention_spatial_std": 13.065847833172667,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 16.509371436068335,
      "attention_bam_384_peak_intensity_mean": 0.2683217525482178,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22609898447990417,
      "attention_bam_16_std_attention": 0.5816664099693298,
      "attention_bam_16_max_attention": 2.4431943893432617,
      "attention_bam_16_min_attention": -1.0662821531295776,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.034597532517965934,
      "attention_bam_16_attention_skewness": 0.4071678982179355,
      "attention_bam_16_attention_sparsity": 0.4287109375,
      "attention_bam_16_attention_concentration_10": 0.5878158173869779,
      "attention_bam_16_attention_concentration_20": 0.9559993293355534,
      "attention_bam_16_attention_center_y": 0.4644474549640731,
      "attention_bam_16_attention_center_x": 0.48497677812113493,
      "attention_bam_16_attention_center_distance": 0.05458352597905749,
      "attention_bam_16_attention_spatial_variance": 42.22240563215081,
      "attention_bam_16_attention_spatial_std": 6.497877009620204,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.795471641190709,
      "attention_bam_16_peak_intensity_mean": 0.37607240676879883,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 105,
      "phase": "train",
      "loss": 0.030194725841283798,
      "timestamp": 1759543898.441331,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.030194725841283798,
      "ssim": 0.6471701860427856,
      "attention_bam_384_mean_attention": 0.18788059055805206,
      "attention_bam_384_std_attention": 0.47218576073646545,
      "attention_bam_384_max_attention": 5.612591743469238,
      "attention_bam_384_min_attention": -1.6101996898651123,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.2128643630757807,
      "attention_bam_384_attention_skewness": 0.7075720933699515,
      "attention_bam_384_attention_sparsity": 0.44592030843098956,
      "attention_bam_384_attention_concentration_10": 0.5788050133560404,
      "attention_bam_384_attention_concentration_20": 0.9281371016692306,
      "attention_bam_384_attention_center_y": 0.4805070860848429,
      "attention_bam_384_attention_center_x": 0.4874496796991423,
      "attention_bam_384_attention_center_distance": 0.03278671171550591,
      "attention_bam_384_attention_spatial_variance": 170.01105582269898,
      "attention_bam_384_attention_spatial_std": 13.038828774959006,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 14.863124996732797,
      "attention_bam_384_peak_intensity_mean": 0.25082096457481384,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21776805818080902,
      "attention_bam_16_std_attention": 0.5022638440132141,
      "attention_bam_16_max_attention": 2.019083261489868,
      "attention_bam_16_min_attention": -1.0403791666030884,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.16017613871961034,
      "attention_bam_16_attention_skewness": 0.27517106054745677,
      "attention_bam_16_attention_sparsity": 0.430419921875,
      "attention_bam_16_attention_concentration_10": 0.5220884638799091,
      "attention_bam_16_attention_concentration_20": 0.8701323174873694,
      "attention_bam_16_attention_center_y": 0.4604273580547424,
      "attention_bam_16_attention_center_x": 0.4788035110690251,
      "attention_bam_16_attention_center_distance": 0.06348677237863812,
      "attention_bam_16_attention_spatial_variance": 41.066884732360755,
      "attention_bam_16_attention_spatial_std": 6.408344929259095,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 7.397320541269685,
      "attention_bam_16_peak_intensity_mean": 0.4210311770439148,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 106,
      "phase": "train",
      "loss": 0.03803764283657074,
      "timestamp": 1759543898.5769444,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.03803764283657074,
      "ssim": 0.6048275828361511,
      "attention_bam_384_mean_attention": 0.1808294802904129,
      "attention_bam_384_std_attention": 0.5614739656448364,
      "attention_bam_384_max_attention": 5.975358009338379,
      "attention_bam_384_min_attention": -1.661684274673462,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2578545951957185,
      "attention_bam_384_attention_skewness": 0.5619541050087131,
      "attention_bam_384_attention_sparsity": 0.4672088623046875,
      "attention_bam_384_attention_concentration_10": 0.6832259950780487,
      "attention_bam_384_attention_concentration_20": 1.1066054778546819,
      "attention_bam_384_attention_center_y": 0.4879926903117905,
      "attention_bam_384_attention_center_x": 0.48440773235927737,
      "attention_bam_384_attention_center_distance": 0.027831431732072146,
      "attention_bam_384_attention_spatial_variance": 170.33771884250964,
      "attention_bam_384_attention_spatial_std": 13.051349311182719,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 18.604448481381297,
      "attention_bam_384_peak_intensity_mean": 0.2418280988931656,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21611115336418152,
      "attention_bam_16_std_attention": 0.6412731409072876,
      "attention_bam_16_max_attention": 2.9168975353240967,
      "attention_bam_16_min_attention": -1.4211018085479736,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.032061590331307066,
      "attention_bam_16_attention_skewness": 0.45392024751601523,
      "attention_bam_16_attention_sparsity": 0.459228515625,
      "attention_bam_16_attention_concentration_10": 0.6507521836482214,
      "attention_bam_16_attention_concentration_20": 1.068957994396519,
      "attention_bam_16_attention_center_y": 0.4826537477440539,
      "attention_bam_16_attention_center_x": 0.4712618281193586,
      "attention_bam_16_attention_center_distance": 0.04747157023668387,
      "attention_bam_16_attention_spatial_variance": 41.94902805391731,
      "attention_bam_16_attention_spatial_std": 6.476806933506457,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 7.2145001772712325,
      "attention_bam_16_peak_intensity_mean": 0.39287349581718445,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 107,
      "phase": "train",
      "loss": 0.04333024471998215,
      "timestamp": 1759543898.7102606,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.04333024471998215,
      "ssim": 0.5530779361724854,
      "attention_bam_384_mean_attention": 0.17300468683242798,
      "attention_bam_384_std_attention": 0.5584560632705688,
      "attention_bam_384_max_attention": 5.879068374633789,
      "attention_bam_384_min_attention": -1.6110005378723145,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.10125595127532,
      "attention_bam_384_attention_skewness": 0.6149725003638039,
      "attention_bam_384_attention_sparsity": 0.48348236083984375,
      "attention_bam_384_attention_concentration_10": 0.719293558244515,
      "attention_bam_384_attention_concentration_20": 1.156023391490332,
      "attention_bam_384_attention_center_y": 0.4851504427853562,
      "attention_bam_384_attention_center_x": 0.48469901261087694,
      "attention_bam_384_attention_center_distance": 0.030153923942103554,
      "attention_bam_384_attention_spatial_variance": 169.4998728249634,
      "attention_bam_384_attention_spatial_std": 13.019211682162764,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 17.637361476855837,
      "attention_bam_384_peak_intensity_mean": 0.24010854959487915,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20333747565746307,
      "attention_bam_16_std_attention": 0.6685174703598022,
      "attention_bam_16_max_attention": 2.7977190017700195,
      "attention_bam_16_min_attention": -1.1095569133758545,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.23232947908007962,
      "attention_bam_16_attention_skewness": 0.7005672035962055,
      "attention_bam_16_attention_sparsity": 0.4912109375,
      "attention_bam_16_attention_concentration_10": 0.7557243293369122,
      "attention_bam_16_attention_concentration_20": 1.214053433630353,
      "attention_bam_16_attention_center_y": 0.47567307427308503,
      "attention_bam_16_attention_center_x": 0.4716219213113799,
      "attention_bam_16_attention_center_distance": 0.05286047039859465,
      "attention_bam_16_attention_spatial_variance": 41.14094403559613,
      "attention_bam_16_attention_spatial_std": 6.414120675166326,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 9.82226401629656,
      "attention_bam_16_peak_intensity_mean": 0.3429315984249115,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 108,
      "phase": "train",
      "loss": 0.03159930929541588,
      "timestamp": 1759543898.8451967,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.03159930929541588,
      "ssim": 0.6009725332260132,
      "attention_bam_384_mean_attention": 0.17810086905956268,
      "attention_bam_384_std_attention": 0.5434595346450806,
      "attention_bam_384_max_attention": 7.411942481994629,
      "attention_bam_384_min_attention": -1.676159143447876,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.564308597676755,
      "attention_bam_384_attention_skewness": 0.7789452007904826,
      "attention_bam_384_attention_sparsity": 0.46874745686848956,
      "attention_bam_384_attention_concentration_10": 0.6800468758191421,
      "attention_bam_384_attention_concentration_20": 1.0790496769895304,
      "attention_bam_384_attention_center_y": 0.4770149299637895,
      "attention_bam_384_attention_center_x": 0.48509581506979793,
      "attention_bam_384_attention_center_distance": 0.03874140351105424,
      "attention_bam_384_attention_spatial_variance": 172.45276451850478,
      "attention_bam_384_attention_spatial_std": 13.132127189397185,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 18.542201056352994,
      "attention_bam_384_peak_intensity_mean": 0.20472685992717743,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20853668451309204,
      "attention_bam_16_std_attention": 0.6328861713409424,
      "attention_bam_16_max_attention": 3.170994997024536,
      "attention_bam_16_min_attention": -1.0107682943344116,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6302142724424287,
      "attention_bam_16_attention_skewness": 0.6009857320174731,
      "attention_bam_16_attention_sparsity": 0.4560546875,
      "attention_bam_16_attention_concentration_10": 0.6672383609098528,
      "attention_bam_16_attention_concentration_20": 1.0796590270734057,
      "attention_bam_16_attention_center_y": 0.44664276836270134,
      "attention_bam_16_attention_center_x": 0.4711174463296172,
      "attention_bam_16_attention_center_distance": 0.08580438304094828,
      "attention_bam_16_attention_spatial_variance": 43.813550113958435,
      "attention_bam_16_attention_spatial_std": 6.619180471475183,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.13687007171536,
      "attention_bam_16_peak_intensity_mean": 0.28999611735343933,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 109,
      "phase": "train",
      "loss": 0.03276991471648216,
      "timestamp": 1759543898.9747727,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.03276991471648216,
      "ssim": 0.5930843353271484,
      "attention_bam_384_mean_attention": 0.19009090960025787,
      "attention_bam_384_std_attention": 0.49448174238204956,
      "attention_bam_384_max_attention": 5.146444320678711,
      "attention_bam_384_min_attention": -1.5702722072601318,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4240616503773253,
      "attention_bam_384_attention_skewness": 0.5098328018644469,
      "attention_bam_384_attention_sparsity": 0.444610595703125,
      "attention_bam_384_attention_concentration_10": 0.5899670230398949,
      "attention_bam_384_attention_concentration_20": 0.9536305332512486,
      "attention_bam_384_attention_center_y": 0.48620546395230035,
      "attention_bam_384_attention_center_x": 0.48699758649257013,
      "attention_bam_384_attention_center_distance": 0.026808654639480872,
      "attention_bam_384_attention_spatial_variance": 171.11578377741577,
      "attention_bam_384_attention_spatial_std": 13.081123184857475,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 17.80364091282905,
      "attention_bam_384_peak_intensity_mean": 0.26267266273498535,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22796989977359772,
      "attention_bam_16_std_attention": 0.5362153649330139,
      "attention_bam_16_max_attention": 2.032930374145508,
      "attention_bam_16_min_attention": -1.0602259635925293,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.2570828336331936,
      "attention_bam_16_attention_skewness": 0.2877856979315247,
      "attention_bam_16_attention_sparsity": 0.424072265625,
      "attention_bam_16_attention_concentration_10": 0.5398398214285912,
      "attention_bam_16_attention_concentration_20": 0.8876438094628832,
      "attention_bam_16_attention_center_y": 0.47841570657193977,
      "attention_bam_16_attention_center_x": 0.480108065329374,
      "attention_bam_16_attention_center_distance": 0.04151074048313416,
      "attention_bam_16_attention_spatial_variance": 42.68853921790083,
      "attention_bam_16_attention_spatial_std": 6.533646701337687,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.467630513654372,
      "attention_bam_16_peak_intensity_mean": 0.42748764157295227,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 110,
      "phase": "train",
      "loss": 0.031081557273864746,
      "timestamp": 1759543899.1468012,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.031081557273864746,
      "ssim": 0.6572989821434021,
      "attention_bam_384_mean_attention": 0.18384207785129547,
      "attention_bam_384_std_attention": 0.5571780204772949,
      "attention_bam_384_max_attention": 4.672264575958252,
      "attention_bam_384_min_attention": -1.5875005722045898,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6164219331085863,
      "attention_bam_384_attention_skewness": 0.5147923157685382,
      "attention_bam_384_attention_sparsity": 0.4648691813151042,
      "attention_bam_384_attention_concentration_10": 0.6689379476551465,
      "attention_bam_384_attention_concentration_20": 1.0861924279224593,
      "attention_bam_384_attention_center_y": 0.4806787529949179,
      "attention_bam_384_attention_center_x": 0.4850571761338793,
      "attention_bam_384_attention_center_distance": 0.03454268579382039,
      "attention_bam_384_attention_spatial_variance": 167.96533838705773,
      "attention_bam_384_attention_spatial_std": 12.96014422709322,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 16.050145355248095,
      "attention_bam_384_peak_intensity_mean": 0.2852725386619568,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22316396236419678,
      "attention_bam_16_std_attention": 0.6560134887695312,
      "attention_bam_16_max_attention": 3.2337381839752197,
      "attention_bam_16_min_attention": -1.298189640045166,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.374944855952406,
      "attention_bam_16_attention_skewness": 0.570412409240366,
      "attention_bam_16_attention_sparsity": 0.45263671875,
      "attention_bam_16_attention_concentration_10": 0.6655383713372719,
      "attention_bam_16_attention_concentration_20": 1.071057632457761,
      "attention_bam_16_attention_center_y": 0.46065650443025213,
      "attention_bam_16_attention_center_x": 0.47566983543245644,
      "attention_bam_16_attention_center_distance": 0.06541968436992832,
      "attention_bam_16_attention_spatial_variance": 39.73843997103557,
      "attention_bam_16_attention_spatial_std": 6.303843269866056,
      "attention_bam_16_num_attention_peaks": 2,
      "attention_bam_16_peak_separation_mean": 6.212414002948457,
      "attention_bam_16_peak_intensity_mean": 0.35980314016342163,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 111,
      "phase": "train",
      "loss": 0.03889867663383484,
      "timestamp": 1759543899.2765076,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.03889867663383484,
      "ssim": 0.6287326812744141,
      "attention_bam_384_mean_attention": 0.17825675010681152,
      "attention_bam_384_std_attention": 0.4976932108402252,
      "attention_bam_384_max_attention": 4.299455642700195,
      "attention_bam_384_min_attention": -1.5888274908065796,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9335370710256172,
      "attention_bam_384_attention_skewness": 0.45143468430584777,
      "attention_bam_384_attention_sparsity": 0.46050262451171875,
      "attention_bam_384_attention_concentration_10": 0.6181511590113916,
      "attention_bam_384_attention_concentration_20": 1.0078336318188263,
      "attention_bam_384_attention_center_y": 0.48053623606235546,
      "attention_bam_384_attention_center_x": 0.47984860343441305,
      "attention_bam_384_attention_center_distance": 0.03962112795375471,
      "attention_bam_384_attention_spatial_variance": 169.159497441661,
      "attention_bam_384_attention_spatial_std": 13.006133070273462,
      "attention_bam_384_num_attention_peaks": 19,
      "attention_bam_384_peak_separation_mean": 16.00368145134854,
      "attention_bam_384_peak_intensity_mean": 0.3030655086040497,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.225677028298378,
      "attention_bam_16_std_attention": 0.5634136199951172,
      "attention_bam_16_max_attention": 2.144028663635254,
      "attention_bam_16_min_attention": -1.065087914466858,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.5841703410821704,
      "attention_bam_16_attention_skewness": 0.20045913863677767,
      "attention_bam_16_attention_sparsity": 0.431884765625,
      "attention_bam_16_attention_concentration_10": 0.5417396146202628,
      "attention_bam_16_attention_concentration_20": 0.9180095859049319,
      "attention_bam_16_attention_center_y": 0.45627054730173494,
      "attention_bam_16_attention_center_x": 0.46141671698700815,
      "attention_bam_16_attention_center_distance": 0.08247344737975279,
      "attention_bam_16_attention_spatial_variance": 40.67862067165636,
      "attention_bam_16_attention_spatial_std": 6.377979356477752,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 7.959934367759885,
      "attention_bam_16_peak_intensity_mean": 0.4104294776916504,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 112,
      "phase": "train",
      "loss": 0.0379340834915638,
      "timestamp": 1759543899.4084063,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0379340834915638,
      "ssim": 0.5731933116912842,
      "attention_bam_384_mean_attention": 0.17743246257305145,
      "attention_bam_384_std_attention": 0.49174055457115173,
      "attention_bam_384_max_attention": 4.104841709136963,
      "attention_bam_384_min_attention": -1.6286256313323975,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5511923984144964,
      "attention_bam_384_attention_skewness": 0.378250966417706,
      "attention_bam_384_attention_sparsity": 0.4532623291015625,
      "attention_bam_384_attention_concentration_10": 0.613876282855413,
      "attention_bam_384_attention_concentration_20": 1.003819172746458,
      "attention_bam_384_attention_center_y": 0.49069745165856893,
      "attention_bam_384_attention_center_x": 0.4826465095223872,
      "attention_bam_384_attention_center_distance": 0.02784532411020782,
      "attention_bam_384_attention_spatial_variance": 170.82705540296485,
      "attention_bam_384_attention_spatial_std": 13.070082455859444,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 17.11947943282082,
      "attention_bam_384_peak_intensity_mean": 0.31903523206710815,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22194130718708038,
      "attention_bam_16_std_attention": 0.5574005246162415,
      "attention_bam_16_max_attention": 2.3259236812591553,
      "attention_bam_16_min_attention": -1.0436975955963135,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.5164691367351439,
      "attention_bam_16_attention_skewness": 0.2651453375932699,
      "attention_bam_16_attention_sparsity": 0.442626953125,
      "attention_bam_16_attention_concentration_10": 0.5539983976283185,
      "attention_bam_16_attention_concentration_20": 0.9323799842104776,
      "attention_bam_16_attention_center_y": 0.4924023819999626,
      "attention_bam_16_attention_center_x": 0.465096596344735,
      "attention_bam_16_attention_center_distance": 0.05051675733846856,
      "attention_bam_16_attention_spatial_variance": 42.58066678335719,
      "attention_bam_16_attention_spatial_std": 6.525386332115302,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.798623820269734,
      "attention_bam_16_peak_intensity_mean": 0.3940683603286743,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 113,
      "phase": "train",
      "loss": 0.02727271430194378,
      "timestamp": 1759543899.5396833,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.02727271430194378,
      "ssim": 0.6913403272628784,
      "attention_bam_384_mean_attention": 0.17593713104724884,
      "attention_bam_384_std_attention": 0.53399658203125,
      "attention_bam_384_max_attention": 4.571272850036621,
      "attention_bam_384_min_attention": -1.558364987373352,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1161224878834801,
      "attention_bam_384_attention_skewness": 0.5635326989493653,
      "attention_bam_384_attention_sparsity": 0.45847829182942706,
      "attention_bam_384_attention_concentration_10": 0.682011293695384,
      "attention_bam_384_attention_concentration_20": 1.0844271719933576,
      "attention_bam_384_attention_center_y": 0.488981504257043,
      "attention_bam_384_attention_center_x": 0.4848843610664682,
      "attention_bam_384_attention_center_distance": 0.026453347191100922,
      "attention_bam_384_attention_spatial_variance": 170.76470698161785,
      "attention_bam_384_attention_spatial_std": 13.067697080266969,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 16.739557891635734,
      "attention_bam_384_peak_intensity_mean": 0.2834506630897522,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22202590107917786,
      "attention_bam_16_std_attention": 0.6241893768310547,
      "attention_bam_16_max_attention": 2.6788604259490967,
      "attention_bam_16_min_attention": -1.1531126499176025,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.36982129181763135,
      "attention_bam_16_attention_skewness": 0.5382061897193354,
      "attention_bam_16_attention_sparsity": 0.4453125,
      "attention_bam_16_attention_concentration_10": 0.6426596919399832,
      "attention_bam_16_attention_concentration_20": 1.0280742710612778,
      "attention_bam_16_attention_center_y": 0.4884436216126561,
      "attention_bam_16_attention_center_x": 0.4740396529549351,
      "attention_bam_16_attention_center_distance": 0.040186801319131604,
      "attention_bam_16_attention_spatial_variance": 42.47813421400101,
      "attention_bam_16_attention_spatial_std": 6.517525160212349,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.125027363745154,
      "attention_bam_16_peak_intensity_mean": 0.36959972977638245,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 114,
      "phase": "train",
      "loss": 0.024297699332237244,
      "timestamp": 1759543899.669835,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.024297699332237244,
      "ssim": 0.6728736758232117,
      "attention_bam_384_mean_attention": 0.17577438056468964,
      "attention_bam_384_std_attention": 0.5290766358375549,
      "attention_bam_384_max_attention": 5.975139617919922,
      "attention_bam_384_min_attention": -1.6540099382400513,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.3856443382298194,
      "attention_bam_384_attention_skewness": 0.5461117134278024,
      "attention_bam_384_attention_sparsity": 0.46540069580078125,
      "attention_bam_384_attention_concentration_10": 0.6619831278665494,
      "attention_bam_384_attention_concentration_20": 1.0736261974942762,
      "attention_bam_384_attention_center_y": 0.48485216762925176,
      "attention_bam_384_attention_center_x": 0.48508558097420545,
      "attention_bam_384_attention_center_distance": 0.030063157532410675,
      "attention_bam_384_attention_spatial_variance": 172.00179530907675,
      "attention_bam_384_attention_spatial_std": 13.114945493942274,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 19.624766278363804,
      "attention_bam_384_peak_intensity_mean": 0.24132563173770905,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21697211265563965,
      "attention_bam_16_std_attention": 0.6085931658744812,
      "attention_bam_16_max_attention": 2.8856992721557617,
      "attention_bam_16_min_attention": -1.010050654411316,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.47312033453209956,
      "attention_bam_16_attention_skewness": 0.2901260039618466,
      "attention_bam_16_attention_sparsity": 0.44873046875,
      "attention_bam_16_attention_concentration_10": 0.605488095662971,
      "attention_bam_16_attention_concentration_20": 1.0140611556212107,
      "attention_bam_16_attention_center_y": 0.473439498662257,
      "attention_bam_16_attention_center_x": 0.4734722057047876,
      "attention_bam_16_attention_center_distance": 0.0530883057081567,
      "attention_bam_16_attention_spatial_variance": 43.61539342724379,
      "attention_bam_16_attention_spatial_std": 6.604195138489155,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.8246737842244,
      "attention_bam_16_peak_intensity_mean": 0.318141907453537,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 115,
      "phase": "train",
      "loss": 0.048028554767370224,
      "timestamp": 1759543899.800607,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.048028554767370224,
      "ssim": 0.6182036399841309,
      "attention_bam_384_mean_attention": 0.16855382919311523,
      "attention_bam_384_std_attention": 0.5186357498168945,
      "attention_bam_384_max_attention": 5.7777299880981445,
      "attention_bam_384_min_attention": -1.6341904401779175,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4808872402959787,
      "attention_bam_384_attention_skewness": 0.5603149097250635,
      "attention_bam_384_attention_sparsity": 0.4703165690104167,
      "attention_bam_384_attention_concentration_10": 0.6791175247464908,
      "attention_bam_384_attention_concentration_20": 1.0925874323044533,
      "attention_bam_384_attention_center_y": 0.48197926809942765,
      "attention_bam_384_attention_center_x": 0.4842880311691301,
      "attention_bam_384_attention_center_distance": 0.03381161761213246,
      "attention_bam_384_attention_spatial_variance": 170.14292101839928,
      "attention_bam_384_attention_spatial_std": 13.043884429816115,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 18.302494562542353,
      "attention_bam_384_peak_intensity_mean": 0.24397169053554535,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22136874496936798,
      "attention_bam_16_std_attention": 0.6021919846534729,
      "attention_bam_16_max_attention": 2.7839515209198,
      "attention_bam_16_min_attention": -1.0339429378509521,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.004009188236172356,
      "attention_bam_16_attention_skewness": 0.4767753129926453,
      "attention_bam_16_attention_sparsity": 0.4638671875,
      "attention_bam_16_attention_concentration_10": 0.6126475811913003,
      "attention_bam_16_attention_concentration_20": 1.0036263938464167,
      "attention_bam_16_attention_center_y": 0.4640623001285244,
      "attention_bam_16_attention_center_x": 0.47070933891014693,
      "attention_bam_16_attention_center_distance": 0.06556616656680318,
      "attention_bam_16_attention_spatial_variance": 41.36986912982938,
      "attention_bam_16_attention_spatial_std": 6.431941318904378,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.33431560394576,
      "attention_bam_16_peak_intensity_mean": 0.34148189425468445,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 116,
      "phase": "train",
      "loss": 0.031727712601423264,
      "timestamp": 1759543899.9332423,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.031727712601423264,
      "ssim": 0.5906537771224976,
      "attention_bam_384_mean_attention": 0.1800498366355896,
      "attention_bam_384_std_attention": 0.45751678943634033,
      "attention_bam_384_max_attention": 5.515199661254883,
      "attention_bam_384_min_attention": -1.5745933055877686,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.223838596428412,
      "attention_bam_384_attention_skewness": 0.5065799959981421,
      "attention_bam_384_attention_sparsity": 0.44294484456380206,
      "attention_bam_384_attention_concentration_10": 0.5693381467313167,
      "attention_bam_384_attention_concentration_20": 0.9287847714765679,
      "attention_bam_384_attention_center_y": 0.4865256288850431,
      "attention_bam_384_attention_center_x": 0.48238591431179584,
      "attention_bam_384_attention_center_distance": 0.031362866309538225,
      "attention_bam_384_attention_spatial_variance": 170.4690505738108,
      "attention_bam_384_attention_spatial_std": 13.05637968863539,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 18.597384482663145,
      "attention_bam_384_peak_intensity_mean": 0.2501307725906372,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21885471045970917,
      "attention_bam_16_std_attention": 0.49387454986572266,
      "attention_bam_16_max_attention": 2.2288129329681396,
      "attention_bam_16_min_attention": -1.052551031112671,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.42891236874414496,
      "attention_bam_16_attention_skewness": 0.09929581438502158,
      "attention_bam_16_attention_sparsity": 0.412353515625,
      "attention_bam_16_attention_concentration_10": 0.4977272898982142,
      "attention_bam_16_attention_concentration_20": 0.8447724603777285,
      "attention_bam_16_attention_center_y": 0.4774075833512968,
      "attention_bam_16_attention_center_x": 0.4673848583794725,
      "attention_bam_16_attention_center_distance": 0.056109976883895886,
      "attention_bam_16_attention_spatial_variance": 42.203565166807664,
      "attention_bam_16_attention_spatial_std": 6.496427107788378,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.67299487047313,
      "attention_bam_16_peak_intensity_mean": 0.39659520983695984,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 117,
      "phase": "train",
      "loss": 0.022669954225420952,
      "timestamp": 1759543900.0596504,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.022669954225420952,
      "ssim": 0.6759999990463257,
      "attention_bam_384_mean_attention": 0.17894601821899414,
      "attention_bam_384_std_attention": 0.5097276568412781,
      "attention_bam_384_max_attention": 5.790998458862305,
      "attention_bam_384_min_attention": -1.6380183696746826,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.1742411967693966,
      "attention_bam_384_attention_skewness": 0.6050191435723186,
      "attention_bam_384_attention_sparsity": 0.45660400390625,
      "attention_bam_384_attention_concentration_10": 0.6452634764897189,
      "attention_bam_384_attention_concentration_20": 1.0273545718672124,
      "attention_bam_384_attention_center_y": 0.4830275818882712,
      "attention_bam_384_attention_center_x": 0.480064613707692,
      "attention_bam_384_attention_center_distance": 0.03702654731899482,
      "attention_bam_384_attention_spatial_variance": 171.34197254328683,
      "attention_bam_384_attention_spatial_std": 13.089765946848967,
      "attention_bam_384_num_attention_peaks": 23,
      "attention_bam_384_peak_separation_mean": 19.561553578769715,
      "attention_bam_384_peak_intensity_mean": 0.24561376869678497,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21527454257011414,
      "attention_bam_16_std_attention": 0.5452346801757812,
      "attention_bam_16_max_attention": 2.3549535274505615,
      "attention_bam_16_min_attention": -1.0262737274169922,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.12670093212020106,
      "attention_bam_16_attention_skewness": 0.30269064282703984,
      "attention_bam_16_attention_sparsity": 0.433349609375,
      "attention_bam_16_attention_concentration_10": 0.5653526067592248,
      "attention_bam_16_attention_concentration_20": 0.9318257361543902,
      "attention_bam_16_attention_center_y": 0.46462821062919424,
      "attention_bam_16_attention_center_x": 0.4550562299028052,
      "attention_bam_16_attention_center_distance": 0.0808839409752288,
      "attention_bam_16_attention_spatial_variance": 42.28056448352924,
      "attention_bam_16_attention_spatial_std": 6.502350689060783,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.430534253949324,
      "attention_bam_16_peak_intensity_mean": 0.3709664046764374,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 118,
      "phase": "train",
      "loss": 0.03071744740009308,
      "timestamp": 1759543900.1887202,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.03071744740009308,
      "ssim": 0.5608291625976562,
      "attention_bam_384_mean_attention": 0.16809479892253876,
      "attention_bam_384_std_attention": 0.5389368534088135,
      "attention_bam_384_max_attention": 5.455548286437988,
      "attention_bam_384_min_attention": -1.6731858253479004,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4735756128639803,
      "attention_bam_384_attention_skewness": 0.6715418028606444,
      "attention_bam_384_attention_sparsity": 0.47968800862630206,
      "attention_bam_384_attention_concentration_10": 0.7197896858903504,
      "attention_bam_384_attention_concentration_20": 1.1424648318156752,
      "attention_bam_384_attention_center_y": 0.47706457083087006,
      "attention_bam_384_attention_center_x": 0.4863198420864751,
      "attention_bam_384_attention_center_distance": 0.037767198246922,
      "attention_bam_384_attention_spatial_variance": 171.6901864572804,
      "attention_bam_384_attention_spatial_std": 13.103060194369878,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 20.897557834959947,
      "attention_bam_384_peak_intensity_mean": 0.2615083158016205,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20570212602615356,
      "attention_bam_16_std_attention": 0.622373640537262,
      "attention_bam_16_max_attention": 3.0833187103271484,
      "attention_bam_16_min_attention": -1.144278883934021,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.22716071856090592,
      "attention_bam_16_attention_skewness": 0.5939565551851648,
      "attention_bam_16_attention_sparsity": 0.47705078125,
      "attention_bam_16_attention_concentration_10": 0.6866885398206412,
      "attention_bam_16_attention_concentration_20": 1.1096793813103405,
      "attention_bam_16_attention_center_y": 0.4500948536145512,
      "attention_bam_16_attention_center_x": 0.47843570131470164,
      "attention_bam_16_attention_center_distance": 0.07688358229871749,
      "attention_bam_16_attention_spatial_variance": 43.140212675527806,
      "attention_bam_16_attention_spatial_std": 6.568120939471791,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 10.71579397026724,
      "attention_bam_16_peak_intensity_mean": 0.3278782069683075,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 119,
      "phase": "train",
      "loss": 0.02589377388358116,
      "timestamp": 1759543900.3175828,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.02589377388358116,
      "ssim": 0.7131959795951843,
      "attention_bam_384_mean_attention": 0.16867470741271973,
      "attention_bam_384_std_attention": 0.528401255607605,
      "attention_bam_384_max_attention": 6.39737606048584,
      "attention_bam_384_min_attention": -1.7483779191970825,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.000577077611978,
      "attention_bam_384_attention_skewness": 0.8402488593430444,
      "attention_bam_384_attention_sparsity": 0.4688873291015625,
      "attention_bam_384_attention_concentration_10": 0.7130184355679873,
      "attention_bam_384_attention_concentration_20": 1.113846158557591,
      "attention_bam_384_attention_center_y": 0.4780244896190598,
      "attention_bam_384_attention_center_x": 0.4903239761732107,
      "attention_bam_384_attention_center_distance": 0.033957281799325584,
      "attention_bam_384_attention_spatial_variance": 170.7887294799435,
      "attention_bam_384_attention_spatial_std": 13.068616203712752,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 15.025754173541731,
      "attention_bam_384_peak_intensity_mean": 0.23471741378307343,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20264539122581482,
      "attention_bam_16_std_attention": 0.6239097714424133,
      "attention_bam_16_max_attention": 3.048466444015503,
      "attention_bam_16_min_attention": -1.07327139377594,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5862994876218757,
      "attention_bam_16_attention_skewness": 0.6842228296550895,
      "attention_bam_16_attention_sparsity": 0.465576171875,
      "attention_bam_16_attention_concentration_10": 0.7091516167435514,
      "attention_bam_16_attention_concentration_20": 1.1184855663780942,
      "attention_bam_16_attention_center_y": 0.4483325270656393,
      "attention_bam_16_attention_center_x": 0.4910365557716895,
      "attention_bam_16_attention_center_distance": 0.07416024665353976,
      "attention_bam_16_attention_spatial_variance": 42.466432555754196,
      "attention_bam_16_attention_spatial_std": 6.516627391201234,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.942100726285398,
      "attention_bam_16_peak_intensity_mean": 0.32378536462783813,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 120,
      "phase": "train",
      "loss": 0.025796299800276756,
      "timestamp": 1759543900.493592,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.025796299800276756,
      "ssim": 0.6535546183586121,
      "attention_bam_384_mean_attention": 0.17599086463451385,
      "attention_bam_384_std_attention": 0.46500614285469055,
      "attention_bam_384_max_attention": 4.874183177947998,
      "attention_bam_384_min_attention": -1.6323423385620117,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.7103965036080462,
      "attention_bam_384_attention_skewness": 0.4788040357913535,
      "attention_bam_384_attention_sparsity": 0.45148468017578125,
      "attention_bam_384_attention_concentration_10": 0.5877795100649305,
      "attention_bam_384_attention_concentration_20": 0.960102552407822,
      "attention_bam_384_attention_center_y": 0.4844358582118263,
      "attention_bam_384_attention_center_x": 0.48069067637242463,
      "attention_bam_384_attention_center_distance": 0.035073992888087775,
      "attention_bam_384_attention_spatial_variance": 169.83136211894134,
      "attention_bam_384_attention_spatial_std": 13.03193623829327,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 16.19390714004558,
      "attention_bam_384_peak_intensity_mean": 0.27859124541282654,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21654972434043884,
      "attention_bam_16_std_attention": 0.5239937901496887,
      "attention_bam_16_max_attention": 2.921572208404541,
      "attention_bam_16_min_attention": -1.0629454851150513,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.38964123030500053,
      "attention_bam_16_attention_skewness": 0.17421183008837066,
      "attention_bam_16_attention_sparsity": 0.4267578125,
      "attention_bam_16_attention_concentration_10": 0.5216426309528192,
      "attention_bam_16_attention_concentration_20": 0.8880709773629017,
      "attention_bam_16_attention_center_y": 0.46985761381282487,
      "attention_bam_16_attention_center_x": 0.45965063442464643,
      "attention_bam_16_attention_center_distance": 0.07122688744273939,
      "attention_bam_16_attention_spatial_variance": 41.79029092380436,
      "attention_bam_16_attention_spatial_std": 6.464541045101683,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 7.786178166197044,
      "attention_bam_16_peak_intensity_mean": 0.32411137223243713,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 121,
      "phase": "train",
      "loss": 0.02241542562842369,
      "timestamp": 1759543900.6310825,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.02241542562842369,
      "ssim": 0.6462014317512512,
      "attention_bam_384_mean_attention": 0.17460709810256958,
      "attention_bam_384_std_attention": 0.49526554346084595,
      "attention_bam_384_max_attention": 4.235883712768555,
      "attention_bam_384_min_attention": -1.5997896194458008,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9800320751039147,
      "attention_bam_384_attention_skewness": 0.5290106234212018,
      "attention_bam_384_attention_sparsity": 0.4679005940755208,
      "attention_bam_384_attention_concentration_10": 0.6400198196161382,
      "attention_bam_384_attention_concentration_20": 1.0320282859079979,
      "attention_bam_384_attention_center_y": 0.48487637663635175,
      "attention_bam_384_attention_center_x": 0.483100322578964,
      "attention_bam_384_attention_center_distance": 0.032072514107271376,
      "attention_bam_384_attention_spatial_variance": 169.13141793465897,
      "attention_bam_384_attention_spatial_std": 13.005053553702075,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 15.394956980399252,
      "attention_bam_384_peak_intensity_mean": 0.3052161633968353,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21795111894607544,
      "attention_bam_16_std_attention": 0.5674583911895752,
      "attention_bam_16_max_attention": 2.5646204948425293,
      "attention_bam_16_min_attention": -1.0836604833602905,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.09256423855684126,
      "attention_bam_16_attention_skewness": 0.4737276018401867,
      "attention_bam_16_attention_sparsity": 0.458251953125,
      "attention_bam_16_attention_concentration_10": 0.6005290278121864,
      "attention_bam_16_attention_concentration_20": 0.979046524737482,
      "attention_bam_16_attention_center_y": 0.4694460338283625,
      "attention_bam_16_attention_center_x": 0.4719101837375606,
      "attention_bam_16_attention_center_distance": 0.05869553009344365,
      "attention_bam_16_attention_spatial_variance": 40.749869501976484,
      "attention_bam_16_attention_spatial_std": 6.3835624459996065,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.402190452749004,
      "attention_bam_16_peak_intensity_mean": 0.3615896999835968,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 122,
      "phase": "train",
      "loss": 0.019418619573116302,
      "timestamp": 1759543900.7638924,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.019418619573116302,
      "ssim": 0.7167020440101624,
      "attention_bam_384_mean_attention": 0.1716325879096985,
      "attention_bam_384_std_attention": 0.5147639513015747,
      "attention_bam_384_max_attention": 4.834719181060791,
      "attention_bam_384_min_attention": -1.5424422025680542,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0747210118736898,
      "attention_bam_384_attention_skewness": 0.5559789703700625,
      "attention_bam_384_attention_sparsity": 0.4704081217447917,
      "attention_bam_384_attention_concentration_10": 0.6704718187111637,
      "attention_bam_384_attention_concentration_20": 1.079004800689215,
      "attention_bam_384_attention_center_y": 0.4768736784882251,
      "attention_bam_384_attention_center_x": 0.4870419739793779,
      "attention_bam_384_attention_center_distance": 0.03748965684071015,
      "attention_bam_384_attention_spatial_variance": 170.61098228900605,
      "attention_bam_384_attention_spatial_std": 13.061813897350017,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 19.470988193802242,
      "attention_bam_384_peak_intensity_mean": 0.27050790190696716,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20803582668304443,
      "attention_bam_16_std_attention": 0.6000232696533203,
      "attention_bam_16_max_attention": 2.343005895614624,
      "attention_bam_16_min_attention": -1.1201168298721313,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.23315507097003518,
      "attention_bam_16_attention_skewness": 0.4421241935148825,
      "attention_bam_16_attention_sparsity": 0.458251953125,
      "attention_bam_16_attention_concentration_10": 0.6411735709163775,
      "attention_bam_16_attention_concentration_20": 1.0584513426088489,
      "attention_bam_16_attention_center_y": 0.4512581622104187,
      "attention_bam_16_attention_center_x": 0.4766029493563867,
      "attention_bam_16_attention_center_distance": 0.07646160775089235,
      "attention_bam_16_attention_spatial_variance": 42.24383071067269,
      "attention_bam_16_attention_spatial_std": 6.499525421957567,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 12.077154643507741,
      "attention_bam_16_peak_intensity_mean": 0.38029980659484863,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 123,
      "phase": "train",
      "loss": 0.024330593645572662,
      "timestamp": 1759543900.8927572,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.024330593645572662,
      "ssim": 0.7324366569519043,
      "attention_bam_384_mean_attention": 0.16998596489429474,
      "attention_bam_384_std_attention": 0.540945827960968,
      "attention_bam_384_max_attention": 4.883136749267578,
      "attention_bam_384_min_attention": -1.5786315202713013,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.660317469418116,
      "attention_bam_384_attention_skewness": 0.5251126364727703,
      "attention_bam_384_attention_sparsity": 0.48167165120442706,
      "attention_bam_384_attention_concentration_10": 0.6946256951818304,
      "attention_bam_384_attention_concentration_20": 1.1363359566994424,
      "attention_bam_384_attention_center_y": 0.4802995970371031,
      "attention_bam_384_attention_center_x": 0.48954815344810465,
      "attention_bam_384_attention_center_distance": 0.03153876894378989,
      "attention_bam_384_attention_spatial_variance": 170.3496860142849,
      "attention_bam_384_attention_spatial_std": 13.051807768055923,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 15.984029210198969,
      "attention_bam_384_peak_intensity_mean": 0.2700428366661072,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20066632330417633,
      "attention_bam_16_std_attention": 0.6175705194473267,
      "attention_bam_16_max_attention": 2.8101654052734375,
      "attention_bam_16_min_attention": -1.0679931640625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.42335222931631256,
      "attention_bam_16_attention_skewness": 0.4858445129383722,
      "attention_bam_16_attention_sparsity": 0.48876953125,
      "attention_bam_16_attention_concentration_10": 0.6808705669227106,
      "attention_bam_16_attention_concentration_20": 1.1304667459955438,
      "attention_bam_16_attention_center_y": 0.46117245037597443,
      "attention_bam_16_attention_center_x": 0.49077146338015504,
      "attention_bam_16_attention_center_distance": 0.05644013639157842,
      "attention_bam_16_attention_spatial_variance": 42.258271714449485,
      "attention_bam_16_attention_spatial_std": 6.500636254586891,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 7.51373086203799,
      "attention_bam_16_peak_intensity_mean": 0.32656803727149963,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 124,
      "phase": "train",
      "loss": 0.017485812306404114,
      "timestamp": 1759543901.0239432,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.017485812306404114,
      "ssim": 0.7318340539932251,
      "attention_bam_384_mean_attention": 0.173378586769104,
      "attention_bam_384_std_attention": 0.5105518698692322,
      "attention_bam_384_max_attention": 4.586516380310059,
      "attention_bam_384_min_attention": -1.5621697902679443,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8374658604781309,
      "attention_bam_384_attention_skewness": 0.5165451769958664,
      "attention_bam_384_attention_sparsity": 0.4682464599609375,
      "attention_bam_384_attention_concentration_10": 0.6576099848390646,
      "attention_bam_384_attention_concentration_20": 1.0649431669077316,
      "attention_bam_384_attention_center_y": 0.4854217855558531,
      "attention_bam_384_attention_center_x": 0.48163496788761007,
      "attention_bam_384_attention_center_distance": 0.03316017915719537,
      "attention_bam_384_attention_spatial_variance": 169.37056484427143,
      "attention_bam_384_attention_spatial_std": 13.014244689734069,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 15.933953398851175,
      "attention_bam_384_peak_intensity_mean": 0.28262385725975037,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22395586967468262,
      "attention_bam_16_std_attention": 0.5879549980163574,
      "attention_bam_16_max_attention": 2.549246311187744,
      "attention_bam_16_min_attention": -1.0871466398239136,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.0036190960950901463,
      "attention_bam_16_attention_skewness": 0.49597147976407346,
      "attention_bam_16_attention_sparsity": 0.451904296875,
      "attention_bam_16_attention_concentration_10": 0.6033112113878185,
      "attention_bam_16_attention_concentration_20": 0.9841544160201187,
      "attention_bam_16_attention_center_y": 0.47912161220072536,
      "attention_bam_16_attention_center_x": 0.4600607101737571,
      "attention_bam_16_attention_center_distance": 0.06373466794330272,
      "attention_bam_16_attention_spatial_variance": 41.0364261959129,
      "attention_bam_16_attention_spatial_std": 6.405968013962675,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.028630700664078,
      "attention_bam_16_peak_intensity_mean": 0.366681843996048,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 125,
      "phase": "train",
      "loss": 0.01995094306766987,
      "timestamp": 1759543901.151899,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.01995094306766987,
      "ssim": 0.7043875455856323,
      "attention_bam_384_mean_attention": 0.17914138734340668,
      "attention_bam_384_std_attention": 0.49647241830825806,
      "attention_bam_384_max_attention": 5.013365268707275,
      "attention_bam_384_min_attention": -1.527954339981079,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1973781284669682,
      "attention_bam_384_attention_skewness": 0.5412181033207161,
      "attention_bam_384_attention_sparsity": 0.45967356363932294,
      "attention_bam_384_attention_concentration_10": 0.6246056526930186,
      "attention_bam_384_attention_concentration_20": 1.0079577609045824,
      "attention_bam_384_attention_center_y": 0.4821886552027991,
      "attention_bam_384_attention_center_x": 0.4848514889206125,
      "attention_bam_384_attention_center_distance": 0.03306724637483753,
      "attention_bam_384_attention_spatial_variance": 169.65279115083175,
      "attention_bam_384_attention_spatial_std": 13.025083153317361,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 17.80562660398955,
      "attention_bam_384_peak_intensity_mean": 0.2627931237220764,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.22063475847244263,
      "attention_bam_16_std_attention": 0.5696463584899902,
      "attention_bam_16_max_attention": 2.395390510559082,
      "attention_bam_16_min_attention": -1.1029698848724365,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.20242394687624898,
      "attention_bam_16_attention_skewness": 0.3998486569397448,
      "attention_bam_16_attention_sparsity": 0.445068359375,
      "attention_bam_16_attention_concentration_10": 0.5822913618964122,
      "attention_bam_16_attention_concentration_20": 0.9624576234678273,
      "attention_bam_16_attention_center_y": 0.4633446570273902,
      "attention_bam_16_attention_center_x": 0.4721037447918329,
      "attention_bam_16_attention_center_distance": 0.06514315348643851,
      "attention_bam_16_attention_spatial_variance": 41.07090807368266,
      "attention_bam_16_attention_spatial_std": 6.408658835800409,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 9.163667062234301,
      "attention_bam_16_peak_intensity_mean": 0.3879789113998413,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 126,
      "phase": "train",
      "loss": 0.018539804965257645,
      "timestamp": 1759543901.2794988,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.018539804965257645,
      "ssim": 0.7202233076095581,
      "attention_bam_384_mean_attention": 0.17672890424728394,
      "attention_bam_384_std_attention": 0.5174628496170044,
      "attention_bam_384_max_attention": 4.916935920715332,
      "attention_bam_384_min_attention": -1.561211347579956,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5877553784813792,
      "attention_bam_384_attention_skewness": 0.6389929167741264,
      "attention_bam_384_attention_sparsity": 0.46650441487630206,
      "attention_bam_384_attention_concentration_10": 0.6648470043529962,
      "attention_bam_384_attention_concentration_20": 1.0601051797642942,
      "attention_bam_384_attention_center_y": 0.486798031932349,
      "attention_bam_384_attention_center_x": 0.48760689954223224,
      "attention_bam_384_attention_center_distance": 0.025607846446571807,
      "attention_bam_384_attention_spatial_variance": 170.19116118920158,
      "attention_bam_384_attention_spatial_std": 13.045733447729246,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 19.22010953266855,
      "attention_bam_384_peak_intensity_mean": 0.26887139678001404,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20778867602348328,
      "attention_bam_16_std_attention": 0.5884791016578674,
      "attention_bam_16_max_attention": 2.5294599533081055,
      "attention_bam_16_min_attention": -1.0384167432785034,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.1472745215777107,
      "attention_bam_16_attention_skewness": 0.5262923937894897,
      "attention_bam_16_attention_sparsity": 0.46240234375,
      "attention_bam_16_attention_concentration_10": 0.6463559511936783,
      "attention_bam_16_attention_concentration_20": 1.0476986491001479,
      "attention_bam_16_attention_center_y": 0.48006307360496364,
      "attention_bam_16_attention_center_x": 0.4819459935850249,
      "attention_bam_16_attention_center_distance": 0.038037565161641466,
      "attention_bam_16_attention_spatial_variance": 41.63121164305742,
      "attention_bam_16_attention_spatial_std": 6.452225324882681,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.233426076846191,
      "attention_bam_16_peak_intensity_mean": 0.3513451814651489,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 127,
      "phase": "train",
      "loss": 0.014162315055727959,
      "timestamp": 1759543901.408587,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.014162315055727959,
      "ssim": 0.7406516075134277,
      "attention_bam_384_mean_attention": 0.1648077815771103,
      "attention_bam_384_std_attention": 0.5320079326629639,
      "attention_bam_384_max_attention": 4.604140758514404,
      "attention_bam_384_min_attention": -1.6643249988555908,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.037006662768797,
      "attention_bam_384_attention_skewness": 0.6200895270613345,
      "attention_bam_384_attention_sparsity": 0.48344167073567706,
      "attention_bam_384_attention_concentration_10": 0.7300757910110776,
      "attention_bam_384_attention_concentration_20": 1.1552612058736402,
      "attention_bam_384_attention_center_y": 0.48855528562662487,
      "attention_bam_384_attention_center_x": 0.4892143907895324,
      "attention_bam_384_attention_center_distance": 0.022240092316762678,
      "attention_bam_384_attention_spatial_variance": 172.68219058917146,
      "attention_bam_384_attention_spatial_std": 13.14085958334429,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 19.875618911916487,
      "attention_bam_384_peak_intensity_mean": 0.29446154832839966,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20163089036941528,
      "attention_bam_16_std_attention": 0.621902585029602,
      "attention_bam_16_max_attention": 2.9695498943328857,
      "attention_bam_16_min_attention": -1.087627649307251,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.30684079685907006,
      "attention_bam_16_attention_skewness": 0.6662232952665799,
      "attention_bam_16_attention_sparsity": 0.485107421875,
      "attention_bam_16_attention_concentration_10": 0.7109595439201725,
      "attention_bam_16_attention_concentration_20": 1.1348287885212176,
      "attention_bam_16_attention_center_y": 0.4855380688574572,
      "attention_bam_16_attention_center_x": 0.48624984697287993,
      "attention_bam_16_attention_center_distance": 0.02822106166113771,
      "attention_bam_16_attention_spatial_variance": 44.24127984094668,
      "attention_bam_16_attention_spatial_std": 6.651411868238704,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 11.337821214258978,
      "attention_bam_16_peak_intensity_mean": 0.3330634534358978,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 128,
      "phase": "train",
      "loss": 0.018513698130846024,
      "timestamp": 1759543901.5381358,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.018513698130846024,
      "ssim": 0.6634955406188965,
      "attention_bam_384_mean_attention": 0.16814835369586945,
      "attention_bam_384_std_attention": 0.4861285388469696,
      "attention_bam_384_max_attention": 5.623443603515625,
      "attention_bam_384_min_attention": -1.61465322971344,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.142513724491965,
      "attention_bam_384_attention_skewness": 0.7186819247116323,
      "attention_bam_384_attention_sparsity": 0.4703623453776042,
      "attention_bam_384_attention_concentration_10": 0.654452863130373,
      "attention_bam_384_attention_concentration_20": 1.0398192925970497,
      "attention_bam_384_attention_center_y": 0.47952825362609586,
      "attention_bam_384_attention_center_x": 0.48685917960777575,
      "attention_bam_384_attention_center_distance": 0.03440271966511235,
      "attention_bam_384_attention_spatial_variance": 171.35558291555517,
      "attention_bam_384_attention_spatial_std": 13.090285822530964,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 18.343925199456606,
      "attention_bam_384_peak_intensity_mean": 0.24847900867462158,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21199651062488556,
      "attention_bam_16_std_attention": 0.5665954351425171,
      "attention_bam_16_max_attention": 2.9916391372680664,
      "attention_bam_16_min_attention": -1.0100030899047852,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.34730784633604417,
      "attention_bam_16_attention_skewness": 0.5651978504375765,
      "attention_bam_16_attention_sparsity": 0.45263671875,
      "attention_bam_16_attention_concentration_10": 0.6144291302744447,
      "attention_bam_16_attention_concentration_20": 0.9939239515041568,
      "attention_bam_16_attention_center_y": 0.45433722514265207,
      "attention_bam_16_attention_center_x": 0.48024232995182214,
      "attention_bam_16_attention_center_distance": 0.07036269655727401,
      "attention_bam_16_attention_spatial_variance": 42.39829116515071,
      "attention_bam_16_attention_spatial_std": 6.51139702100484,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.354866126279436,
      "attention_bam_16_peak_intensity_mean": 0.3199376165866852,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 129,
      "phase": "train",
      "loss": 0.01840660721063614,
      "timestamp": 1759543901.6694086,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.01840660721063614,
      "ssim": 0.6864922642707825,
      "attention_bam_384_mean_attention": 0.17540878057479858,
      "attention_bam_384_std_attention": 0.5120491981506348,
      "attention_bam_384_max_attention": 4.2582221031188965,
      "attention_bam_384_min_attention": -1.4730939865112305,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.50824791569543,
      "attention_bam_384_attention_skewness": 0.4650800822200246,
      "attention_bam_384_attention_sparsity": 0.468475341796875,
      "attention_bam_384_attention_concentration_10": 0.6479761883320937,
      "attention_bam_384_attention_concentration_20": 1.0540816547286251,
      "attention_bam_384_attention_center_y": 0.4878642384567063,
      "attention_bam_384_attention_center_x": 0.48694140227949806,
      "attention_bam_384_attention_center_distance": 0.025211254735200507,
      "attention_bam_384_attention_spatial_variance": 169.71610197184427,
      "attention_bam_384_attention_spatial_std": 13.027513268918373,
      "attention_bam_384_num_attention_peaks": 21,
      "attention_bam_384_peak_separation_mean": 14.046534579935297,
      "attention_bam_384_peak_intensity_mean": 0.2903495728969574,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21040940284729004,
      "attention_bam_16_std_attention": 0.5870165228843689,
      "attention_bam_16_max_attention": 2.3512377738952637,
      "attention_bam_16_min_attention": -1.0432227849960327,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.35106736394178517,
      "attention_bam_16_attention_skewness": 0.37047829870929166,
      "attention_bam_16_attention_sparsity": 0.456787109375,
      "attention_bam_16_attention_concentration_10": 0.6128608412646547,
      "attention_bam_16_attention_concentration_20": 1.0205090020402348,
      "attention_bam_16_attention_center_y": 0.4824658229542182,
      "attention_bam_16_attention_center_x": 0.4797520815189044,
      "attention_bam_16_attention_center_distance": 0.0378794289157034,
      "attention_bam_16_attention_spatial_variance": 41.17090589087629,
      "attention_bam_16_attention_spatial_std": 6.416455866822142,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 6.9001158512709075,
      "attention_bam_16_peak_intensity_mean": 0.38272011280059814,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 130,
      "phase": "train",
      "loss": 0.021225741133093834,
      "timestamp": 1759543901.8379874,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.021225741133093834,
      "ssim": 0.7209907174110413,
      "attention_bam_384_mean_attention": 0.17021216452121735,
      "attention_bam_384_std_attention": 0.5103753209114075,
      "attention_bam_384_max_attention": 5.4800639152526855,
      "attention_bam_384_min_attention": -1.641516923904419,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.261372742338488,
      "attention_bam_384_attention_skewness": 0.8305122222594596,
      "attention_bam_384_attention_sparsity": 0.4750874837239583,
      "attention_bam_384_attention_concentration_10": 0.6883597976854273,
      "attention_bam_384_attention_concentration_20": 1.078069381802859,
      "attention_bam_384_attention_center_y": 0.47497786955325305,
      "attention_bam_384_attention_center_x": 0.4812512828875508,
      "attention_bam_384_attention_center_distance": 0.04421812762785565,
      "attention_bam_384_attention_spatial_variance": 171.42344272501757,
      "attention_bam_384_attention_spatial_std": 13.092877557092542,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 15.621688091910595,
      "attention_bam_384_peak_intensity_mean": 0.2580510675907135,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2017698436975479,
      "attention_bam_16_std_attention": 0.606592059135437,
      "attention_bam_16_max_attention": 3.5698342323303223,
      "attention_bam_16_min_attention": -1.127834677696228,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.929906030384327,
      "attention_bam_16_attention_skewness": 0.9112985557340706,
      "attention_bam_16_attention_sparsity": 0.4677734375,
      "attention_bam_16_attention_concentration_10": 0.6890828987966955,
      "attention_bam_16_attention_concentration_20": 1.0874566717825487,
      "attention_bam_16_attention_center_y": 0.44013998147358985,
      "attention_bam_16_attention_center_x": 0.45843553743117105,
      "attention_bam_16_attention_center_distance": 0.10306140273271802,
      "attention_bam_16_attention_spatial_variance": 42.377808401546105,
      "attention_bam_16_attention_spatial_std": 6.509823991595019,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.632346632500907,
      "attention_bam_16_peak_intensity_mean": 0.29443666338920593,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 131,
      "phase": "train",
      "loss": 0.01853237859904766,
      "timestamp": 1759543901.9672608,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.01853237859904766,
      "ssim": 0.7185113430023193,
      "attention_bam_384_mean_attention": 0.16962824761867523,
      "attention_bam_384_std_attention": 0.5382463932037354,
      "attention_bam_384_max_attention": 5.248068809509277,
      "attention_bam_384_min_attention": -1.6215767860412598,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0684017799315244,
      "attention_bam_384_attention_skewness": 0.6254146678674296,
      "attention_bam_384_attention_sparsity": 0.4772084554036458,
      "attention_bam_384_attention_concentration_10": 0.717326532569848,
      "attention_bam_384_attention_concentration_20": 1.1358955237077646,
      "attention_bam_384_attention_center_y": 0.48725613406190016,
      "attention_bam_384_attention_center_x": 0.48164888320338134,
      "attention_bam_384_attention_center_distance": 0.0315965063490064,
      "attention_bam_384_attention_spatial_variance": 170.4770171332228,
      "attention_bam_384_attention_spatial_std": 13.056684768088061,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 17.951228465353374,
      "attention_bam_384_peak_intensity_mean": 0.26291242241859436,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2106776237487793,
      "attention_bam_16_std_attention": 0.6438029408454895,
      "attention_bam_16_max_attention": 2.7863481044769287,
      "attention_bam_16_min_attention": -1.1000534296035767,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.29222100271006957,
      "attention_bam_16_attention_skewness": 0.6573341179896903,
      "attention_bam_16_attention_sparsity": 0.482421875,
      "attention_bam_16_attention_concentration_10": 0.7057683450078118,
      "attention_bam_16_attention_concentration_20": 1.1301564059458507,
      "attention_bam_16_attention_center_y": 0.48290910389466063,
      "attention_bam_16_attention_center_x": 0.4637911588302714,
      "attention_bam_16_attention_center_distance": 0.05662471030456823,
      "attention_bam_16_attention_spatial_variance": 42.02101176661602,
      "attention_bam_16_attention_spatial_std": 6.482361588697133,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.456765346018267,
      "attention_bam_16_peak_intensity_mean": 0.3361654579639435,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 132,
      "phase": "train",
      "loss": 0.011951364576816559,
      "timestamp": 1759543902.0960147,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.011951364576816559,
      "ssim": 0.7076120972633362,
      "attention_bam_384_mean_attention": 0.17008012533187866,
      "attention_bam_384_std_attention": 0.4571542739868164,
      "attention_bam_384_max_attention": 4.223622798919678,
      "attention_bam_384_min_attention": -1.4340062141418457,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.099637034034746,
      "attention_bam_384_attention_skewness": 0.5665289048675773,
      "attention_bam_384_attention_sparsity": 0.4675750732421875,
      "attention_bam_384_attention_concentration_10": 0.6124198096516157,
      "attention_bam_384_attention_concentration_20": 0.9887239085309009,
      "attention_bam_384_attention_center_y": 0.48834334114308026,
      "attention_bam_384_attention_center_x": 0.4910823764269972,
      "attention_bam_384_attention_center_distance": 0.02075580429163759,
      "attention_bam_384_attention_spatial_variance": 171.01568933344862,
      "attention_bam_384_attention_spatial_std": 13.077296713520292,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 17.423870036474753,
      "attention_bam_384_peak_intensity_mean": 0.2867366075515747,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20149016380310059,
      "attention_bam_16_std_attention": 0.5522218346595764,
      "attention_bam_16_max_attention": 2.5762434005737305,
      "attention_bam_16_min_attention": -0.9512450695037842,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.04590184735197633,
      "attention_bam_16_attention_skewness": 0.566206086645007,
      "attention_bam_16_attention_sparsity": 0.473388671875,
      "attention_bam_16_attention_concentration_10": 0.6314387991560092,
      "attention_bam_16_attention_concentration_20": 1.0280824796854762,
      "attention_bam_16_attention_center_y": 0.4805878142109923,
      "attention_bam_16_attention_center_x": 0.4934033398722606,
      "attention_bam_16_attention_center_distance": 0.02899478856442516,
      "attention_bam_16_attention_spatial_variance": 42.41362175372032,
      "attention_bam_16_attention_spatial_std": 6.512574126543231,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.969304773043332,
      "attention_bam_16_peak_intensity_mean": 0.3347676396369934,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 133,
      "phase": "train",
      "loss": 0.013379557989537716,
      "timestamp": 1759543902.227619,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.013379557989537716,
      "ssim": 0.7462832927703857,
      "attention_bam_384_mean_attention": 0.16837656497955322,
      "attention_bam_384_std_attention": 0.5282300114631653,
      "attention_bam_384_max_attention": 3.731142044067383,
      "attention_bam_384_min_attention": -1.567223310470581,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.386642189233509,
      "attention_bam_384_attention_skewness": 0.7412799320719033,
      "attention_bam_384_attention_sparsity": 0.47735341389973956,
      "attention_bam_384_attention_concentration_10": 0.7231421400478218,
      "attention_bam_384_attention_concentration_20": 1.122585304206366,
      "attention_bam_384_attention_center_y": 0.4853097866792319,
      "attention_bam_384_attention_center_x": 0.4858236326822357,
      "attention_bam_384_attention_center_distance": 0.02887115369145637,
      "attention_bam_384_attention_spatial_variance": 172.7432059930609,
      "attention_bam_384_attention_spatial_std": 13.143180969349121,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 18.557839457097195,
      "attention_bam_384_peak_intensity_mean": 0.3288409113883972,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.203912153840065,
      "attention_bam_16_std_attention": 0.6502395868301392,
      "attention_bam_16_max_attention": 2.872403860092163,
      "attention_bam_16_min_attention": -1.2450761795043945,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5272584291993727,
      "attention_bam_16_attention_skewness": 0.7562492472664494,
      "attention_bam_16_attention_sparsity": 0.477783203125,
      "attention_bam_16_attention_concentration_10": 0.7376564683867682,
      "attention_bam_16_attention_concentration_20": 1.1612718884616084,
      "attention_bam_16_attention_center_y": 0.4712742905995633,
      "attention_bam_16_attention_center_x": 0.4739145660915613,
      "attention_bam_16_attention_center_distance": 0.05487469804472481,
      "attention_bam_16_attention_spatial_variance": 43.70649784456314,
      "attention_bam_16_attention_spatial_std": 6.611089005947744,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.39566243723903,
      "attention_bam_16_peak_intensity_mean": 0.3580973148345947,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 134,
      "phase": "train",
      "loss": 0.018046334385871887,
      "timestamp": 1759543902.3583891,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.018046334385871887,
      "ssim": 0.7374681234359741,
      "attention_bam_384_mean_attention": 0.172984316945076,
      "attention_bam_384_std_attention": 0.5276946425437927,
      "attention_bam_384_max_attention": 4.426222324371338,
      "attention_bam_384_min_attention": -1.6479204893112183,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.9942235885081105,
      "attention_bam_384_attention_skewness": 0.8531055426686622,
      "attention_bam_384_attention_sparsity": 0.47632090250651044,
      "attention_bam_384_attention_concentration_10": 0.7129115246778803,
      "attention_bam_384_attention_concentration_20": 1.0991037129821717,
      "attention_bam_384_attention_center_y": 0.4780234554573079,
      "attention_bam_384_attention_center_x": 0.47824986009039766,
      "attention_bam_384_attention_center_distance": 0.043727270578534996,
      "attention_bam_384_attention_spatial_variance": 170.45135589814518,
      "attention_bam_384_attention_spatial_std": 13.055702045395536,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 17.666190956691384,
      "attention_bam_384_peak_intensity_mean": 0.30244866013526917,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21044056117534637,
      "attention_bam_16_std_attention": 0.6091065406799316,
      "attention_bam_16_max_attention": 3.0246448516845703,
      "attention_bam_16_min_attention": -1.0840545892715454,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.123123595737959,
      "attention_bam_16_attention_skewness": 0.8332467617434811,
      "attention_bam_16_attention_sparsity": 0.462646484375,
      "attention_bam_16_attention_concentration_10": 0.6827374643103583,
      "attention_bam_16_attention_concentration_20": 1.0614114698433985,
      "attention_bam_16_attention_center_y": 0.45055886323805017,
      "attention_bam_16_attention_center_x": 0.44839530584418164,
      "attention_bam_16_attention_center_distance": 0.10106899092431249,
      "attention_bam_16_attention_spatial_variance": 41.9815581938291,
      "attention_bam_16_attention_spatial_std": 6.479317725951484,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 8.679150187247243,
      "attention_bam_16_peak_intensity_mean": 0.33048295974731445,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 135,
      "phase": "train",
      "loss": 0.013914048671722412,
      "timestamp": 1759543902.490429,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.013914048671722412,
      "ssim": 0.7229335308074951,
      "attention_bam_384_mean_attention": 0.1705063134431839,
      "attention_bam_384_std_attention": 0.49718913435935974,
      "attention_bam_384_max_attention": 4.342754364013672,
      "attention_bam_384_min_attention": -1.5168681144714355,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.1952311265257825,
      "attention_bam_384_attention_skewness": 0.9204509515573241,
      "attention_bam_384_attention_sparsity": 0.47978464762369794,
      "attention_bam_384_attention_concentration_10": 0.6952096304484795,
      "attention_bam_384_attention_concentration_20": 1.067121082319486,
      "attention_bam_384_attention_center_y": 0.4787251399105507,
      "attention_bam_384_attention_center_x": 0.48458950464199557,
      "attention_bam_384_attention_center_distance": 0.037151124855237375,
      "attention_bam_384_attention_spatial_variance": 169.60758732763784,
      "attention_bam_384_attention_spatial_std": 13.023347777266713,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 18.33208732392971,
      "attention_bam_384_peak_intensity_mean": 0.2896946668624878,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19795823097229004,
      "attention_bam_16_std_attention": 0.5857661962509155,
      "attention_bam_16_max_attention": 2.826446533203125,
      "attention_bam_16_min_attention": -1.0271003246307373,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.6713240835382956,
      "attention_bam_16_attention_skewness": 1.0540125439068209,
      "attention_bam_16_attention_sparsity": 0.489501953125,
      "attention_bam_16_attention_concentration_10": 0.7175731997016153,
      "attention_bam_16_attention_concentration_20": 1.1011568751768634,
      "attention_bam_16_attention_center_y": 0.4542615904108578,
      "attention_bam_16_attention_center_x": 0.47457806348717224,
      "attention_bam_16_attention_center_distance": 0.07400374271354633,
      "attention_bam_16_attention_spatial_variance": 40.968590349358216,
      "attention_bam_16_attention_spatial_std": 6.40067108585953,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 10.074937964800972,
      "attention_bam_16_peak_intensity_mean": 0.3295035660266876,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 136,
      "phase": "train",
      "loss": 0.01887301728129387,
      "timestamp": 1759543902.6234348,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.01887301728129387,
      "ssim": 0.7509950995445251,
      "attention_bam_384_mean_attention": 0.17252744734287262,
      "attention_bam_384_std_attention": 0.5268973708152771,
      "attention_bam_384_max_attention": 5.713760852813721,
      "attention_bam_384_min_attention": -1.5888311862945557,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.9035790010227807,
      "attention_bam_384_attention_skewness": 0.9410812904598167,
      "attention_bam_384_attention_sparsity": 0.4730428059895833,
      "attention_bam_384_attention_concentration_10": 0.7023978904578879,
      "attention_bam_384_attention_concentration_20": 1.089121309375189,
      "attention_bam_384_attention_center_y": 0.47593712634645435,
      "attention_bam_384_attention_center_x": 0.4835663357630217,
      "attention_bam_384_attention_center_distance": 0.04120891186916345,
      "attention_bam_384_attention_spatial_variance": 170.2565023687935,
      "attention_bam_384_attention_spatial_std": 13.048237519634347,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 13.815912946092253,
      "attention_bam_384_peak_intensity_mean": 0.24313120543956757,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1999158263206482,
      "attention_bam_16_std_attention": 0.6289928555488586,
      "attention_bam_16_max_attention": 3.6070680618286133,
      "attention_bam_16_min_attention": -1.1336166858673096,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.7449062280884657,
      "attention_bam_16_attention_skewness": 0.9543443533054858,
      "attention_bam_16_attention_sparsity": 0.481689453125,
      "attention_bam_16_attention_concentration_10": 0.7270339779120171,
      "attention_bam_16_attention_concentration_20": 1.137850544599437,
      "attention_bam_16_attention_center_y": 0.44582630170067206,
      "attention_bam_16_attention_center_x": 0.4666690840168001,
      "attention_bam_16_attention_center_distance": 0.08995264918506557,
      "attention_bam_16_attention_spatial_variance": 41.527348024198865,
      "attention_bam_16_attention_spatial_std": 6.444171632118349,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 9.721558071671714,
      "attention_bam_16_peak_intensity_mean": 0.28958308696746826,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 137,
      "phase": "train",
      "loss": 0.014822853729128838,
      "timestamp": 1759543902.7476432,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.014822853729128838,
      "ssim": 0.7345585823059082,
      "attention_bam_384_mean_attention": 0.1707100123167038,
      "attention_bam_384_std_attention": 0.495784729719162,
      "attention_bam_384_max_attention": 3.971101999282837,
      "attention_bam_384_min_attention": -1.4752905368804932,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.815021259232406,
      "attention_bam_384_attention_skewness": 0.5950196044693001,
      "attention_bam_384_attention_sparsity": 0.4738820393880208,
      "attention_bam_384_attention_concentration_10": 0.6588637769787044,
      "attention_bam_384_attention_concentration_20": 1.054825726281937,
      "attention_bam_384_attention_center_y": 0.4845650275180201,
      "attention_bam_384_attention_center_x": 0.48087533757762146,
      "attention_bam_384_attention_center_distance": 0.03475603798736024,
      "attention_bam_384_attention_spatial_variance": 170.0803719432231,
      "attention_bam_384_attention_spatial_std": 13.041486569529683,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 16.678706731223723,
      "attention_bam_384_peak_intensity_mean": 0.305668443441391,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21070986986160278,
      "attention_bam_16_std_attention": 0.5671334266662598,
      "attention_bam_16_max_attention": 2.64501690864563,
      "attention_bam_16_min_attention": -0.9460572600364685,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.27050330587621607,
      "attention_bam_16_attention_skewness": 0.580896966792913,
      "attention_bam_16_attention_sparsity": 0.4580078125,
      "attention_bam_16_attention_concentration_10": 0.6148175807007721,
      "attention_bam_16_attention_concentration_20": 1.0007173720756721,
      "attention_bam_16_attention_center_y": 0.4634422194372189,
      "attention_bam_16_attention_center_x": 0.46031211358460766,
      "attention_bam_16_attention_center_distance": 0.07630988989374231,
      "attention_bam_16_attention_spatial_variance": 41.44777030789112,
      "attention_bam_16_attention_spatial_std": 6.437994276783035,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.639994031944067,
      "attention_bam_16_peak_intensity_mean": 0.32985126972198486,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 138,
      "phase": "train",
      "loss": 0.012738185934722424,
      "timestamp": 1759543902.877666,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.012738185934722424,
      "ssim": 0.78151535987854,
      "attention_bam_384_mean_attention": 0.16785770654678345,
      "attention_bam_384_std_attention": 0.5199347138404846,
      "attention_bam_384_max_attention": 4.3088603019714355,
      "attention_bam_384_min_attention": -1.504619836807251,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1014566995781623,
      "attention_bam_384_attention_skewness": 0.6561231552732596,
      "attention_bam_384_attention_sparsity": 0.4790802001953125,
      "attention_bam_384_attention_concentration_10": 0.7032768917287158,
      "attention_bam_384_attention_concentration_20": 1.115983265777233,
      "attention_bam_384_attention_center_y": 0.4853190304232901,
      "attention_bam_384_attention_center_x": 0.4832512342466186,
      "attention_bam_384_attention_center_distance": 0.031497683152064485,
      "attention_bam_384_attention_spatial_variance": 168.35279132976652,
      "attention_bam_384_attention_spatial_std": 12.975083480647303,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 15.577548426289868,
      "attention_bam_384_peak_intensity_mean": 0.29099953174591064,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20700234174728394,
      "attention_bam_16_std_attention": 0.6090412139892578,
      "attention_bam_16_max_attention": 3.3599886894226074,
      "attention_bam_16_min_attention": -1.0278512239456177,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.22515738080269943,
      "attention_bam_16_attention_skewness": 0.5943631622529135,
      "attention_bam_16_attention_sparsity": 0.466552734375,
      "attention_bam_16_attention_concentration_10": 0.6718257214376714,
      "attention_bam_16_attention_concentration_20": 1.081127770456102,
      "attention_bam_16_attention_center_y": 0.474599304466212,
      "attention_bam_16_attention_center_x": 0.4649820127557911,
      "attention_bam_16_attention_center_distance": 0.06117932271994802,
      "attention_bam_16_attention_spatial_variance": 40.49814880513352,
      "attention_bam_16_attention_spatial_std": 6.363815585412066,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 7.708282266732498,
      "attention_bam_16_peak_intensity_mean": 0.2896735668182373,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 139,
      "phase": "train",
      "loss": 0.01578447036445141,
      "timestamp": 1759543903.0087101,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.01578447036445141,
      "ssim": 0.7133201956748962,
      "attention_bam_384_mean_attention": 0.17083938419818878,
      "attention_bam_384_std_attention": 0.5031391978263855,
      "attention_bam_384_max_attention": 4.082921504974365,
      "attention_bam_384_min_attention": -1.5324435234069824,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.7451713345232003,
      "attention_bam_384_attention_skewness": 0.9117603467535813,
      "attention_bam_384_attention_sparsity": 0.4643402099609375,
      "attention_bam_384_attention_concentration_10": 0.6864630613161915,
      "attention_bam_384_attention_concentration_20": 1.0543949569627447,
      "attention_bam_384_attention_center_y": 0.4893394335860352,
      "attention_bam_384_attention_center_x": 0.48641751387538584,
      "attention_bam_384_attention_center_distance": 0.024418501411507223,
      "attention_bam_384_attention_spatial_variance": 172.5114707674899,
      "attention_bam_384_attention_spatial_std": 13.134362213959607,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 18.746969015628217,
      "attention_bam_384_peak_intensity_mean": 0.30596452951431274,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2113543450832367,
      "attention_bam_16_std_attention": 0.5578665733337402,
      "attention_bam_16_max_attention": 3.347878932952881,
      "attention_bam_16_min_attention": -1.1028547286987305,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.6364080711657412,
      "attention_bam_16_attention_skewness": 0.7369383859637412,
      "attention_bam_16_attention_sparsity": 0.43310546875,
      "attention_bam_16_attention_concentration_10": 0.6012535471861454,
      "attention_bam_16_attention_concentration_20": 0.9557028289305309,
      "attention_bam_16_attention_center_y": 0.47942932631263796,
      "attention_bam_16_attention_center_x": 0.4754079335303237,
      "attention_bam_16_attention_center_distance": 0.04534142364771771,
      "attention_bam_16_attention_spatial_variance": 43.36064891963737,
      "attention_bam_16_attention_spatial_std": 6.584880326903244,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 10.588066252848401,
      "attention_bam_16_peak_intensity_mean": 0.30608659982681274,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 140,
      "phase": "train",
      "loss": 0.018906310200691223,
      "timestamp": 1759543903.1827374,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.018906310200691223,
      "ssim": 0.665652871131897,
      "attention_bam_384_mean_attention": 0.1698518544435501,
      "attention_bam_384_std_attention": 0.5106370449066162,
      "attention_bam_384_max_attention": 4.529942512512207,
      "attention_bam_384_min_attention": -1.4063955545425415,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.4542784764690504,
      "attention_bam_384_attention_skewness": 0.910704013017009,
      "attention_bam_384_attention_sparsity": 0.4772135416666667,
      "attention_bam_384_attention_concentration_10": 0.6963909142248906,
      "attention_bam_384_attention_concentration_20": 1.0823275537364252,
      "attention_bam_384_attention_center_y": 0.49033025747487274,
      "attention_bam_384_attention_center_x": 0.47790210274779843,
      "attention_bam_384_attention_center_distance": 0.03411219674753041,
      "attention_bam_384_attention_spatial_variance": 169.4440064382144,
      "attention_bam_384_attention_spatial_std": 13.017065968881559,
      "attention_bam_384_num_attention_peaks": 4,
      "attention_bam_384_peak_separation_mean": 21.14482426190487,
      "attention_bam_384_peak_intensity_mean": 0.2691563069820404,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19710548222064972,
      "attention_bam_16_std_attention": 0.6219751834869385,
      "attention_bam_16_max_attention": 3.5729804039001465,
      "attention_bam_16_min_attention": -1.118790864944458,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.2700469441837203,
      "attention_bam_16_attention_skewness": 1.0786283982927696,
      "attention_bam_16_attention_sparsity": 0.48193359375,
      "attention_bam_16_attention_concentration_10": 0.7368495617947631,
      "attention_bam_16_attention_concentration_20": 1.1392289940720843,
      "attention_bam_16_attention_center_y": 0.4848628494538785,
      "attention_bam_16_attention_center_x": 0.4544111192047323,
      "attention_bam_16_attention_center_distance": 0.06793348774825378,
      "attention_bam_16_attention_spatial_variance": 41.50516965759325,
      "attention_bam_16_attention_spatial_std": 6.442450594113489,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 10.515334880016574,
      "attention_bam_16_peak_intensity_mean": 0.28935950994491577,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 141,
      "phase": "train",
      "loss": 0.01841416023671627,
      "timestamp": 1759543903.3234124,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.01841416023671627,
      "ssim": 0.7173675298690796,
      "attention_bam_384_mean_attention": 0.17503221333026886,
      "attention_bam_384_std_attention": 0.507006824016571,
      "attention_bam_384_max_attention": 4.211553573608398,
      "attention_bam_384_min_attention": -1.6011443138122559,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4976557557779824,
      "attention_bam_384_attention_skewness": 0.666986736524229,
      "attention_bam_384_attention_sparsity": 0.4624684651692708,
      "attention_bam_384_attention_concentration_10": 0.6690003359947085,
      "attention_bam_384_attention_concentration_20": 1.0456927963166185,
      "attention_bam_384_attention_center_y": 0.48190889153122773,
      "attention_bam_384_attention_center_x": 0.48319383774155117,
      "attention_bam_384_attention_center_distance": 0.03492091910262939,
      "attention_bam_384_attention_spatial_variance": 171.4315835468047,
      "attention_bam_384_attention_spatial_std": 13.093188440819322,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 17.60815856482487,
      "attention_bam_384_peak_intensity_mean": 0.30834564566612244,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2070835828781128,
      "attention_bam_16_std_attention": 0.6020380854606628,
      "attention_bam_16_max_attention": 2.456374168395996,
      "attention_bam_16_min_attention": -1.1232774257659912,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.3693087806989026,
      "attention_bam_16_attention_skewness": 0.6209514534671634,
      "attention_bam_16_attention_sparsity": 0.468505859375,
      "attention_bam_16_attention_concentration_10": 0.6717792519016811,
      "attention_bam_16_attention_concentration_20": 1.066763070154934,
      "attention_bam_16_attention_center_y": 0.46160816232513213,
      "attention_bam_16_attention_center_x": 0.46874122865694196,
      "attention_bam_16_attention_center_distance": 0.07001491249628167,
      "attention_bam_16_attention_spatial_variance": 42.841413682399654,
      "attention_bam_16_attention_spatial_std": 6.545335261268108,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.500441169796854,
      "attention_bam_16_peak_intensity_mean": 0.3760649561882019,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 142,
      "phase": "train",
      "loss": 0.014186881482601166,
      "timestamp": 1759543903.4549243,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.014186881482601166,
      "ssim": 0.7390872240066528,
      "attention_bam_384_mean_attention": 0.16994662582874298,
      "attention_bam_384_std_attention": 0.4886970818042755,
      "attention_bam_384_max_attention": 3.7980751991271973,
      "attention_bam_384_min_attention": -1.4844577312469482,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0690626404539447,
      "attention_bam_384_attention_skewness": 0.6628678043293992,
      "attention_bam_384_attention_sparsity": 0.4766794840494792,
      "attention_bam_384_attention_concentration_10": 0.6710487889792576,
      "attention_bam_384_attention_concentration_20": 1.057345750268673,
      "attention_bam_384_attention_center_y": 0.48146492861749884,
      "attention_bam_384_attention_center_x": 0.48578737742524836,
      "attention_bam_384_attention_center_distance": 0.03303172752390505,
      "attention_bam_384_attention_spatial_variance": 171.4285324594594,
      "attention_bam_384_attention_spatial_std": 13.093071926001912,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 20.72668559864939,
      "attention_bam_384_peak_intensity_mean": 0.31496870517730713,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19861790537834167,
      "attention_bam_16_std_attention": 0.5630149841308594,
      "attention_bam_16_max_attention": 2.4321482181549072,
      "attention_bam_16_min_attention": -1.141275405883789,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.3700939204540359,
      "attention_bam_16_attention_skewness": 0.6632679925349231,
      "attention_bam_16_attention_sparsity": 0.47314453125,
      "attention_bam_16_attention_concentration_10": 0.6597441282557646,
      "attention_bam_16_attention_concentration_20": 1.0540367477694392,
      "attention_bam_16_attention_center_y": 0.46287013618930795,
      "attention_bam_16_attention_center_x": 0.47154061299383027,
      "attention_bam_16_attention_center_distance": 0.06615985936151138,
      "attention_bam_16_attention_spatial_variance": 42.67534072168842,
      "attention_bam_16_attention_spatial_std": 6.532636582704446,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 10.274666187623726,
      "attention_bam_16_peak_intensity_mean": 0.37922370433807373,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 143,
      "phase": "train",
      "loss": 0.014677217230200768,
      "timestamp": 1759543903.5865912,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.014677217230200768,
      "ssim": 0.7301625609397888,
      "attention_bam_384_mean_attention": 0.16786076128482819,
      "attention_bam_384_std_attention": 0.5623955130577087,
      "attention_bam_384_max_attention": 5.688475608825684,
      "attention_bam_384_min_attention": -1.5263051986694336,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 4.029575715796619,
      "attention_bam_384_attention_skewness": 1.0796098955829192,
      "attention_bam_384_attention_sparsity": 0.48334503173828125,
      "attention_bam_384_attention_concentration_10": 0.7566985677929056,
      "attention_bam_384_attention_concentration_20": 1.176177212399965,
      "attention_bam_384_attention_center_y": 0.4851260030717135,
      "attention_bam_384_attention_center_x": 0.4794074946982337,
      "attention_bam_384_attention_center_distance": 0.035924561492826884,
      "attention_bam_384_attention_spatial_variance": 171.01804350543048,
      "attention_bam_384_attention_spatial_std": 13.077386723096877,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 18.145289891916242,
      "attention_bam_384_peak_intensity_mean": 0.23671436309814453,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20554065704345703,
      "attention_bam_16_std_attention": 0.6826980113983154,
      "attention_bam_16_max_attention": 5.8794450759887695,
      "attention_bam_16_min_attention": -1.1611019372940063,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 6.662568445496703,
      "attention_bam_16_attention_skewness": 1.6026950813635896,
      "attention_bam_16_attention_sparsity": 0.475830078125,
      "attention_bam_16_attention_concentration_10": 0.7654916047931346,
      "attention_bam_16_attention_concentration_20": 1.1641686724139646,
      "attention_bam_16_attention_center_y": 0.47188143584748715,
      "attention_bam_16_attention_center_x": 0.4536526463884713,
      "attention_bam_16_attention_center_distance": 0.07666460508984654,
      "attention_bam_16_attention_spatial_variance": 42.32622840859376,
      "attention_bam_16_attention_spatial_std": 6.505861081255405,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 7.735322591823821,
      "attention_bam_16_peak_intensity_mean": 0.20142525434494019,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 144,
      "phase": "train",
      "loss": 0.01606033742427826,
      "timestamp": 1759543903.7191894,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.01606033742427826,
      "ssim": 0.7295436263084412,
      "attention_bam_384_mean_attention": 0.16325049102306366,
      "attention_bam_384_std_attention": 0.5410979390144348,
      "attention_bam_384_max_attention": 4.230222225189209,
      "attention_bam_384_min_attention": -1.4386793375015259,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8021315038753922,
      "attention_bam_384_attention_skewness": 0.8636369494945377,
      "attention_bam_384_attention_sparsity": 0.49386342366536456,
      "attention_bam_384_attention_concentration_10": 0.7604819886799618,
      "attention_bam_384_attention_concentration_20": 1.1846856133617314,
      "attention_bam_384_attention_center_y": 0.4863655684809577,
      "attention_bam_384_attention_center_x": 0.4910460551282586,
      "attention_bam_384_attention_center_distance": 0.02306819679184476,
      "attention_bam_384_attention_spatial_variance": 169.6703387611978,
      "attention_bam_384_attention_spatial_std": 13.025756744281608,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 10.676092112277066,
      "attention_bam_384_peak_intensity_mean": 0.28520697355270386,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18498361110687256,
      "attention_bam_16_std_attention": 0.6489489674568176,
      "attention_bam_16_max_attention": 3.411390781402588,
      "attention_bam_16_min_attention": -1.1675609350204468,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.030310322870643,
      "attention_bam_16_attention_skewness": 1.1507056244020686,
      "attention_bam_16_attention_sparsity": 0.506591796875,
      "attention_bam_16_attention_concentration_10": 0.8510897338707268,
      "attention_bam_16_attention_concentration_20": 1.2738981830082137,
      "attention_bam_16_attention_center_y": 0.47552907461385263,
      "attention_bam_16_attention_center_x": 0.48977281003109635,
      "attention_bam_16_attention_center_distance": 0.03750790860377142,
      "attention_bam_16_attention_spatial_variance": 41.65023676323617,
      "attention_bam_16_attention_spatial_std": 6.453699463349388,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 7.723139367797984,
      "attention_bam_16_peak_intensity_mean": 0.3041437864303589,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 145,
      "phase": "train",
      "loss": 0.014669719152152538,
      "timestamp": 1759543903.8491797,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.014669719152152538,
      "ssim": 0.7669651508331299,
      "attention_bam_384_mean_attention": 0.17045362293720245,
      "attention_bam_384_std_attention": 0.5545074939727783,
      "attention_bam_384_max_attention": 3.713916301727295,
      "attention_bam_384_min_attention": -1.3960769176483154,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.2791509339988334,
      "attention_bam_384_attention_skewness": 0.5588106480397227,
      "attention_bam_384_attention_sparsity": 0.48514048258463544,
      "attention_bam_384_attention_concentration_10": 0.725145619434404,
      "attention_bam_384_attention_concentration_20": 1.1701943022271162,
      "attention_bam_384_attention_center_y": 0.48459286180250644,
      "attention_bam_384_attention_center_x": 0.48352590236523174,
      "attention_bam_384_attention_center_distance": 0.03189908463628831,
      "attention_bam_384_attention_spatial_variance": 168.5333899301698,
      "attention_bam_384_attention_spatial_std": 12.982041054093528,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 16.150389300796462,
      "attention_bam_384_peak_intensity_mean": 0.3119887113571167,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20758378505706787,
      "attention_bam_16_std_attention": 0.6686274409294128,
      "attention_bam_16_max_attention": 3.238940477371216,
      "attention_bam_16_min_attention": -1.0824934244155884,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.4129226746059289,
      "attention_bam_16_attention_skewness": 0.7295189951397496,
      "attention_bam_16_attention_sparsity": 0.4912109375,
      "attention_bam_16_attention_concentration_10": 0.7440648403238895,
      "attention_bam_16_attention_concentration_20": 1.1874797928351002,
      "attention_bam_16_attention_center_y": 0.4703425985383341,
      "attention_bam_16_attention_center_x": 0.46887285096730974,
      "attention_bam_16_attention_center_distance": 0.060802316869700494,
      "attention_bam_16_attention_spatial_variance": 40.988027328773555,
      "attention_bam_16_attention_spatial_std": 6.402189260618086,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 7.366846824929818,
      "attention_bam_16_peak_intensity_mean": 0.3253222107887268,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 146,
      "phase": "train",
      "loss": 0.015403184108436108,
      "timestamp": 1759543903.9796221,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.015403184108436108,
      "ssim": 0.7615155577659607,
      "attention_bam_384_mean_attention": 0.16795724630355835,
      "attention_bam_384_std_attention": 0.5154668092727661,
      "attention_bam_384_max_attention": 4.306217193603516,
      "attention_bam_384_min_attention": -1.4656920433044434,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0906549259520197,
      "attention_bam_384_attention_skewness": 0.6352865586841021,
      "attention_bam_384_attention_sparsity": 0.47644297281901044,
      "attention_bam_384_attention_concentration_10": 0.6935840677866808,
      "attention_bam_384_attention_concentration_20": 1.1046894416732569,
      "attention_bam_384_attention_center_y": 0.47915014232159187,
      "attention_bam_384_attention_center_x": 0.4862671825198651,
      "attention_bam_384_attention_center_distance": 0.03530741681722334,
      "attention_bam_384_attention_spatial_variance": 170.04150338361308,
      "attention_bam_384_attention_spatial_std": 13.03999629538341,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 17.15846296854913,
      "attention_bam_384_peak_intensity_mean": 0.2864462733268738,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18723931908607483,
      "attention_bam_16_std_attention": 0.5982174873352051,
      "attention_bam_16_max_attention": 3.057715892791748,
      "attention_bam_16_min_attention": -1.0480324029922485,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5329571093021035,
      "attention_bam_16_attention_skewness": 0.6946503752416604,
      "attention_bam_16_attention_sparsity": 0.485107421875,
      "attention_bam_16_attention_concentration_10": 0.7356600472725594,
      "attention_bam_16_attention_concentration_20": 1.171927109771278,
      "attention_bam_16_attention_center_y": 0.45343166470324153,
      "attention_bam_16_attention_center_x": 0.477286617244155,
      "attention_bam_16_attention_center_distance": 0.07327356424420525,
      "attention_bam_16_attention_spatial_variance": 41.657128822906785,
      "attention_bam_16_attention_spatial_std": 6.454233403194123,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.735654740389595,
      "attention_bam_16_peak_intensity_mean": 0.30449753999710083,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 147,
      "phase": "train",
      "loss": 0.01455793809145689,
      "timestamp": 1759543904.1110241,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.01455793809145689,
      "ssim": 0.7357597351074219,
      "attention_bam_384_mean_attention": 0.16934321820735931,
      "attention_bam_384_std_attention": 0.5513037443161011,
      "attention_bam_384_max_attention": 4.816652774810791,
      "attention_bam_384_min_attention": -1.3710829019546509,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.4042351671001994,
      "attention_bam_384_attention_skewness": 0.9612256568159842,
      "attention_bam_384_attention_sparsity": 0.48944854736328125,
      "attention_bam_384_attention_concentration_10": 0.748289663550125,
      "attention_bam_384_attention_concentration_20": 1.1610762609839513,
      "attention_bam_384_attention_center_y": 0.4842422649427095,
      "attention_bam_384_attention_center_x": 0.4808515755236192,
      "attention_bam_384_attention_center_distance": 0.03507045406217097,
      "attention_bam_384_attention_spatial_variance": 167.08087798156726,
      "attention_bam_384_attention_spatial_std": 12.925976867593693,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 12.488593947101272,
      "attention_bam_384_peak_intensity_mean": 0.2535953223705292,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1980426013469696,
      "attention_bam_16_std_attention": 0.6761423945426941,
      "attention_bam_16_max_attention": 4.460664749145508,
      "attention_bam_16_min_attention": -1.1326154470443726,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.7080097032174537,
      "attention_bam_16_attention_skewness": 1.384202865749232,
      "attention_bam_16_attention_sparsity": 0.501220703125,
      "attention_bam_16_attention_concentration_10": 0.82058075842224,
      "attention_bam_16_attention_concentration_20": 1.2318699778500632,
      "attention_bam_16_attention_center_y": 0.47192090903030554,
      "attention_bam_16_attention_center_x": 0.46357182544586084,
      "attention_bam_16_attention_center_distance": 0.06504532651976172,
      "attention_bam_16_attention_spatial_variance": 39.47168520702132,
      "attention_bam_16_attention_spatial_std": 6.282649537179463,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 7.133777721965423,
      "attention_bam_16_peak_intensity_mean": 0.25619250535964966,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 148,
      "phase": "train",
      "loss": 0.011368323117494583,
      "timestamp": 1759543904.2404249,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.011368323117494583,
      "ssim": 0.788063108921051,
      "attention_bam_384_mean_attention": 0.17053638398647308,
      "attention_bam_384_std_attention": 0.5447936654090881,
      "attention_bam_384_max_attention": 3.7034292221069336,
      "attention_bam_384_min_attention": -1.4709349870681763,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1234238604461435,
      "attention_bam_384_attention_skewness": 0.6746253098692803,
      "attention_bam_384_attention_sparsity": 0.48014068603515625,
      "attention_bam_384_attention_concentration_10": 0.7276142012635667,
      "attention_bam_384_attention_concentration_20": 1.144013014923909,
      "attention_bam_384_attention_center_y": 0.49068344886505777,
      "attention_bam_384_attention_center_x": 0.48155304613805516,
      "attention_bam_384_attention_center_distance": 0.029226297467681902,
      "attention_bam_384_attention_spatial_variance": 170.56445318610537,
      "attention_bam_384_attention_spatial_std": 13.060032664052008,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 16.050836082571095,
      "attention_bam_384_peak_intensity_mean": 0.31725484132766724,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20077842473983765,
      "attention_bam_16_std_attention": 0.6371825933456421,
      "attention_bam_16_max_attention": 3.339731216430664,
      "attention_bam_16_min_attention": -1.384159803390503,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6425764552835385,
      "attention_bam_16_attention_skewness": 0.7285550060170377,
      "attention_bam_16_attention_sparsity": 0.481689453125,
      "attention_bam_16_attention_concentration_10": 0.7287014439263234,
      "attention_bam_16_attention_concentration_20": 1.1647092936988013,
      "attention_bam_16_attention_center_y": 0.48437159216519704,
      "attention_bam_16_attention_center_x": 0.46530713376302474,
      "attention_bam_16_attention_center_distance": 0.053811561939560694,
      "attention_bam_16_attention_spatial_variance": 42.359482078510915,
      "attention_bam_16_attention_spatial_std": 6.508416249634846,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.445158592083615,
      "attention_bam_16_peak_intensity_mean": 0.34160149097442627,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 149,
      "phase": "train",
      "loss": 0.010426566004753113,
      "timestamp": 1759543904.369889,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.010426566004753113,
      "ssim": 0.7738374471664429,
      "attention_bam_384_mean_attention": 0.1686343401670456,
      "attention_bam_384_std_attention": 0.5356895923614502,
      "attention_bam_384_max_attention": 3.807150363922119,
      "attention_bam_384_min_attention": -1.4553546905517578,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.314243433869417,
      "attention_bam_384_attention_skewness": 0.7810973054245759,
      "attention_bam_384_attention_sparsity": 0.48541514078776044,
      "attention_bam_384_attention_concentration_10": 0.738367855673383,
      "attention_bam_384_attention_concentration_20": 1.145929070540486,
      "attention_bam_384_attention_center_y": 0.4911382721376774,
      "attention_bam_384_attention_center_x": 0.47957583972500195,
      "attention_bam_384_attention_center_distance": 0.0314857600716474,
      "attention_bam_384_attention_spatial_variance": 173.03030477070675,
      "attention_bam_384_attention_spatial_std": 13.154098402045909,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 18.547917925343405,
      "attention_bam_384_peak_intensity_mean": 0.3111734092235565,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19175496697425842,
      "attention_bam_16_std_attention": 0.6355879902839661,
      "attention_bam_16_max_attention": 3.2889404296875,
      "attention_bam_16_min_attention": -1.2090363502502441,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.3542005870061562,
      "attention_bam_16_attention_skewness": 0.9522061567612273,
      "attention_bam_16_attention_sparsity": 0.491455078125,
      "attention_bam_16_attention_concentration_10": 0.7840598306239597,
      "attention_bam_16_attention_concentration_20": 1.2099806363592092,
      "attention_bam_16_attention_center_y": 0.49011962954146715,
      "attention_bam_16_attention_center_x": 0.45520503758820896,
      "attention_bam_16_attention_center_distance": 0.06487234199366662,
      "attention_bam_16_attention_spatial_variance": 43.7246235483708,
      "attention_bam_16_attention_spatial_std": 6.612459719980969,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.347400378432678,
      "attention_bam_16_peak_intensity_mean": 0.3190714418888092,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 150,
      "phase": "train",
      "loss": 0.01082709338515997,
      "timestamp": 1759543904.5415096,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.01082709338515997,
      "ssim": 0.7650290727615356,
      "attention_bam_384_mean_attention": 0.1741958111524582,
      "attention_bam_384_std_attention": 0.4799386262893677,
      "attention_bam_384_max_attention": 3.779201030731201,
      "attention_bam_384_min_attention": -1.3791297674179077,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0184390136978578,
      "attention_bam_384_attention_skewness": 0.5892438332081626,
      "attention_bam_384_attention_sparsity": 0.4617767333984375,
      "attention_bam_384_attention_concentration_10": 0.6353607764620526,
      "attention_bam_384_attention_concentration_20": 1.0096749814827324,
      "attention_bam_384_attention_center_y": 0.48034957193822914,
      "attention_bam_384_attention_center_x": 0.4846003985716354,
      "attention_bam_384_attention_center_distance": 0.03530685619432353,
      "attention_bam_384_attention_spatial_variance": 171.04864025238626,
      "attention_bam_384_attention_spatial_std": 13.078556504920039,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 19.597918007578517,
      "attention_bam_384_peak_intensity_mean": 0.3025730848312378,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20623520016670227,
      "attention_bam_16_std_attention": 0.5872301459312439,
      "attention_bam_16_max_attention": 2.9654970169067383,
      "attention_bam_16_min_attention": -0.999289870262146,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5672034510391164,
      "attention_bam_16_attention_skewness": 0.6305024116474286,
      "attention_bam_16_attention_sparsity": 0.4677734375,
      "attention_bam_16_attention_concentration_10": 0.657803241417018,
      "attention_bam_16_attention_concentration_20": 1.0533452888234658,
      "attention_bam_16_attention_center_y": 0.45657382708550187,
      "attention_bam_16_attention_center_x": 0.47094967454817643,
      "attention_bam_16_attention_center_distance": 0.07388848222634918,
      "attention_bam_16_attention_spatial_variance": 42.36721337953908,
      "attention_bam_16_attention_spatial_std": 6.509010168953424,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.350085788768995,
      "attention_bam_16_peak_intensity_mean": 0.3057723045349121,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 151,
      "phase": "train",
      "loss": 0.0130386371165514,
      "timestamp": 1759543904.6696355,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0130386371165514,
      "ssim": 0.7318618297576904,
      "attention_bam_384_mean_attention": 0.1685047298669815,
      "attention_bam_384_std_attention": 0.5207090973854065,
      "attention_bam_384_max_attention": 4.279864311218262,
      "attention_bam_384_min_attention": -1.443182349205017,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1993122124142204,
      "attention_bam_384_attention_skewness": 0.7384793863681993,
      "attention_bam_384_attention_sparsity": 0.48641713460286456,
      "attention_bam_384_attention_concentration_10": 0.7141074864984341,
      "attention_bam_384_attention_concentration_20": 1.1247098113561356,
      "attention_bam_384_attention_center_y": 0.4774634964188209,
      "attention_bam_384_attention_center_x": 0.4830919461514446,
      "attention_bam_384_attention_center_distance": 0.0398441031674738,
      "attention_bam_384_attention_spatial_variance": 170.75197990687383,
      "attention_bam_384_attention_spatial_std": 13.067210104183442,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 19.700314131582125,
      "attention_bam_384_peak_intensity_mean": 0.2860713303089142,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1857975870370865,
      "attention_bam_16_std_attention": 0.6181589961051941,
      "attention_bam_16_max_attention": 2.907565116882324,
      "attention_bam_16_min_attention": -1.0637726783752441,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5599250465949916,
      "attention_bam_16_attention_skewness": 0.7713898264199236,
      "attention_bam_16_attention_sparsity": 0.489501953125,
      "attention_bam_16_attention_concentration_10": 0.7724839828380533,
      "attention_bam_16_attention_concentration_20": 1.2190002698605087,
      "attention_bam_16_attention_center_y": 0.45181346839453906,
      "attention_bam_16_attention_center_x": 0.4671170293354258,
      "attention_bam_16_attention_center_distance": 0.0825012919643242,
      "attention_bam_16_attention_spatial_variance": 42.107482741391465,
      "attention_bam_16_attention_spatial_std": 6.489027873371439,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 10.468042051540571,
      "attention_bam_16_peak_intensity_mean": 0.3282340168952942,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 152,
      "phase": "train",
      "loss": 0.011072240769863129,
      "timestamp": 1759543904.8003452,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.011072240769863129,
      "ssim": 0.7858601212501526,
      "attention_bam_384_mean_attention": 0.17300017178058624,
      "attention_bam_384_std_attention": 0.5051867365837097,
      "attention_bam_384_max_attention": 4.237845420837402,
      "attention_bam_384_min_attention": -1.4566600322723389,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.47973916447433274,
      "attention_bam_384_attention_skewness": 0.5115274976843484,
      "attention_bam_384_attention_sparsity": 0.471954345703125,
      "attention_bam_384_attention_concentration_10": 0.65513402188294,
      "attention_bam_384_attention_concentration_20": 1.0586015271634563,
      "attention_bam_384_attention_center_y": 0.4853127627830016,
      "attention_bam_384_attention_center_x": 0.482543819410753,
      "attention_bam_384_attention_center_distance": 0.03226246047135231,
      "attention_bam_384_attention_spatial_variance": 169.6032271730385,
      "attention_bam_384_attention_spatial_std": 13.023180378580284,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 17.251903603376643,
      "attention_bam_384_peak_intensity_mean": 0.28773757815361023,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20701321959495544,
      "attention_bam_16_std_attention": 0.6170648336410522,
      "attention_bam_16_max_attention": 2.7359535694122314,
      "attention_bam_16_min_attention": -1.1924470663070679,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.22320816122296305,
      "attention_bam_16_attention_skewness": 0.6427893030075139,
      "attention_bam_16_attention_sparsity": 0.4755859375,
      "attention_bam_16_attention_concentration_10": 0.691980851135002,
      "attention_bam_16_attention_concentration_20": 1.1102697571250062,
      "attention_bam_16_attention_center_y": 0.47338184150674484,
      "attention_bam_16_attention_center_x": 0.467152465091311,
      "attention_bam_16_attention_center_distance": 0.059791084806174837,
      "attention_bam_16_attention_spatial_variance": 41.58317335518609,
      "attention_bam_16_attention_spatial_std": 6.448501636441297,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.810880122508413,
      "attention_bam_16_peak_intensity_mean": 0.3634525239467621,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 153,
      "phase": "train",
      "loss": 0.012158561497926712,
      "timestamp": 1759543904.9320018,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.012158561497926712,
      "ssim": 0.7745479941368103,
      "attention_bam_384_mean_attention": 0.1687934398651123,
      "attention_bam_384_std_attention": 0.5065830945968628,
      "attention_bam_384_max_attention": 3.965653896331787,
      "attention_bam_384_min_attention": -1.4180082082748413,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5430952998793837,
      "attention_bam_384_attention_skewness": 0.5976428175367297,
      "attention_bam_384_attention_sparsity": 0.48206329345703125,
      "attention_bam_384_attention_concentration_10": 0.6843119280308474,
      "attention_bam_384_attention_concentration_20": 1.0964947716783358,
      "attention_bam_384_attention_center_y": 0.4837154054669627,
      "attention_bam_384_attention_center_x": 0.4913877856289247,
      "attention_bam_384_attention_center_distance": 0.026052188218220158,
      "attention_bam_384_attention_spatial_variance": 170.0105894298148,
      "attention_bam_384_attention_spatial_std": 13.038810890177631,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 15.749177123197502,
      "attention_bam_384_peak_intensity_mean": 0.2955654561519623,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2000313401222229,
      "attention_bam_16_std_attention": 0.600017786026001,
      "attention_bam_16_max_attention": 2.725856304168701,
      "attention_bam_16_min_attention": -1.0474169254302979,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.11978680152507382,
      "attention_bam_16_attention_skewness": 0.6321585644566446,
      "attention_bam_16_attention_sparsity": 0.486572265625,
      "attention_bam_16_attention_concentration_10": 0.6902479581818924,
      "attention_bam_16_attention_concentration_20": 1.1114217681851282,
      "attention_bam_16_attention_center_y": 0.4690539714884095,
      "attention_bam_16_attention_center_x": 0.48969225243355974,
      "attention_bam_16_attention_center_distance": 0.04612822000757514,
      "attention_bam_16_attention_spatial_variance": 41.72591102273633,
      "attention_bam_16_attention_spatial_std": 6.459559661674805,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.60810208784006,
      "attention_bam_16_peak_intensity_mean": 0.32986098527908325,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 154,
      "phase": "train",
      "loss": 0.012915875762701035,
      "timestamp": 1759543905.0631561,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.012915875762701035,
      "ssim": 0.7875270247459412,
      "attention_bam_384_mean_attention": 0.17212367057800293,
      "attention_bam_384_std_attention": 0.5051249861717224,
      "attention_bam_384_max_attention": 4.364995002746582,
      "attention_bam_384_min_attention": -1.4347385168075562,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.5078745464387984,
      "attention_bam_384_attention_skewness": 0.904081232820254,
      "attention_bam_384_attention_sparsity": 0.47332509358723956,
      "attention_bam_384_attention_concentration_10": 0.6828473966174342,
      "attention_bam_384_attention_concentration_20": 1.0590279557320221,
      "attention_bam_384_attention_center_y": 0.48763735625091276,
      "attention_bam_384_attention_center_x": 0.4815561338242224,
      "attention_bam_384_attention_center_distance": 0.03140099234026971,
      "attention_bam_384_attention_spatial_variance": 168.64189667745816,
      "attention_bam_384_attention_spatial_std": 12.98621949134767,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 18.4332387801684,
      "attention_bam_384_peak_intensity_mean": 0.27723515033721924,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.21111075580120087,
      "attention_bam_16_std_attention": 0.6357596516609192,
      "attention_bam_16_max_attention": 4.017589569091797,
      "attention_bam_16_min_attention": -1.1965217590332031,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.8052995680845783,
      "attention_bam_16_attention_skewness": 1.105554571517433,
      "attention_bam_16_attention_sparsity": 0.46923828125,
      "attention_bam_16_attention_concentration_10": 0.7091819862739704,
      "attention_bam_16_attention_concentration_20": 1.0907546711151854,
      "attention_bam_16_attention_center_y": 0.4791213689373799,
      "attention_bam_16_attention_center_x": 0.46258298867853637,
      "attention_bam_16_attention_center_distance": 0.06059620402763762,
      "attention_bam_16_attention_spatial_variance": 41.09305691968636,
      "attention_bam_16_attention_spatial_std": 6.410386643540806,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 7.917222466762949,
      "attention_bam_16_peak_intensity_mean": 0.2800446152687073,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 155,
      "phase": "train",
      "loss": 0.010304424911737442,
      "timestamp": 1759543905.196757,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.010304424911737442,
      "ssim": 0.7972153425216675,
      "attention_bam_384_mean_attention": 0.16610336303710938,
      "attention_bam_384_std_attention": 0.5434231758117676,
      "attention_bam_384_max_attention": 4.63404655456543,
      "attention_bam_384_min_attention": -1.4315621852874756,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8780575337032799,
      "attention_bam_384_attention_skewness": 0.9022657954859029,
      "attention_bam_384_attention_sparsity": 0.49162546793619794,
      "attention_bam_384_attention_concentration_10": 0.7589290327950519,
      "attention_bam_384_attention_concentration_20": 1.175359462676561,
      "attention_bam_384_attention_center_y": 0.49057118793022125,
      "attention_bam_384_attention_center_x": 0.4808249704877348,
      "attention_bam_384_attention_center_distance": 0.03021867812606786,
      "attention_bam_384_attention_spatial_variance": 170.23444152260262,
      "attention_bam_384_attention_spatial_std": 13.047392134928828,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 19.06183538771448,
      "attention_bam_384_peak_intensity_mean": 0.2647281587123871,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18774625658988953,
      "attention_bam_16_std_attention": 0.664514422416687,
      "attention_bam_16_max_attention": 3.7435407638549805,
      "attention_bam_16_min_attention": -1.0539772510528564,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.325980667626272,
      "attention_bam_16_attention_skewness": 1.1938035241769924,
      "attention_bam_16_attention_sparsity": 0.503173828125,
      "attention_bam_16_attention_concentration_10": 0.8462577457709899,
      "attention_bam_16_attention_concentration_20": 1.2789499817206496,
      "attention_bam_16_attention_center_y": 0.4929370246526051,
      "attention_bam_16_attention_center_x": 0.4632935934082399,
      "attention_bam_16_attention_center_distance": 0.05286295310777706,
      "attention_bam_16_attention_spatial_variance": 42.15901580056751,
      "attention_bam_16_attention_spatial_std": 6.492997443443784,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.39549076337123,
      "attention_bam_16_peak_intensity_mean": 0.2596574127674103,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 156,
      "phase": "train",
      "loss": 0.01284073106944561,
      "timestamp": 1759543905.3246384,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.01284073106944561,
      "ssim": 0.7624608278274536,
      "attention_bam_384_mean_attention": 0.1698429435491562,
      "attention_bam_384_std_attention": 0.5279277563095093,
      "attention_bam_384_max_attention": 4.375811576843262,
      "attention_bam_384_min_attention": -1.3632311820983887,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.6872136768937303,
      "attention_bam_384_attention_skewness": 0.7684297650466686,
      "attention_bam_384_attention_sparsity": 0.4772898356119792,
      "attention_bam_384_attention_concentration_10": 0.7114867856546447,
      "attention_bam_384_attention_concentration_20": 1.1142486817822563,
      "attention_bam_384_attention_center_y": 0.48535100775413004,
      "attention_bam_384_attention_center_x": 0.48762750032450525,
      "attention_bam_384_attention_center_distance": 0.027117216746549638,
      "attention_bam_384_attention_spatial_variance": 168.7174447774982,
      "attention_bam_384_attention_spatial_std": 12.989127945227816,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 16.79104501405047,
      "attention_bam_384_peak_intensity_mean": 0.26747560501098633,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20825308561325073,
      "attention_bam_16_std_attention": 0.6476866006851196,
      "attention_bam_16_max_attention": 3.765005111694336,
      "attention_bam_16_min_attention": -1.2079449892044067,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.7998285408284653,
      "attention_bam_16_attention_skewness": 0.9700886375926282,
      "attention_bam_16_attention_sparsity": 0.47412109375,
      "attention_bam_16_attention_concentration_10": 0.7292812888179704,
      "attention_bam_16_attention_concentration_20": 1.133880352268551,
      "attention_bam_16_attention_center_y": 0.47368647601625413,
      "attention_bam_16_attention_center_x": 0.4811410664518803,
      "attention_bam_16_attention_center_distance": 0.04578342317947759,
      "attention_bam_16_attention_spatial_variance": 41.344515125705755,
      "attention_bam_16_attention_spatial_std": 6.429970071913691,
      "attention_bam_16_num_attention_peaks": 2,
      "attention_bam_16_peak_separation_mean": 8.039900496896712,
      "attention_bam_16_peak_intensity_mean": 0.2841978669166565,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 157,
      "phase": "train",
      "loss": 0.012962063774466515,
      "timestamp": 1759543905.45682,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.012962063774466515,
      "ssim": 0.7625176906585693,
      "attention_bam_384_mean_attention": 0.16692166030406952,
      "attention_bam_384_std_attention": 0.515139102935791,
      "attention_bam_384_max_attention": 4.260313034057617,
      "attention_bam_384_min_attention": -1.4900639057159424,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.789958452022372,
      "attention_bam_384_attention_skewness": 0.857667867527762,
      "attention_bam_384_attention_sparsity": 0.4823455810546875,
      "attention_bam_384_attention_concentration_10": 0.721497035865876,
      "attention_bam_384_attention_concentration_20": 1.1119291188344307,
      "attention_bam_384_attention_center_y": 0.48300510839374255,
      "attention_bam_384_attention_center_x": 0.4872064849789798,
      "attention_bam_384_attention_center_distance": 0.030083230122495478,
      "attention_bam_384_attention_spatial_variance": 172.78322503645214,
      "attention_bam_384_attention_spatial_std": 13.144703307281308,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 17.173624705847097,
      "attention_bam_384_peak_intensity_mean": 0.29019036889076233,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19283470511436462,
      "attention_bam_16_std_attention": 0.6091687679290771,
      "attention_bam_16_max_attention": 3.750261068344116,
      "attention_bam_16_min_attention": -1.1662577390670776,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.6282796062066929,
      "attention_bam_16_attention_skewness": 0.9388081445941269,
      "attention_bam_16_attention_sparsity": 0.4833984375,
      "attention_bam_16_attention_concentration_10": 0.7484992950173524,
      "attention_bam_16_attention_concentration_20": 1.1451878452372832,
      "attention_bam_16_attention_center_y": 0.46567045337098145,
      "attention_bam_16_attention_center_x": 0.4774275989632022,
      "attention_bam_16_attention_center_distance": 0.05810389075302943,
      "attention_bam_16_attention_spatial_variance": 43.67993228274832,
      "attention_bam_16_attention_spatial_std": 6.609079533698193,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.07662107027146,
      "attention_bam_16_peak_intensity_mean": 0.28703510761260986,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 158,
      "phase": "train",
      "loss": 0.008918299339711666,
      "timestamp": 1759543905.5878043,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008918299339711666,
      "ssim": 0.8261681795120239,
      "attention_bam_384_mean_attention": 0.16658200323581696,
      "attention_bam_384_std_attention": 0.5403400659561157,
      "attention_bam_384_max_attention": 4.827775001525879,
      "attention_bam_384_min_attention": -1.406973958015442,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.337035022180296,
      "attention_bam_384_attention_skewness": 1.1415094285282605,
      "attention_bam_384_attention_sparsity": 0.49320729573567706,
      "attention_bam_384_attention_concentration_10": 0.7558298815637082,
      "attention_bam_384_attention_concentration_20": 1.156830818189958,
      "attention_bam_384_attention_center_y": 0.48994793451052737,
      "attention_bam_384_attention_center_x": 0.48486541970999536,
      "attention_bam_384_attention_center_distance": 0.02569433949955684,
      "attention_bam_384_attention_spatial_variance": 171.4462730501396,
      "attention_bam_384_attention_spatial_std": 13.093749388549469,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 15.640942115536696,
      "attention_bam_384_peak_intensity_mean": 0.2542608976364136,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19678160548210144,
      "attention_bam_16_std_attention": 0.6504195928573608,
      "attention_bam_16_max_attention": 4.140196800231934,
      "attention_bam_16_min_attention": -1.0230071544647217,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 4.028071978245494,
      "attention_bam_16_attention_skewness": 1.3921371806964422,
      "attention_bam_16_attention_sparsity": 0.491943359375,
      "attention_bam_16_attention_concentration_10": 0.7754690177469843,
      "attention_bam_16_attention_concentration_20": 1.1773054849279831,
      "attention_bam_16_attention_center_y": 0.484460544748469,
      "attention_bam_16_attention_center_x": 0.4730552978625976,
      "attention_bam_16_attention_center_distance": 0.04398844490971855,
      "attention_bam_16_attention_spatial_variance": 43.06090308037571,
      "attention_bam_16_attention_spatial_std": 6.56208069749037,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.613906056204215,
      "attention_bam_16_peak_intensity_mean": 0.24371245503425598,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 159,
      "phase": "train",
      "loss": 0.01071099005639553,
      "timestamp": 1759543905.719607,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.01071099005639553,
      "ssim": 0.787902295589447,
      "attention_bam_384_mean_attention": 0.16953031718730927,
      "attention_bam_384_std_attention": 0.5079508423805237,
      "attention_bam_384_max_attention": 3.4970078468322754,
      "attention_bam_384_min_attention": -1.3448822498321533,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.42514097313658006,
      "attention_bam_384_attention_skewness": 0.5374904252526977,
      "attention_bam_384_attention_sparsity": 0.48158009847005206,
      "attention_bam_384_attention_concentration_10": 0.6725041428660828,
      "attention_bam_384_attention_concentration_20": 1.0867264208212848,
      "attention_bam_384_attention_center_y": 0.4910677580146589,
      "attention_bam_384_attention_center_x": 0.480633549156971,
      "attention_bam_384_attention_center_distance": 0.030161046571369154,
      "attention_bam_384_attention_spatial_variance": 172.0966454417762,
      "attention_bam_384_attention_spatial_std": 13.118561104091263,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 18.437511247489947,
      "attention_bam_384_peak_intensity_mean": 0.3157607614994049,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20984195172786713,
      "attention_bam_16_std_attention": 0.6268020868301392,
      "attention_bam_16_max_attention": 2.6503279209136963,
      "attention_bam_16_min_attention": -1.1071901321411133,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.2025164728194757,
      "attention_bam_16_attention_skewness": 0.6335665635210795,
      "attention_bam_16_attention_sparsity": 0.470947265625,
      "attention_bam_16_attention_concentration_10": 0.6849644463821863,
      "attention_bam_16_attention_concentration_20": 1.102594009256284,
      "attention_bam_16_attention_center_y": 0.4902697616535744,
      "attention_bam_16_attention_center_x": 0.458554232402959,
      "attention_bam_16_attention_center_distance": 0.060206796792159345,
      "attention_bam_16_attention_spatial_variance": 43.13747227265178,
      "attention_bam_16_attention_spatial_std": 6.5679123222415035,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.784414098176075,
      "attention_bam_16_peak_intensity_mean": 0.3626616895198822,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 160,
      "phase": "train",
      "loss": 0.01200124528259039,
      "timestamp": 1759543905.888198,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.01200124528259039,
      "ssim": 0.7787598371505737,
      "attention_bam_384_mean_attention": 0.162216454744339,
      "attention_bam_384_std_attention": 0.5071648359298706,
      "attention_bam_384_max_attention": 3.8349404335021973,
      "attention_bam_384_min_attention": -1.4046118259429932,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.6552513472477255,
      "attention_bam_384_attention_skewness": 0.9199346563533372,
      "attention_bam_384_attention_sparsity": 0.5000991821289062,
      "attention_bam_384_attention_concentration_10": 0.7422322026806816,
      "attention_bam_384_attention_concentration_20": 1.1437773324824103,
      "attention_bam_384_attention_center_y": 0.48446064341125644,
      "attention_bam_384_attention_center_x": 0.47863598663159757,
      "attention_bam_384_attention_center_distance": 0.03736021066314818,
      "attention_bam_384_attention_spatial_variance": 169.41998140243706,
      "attention_bam_384_attention_spatial_std": 13.016143107788768,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 17.300166153734224,
      "attention_bam_384_peak_intensity_mean": 0.29915285110473633,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18591459095478058,
      "attention_bam_16_std_attention": 0.6129887104034424,
      "attention_bam_16_max_attention": 3.2468020915985107,
      "attention_bam_16_min_attention": -1.0446536540985107,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.255171338205919,
      "attention_bam_16_attention_skewness": 0.9793254597330218,
      "attention_bam_16_attention_sparsity": 0.501708984375,
      "attention_bam_16_attention_concentration_10": 0.7854806754057488,
      "attention_bam_16_attention_concentration_20": 1.2125048200392259,
      "attention_bam_16_attention_center_y": 0.47084626685348624,
      "attention_bam_16_attention_center_x": 0.4545967664410203,
      "attention_bam_16_attention_center_distance": 0.07630719198069594,
      "attention_bam_16_attention_spatial_variance": 41.06629109850005,
      "attention_bam_16_attention_spatial_std": 6.408298611839187,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.762440834553125,
      "attention_bam_16_peak_intensity_mean": 0.28475895524024963,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 161,
      "phase": "train",
      "loss": 0.01225089468061924,
      "timestamp": 1759543906.0314262,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.01225089468061924,
      "ssim": 0.7785990238189697,
      "attention_bam_384_mean_attention": 0.166873499751091,
      "attention_bam_384_std_attention": 0.48178836703300476,
      "attention_bam_384_max_attention": 4.036611557006836,
      "attention_bam_384_min_attention": -1.434733510017395,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4164805840359183,
      "attention_bam_384_attention_skewness": 0.6340652052071146,
      "attention_bam_384_attention_sparsity": 0.46555836995442706,
      "attention_bam_384_attention_concentration_10": 0.6607618890683594,
      "attention_bam_384_attention_concentration_20": 1.0438609608883638,
      "attention_bam_384_attention_center_y": 0.48408992278424684,
      "attention_bam_384_attention_center_x": 0.4854931092675281,
      "attention_bam_384_attention_center_distance": 0.03044931643683015,
      "attention_bam_384_attention_spatial_variance": 172.83088717817085,
      "attention_bam_384_attention_spatial_std": 13.146516161256216,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 19.331153578906793,
      "attention_bam_384_peak_intensity_mean": 0.29568275809288025,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19007042050361633,
      "attention_bam_16_std_attention": 0.5777944922447205,
      "attention_bam_16_max_attention": 3.5212838649749756,
      "attention_bam_16_min_attention": -1.1051182746887207,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.2585053321307935,
      "attention_bam_16_attention_skewness": 0.7891235900897356,
      "attention_bam_16_attention_sparsity": 0.47607421875,
      "attention_bam_16_attention_concentration_10": 0.7032990707382022,
      "attention_bam_16_attention_concentration_20": 1.1021303117515961,
      "attention_bam_16_attention_center_y": 0.4687487543675605,
      "attention_bam_16_attention_center_x": 0.4723572179569744,
      "attention_bam_16_attention_center_distance": 0.05900447021467588,
      "attention_bam_16_attention_spatial_variance": 44.01504424712026,
      "attention_bam_16_attention_spatial_std": 6.634383486588656,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.436322678195976,
      "attention_bam_16_peak_intensity_mean": 0.2895285189151764,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 162,
      "phase": "train",
      "loss": 0.012274045497179031,
      "timestamp": 1759543906.3547952,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.012274045497179031,
      "ssim": 0.8156254291534424,
      "attention_bam_384_mean_attention": 0.16454850137233734,
      "attention_bam_384_std_attention": 0.5243272185325623,
      "attention_bam_384_max_attention": 3.6772494316101074,
      "attention_bam_384_min_attention": -1.470108151435852,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.3627601426621898,
      "attention_bam_384_attention_skewness": 0.5153457321021709,
      "attention_bam_384_attention_sparsity": 0.48279062906901044,
      "attention_bam_384_attention_concentration_10": 0.7039151306139206,
      "attention_bam_384_attention_concentration_20": 1.138739726662367,
      "attention_bam_384_attention_center_y": 0.487543040616643,
      "attention_bam_384_attention_center_x": 0.4886381654717013,
      "attention_bam_384_attention_center_distance": 0.023843956086482227,
      "attention_bam_384_attention_spatial_variance": 172.59726486566942,
      "attention_bam_384_attention_spatial_std": 13.137627824903149,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 20.546474302671154,
      "attention_bam_384_peak_intensity_mean": 0.32235127687454224,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18903440237045288,
      "attention_bam_16_std_attention": 0.6202760934829712,
      "attention_bam_16_max_attention": 2.8650262355804443,
      "attention_bam_16_min_attention": -1.2102470397949219,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.3931382668561838,
      "attention_bam_16_attention_skewness": 0.6425483135691342,
      "attention_bam_16_attention_sparsity": 0.482666015625,
      "attention_bam_16_attention_concentration_10": 0.7431996067344013,
      "attention_bam_16_attention_concentration_20": 1.1833399233199768,
      "attention_bam_16_attention_center_y": 0.4797858936343832,
      "attention_bam_16_attention_center_x": 0.4776243148986746,
      "attention_bam_16_attention_center_distance": 0.0426446099739263,
      "attention_bam_16_attention_spatial_variance": 43.877355557817936,
      "attention_bam_16_attention_spatial_std": 6.623998456960715,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.015101601147064,
      "attention_bam_16_peak_intensity_mean": 0.3494011163711548,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 163,
      "phase": "train",
      "loss": 0.013061387464404106,
      "timestamp": 1759543906.4862182,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.013061387464404106,
      "ssim": 0.7889271974563599,
      "attention_bam_384_mean_attention": 0.1650305837392807,
      "attention_bam_384_std_attention": 0.5165056586265564,
      "attention_bam_384_max_attention": 3.646787405014038,
      "attention_bam_384_min_attention": -1.4477728605270386,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.48237785178921966,
      "attention_bam_384_attention_skewness": 0.5342915733229392,
      "attention_bam_384_attention_sparsity": 0.48048655192057294,
      "attention_bam_384_attention_concentration_10": 0.705651754402278,
      "attention_bam_384_attention_concentration_20": 1.129334538769163,
      "attention_bam_384_attention_center_y": 0.4868654224600779,
      "attention_bam_384_attention_center_x": 0.4883596502179776,
      "attention_bam_384_attention_center_distance": 0.02481994642218449,
      "attention_bam_384_attention_spatial_variance": 170.7436598634865,
      "attention_bam_384_attention_spatial_std": 13.066891744538427,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 17.10766004737918,
      "attention_bam_384_peak_intensity_mean": 0.31921619176864624,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19245469570159912,
      "attention_bam_16_std_attention": 0.6060044169425964,
      "attention_bam_16_max_attention": 2.792428970336914,
      "attention_bam_16_min_attention": -1.2396190166473389,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.49176310777791077,
      "attention_bam_16_attention_skewness": 0.691501959911584,
      "attention_bam_16_attention_sparsity": 0.48681640625,
      "attention_bam_16_attention_concentration_10": 0.7270376734191824,
      "attention_bam_16_attention_concentration_20": 1.1583811160097524,
      "attention_bam_16_attention_center_y": 0.47832365213664835,
      "attention_bam_16_attention_center_x": 0.4819787621155872,
      "attention_bam_16_attention_center_distance": 0.039865500663596946,
      "attention_bam_16_attention_spatial_variance": 42.61804063290182,
      "attention_bam_16_attention_spatial_std": 6.528249430965534,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.901721849492404,
      "attention_bam_16_peak_intensity_mean": 0.3650215268135071,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 164,
      "phase": "train",
      "loss": 0.012314270250499249,
      "timestamp": 1759543906.6193595,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.012314270250499249,
      "ssim": 0.8028583526611328,
      "attention_bam_384_mean_attention": 0.16364562511444092,
      "attention_bam_384_std_attention": 0.4929617941379547,
      "attention_bam_384_max_attention": 3.4174976348876953,
      "attention_bam_384_min_attention": -1.359971523284912,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.091940646559939,
      "attention_bam_384_attention_skewness": 0.6929571886703986,
      "attention_bam_384_attention_sparsity": 0.4812571207682292,
      "attention_bam_384_attention_concentration_10": 0.6954058699790119,
      "attention_bam_384_attention_concentration_20": 1.0946168749696292,
      "attention_bam_384_attention_center_y": 0.4879015531469944,
      "attention_bam_384_attention_center_x": 0.4822329981872028,
      "attention_bam_384_attention_center_distance": 0.030398643708920328,
      "attention_bam_384_attention_spatial_variance": 168.8726017138489,
      "attention_bam_384_attention_spatial_std": 12.995099142132348,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 17.659589869644744,
      "attention_bam_384_peak_intensity_mean": 0.3209206461906433,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19852469861507416,
      "attention_bam_16_std_attention": 0.6089495420455933,
      "attention_bam_16_max_attention": 3.5545568466186523,
      "attention_bam_16_min_attention": -0.9735555648803711,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.1601936707523937,
      "attention_bam_16_attention_skewness": 0.894654129732202,
      "attention_bam_16_attention_sparsity": 0.488037109375,
      "attention_bam_16_attention_concentration_10": 0.731907493381824,
      "attention_bam_16_attention_concentration_20": 1.1388857134417651,
      "attention_bam_16_attention_center_y": 0.48337597314926917,
      "attention_bam_16_attention_center_x": 0.46563976603163465,
      "attention_bam_16_attention_center_distance": 0.053981180926219605,
      "attention_bam_16_attention_spatial_variance": 41.04897027340187,
      "attention_bam_16_attention_spatial_std": 6.406947032198867,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.746896159654481,
      "attention_bam_16_peak_intensity_mean": 0.2634510397911072,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 165,
      "phase": "train",
      "loss": 0.010861638002097607,
      "timestamp": 1759543906.7516346,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.010861638002097607,
      "ssim": 0.7804886102676392,
      "attention_bam_384_mean_attention": 0.16834880411624908,
      "attention_bam_384_std_attention": 0.5088216662406921,
      "attention_bam_384_max_attention": 3.7616825103759766,
      "attention_bam_384_min_attention": -1.3889517784118652,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.706289917375146,
      "attention_bam_384_attention_skewness": 0.606709422042609,
      "attention_bam_384_attention_sparsity": 0.48113250732421875,
      "attention_bam_384_attention_concentration_10": 0.6918965079962742,
      "attention_bam_384_attention_concentration_20": 1.101867011720098,
      "attention_bam_384_attention_center_y": 0.48263945220990584,
      "attention_bam_384_attention_center_x": 0.48797317066317875,
      "attention_bam_384_attention_center_distance": 0.029867482099071144,
      "attention_bam_384_attention_spatial_variance": 168.70539075595647,
      "attention_bam_384_attention_spatial_std": 12.988663932674386,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 18.37504573051512,
      "attention_bam_384_peak_intensity_mean": 0.3039731979370117,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20493727922439575,
      "attention_bam_16_std_attention": 0.6102845072746277,
      "attention_bam_16_max_attention": 2.817310333251953,
      "attention_bam_16_min_attention": -1.2357138395309448,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8703383898759451,
      "attention_bam_16_attention_skewness": 0.7921874999920664,
      "attention_bam_16_attention_sparsity": 0.480712890625,
      "attention_bam_16_attention_concentration_10": 0.7074192247951587,
      "attention_bam_16_attention_concentration_20": 1.1086547127978896,
      "attention_bam_16_attention_center_y": 0.4666883625093027,
      "attention_bam_16_attention_center_x": 0.4806784192796633,
      "attention_bam_16_attention_center_distance": 0.05446078724814979,
      "attention_bam_16_attention_spatial_variance": 41.08631069219202,
      "attention_bam_16_attention_spatial_std": 6.409860426888562,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 8.610974268816152,
      "attention_bam_16_peak_intensity_mean": 0.35979345440864563,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 166,
      "phase": "train",
      "loss": 0.010890758596360683,
      "timestamp": 1759543906.8802757,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.010890758596360683,
      "ssim": 0.7980587482452393,
      "attention_bam_384_mean_attention": 0.16656292974948883,
      "attention_bam_384_std_attention": 0.5242964625358582,
      "attention_bam_384_max_attention": 3.774331569671631,
      "attention_bam_384_min_attention": -1.4474633932113647,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5182954466172722,
      "attention_bam_384_attention_skewness": 0.5043800081111243,
      "attention_bam_384_attention_sparsity": 0.47436777750651044,
      "attention_bam_384_attention_concentration_10": 0.7058245495420135,
      "attention_bam_384_attention_concentration_20": 1.1282840174431366,
      "attention_bam_384_attention_center_y": 0.4812580291723646,
      "attention_bam_384_attention_center_x": 0.4859827194321423,
      "attention_bam_384_attention_center_distance": 0.03309820614540849,
      "attention_bam_384_attention_spatial_variance": 170.1523381508372,
      "attention_bam_384_attention_spatial_std": 13.044245403657401,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 17.71118693772917,
      "attention_bam_384_peak_intensity_mean": 0.30994483828544617,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19624127447605133,
      "attention_bam_16_std_attention": 0.6401301622390747,
      "attention_bam_16_max_attention": 2.8719658851623535,
      "attention_bam_16_min_attention": -1.1933445930480957,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.14750109443586457,
      "attention_bam_16_attention_skewness": 0.5968114545888988,
      "attention_bam_16_attention_sparsity": 0.487548828125,
      "attention_bam_16_attention_concentration_10": 0.7417109601929179,
      "attention_bam_16_attention_concentration_20": 1.1895523370505585,
      "attention_bam_16_attention_center_y": 0.46055056554558005,
      "attention_bam_16_attention_center_x": 0.4755141616359637,
      "attention_bam_16_attention_center_distance": 0.06566299047657344,
      "attention_bam_16_attention_spatial_variance": 41.79954587905501,
      "attention_bam_16_attention_spatial_std": 6.46525683009229,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.121808696956,
      "attention_bam_16_peak_intensity_mean": 0.3431508541107178,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 167,
      "phase": "train",
      "loss": 0.009453070349991322,
      "timestamp": 1759543907.0122206,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.009453070349991322,
      "ssim": 0.8082031011581421,
      "attention_bam_384_mean_attention": 0.1604079157114029,
      "attention_bam_384_std_attention": 0.5085203051567078,
      "attention_bam_384_max_attention": 3.3957746028900146,
      "attention_bam_384_min_attention": -1.4255003929138184,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5553728347461955,
      "attention_bam_384_attention_skewness": 0.6255472617225338,
      "attention_bam_384_attention_sparsity": 0.49326324462890625,
      "attention_bam_384_attention_concentration_10": 0.7229958725322501,
      "attention_bam_384_attention_concentration_20": 1.1510284545500182,
      "attention_bam_384_attention_center_y": 0.4814712804919716,
      "attention_bam_384_attention_center_x": 0.479396693311853,
      "attention_bam_384_attention_center_distance": 0.03918697980434412,
      "attention_bam_384_attention_spatial_variance": 170.53583753302632,
      "attention_bam_384_attention_spatial_std": 13.05893707516145,
      "attention_bam_384_num_attention_peaks": 18,
      "attention_bam_384_peak_separation_mean": 17.461824737070323,
      "attention_bam_384_peak_intensity_mean": 0.3352700471878052,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.186926007270813,
      "attention_bam_16_std_attention": 0.6007857322692871,
      "attention_bam_16_max_attention": 3.3755204677581787,
      "attention_bam_16_min_attention": -1.1802576780319214,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.25932262989772203,
      "attention_bam_16_attention_skewness": 0.6285542515130672,
      "attention_bam_16_attention_sparsity": 0.484619140625,
      "attention_bam_16_attention_concentration_10": 0.728495011944831,
      "attention_bam_16_attention_concentration_20": 1.1716776707717704,
      "attention_bam_16_attention_center_y": 0.4632577801066833,
      "attention_bam_16_attention_center_x": 0.45936549239910307,
      "attention_bam_16_attention_center_distance": 0.07747456267261131,
      "attention_bam_16_attention_spatial_variance": 42.463136858733705,
      "attention_bam_16_attention_spatial_std": 6.516374517991864,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 8.63718415725599,
      "attention_bam_16_peak_intensity_mean": 0.3102570176124573,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 168,
      "phase": "train",
      "loss": 0.00934852845966816,
      "timestamp": 1759543907.143205,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00934852845966816,
      "ssim": 0.8066010475158691,
      "attention_bam_384_mean_attention": 0.1583845466375351,
      "attention_bam_384_std_attention": 0.4870871603488922,
      "attention_bam_384_max_attention": 4.422791004180908,
      "attention_bam_384_min_attention": -1.47981858253479,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0132515788699914,
      "attention_bam_384_attention_skewness": 0.6683942633285616,
      "attention_bam_384_attention_sparsity": 0.4872589111328125,
      "attention_bam_384_attention_concentration_10": 0.7095944368585201,
      "attention_bam_384_attention_concentration_20": 1.1203844071974824,
      "attention_bam_384_attention_center_y": 0.48387572100468873,
      "attention_bam_384_attention_center_x": 0.4827739216430546,
      "attention_bam_384_attention_center_distance": 0.03336855252114657,
      "attention_bam_384_attention_spatial_variance": 169.9770446233536,
      "attention_bam_384_attention_spatial_std": 13.037524482176577,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 17.752070517761577,
      "attention_bam_384_peak_intensity_mean": 0.2791328430175781,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1838051676750183,
      "attention_bam_16_std_attention": 0.5853610634803772,
      "attention_bam_16_max_attention": 3.046708822250366,
      "attention_bam_16_min_attention": -1.1062774658203125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.9611584178563755,
      "attention_bam_16_attention_skewness": 0.8624741945851578,
      "attention_bam_16_attention_sparsity": 0.499755859375,
      "attention_bam_16_attention_concentration_10": 0.7527501516727477,
      "attention_bam_16_attention_concentration_20": 1.1856036616430372,
      "attention_bam_16_attention_center_y": 0.46954762196019717,
      "attention_bam_16_attention_center_x": 0.46808783260904957,
      "attention_bam_16_attention_center_distance": 0.062381627998427634,
      "attention_bam_16_attention_spatial_variance": 42.16283732021195,
      "attention_bam_16_attention_spatial_std": 6.493291716857633,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.03700546906818,
      "attention_bam_16_peak_intensity_mean": 0.31428244709968567,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 169,
      "phase": "train",
      "loss": 0.014404991641640663,
      "timestamp": 1759543907.2747715,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.014404991641640663,
      "ssim": 0.7964107990264893,
      "attention_bam_384_mean_attention": 0.15710614621639252,
      "attention_bam_384_std_attention": 0.508847713470459,
      "attention_bam_384_max_attention": 3.5746591091156006,
      "attention_bam_384_min_attention": -1.4642047882080078,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4311417558011694,
      "attention_bam_384_attention_skewness": 0.8297499174854697,
      "attention_bam_384_attention_sparsity": 0.4989776611328125,
      "attention_bam_384_attention_concentration_10": 0.7540997455360753,
      "attention_bam_384_attention_concentration_20": 1.1691589592875626,
      "attention_bam_384_attention_center_y": 0.4899986317555891,
      "attention_bam_384_attention_center_x": 0.4800450862405647,
      "attention_bam_384_attention_center_distance": 0.0315666263609785,
      "attention_bam_384_attention_spatial_variance": 168.77812315908938,
      "attention_bam_384_attention_spatial_std": 12.9914634725688,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 16.830922217195635,
      "attention_bam_384_peak_intensity_mean": 0.32289913296699524,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18790818750858307,
      "attention_bam_16_std_attention": 0.6266178488731384,
      "attention_bam_16_max_attention": 3.6681761741638184,
      "attention_bam_16_min_attention": -1.2325613498687744,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.4672212306149977,
      "attention_bam_16_attention_skewness": 0.9965122799256098,
      "attention_bam_16_attention_sparsity": 0.501953125,
      "attention_bam_16_attention_concentration_10": 0.7972803195378203,
      "attention_bam_16_attention_concentration_20": 1.2243855322927872,
      "attention_bam_16_attention_center_y": 0.4815006509891594,
      "attention_bam_16_attention_center_x": 0.4578692571739666,
      "attention_bam_16_attention_center_distance": 0.06507265792786175,
      "attention_bam_16_attention_spatial_variance": 41.23008918336297,
      "attention_bam_16_attention_spatial_std": 6.421066047266837,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.111659421874766,
      "attention_bam_16_peak_intensity_mean": 0.29478922486305237,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 170,
      "phase": "train",
      "loss": 0.011335785500705242,
      "timestamp": 1759543907.44643,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.011335785500705242,
      "ssim": 0.8185372352600098,
      "attention_bam_384_mean_attention": 0.15662790834903717,
      "attention_bam_384_std_attention": 0.5914278030395508,
      "attention_bam_384_max_attention": 5.914130687713623,
      "attention_bam_384_min_attention": -1.4095180034637451,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 5.548939854860967,
      "attention_bam_384_attention_skewness": 1.4774391747647857,
      "attention_bam_384_attention_sparsity": 0.505523681640625,
      "attention_bam_384_attention_concentration_10": 0.8701013865884503,
      "attention_bam_384_attention_concentration_20": 1.3012577599557364,
      "attention_bam_384_attention_center_y": 0.48532646143873304,
      "attention_bam_384_attention_center_x": 0.47574766183769335,
      "attention_bam_384_attention_center_distance": 0.040087121130055324,
      "attention_bam_384_attention_spatial_variance": 169.66533288868834,
      "attention_bam_384_attention_spatial_std": 13.025564590016371,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 16.032673503381247,
      "attention_bam_384_peak_intensity_mean": 0.21461665630340576,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17466142773628235,
      "attention_bam_16_std_attention": 0.7318344116210938,
      "attention_bam_16_max_attention": 5.2992048263549805,
      "attention_bam_16_min_attention": -1.2928037643432617,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 7.531336645250047,
      "attention_bam_16_attention_skewness": 2.0136314147787924,
      "attention_bam_16_attention_sparsity": 0.526611328125,
      "attention_bam_16_attention_concentration_10": 0.9910174015950094,
      "attention_bam_16_attention_concentration_20": 1.432155565943912,
      "attention_bam_16_attention_center_y": 0.4730489520575971,
      "attention_bam_16_attention_center_x": 0.45002872207737604,
      "attention_bam_16_attention_center_distance": 0.08029305826052241,
      "attention_bam_16_attention_spatial_variance": 41.80000883474839,
      "attention_bam_16_attention_spatial_std": 6.465292633342159,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.593108010818218,
      "attention_bam_16_peak_intensity_mean": 0.22071433067321777,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 171,
      "phase": "train",
      "loss": 0.010014120489358902,
      "timestamp": 1759543907.5780225,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.010014120489358902,
      "ssim": 0.8077216148376465,
      "attention_bam_384_mean_attention": 0.16111767292022705,
      "attention_bam_384_std_attention": 0.506921648979187,
      "attention_bam_384_max_attention": 3.9518370628356934,
      "attention_bam_384_min_attention": -1.4388192892074585,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.468010928032644,
      "attention_bam_384_attention_skewness": 0.7720961462778684,
      "attention_bam_384_attention_sparsity": 0.48944854736328125,
      "attention_bam_384_attention_concentration_10": 0.7236043154306039,
      "attention_bam_384_attention_concentration_20": 1.1353203808259273,
      "attention_bam_384_attention_center_y": 0.4847045702122579,
      "attention_bam_384_attention_center_x": 0.48055301421044816,
      "attention_bam_384_attention_center_distance": 0.034989582126421004,
      "attention_bam_384_attention_spatial_variance": 169.35754489652166,
      "attention_bam_384_attention_spatial_std": 13.013744461012044,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 16.896407196903933,
      "attention_bam_384_peak_intensity_mean": 0.2992841303348541,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1981237828731537,
      "attention_bam_16_std_attention": 0.6271114945411682,
      "attention_bam_16_max_attention": 3.618175506591797,
      "attention_bam_16_min_attention": -1.2299885749816895,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.6559856921977358,
      "attention_bam_16_attention_skewness": 0.9393103945536205,
      "attention_bam_16_attention_sparsity": 0.48486328125,
      "attention_bam_16_attention_concentration_10": 0.7438211978943623,
      "attention_bam_16_attention_concentration_20": 1.1631501590351516,
      "attention_bam_16_attention_center_y": 0.4707373331664623,
      "attention_bam_16_attention_center_x": 0.4597024033964836,
      "attention_bam_16_attention_center_distance": 0.07043010666228415,
      "attention_bam_16_attention_spatial_variance": 41.642051926476,
      "attention_bam_16_attention_spatial_std": 6.453065312429125,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.733427602308286,
      "attention_bam_16_peak_intensity_mean": 0.3014480173587799,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 172,
      "phase": "train",
      "loss": 0.012497412972152233,
      "timestamp": 1759543907.7081869,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.012497412972152233,
      "ssim": 0.7563959360122681,
      "attention_bam_384_mean_attention": 0.16117335855960846,
      "attention_bam_384_std_attention": 0.5022755265235901,
      "attention_bam_384_max_attention": 3.717916965484619,
      "attention_bam_384_min_attention": -1.4144978523254395,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9726121895213065,
      "attention_bam_384_attention_skewness": 0.6635877450096012,
      "attention_bam_384_attention_sparsity": 0.4838714599609375,
      "attention_bam_384_attention_concentration_10": 0.7097465631983413,
      "attention_bam_384_attention_concentration_20": 1.1252472688706887,
      "attention_bam_384_attention_center_y": 0.48030059432660577,
      "attention_bam_384_attention_center_x": 0.48602974202725324,
      "attention_bam_384_attention_center_distance": 0.0341536145000804,
      "attention_bam_384_attention_spatial_variance": 172.08459796422008,
      "attention_bam_384_attention_spatial_std": 13.118101919264848,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 19.464082636193794,
      "attention_bam_384_peak_intensity_mean": 0.3080075979232788,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19499419629573822,
      "attention_bam_16_std_attention": 0.6174744963645935,
      "attention_bam_16_max_attention": 3.4781270027160645,
      "attention_bam_16_min_attention": -1.2153418064117432,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.0107149237949633,
      "attention_bam_16_attention_skewness": 0.837343529768862,
      "attention_bam_16_attention_sparsity": 0.488037109375,
      "attention_bam_16_attention_concentration_10": 0.7398752957207236,
      "attention_bam_16_attention_concentration_20": 1.1608239257574398,
      "attention_bam_16_attention_center_y": 0.4592044920192695,
      "attention_bam_16_attention_center_x": 0.4739063894534935,
      "attention_bam_16_attention_center_distance": 0.06848576469250528,
      "attention_bam_16_attention_spatial_variance": 43.32744998621228,
      "attention_bam_16_attention_spatial_std": 6.582358998581912,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 10.061379675281044,
      "attention_bam_16_peak_intensity_mean": 0.3015986680984497,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 173,
      "phase": "train",
      "loss": 0.011656182818114758,
      "timestamp": 1759543907.8389733,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.011656182818114758,
      "ssim": 0.8258647918701172,
      "attention_bam_384_mean_attention": 0.1597001850605011,
      "attention_bam_384_std_attention": 0.5423822402954102,
      "attention_bam_384_max_attention": 4.03858757019043,
      "attention_bam_384_min_attention": -1.3941229581832886,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1149840921517606,
      "attention_bam_384_attention_skewness": 0.7956453421684712,
      "attention_bam_384_attention_sparsity": 0.4982248942057292,
      "attention_bam_384_attention_concentration_10": 0.7785808201531149,
      "attention_bam_384_attention_concentration_20": 1.2199507749059435,
      "attention_bam_384_attention_center_y": 0.4862407541931809,
      "attention_bam_384_attention_center_x": 0.4831209942049676,
      "attention_bam_384_attention_center_distance": 0.03079667780138647,
      "attention_bam_384_attention_spatial_variance": 166.45106420840077,
      "attention_bam_384_attention_spatial_std": 12.90159153780652,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 16.76997433612264,
      "attention_bam_384_peak_intensity_mean": 0.28894081711769104,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20063194632530212,
      "attention_bam_16_std_attention": 0.6718416213989258,
      "attention_bam_16_max_attention": 3.515962600708008,
      "attention_bam_16_min_attention": -1.074573040008545,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.473863008218549,
      "attention_bam_16_attention_skewness": 1.0196321672331234,
      "attention_bam_16_attention_sparsity": 0.500244140625,
      "attention_bam_16_attention_concentration_10": 0.7914295127524518,
      "attention_bam_16_attention_concentration_20": 1.2310164850563006,
      "attention_bam_16_attention_center_y": 0.4747548465805735,
      "attention_bam_16_attention_center_x": 0.46653538985088017,
      "attention_bam_16_attention_center_distance": 0.059282339758193685,
      "attention_bam_16_attention_spatial_variance": 39.75247005630119,
      "attention_bam_16_attention_spatial_std": 6.304955991622875,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 10.276847951501738,
      "attention_bam_16_peak_intensity_mean": 0.28057846426963806,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 174,
      "phase": "train",
      "loss": 0.010366073809564114,
      "timestamp": 1759543907.9685743,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.010366073809564114,
      "ssim": 0.7830952405929565,
      "attention_bam_384_mean_attention": 0.15864236652851105,
      "attention_bam_384_std_attention": 0.553508996963501,
      "attention_bam_384_max_attention": 4.216187000274658,
      "attention_bam_384_min_attention": -1.439873456954956,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.7776492631847134,
      "attention_bam_384_attention_skewness": 0.8451372262525401,
      "attention_bam_384_attention_sparsity": 0.4969126383463542,
      "attention_bam_384_attention_concentration_10": 0.7945416198401891,
      "attention_bam_384_attention_concentration_20": 1.2329331299366075,
      "attention_bam_384_attention_center_y": 0.48405000299005285,
      "attention_bam_384_attention_center_x": 0.47860207414850175,
      "attention_bam_384_attention_center_distance": 0.03774317515428557,
      "attention_bam_384_attention_spatial_variance": 171.4512663125805,
      "attention_bam_384_attention_spatial_std": 13.093940060676179,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 18.302176666235663,
      "attention_bam_384_peak_intensity_mean": 0.28640443086624146,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19230026006698608,
      "attention_bam_16_std_attention": 0.6618496775627136,
      "attention_bam_16_max_attention": 4.081779479980469,
      "attention_bam_16_min_attention": -1.2937555313110352,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.8339558591722884,
      "attention_bam_16_attention_skewness": 0.9881238003669277,
      "attention_bam_16_attention_sparsity": 0.49365234375,
      "attention_bam_16_attention_concentration_10": 0.802600950377302,
      "attention_bam_16_attention_concentration_20": 1.2430985942401729,
      "attention_bam_16_attention_center_y": 0.46850301024228,
      "attention_bam_16_attention_center_x": 0.46002325046599307,
      "attention_bam_16_attention_center_distance": 0.07197500770548954,
      "attention_bam_16_attention_spatial_variance": 43.1597086297388,
      "attention_bam_16_attention_spatial_std": 6.569604906669715,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.321258659509663,
      "attention_bam_16_peak_intensity_mean": 0.28736454248428345,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 175,
      "phase": "train",
      "loss": 0.008600165136158466,
      "timestamp": 1759543908.0992699,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008600165136158466,
      "ssim": 0.8236581683158875,
      "attention_bam_384_mean_attention": 0.1621374636888504,
      "attention_bam_384_std_attention": 0.45458126068115234,
      "attention_bam_384_max_attention": 3.5133228302001953,
      "attention_bam_384_min_attention": -1.3576223850250244,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5666928107450224,
      "attention_bam_384_attention_skewness": 0.4909044560820296,
      "attention_bam_384_attention_sparsity": 0.47193145751953125,
      "attention_bam_384_attention_concentration_10": 0.6412652038370223,
      "attention_bam_384_attention_concentration_20": 1.0266432967831634,
      "attention_bam_384_attention_center_y": 0.4812345147281321,
      "attention_bam_384_attention_center_x": 0.48227977752041423,
      "attention_bam_384_attention_center_distance": 0.03650067731466657,
      "attention_bam_384_attention_spatial_variance": 170.32365449919817,
      "attention_bam_384_attention_spatial_std": 13.050810492042176,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 19.14210997688359,
      "attention_bam_384_peak_intensity_mean": 0.3144693374633789,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2077992558479309,
      "attention_bam_16_std_attention": 0.5556672811508179,
      "attention_bam_16_max_attention": 2.610626220703125,
      "attention_bam_16_min_attention": -1.0880987644195557,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.15037516847277166,
      "attention_bam_16_attention_skewness": 0.4684127704175472,
      "attention_bam_16_attention_sparsity": 0.450439453125,
      "attention_bam_16_attention_concentration_10": 0.6055558870052506,
      "attention_bam_16_attention_concentration_20": 0.988553386063509,
      "attention_bam_16_attention_center_y": 0.46263719497325306,
      "attention_bam_16_attention_center_x": 0.4670555229148019,
      "attention_bam_16_attention_center_distance": 0.07044597603673113,
      "attention_bam_16_attention_spatial_variance": 42.309935369512154,
      "attention_bam_16_attention_spatial_std": 6.5046087791282385,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.281009094040458,
      "attention_bam_16_peak_intensity_mean": 0.35489416122436523,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 176,
      "phase": "train",
      "loss": 0.009172128513455391,
      "timestamp": 1759543908.2298853,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.009172128513455391,
      "ssim": 0.8056057095527649,
      "attention_bam_384_mean_attention": 0.15785343945026398,
      "attention_bam_384_std_attention": 0.5149142146110535,
      "attention_bam_384_max_attention": 4.145018577575684,
      "attention_bam_384_min_attention": -1.4152905941009521,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.158408886955785,
      "attention_bam_384_attention_skewness": 0.7369271152186686,
      "attention_bam_384_attention_sparsity": 0.4940643310546875,
      "attention_bam_384_attention_concentration_10": 0.7492840644208342,
      "attention_bam_384_attention_concentration_20": 1.1730575749711123,
      "attention_bam_384_attention_center_y": 0.4900514824078671,
      "attention_bam_384_attention_center_x": 0.4817954245933698,
      "attention_bam_384_attention_center_distance": 0.029338696904145613,
      "attention_bam_384_attention_spatial_variance": 172.88990517374242,
      "attention_bam_384_attention_spatial_std": 13.148760594586184,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 19.446851117395656,
      "attention_bam_384_peak_intensity_mean": 0.2855428457260132,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18913693726062775,
      "attention_bam_16_std_attention": 0.6189548373222351,
      "attention_bam_16_max_attention": 3.16576886177063,
      "attention_bam_16_min_attention": -1.2202317714691162,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7778845287644409,
      "attention_bam_16_attention_skewness": 0.8155441371759671,
      "attention_bam_16_attention_sparsity": 0.499267578125,
      "attention_bam_16_attention_concentration_10": 0.7640719732757059,
      "attention_bam_16_attention_concentration_20": 1.205057841991289,
      "attention_bam_16_attention_center_y": 0.48035579646433235,
      "attention_bam_16_attention_center_x": 0.4641966061355847,
      "attention_bam_16_attention_center_distance": 0.057754268149829174,
      "attention_bam_16_attention_spatial_variance": 43.89764638195277,
      "attention_bam_16_attention_spatial_std": 6.625529894427522,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.882985272352803,
      "attention_bam_16_peak_intensity_mean": 0.33165329694747925,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 177,
      "phase": "train",
      "loss": 0.010124437510967255,
      "timestamp": 1759543908.360752,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.010124437510967255,
      "ssim": 0.8309708833694458,
      "attention_bam_384_mean_attention": 0.15780293941497803,
      "attention_bam_384_std_attention": 0.5154240131378174,
      "attention_bam_384_max_attention": 3.552849054336548,
      "attention_bam_384_min_attention": -1.3863630294799805,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.97154654303516,
      "attention_bam_384_attention_skewness": 0.6698221291994904,
      "attention_bam_384_attention_sparsity": 0.4918365478515625,
      "attention_bam_384_attention_concentration_10": 0.7408378136707205,
      "attention_bam_384_attention_concentration_20": 1.1690529484358294,
      "attention_bam_384_attention_center_y": 0.4784866387435174,
      "attention_bam_384_attention_center_x": 0.48142815247590454,
      "attention_bam_384_attention_center_distance": 0.040192990259749976,
      "attention_bam_384_attention_spatial_variance": 170.817289456797,
      "attention_bam_384_attention_spatial_std": 13.069708851263558,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 17.582977087227313,
      "attention_bam_384_peak_intensity_mean": 0.3171423375606537,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19429050385951996,
      "attention_bam_16_std_attention": 0.6308012008666992,
      "attention_bam_16_max_attention": 3.508965492248535,
      "attention_bam_16_min_attention": -1.319667100906372,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8467775753568803,
      "attention_bam_16_attention_skewness": 0.8173248354463866,
      "attention_bam_16_attention_sparsity": 0.491455078125,
      "attention_bam_16_attention_concentration_10": 0.7530931774484186,
      "attention_bam_16_attention_concentration_20": 1.1906878146033852,
      "attention_bam_16_attention_center_y": 0.45625755459183753,
      "attention_bam_16_attention_center_x": 0.4624779251506565,
      "attention_bam_16_attention_center_distance": 0.0815022408438665,
      "attention_bam_16_attention_spatial_variance": 42.372406544208104,
      "attention_bam_16_attention_spatial_std": 6.509409077958467,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.8282069970942,
      "attention_bam_16_peak_intensity_mean": 0.3199658989906311,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 178,
      "phase": "train",
      "loss": 0.013340703211724758,
      "timestamp": 1759543908.4923792,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.013340703211724758,
      "ssim": 0.8164659738540649,
      "attention_bam_384_mean_attention": 0.15076841413974762,
      "attention_bam_384_std_attention": 0.5074009895324707,
      "attention_bam_384_max_attention": 5.111636161804199,
      "attention_bam_384_min_attention": -1.5416643619537354,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 4.7561157874919635,
      "attention_bam_384_attention_skewness": 1.2688570959856738,
      "attention_bam_384_attention_sparsity": 0.5011062622070312,
      "attention_bam_384_attention_concentration_10": 0.7795116323904192,
      "attention_bam_384_attention_concentration_20": 1.1788048715785204,
      "attention_bam_384_attention_center_y": 0.48444244089807986,
      "attention_bam_384_attention_center_x": 0.4808137300167587,
      "attention_bam_384_attention_center_distance": 0.034932809823418565,
      "attention_bam_384_attention_spatial_variance": 169.34158666595687,
      "attention_bam_384_attention_spatial_std": 13.013131316710703,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 17.703980983837702,
      "attention_bam_384_peak_intensity_mean": 0.25646811723709106,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16986311972141266,
      "attention_bam_16_std_attention": 0.6436349749565125,
      "attention_bam_16_max_attention": 4.457035064697266,
      "attention_bam_16_min_attention": -1.3536083698272705,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 6.117594259497759,
      "attention_bam_16_attention_skewness": 1.7351754749211359,
      "attention_bam_16_attention_sparsity": 0.521484375,
      "attention_bam_16_attention_concentration_10": 0.9011260407398265,
      "attention_bam_16_attention_concentration_20": 1.3299579860749688,
      "attention_bam_16_attention_center_y": 0.4697044053194732,
      "attention_bam_16_attention_center_x": 0.46044532990692844,
      "attention_bam_16_attention_center_distance": 0.07046126571696669,
      "attention_bam_16_attention_spatial_variance": 41.70682843975733,
      "attention_bam_16_attention_spatial_std": 6.458082411966987,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.513023058440215,
      "attention_bam_16_peak_intensity_mean": 0.2646504044532776,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 179,
      "phase": "train",
      "loss": 0.00822908990085125,
      "timestamp": 1759543908.622947,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00822908990085125,
      "ssim": 0.8320255279541016,
      "attention_bam_384_mean_attention": 0.15759141743183136,
      "attention_bam_384_std_attention": 0.4871453046798706,
      "attention_bam_384_max_attention": 3.5271472930908203,
      "attention_bam_384_min_attention": -1.3720998764038086,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1469816088361187,
      "attention_bam_384_attention_skewness": 0.7620305370834044,
      "attention_bam_384_attention_sparsity": 0.4950154622395833,
      "attention_bam_384_attention_concentration_10": 0.7165665049049278,
      "attention_bam_384_attention_concentration_20": 1.1286549545399773,
      "attention_bam_384_attention_center_y": 0.48721432085453953,
      "attention_bam_384_attention_center_x": 0.48489892415545927,
      "attention_bam_384_attention_center_distance": 0.02798271190836351,
      "attention_bam_384_attention_spatial_variance": 174.43347843800723,
      "attention_bam_384_attention_spatial_std": 13.20732669536145,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 23.121545967567652,
      "attention_bam_384_peak_intensity_mean": 0.32092756032943726,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19249579310417175,
      "attention_bam_16_std_attention": 0.6230990886688232,
      "attention_bam_16_max_attention": 3.1378655433654785,
      "attention_bam_16_min_attention": -1.0766228437423706,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6619117970040418,
      "attention_bam_16_attention_skewness": 0.8246506584807197,
      "attention_bam_16_attention_sparsity": 0.503662109375,
      "attention_bam_16_attention_concentration_10": 0.7532566909128633,
      "attention_bam_16_attention_concentration_20": 1.2005219932633906,
      "attention_bam_16_attention_center_y": 0.4770867524823968,
      "attention_bam_16_attention_center_x": 0.47103003330714266,
      "attention_bam_16_attention_center_distance": 0.052235541195400914,
      "attention_bam_16_attention_spatial_variance": 45.066126391784685,
      "attention_bam_16_attention_spatial_std": 6.7131308933898115,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 11.763384504675026,
      "attention_bam_16_peak_intensity_mean": 0.32754188776016235,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 180,
      "phase": "train",
      "loss": 0.011679391376674175,
      "timestamp": 1759543908.7931948,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.011679391376674175,
      "ssim": 0.7841788530349731,
      "attention_bam_384_mean_attention": 0.15437227487564087,
      "attention_bam_384_std_attention": 0.47519320249557495,
      "attention_bam_384_max_attention": 3.73545503616333,
      "attention_bam_384_min_attention": -1.4435107707977295,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4559564680166819,
      "attention_bam_384_attention_skewness": 0.666381426481583,
      "attention_bam_384_attention_sparsity": 0.48415883382161456,
      "attention_bam_384_attention_concentration_10": 0.6931301160348834,
      "attention_bam_384_attention_concentration_20": 1.0980651910321364,
      "attention_bam_384_attention_center_y": 0.4800459282901589,
      "attention_bam_384_attention_center_x": 0.48834640576308247,
      "attention_bam_384_attention_center_distance": 0.03267938911424747,
      "attention_bam_384_attention_spatial_variance": 168.2293251857191,
      "attention_bam_384_attention_spatial_std": 12.970324791065146,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 15.228142714957231,
      "attention_bam_384_peak_intensity_mean": 0.3106768727302551,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19374647736549377,
      "attention_bam_16_std_attention": 0.616377055644989,
      "attention_bam_16_max_attention": 3.4913105964660645,
      "attention_bam_16_min_attention": -1.441026210784912,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.031525491389865,
      "attention_bam_16_attention_skewness": 1.0203598006957437,
      "attention_bam_16_attention_sparsity": 0.4853515625,
      "attention_bam_16_attention_concentration_10": 0.7495654934575361,
      "attention_bam_16_attention_concentration_20": 1.1567224571012176,
      "attention_bam_16_attention_center_y": 0.45942204136816533,
      "attention_bam_16_attention_center_x": 0.47656549621815375,
      "attention_bam_16_attention_center_distance": 0.06626834378839193,
      "attention_bam_16_attention_spatial_variance": 40.968665415406356,
      "attention_bam_16_attention_spatial_std": 6.400676949776981,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 7.6534733706505715,
      "attention_bam_16_peak_intensity_mean": 0.34376102685928345,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 181,
      "phase": "train",
      "loss": 0.010697919875383377,
      "timestamp": 1759543908.934704,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.010697919875383377,
      "ssim": 0.8475911617279053,
      "attention_bam_384_mean_attention": 0.15826784074306488,
      "attention_bam_384_std_attention": 0.5174939632415771,
      "attention_bam_384_max_attention": 3.99308180809021,
      "attention_bam_384_min_attention": -1.3210182189941406,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.7818045431878113,
      "attention_bam_384_attention_skewness": 0.8569076358378749,
      "attention_bam_384_attention_sparsity": 0.49546559651692706,
      "attention_bam_384_attention_concentration_10": 0.7516514494754615,
      "attention_bam_384_attention_concentration_20": 1.1733324914091108,
      "attention_bam_384_attention_center_y": 0.4872186955408154,
      "attention_bam_384_attention_center_x": 0.4886299108037966,
      "attention_bam_384_attention_center_distance": 0.024192588617508174,
      "attention_bam_384_attention_spatial_variance": 171.12029367652863,
      "attention_bam_384_attention_spatial_std": 13.081295565674244,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 16.905694186750697,
      "attention_bam_384_peak_intensity_mean": 0.2819007635116577,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18947970867156982,
      "attention_bam_16_std_attention": 0.6574559211730957,
      "attention_bam_16_max_attention": 3.677934169769287,
      "attention_bam_16_min_attention": -1.1572991609573364,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.5956932100926169,
      "attention_bam_16_attention_skewness": 1.0420442174445734,
      "attention_bam_16_attention_sparsity": 0.5107421875,
      "attention_bam_16_attention_concentration_10": 0.8188216393902314,
      "attention_bam_16_attention_concentration_20": 1.2651235064836603,
      "attention_bam_16_attention_center_y": 0.47444412219749965,
      "attention_bam_16_attention_center_x": 0.4788913505107775,
      "attention_bam_16_attention_center_distance": 0.04687596342508989,
      "attention_bam_16_attention_spatial_variance": 42.511578150561974,
      "attention_bam_16_attention_spatial_std": 6.520090348343493,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.61131421104128,
      "attention_bam_16_peak_intensity_mean": 0.29018422961235046,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 182,
      "phase": "train",
      "loss": 0.009238882921636105,
      "timestamp": 1759543909.0644042,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.009238882921636105,
      "ssim": 0.8086845874786377,
      "attention_bam_384_mean_attention": 0.15355491638183594,
      "attention_bam_384_std_attention": 0.49453088641166687,
      "attention_bam_384_max_attention": 3.4040379524230957,
      "attention_bam_384_min_attention": -1.3725483417510986,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0244209564462627,
      "attention_bam_384_attention_skewness": 0.7179103824037614,
      "attention_bam_384_attention_sparsity": 0.4959665934244792,
      "attention_bam_384_attention_concentration_10": 0.7449323764805967,
      "attention_bam_384_attention_concentration_20": 1.1632963593225991,
      "attention_bam_384_attention_center_y": 0.49097811722789314,
      "attention_bam_384_attention_center_x": 0.4814014209098859,
      "attention_bam_384_attention_center_distance": 0.029233594131576345,
      "attention_bam_384_attention_spatial_variance": 172.8733220282785,
      "attention_bam_384_attention_spatial_std": 13.148129982179158,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 17.556154513747554,
      "attention_bam_384_peak_intensity_mean": 0.32239046692848206,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1821173131465912,
      "attention_bam_16_std_attention": 0.6099525094032288,
      "attention_bam_16_max_attention": 2.741161823272705,
      "attention_bam_16_min_attention": -1.1126065254211426,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5108841740269532,
      "attention_bam_16_attention_skewness": 0.7872259460630113,
      "attention_bam_16_attention_sparsity": 0.502197265625,
      "attention_bam_16_attention_concentration_10": 0.7782424617906639,
      "attention_bam_16_attention_concentration_20": 1.2339536459861453,
      "attention_bam_16_attention_center_y": 0.487213763734357,
      "attention_bam_16_attention_center_x": 0.4608624095316745,
      "attention_bam_16_attention_center_distance": 0.05822780822780824,
      "attention_bam_16_attention_spatial_variance": 43.952102421125204,
      "attention_bam_16_attention_spatial_std": 6.629638181765669,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.54667428597862,
      "attention_bam_16_peak_intensity_mean": 0.34746047854423523,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 183,
      "phase": "train",
      "loss": 0.0075522176921367645,
      "timestamp": 1759543909.194525,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0075522176921367645,
      "ssim": 0.8304653167724609,
      "attention_bam_384_mean_attention": 0.15531323850154877,
      "attention_bam_384_std_attention": 0.521289050579071,
      "attention_bam_384_max_attention": 3.860607147216797,
      "attention_bam_384_min_attention": -1.4470109939575195,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2778436613049085,
      "attention_bam_384_attention_skewness": 0.8138542202804372,
      "attention_bam_384_attention_sparsity": 0.5037129720052084,
      "attention_bam_384_attention_concentration_10": 0.7803219988406294,
      "attention_bam_384_attention_concentration_20": 1.2108058017406105,
      "attention_bam_384_attention_center_y": 0.481734794048488,
      "attention_bam_384_attention_center_x": 0.48221927103177276,
      "attention_bam_384_attention_center_distance": 0.03604919058987883,
      "attention_bam_384_attention_spatial_variance": 171.66430021028467,
      "attention_bam_384_attention_spatial_std": 13.102072363190667,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 19.118748033213286,
      "attention_bam_384_peak_intensity_mean": 0.30453571677207947,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19309593737125397,
      "attention_bam_16_std_attention": 0.6663825511932373,
      "attention_bam_16_max_attention": 3.097515106201172,
      "attention_bam_16_min_attention": -1.176264762878418,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7870856267534614,
      "attention_bam_16_attention_skewness": 0.8966041102191346,
      "attention_bam_16_attention_sparsity": 0.506103515625,
      "attention_bam_16_attention_concentration_10": 0.8172320622526743,
      "attention_bam_16_attention_concentration_20": 1.2702218452063119,
      "attention_bam_16_attention_center_y": 0.464449314212895,
      "attention_bam_16_attention_center_x": 0.4605889389798343,
      "attention_bam_16_attention_center_distance": 0.07506108166911396,
      "attention_bam_16_attention_spatial_variance": 43.12915120926892,
      "attention_bam_16_attention_spatial_std": 6.567278828348079,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 11.392054566435036,
      "attention_bam_16_peak_intensity_mean": 0.33214229345321655,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 184,
      "phase": "train",
      "loss": 0.016519859433174133,
      "timestamp": 1759543909.3249657,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.016519859433174133,
      "ssim": 0.7281478643417358,
      "attention_bam_384_mean_attention": 0.156519815325737,
      "attention_bam_384_std_attention": 0.47690701484680176,
      "attention_bam_384_max_attention": 3.564960479736328,
      "attention_bam_384_min_attention": -1.3450160026550293,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.9160081721115763,
      "attention_bam_384_attention_skewness": 0.8678827256685536,
      "attention_bam_384_attention_sparsity": 0.492767333984375,
      "attention_bam_384_attention_concentration_10": 0.7153137257389767,
      "attention_bam_384_attention_concentration_20": 1.1040446057957816,
      "attention_bam_384_attention_center_y": 0.48142657234652403,
      "attention_bam_384_attention_center_x": 0.48135549695855345,
      "attention_bam_384_attention_center_distance": 0.03721799856148676,
      "attention_bam_384_attention_spatial_variance": 169.68776715919242,
      "attention_bam_384_attention_spatial_std": 13.026425724625785,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 18.221791807958045,
      "attention_bam_384_peak_intensity_mean": 0.3103923499584198,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19286702573299408,
      "attention_bam_16_std_attention": 0.6360377669334412,
      "attention_bam_16_max_attention": 2.9409987926483154,
      "attention_bam_16_min_attention": -1.1790739297866821,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.0490171628032972,
      "attention_bam_16_attention_skewness": 0.9295272103708584,
      "attention_bam_16_attention_sparsity": 0.501953125,
      "attention_bam_16_attention_concentration_10": 0.780328834989068,
      "attention_bam_16_attention_concentration_20": 1.2195723477560017,
      "attention_bam_16_attention_center_y": 0.46163168521574954,
      "attention_bam_16_attention_center_x": 0.46174914756027646,
      "attention_bam_16_attention_center_distance": 0.07661925726276438,
      "attention_bam_16_attention_spatial_variance": 41.96072399892804,
      "attention_bam_16_attention_spatial_std": 6.477709780387513,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.729703588398138,
      "attention_bam_16_peak_intensity_mean": 0.3502369523048401,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 185,
      "phase": "train",
      "loss": 0.01074168086051941,
      "timestamp": 1759543909.45575,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.01074168086051941,
      "ssim": 0.8022099733352661,
      "attention_bam_384_mean_attention": 0.15661363303661346,
      "attention_bam_384_std_attention": 0.49218931794166565,
      "attention_bam_384_max_attention": 4.382248878479004,
      "attention_bam_384_min_attention": -1.3799583911895752,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.587388311282428,
      "attention_bam_384_attention_skewness": 0.7492553425627234,
      "attention_bam_384_attention_sparsity": 0.48757171630859375,
      "attention_bam_384_attention_concentration_10": 0.7079239808831508,
      "attention_bam_384_attention_concentration_20": 1.1218276658559463,
      "attention_bam_384_attention_center_y": 0.47874131922087915,
      "attention_bam_384_attention_center_x": 0.4885493649734522,
      "attention_bam_384_attention_center_distance": 0.034148163961764205,
      "attention_bam_384_attention_spatial_variance": 168.3788628609676,
      "attention_bam_384_attention_spatial_std": 12.976088118572854,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 15.088940445890687,
      "attention_bam_384_peak_intensity_mean": 0.2694528102874756,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20632654428482056,
      "attention_bam_16_std_attention": 0.6304484605789185,
      "attention_bam_16_max_attention": 3.4802868366241455,
      "attention_bam_16_min_attention": -1.07463538646698,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.2239261348251702,
      "attention_bam_16_attention_skewness": 0.8424980071730832,
      "attention_bam_16_attention_sparsity": 0.4755859375,
      "attention_bam_16_attention_concentration_10": 0.7079410154513042,
      "attention_bam_16_attention_concentration_20": 1.1190538438184137,
      "attention_bam_16_attention_center_y": 0.45347941343269293,
      "attention_bam_16_attention_center_x": 0.48204930296911336,
      "attention_bam_16_attention_center_distance": 0.07051797640972113,
      "attention_bam_16_attention_spatial_variance": 40.53894451210884,
      "attention_bam_16_attention_spatial_std": 6.367020065313823,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.49195081908737,
      "attention_bam_16_peak_intensity_mean": 0.2895861268043518,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 186,
      "phase": "train",
      "loss": 0.009759718552231789,
      "timestamp": 1759543909.584297,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.009759718552231789,
      "ssim": 0.8289735913276672,
      "attention_bam_384_mean_attention": 0.14991602301597595,
      "attention_bam_384_std_attention": 0.5351817011833191,
      "attention_bam_384_max_attention": 4.029781818389893,
      "attention_bam_384_min_attention": -1.413668155670166,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4979067422221828,
      "attention_bam_384_attention_skewness": 0.8422508894388904,
      "attention_bam_384_attention_sparsity": 0.5060323079427084,
      "attention_bam_384_attention_concentration_10": 0.8115482556834829,
      "attention_bam_384_attention_concentration_20": 1.2687465364381922,
      "attention_bam_384_attention_center_y": 0.4807074376375798,
      "attention_bam_384_attention_center_x": 0.48345651025800634,
      "attention_bam_384_attention_center_distance": 0.035941341526195776,
      "attention_bam_384_attention_spatial_variance": 169.7580576173635,
      "attention_bam_384_attention_spatial_std": 13.02912344010001,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 18.211388397734158,
      "attention_bam_384_peak_intensity_mean": 0.2899209260940552,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18429841101169586,
      "attention_bam_16_std_attention": 0.675880491733551,
      "attention_bam_16_max_attention": 4.2148637771606445,
      "attention_bam_16_min_attention": -1.0542947053909302,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.355567026896571,
      "attention_bam_16_attention_skewness": 0.9781997161854439,
      "attention_bam_16_attention_sparsity": 0.5146484375,
      "attention_bam_16_attention_concentration_10": 0.8585218357143195,
      "attention_bam_16_attention_concentration_20": 1.3347108603866655,
      "attention_bam_16_attention_center_y": 0.45370866753279465,
      "attention_bam_16_attention_center_x": 0.4681222393479705,
      "attention_bam_16_attention_center_distance": 0.07948684275749567,
      "attention_bam_16_attention_spatial_variance": 41.7990646084605,
      "attention_bam_16_attention_spatial_std": 6.465219610226748,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.20942852840964,
      "attention_bam_16_peak_intensity_mean": 0.23076261579990387,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 187,
      "phase": "train",
      "loss": 0.009813033975660801,
      "timestamp": 1759543909.7158713,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.009813033975660801,
      "ssim": 0.8166975378990173,
      "attention_bam_384_mean_attention": 0.1540554016828537,
      "attention_bam_384_std_attention": 0.48788920044898987,
      "attention_bam_384_max_attention": 3.515484094619751,
      "attention_bam_384_min_attention": -1.215493083000183,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5042183999703767,
      "attention_bam_384_attention_skewness": 0.5748536462384537,
      "attention_bam_384_attention_sparsity": 0.49105580647786456,
      "attention_bam_384_attention_concentration_10": 0.7198542661801236,
      "attention_bam_384_attention_concentration_20": 1.1435735415734463,
      "attention_bam_384_attention_center_y": 0.4925429116275196,
      "attention_bam_384_attention_center_x": 0.4821346433627732,
      "attention_bam_384_attention_center_distance": 0.02737806182951184,
      "attention_bam_384_attention_spatial_variance": 169.26640543551582,
      "attention_bam_384_attention_spatial_std": 13.010242328085816,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 18.44318138302434,
      "attention_bam_384_peak_intensity_mean": 0.29241427779197693,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19499416649341583,
      "attention_bam_16_std_attention": 0.6117215752601624,
      "attention_bam_16_max_attention": 2.6606152057647705,
      "attention_bam_16_min_attention": -1.099857211112976,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.05630494347810089,
      "attention_bam_16_attention_skewness": 0.6416904508228523,
      "attention_bam_16_attention_sparsity": 0.49755859375,
      "attention_bam_16_attention_concentration_10": 0.726091651598674,
      "attention_bam_16_attention_concentration_20": 1.1733826426087803,
      "attention_bam_16_attention_center_y": 0.49980089724886084,
      "attention_bam_16_attention_center_x": 0.46456590737785947,
      "attention_bam_16_attention_center_distance": 0.050112165426370175,
      "attention_bam_16_attention_spatial_variance": 41.209983738461105,
      "attention_bam_16_attention_spatial_std": 6.4195002717081575,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 7.3654841049877975,
      "attention_bam_16_peak_intensity_mean": 0.3668877184391022,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 188,
      "phase": "train",
      "loss": 0.009005602449178696,
      "timestamp": 1759543909.8467112,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.009005602449178696,
      "ssim": 0.83002108335495,
      "attention_bam_384_mean_attention": 0.15203024446964264,
      "attention_bam_384_std_attention": 0.5201114416122437,
      "attention_bam_384_max_attention": 4.488273620605469,
      "attention_bam_384_min_attention": -1.3535737991333008,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.331884885757769,
      "attention_bam_384_attention_skewness": 0.9616241501690947,
      "attention_bam_384_attention_sparsity": 0.49873097737630206,
      "attention_bam_384_attention_concentration_10": 0.7927119717795453,
      "attention_bam_384_attention_concentration_20": 1.2118436747839123,
      "attention_bam_384_attention_center_y": 0.47566027064225663,
      "attention_bam_384_attention_center_x": 0.48623702724971857,
      "attention_bam_384_attention_center_distance": 0.03954344052136039,
      "attention_bam_384_attention_spatial_variance": 170.47798748669294,
      "attention_bam_384_attention_spatial_std": 13.056721927294497,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 15.274095441707702,
      "attention_bam_384_peak_intensity_mean": 0.2585636079311371,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20255911350250244,
      "attention_bam_16_std_attention": 0.6596841812133789,
      "attention_bam_16_max_attention": 3.529550552368164,
      "attention_bam_16_min_attention": -1.241339921951294,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.9338398990805539,
      "attention_bam_16_attention_skewness": 1.0974776175764267,
      "attention_bam_16_attention_sparsity": 0.509521484375,
      "attention_bam_16_attention_concentration_10": 0.7807003076079302,
      "attention_bam_16_attention_concentration_20": 1.2002314044967448,
      "attention_bam_16_attention_center_y": 0.4466469922845373,
      "attention_bam_16_attention_center_x": 0.47385447593048635,
      "attention_bam_16_attention_center_distance": 0.08402537546664983,
      "attention_bam_16_attention_spatial_variance": 42.178759355284576,
      "attention_bam_16_attention_spatial_std": 6.494517638384284,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 10.879255457694319,
      "attention_bam_16_peak_intensity_mean": 0.307131290435791,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 189,
      "phase": "train",
      "loss": 0.012292146682739258,
      "timestamp": 1759543909.9761717,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.012292146682739258,
      "ssim": 0.794190526008606,
      "attention_bam_384_mean_attention": 0.1550624668598175,
      "attention_bam_384_std_attention": 0.4586993455886841,
      "attention_bam_384_max_attention": 4.488096714019775,
      "attention_bam_384_min_attention": -1.3030000925064087,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0964114310786677,
      "attention_bam_384_attention_skewness": 0.5730471709950226,
      "attention_bam_384_attention_sparsity": 0.47820790608723956,
      "attention_bam_384_attention_concentration_10": 0.6707008521118537,
      "attention_bam_384_attention_concentration_20": 1.064625831381893,
      "attention_bam_384_attention_center_y": 0.48628538691194184,
      "attention_bam_384_attention_center_x": 0.47863207254655166,
      "attention_bam_384_attention_center_distance": 0.035907629713223,
      "attention_bam_384_attention_spatial_variance": 170.31972882991374,
      "attention_bam_384_attention_spatial_std": 13.050660091731519,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 17.305180327369854,
      "attention_bam_384_peak_intensity_mean": 0.2553086578845978,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20682388544082642,
      "attention_bam_16_std_attention": 0.5732237100601196,
      "attention_bam_16_max_attention": 2.864482879638672,
      "attention_bam_16_min_attention": -1.1348549127578735,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.27985270622772696,
      "attention_bam_16_attention_skewness": 0.5340611271425421,
      "attention_bam_16_attention_sparsity": 0.45361328125,
      "attention_bam_16_attention_concentration_10": 0.6390993158574203,
      "attention_bam_16_attention_concentration_20": 1.026997094164732,
      "attention_bam_16_attention_center_y": 0.4743478312867929,
      "attention_bam_16_attention_center_x": 0.45548863531435574,
      "attention_bam_16_attention_center_distance": 0.07265391036784268,
      "attention_bam_16_attention_spatial_variance": 42.229124888784135,
      "attention_bam_16_attention_spatial_std": 6.49839402381728,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.203113475666694,
      "attention_bam_16_peak_intensity_mean": 0.3487781286239624,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 190,
      "phase": "train",
      "loss": 0.00853176973760128,
      "timestamp": 1759543910.1494718,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00853176973760128,
      "ssim": 0.8311448097229004,
      "attention_bam_384_mean_attention": 0.14852704107761383,
      "attention_bam_384_std_attention": 0.511890709400177,
      "attention_bam_384_max_attention": 4.3653483390808105,
      "attention_bam_384_min_attention": -1.3967338800430298,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7919436116835916,
      "attention_bam_384_attention_skewness": 0.6457235812591122,
      "attention_bam_384_attention_sparsity": 0.49853515625,
      "attention_bam_384_attention_concentration_10": 0.7784388980671216,
      "attention_bam_384_attention_concentration_20": 1.2297802299890326,
      "attention_bam_384_attention_center_y": 0.4803313496261327,
      "attention_bam_384_attention_center_x": 0.4838044016331598,
      "attention_bam_384_attention_center_distance": 0.03603201948238335,
      "attention_bam_384_attention_spatial_variance": 169.65573067977076,
      "attention_bam_384_attention_spatial_std": 13.025195993910064,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 15.3518973379408,
      "attention_bam_384_peak_intensity_mean": 0.26996082067489624,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1812298744916916,
      "attention_bam_16_std_attention": 0.6345568895339966,
      "attention_bam_16_max_attention": 2.79272198677063,
      "attention_bam_16_min_attention": -1.0656991004943848,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.34739737380896596,
      "attention_bam_16_attention_skewness": 0.7350631229357791,
      "attention_bam_16_attention_sparsity": 0.50537109375,
      "attention_bam_16_attention_concentration_10": 0.8062485102214327,
      "attention_bam_16_attention_concentration_20": 1.278397182187114,
      "attention_bam_16_attention_center_y": 0.4569460714760007,
      "attention_bam_16_attention_center_x": 0.4683668228294778,
      "attention_bam_16_attention_center_distance": 0.07555526003199631,
      "attention_bam_16_attention_spatial_variance": 41.621901234478074,
      "attention_bam_16_attention_spatial_std": 6.4515037963623705,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 7.591885193924568,
      "attention_bam_16_peak_intensity_mean": 0.3328935205936432,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 191,
      "phase": "train",
      "loss": 0.009435735642910004,
      "timestamp": 1759543910.4668763,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.009435735642910004,
      "ssim": 0.7934062480926514,
      "attention_bam_384_mean_attention": 0.15299127995967865,
      "attention_bam_384_std_attention": 0.4921712577342987,
      "attention_bam_384_max_attention": 3.790971517562866,
      "attention_bam_384_min_attention": -1.2621790170669556,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.9853569023835256,
      "attention_bam_384_attention_skewness": 0.8713263267707461,
      "attention_bam_384_attention_sparsity": 0.49174245198567706,
      "attention_bam_384_attention_concentration_10": 0.746815239165449,
      "attention_bam_384_attention_concentration_20": 1.1552169339816958,
      "attention_bam_384_attention_center_y": 0.4841578256553989,
      "attention_bam_384_attention_center_x": 0.48975480123570747,
      "attention_bam_384_attention_center_distance": 0.026681026430203123,
      "attention_bam_384_attention_spatial_variance": 170.7550407252798,
      "attention_bam_384_attention_spatial_std": 13.067327221940982,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 20.22036424987237,
      "attention_bam_384_peak_intensity_mean": 0.28179383277893066,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20641207695007324,
      "attention_bam_16_std_attention": 0.638505756855011,
      "attention_bam_16_max_attention": 3.623220682144165,
      "attention_bam_16_min_attention": -1.140231966972351,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.879090987596988,
      "attention_bam_16_attention_skewness": 1.0503809089861385,
      "attention_bam_16_attention_sparsity": 0.4892578125,
      "attention_bam_16_attention_concentration_10": 0.7441296180702163,
      "attention_bam_16_attention_concentration_20": 1.148152479614028,
      "attention_bam_16_attention_center_y": 0.46994598782229097,
      "attention_bam_16_attention_center_x": 0.4824656674962838,
      "attention_bam_16_attention_center_distance": 0.04920765111908436,
      "attention_bam_16_attention_spatial_variance": 42.701187774187325,
      "attention_bam_16_attention_spatial_std": 6.534614584976479,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 10.29715387292591,
      "attention_bam_16_peak_intensity_mean": 0.28934210538864136,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 192,
      "phase": "train",
      "loss": 0.006707347463816404,
      "timestamp": 1759543910.5970812,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006707347463816404,
      "ssim": 0.8558022975921631,
      "attention_bam_384_mean_attention": 0.14633528888225555,
      "attention_bam_384_std_attention": 0.49214819073677063,
      "attention_bam_384_max_attention": 4.283814430236816,
      "attention_bam_384_min_attention": -1.382073163986206,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.696028379362013,
      "attention_bam_384_attention_skewness": 0.8304457575265883,
      "attention_bam_384_attention_sparsity": 0.5024464925130209,
      "attention_bam_384_attention_concentration_10": 0.763829331242676,
      "attention_bam_384_attention_concentration_20": 1.2027526658293337,
      "attention_bam_384_attention_center_y": 0.4899780505353789,
      "attention_bam_384_attention_center_x": 0.482231209736573,
      "attention_bam_384_attention_center_distance": 0.028850281748956163,
      "attention_bam_384_attention_spatial_variance": 170.4416530078137,
      "attention_bam_384_attention_spatial_std": 13.055330444221383,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 17.63758530099728,
      "attention_bam_384_peak_intensity_mean": 0.2710633873939514,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18510985374450684,
      "attention_bam_16_std_attention": 0.6272825598716736,
      "attention_bam_16_max_attention": 4.120862007141113,
      "attention_bam_16_min_attention": -1.312334656715393,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.980911063845955,
      "attention_bam_16_attention_skewness": 1.0498315797450593,
      "attention_bam_16_attention_sparsity": 0.5146484375,
      "attention_bam_16_attention_concentration_10": 0.7914159390524504,
      "attention_bam_16_attention_concentration_20": 1.2403018004568471,
      "attention_bam_16_attention_center_y": 0.4808565240184025,
      "attention_bam_16_attention_center_x": 0.46528754832386404,
      "attention_bam_16_attention_center_distance": 0.056061162564222194,
      "attention_bam_16_attention_spatial_variance": 42.43759067537752,
      "attention_bam_16_attention_spatial_std": 6.514414069997203,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.753855527375539,
      "attention_bam_16_peak_intensity_mean": 0.27612683176994324,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 193,
      "phase": "train",
      "loss": 0.00949489139020443,
      "timestamp": 1759543910.7306983,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00949489139020443,
      "ssim": 0.812744140625,
      "attention_bam_384_mean_attention": 0.15091665089130402,
      "attention_bam_384_std_attention": 0.48192086815834045,
      "attention_bam_384_max_attention": 3.929131031036377,
      "attention_bam_384_min_attention": -1.2138062715530396,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.9369965325805545,
      "attention_bam_384_attention_skewness": 0.8772814491330282,
      "attention_bam_384_attention_sparsity": 0.4930572509765625,
      "attention_bam_384_attention_concentration_10": 0.7355702772710929,
      "attention_bam_384_attention_concentration_20": 1.1464435212542126,
      "attention_bam_384_attention_center_y": 0.4730053084834942,
      "attention_bam_384_attention_center_x": 0.4797501873503538,
      "attention_bam_384_attention_center_distance": 0.04772354308760156,
      "attention_bam_384_attention_spatial_variance": 171.86351127758547,
      "attention_bam_384_attention_spatial_std": 13.109672432123752,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 19.515219756618578,
      "attention_bam_384_peak_intensity_mean": 0.2767146825790405,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19409558176994324,
      "attention_bam_16_std_attention": 0.6015519499778748,
      "attention_bam_16_max_attention": 3.206672191619873,
      "attention_bam_16_min_attention": -0.9898277521133423,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.6548126549923392,
      "attention_bam_16_attention_skewness": 0.9525794858193954,
      "attention_bam_16_attention_sparsity": 0.4853515625,
      "attention_bam_16_attention_concentration_10": 0.7266624155202346,
      "attention_bam_16_attention_concentration_20": 1.1415420665143532,
      "attention_bam_16_attention_center_y": 0.4458923631880066,
      "attention_bam_16_attention_center_x": 0.46170937761597763,
      "attention_bam_16_attention_center_distance": 0.09374228633796357,
      "attention_bam_16_attention_spatial_variance": 43.1859941204716,
      "attention_bam_16_attention_spatial_std": 6.571605140334559,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 10.646670379825284,
      "attention_bam_16_peak_intensity_mean": 0.29802316427230835,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 194,
      "phase": "train",
      "loss": 0.017351647838950157,
      "timestamp": 1759543910.8550882,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.017351647838950157,
      "ssim": 0.8022069931030273,
      "attention_bam_384_mean_attention": 0.147705540060997,
      "attention_bam_384_std_attention": 0.5020759701728821,
      "attention_bam_384_max_attention": 4.210869312286377,
      "attention_bam_384_min_attention": -1.294559121131897,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.0245035543822993,
      "attention_bam_384_attention_skewness": 0.922564997874937,
      "attention_bam_384_attention_sparsity": 0.5017293294270834,
      "attention_bam_384_attention_concentration_10": 0.7855471349344239,
      "attention_bam_384_attention_concentration_20": 1.212751015130679,
      "attention_bam_384_attention_center_y": 0.4948224063987425,
      "attention_bam_384_attention_center_x": 0.4863113021597306,
      "attention_bam_384_attention_center_distance": 0.020697242524644603,
      "attention_bam_384_attention_spatial_variance": 171.348426392829,
      "attention_bam_384_attention_spatial_std": 13.090012467252619,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 17.05981413926973,
      "attention_bam_384_peak_intensity_mean": 0.2707752287387848,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1835981011390686,
      "attention_bam_16_std_attention": 0.6545537710189819,
      "attention_bam_16_max_attention": 4.214827537536621,
      "attention_bam_16_min_attention": -1.3184703588485718,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.566925001903699,
      "attention_bam_16_attention_skewness": 1.1315386948736181,
      "attention_bam_16_attention_sparsity": 0.4951171875,
      "attention_bam_16_attention_concentration_10": 0.834197707004375,
      "attention_bam_16_attention_concentration_20": 1.2761777801415553,
      "attention_bam_16_attention_center_y": 0.4906315078396219,
      "attention_bam_16_attention_center_x": 0.4726202451197807,
      "attention_bam_16_attention_center_distance": 0.04092479988124462,
      "attention_bam_16_attention_spatial_variance": 43.172615603549595,
      "attention_bam_16_attention_spatial_std": 6.570587158203565,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.24379620691304,
      "attention_bam_16_peak_intensity_mean": 0.2938913404941559,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 195,
      "phase": "train",
      "loss": 0.012298354879021645,
      "timestamp": 1759543910.9854186,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.012298354879021645,
      "ssim": 0.8219423294067383,
      "attention_bam_384_mean_attention": 0.14342518150806427,
      "attention_bam_384_std_attention": 0.4766761362552643,
      "attention_bam_384_max_attention": 4.716835975646973,
      "attention_bam_384_min_attention": -1.3502368927001953,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.3032577175715563,
      "attention_bam_384_attention_skewness": 0.961715427070382,
      "attention_bam_384_attention_sparsity": 0.5073750813802084,
      "attention_bam_384_attention_concentration_10": 0.7667528464289681,
      "attention_bam_384_attention_concentration_20": 1.1922115308090595,
      "attention_bam_384_attention_center_y": 0.48053888678442713,
      "attention_bam_384_attention_center_x": 0.4884499266655776,
      "attention_bam_384_attention_center_distance": 0.03200434725533016,
      "attention_bam_384_attention_spatial_variance": 169.88196729205808,
      "attention_bam_384_attention_spatial_std": 13.033877676733738,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 19.429657907791324,
      "attention_bam_384_peak_intensity_mean": 0.2532617747783661,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17728310823440552,
      "attention_bam_16_std_attention": 0.6027597784996033,
      "attention_bam_16_max_attention": 3.4974558353424072,
      "attention_bam_16_min_attention": -1.1651828289031982,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.346804096413873,
      "attention_bam_16_attention_skewness": 0.8966743550329677,
      "attention_bam_16_attention_sparsity": 0.505859375,
      "attention_bam_16_attention_concentration_10": 0.7812984459854138,
      "attention_bam_16_attention_concentration_20": 1.231504997600981,
      "attention_bam_16_attention_center_y": 0.46138051945175074,
      "attention_bam_16_attention_center_x": 0.4783952980663322,
      "attention_bam_16_attention_center_distance": 0.06258158552576361,
      "attention_bam_16_attention_spatial_variance": 42.33082406315534,
      "attention_bam_16_attention_spatial_std": 6.50621426508191,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 7.0935201395395895,
      "attention_bam_16_peak_intensity_mean": 0.31961214542388916,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 196,
      "phase": "train",
      "loss": 0.00983511283993721,
      "timestamp": 1759543911.1175032,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00983511283993721,
      "ssim": 0.8342832326889038,
      "attention_bam_384_mean_attention": 0.14710350334644318,
      "attention_bam_384_std_attention": 0.4745241403579712,
      "attention_bam_384_max_attention": 3.754079580307007,
      "attention_bam_384_min_attention": -1.2847673892974854,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.39002192419398574,
      "attention_bam_384_attention_skewness": 0.4990279483416945,
      "attention_bam_384_attention_sparsity": 0.48823801676432294,
      "attention_bam_384_attention_concentration_10": 0.7148863000646256,
      "attention_bam_384_attention_concentration_20": 1.15299875931272,
      "attention_bam_384_attention_center_y": 0.4872835189424102,
      "attention_bam_384_attention_center_x": 0.48346533552385645,
      "attention_bam_384_attention_center_distance": 0.02949928879911121,
      "attention_bam_384_attention_spatial_variance": 171.01989587051315,
      "attention_bam_384_attention_spatial_std": 13.077457546117792,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 15.759135459023094,
      "attention_bam_384_peak_intensity_mean": 0.2850953936576843,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19524824619293213,
      "attention_bam_16_std_attention": 0.597293496131897,
      "attention_bam_16_max_attention": 2.623300790786743,
      "attention_bam_16_min_attention": -1.2038376331329346,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.029531373200969213,
      "attention_bam_16_attention_skewness": 0.4954963891241227,
      "attention_bam_16_attention_sparsity": 0.46142578125,
      "attention_bam_16_attention_concentration_10": 0.6795678937260747,
      "attention_bam_16_attention_concentration_20": 1.1076593953805085,
      "attention_bam_16_attention_center_y": 0.4744798360515681,
      "attention_bam_16_attention_center_x": 0.4668306901774729,
      "attention_bam_16_attention_center_distance": 0.05918584090908286,
      "attention_bam_16_attention_spatial_variance": 42.7803123854736,
      "attention_bam_16_attention_spatial_std": 6.540666050600168,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.128452192091487,
      "attention_bam_16_peak_intensity_mean": 0.3668041229248047,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 197,
      "phase": "train",
      "loss": 0.008955925703048706,
      "timestamp": 1759543911.2459614,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008955925703048706,
      "ssim": 0.8170914649963379,
      "attention_bam_384_mean_attention": 0.1445036232471466,
      "attention_bam_384_std_attention": 0.4816187918186188,
      "attention_bam_384_max_attention": 3.689765214920044,
      "attention_bam_384_min_attention": -1.3271178007125854,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7170223818199366,
      "attention_bam_384_attention_skewness": 0.6509410083848471,
      "attention_bam_384_attention_sparsity": 0.4989217122395833,
      "attention_bam_384_attention_concentration_10": 0.7598208220682386,
      "attention_bam_384_attention_concentration_20": 1.1938825856435704,
      "attention_bam_384_attention_center_y": 0.4889265114647527,
      "attention_bam_384_attention_center_x": 0.4878289418942422,
      "attention_bam_384_attention_center_distance": 0.02327044493575429,
      "attention_bam_384_attention_spatial_variance": 171.59884140764714,
      "attention_bam_384_attention_spatial_std": 13.099574092604962,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 18.3880140974965,
      "attention_bam_384_peak_intensity_mean": 0.29613032937049866,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.189358651638031,
      "attention_bam_16_std_attention": 0.5930258631706238,
      "attention_bam_16_max_attention": 2.818603515625,
      "attention_bam_16_min_attention": -1.1211920976638794,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.4372713765100338,
      "attention_bam_16_attention_skewness": 0.6826282530799811,
      "attention_bam_16_attention_sparsity": 0.47607421875,
      "attention_bam_16_attention_concentration_10": 0.7263033178991324,
      "attention_bam_16_attention_concentration_20": 1.1502917456462847,
      "attention_bam_16_attention_center_y": 0.48007753339268666,
      "attention_bam_16_attention_center_x": 0.47836839208946136,
      "attention_bam_16_attention_center_distance": 0.04158920861268685,
      "attention_bam_16_attention_spatial_variance": 43.30517348252322,
      "attention_bam_16_attention_spatial_std": 6.580666644233183,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.268595202212415,
      "attention_bam_16_peak_intensity_mean": 0.3410319685935974,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 198,
      "phase": "train",
      "loss": 0.008614829741418362,
      "timestamp": 1759543911.377339,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008614829741418362,
      "ssim": 0.8165087103843689,
      "attention_bam_384_mean_attention": 0.13887996971607208,
      "attention_bam_384_std_attention": 0.4952761232852936,
      "attention_bam_384_max_attention": 4.90936279296875,
      "attention_bam_384_min_attention": -1.3608472347259521,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.7437818065960906,
      "attention_bam_384_attention_skewness": 1.1423822368578416,
      "attention_bam_384_attention_sparsity": 0.5080490112304688,
      "attention_bam_384_attention_concentration_10": 0.8222820182606422,
      "attention_bam_384_attention_concentration_20": 1.2462138368520554,
      "attention_bam_384_attention_center_y": 0.48201924346248337,
      "attention_bam_384_attention_center_x": 0.4792176771263824,
      "attention_bam_384_attention_center_distance": 0.03886418787739519,
      "attention_bam_384_attention_spatial_variance": 169.7848832879808,
      "attention_bam_384_attention_spatial_std": 13.030152849755094,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 16.471073349806726,
      "attention_bam_384_peak_intensity_mean": 0.2403397560119629,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1755947470664978,
      "attention_bam_16_std_attention": 0.6101706624031067,
      "attention_bam_16_max_attention": 4.499420166015625,
      "attention_bam_16_min_attention": -1.066493272781372,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.6634448899744942,
      "attention_bam_16_attention_skewness": 1.2802626348179562,
      "attention_bam_16_attention_sparsity": 0.499267578125,
      "attention_bam_16_attention_concentration_10": 0.8208502673519295,
      "attention_bam_16_attention_concentration_20": 1.2402783986608235,
      "attention_bam_16_attention_center_y": 0.4619253324042445,
      "attention_bam_16_attention_center_x": 0.45899409119812384,
      "attention_bam_16_attention_center_distance": 0.079134883195656,
      "attention_bam_16_attention_spatial_variance": 41.93830187607725,
      "attention_bam_16_attention_spatial_std": 6.4759788353635965,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.383604530663076,
      "attention_bam_16_peak_intensity_mean": 0.2273620367050171,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 199,
      "phase": "train",
      "loss": 0.007519576698541641,
      "timestamp": 1759543911.5173364,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007519576698541641,
      "ssim": 0.8390247821807861,
      "attention_bam_384_mean_attention": 0.14188824594020844,
      "attention_bam_384_std_attention": 0.47779011726379395,
      "attention_bam_384_max_attention": 3.660221576690674,
      "attention_bam_384_min_attention": -1.4077683687210083,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8068839570945183,
      "attention_bam_384_attention_skewness": 0.8743367004041966,
      "attention_bam_384_attention_sparsity": 0.5031077067057291,
      "attention_bam_384_attention_concentration_10": 0.7779949055298013,
      "attention_bam_384_attention_concentration_20": 1.2007502938118844,
      "attention_bam_384_attention_center_y": 0.4774826143818948,
      "attention_bam_384_attention_center_x": 0.4818585635821838,
      "attention_bam_384_attention_center_distance": 0.040893627141062386,
      "attention_bam_384_attention_spatial_variance": 169.61064769732602,
      "attention_bam_384_attention_spatial_std": 13.023465272243252,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 17.590857311039418,
      "attention_bam_384_peak_intensity_mean": 0.3048146069049835,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19306091964244843,
      "attention_bam_16_std_attention": 0.6028867363929749,
      "attention_bam_16_max_attention": 3.5798587799072266,
      "attention_bam_16_min_attention": -1.2818440198898315,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.3807082501532673,
      "attention_bam_16_attention_skewness": 0.9163019242940298,
      "attention_bam_16_attention_sparsity": 0.48681640625,
      "attention_bam_16_attention_concentration_10": 0.736296164445746,
      "attention_bam_16_attention_concentration_20": 1.1411407090832693,
      "attention_bam_16_attention_center_y": 0.4570575004693984,
      "attention_bam_16_attention_center_x": 0.4655837900287233,
      "attention_bam_16_attention_center_distance": 0.07782716459852206,
      "attention_bam_16_attention_spatial_variance": 42.02114590920369,
      "attention_bam_16_attention_spatial_std": 6.48237193542639,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.546863316031624,
      "attention_bam_16_peak_intensity_mean": 0.3038835823535919,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 200,
      "phase": "train",
      "loss": 0.012391421012580395,
      "timestamp": 1759543911.730621,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.012391421012580395,
      "ssim": 0.8507910966873169,
      "attention_bam_384_mean_attention": 0.14395858347415924,
      "attention_bam_384_std_attention": 0.47958746552467346,
      "attention_bam_384_max_attention": 3.54939866065979,
      "attention_bam_384_min_attention": -1.2895009517669678,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8785932480547953,
      "attention_bam_384_attention_skewness": 0.636993790960357,
      "attention_bam_384_attention_sparsity": 0.4995981852213542,
      "attention_bam_384_attention_concentration_10": 0.7373112019621445,
      "attention_bam_384_attention_concentration_20": 1.1836673545483163,
      "attention_bam_384_attention_center_y": 0.484133136667208,
      "attention_bam_384_attention_center_x": 0.48278204651647294,
      "attention_bam_384_attention_center_distance": 0.03311239267049126,
      "attention_bam_384_attention_spatial_variance": 167.34679307529623,
      "attention_bam_384_attention_spatial_std": 12.936258851588285,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 15.19542198032123,
      "attention_bam_384_peak_intensity_mean": 0.3000822365283966,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2035994678735733,
      "attention_bam_16_std_attention": 0.5996523499488831,
      "attention_bam_16_max_attention": 2.849184036254883,
      "attention_bam_16_min_attention": -1.2806262969970703,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.4820705119106825,
      "attention_bam_16_attention_skewness": 0.6197650567441203,
      "attention_bam_16_attention_sparsity": 0.47216796875,
      "attention_bam_16_attention_concentration_10": 0.6629999906970969,
      "attention_bam_16_attention_concentration_20": 1.0716943872042028,
      "attention_bam_16_attention_center_y": 0.4684966499822603,
      "attention_bam_16_attention_center_x": 0.46770131095994766,
      "attention_bam_16_attention_center_distance": 0.06380699610616716,
      "attention_bam_16_attention_spatial_variance": 41.2339227301045,
      "attention_bam_16_attention_spatial_std": 6.4213645535901875,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 7.329997783660099,
      "attention_bam_16_peak_intensity_mean": 0.36567845940589905,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 201,
      "phase": "train",
      "loss": 0.007504624780267477,
      "timestamp": 1759543913.9554021,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007504624780267477,
      "ssim": 0.8457408547401428,
      "attention_bam_384_mean_attention": 0.14505413174629211,
      "attention_bam_384_std_attention": 0.49353283643722534,
      "attention_bam_384_max_attention": 4.463116645812988,
      "attention_bam_384_min_attention": -1.4484611749649048,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.4574995636771417,
      "attention_bam_384_attention_skewness": 0.9135135768808836,
      "attention_bam_384_attention_sparsity": 0.5004119873046875,
      "attention_bam_384_attention_concentration_10": 0.7771692154578398,
      "attention_bam_384_attention_concentration_20": 1.20152117294853,
      "attention_bam_384_attention_center_y": 0.4852565341943822,
      "attention_bam_384_attention_center_x": 0.48247325362936705,
      "attention_bam_384_attention_center_distance": 0.032390017669088014,
      "attention_bam_384_attention_spatial_variance": 170.0989004135916,
      "attention_bam_384_attention_spatial_std": 13.042196916685148,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 17.22062614829871,
      "attention_bam_384_peak_intensity_mean": 0.27108892798423767,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2000674605369568,
      "attention_bam_16_std_attention": 0.6083325147628784,
      "attention_bam_16_max_attention": 3.9837355613708496,
      "attention_bam_16_min_attention": -1.1598223447799683,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.991967808524982,
      "attention_bam_16_attention_skewness": 1.0982809771769833,
      "attention_bam_16_attention_sparsity": 0.469970703125,
      "attention_bam_16_attention_concentration_10": 0.7064481651597428,
      "attention_bam_16_attention_concentration_20": 1.100182030776889,
      "attention_bam_16_attention_center_y": 0.4712976606176873,
      "attention_bam_16_attention_center_x": 0.46535963551507914,
      "attention_bam_16_attention_center_distance": 0.06362042341364328,
      "attention_bam_16_attention_spatial_variance": 42.118390481796716,
      "attention_bam_16_attention_spatial_std": 6.489868294641789,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 7.689147707158228,
      "attention_bam_16_peak_intensity_mean": 0.27098506689071655,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 202,
      "phase": "train",
      "loss": 0.007833022624254227,
      "timestamp": 1759543914.0871758,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007833022624254227,
      "ssim": 0.8590744733810425,
      "attention_bam_384_mean_attention": 0.14339473843574524,
      "attention_bam_384_std_attention": 0.5029557347297668,
      "attention_bam_384_max_attention": 4.846997261047363,
      "attention_bam_384_min_attention": -1.4436633586883545,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.454277362700825,
      "attention_bam_384_attention_skewness": 0.8490973172351725,
      "attention_bam_384_attention_sparsity": 0.5014724731445312,
      "attention_bam_384_attention_concentration_10": 0.7863817648539572,
      "attention_bam_384_attention_concentration_20": 1.229097029239344,
      "attention_bam_384_attention_center_y": 0.48361414714283824,
      "attention_bam_384_attention_center_x": 0.4770526853113457,
      "attention_bam_384_attention_center_distance": 0.03987669558217395,
      "attention_bam_384_attention_spatial_variance": 169.8537923985868,
      "attention_bam_384_attention_spatial_std": 13.032796798791377,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 15.296104646039915,
      "attention_bam_384_peak_intensity_mean": 0.2534787952899933,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20178402960300446,
      "attention_bam_16_std_attention": 0.6279023289680481,
      "attention_bam_16_max_attention": 4.080934047698975,
      "attention_bam_16_min_attention": -1.2787673473358154,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.490307887362855,
      "attention_bam_16_attention_skewness": 1.012302567667483,
      "attention_bam_16_attention_sparsity": 0.481201171875,
      "attention_bam_16_attention_concentration_10": 0.7120443182820436,
      "attention_bam_16_attention_concentration_20": 1.1236403183352552,
      "attention_bam_16_attention_center_y": 0.4663840968554941,
      "attention_bam_16_attention_center_x": 0.45485888289325593,
      "attention_bam_16_attention_center_distance": 0.07959584659849513,
      "attention_bam_16_attention_spatial_variance": 42.103530711207746,
      "attention_bam_16_attention_spatial_std": 6.488723349874592,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 7.894895787316868,
      "attention_bam_16_peak_intensity_mean": 0.2791069746017456,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 203,
      "phase": "train",
      "loss": 0.015508456155657768,
      "timestamp": 1759543914.2192883,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.015508456155657768,
      "ssim": 0.8005753755569458,
      "attention_bam_384_mean_attention": 0.1383049488067627,
      "attention_bam_384_std_attention": 0.42259883880615234,
      "attention_bam_384_max_attention": 3.8458409309387207,
      "attention_bam_384_min_attention": -1.4024103879928589,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 4.169508057486888,
      "attention_bam_384_attention_skewness": 1.12683728084083,
      "attention_bam_384_attention_sparsity": 0.49613698323567706,
      "attention_bam_384_attention_concentration_10": 0.7162424818088197,
      "attention_bam_384_attention_concentration_20": 1.0794477494698578,
      "attention_bam_384_attention_center_y": 0.4797556701004041,
      "attention_bam_384_attention_center_x": 0.48171021871384523,
      "attention_bam_384_attention_center_distance": 0.03858364919442042,
      "attention_bam_384_attention_spatial_variance": 170.510405393903,
      "attention_bam_384_attention_spatial_std": 13.05796329424704,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 17.347553223192396,
      "attention_bam_384_peak_intensity_mean": 0.29600128531455994,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1794079691171646,
      "attention_bam_16_std_attention": 0.5479638576507568,
      "attention_bam_16_max_attention": 3.802489757537842,
      "attention_bam_16_min_attention": -1.1101642847061157,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.552945380436361,
      "attention_bam_16_attention_skewness": 1.1924255852598111,
      "attention_bam_16_attention_sparsity": 0.47216796875,
      "attention_bam_16_attention_concentration_10": 0.7230150005736394,
      "attention_bam_16_attention_concentration_20": 1.095755143419006,
      "attention_bam_16_attention_center_y": 0.45637191680925615,
      "attention_bam_16_attention_center_x": 0.46494450258318915,
      "attention_bam_16_attention_center_distance": 0.07914919509430905,
      "attention_bam_16_attention_spatial_variance": 42.461898449947306,
      "attention_bam_16_attention_spatial_std": 6.516279494462105,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.506230187241222,
      "attention_bam_16_peak_intensity_mean": 0.2716118097305298,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 204,
      "phase": "train",
      "loss": 0.009196639060974121,
      "timestamp": 1759543914.3509638,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.009196639060974121,
      "ssim": 0.8216139674186707,
      "attention_bam_384_mean_attention": 0.13492482900619507,
      "attention_bam_384_std_attention": 0.4715151786804199,
      "attention_bam_384_max_attention": 5.106144905090332,
      "attention_bam_384_min_attention": -1.3426003456115723,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 4.162077033629643,
      "attention_bam_384_attention_skewness": 1.1722459956197577,
      "attention_bam_384_attention_sparsity": 0.5129903157552084,
      "attention_bam_384_attention_concentration_10": 0.7950408990500475,
      "attention_bam_384_attention_concentration_20": 1.2268080540254784,
      "attention_bam_384_attention_center_y": 0.47971695146222676,
      "attention_bam_384_attention_center_x": 0.4830800043071246,
      "attention_bam_384_attention_center_distance": 0.037354740321211895,
      "attention_bam_384_attention_spatial_variance": 170.31597835378145,
      "attention_bam_384_attention_spatial_std": 13.050516401805005,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 17.151469078842187,
      "attention_bam_384_peak_intensity_mean": 0.22992846369743347,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1922927349805832,
      "attention_bam_16_std_attention": 0.616927444934845,
      "attention_bam_16_max_attention": 4.462656497955322,
      "attention_bam_16_min_attention": -1.3186448812484741,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 4.780389788069414,
      "attention_bam_16_attention_skewness": 1.4359166273313169,
      "attention_bam_16_attention_sparsity": 0.4873046875,
      "attention_bam_16_attention_concentration_10": 0.7546555489221247,
      "attention_bam_16_attention_concentration_20": 1.1469423141945305,
      "attention_bam_16_attention_center_y": 0.4602664804916983,
      "attention_bam_16_attention_center_x": 0.46598591832734315,
      "attention_bam_16_attention_center_distance": 0.07396905196838417,
      "attention_bam_16_attention_spatial_variance": 42.33005979224493,
      "attention_bam_16_attention_spatial_std": 6.506155530898791,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.007552191932184,
      "attention_bam_16_peak_intensity_mean": 0.25726109743118286,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 205,
      "phase": "train",
      "loss": 0.008867939934134483,
      "timestamp": 1759543914.481155,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008867939934134483,
      "ssim": 0.8093408942222595,
      "attention_bam_384_mean_attention": 0.13543765246868134,
      "attention_bam_384_std_attention": 0.494917631149292,
      "attention_bam_384_max_attention": 4.63588809967041,
      "attention_bam_384_min_attention": -1.4181973934173584,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.9817502433061192,
      "attention_bam_384_attention_skewness": 0.8734048525702397,
      "attention_bam_384_attention_sparsity": 0.5102132161458334,
      "attention_bam_384_attention_concentration_10": 0.8327203379883427,
      "attention_bam_384_attention_concentration_20": 1.284589543480571,
      "attention_bam_384_attention_center_y": 0.48094253124122216,
      "attention_bam_384_attention_center_x": 0.48405866433062117,
      "attention_bam_384_attention_center_distance": 0.03513725368937086,
      "attention_bam_384_attention_spatial_variance": 170.35626596929424,
      "attention_bam_384_attention_spatial_std": 13.052059836259343,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 14.452733999598713,
      "attention_bam_384_peak_intensity_mean": 0.25683319568634033,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18779432773590088,
      "attention_bam_16_std_attention": 0.6170536279678345,
      "attention_bam_16_max_attention": 4.444238185882568,
      "attention_bam_16_min_attention": -1.372320294380188,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.268428198696598,
      "attention_bam_16_attention_skewness": 1.012964310326288,
      "attention_bam_16_attention_sparsity": 0.484375,
      "attention_bam_16_attention_concentration_10": 0.7686819231135623,
      "attention_bam_16_attention_concentration_20": 1.1813158709782672,
      "attention_bam_16_attention_center_y": 0.4639657875728878,
      "attention_bam_16_attention_center_x": 0.46423647352666686,
      "attention_bam_16_attention_center_distance": 0.0717982491576368,
      "attention_bam_16_attention_spatial_variance": 42.37416330185883,
      "attention_bam_16_attention_spatial_std": 6.509544016431476,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.950691405628502,
      "attention_bam_16_peak_intensity_mean": 0.27100369334220886,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 206,
      "phase": "train",
      "loss": 0.00840152706950903,
      "timestamp": 1759543914.6122339,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00840152706950903,
      "ssim": 0.8228289484977722,
      "attention_bam_384_mean_attention": 0.1325465887784958,
      "attention_bam_384_std_attention": 0.471238911151886,
      "attention_bam_384_max_attention": 3.878072738647461,
      "attention_bam_384_min_attention": -1.3703830242156982,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.3334399546495934,
      "attention_bam_384_attention_skewness": 0.9214267573133625,
      "attention_bam_384_attention_sparsity": 0.5085627237955729,
      "attention_bam_384_attention_concentration_10": 0.8099053735948686,
      "attention_bam_384_attention_concentration_20": 1.2491824667138343,
      "attention_bam_384_attention_center_y": 0.4823528656155446,
      "attention_bam_384_attention_center_x": 0.4905909112291975,
      "attention_bam_384_attention_center_distance": 0.02828258487054782,
      "attention_bam_384_attention_spatial_variance": 170.8578827818668,
      "attention_bam_384_attention_spatial_std": 13.071261713463885,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 19.86435297348198,
      "attention_bam_384_peak_intensity_mean": 0.28779903054237366,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18535752594470978,
      "attention_bam_16_std_attention": 0.5840983986854553,
      "attention_bam_16_max_attention": 3.636023998260498,
      "attention_bam_16_min_attention": -1.1032296419143677,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.7125189797525664,
      "attention_bam_16_attention_skewness": 1.1068508416872047,
      "attention_bam_16_attention_sparsity": 0.48583984375,
      "attention_bam_16_attention_concentration_10": 0.7395065234754575,
      "attention_bam_16_attention_concentration_20": 1.1348035268868075,
      "attention_bam_16_attention_center_y": 0.46576722030371215,
      "attention_bam_16_attention_center_x": 0.4815002277732648,
      "attention_bam_16_attention_center_distance": 0.0550295334920379,
      "attention_bam_16_attention_spatial_variance": 42.949559735268245,
      "attention_bam_16_attention_spatial_std": 6.553591361632814,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 7.901296515851425,
      "attention_bam_16_peak_intensity_mean": 0.2731432318687439,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 207,
      "phase": "train",
      "loss": 0.009956100955605507,
      "timestamp": 1759543914.7428536,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.009956100955605507,
      "ssim": 0.8102021217346191,
      "attention_bam_384_mean_attention": 0.13996027410030365,
      "attention_bam_384_std_attention": 0.44727057218551636,
      "attention_bam_384_max_attention": 3.3968007564544678,
      "attention_bam_384_min_attention": -1.2538071870803833,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2420405185877756,
      "attention_bam_384_attention_skewness": 0.6171240615062648,
      "attention_bam_384_attention_sparsity": 0.48303476969401044,
      "attention_bam_384_attention_concentration_10": 0.7116452193479473,
      "attention_bam_384_attention_concentration_20": 1.126074616524919,
      "attention_bam_384_attention_center_y": 0.4894685054595933,
      "attention_bam_384_attention_center_x": 0.4849534612887511,
      "attention_bam_384_attention_center_distance": 0.02597347510225489,
      "attention_bam_384_attention_spatial_variance": 169.2480382818185,
      "attention_bam_384_attention_spatial_std": 13.00953643608482,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 17.220041687005214,
      "attention_bam_384_peak_intensity_mean": 0.3024619221687317,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2095615118741989,
      "attention_bam_16_std_attention": 0.5744051933288574,
      "attention_bam_16_max_attention": 3.1379787921905518,
      "attention_bam_16_min_attention": -1.0899072885513306,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.9874698006930136,
      "attention_bam_16_attention_skewness": 0.6640271979410144,
      "attention_bam_16_attention_sparsity": 0.452392578125,
      "attention_bam_16_attention_concentration_10": 0.6376306357511896,
      "attention_bam_16_attention_concentration_20": 1.0128529054127995,
      "attention_bam_16_attention_center_y": 0.4761413072841516,
      "attention_bam_16_attention_center_x": 0.4704860290030856,
      "attention_bam_16_attention_center_distance": 0.05367143937171763,
      "attention_bam_16_attention_spatial_variance": 42.31859762427656,
      "attention_bam_16_attention_spatial_std": 6.505274600220698,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.587756881833515,
      "attention_bam_16_peak_intensity_mean": 0.31284552812576294,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 208,
      "phase": "train",
      "loss": 0.007442230358719826,
      "timestamp": 1759543914.8739023,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007442230358719826,
      "ssim": 0.8567006587982178,
      "attention_bam_384_mean_attention": 0.13515399396419525,
      "attention_bam_384_std_attention": 0.4915706515312195,
      "attention_bam_384_max_attention": 3.9395689964294434,
      "attention_bam_384_min_attention": -1.3813108205795288,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.316524083623385,
      "attention_bam_384_attention_skewness": 0.9701774005826872,
      "attention_bam_384_attention_sparsity": 0.5150807698567709,
      "attention_bam_384_attention_concentration_10": 0.8350590777082845,
      "attention_bam_384_attention_concentration_20": 1.2855179405110992,
      "attention_bam_384_attention_center_y": 0.4794959580316606,
      "attention_bam_384_attention_center_x": 0.48836519591347183,
      "attention_bam_384_attention_center_distance": 0.03334019805494008,
      "attention_bam_384_attention_spatial_variance": 173.2606796319607,
      "attention_bam_384_attention_spatial_std": 13.162852260508005,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 19.233837990128492,
      "attention_bam_384_peak_intensity_mean": 0.28608086705207825,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19278064370155334,
      "attention_bam_16_std_attention": 0.6090941429138184,
      "attention_bam_16_max_attention": 4.275623798370361,
      "attention_bam_16_min_attention": -1.1482385396957397,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.345685455681152,
      "attention_bam_16_attention_skewness": 1.038692656907698,
      "attention_bam_16_attention_sparsity": 0.486083984375,
      "attention_bam_16_attention_concentration_10": 0.7393849871092678,
      "attention_bam_16_attention_concentration_20": 1.1487200951522145,
      "attention_bam_16_attention_center_y": 0.4580630164947441,
      "attention_bam_16_attention_center_x": 0.47462378697807533,
      "attention_bam_16_attention_center_distance": 0.06932045546379802,
      "attention_bam_16_attention_spatial_variance": 43.855899485965274,
      "attention_bam_16_attention_spatial_std": 6.6223786879009925,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.293225001673722,
      "attention_bam_16_peak_intensity_mean": 0.24935713410377502,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 209,
      "phase": "train",
      "loss": 0.008819065056741238,
      "timestamp": 1759543915.0039825,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008819065056741238,
      "ssim": 0.7889212369918823,
      "attention_bam_384_mean_attention": 0.13678045570850372,
      "attention_bam_384_std_attention": 0.5199711322784424,
      "attention_bam_384_max_attention": 3.4097723960876465,
      "attention_bam_384_min_attention": -1.3611754179000854,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1336377632455994,
      "attention_bam_384_attention_skewness": 0.7568721154531336,
      "attention_bam_384_attention_sparsity": 0.5143966674804688,
      "attention_bam_384_attention_concentration_10": 0.8556278552383368,
      "attention_bam_384_attention_concentration_20": 1.3358025926930284,
      "attention_bam_384_attention_center_y": 0.4868951176036421,
      "attention_bam_384_attention_center_x": 0.47441875165637076,
      "attention_bam_384_attention_center_distance": 0.04064820314456234,
      "attention_bam_384_attention_spatial_variance": 167.73250350918022,
      "attention_bam_384_attention_spatial_std": 12.951158384838795,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 16.518356023892377,
      "attention_bam_384_peak_intensity_mean": 0.3169579803943634,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19181230664253235,
      "attention_bam_16_std_attention": 0.6569133996963501,
      "attention_bam_16_max_attention": 3.167470932006836,
      "attention_bam_16_min_attention": -1.3829344511032104,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.2516623697161702,
      "attention_bam_16_attention_skewness": 0.914318199440645,
      "attention_bam_16_attention_sparsity": 0.502197265625,
      "attention_bam_16_attention_concentration_10": 0.7968154268449996,
      "attention_bam_16_attention_concentration_20": 1.235947467361132,
      "attention_bam_16_attention_center_y": 0.47152160947987976,
      "attention_bam_16_attention_center_x": 0.4528262013016736,
      "attention_bam_16_attention_center_distance": 0.07792799253473291,
      "attention_bam_16_attention_spatial_variance": 41.26265154670689,
      "attention_bam_16_attention_spatial_std": 6.423601135399589,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.513358824975827,
      "attention_bam_16_peak_intensity_mean": 0.3468717932701111,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 210,
      "phase": "train",
      "loss": 0.008261008188128471,
      "timestamp": 1759543915.178717,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008261008188128471,
      "ssim": 0.8505794405937195,
      "attention_bam_384_mean_attention": 0.13946765661239624,
      "attention_bam_384_std_attention": 0.48086652159690857,
      "attention_bam_384_max_attention": 3.5354511737823486,
      "attention_bam_384_min_attention": -1.3249573707580566,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2825390791207667,
      "attention_bam_384_attention_skewness": 0.6739302431801518,
      "attention_bam_384_attention_sparsity": 0.49725341796875,
      "attention_bam_384_attention_concentration_10": 0.766773125162885,
      "attention_bam_384_attention_concentration_20": 1.2132994911273114,
      "attention_bam_384_attention_center_y": 0.48593116025699756,
      "attention_bam_384_attention_center_x": 0.49267376336514257,
      "attention_bam_384_attention_center_distance": 0.02243238707512921,
      "attention_bam_384_attention_spatial_variance": 168.42814855094616,
      "attention_bam_384_attention_spatial_std": 12.977987076235905,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 17.900611419099853,
      "attention_bam_384_peak_intensity_mean": 0.3051481246948242,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19579678773880005,
      "attention_bam_16_std_attention": 0.6071983575820923,
      "attention_bam_16_max_attention": 3.706533908843994,
      "attention_bam_16_min_attention": -1.1295156478881836,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.5127893607332403,
      "attention_bam_16_attention_skewness": 0.8362190692473871,
      "attention_bam_16_attention_sparsity": 0.477294921875,
      "attention_bam_16_attention_concentration_10": 0.7106242151558689,
      "attention_bam_16_attention_concentration_20": 1.123670327314619,
      "attention_bam_16_attention_center_y": 0.47208029811217456,
      "attention_bam_16_attention_center_x": 0.48692821278590126,
      "attention_bam_16_attention_center_distance": 0.04359773788800788,
      "attention_bam_16_attention_spatial_variance": 41.62320612075522,
      "attention_bam_16_attention_spatial_std": 6.451604925966501,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.462663422835943,
      "attention_bam_16_peak_intensity_mean": 0.27703380584716797,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 211,
      "phase": "train",
      "loss": 0.008133772760629654,
      "timestamp": 1759543915.3107197,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008133772760629654,
      "ssim": 0.8109790682792664,
      "attention_bam_384_mean_attention": 0.1366269737482071,
      "attention_bam_384_std_attention": 0.429181307554245,
      "attention_bam_384_max_attention": 3.2370073795318604,
      "attention_bam_384_min_attention": -1.3290420770645142,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7134842797826138,
      "attention_bam_384_attention_skewness": 0.5858950839714103,
      "attention_bam_384_attention_sparsity": 0.5001653035481771,
      "attention_bam_384_attention_concentration_10": 0.7102871582587961,
      "attention_bam_384_attention_concentration_20": 1.1336927180209333,
      "attention_bam_384_attention_center_y": 0.48499282940460625,
      "attention_bam_384_attention_center_x": 0.48526186654136777,
      "attention_bam_384_attention_center_distance": 0.0297465207082679,
      "attention_bam_384_attention_spatial_variance": 168.62436633027332,
      "attention_bam_384_attention_spatial_std": 12.98554451420014,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 16.320031446737286,
      "attention_bam_384_peak_intensity_mean": 0.323563814163208,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19693982601165771,
      "attention_bam_16_std_attention": 0.5564566850662231,
      "attention_bam_16_max_attention": 2.679421901702881,
      "attention_bam_16_min_attention": -1.0643064975738525,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.42072256381154016,
      "attention_bam_16_attention_skewness": 0.628235075862957,
      "attention_bam_16_attention_sparsity": 0.471923828125,
      "attention_bam_16_attention_concentration_10": 0.6515459419755543,
      "attention_bam_16_attention_concentration_20": 1.0489595962706462,
      "attention_bam_16_attention_center_y": 0.46931731481149047,
      "attention_bam_16_attention_center_x": 0.4716671787744202,
      "attention_bam_16_attention_center_distance": 0.059062271019286856,
      "attention_bam_16_attention_spatial_variance": 41.53125786301622,
      "attention_bam_16_attention_spatial_std": 6.444474987383861,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.045935753708488,
      "attention_bam_16_peak_intensity_mean": 0.3436731696128845,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 212,
      "phase": "train",
      "loss": 0.010335159488022327,
      "timestamp": 1759543915.4431076,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.010335159488022327,
      "ssim": 0.8514715433120728,
      "attention_bam_384_mean_attention": 0.13798673450946808,
      "attention_bam_384_std_attention": 0.4526837468147278,
      "attention_bam_384_max_attention": 3.551018476486206,
      "attention_bam_384_min_attention": -1.3102734088897705,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9659517654278389,
      "attention_bam_384_attention_skewness": 0.6136826235431846,
      "attention_bam_384_attention_sparsity": 0.49946339925130206,
      "attention_bam_384_attention_concentration_10": 0.736142892110849,
      "attention_bam_384_attention_concentration_20": 1.1707187801469383,
      "attention_bam_384_attention_center_y": 0.48669787094620715,
      "attention_bam_384_attention_center_x": 0.48732094193981407,
      "attention_bam_384_attention_center_distance": 0.025988657166438046,
      "attention_bam_384_attention_spatial_variance": 169.31140497406454,
      "attention_bam_384_attention_spatial_std": 13.011971602107982,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 16.587172392856154,
      "attention_bam_384_peak_intensity_mean": 0.3010706305503845,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1986703872680664,
      "attention_bam_16_std_attention": 0.5755923986434937,
      "attention_bam_16_max_attention": 2.9727301597595215,
      "attention_bam_16_min_attention": -1.1389588117599487,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.9883101891106358,
      "attention_bam_16_attention_skewness": 0.7515112377782878,
      "attention_bam_16_attention_sparsity": 0.470703125,
      "attention_bam_16_attention_concentration_10": 0.6706490524156621,
      "attention_bam_16_attention_concentration_20": 1.0692876018128878,
      "attention_bam_16_attention_center_y": 0.4718502352220413,
      "attention_bam_16_attention_center_x": 0.4761635519341372,
      "attention_bam_16_attention_center_distance": 0.052164844741472795,
      "attention_bam_16_attention_spatial_variance": 41.9588491613469,
      "attention_bam_16_attention_spatial_std": 6.477565064231072,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.188670172353264,
      "attention_bam_16_peak_intensity_mean": 0.32940489053726196,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 213,
      "phase": "train",
      "loss": 0.0071368589997291565,
      "timestamp": 1759543915.5752351,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0071368589997291565,
      "ssim": 0.8678572773933411,
      "attention_bam_384_mean_attention": 0.1339748054742813,
      "attention_bam_384_std_attention": 0.464016854763031,
      "attention_bam_384_max_attention": 3.922628402709961,
      "attention_bam_384_min_attention": -1.4318163394927979,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1633332748512561,
      "attention_bam_384_attention_skewness": 0.696915507599391,
      "attention_bam_384_attention_sparsity": 0.5089187622070312,
      "attention_bam_384_attention_concentration_10": 0.7802395845396524,
      "attention_bam_384_attention_concentration_20": 1.229718487127414,
      "attention_bam_384_attention_center_y": 0.487237518681383,
      "attention_bam_384_attention_center_x": 0.4853920857711389,
      "attention_bam_384_attention_center_distance": 0.027432538618429418,
      "attention_bam_384_attention_spatial_variance": 169.61384646780985,
      "attention_bam_384_attention_spatial_std": 13.023588079627283,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 16.997225586240383,
      "attention_bam_384_peak_intensity_mean": 0.2943425476551056,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19117391109466553,
      "attention_bam_16_std_attention": 0.6070590615272522,
      "attention_bam_16_max_attention": 3.323629140853882,
      "attention_bam_16_min_attention": -1.2427978515625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.4759207964576566,
      "attention_bam_16_attention_skewness": 0.8937494118544789,
      "attention_bam_16_attention_sparsity": 0.488525390625,
      "attention_bam_16_attention_concentration_10": 0.7382652151234879,
      "attention_bam_16_attention_concentration_20": 1.1585689783930317,
      "attention_bam_16_attention_center_y": 0.4741247502189748,
      "attention_bam_16_attention_center_x": 0.4731239022524424,
      "attention_bam_16_attention_center_distance": 0.05276084118674976,
      "attention_bam_16_attention_spatial_variance": 42.240152885495654,
      "attention_bam_16_attention_spatial_std": 6.499242485512881,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 7.2116030377781,
      "attention_bam_16_peak_intensity_mean": 0.3226604461669922,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 214,
      "phase": "train",
      "loss": 0.009815896861255169,
      "timestamp": 1759543915.707284,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.009815896861255169,
      "ssim": 0.8291031122207642,
      "attention_bam_384_mean_attention": 0.1375407725572586,
      "attention_bam_384_std_attention": 0.4411123991012573,
      "attention_bam_384_max_attention": 3.671097993850708,
      "attention_bam_384_min_attention": -1.2387478351593018,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.4248072952386597,
      "attention_bam_384_attention_skewness": 0.5159070171393044,
      "attention_bam_384_attention_sparsity": 0.49716949462890625,
      "attention_bam_384_attention_concentration_10": 0.7129958394568163,
      "attention_bam_384_attention_concentration_20": 1.149115209282239,
      "attention_bam_384_attention_center_y": 0.49104608621726453,
      "attention_bam_384_attention_center_x": 0.48350476469463227,
      "attention_bam_384_attention_center_distance": 0.026542997562751275,
      "attention_bam_384_attention_spatial_variance": 169.80320963964795,
      "attention_bam_384_attention_spatial_std": 13.03085605935573,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 16.536504034033634,
      "attention_bam_384_peak_intensity_mean": 0.28190284967422485,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20211347937583923,
      "attention_bam_16_std_attention": 0.5565438866615295,
      "attention_bam_16_max_attention": 2.8918843269348145,
      "attention_bam_16_min_attention": -1.0685179233551025,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.40307320998817486,
      "attention_bam_16_attention_skewness": 0.5954378594583114,
      "attention_bam_16_attention_sparsity": 0.46826171875,
      "attention_bam_16_attention_concentration_10": 0.6268768791940206,
      "attention_bam_16_attention_concentration_20": 1.020278456911299,
      "attention_bam_16_attention_center_y": 0.4859976483201087,
      "attention_bam_16_attention_center_x": 0.46989616786750665,
      "attention_bam_16_attention_center_distance": 0.046953307905379646,
      "attention_bam_16_attention_spatial_variance": 42.23255859924248,
      "attention_bam_16_attention_spatial_std": 6.498658215296638,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 7.815213108919347,
      "attention_bam_16_peak_intensity_mean": 0.33379989862442017,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 215,
      "phase": "train",
      "loss": 0.010383591055870056,
      "timestamp": 1759543915.8406806,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.010383591055870056,
      "ssim": 0.7825644016265869,
      "attention_bam_384_mean_attention": 0.14124812185764313,
      "attention_bam_384_std_attention": 0.45451587438583374,
      "attention_bam_384_max_attention": 3.4672060012817383,
      "attention_bam_384_min_attention": -1.3203827142715454,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8626148121388852,
      "attention_bam_384_attention_skewness": 0.5713293522330193,
      "attention_bam_384_attention_sparsity": 0.49098968505859375,
      "attention_bam_384_attention_concentration_10": 0.7115195398219994,
      "attention_bam_384_attention_concentration_20": 1.1430626095489578,
      "attention_bam_384_attention_center_y": 0.4846408902706839,
      "attention_bam_384_attention_center_x": 0.48540633839650327,
      "attention_bam_384_attention_center_distance": 0.0299625503145025,
      "attention_bam_384_attention_spatial_variance": 169.53463135728936,
      "attention_bam_384_attention_spatial_std": 13.020546507627449,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 17.760836737876133,
      "attention_bam_384_peak_intensity_mean": 0.3059798777103424,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20706364512443542,
      "attention_bam_16_std_attention": 0.5718452334403992,
      "attention_bam_16_max_attention": 3.798508644104004,
      "attention_bam_16_min_attention": -1.1648198366165161,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.40086963558345,
      "attention_bam_16_attention_skewness": 0.7343183213675178,
      "attention_bam_16_attention_sparsity": 0.451416015625,
      "attention_bam_16_attention_concentration_10": 0.6292892258208626,
      "attention_bam_16_attention_concentration_20": 1.0070603317169946,
      "attention_bam_16_attention_center_y": 0.47202480650396356,
      "attention_bam_16_attention_center_x": 0.4746727102222486,
      "attention_bam_16_attention_center_distance": 0.05336821261063311,
      "attention_bam_16_attention_spatial_variance": 42.008377067297396,
      "attention_bam_16_attention_spatial_std": 6.481386970957481,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.640809132024216,
      "attention_bam_16_peak_intensity_mean": 0.27673834562301636,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 216,
      "phase": "train",
      "loss": 0.0076491208747029305,
      "timestamp": 1759543915.9681692,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0076491208747029305,
      "ssim": 0.8519669771194458,
      "attention_bam_384_mean_attention": 0.1364513486623764,
      "attention_bam_384_std_attention": 0.47262170910835266,
      "attention_bam_384_max_attention": 3.2097394466400146,
      "attention_bam_384_min_attention": -1.3886449337005615,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4306563306253812,
      "attention_bam_384_attention_skewness": 0.8087058897250925,
      "attention_bam_384_attention_sparsity": 0.5128555297851562,
      "attention_bam_384_attention_concentration_10": 0.8062789634236953,
      "attention_bam_384_attention_concentration_20": 1.238803017812623,
      "attention_bam_384_attention_center_y": 0.48449459714410326,
      "attention_bam_384_attention_center_x": 0.4753221263228697,
      "attention_bam_384_attention_center_distance": 0.041216864678139994,
      "attention_bam_384_attention_spatial_variance": 171.06078776355633,
      "attention_bam_384_attention_spatial_std": 13.079020902328903,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 15.796004892385021,
      "attention_bam_384_peak_intensity_mean": 0.3347734212875366,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18397152423858643,
      "attention_bam_16_std_attention": 0.6044011116027832,
      "attention_bam_16_max_attention": 3.101771593093872,
      "attention_bam_16_min_attention": -1.1644920110702515,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.0919950316515719,
      "attention_bam_16_attention_skewness": 0.8814322898694597,
      "attention_bam_16_attention_sparsity": 0.50439453125,
      "attention_bam_16_attention_concentration_10": 0.7646345572434677,
      "attention_bam_16_attention_concentration_20": 1.2041157869681096,
      "attention_bam_16_attention_center_y": 0.4696370845516518,
      "attention_bam_16_attention_center_x": 0.4516713511770879,
      "attention_bam_16_attention_center_distance": 0.08071635437223244,
      "attention_bam_16_attention_spatial_variance": 42.60117776421375,
      "attention_bam_16_attention_spatial_std": 6.526957772516515,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.500793774496115,
      "attention_bam_16_peak_intensity_mean": 0.3183252811431885,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 217,
      "phase": "train",
      "loss": 0.008716429583728313,
      "timestamp": 1759543916.1002843,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008716429583728313,
      "ssim": 0.8376187682151794,
      "attention_bam_384_mean_attention": 0.1350044161081314,
      "attention_bam_384_std_attention": 0.4448260962963104,
      "attention_bam_384_max_attention": 3.3900413513183594,
      "attention_bam_384_min_attention": -1.2885005474090576,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5754006507401646,
      "attention_bam_384_attention_skewness": 0.5515994838549786,
      "attention_bam_384_attention_sparsity": 0.49894968668619794,
      "attention_bam_384_attention_concentration_10": 0.7341549920197235,
      "attention_bam_384_attention_concentration_20": 1.173591224128715,
      "attention_bam_384_attention_center_y": 0.4842080158887582,
      "attention_bam_384_attention_center_x": 0.4915655066720525,
      "attention_bam_384_attention_center_distance": 0.025319061588807094,
      "attention_bam_384_attention_spatial_variance": 171.5180604140882,
      "attention_bam_384_attention_spatial_std": 13.096490385369975,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 17.708768996308365,
      "attention_bam_384_peak_intensity_mean": 0.3082263767719269,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19579248130321503,
      "attention_bam_16_std_attention": 0.5715126395225525,
      "attention_bam_16_max_attention": 2.6180131435394287,
      "attention_bam_16_min_attention": -1.056281566619873,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.4454804751209269,
      "attention_bam_16_attention_skewness": 0.7019608061406786,
      "attention_bam_16_attention_sparsity": 0.480712890625,
      "attention_bam_16_attention_concentration_10": 0.6868432686889441,
      "attention_bam_16_attention_concentration_20": 1.0944310973924698,
      "attention_bam_16_attention_center_y": 0.4683932132055539,
      "attention_bam_16_attention_center_x": 0.48566909288519217,
      "attention_bam_16_attention_center_distance": 0.04907879114653953,
      "attention_bam_16_attention_spatial_variance": 43.08257085155008,
      "attention_bam_16_attention_spatial_std": 6.563731473144684,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.566852064091233,
      "attention_bam_16_peak_intensity_mean": 0.3563878536224365,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 218,
      "phase": "train",
      "loss": 0.008928279392421246,
      "timestamp": 1759543916.2357216,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008928279392421246,
      "ssim": 0.8326166868209839,
      "attention_bam_384_mean_attention": 0.13423390686511993,
      "attention_bam_384_std_attention": 0.45164015889167786,
      "attention_bam_384_max_attention": 2.871805429458618,
      "attention_bam_384_min_attention": -1.295610785484314,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8391118384450511,
      "attention_bam_384_attention_skewness": 0.6168841705086398,
      "attention_bam_384_attention_sparsity": 0.5036493937174479,
      "attention_bam_384_attention_concentration_10": 0.7589217866691358,
      "attention_bam_384_attention_concentration_20": 1.200173647548533,
      "attention_bam_384_attention_center_y": 0.4882183785785238,
      "attention_bam_384_attention_center_x": 0.48742653152836585,
      "attention_bam_384_attention_center_distance": 0.02436795899233931,
      "attention_bam_384_attention_spatial_variance": 172.38165097050378,
      "attention_bam_384_attention_spatial_std": 13.129419292965846,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 16.489495114056908,
      "attention_bam_384_peak_intensity_mean": 0.34344619512557983,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20872926712036133,
      "attention_bam_16_std_attention": 0.5717573761940002,
      "attention_bam_16_max_attention": 2.9049854278564453,
      "attention_bam_16_min_attention": -1.128018856048584,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8530275739931286,
      "attention_bam_16_attention_skewness": 0.7922501408664032,
      "attention_bam_16_attention_sparsity": 0.48193359375,
      "attention_bam_16_attention_concentration_10": 0.652391304588508,
      "attention_bam_16_attention_concentration_20": 1.0355116913687858,
      "attention_bam_16_attention_center_y": 0.4782102385901725,
      "attention_bam_16_attention_center_x": 0.47645031130211196,
      "attention_bam_16_attention_center_distance": 0.045373594525112165,
      "attention_bam_16_attention_spatial_variance": 43.445786651086074,
      "attention_bam_16_attention_spatial_std": 6.591341794436553,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.497964787502546,
      "attention_bam_16_peak_intensity_mean": 0.3409404456615448,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 219,
      "phase": "train",
      "loss": 0.006573709659278393,
      "timestamp": 1759543916.3847966,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006573709659278393,
      "ssim": 0.8477177619934082,
      "attention_bam_384_mean_attention": 0.13046623766422272,
      "attention_bam_384_std_attention": 0.4330170750617981,
      "attention_bam_384_max_attention": 3.724935293197632,
      "attention_bam_384_min_attention": -1.3114166259765625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.629929704673293,
      "attention_bam_384_attention_skewness": 0.9584104914814678,
      "attention_bam_384_attention_sparsity": 0.5088551839192709,
      "attention_bam_384_attention_concentration_10": 0.7664275188584103,
      "attention_bam_384_attention_concentration_20": 1.1777661904850618,
      "attention_bam_384_attention_center_y": 0.48894389324965093,
      "attention_bam_384_attention_center_x": 0.4800052157315069,
      "attention_bam_384_attention_center_distance": 0.032311883090240766,
      "attention_bam_384_attention_spatial_variance": 170.47628102708097,
      "attention_bam_384_attention_spatial_std": 13.05665657919672,
      "attention_bam_384_num_attention_peaks": 18,
      "attention_bam_384_peak_separation_mean": 17.67356345876599,
      "attention_bam_384_peak_intensity_mean": 0.2890484631061554,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18211400508880615,
      "attention_bam_16_std_attention": 0.5408937335014343,
      "attention_bam_16_max_attention": 3.4697680473327637,
      "attention_bam_16_min_attention": -1.012907862663269,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.42782476361738,
      "attention_bam_16_attention_skewness": 1.201380786726843,
      "attention_bam_16_attention_sparsity": 0.482421875,
      "attention_bam_16_attention_concentration_10": 0.6964976536269211,
      "attention_bam_16_attention_concentration_20": 1.0782810471661444,
      "attention_bam_16_attention_center_y": 0.47999574533542505,
      "attention_bam_16_attention_center_x": 0.46024566190998756,
      "attention_bam_16_attention_center_distance": 0.06293770891381704,
      "attention_bam_16_attention_spatial_variance": 42.451594581041995,
      "attention_bam_16_attention_spatial_std": 6.515488821342724,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.253947653961136,
      "attention_bam_16_peak_intensity_mean": 0.27819254994392395,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 220,
      "phase": "train",
      "loss": 0.007585862651467323,
      "timestamp": 1759543916.5876906,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007585862651467323,
      "ssim": 0.8481943607330322,
      "attention_bam_384_mean_attention": 0.13177074491977692,
      "attention_bam_384_std_attention": 0.4747800827026367,
      "attention_bam_384_max_attention": 4.001222610473633,
      "attention_bam_384_min_attention": -1.2455739974975586,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.763134168047416,
      "attention_bam_384_attention_skewness": 0.8592191654628965,
      "attention_bam_384_attention_sparsity": 0.5113932291666666,
      "attention_bam_384_attention_concentration_10": 0.8252836504596365,
      "attention_bam_384_attention_concentration_20": 1.2737304305323716,
      "attention_bam_384_attention_center_y": 0.49061871163167237,
      "attention_bam_384_attention_center_x": 0.4831164255132347,
      "attention_bam_384_attention_center_distance": 0.027315331185979484,
      "attention_bam_384_attention_spatial_variance": 171.84318003013365,
      "attention_bam_384_attention_spatial_std": 13.108896979919159,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 17.412332495988576,
      "attention_bam_384_peak_intensity_mean": 0.2639829218387604,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18701305985450745,
      "attention_bam_16_std_attention": 0.6117917895317078,
      "attention_bam_16_max_attention": 4.00971794128418,
      "attention_bam_16_min_attention": -1.0807652473449707,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.814377277561312,
      "attention_bam_16_attention_skewness": 1.1742244197177116,
      "attention_bam_16_attention_sparsity": 0.490478515625,
      "attention_bam_16_attention_concentration_10": 0.7689678933376073,
      "attention_bam_16_attention_concentration_20": 1.1746114056365444,
      "attention_bam_16_attention_center_y": 0.48520279744725636,
      "attention_bam_16_attention_center_x": 0.46893317644607496,
      "attention_bam_16_attention_center_distance": 0.04866425236490609,
      "attention_bam_16_attention_spatial_variance": 43.26512076728686,
      "attention_bam_16_attention_spatial_std": 6.577622729169472,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 10.1116475040631,
      "attention_bam_16_peak_intensity_mean": 0.25709205865859985,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 221,
      "phase": "train",
      "loss": 0.0066953254863619804,
      "timestamp": 1759543916.731933,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0066953254863619804,
      "ssim": 0.8674718141555786,
      "attention_bam_384_mean_attention": 0.13190415501594543,
      "attention_bam_384_std_attention": 0.49865758419036865,
      "attention_bam_384_max_attention": 3.560309648513794,
      "attention_bam_384_min_attention": -1.3141976594924927,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4348551319735128,
      "attention_bam_384_attention_skewness": 0.8004050446938036,
      "attention_bam_384_attention_sparsity": 0.5127766927083334,
      "attention_bam_384_attention_concentration_10": 0.8470606850912445,
      "attention_bam_384_attention_concentration_20": 1.3225771200232548,
      "attention_bam_384_attention_center_y": 0.477619790789429,
      "attention_bam_384_attention_center_x": 0.482373621094825,
      "attention_bam_384_attention_center_distance": 0.04028803786777719,
      "attention_bam_384_attention_spatial_variance": 170.60898525971615,
      "attention_bam_384_attention_spatial_std": 13.061737451798523,
      "attention_bam_384_num_attention_peaks": 19,
      "attention_bam_384_peak_separation_mean": 17.24076952316878,
      "attention_bam_384_peak_intensity_mean": 0.29729798436164856,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1825694739818573,
      "attention_bam_16_std_attention": 0.636785089969635,
      "attention_bam_16_max_attention": 3.6130142211914062,
      "attention_bam_16_min_attention": -1.1391899585723877,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.6782306522588124,
      "attention_bam_16_attention_skewness": 0.9811703542507976,
      "attention_bam_16_attention_sparsity": 0.497802734375,
      "attention_bam_16_attention_concentration_10": 0.8053796799279831,
      "attention_bam_16_attention_concentration_20": 1.2597256944190969,
      "attention_bam_16_attention_center_y": 0.4540344698505598,
      "attention_bam_16_attention_center_x": 0.4646055431411208,
      "attention_bam_16_attention_center_distance": 0.0820438606874903,
      "attention_bam_16_attention_spatial_variance": 42.34874355875019,
      "attention_bam_16_attention_spatial_std": 6.507591225541921,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.026377076997045,
      "attention_bam_16_peak_intensity_mean": 0.28347980976104736,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 222,
      "phase": "train",
      "loss": 0.007730675395578146,
      "timestamp": 1759543916.8645706,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007730675395578146,
      "ssim": 0.8721374273300171,
      "attention_bam_384_mean_attention": 0.13316012918949127,
      "attention_bam_384_std_attention": 0.4650684595108032,
      "attention_bam_384_max_attention": 3.2781763076782227,
      "attention_bam_384_min_attention": -1.3156633377075195,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.818076670862053,
      "attention_bam_384_attention_skewness": 0.6384542046600988,
      "attention_bam_384_attention_sparsity": 0.5062459309895834,
      "attention_bam_384_attention_concentration_10": 0.7867726691740133,
      "attention_bam_384_attention_concentration_20": 1.2377343989484024,
      "attention_bam_384_attention_center_y": 0.4884442958658934,
      "attention_bam_384_attention_center_x": 0.4849489362020423,
      "attention_bam_384_attention_center_distance": 0.026835380358221153,
      "attention_bam_384_attention_spatial_variance": 169.7782794081166,
      "attention_bam_384_attention_spatial_std": 13.029899439677829,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 18.33870100699202,
      "attention_bam_384_peak_intensity_mean": 0.31760090589523315,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1946919858455658,
      "attention_bam_16_std_attention": 0.6002321243286133,
      "attention_bam_16_max_attention": 2.9524481296539307,
      "attention_bam_16_min_attention": -1.2656350135803223,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.40975887638420305,
      "attention_bam_16_attention_skewness": 0.7001480903975414,
      "attention_bam_16_attention_sparsity": 0.482177734375,
      "attention_bam_16_attention_concentration_10": 0.7209982152987168,
      "attention_bam_16_attention_concentration_20": 1.1441532003311716,
      "attention_bam_16_attention_center_y": 0.47878992613818655,
      "attention_bam_16_attention_center_x": 0.4711625238589596,
      "attention_bam_16_attention_center_distance": 0.050625433596338795,
      "attention_bam_16_attention_spatial_variance": 42.21487087604356,
      "attention_bam_16_attention_spatial_std": 6.497297197761817,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.05115312965414,
      "attention_bam_16_peak_intensity_mean": 0.3503398597240448,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 223,
      "phase": "train",
      "loss": 0.010498329997062683,
      "timestamp": 1759543916.9987483,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.010498329997062683,
      "ssim": 0.8489426970481873,
      "attention_bam_384_mean_attention": 0.13188326358795166,
      "attention_bam_384_std_attention": 0.4730830490589142,
      "attention_bam_384_max_attention": 4.012442111968994,
      "attention_bam_384_min_attention": -1.259866714477539,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0840689852390577,
      "attention_bam_384_attention_skewness": 0.6938148450760244,
      "attention_bam_384_attention_sparsity": 0.5088144938151041,
      "attention_bam_384_attention_concentration_10": 0.8032198275899481,
      "attention_bam_384_attention_concentration_20": 1.2649758914787204,
      "attention_bam_384_attention_center_y": 0.47668190565094926,
      "attention_bam_384_attention_center_x": 0.48501538319192594,
      "attention_bam_384_attention_center_distance": 0.03919878225037221,
      "attention_bam_384_attention_spatial_variance": 171.65177193649728,
      "attention_bam_384_attention_spatial_std": 13.101594251712166,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 20.934021255406844,
      "attention_bam_384_peak_intensity_mean": 0.2690623700618744,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1997165083885193,
      "attention_bam_16_std_attention": 0.5976754426956177,
      "attention_bam_16_max_attention": 3.1469528675079346,
      "attention_bam_16_min_attention": -1.137474536895752,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7613845587092838,
      "attention_bam_16_attention_skewness": 0.7631843256433762,
      "attention_bam_16_attention_sparsity": 0.479736328125,
      "attention_bam_16_attention_concentration_10": 0.6944513916016493,
      "attention_bam_16_attention_concentration_20": 1.1115436923694966,
      "attention_bam_16_attention_center_y": 0.450904148618071,
      "attention_bam_16_attention_center_x": 0.4726481534272039,
      "attention_bam_16_attention_center_distance": 0.07947988593170272,
      "attention_bam_16_attention_spatial_variance": 43.07422123676593,
      "attention_bam_16_attention_spatial_std": 6.563095400553456,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.512559545945154,
      "attention_bam_16_peak_intensity_mean": 0.3260394334793091,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 224,
      "phase": "train",
      "loss": 0.00997413881123066,
      "timestamp": 1759543917.134466,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00997413881123066,
      "ssim": 0.8176301717758179,
      "attention_bam_384_mean_attention": 0.13414861261844635,
      "attention_bam_384_std_attention": 0.40455782413482666,
      "attention_bam_384_max_attention": 3.5545811653137207,
      "attention_bam_384_min_attention": -1.3861501216888428,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9932416645910007,
      "attention_bam_384_attention_skewness": 0.5649992163057217,
      "attention_bam_384_attention_sparsity": 0.493927001953125,
      "attention_bam_384_attention_concentration_10": 0.6752312415976336,
      "attention_bam_384_attention_concentration_20": 1.0821111502931706,
      "attention_bam_384_attention_center_y": 0.4817860290804402,
      "attention_bam_384_attention_center_x": 0.47767326435797386,
      "attention_bam_384_attention_center_distance": 0.04074878798412267,
      "attention_bam_384_attention_spatial_variance": 168.28847115045045,
      "attention_bam_384_attention_spatial_std": 12.972604640181187,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 13.909381619009363,
      "attention_bam_384_peak_intensity_mean": 0.313362717628479,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20612859725952148,
      "attention_bam_16_std_attention": 0.5294400453567505,
      "attention_bam_16_max_attention": 2.8051013946533203,
      "attention_bam_16_min_attention": -1.1460700035095215,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.36956379137279116,
      "attention_bam_16_attention_skewness": 0.5585163907246564,
      "attention_bam_16_attention_sparsity": 0.448486328125,
      "attention_bam_16_attention_concentration_10": 0.5884133990279222,
      "attention_bam_16_attention_concentration_20": 0.9630149693489435,
      "attention_bam_16_attention_center_y": 0.46282788178865913,
      "attention_bam_16_attention_center_x": 0.4542411227514469,
      "attention_bam_16_attention_center_distance": 0.08337435120426484,
      "attention_bam_16_attention_spatial_variance": 40.94579701427282,
      "attention_bam_16_attention_spatial_std": 6.398890295533501,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 6.954487912277304,
      "attention_bam_16_peak_intensity_mean": 0.3592725396156311,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 225,
      "phase": "train",
      "loss": 0.01563510112464428,
      "timestamp": 1759543917.2690752,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.01563510112464428,
      "ssim": 0.7729825973510742,
      "attention_bam_384_mean_attention": 0.13401025533676147,
      "attention_bam_384_std_attention": 0.3737199306488037,
      "attention_bam_384_max_attention": 3.8265786170959473,
      "attention_bam_384_min_attention": -1.1596988439559937,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8776776156325461,
      "attention_bam_384_attention_skewness": 0.5452653565577057,
      "attention_bam_384_attention_sparsity": 0.49168141682942706,
      "attention_bam_384_attention_concentration_10": 0.6342566750239014,
      "attention_bam_384_attention_concentration_20": 1.0198713646356374,
      "attention_bam_384_attention_center_y": 0.48918802166760506,
      "attention_bam_384_attention_center_x": 0.4875449988899365,
      "attention_bam_384_attention_center_distance": 0.023324919211515405,
      "attention_bam_384_attention_spatial_variance": 171.4379041770537,
      "attention_bam_384_attention_spatial_std": 13.09342980952866,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 18.622675288142343,
      "attention_bam_384_peak_intensity_mean": 0.2597815990447998,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20580607652664185,
      "attention_bam_16_std_attention": 0.5195553302764893,
      "attention_bam_16_max_attention": 2.540323257446289,
      "attention_bam_16_min_attention": -0.9622884392738342,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6121038162609338,
      "attention_bam_16_attention_skewness": 0.6638616411859803,
      "attention_bam_16_attention_sparsity": 0.46044921875,
      "attention_bam_16_attention_concentration_10": 0.6028880320057951,
      "attention_bam_16_attention_concentration_20": 0.9572279792857651,
      "attention_bam_16_attention_center_y": 0.4820966486240603,
      "attention_bam_16_attention_center_x": 0.4801149935565717,
      "attention_bam_16_attention_center_distance": 0.037840282021822866,
      "attention_bam_16_attention_spatial_variance": 43.25253818786893,
      "attention_bam_16_attention_spatial_std": 6.576666191002013,
      "attention_bam_16_num_attention_peaks": 2,
      "attention_bam_16_peak_separation_mean": 8.527427155296543,
      "attention_bam_16_peak_intensity_mean": 0.3451263904571533,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 226,
      "phase": "train",
      "loss": 0.008171802386641502,
      "timestamp": 1759543917.4002469,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008171802386641502,
      "ssim": 0.8540301322937012,
      "attention_bam_384_mean_attention": 0.1330956518650055,
      "attention_bam_384_std_attention": 0.4719393253326416,
      "attention_bam_384_max_attention": 3.4655466079711914,
      "attention_bam_384_min_attention": -1.490977168083191,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.229124686693827,
      "attention_bam_384_attention_skewness": 0.8394091813059043,
      "attention_bam_384_attention_sparsity": 0.505279541015625,
      "attention_bam_384_attention_concentration_10": 0.7960087915616564,
      "attention_bam_384_attention_concentration_20": 1.2308859774258394,
      "attention_bam_384_attention_center_y": 0.4789184866403141,
      "attention_bam_384_attention_center_x": 0.48064373043439645,
      "attention_bam_384_attention_center_distance": 0.04047456922639016,
      "attention_bam_384_attention_spatial_variance": 169.2303365397765,
      "attention_bam_384_attention_spatial_std": 13.00885608113859,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 18.03609949298975,
      "attention_bam_384_peak_intensity_mean": 0.332861989736557,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1930851936340332,
      "attention_bam_16_std_attention": 0.6161863803863525,
      "attention_bam_16_max_attention": 3.743299961090088,
      "attention_bam_16_min_attention": -1.4154951572418213,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.1591575896257478,
      "attention_bam_16_attention_skewness": 0.9626659870651094,
      "attention_bam_16_attention_sparsity": 0.4765625,
      "attention_bam_16_attention_concentration_10": 0.741022963275552,
      "attention_bam_16_attention_concentration_20": 1.142179709267926,
      "attention_bam_16_attention_center_y": 0.4574914304173079,
      "attention_bam_16_attention_center_x": 0.4623082220850084,
      "attention_bam_16_attention_center_distance": 0.0803448643083007,
      "attention_bam_16_attention_spatial_variance": 41.65567765966588,
      "attention_bam_16_attention_spatial_std": 6.454120982726144,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 9.435245372911181,
      "attention_bam_16_peak_intensity_mean": 0.320027619600296,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 227,
      "phase": "train",
      "loss": 0.008784333243966103,
      "timestamp": 1759543917.531186,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008784333243966103,
      "ssim": 0.8327431678771973,
      "attention_bam_384_mean_attention": 0.12970729172229767,
      "attention_bam_384_std_attention": 0.5003383159637451,
      "attention_bam_384_max_attention": 4.881320953369141,
      "attention_bam_384_min_attention": -1.3673555850982666,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.863175530970456,
      "attention_bam_384_attention_skewness": 1.0142430140015588,
      "attention_bam_384_attention_sparsity": 0.5192286173502604,
      "attention_bam_384_attention_concentration_10": 0.8742819334315682,
      "attention_bam_384_attention_concentration_20": 1.3433511812994203,
      "attention_bam_384_attention_center_y": 0.4848052411764825,
      "attention_bam_384_attention_center_x": 0.47624776258245566,
      "attention_bam_384_attention_center_distance": 0.03987604489024097,
      "attention_bam_384_attention_spatial_variance": 170.5436262956141,
      "attention_bam_384_attention_spatial_std": 13.05923528755088,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 16.58126803671798,
      "attention_bam_384_peak_intensity_mean": 0.2409682720899582,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1824280023574829,
      "attention_bam_16_std_attention": 0.6507234573364258,
      "attention_bam_16_max_attention": 4.836528778076172,
      "attention_bam_16_min_attention": -1.1960928440093994,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.4026645432732643,
      "attention_bam_16_attention_skewness": 1.262092378464825,
      "attention_bam_16_attention_sparsity": 0.507568359375,
      "attention_bam_16_attention_concentration_10": 0.8334168672130883,
      "attention_bam_16_attention_concentration_20": 1.2820659869646245,
      "attention_bam_16_attention_center_y": 0.4686342589382211,
      "attention_bam_16_attention_center_x": 0.4498746802711456,
      "attention_bam_16_attention_center_distance": 0.08362245380607349,
      "attention_bam_16_attention_spatial_variance": 42.25997402814793,
      "attention_bam_16_attention_spatial_std": 6.50076718765931,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 7.412775608852621,
      "attention_bam_16_peak_intensity_mean": 0.22915750741958618,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 228,
      "phase": "train",
      "loss": 0.0059167868457734585,
      "timestamp": 1759543917.6622186,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0059167868457734585,
      "ssim": 0.8731276988983154,
      "attention_bam_384_mean_attention": 0.12893076241016388,
      "attention_bam_384_std_attention": 0.5039969682693481,
      "attention_bam_384_max_attention": 3.684678554534912,
      "attention_bam_384_min_attention": -1.2303731441497803,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.41011684620939,
      "attention_bam_384_attention_skewness": 1.048453723129749,
      "attention_bam_384_attention_sparsity": 0.5242411295572916,
      "attention_bam_384_attention_concentration_10": 0.8946755792901859,
      "attention_bam_384_attention_concentration_20": 1.3650235637984316,
      "attention_bam_384_attention_center_y": 0.4819250994683755,
      "attention_bam_384_attention_center_x": 0.48964230166937234,
      "attention_bam_384_attention_center_distance": 0.029461294741962976,
      "attention_bam_384_attention_spatial_variance": 165.6335767446653,
      "attention_bam_384_attention_spatial_std": 12.869870890753539,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 14.389329546918944,
      "attention_bam_384_peak_intensity_mean": 0.28336217999458313,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16586270928382874,
      "attention_bam_16_std_attention": 0.6690589785575867,
      "attention_bam_16_max_attention": 3.753737449645996,
      "attention_bam_16_min_attention": -1.1553488969802856,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.2563456116477836,
      "attention_bam_16_attention_skewness": 1.4151924087113223,
      "attention_bam_16_attention_sparsity": 0.540771484375,
      "attention_bam_16_attention_concentration_10": 0.9633172033855943,
      "attention_bam_16_attention_concentration_20": 1.4416738583641797,
      "attention_bam_16_attention_center_y": 0.4640306479258831,
      "attention_bam_16_attention_center_x": 0.4822198704083262,
      "attention_bam_16_attention_center_distance": 0.05674376259869433,
      "attention_bam_16_attention_spatial_variance": 39.96175640911426,
      "attention_bam_16_attention_spatial_std": 6.321531175997968,
      "attention_bam_16_num_attention_peaks": 1,
      "attention_bam_16_peak_separation_mean": 0.0,
      "attention_bam_16_peak_intensity_mean": 0.29529517889022827,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 229,
      "phase": "train",
      "loss": 0.010245620273053646,
      "timestamp": 1759543917.7930844,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.010245620273053646,
      "ssim": 0.8144851922988892,
      "attention_bam_384_mean_attention": 0.1347106546163559,
      "attention_bam_384_std_attention": 0.44141867756843567,
      "attention_bam_384_max_attention": 3.4170889854431152,
      "attention_bam_384_min_attention": -1.199782371520996,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.37264485921831847,
      "attention_bam_384_attention_skewness": 0.49069166518001706,
      "attention_bam_384_attention_sparsity": 0.4967905680338542,
      "attention_bam_384_attention_concentration_10": 0.7247733274317073,
      "attention_bam_384_attention_concentration_20": 1.1677242421489344,
      "attention_bam_384_attention_center_y": 0.4786289654797876,
      "attention_bam_384_attention_center_x": 0.4827025661579038,
      "attention_bam_384_attention_center_distance": 0.03888244678478463,
      "attention_bam_384_attention_spatial_variance": 171.90536879680286,
      "attention_bam_384_attention_spatial_std": 13.111268771434855,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 17.083218823477782,
      "attention_bam_384_peak_intensity_mean": 0.28968366980552673,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19186446070671082,
      "attention_bam_16_std_attention": 0.560887336730957,
      "attention_bam_16_max_attention": 3.1413309574127197,
      "attention_bam_16_min_attention": -1.0228081941604614,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5010077117477283,
      "attention_bam_16_attention_skewness": 0.6347168816324997,
      "attention_bam_16_attention_sparsity": 0.4775390625,
      "attention_bam_16_attention_concentration_10": 0.6686845856399547,
      "attention_bam_16_attention_concentration_20": 1.0767257599115418,
      "attention_bam_16_attention_center_y": 0.45446956988954545,
      "attention_bam_16_attention_center_x": 0.46545951272719394,
      "attention_bam_16_attention_center_distance": 0.08082159769623294,
      "attention_bam_16_attention_spatial_variance": 43.28377015592412,
      "attention_bam_16_attention_spatial_std": 6.5790402154055965,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.86937795682205,
      "attention_bam_16_peak_intensity_mean": 0.29536113142967224,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 230,
      "phase": "train",
      "loss": 0.008150190114974976,
      "timestamp": 1759543917.9674156,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008150190114974976,
      "ssim": 0.8043915629386902,
      "attention_bam_384_mean_attention": 0.1334977149963379,
      "attention_bam_384_std_attention": 0.4400249123573303,
      "attention_bam_384_max_attention": 3.2811222076416016,
      "attention_bam_384_min_attention": -1.2105252742767334,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6627276174027652,
      "attention_bam_384_attention_skewness": 0.5998241583772398,
      "attention_bam_384_attention_sparsity": 0.5059026082356771,
      "attention_bam_384_attention_concentration_10": 0.7432250459877497,
      "attention_bam_384_attention_concentration_20": 1.1820354032347031,
      "attention_bam_384_attention_center_y": 0.4842117041856073,
      "attention_bam_384_attention_center_x": 0.48492618418365785,
      "attention_bam_384_attention_center_distance": 0.030870380884847455,
      "attention_bam_384_attention_spatial_variance": 171.08279056914824,
      "attention_bam_384_attention_spatial_std": 13.079862024086808,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 18.016463982297235,
      "attention_bam_384_peak_intensity_mean": 0.3005560338497162,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19148598611354828,
      "attention_bam_16_std_attention": 0.5892837047576904,
      "attention_bam_16_max_attention": 3.3410744667053223,
      "attention_bam_16_min_attention": -1.1293500661849976,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5337088131619034,
      "attention_bam_16_attention_skewness": 0.7180066719660436,
      "attention_bam_16_attention_sparsity": 0.4853515625,
      "attention_bam_16_attention_concentration_10": 0.7167477263469217,
      "attention_bam_16_attention_concentration_20": 1.1405630965473024,
      "attention_bam_16_attention_center_y": 0.46874727502157304,
      "attention_bam_16_attention_center_x": 0.4722101194657837,
      "attention_bam_16_attention_center_distance": 0.05914406612134826,
      "attention_bam_16_attention_spatial_variance": 42.84563278866579,
      "attention_bam_16_attention_spatial_std": 6.545657552046684,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.311615387487384,
      "attention_bam_16_peak_intensity_mean": 0.3014879822731018,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 231,
      "phase": "train",
      "loss": 0.006593569181859493,
      "timestamp": 1759543918.1245456,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006593569181859493,
      "ssim": 0.8286765813827515,
      "attention_bam_384_mean_attention": 0.1276565045118332,
      "attention_bam_384_std_attention": 0.4488396942615509,
      "attention_bam_384_max_attention": 3.6454219818115234,
      "attention_bam_384_min_attention": -1.2578856945037842,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.9304230160857996,
      "attention_bam_384_attention_skewness": 0.9147090676349922,
      "attention_bam_384_attention_sparsity": 0.5216242472330729,
      "attention_bam_384_attention_concentration_10": 0.8122721263680138,
      "attention_bam_384_attention_concentration_20": 1.2540633216716397,
      "attention_bam_384_attention_center_y": 0.4917185903169701,
      "attention_bam_384_attention_center_x": 0.4831550231332586,
      "attention_bam_384_attention_center_distance": 0.026545620805670946,
      "attention_bam_384_attention_spatial_variance": 172.59905241616295,
      "attention_bam_384_attention_spatial_std": 13.137695856433995,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 22.465438993717168,
      "attention_bam_384_peak_intensity_mean": 0.2838350832462311,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16658499836921692,
      "attention_bam_16_std_attention": 0.5975565314292908,
      "attention_bam_16_max_attention": 3.6221678256988525,
      "attention_bam_16_min_attention": -1.0952627658843994,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.539234587771607,
      "attention_bam_16_attention_skewness": 1.1742642185568575,
      "attention_bam_16_attention_sparsity": 0.5185546875,
      "attention_bam_16_attention_concentration_10": 0.8444139317706563,
      "attention_bam_16_attention_concentration_20": 1.2924305839248191,
      "attention_bam_16_attention_center_y": 0.4854625800208289,
      "attention_bam_16_attention_center_x": 0.4689828170881901,
      "attention_bam_16_attention_center_distance": 0.04844382758278856,
      "attention_bam_16_attention_spatial_variance": 43.93249862446573,
      "attention_bam_16_attention_spatial_std": 6.62815952014326,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 11.238593913890009,
      "attention_bam_16_peak_intensity_mean": 0.26884716749191284,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 232,
      "phase": "train",
      "loss": 0.007916438393294811,
      "timestamp": 1759543918.2923317,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007916438393294811,
      "ssim": 0.8501567840576172,
      "attention_bam_384_mean_attention": 0.12769095599651337,
      "attention_bam_384_std_attention": 0.478133887052536,
      "attention_bam_384_max_attention": 3.5820329189300537,
      "attention_bam_384_min_attention": -1.3184800148010254,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5066152236566328,
      "attention_bam_384_attention_skewness": 0.8370715893815621,
      "attention_bam_384_attention_sparsity": 0.5205790201822916,
      "attention_bam_384_attention_concentration_10": 0.847548645566836,
      "attention_bam_384_attention_concentration_20": 1.3206102914997084,
      "attention_bam_384_attention_center_y": 0.47736768370897886,
      "attention_bam_384_attention_center_x": 0.49270477509889105,
      "attention_bam_384_attention_center_distance": 0.03362862016362196,
      "attention_bam_384_attention_spatial_variance": 174.31390303177454,
      "attention_bam_384_attention_spatial_std": 13.202799060493746,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 18.57393158921126,
      "attention_bam_384_peak_intensity_mean": 0.2983597218990326,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17085057497024536,
      "attention_bam_16_std_attention": 0.637872576713562,
      "attention_bam_16_max_attention": 3.6103315353393555,
      "attention_bam_16_min_attention": -1.085226058959961,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.944042845790804,
      "attention_bam_16_attention_skewness": 1.098209059667924,
      "attention_bam_16_attention_sparsity": 0.520263671875,
      "attention_bam_16_attention_concentration_10": 0.8686706691237882,
      "attention_bam_16_attention_concentration_20": 1.347008108069059,
      "attention_bam_16_attention_center_y": 0.4504962856998515,
      "attention_bam_16_attention_center_x": 0.48864928953040243,
      "attention_bam_16_attention_center_distance": 0.07182557145857398,
      "attention_bam_16_attention_spatial_variance": 44.77230454284265,
      "attention_bam_16_attention_spatial_std": 6.691210992252646,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.08721828915318,
      "attention_bam_16_peak_intensity_mean": 0.28345978260040283,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 233,
      "phase": "train",
      "loss": 0.0072007919661700726,
      "timestamp": 1759543918.4454985,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0072007919661700726,
      "ssim": 0.8700513243675232,
      "attention_bam_384_mean_attention": 0.12783847749233246,
      "attention_bam_384_std_attention": 0.49350640177726746,
      "attention_bam_384_max_attention": 3.615260601043701,
      "attention_bam_384_min_attention": -1.363590955734253,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0987389299605033,
      "attention_bam_384_attention_skewness": 0.7428074381316688,
      "attention_bam_384_attention_sparsity": 0.5182876586914062,
      "attention_bam_384_attention_concentration_10": 0.85780948309762,
      "attention_bam_384_attention_concentration_20": 1.3538515288672268,
      "attention_bam_384_attention_center_y": 0.4803710396673667,
      "attention_bam_384_attention_center_x": 0.4849113947251915,
      "attention_bam_384_attention_center_distance": 0.0350132001644828,
      "attention_bam_384_attention_spatial_variance": 170.08609978216373,
      "attention_bam_384_attention_spatial_std": 13.04170616837244,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 14.760155769409925,
      "attention_bam_384_peak_intensity_mean": 0.30100715160369873,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16847997903823853,
      "attention_bam_16_std_attention": 0.6493444442749023,
      "attention_bam_16_max_attention": 3.8179972171783447,
      "attention_bam_16_min_attention": -1.0372188091278076,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.769822695148859,
      "attention_bam_16_attention_skewness": 1.0775546411035222,
      "attention_bam_16_attention_sparsity": 0.525146484375,
      "attention_bam_16_attention_concentration_10": 0.8988896652237851,
      "attention_bam_16_attention_concentration_20": 1.390341750300465,
      "attention_bam_16_attention_center_y": 0.45674002294432575,
      "attention_bam_16_attention_center_x": 0.4704396423813077,
      "attention_bam_16_attention_center_distance": 0.07409777806928412,
      "attention_bam_16_attention_spatial_variance": 42.0800070866271,
      "attention_bam_16_attention_spatial_std": 6.486910442315903,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.725295749608541,
      "attention_bam_16_peak_intensity_mean": 0.2503816783428192,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 234,
      "phase": "train",
      "loss": 0.007953397929668427,
      "timestamp": 1759543918.5851145,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007953397929668427,
      "ssim": 0.8396388292312622,
      "attention_bam_384_mean_attention": 0.13132481276988983,
      "attention_bam_384_std_attention": 0.48100996017456055,
      "attention_bam_384_max_attention": 3.8069071769714355,
      "attention_bam_384_min_attention": -1.3213398456573486,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7707843941019932,
      "attention_bam_384_attention_skewness": 0.6452245179507216,
      "attention_bam_384_attention_sparsity": 0.5095316569010416,
      "attention_bam_384_attention_concentration_10": 0.8135345962720867,
      "attention_bam_384_attention_concentration_20": 1.2902063747970303,
      "attention_bam_384_attention_center_y": 0.48327169044120893,
      "attention_bam_384_attention_center_x": 0.48758648013161104,
      "attention_bam_384_attention_center_distance": 0.02945952532603429,
      "attention_bam_384_attention_spatial_variance": 170.83924794136527,
      "attention_bam_384_attention_spatial_std": 13.070548876820945,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 17.206378047823023,
      "attention_bam_384_peak_intensity_mean": 0.2853277921676636,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17652831971645355,
      "attention_bam_16_std_attention": 0.6238294243812561,
      "attention_bam_16_max_attention": 2.574910879135132,
      "attention_bam_16_min_attention": -1.0978896617889404,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.42987000649987817,
      "attention_bam_16_attention_skewness": 0.7719780786017821,
      "attention_bam_16_attention_sparsity": 0.508056640625,
      "attention_bam_16_attention_concentration_10": 0.8207022849873602,
      "attention_bam_16_attention_concentration_20": 1.294874527431494,
      "attention_bam_16_attention_center_y": 0.46647006013395703,
      "attention_bam_16_attention_center_x": 0.4797916655793064,
      "attention_bam_16_attention_center_distance": 0.055364856135982986,
      "attention_bam_16_attention_spatial_variance": 42.66162354153341,
      "attention_bam_16_attention_spatial_std": 6.531586602161331,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 8.334130969402002,
      "attention_bam_16_peak_intensity_mean": 0.35630497336387634,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 235,
      "phase": "train",
      "loss": 0.0075638494454324245,
      "timestamp": 1759543918.7252805,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0075638494454324245,
      "ssim": 0.8780252933502197,
      "attention_bam_384_mean_attention": 0.12997104227542877,
      "attention_bam_384_std_attention": 0.46669846773147583,
      "attention_bam_384_max_attention": 3.133932590484619,
      "attention_bam_384_min_attention": -1.2765189409255981,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6693312449079318,
      "attention_bam_384_attention_skewness": 0.6027955580135205,
      "attention_bam_384_attention_sparsity": 0.5085830688476562,
      "attention_bam_384_attention_concentration_10": 0.7990852164125367,
      "attention_bam_384_attention_concentration_20": 1.2673050014164422,
      "attention_bam_384_attention_center_y": 0.4887298139832673,
      "attention_bam_384_attention_center_x": 0.49011776455827544,
      "attention_bam_384_attention_center_distance": 0.021197908867500777,
      "attention_bam_384_attention_spatial_variance": 171.5385776360408,
      "attention_bam_384_attention_spatial_std": 13.097273671876938,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 16.86239849907312,
      "attention_bam_384_peak_intensity_mean": 0.32358354330062866,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17592555284500122,
      "attention_bam_16_std_attention": 0.6112313270568848,
      "attention_bam_16_max_attention": 2.831490993499756,
      "attention_bam_16_min_attention": -1.1840726137161255,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6501315921967423,
      "attention_bam_16_attention_skewness": 0.7687491910723686,
      "attention_bam_16_attention_sparsity": 0.498046875,
      "attention_bam_16_attention_concentration_10": 0.7978191730920632,
      "attention_bam_16_attention_concentration_20": 1.2625997741343535,
      "attention_bam_16_attention_center_y": 0.4818288047120421,
      "attention_bam_16_attention_center_x": 0.4857616676645715,
      "attention_bam_16_attention_center_distance": 0.03264728000575889,
      "attention_bam_16_attention_spatial_variance": 43.38426996313013,
      "attention_bam_16_attention_spatial_std": 6.586673664538887,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 7.397969761795077,
      "attention_bam_16_peak_intensity_mean": 0.3624539375305176,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 236,
      "phase": "train",
      "loss": 0.01044672355055809,
      "timestamp": 1759543918.8653593,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.01044672355055809,
      "ssim": 0.8402445316314697,
      "attention_bam_384_mean_attention": 0.13099785149097443,
      "attention_bam_384_std_attention": 0.4401285946369171,
      "attention_bam_384_max_attention": 3.325806140899658,
      "attention_bam_384_min_attention": -1.214839220046997,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8043010879457371,
      "attention_bam_384_attention_skewness": 0.6609299724831552,
      "attention_bam_384_attention_sparsity": 0.5099538167317709,
      "attention_bam_384_attention_concentration_10": 0.7615588644172383,
      "attention_bam_384_attention_concentration_20": 1.2025129759764266,
      "attention_bam_384_attention_center_y": 0.47976448837510954,
      "attention_bam_384_attention_center_x": 0.49105665340029214,
      "attention_bam_384_attention_center_distance": 0.03128767741854875,
      "attention_bam_384_attention_spatial_variance": 170.39633428606552,
      "attention_bam_384_attention_spatial_std": 13.053594688286653,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 16.675330395256267,
      "attention_bam_384_peak_intensity_mean": 0.29845860600471497,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18938857316970825,
      "attention_bam_16_std_attention": 0.5948646068572998,
      "attention_bam_16_max_attention": 2.5208792686462402,
      "attention_bam_16_min_attention": -1.1428383588790894,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.19410938197263894,
      "attention_bam_16_attention_skewness": 0.6894018079925602,
      "attention_bam_16_attention_sparsity": 0.49072265625,
      "attention_bam_16_attention_concentration_10": 0.7271442994568903,
      "attention_bam_16_attention_concentration_20": 1.167902315485007,
      "attention_bam_16_attention_center_y": 0.4534726002410123,
      "attention_bam_16_attention_center_x": 0.4873517481828499,
      "attention_bam_16_attention_center_distance": 0.06818764114357803,
      "attention_bam_16_attention_spatial_variance": 42.29309583403421,
      "attention_bam_16_attention_spatial_std": 6.503314219229623,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 7.751419725318602,
      "attention_bam_16_peak_intensity_mean": 0.36521482467651367,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 237,
      "phase": "train",
      "loss": 0.007739420980215073,
      "timestamp": 1759543918.999066,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007739420980215073,
      "ssim": 0.863426685333252,
      "attention_bam_384_mean_attention": 0.129477396607399,
      "attention_bam_384_std_attention": 0.48728010058403015,
      "attention_bam_384_max_attention": 3.52601957321167,
      "attention_bam_384_min_attention": -1.296148657798767,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8130041867935422,
      "attention_bam_384_attention_skewness": 0.6601953597581833,
      "attention_bam_384_attention_sparsity": 0.5109151204427084,
      "attention_bam_384_attention_concentration_10": 0.8373871821660822,
      "attention_bam_384_attention_concentration_20": 1.3217202401601502,
      "attention_bam_384_attention_center_y": 0.4910474646871457,
      "attention_bam_384_attention_center_x": 0.4744055896634311,
      "attention_bam_384_attention_center_distance": 0.038346361731057814,
      "attention_bam_384_attention_spatial_variance": 169.8351556671256,
      "attention_bam_384_attention_spatial_std": 13.03208178562142,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 18.263938878306494,
      "attention_bam_384_peak_intensity_mean": 0.2983458936214447,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18626725673675537,
      "attention_bam_16_std_attention": 0.6589603424072266,
      "attention_bam_16_max_attention": 3.4537699222564697,
      "attention_bam_16_min_attention": -1.2163515090942383,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8829894404737737,
      "attention_bam_16_attention_skewness": 0.8450657835127987,
      "attention_bam_16_attention_sparsity": 0.5126953125,
      "attention_bam_16_attention_concentration_10": 0.8064391692048591,
      "attention_bam_16_attention_concentration_20": 1.2804850712429676,
      "attention_bam_16_attention_center_y": 0.4858680466203264,
      "attention_bam_16_attention_center_x": 0.44081755511950904,
      "attention_bam_16_attention_center_distance": 0.08604968202564862,
      "attention_bam_16_attention_spatial_variance": 41.689525497297474,
      "attention_bam_16_attention_spatial_std": 6.4567426383043545,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 7.3527037692804385,
      "attention_bam_16_peak_intensity_mean": 0.3071153163909912,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 238,
      "phase": "train",
      "loss": 0.008153803646564484,
      "timestamp": 1759543919.1437695,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008153803646564484,
      "ssim": 0.8549270629882812,
      "attention_bam_384_mean_attention": 0.13247652351856232,
      "attention_bam_384_std_attention": 0.4333188831806183,
      "attention_bam_384_max_attention": 3.233541488647461,
      "attention_bam_384_min_attention": -1.1287341117858887,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.3410290635770767,
      "attention_bam_384_attention_skewness": 0.7777663556196776,
      "attention_bam_384_attention_sparsity": 0.5078023274739584,
      "attention_bam_384_attention_concentration_10": 0.7608904427668906,
      "attention_bam_384_attention_concentration_20": 1.176603722253487,
      "attention_bam_384_attention_center_y": 0.4873967257204112,
      "attention_bam_384_attention_center_x": 0.47365256965061986,
      "attention_bam_384_attention_center_distance": 0.041304469699585344,
      "attention_bam_384_attention_spatial_variance": 171.33988890192924,
      "attention_bam_384_attention_spatial_std": 13.089686356132802,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 17.189812917620092,
      "attention_bam_384_peak_intensity_mean": 0.2914477586746216,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.2029736042022705,
      "attention_bam_16_std_attention": 0.602501392364502,
      "attention_bam_16_max_attention": 2.9024910926818848,
      "attention_bam_16_min_attention": -1.0326060056686401,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.0279255266012557,
      "attention_bam_16_attention_skewness": 0.8953916338544696,
      "attention_bam_16_attention_sparsity": 0.483154296875,
      "attention_bam_16_attention_concentration_10": 0.7115194641729077,
      "attention_bam_16_attention_concentration_20": 1.1067962683094235,
      "attention_bam_16_attention_center_y": 0.47972936787176135,
      "attention_bam_16_attention_center_x": 0.4414305807066977,
      "attention_bam_16_attention_center_distance": 0.0876501614742726,
      "attention_bam_16_attention_spatial_variance": 42.73747812970511,
      "attention_bam_16_attention_spatial_std": 6.537390773825985,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.67761780467074,
      "attention_bam_16_peak_intensity_mean": 0.32004454731941223,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 239,
      "phase": "train",
      "loss": 0.00717120710760355,
      "timestamp": 1759543919.301038,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00717120710760355,
      "ssim": 0.8630017042160034,
      "attention_bam_384_mean_attention": 0.1294112652540207,
      "attention_bam_384_std_attention": 0.49391257762908936,
      "attention_bam_384_max_attention": 3.9933652877807617,
      "attention_bam_384_min_attention": -1.2685658931732178,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.879176352365957,
      "attention_bam_384_attention_skewness": 0.8971417137390933,
      "attention_bam_384_attention_sparsity": 0.5168329874674479,
      "attention_bam_384_attention_concentration_10": 0.8728181025139676,
      "attention_bam_384_attention_concentration_20": 1.3360740077270945,
      "attention_bam_384_attention_center_y": 0.491453892492319,
      "attention_bam_384_attention_center_x": 0.4812319648076032,
      "attention_bam_384_attention_center_distance": 0.029164193749043887,
      "attention_bam_384_attention_spatial_variance": 170.8653588034668,
      "attention_bam_384_attention_spatial_std": 13.071547682025521,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 19.718187459449187,
      "attention_bam_384_peak_intensity_mean": 0.26948651671409607,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18712449073791504,
      "attention_bam_16_std_attention": 0.6755611300468445,
      "attention_bam_16_max_attention": 3.512343645095825,
      "attention_bam_16_min_attention": -1.2630118131637573,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.5347155083565376,
      "attention_bam_16_attention_skewness": 1.064448934339398,
      "attention_bam_16_attention_sparsity": 0.509033203125,
      "attention_bam_16_attention_concentration_10": 0.8627568461403355,
      "attention_bam_16_attention_concentration_20": 1.3156701634648447,
      "attention_bam_16_attention_center_y": 0.48968083075650504,
      "attention_bam_16_attention_center_x": 0.46110917285925185,
      "attention_bam_16_attention_center_distance": 0.05690310518007687,
      "attention_bam_16_attention_spatial_variance": 42.570900226880006,
      "attention_bam_16_attention_spatial_std": 6.524637938374819,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 11.040466573974143,
      "attention_bam_16_peak_intensity_mean": 0.31667134165763855,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 240,
      "phase": "train",
      "loss": 0.007412581704556942,
      "timestamp": 1759543919.487512,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007412581704556942,
      "ssim": 0.8670365214347839,
      "attention_bam_384_mean_attention": 0.13300871849060059,
      "attention_bam_384_std_attention": 0.39585116505622864,
      "attention_bam_384_max_attention": 2.6982550621032715,
      "attention_bam_384_min_attention": -1.1542987823486328,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.3009055722438734,
      "attention_bam_384_attention_skewness": 0.3604465388710129,
      "attention_bam_384_attention_sparsity": 0.4845174153645833,
      "attention_bam_384_attention_concentration_10": 0.6544054953372749,
      "attention_bam_384_attention_concentration_20": 1.0631829811360887,
      "attention_bam_384_attention_center_y": 0.48348472801405273,
      "attention_bam_384_attention_center_x": 0.48730021747566626,
      "attention_bam_384_attention_center_distance": 0.029463152748312155,
      "attention_bam_384_attention_spatial_variance": 169.25752325870715,
      "attention_bam_384_attention_spatial_std": 13.009900970365115,
      "attention_bam_384_num_attention_peaks": 19,
      "attention_bam_384_peak_separation_mean": 16.742553280438724,
      "attention_bam_384_peak_intensity_mean": 0.33955177664756775,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20456436276435852,
      "attention_bam_16_std_attention": 0.5447896122932434,
      "attention_bam_16_max_attention": 2.8377151489257812,
      "attention_bam_16_min_attention": -1.0859533548355103,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.018071155471068412,
      "attention_bam_16_attention_skewness": 0.40145951813907954,
      "attention_bam_16_attention_sparsity": 0.447998046875,
      "attention_bam_16_attention_concentration_10": 0.6007527489930183,
      "attention_bam_16_attention_concentration_20": 0.9816893576130417,
      "attention_bam_16_attention_center_y": 0.4683809350311538,
      "attention_bam_16_attention_center_x": 0.4776118123720892,
      "attention_bam_16_attention_center_distance": 0.0547904410416024,
      "attention_bam_16_attention_spatial_variance": 41.969678299428516,
      "attention_bam_16_attention_spatial_std": 6.478400906043753,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.896984193575648,
      "attention_bam_16_peak_intensity_mean": 0.3376511037349701,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 241,
      "phase": "train",
      "loss": 0.009473673067986965,
      "timestamp": 1759543919.6304846,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.009473673067986965,
      "ssim": 0.8358873724937439,
      "attention_bam_384_mean_attention": 0.12508578598499298,
      "attention_bam_384_std_attention": 0.44437554478645325,
      "attention_bam_384_max_attention": 3.361773729324341,
      "attention_bam_384_min_attention": -1.2794393301010132,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2776494077424072,
      "attention_bam_384_attention_skewness": 0.7927082917013214,
      "attention_bam_384_attention_sparsity": 0.5187861124674479,
      "attention_bam_384_attention_concentration_10": 0.8176224241846918,
      "attention_bam_384_attention_concentration_20": 1.2675626539323646,
      "attention_bam_384_attention_center_y": 0.4907846352570779,
      "attention_bam_384_attention_center_x": 0.48233514423279866,
      "attention_bam_384_attention_center_distance": 0.028176943646219626,
      "attention_bam_384_attention_spatial_variance": 170.8387077005476,
      "attention_bam_384_attention_spatial_std": 13.070528210464472,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 17.74406069636281,
      "attention_bam_384_peak_intensity_mean": 0.3067088723182678,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17142248153686523,
      "attention_bam_16_std_attention": 0.6039673686027527,
      "attention_bam_16_max_attention": 2.9022021293640137,
      "attention_bam_16_min_attention": -1.1247352361679077,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6155749845656189,
      "attention_bam_16_attention_skewness": 0.8314930882758972,
      "attention_bam_16_attention_sparsity": 0.510498046875,
      "attention_bam_16_attention_concentration_10": 0.8223805038283539,
      "attention_bam_16_attention_concentration_20": 1.288772013255674,
      "attention_bam_16_attention_center_y": 0.4869760435680235,
      "attention_bam_16_attention_center_x": 0.4640037436161623,
      "attention_bam_16_attention_center_distance": 0.05413601231699648,
      "attention_bam_16_attention_spatial_variance": 42.64259202653326,
      "attention_bam_16_attention_spatial_std": 6.530129556642292,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 7.475685895050363,
      "attention_bam_16_peak_intensity_mean": 0.33276286721229553,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 242,
      "phase": "train",
      "loss": 0.006615319289267063,
      "timestamp": 1759543919.7637703,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006615319289267063,
      "ssim": 0.8614001274108887,
      "attention_bam_384_mean_attention": 0.12820394337177277,
      "attention_bam_384_std_attention": 0.43177330493927,
      "attention_bam_384_max_attention": 4.055536270141602,
      "attention_bam_384_min_attention": -1.3033242225646973,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.0367117169182976,
      "attention_bam_384_attention_skewness": 0.8621692083308765,
      "attention_bam_384_attention_sparsity": 0.5079625447591146,
      "attention_bam_384_attention_concentration_10": 0.7722028212614676,
      "attention_bam_384_attention_concentration_20": 1.1901524877274123,
      "attention_bam_384_attention_center_y": 0.4860769141001919,
      "attention_bam_384_attention_center_x": 0.4798379240189023,
      "attention_bam_384_attention_center_distance": 0.03465145390430227,
      "attention_bam_384_attention_spatial_variance": 171.54759968948295,
      "attention_bam_384_attention_spatial_std": 13.097618092213674,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 18.87565618308635,
      "attention_bam_384_peak_intensity_mean": 0.2680321931838989,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20130258798599243,
      "attention_bam_16_std_attention": 0.6085913777351379,
      "attention_bam_16_max_attention": 3.508129835128784,
      "attention_bam_16_min_attention": -1.1192073822021484,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.7808530793405346,
      "attention_bam_16_attention_skewness": 0.9818277985863958,
      "attention_bam_16_attention_sparsity": 0.48291015625,
      "attention_bam_16_attention_concentration_10": 0.7163422405464069,
      "attention_bam_16_attention_concentration_20": 1.1096433775159689,
      "attention_bam_16_attention_center_y": 0.4751981560840871,
      "attention_bam_16_attention_center_x": 0.4553535514219923,
      "attention_bam_16_attention_center_distance": 0.07222792856309797,
      "attention_bam_16_attention_spatial_variance": 43.082402296422785,
      "attention_bam_16_attention_spatial_std": 6.563718633246156,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.599413588397336,
      "attention_bam_16_peak_intensity_mean": 0.2964784502983093,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 243,
      "phase": "train",
      "loss": 0.008623386733233929,
      "timestamp": 1759543919.8966515,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008623386733233929,
      "ssim": 0.8687101602554321,
      "attention_bam_384_mean_attention": 0.12607616186141968,
      "attention_bam_384_std_attention": 0.4517747461795807,
      "attention_bam_384_max_attention": 2.6850743293762207,
      "attention_bam_384_min_attention": -1.2614941596984863,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.3762473675252216,
      "attention_bam_384_attention_skewness": 0.6103744152238162,
      "attention_bam_384_attention_sparsity": 0.5191497802734375,
      "attention_bam_384_attention_concentration_10": 0.8013575030716418,
      "attention_bam_384_attention_concentration_20": 1.27895914363596,
      "attention_bam_384_attention_center_y": 0.48602197004267345,
      "attention_bam_384_attention_center_x": 0.4818716887700826,
      "attention_bam_384_attention_center_distance": 0.032373476474937594,
      "attention_bam_384_attention_spatial_variance": 172.33757664506248,
      "attention_bam_384_attention_spatial_std": 13.127740728894004,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 21.88323001782372,
      "attention_bam_384_peak_intensity_mean": 0.35756245255470276,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18341538310050964,
      "attention_bam_16_std_attention": 0.616194486618042,
      "attention_bam_16_max_attention": 2.8847005367279053,
      "attention_bam_16_min_attention": -1.1624476909637451,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.010240728222376205,
      "attention_bam_16_attention_skewness": 0.6507213262608174,
      "attention_bam_16_attention_sparsity": 0.505126953125,
      "attention_bam_16_attention_concentration_10": 0.7652453960065493,
      "attention_bam_16_attention_concentration_20": 1.237019731723384,
      "attention_bam_16_attention_center_y": 0.4732959299532236,
      "attention_bam_16_attention_center_x": 0.4612501375515769,
      "attention_bam_16_attention_center_distance": 0.06655312459734479,
      "attention_bam_16_attention_spatial_variance": 43.450214733788236,
      "attention_bam_16_attention_spatial_std": 6.591677687340927,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 11.839913694548214,
      "attention_bam_16_peak_intensity_mean": 0.33585500717163086,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 244,
      "phase": "train",
      "loss": 0.008328416384756565,
      "timestamp": 1759543920.0305383,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008328416384756565,
      "ssim": 0.8273974657058716,
      "attention_bam_384_mean_attention": 0.12502162158489227,
      "attention_bam_384_std_attention": 0.4190943241119385,
      "attention_bam_384_max_attention": 2.98634672164917,
      "attention_bam_384_min_attention": -1.2681220769882202,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9025194275625572,
      "attention_bam_384_attention_skewness": 0.6942174224385066,
      "attention_bam_384_attention_sparsity": 0.5197728474934896,
      "attention_bam_384_attention_concentration_10": 0.7728739939779545,
      "attention_bam_384_attention_concentration_20": 1.2133073512628234,
      "attention_bam_384_attention_center_y": 0.4872965244581332,
      "attention_bam_384_attention_center_x": 0.48642618173020463,
      "attention_bam_384_attention_center_distance": 0.026291703378223265,
      "attention_bam_384_attention_spatial_variance": 171.52839147112118,
      "attention_bam_384_attention_spatial_std": 13.096884800253882,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 17.676989919921922,
      "attention_bam_384_peak_intensity_mean": 0.32845789194107056,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17951279878616333,
      "attention_bam_16_std_attention": 0.5791409015655518,
      "attention_bam_16_max_attention": 2.9169819355010986,
      "attention_bam_16_min_attention": -1.0637755393981934,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.37701242190701034,
      "attention_bam_16_attention_skewness": 0.7525686249073393,
      "attention_bam_16_attention_sparsity": 0.51123046875,
      "attention_bam_16_attention_concentration_10": 0.755550473555538,
      "attention_bam_16_attention_concentration_20": 1.2050648714443186,
      "attention_bam_16_attention_center_y": 0.47612839213653724,
      "attention_bam_16_attention_center_x": 0.4749739673086386,
      "attention_bam_16_attention_center_distance": 0.04891126606940421,
      "attention_bam_16_attention_spatial_variance": 43.17874772516863,
      "attention_bam_16_attention_spatial_std": 6.571053775854268,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.599247621962856,
      "attention_bam_16_peak_intensity_mean": 0.3146653473377228,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 245,
      "phase": "train",
      "loss": 0.010381321422755718,
      "timestamp": 1759543920.1658316,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.010381321422755718,
      "ssim": 0.8387474417686462,
      "attention_bam_384_mean_attention": 0.1255512237548828,
      "attention_bam_384_std_attention": 0.47494375705718994,
      "attention_bam_384_max_attention": 3.542207717895508,
      "attention_bam_384_min_attention": -1.312160849571228,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8621007409401193,
      "attention_bam_384_attention_skewness": 0.685916960917682,
      "attention_bam_384_attention_sparsity": 0.515380859375,
      "attention_bam_384_attention_concentration_10": 0.8454725281679514,
      "attention_bam_384_attention_concentration_20": 1.3276177364220632,
      "attention_bam_384_attention_center_y": 0.4859029210261321,
      "attention_bam_384_attention_center_x": 0.4836645045062498,
      "attention_bam_384_attention_center_distance": 0.03051478489590911,
      "attention_bam_384_attention_spatial_variance": 169.74476911653576,
      "attention_bam_384_attention_spatial_std": 13.028613476365617,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 14.898584902714846,
      "attention_bam_384_peak_intensity_mean": 0.29712969064712524,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18249130249023438,
      "attention_bam_16_std_attention": 0.6456621885299683,
      "attention_bam_16_max_attention": 4.8227386474609375,
      "attention_bam_16_min_attention": -1.1644854545593262,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.7949005821574993,
      "attention_bam_16_attention_skewness": 0.9699576889554351,
      "attention_bam_16_attention_sparsity": 0.50732421875,
      "attention_bam_16_attention_concentration_10": 0.8195051043494955,
      "attention_bam_16_attention_concentration_20": 1.2850854558869864,
      "attention_bam_16_attention_center_y": 0.47069529523696785,
      "attention_bam_16_attention_center_x": 0.4683415866637306,
      "attention_bam_16_attention_center_distance": 0.06100853802900966,
      "attention_bam_16_attention_spatial_variance": 42.05418142374759,
      "attention_bam_16_attention_spatial_std": 6.484919538725796,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.48095382213553,
      "attention_bam_16_peak_intensity_mean": 0.22707781195640564,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 246,
      "phase": "train",
      "loss": 0.005734874866902828,
      "timestamp": 1759543920.3221755,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005734874866902828,
      "ssim": 0.8679025173187256,
      "attention_bam_384_mean_attention": 0.12517012655735016,
      "attention_bam_384_std_attention": 0.4469403922557831,
      "attention_bam_384_max_attention": 3.23671817779541,
      "attention_bam_384_min_attention": -1.2897554636001587,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5359646952292652,
      "attention_bam_384_attention_skewness": 0.7940712960885372,
      "attention_bam_384_attention_sparsity": 0.5162785847981771,
      "attention_bam_384_attention_concentration_10": 0.8147776220990695,
      "attention_bam_384_attention_concentration_20": 1.2643990438756425,
      "attention_bam_384_attention_center_y": 0.4839873193030177,
      "attention_bam_384_attention_center_x": 0.4849704461629932,
      "attention_bam_384_attention_center_distance": 0.031057798751456818,
      "attention_bam_384_attention_spatial_variance": 171.83560312964985,
      "attention_bam_384_attention_spatial_std": 13.108607978334307,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 18.311117567001858,
      "attention_bam_384_peak_intensity_mean": 0.31381165981292725,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1793990433216095,
      "attention_bam_16_std_attention": 0.6096744537353516,
      "attention_bam_16_max_attention": 3.1912007331848145,
      "attention_bam_16_min_attention": -1.2118079662322998,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.1434316774908222,
      "attention_bam_16_attention_skewness": 0.9058884792074064,
      "attention_bam_16_attention_sparsity": 0.5146484375,
      "attention_bam_16_attention_concentration_10": 0.7940366131847162,
      "attention_bam_16_attention_concentration_20": 1.2492309746952452,
      "attention_bam_16_attention_center_y": 0.4698367194696201,
      "attention_bam_16_attention_center_x": 0.46960612473734525,
      "attention_bam_16_attention_center_distance": 0.060557594830643866,
      "attention_bam_16_attention_spatial_variance": 43.2029161981742,
      "attention_bam_16_attention_spatial_std": 6.572892529029682,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.44318323596997,
      "attention_bam_16_peak_intensity_mean": 0.3205616772174835,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 247,
      "phase": "train",
      "loss": 0.005957173183560371,
      "timestamp": 1759543920.498755,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005957173183560371,
      "ssim": 0.8608056306838989,
      "attention_bam_384_mean_attention": 0.1257910281419754,
      "attention_bam_384_std_attention": 0.4452663064002991,
      "attention_bam_384_max_attention": 3.010497570037842,
      "attention_bam_384_min_attention": -1.3021764755249023,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.6453080957022124,
      "attention_bam_384_attention_skewness": 0.8147210749314614,
      "attention_bam_384_attention_sparsity": 0.5147145589192709,
      "attention_bam_384_attention_concentration_10": 0.8086643602833469,
      "attention_bam_384_attention_concentration_20": 1.248468810243886,
      "attention_bam_384_attention_center_y": 0.4914754286543752,
      "attention_bam_384_attention_center_x": 0.4823357913738489,
      "attention_bam_384_attention_center_distance": 0.027737793099482076,
      "attention_bam_384_attention_spatial_variance": 170.53458449156764,
      "attention_bam_384_attention_spatial_std": 13.058889098677867,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 18.601552432535684,
      "attention_bam_384_peak_intensity_mean": 0.33340662717819214,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19623731076717377,
      "attention_bam_16_std_attention": 0.6083473563194275,
      "attention_bam_16_max_attention": 3.5042500495910645,
      "attention_bam_16_min_attention": -1.218586802482605,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.3995234298811203,
      "attention_bam_16_attention_skewness": 0.9538762777054594,
      "attention_bam_16_attention_sparsity": 0.495361328125,
      "attention_bam_16_attention_concentration_10": 0.744854970234702,
      "attention_bam_16_attention_concentration_20": 1.1500741537177572,
      "attention_bam_16_attention_center_y": 0.48778133980399974,
      "attention_bam_16_attention_center_x": 0.4656029609844972,
      "attention_bam_16_attention_center_distance": 0.05162270721338318,
      "attention_bam_16_attention_spatial_variance": 42.44394223496688,
      "attention_bam_16_attention_spatial_std": 6.514901552208359,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 6.910521901650028,
      "attention_bam_16_peak_intensity_mean": 0.3125452399253845,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 248,
      "phase": "train",
      "loss": 0.005761319771409035,
      "timestamp": 1759543920.6637108,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005761319771409035,
      "ssim": 0.8799788355827332,
      "attention_bam_384_mean_attention": 0.12157538533210754,
      "attention_bam_384_std_attention": 0.4678060710430145,
      "attention_bam_384_max_attention": 5.2420759201049805,
      "attention_bam_384_min_attention": -1.38933265209198,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 4.635326795806498,
      "attention_bam_384_attention_skewness": 1.1702892037755726,
      "attention_bam_384_attention_sparsity": 0.5221227010091146,
      "attention_bam_384_attention_concentration_10": 0.8602973530619056,
      "attention_bam_384_attention_concentration_20": 1.3298277464316053,
      "attention_bam_384_attention_center_y": 0.4895003821322324,
      "attention_bam_384_attention_center_x": 0.48538471886942713,
      "attention_bam_384_attention_center_distance": 0.025449888718610297,
      "attention_bam_384_attention_spatial_variance": 173.1701819429833,
      "attention_bam_384_attention_spatial_std": 13.159414194521856,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 17.28224943462304,
      "attention_bam_384_peak_intensity_mean": 0.22946830093860626,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18173879384994507,
      "attention_bam_16_std_attention": 0.6398770213127136,
      "attention_bam_16_max_attention": 4.834367752075195,
      "attention_bam_16_min_attention": -1.1306283473968506,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 4.5097408554539875,
      "attention_bam_16_attention_skewness": 1.4085670991880515,
      "attention_bam_16_attention_sparsity": 0.512939453125,
      "attention_bam_16_attention_concentration_10": 0.8232606751257282,
      "attention_bam_16_attention_concentration_20": 1.2699200018458028,
      "attention_bam_16_attention_center_y": 0.4814901029094491,
      "attention_bam_16_attention_center_x": 0.47180687229693263,
      "attention_bam_16_attention_center_distance": 0.04769630467833434,
      "attention_bam_16_attention_spatial_variance": 44.28803091804814,
      "attention_bam_16_attention_spatial_std": 6.654925312732528,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.20999673739181,
      "attention_bam_16_peak_intensity_mean": 0.2221987247467041,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 249,
      "phase": "train",
      "loss": 0.0072485413402318954,
      "timestamp": 1759543920.8120527,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0072485413402318954,
      "ssim": 0.845007598400116,
      "attention_bam_384_mean_attention": 0.1214880421757698,
      "attention_bam_384_std_attention": 0.43753185868263245,
      "attention_bam_384_max_attention": 3.819861650466919,
      "attention_bam_384_min_attention": -1.2157511711120605,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.6210327322752685,
      "attention_bam_384_attention_skewness": 0.790976347056727,
      "attention_bam_384_attention_sparsity": 0.5158894856770834,
      "attention_bam_384_attention_concentration_10": 0.8136304787801644,
      "attention_bam_384_attention_concentration_20": 1.2651288245270806,
      "attention_bam_384_attention_center_y": 0.48306701328853036,
      "attention_bam_384_attention_center_x": 0.4911664471445649,
      "attention_bam_384_attention_center_distance": 0.027009542573711715,
      "attention_bam_384_attention_spatial_variance": 173.96411083783605,
      "attention_bam_384_attention_spatial_std": 13.18954551293698,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 17.91902119043012,
      "attention_bam_384_peak_intensity_mean": 0.2668631970882416,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17647209763526917,
      "attention_bam_16_std_attention": 0.6062365770339966,
      "attention_bam_16_max_attention": 3.3739938735961914,
      "attention_bam_16_min_attention": -1.1964561939239502,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.689146739385012,
      "attention_bam_16_attention_skewness": 1.0251745192749508,
      "attention_bam_16_attention_sparsity": 0.49853515625,
      "attention_bam_16_attention_concentration_10": 0.8165779801728514,
      "attention_bam_16_attention_concentration_20": 1.253754461960616,
      "attention_bam_16_attention_center_y": 0.46544540641458715,
      "attention_bam_16_attention_center_x": 0.48788652034675445,
      "attention_bam_16_attention_center_distance": 0.051783324094975755,
      "attention_bam_16_attention_spatial_variance": 45.05955089667682,
      "attention_bam_16_attention_spatial_std": 6.712641126760525,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 10.504422563100215,
      "attention_bam_16_peak_intensity_mean": 0.30396631360054016,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 250,
      "phase": "train",
      "loss": 0.009731816127896309,
      "timestamp": 1759543920.9948835,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.009731816127896309,
      "ssim": 0.8305110931396484,
      "attention_bam_384_mean_attention": 0.12486197799444199,
      "attention_bam_384_std_attention": 0.43561509251594543,
      "attention_bam_384_max_attention": 3.5427136421203613,
      "attention_bam_384_min_attention": -1.168286681175232,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.6476098554942178,
      "attention_bam_384_attention_skewness": 0.7746327844210396,
      "attention_bam_384_attention_sparsity": 0.5110092163085938,
      "attention_bam_384_attention_concentration_10": 0.7835069533672395,
      "attention_bam_384_attention_concentration_20": 1.2254147460045697,
      "attention_bam_384_attention_center_y": 0.4842814915329936,
      "attention_bam_384_attention_center_x": 0.4919582973415297,
      "attention_bam_384_attention_center_distance": 0.024969601121147305,
      "attention_bam_384_attention_spatial_variance": 171.05497380058668,
      "attention_bam_384_attention_spatial_std": 13.078798637512035,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 16.84352498394724,
      "attention_bam_384_peak_intensity_mean": 0.27835607528686523,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19535213708877563,
      "attention_bam_16_std_attention": 0.6043063402175903,
      "attention_bam_16_max_attention": 3.486992359161377,
      "attention_bam_16_min_attention": -1.1448171138763428,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.7476725733753113,
      "attention_bam_16_attention_skewness": 0.9594272313620333,
      "attention_bam_16_attention_sparsity": 0.48291015625,
      "attention_bam_16_attention_concentration_10": 0.7236908708316817,
      "attention_bam_16_attention_concentration_20": 1.1372132120261909,
      "attention_bam_16_attention_center_y": 0.4689788587680988,
      "attention_bam_16_attention_center_x": 0.4928856067471685,
      "attention_bam_16_attention_center_distance": 0.04500946110953773,
      "attention_bam_16_attention_spatial_variance": 42.93474259073473,
      "attention_bam_16_attention_spatial_std": 6.5524608042120125,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.741502552715295,
      "attention_bam_16_peak_intensity_mean": 0.29788920283317566,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 251,
      "phase": "train",
      "loss": 0.007160609588027,
      "timestamp": 1759543921.1364663,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007160609588027,
      "ssim": 0.856939435005188,
      "attention_bam_384_mean_attention": 0.1247178390622139,
      "attention_bam_384_std_attention": 0.45267820358276367,
      "attention_bam_384_max_attention": 4.3997039794921875,
      "attention_bam_384_min_attention": -1.2657129764556885,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1976054055655299,
      "attention_bam_384_attention_skewness": 0.6705503950795456,
      "attention_bam_384_attention_sparsity": 0.51123046875,
      "attention_bam_384_attention_concentration_10": 0.809144029447741,
      "attention_bam_384_attention_concentration_20": 1.2744717455693997,
      "attention_bam_384_attention_center_y": 0.48663357839900906,
      "attention_bam_384_attention_center_x": 0.48314426842814184,
      "attention_bam_384_attention_center_distance": 0.03042291614023787,
      "attention_bam_384_attention_spatial_variance": 171.65843567322244,
      "attention_bam_384_attention_spatial_std": 13.101848559391245,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 17.40552278716975,
      "attention_bam_384_peak_intensity_mean": 0.24702583253383636,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18994398415088654,
      "attention_bam_16_std_attention": 0.6166006922721863,
      "attention_bam_16_max_attention": 3.917904853820801,
      "attention_bam_16_min_attention": -1.1410908699035645,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.0309652452848317,
      "attention_bam_16_attention_skewness": 0.7865772210757622,
      "attention_bam_16_attention_sparsity": 0.492919921875,
      "attention_bam_16_attention_concentration_10": 0.746259744987731,
      "attention_bam_16_attention_concentration_20": 1.1859126808862295,
      "attention_bam_16_attention_center_y": 0.47855909996534807,
      "attention_bam_16_attention_center_x": 0.4627840640366828,
      "attention_bam_16_attention_center_distance": 0.060741058336543044,
      "attention_bam_16_attention_spatial_variance": 43.00460996567068,
      "attention_bam_16_attention_spatial_std": 6.557790021468413,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.377921825329159,
      "attention_bam_16_peak_intensity_mean": 0.266818642616272,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 252,
      "phase": "train",
      "loss": 0.01316110324114561,
      "timestamp": 1759543921.2768607,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.01316110324114561,
      "ssim": 0.8284634351730347,
      "attention_bam_384_mean_attention": 0.11939582228660583,
      "attention_bam_384_std_attention": 0.4686383008956909,
      "attention_bam_384_max_attention": 3.548692226409912,
      "attention_bam_384_min_attention": -1.197556972503662,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1654120005931636,
      "attention_bam_384_attention_skewness": 0.750097393542593,
      "attention_bam_384_attention_sparsity": 0.5251998901367188,
      "attention_bam_384_attention_concentration_10": 0.8816958663928737,
      "attention_bam_384_attention_concentration_20": 1.374284588190336,
      "attention_bam_384_attention_center_y": 0.48419793230630365,
      "attention_bam_384_attention_center_x": 0.487458574876062,
      "attention_bam_384_attention_center_distance": 0.028530428932475087,
      "attention_bam_384_attention_spatial_variance": 169.92082065380768,
      "attention_bam_384_attention_spatial_std": 13.035368067446646,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 18.005373032282396,
      "attention_bam_384_peak_intensity_mean": 0.27857211232185364,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1744784712791443,
      "attention_bam_16_std_attention": 0.6372165679931641,
      "attention_bam_16_max_attention": 3.5621745586395264,
      "attention_bam_16_min_attention": -1.0670267343521118,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8412403778261384,
      "attention_bam_16_attention_skewness": 0.8716363153879835,
      "attention_bam_16_attention_sparsity": 0.514892578125,
      "attention_bam_16_attention_concentration_10": 0.8533345824973866,
      "attention_bam_16_attention_concentration_20": 1.331953090632937,
      "attention_bam_16_attention_center_y": 0.46860719021870434,
      "attention_bam_16_attention_center_x": 0.4787387178102127,
      "attention_bam_16_attention_center_distance": 0.05361997065121126,
      "attention_bam_16_attention_spatial_variance": 42.01548887540431,
      "attention_bam_16_attention_spatial_std": 6.481935580936015,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 7.865158077320531,
      "attention_bam_16_peak_intensity_mean": 0.27154842019081116,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 253,
      "phase": "train",
      "loss": 0.0062513453885912895,
      "timestamp": 1759543921.410482,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0062513453885912895,
      "ssim": 0.8906629085540771,
      "attention_bam_384_mean_attention": 0.12318124622106552,
      "attention_bam_384_std_attention": 0.4335375428199768,
      "attention_bam_384_max_attention": 2.695049285888672,
      "attention_bam_384_min_attention": -1.3197256326675415,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7198934719440295,
      "attention_bam_384_attention_skewness": 0.6222843605470796,
      "attention_bam_384_attention_sparsity": 0.5152765909830729,
      "attention_bam_384_attention_concentration_10": 0.7942584696724042,
      "attention_bam_384_attention_concentration_20": 1.2527003999245792,
      "attention_bam_384_attention_center_y": 0.48535902070413894,
      "attention_bam_384_attention_center_x": 0.48001913080513453,
      "attention_bam_384_attention_center_distance": 0.035031226313794836,
      "attention_bam_384_attention_spatial_variance": 171.07211113140823,
      "attention_bam_384_attention_spatial_std": 13.079453778021781,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 17.88042324791431,
      "attention_bam_384_peak_intensity_mean": 0.3598291873931885,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1882266104221344,
      "attention_bam_16_std_attention": 0.5837174654006958,
      "attention_bam_16_max_attention": 2.527555227279663,
      "attention_bam_16_min_attention": -0.9881402850151062,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.2463157044167792,
      "attention_bam_16_attention_skewness": 0.6423711216438174,
      "attention_bam_16_attention_sparsity": 0.49267578125,
      "attention_bam_16_attention_concentration_10": 0.7164967208528822,
      "attention_bam_16_attention_concentration_20": 1.1485096907830132,
      "attention_bam_16_attention_center_y": 0.4720877843506287,
      "attention_bam_16_attention_center_x": 0.4580855743587479,
      "attention_bam_16_attention_center_distance": 0.07121672358783515,
      "attention_bam_16_attention_spatial_variance": 43.0012214714958,
      "attention_bam_16_attention_spatial_std": 6.557531659969001,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.104742372197753,
      "attention_bam_16_peak_intensity_mean": 0.34188875555992126,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 254,
      "phase": "train",
      "loss": 0.00888579897582531,
      "timestamp": 1759543921.5468187,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00888579897582531,
      "ssim": 0.860553503036499,
      "attention_bam_384_mean_attention": 0.11997216194868088,
      "attention_bam_384_std_attention": 0.43147900700569153,
      "attention_bam_384_max_attention": 2.721970558166504,
      "attention_bam_384_min_attention": -1.26265549659729,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7342855814998903,
      "attention_bam_384_attention_skewness": 0.6164519893785756,
      "attention_bam_384_attention_sparsity": 0.5144526163736979,
      "attention_bam_384_attention_concentration_10": 0.8069669654847884,
      "attention_bam_384_attention_concentration_20": 1.2686545178009387,
      "attention_bam_384_attention_center_y": 0.48278745377119486,
      "attention_bam_384_attention_center_x": 0.48200081585029814,
      "attention_bam_384_attention_center_distance": 0.03522051611585591,
      "attention_bam_384_attention_spatial_variance": 169.61941102549122,
      "attention_bam_384_attention_spatial_std": 13.023801711692759,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 18.272477420050233,
      "attention_bam_384_peak_intensity_mean": 0.3455794155597687,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17715969681739807,
      "attention_bam_16_std_attention": 0.5990957021713257,
      "attention_bam_16_max_attention": 2.6046125888824463,
      "attention_bam_16_min_attention": -1.1280863285064697,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.560933091595532,
      "attention_bam_16_attention_skewness": 0.756783021543432,
      "attention_bam_16_attention_sparsity": 0.501220703125,
      "attention_bam_16_attention_concentration_10": 0.7804931387649143,
      "attention_bam_16_attention_concentration_20": 1.2351277896868276,
      "attention_bam_16_attention_center_y": 0.465795886487715,
      "attention_bam_16_attention_center_x": 0.4630277809246066,
      "attention_bam_16_attention_center_distance": 0.07123013919009505,
      "attention_bam_16_attention_spatial_variance": 41.77466374117903,
      "attention_bam_16_attention_spatial_std": 6.463332247469492,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.530914572634956,
      "attention_bam_16_peak_intensity_mean": 0.34722572565078735,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 255,
      "phase": "train",
      "loss": 0.009768643416464329,
      "timestamp": 1759543921.6846561,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.009768643416464329,
      "ssim": 0.8487281799316406,
      "attention_bam_384_mean_attention": 0.11708908528089523,
      "attention_bam_384_std_attention": 0.4651225507259369,
      "attention_bam_384_max_attention": 3.4087347984313965,
      "attention_bam_384_min_attention": -1.2502989768981934,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.402445807557256,
      "attention_bam_384_attention_skewness": 0.7460825650184465,
      "attention_bam_384_attention_sparsity": 0.5191014607747396,
      "attention_bam_384_attention_concentration_10": 0.875865783887968,
      "attention_bam_384_attention_concentration_20": 1.3710448321150255,
      "attention_bam_384_attention_center_y": 0.4816169871713759,
      "attention_bam_384_attention_center_x": 0.48485685768799747,
      "attention_bam_384_attention_center_distance": 0.03368233720331531,
      "attention_bam_384_attention_spatial_variance": 168.59241140530247,
      "attention_bam_384_attention_spatial_std": 12.98431405216704,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 14.434864523847812,
      "attention_bam_384_peak_intensity_mean": 0.29469066858291626,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17781665921211243,
      "attention_bam_16_std_attention": 0.6502586603164673,
      "attention_bam_16_max_attention": 3.6305766105651855,
      "attention_bam_16_min_attention": -1.0665600299835205,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.0590645781170744,
      "attention_bam_16_attention_skewness": 0.8938556451894649,
      "attention_bam_16_attention_sparsity": 0.515380859375,
      "attention_bam_16_attention_concentration_10": 0.8403238763006348,
      "attention_bam_16_attention_concentration_20": 1.3221267210597523,
      "attention_bam_16_attention_center_y": 0.46251806821442615,
      "attention_bam_16_attention_center_x": 0.47121976057315346,
      "attention_bam_16_attention_center_distance": 0.06683109144470145,
      "attention_bam_16_attention_spatial_variance": 40.77724854692455,
      "attention_bam_16_attention_spatial_std": 6.385706581649719,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 7.2387766834224,
      "attention_bam_16_peak_intensity_mean": 0.2749912142753601,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 256,
      "phase": "train",
      "loss": 0.006107610650360584,
      "timestamp": 1759543921.8319142,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006107610650360584,
      "ssim": 0.8699754476547241,
      "attention_bam_384_mean_attention": 0.11749713867902756,
      "attention_bam_384_std_attention": 0.45533299446105957,
      "attention_bam_384_max_attention": 2.838047981262207,
      "attention_bam_384_min_attention": -1.293292760848999,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5239261411723763,
      "attention_bam_384_attention_skewness": 0.6377116300683929,
      "attention_bam_384_attention_sparsity": 0.5253702799479166,
      "attention_bam_384_attention_concentration_10": 0.8626582510182532,
      "attention_bam_384_attention_concentration_20": 1.369075375841513,
      "attention_bam_384_attention_center_y": 0.48066671159425245,
      "attention_bam_384_attention_center_x": 0.49050915038997916,
      "attention_bam_384_attention_center_distance": 0.030458242460780473,
      "attention_bam_384_attention_spatial_variance": 170.4492002233838,
      "attention_bam_384_attention_spatial_std": 13.055619488304023,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 17.831800815106615,
      "attention_bam_384_peak_intensity_mean": 0.3410469591617584,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.175735205411911,
      "attention_bam_16_std_attention": 0.6200176477432251,
      "attention_bam_16_max_attention": 2.6892566680908203,
      "attention_bam_16_min_attention": -1.02369225025177,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.34150265008144576,
      "attention_bam_16_attention_skewness": 0.7431879046156917,
      "attention_bam_16_attention_sparsity": 0.51025390625,
      "attention_bam_16_attention_concentration_10": 0.8097723385614591,
      "attention_bam_16_attention_concentration_20": 1.295469580823474,
      "attention_bam_16_attention_center_y": 0.45704296600732425,
      "attention_bam_16_attention_center_x": 0.49287535578018515,
      "attention_bam_16_attention_center_distance": 0.061580310566070405,
      "attention_bam_16_attention_spatial_variance": 42.62332738410084,
      "attention_bam_16_attention_spatial_std": 6.528654331797697,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 7.728774884128959,
      "attention_bam_16_peak_intensity_mean": 0.32932648062705994,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 257,
      "phase": "train",
      "loss": 0.014961285516619682,
      "timestamp": 1759543921.9859076,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.014961285516619682,
      "ssim": 0.8598815202713013,
      "attention_bam_384_mean_attention": 0.11887192726135254,
      "attention_bam_384_std_attention": 0.40851089358329773,
      "attention_bam_384_max_attention": 2.857158899307251,
      "attention_bam_384_min_attention": -1.19216787815094,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7277730995202685,
      "attention_bam_384_attention_skewness": 0.6450051259865216,
      "attention_bam_384_attention_sparsity": 0.5161488850911459,
      "attention_bam_384_attention_concentration_10": 0.7758993785745338,
      "attention_bam_384_attention_concentration_20": 1.2257063322533488,
      "attention_bam_384_attention_center_y": 0.48448670787764575,
      "attention_bam_384_attention_center_x": 0.4913928963609195,
      "attention_bam_384_attention_center_distance": 0.025089617993400034,
      "attention_bam_384_attention_spatial_variance": 172.9449730275656,
      "attention_bam_384_attention_spatial_std": 13.15085445997961,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 17.88018253434723,
      "attention_bam_384_peak_intensity_mean": 0.32996222376823425,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18885844945907593,
      "attention_bam_16_std_attention": 0.5844645500183105,
      "attention_bam_16_max_attention": 3.0817317962646484,
      "attention_bam_16_min_attention": -0.9786288738250732,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.37103863291430406,
      "attention_bam_16_attention_skewness": 0.685949195611958,
      "attention_bam_16_attention_sparsity": 0.485595703125,
      "attention_bam_16_attention_concentration_10": 0.7166146076355066,
      "attention_bam_16_attention_concentration_20": 1.1397696368408443,
      "attention_bam_16_attention_center_y": 0.46817806971843823,
      "attention_bam_16_attention_center_x": 0.49439433256354565,
      "attention_bam_16_attention_center_distance": 0.04569592441898298,
      "attention_bam_16_attention_spatial_variance": 44.65776455010459,
      "attention_bam_16_attention_spatial_std": 6.68264652290577,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.674141037183645,
      "attention_bam_16_peak_intensity_mean": 0.29815673828125,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 258,
      "phase": "train",
      "loss": 0.013713951222598553,
      "timestamp": 1759543922.138267,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.013713951222598553,
      "ssim": 0.8692094683647156,
      "attention_bam_384_mean_attention": 0.11941944807767868,
      "attention_bam_384_std_attention": 0.4077672064304352,
      "attention_bam_384_max_attention": 3.264796733856201,
      "attention_bam_384_min_attention": -1.303701639175415,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7772092931460874,
      "attention_bam_384_attention_skewness": 0.6227697007945988,
      "attention_bam_384_attention_sparsity": 0.5169626871744791,
      "attention_bam_384_attention_concentration_10": 0.7713985053847177,
      "attention_bam_384_attention_concentration_20": 1.2186040359679982,
      "attention_bam_384_attention_center_y": 0.4770889614757288,
      "attention_bam_384_attention_center_x": 0.4854273296305835,
      "attention_bam_384_attention_center_distance": 0.038399958540506464,
      "attention_bam_384_attention_spatial_variance": 171.19674024006,
      "attention_bam_384_attention_spatial_std": 13.08421721923249,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 16.4451410667268,
      "attention_bam_384_peak_intensity_mean": 0.31517496705055237,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1816418468952179,
      "attention_bam_16_std_attention": 0.574830174446106,
      "attention_bam_16_max_attention": 2.584702253341675,
      "attention_bam_16_min_attention": -1.0144736766815186,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.22780484546978075,
      "attention_bam_16_attention_skewness": 0.6639686649481726,
      "attention_bam_16_attention_sparsity": 0.491943359375,
      "attention_bam_16_attention_concentration_10": 0.7391594826319967,
      "attention_bam_16_attention_concentration_20": 1.1749761152178073,
      "attention_bam_16_attention_center_y": 0.4484082768375862,
      "attention_bam_16_attention_center_x": 0.4675089014360622,
      "attention_bam_16_attention_center_distance": 0.08622502403315017,
      "attention_bam_16_attention_spatial_variance": 42.912540414028626,
      "attention_bam_16_attention_spatial_std": 6.550766398981773,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.411177259948062,
      "attention_bam_16_peak_intensity_mean": 0.34249821305274963,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 259,
      "phase": "train",
      "loss": 0.00742822652682662,
      "timestamp": 1759543922.2717974,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00742822652682662,
      "ssim": 0.8730816841125488,
      "attention_bam_384_mean_attention": 0.11668276786804199,
      "attention_bam_384_std_attention": 0.43855857849121094,
      "attention_bam_384_max_attention": 3.152961254119873,
      "attention_bam_384_min_attention": -1.4648969173431396,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2712195414561096,
      "attention_bam_384_attention_skewness": 0.783746690532811,
      "attention_bam_384_attention_sparsity": 0.5255304972330729,
      "attention_bam_384_attention_concentration_10": 0.8553244973976637,
      "attention_bam_384_attention_concentration_20": 1.3264221919356003,
      "attention_bam_384_attention_center_y": 0.48325187123302094,
      "attention_bam_384_attention_center_x": 0.47881976634404233,
      "attention_bam_384_attention_center_distance": 0.03818644039227206,
      "attention_bam_384_attention_spatial_variance": 170.45692253193073,
      "attention_bam_384_attention_spatial_std": 13.055915231492992,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 18.524536539256857,
      "attention_bam_384_peak_intensity_mean": 0.3439022898674011,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16934910416603088,
      "attention_bam_16_std_attention": 0.5966850519180298,
      "attention_bam_16_max_attention": 2.783108711242676,
      "attention_bam_16_min_attention": -1.110460638999939,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.9410611674104912,
      "attention_bam_16_attention_skewness": 0.901932827233074,
      "attention_bam_16_attention_sparsity": 0.51416015625,
      "attention_bam_16_attention_concentration_10": 0.833605019545695,
      "attention_bam_16_attention_concentration_20": 1.2907439145824604,
      "attention_bam_16_attention_center_y": 0.4659372446140893,
      "attention_bam_16_attention_center_x": 0.4542249600797649,
      "attention_bam_16_attention_center_distance": 0.08069232409813844,
      "attention_bam_16_attention_spatial_variance": 42.46823073962259,
      "attention_bam_16_attention_spatial_std": 6.51676535864401,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.761555559435516,
      "attention_bam_16_peak_intensity_mean": 0.3379482626914978,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 260,
      "phase": "train",
      "loss": 0.006951767485588789,
      "timestamp": 1759543922.4609904,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006951767485588789,
      "ssim": 0.8812186121940613,
      "attention_bam_384_mean_attention": 0.11816040426492691,
      "attention_bam_384_std_attention": 0.4147416651248932,
      "attention_bam_384_max_attention": 3.1521918773651123,
      "attention_bam_384_min_attention": -1.2007560729980469,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0327897020725878,
      "attention_bam_384_attention_skewness": 0.7706811574386812,
      "attention_bam_384_attention_sparsity": 0.5271631876627604,
      "attention_bam_384_attention_concentration_10": 0.8073557373475027,
      "attention_bam_384_attention_concentration_20": 1.2597329704961366,
      "attention_bam_384_attention_center_y": 0.4864807022399445,
      "attention_bam_384_attention_center_x": 0.4880607250198561,
      "attention_bam_384_attention_center_distance": 0.025507555703223782,
      "attention_bam_384_attention_spatial_variance": 168.26093464061498,
      "attention_bam_384_attention_spatial_std": 12.971543263645039,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 13.031826409293584,
      "attention_bam_384_peak_intensity_mean": 0.3064271807670593,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18745052814483643,
      "attention_bam_16_std_attention": 0.5794767737388611,
      "attention_bam_16_max_attention": 2.9524471759796143,
      "attention_bam_16_min_attention": -0.9745572209358215,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6728278164437147,
      "attention_bam_16_attention_skewness": 0.8450481714572955,
      "attention_bam_16_attention_sparsity": 0.503173828125,
      "attention_bam_16_attention_concentration_10": 0.7350991987561728,
      "attention_bam_16_attention_concentration_20": 1.1606066396914818,
      "attention_bam_16_attention_center_y": 0.47581472731299185,
      "attention_bam_16_attention_center_x": 0.48095538966786594,
      "attention_bam_16_attention_center_distance": 0.043534459859926364,
      "attention_bam_16_attention_spatial_variance": 40.88606519921624,
      "attention_bam_16_attention_spatial_std": 6.394221234772553,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 7.9909508648552645,
      "attention_bam_16_peak_intensity_mean": 0.3048546314239502,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 261,
      "phase": "train",
      "loss": 0.012952476739883423,
      "timestamp": 1759543922.6172905,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.012952476739883423,
      "ssim": 0.8176043033599854,
      "attention_bam_384_mean_attention": 0.11909559369087219,
      "attention_bam_384_std_attention": 0.4161824882030487,
      "attention_bam_384_max_attention": 3.2072620391845703,
      "attention_bam_384_min_attention": -1.185072898864746,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.3041912162849796,
      "attention_bam_384_attention_skewness": 0.7522291551874888,
      "attention_bam_384_attention_sparsity": 0.5197957356770834,
      "attention_bam_384_attention_concentration_10": 0.7943517796763636,
      "attention_bam_384_attention_concentration_20": 1.2414934910835227,
      "attention_bam_384_attention_center_y": 0.48188014667717693,
      "attention_bam_384_attention_center_x": 0.4927941273614935,
      "attention_bam_384_attention_center_distance": 0.02757729808821013,
      "attention_bam_384_attention_spatial_variance": 171.53196147896986,
      "attention_bam_384_attention_spatial_std": 13.097021091796785,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 17.00576878798724,
      "attention_bam_384_peak_intensity_mean": 0.29540783166885376,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1859361082315445,
      "attention_bam_16_std_attention": 0.5757910013198853,
      "attention_bam_16_max_attention": 2.9618258476257324,
      "attention_bam_16_min_attention": -1.190239667892456,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8161258544880754,
      "attention_bam_16_attention_skewness": 0.8040501175179127,
      "attention_bam_16_attention_sparsity": 0.491455078125,
      "attention_bam_16_attention_concentration_10": 0.7242755446888586,
      "attention_bam_16_attention_concentration_20": 1.1507209390870403,
      "attention_bam_16_attention_center_y": 0.46258855126859333,
      "attention_bam_16_attention_center_x": 0.49023745788220896,
      "attention_bam_16_attention_center_distance": 0.054679497524836744,
      "attention_bam_16_attention_spatial_variance": 43.18400393224195,
      "attention_bam_16_attention_spatial_std": 6.571453715293288,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 7.803561342157279,
      "attention_bam_16_peak_intensity_mean": 0.3248702585697174,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 262,
      "phase": "train",
      "loss": 0.005346134305000305,
      "timestamp": 1759543922.7608962,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005346134305000305,
      "ssim": 0.8839638829231262,
      "attention_bam_384_mean_attention": 0.11349823325872421,
      "attention_bam_384_std_attention": 0.4625406563282013,
      "attention_bam_384_max_attention": 3.3596596717834473,
      "attention_bam_384_min_attention": -1.3030905723571777,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0025414707933527,
      "attention_bam_384_attention_skewness": 0.7688199825909307,
      "attention_bam_384_attention_sparsity": 0.5338134765625,
      "attention_bam_384_attention_concentration_10": 0.9122089545600421,
      "attention_bam_384_attention_concentration_20": 1.4292382057546198,
      "attention_bam_384_attention_center_y": 0.49095229050180855,
      "attention_bam_384_attention_center_x": 0.49059190080012643,
      "attention_bam_384_attention_center_distance": 0.018459327058066084,
      "attention_bam_384_attention_spatial_variance": 171.0463100131746,
      "attention_bam_384_attention_spatial_std": 13.078467418362695,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 17.022412626845927,
      "attention_bam_384_peak_intensity_mean": 0.3048912286758423,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1707424819469452,
      "attention_bam_16_std_attention": 0.6396780610084534,
      "attention_bam_16_max_attention": 3.1612722873687744,
      "attention_bam_16_min_attention": -1.0259605646133423,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.01347828171202,
      "attention_bam_16_attention_skewness": 0.9723332845572721,
      "attention_bam_16_attention_sparsity": 0.521728515625,
      "attention_bam_16_attention_concentration_10": 0.8824631050077103,
      "attention_bam_16_attention_concentration_20": 1.3733606473484705,
      "attention_bam_16_attention_center_y": 0.4870775059775783,
      "attention_bam_16_attention_center_x": 0.48881990013387405,
      "attention_bam_16_attention_center_distance": 0.024165491295484707,
      "attention_bam_16_attention_spatial_variance": 43.01654501227809,
      "attention_bam_16_attention_spatial_std": 6.5586999483341275,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.382395455169828,
      "attention_bam_16_peak_intensity_mean": 0.29404354095458984,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 263,
      "phase": "train",
      "loss": 0.008631547912955284,
      "timestamp": 1759543923.12411,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008631547912955284,
      "ssim": 0.8719766736030579,
      "attention_bam_384_mean_attention": 0.11758964508771896,
      "attention_bam_384_std_attention": 0.463252454996109,
      "attention_bam_384_max_attention": 3.872917652130127,
      "attention_bam_384_min_attention": -1.394453763961792,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.3259498775523246,
      "attention_bam_384_attention_skewness": 0.9092351593134096,
      "attention_bam_384_attention_sparsity": 0.526031494140625,
      "attention_bam_384_attention_concentration_10": 0.8911191816884181,
      "attention_bam_384_attention_concentration_20": 1.3651505652503633,
      "attention_bam_384_attention_center_y": 0.4834248875019331,
      "attention_bam_384_attention_center_x": 0.4850789881831564,
      "attention_bam_384_attention_center_distance": 0.03153952910117588,
      "attention_bam_384_attention_spatial_variance": 168.5344830592827,
      "attention_bam_384_attention_spatial_std": 12.98208315561423,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 14.583829001075985,
      "attention_bam_384_peak_intensity_mean": 0.2896345555782318,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18324510753154755,
      "attention_bam_16_std_attention": 0.62212735414505,
      "attention_bam_16_max_attention": 3.855800151824951,
      "attention_bam_16_min_attention": -1.2426837682724,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.954969782421836,
      "attention_bam_16_attention_skewness": 1.0240568786113355,
      "attention_bam_16_attention_sparsity": 0.506591796875,
      "attention_bam_16_attention_concentration_10": 0.7922406341867867,
      "attention_bam_16_attention_concentration_20": 1.2378317284074127,
      "attention_bam_16_attention_center_y": 0.4672302017908989,
      "attention_bam_16_attention_center_x": 0.46838946147112165,
      "attention_bam_16_attention_center_distance": 0.06439077295313216,
      "attention_bam_16_attention_spatial_variance": 41.23353847621132,
      "attention_bam_16_attention_spatial_std": 6.421334633564219,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.88414539479788,
      "attention_bam_16_peak_intensity_mean": 0.29838281869888306,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 264,
      "phase": "train",
      "loss": 0.00614527054131031,
      "timestamp": 1759543923.2541702,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00614527054131031,
      "ssim": 0.8798012733459473,
      "attention_bam_384_mean_attention": 0.11750543117523193,
      "attention_bam_384_std_attention": 0.4554016590118408,
      "attention_bam_384_max_attention": 3.128943920135498,
      "attention_bam_384_min_attention": -1.3048783540725708,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7025488845297403,
      "attention_bam_384_attention_skewness": 0.6422739924915849,
      "attention_bam_384_attention_sparsity": 0.5202458699544271,
      "attention_bam_384_attention_concentration_10": 0.8595257008419507,
      "attention_bam_384_attention_concentration_20": 1.355450284245769,
      "attention_bam_384_attention_center_y": 0.48489490017026865,
      "attention_bam_384_attention_center_x": 0.48348150149766533,
      "attention_bam_384_attention_center_distance": 0.03165516809741445,
      "attention_bam_384_attention_spatial_variance": 170.8106003836289,
      "attention_bam_384_attention_spatial_std": 13.069452948904514,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 17.146986436259148,
      "attention_bam_384_peak_intensity_mean": 0.3220212161540985,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17172057926654816,
      "attention_bam_16_std_attention": 0.6192870140075684,
      "attention_bam_16_max_attention": 3.1431024074554443,
      "attention_bam_16_min_attention": -1.0224120616912842,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6771083751737756,
      "attention_bam_16_attention_skewness": 0.7814054033758949,
      "attention_bam_16_attention_sparsity": 0.50927734375,
      "attention_bam_16_attention_concentration_10": 0.8229412720652131,
      "attention_bam_16_attention_concentration_20": 1.301107265678844,
      "attention_bam_16_attention_center_y": 0.468389930251825,
      "attention_bam_16_attention_center_x": 0.46572093718946833,
      "attention_bam_16_attention_center_distance": 0.06594316729810394,
      "attention_bam_16_attention_spatial_variance": 42.65584996829005,
      "attention_bam_16_attention_spatial_std": 6.531144613947087,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.99942082307197,
      "attention_bam_16_peak_intensity_mean": 0.2889474928379059,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 265,
      "phase": "train",
      "loss": 0.005559922195971012,
      "timestamp": 1759543923.3927107,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005559922195971012,
      "ssim": 0.8924224376678467,
      "attention_bam_384_mean_attention": 0.11481144279241562,
      "attention_bam_384_std_attention": 0.44631636142730713,
      "attention_bam_384_max_attention": 2.8546926975250244,
      "attention_bam_384_min_attention": -1.206907868385315,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0665956813472022,
      "attention_bam_384_attention_skewness": 0.7709044110717471,
      "attention_bam_384_attention_sparsity": 0.5313491821289062,
      "attention_bam_384_attention_concentration_10": 0.8854424278060264,
      "attention_bam_384_attention_concentration_20": 1.3740713443571744,
      "attention_bam_384_attention_center_y": 0.4812827371837745,
      "attention_bam_384_attention_center_x": 0.48791638127353876,
      "attention_bam_384_attention_center_distance": 0.031507134711304424,
      "attention_bam_384_attention_spatial_variance": 171.1644816852006,
      "attention_bam_384_attention_spatial_std": 13.08298443342346,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 17.547227915418354,
      "attention_bam_384_peak_intensity_mean": 0.3329552412033081,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1758013665676117,
      "attention_bam_16_std_attention": 0.6116763353347778,
      "attention_bam_16_max_attention": 3.1744346618652344,
      "attention_bam_16_min_attention": -1.0787353515625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.0033312702249795,
      "attention_bam_16_attention_skewness": 0.9296048769432027,
      "attention_bam_16_attention_sparsity": 0.52099609375,
      "attention_bam_16_attention_concentration_10": 0.8169339615731158,
      "attention_bam_16_attention_concentration_20": 1.286119566037931,
      "attention_bam_16_attention_center_y": 0.4591295192300498,
      "attention_bam_16_attention_center_x": 0.47902265259144905,
      "attention_bam_16_attention_center_distance": 0.06496838158159565,
      "attention_bam_16_attention_spatial_variance": 42.91769172117681,
      "attention_bam_16_attention_spatial_std": 6.551159570730728,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.562482375738119,
      "attention_bam_16_peak_intensity_mean": 0.311785489320755,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 266,
      "phase": "train",
      "loss": 0.006996700074523687,
      "timestamp": 1759543923.5410647,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006996700074523687,
      "ssim": 0.8795108795166016,
      "attention_bam_384_mean_attention": 0.11694830656051636,
      "attention_bam_384_std_attention": 0.4792553186416626,
      "attention_bam_384_max_attention": 2.7753477096557617,
      "attention_bam_384_min_attention": -1.1597533226013184,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7086083651791832,
      "attention_bam_384_attention_skewness": 0.6881402130862996,
      "attention_bam_384_attention_sparsity": 0.5292078653971354,
      "attention_bam_384_attention_concentration_10": 0.9208542997425371,
      "attention_bam_384_attention_concentration_20": 1.4338006806084544,
      "attention_bam_384_attention_center_y": 0.47895497359809536,
      "attention_bam_384_attention_center_x": 0.48851802770267766,
      "attention_bam_384_attention_center_distance": 0.033903652431363236,
      "attention_bam_384_attention_spatial_variance": 170.9648567344774,
      "attention_bam_384_attention_spatial_std": 13.075353025233293,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 19.46438726430861,
      "attention_bam_384_peak_intensity_mean": 0.32637256383895874,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18104100227355957,
      "attention_bam_16_std_attention": 0.648539125919342,
      "attention_bam_16_max_attention": 3.0995378494262695,
      "attention_bam_16_min_attention": -1.221906065940857,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7026353372545509,
      "attention_bam_16_attention_skewness": 0.909481473818987,
      "attention_bam_16_attention_sparsity": 0.522705078125,
      "attention_bam_16_attention_concentration_10": 0.8528556340185328,
      "attention_bam_16_attention_concentration_20": 1.3293163084653505,
      "attention_bam_16_attention_center_y": 0.4538635584663391,
      "attention_bam_16_attention_center_x": 0.4809988164254215,
      "attention_bam_16_attention_center_distance": 0.07056367641533061,
      "attention_bam_16_attention_spatial_variance": 42.79114261193963,
      "attention_bam_16_attention_spatial_std": 6.541493912856575,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 10.364244738606276,
      "attention_bam_16_peak_intensity_mean": 0.3390728235244751,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 267,
      "phase": "train",
      "loss": 0.007502625696361065,
      "timestamp": 1759543923.6701875,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007502625696361065,
      "ssim": 0.8753948211669922,
      "attention_bam_384_mean_attention": 0.11536290496587753,
      "attention_bam_384_std_attention": 0.42047396302223206,
      "attention_bam_384_max_attention": 3.283900499343872,
      "attention_bam_384_min_attention": -1.2346514463424683,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6007307193573812,
      "attention_bam_384_attention_skewness": 0.5905567048546888,
      "attention_bam_384_attention_sparsity": 0.5161997477213541,
      "attention_bam_384_attention_concentration_10": 0.8126093512248904,
      "attention_bam_384_attention_concentration_20": 1.2820621365540914,
      "attention_bam_384_attention_center_y": 0.48444642817912215,
      "attention_bam_384_attention_center_x": 0.4783911236627281,
      "attention_bam_384_attention_center_distance": 0.037652546605686954,
      "attention_bam_384_attention_spatial_variance": 170.02014185876212,
      "attention_bam_384_attention_spatial_std": 13.039177192551765,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 17.569163766101866,
      "attention_bam_384_peak_intensity_mean": 0.3022180497646332,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18065235018730164,
      "attention_bam_16_std_attention": 0.572559654712677,
      "attention_bam_16_max_attention": 2.6262941360473633,
      "attention_bam_16_min_attention": -1.2015231847763062,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.40847139917853204,
      "attention_bam_16_attention_skewness": 0.7049150181558721,
      "attention_bam_16_attention_sparsity": 0.498046875,
      "attention_bam_16_attention_concentration_10": 0.7316004603899983,
      "attention_bam_16_attention_concentration_20": 1.1688280011660532,
      "attention_bam_16_attention_center_y": 0.46855820439886886,
      "attention_bam_16_attention_center_x": 0.4557769160151961,
      "attention_bam_16_attention_center_distance": 0.07673679258022618,
      "attention_bam_16_attention_spatial_variance": 42.0368645101232,
      "attention_bam_16_attention_spatial_std": 6.483584233286647,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.18846002576334,
      "attention_bam_16_peak_intensity_mean": 0.37766900658607483,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 268,
      "phase": "train",
      "loss": 0.005460366606712341,
      "timestamp": 1759543923.813845,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005460366606712341,
      "ssim": 0.8955014944076538,
      "attention_bam_384_mean_attention": 0.11145009845495224,
      "attention_bam_384_std_attention": 0.4553467631340027,
      "attention_bam_384_max_attention": 3.9085910320281982,
      "attention_bam_384_min_attention": -1.4289195537567139,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.0430398459974963,
      "attention_bam_384_attention_skewness": 0.9455390817810687,
      "attention_bam_384_attention_sparsity": 0.5363032023111979,
      "attention_bam_384_attention_concentration_10": 0.927000372762477,
      "attention_bam_384_attention_concentration_20": 1.4238526583716737,
      "attention_bam_384_attention_center_y": 0.4911046725802252,
      "attention_bam_384_attention_center_x": 0.4857082711676485,
      "attention_bam_384_attention_center_distance": 0.02380673698441115,
      "attention_bam_384_attention_spatial_variance": 172.44950411768474,
      "attention_bam_384_attention_spatial_std": 13.132003050475001,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 17.444206001193933,
      "attention_bam_384_peak_intensity_mean": 0.292471706867218,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16204333305358887,
      "attention_bam_16_std_attention": 0.6218740344047546,
      "attention_bam_16_max_attention": 3.2246253490448,
      "attention_bam_16_min_attention": -1.1219761371612549,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.6718513523737206,
      "attention_bam_16_attention_skewness": 1.0791678657177044,
      "attention_bam_16_attention_sparsity": 0.525390625,
      "attention_bam_16_attention_concentration_10": 0.9049030469555083,
      "attention_bam_16_attention_concentration_20": 1.3886353303432757,
      "attention_bam_16_attention_center_y": 0.48791420749382586,
      "attention_bam_16_attention_center_x": 0.474249920403625,
      "attention_bam_16_attention_center_distance": 0.04022767653548841,
      "attention_bam_16_attention_spatial_variance": 43.89861986724435,
      "attention_bam_16_attention_spatial_std": 6.6256033587322705,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.986119903063564,
      "attention_bam_16_peak_intensity_mean": 0.31153789162635803,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 269,
      "phase": "train",
      "loss": 0.006334502249956131,
      "timestamp": 1759543923.9578,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006334502249956131,
      "ssim": 0.8848559856414795,
      "attention_bam_384_mean_attention": 0.11554829031229019,
      "attention_bam_384_std_attention": 0.39965736865997314,
      "attention_bam_384_max_attention": 2.9253761768341064,
      "attention_bam_384_min_attention": -1.2328062057495117,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6751637049978751,
      "attention_bam_384_attention_skewness": 0.528144092653466,
      "attention_bam_384_attention_sparsity": 0.5116475423177084,
      "attention_bam_384_attention_concentration_10": 0.7627040670345119,
      "attention_bam_384_attention_concentration_20": 1.2155421085135991,
      "attention_bam_384_attention_center_y": 0.48277909862052343,
      "attention_bam_384_attention_center_x": 0.48425627748672334,
      "attention_bam_384_attention_center_distance": 0.032997704250347856,
      "attention_bam_384_attention_spatial_variance": 170.78050208239762,
      "attention_bam_384_attention_spatial_std": 13.068301423000527,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 18.008543240830456,
      "attention_bam_384_peak_intensity_mean": 0.32788339257240295,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18678933382034302,
      "attention_bam_16_std_attention": 0.5574252009391785,
      "attention_bam_16_max_attention": 2.4681944847106934,
      "attention_bam_16_min_attention": -1.090050220489502,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.2167475222998254,
      "attention_bam_16_attention_skewness": 0.5912073078567349,
      "attention_bam_16_attention_sparsity": 0.475830078125,
      "attention_bam_16_attention_concentration_10": 0.6875497199001973,
      "attention_bam_16_attention_concentration_20": 1.1005443063480087,
      "attention_bam_16_attention_center_y": 0.4653065005876159,
      "attention_bam_16_attention_center_x": 0.4730377114428737,
      "attention_bam_16_attention_center_distance": 0.0621386177141854,
      "attention_bam_16_attention_spatial_variance": 42.82336290469133,
      "attention_bam_16_attention_spatial_std": 6.543956212009012,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.006731787937559,
      "attention_bam_16_peak_intensity_mean": 0.36829400062561035,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 270,
      "phase": "train",
      "loss": 0.004674128722399473,
      "timestamp": 1759543924.1382072,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004674128722399473,
      "ssim": 0.900266706943512,
      "attention_bam_384_mean_attention": 0.11052047461271286,
      "attention_bam_384_std_attention": 0.42138490080833435,
      "attention_bam_384_max_attention": 3.1505722999572754,
      "attention_bam_384_min_attention": -1.2694952487945557,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0100713612161627,
      "attention_bam_384_attention_skewness": 0.7091215299292398,
      "attention_bam_384_attention_sparsity": 0.5298792521158854,
      "attention_bam_384_attention_concentration_10": 0.8599216833977702,
      "attention_bam_384_attention_concentration_20": 1.3359387633020772,
      "attention_bam_384_attention_center_y": 0.4815432043146323,
      "attention_bam_384_attention_center_x": 0.4837214519370009,
      "attention_bam_384_attention_center_distance": 0.03480357550628323,
      "attention_bam_384_attention_spatial_variance": 173.19683521210615,
      "attention_bam_384_attention_spatial_std": 13.160426862837928,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 16.696481076673063,
      "attention_bam_384_peak_intensity_mean": 0.31598761677742004,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1722475290298462,
      "attention_bam_16_std_attention": 0.5909645557403564,
      "attention_bam_16_max_attention": 2.6598286628723145,
      "attention_bam_16_min_attention": -1.1102641820907593,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8200466937649935,
      "attention_bam_16_attention_skewness": 0.8552398592443071,
      "attention_bam_16_attention_sparsity": 0.5078125,
      "attention_bam_16_attention_concentration_10": 0.8001341945479313,
      "attention_bam_16_attention_concentration_20": 1.2593081470937149,
      "attention_bam_16_attention_center_y": 0.4622324082992401,
      "attention_bam_16_attention_center_x": 0.4710903455019765,
      "attention_bam_16_attention_center_distance": 0.06726305235521798,
      "attention_bam_16_attention_spatial_variance": 44.248797640366554,
      "attention_bam_16_attention_spatial_std": 6.65197697232684,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.899931101997405,
      "attention_bam_16_peak_intensity_mean": 0.3437173366546631,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 271,
      "phase": "train",
      "loss": 0.006569835357367992,
      "timestamp": 1759543924.268443,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006569835357367992,
      "ssim": 0.8613429069519043,
      "attention_bam_384_mean_attention": 0.10955566167831421,
      "attention_bam_384_std_attention": 0.41820135712623596,
      "attention_bam_384_max_attention": 2.6883249282836914,
      "attention_bam_384_min_attention": -1.1469337940216064,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9047334793656181,
      "attention_bam_384_attention_skewness": 0.7462391347926741,
      "attention_bam_384_attention_sparsity": 0.5329767862955729,
      "attention_bam_384_attention_concentration_10": 0.8652861373813601,
      "attention_bam_384_attention_concentration_20": 1.345650536613256,
      "attention_bam_384_attention_center_y": 0.4863005415371589,
      "attention_bam_384_attention_center_x": 0.48981360984325034,
      "attention_bam_384_attention_center_distance": 0.02414281286845569,
      "attention_bam_384_attention_spatial_variance": 171.29929018718101,
      "attention_bam_384_attention_spatial_std": 13.08813547405363,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 16.15117180115395,
      "attention_bam_384_peak_intensity_mean": 0.3361262381076813,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17933697998523712,
      "attention_bam_16_std_attention": 0.5939844846725464,
      "attention_bam_16_max_attention": 2.887204170227051,
      "attention_bam_16_min_attention": -1.200984239578247,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7177286646258567,
      "attention_bam_16_attention_skewness": 0.8395145299271946,
      "attention_bam_16_attention_sparsity": 0.509033203125,
      "attention_bam_16_attention_concentration_10": 0.7745774630286105,
      "attention_bam_16_attention_concentration_20": 1.2224947675802393,
      "attention_bam_16_attention_center_y": 0.4751030732250358,
      "attention_bam_16_attention_center_x": 0.48503644344497304,
      "attention_bam_16_attention_center_distance": 0.04107955665810961,
      "attention_bam_16_attention_spatial_variance": 43.04786613285864,
      "attention_bam_16_attention_spatial_std": 6.561087267584439,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 9.7152308953669,
      "attention_bam_16_peak_intensity_mean": 0.35729965567588806,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 272,
      "phase": "train",
      "loss": 0.005390016362071037,
      "timestamp": 1759543924.4213018,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005390016362071037,
      "ssim": 0.8887228965759277,
      "attention_bam_384_mean_attention": 0.11345567554235458,
      "attention_bam_384_std_attention": 0.4557287096977234,
      "attention_bam_384_max_attention": 2.952072858810425,
      "attention_bam_384_min_attention": -1.2373062372207642,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.0879957625672132,
      "attention_bam_384_attention_skewness": 0.5203159744426044,
      "attention_bam_384_attention_sparsity": 0.5249303181966146,
      "attention_bam_384_attention_concentration_10": 0.8774478754679614,
      "attention_bam_384_attention_concentration_20": 1.4047372422051938,
      "attention_bam_384_attention_center_y": 0.48187098101741693,
      "attention_bam_384_attention_center_x": 0.48904228331919275,
      "attention_bam_384_attention_center_distance": 0.029957733029309763,
      "attention_bam_384_attention_spatial_variance": 169.47677177971067,
      "attention_bam_384_attention_spatial_std": 13.018324461301104,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 16.729025776296798,
      "attention_bam_384_peak_intensity_mean": 0.32403409481048584,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18124771118164062,
      "attention_bam_16_std_attention": 0.616668164730072,
      "attention_bam_16_max_attention": 2.5878407955169678,
      "attention_bam_16_min_attention": -1.1688477993011475,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.1400382831979181,
      "attention_bam_16_attention_skewness": 0.5641563613903647,
      "attention_bam_16_attention_sparsity": 0.491455078125,
      "attention_bam_16_attention_concentration_10": 0.7568896440082838,
      "attention_bam_16_attention_concentration_20": 1.2362938827101797,
      "attention_bam_16_attention_center_y": 0.4660503743373963,
      "attention_bam_16_attention_center_x": 0.4824062263760873,
      "attention_bam_16_attention_center_distance": 0.054076204618305146,
      "attention_bam_16_attention_spatial_variance": 41.74412608284206,
      "attention_bam_16_attention_spatial_std": 6.460969438315125,
      "attention_bam_16_num_attention_peaks": 11,
      "attention_bam_16_peak_separation_mean": 7.267395940498079,
      "attention_bam_16_peak_intensity_mean": 0.3647085130214691,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 273,
      "phase": "train",
      "loss": 0.0069220419973134995,
      "timestamp": 1759543924.5958238,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0069220419973134995,
      "ssim": 0.8528751134872437,
      "attention_bam_384_mean_attention": 0.11140316724777222,
      "attention_bam_384_std_attention": 0.45352861285209656,
      "attention_bam_384_max_attention": 3.8567123413085938,
      "attention_bam_384_min_attention": -1.2835967540740967,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.138730521576539,
      "attention_bam_384_attention_skewness": 0.8599422601738312,
      "attention_bam_384_attention_sparsity": 0.5257492065429688,
      "attention_bam_384_attention_concentration_10": 0.9062603607385344,
      "attention_bam_384_attention_concentration_20": 1.3991130003804475,
      "attention_bam_384_attention_center_y": 0.48084963005877035,
      "attention_bam_384_attention_center_x": 0.4832674463111106,
      "attention_bam_384_attention_center_distance": 0.03596428844944711,
      "attention_bam_384_attention_spatial_variance": 169.35223847410555,
      "attention_bam_384_attention_spatial_std": 13.01354058179808,
      "attention_bam_384_num_attention_peaks": 20,
      "attention_bam_384_peak_separation_mean": 18.01345906341177,
      "attention_bam_384_peak_intensity_mean": 0.27242138981819153,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17896121740341187,
      "attention_bam_16_std_attention": 0.6309845447540283,
      "attention_bam_16_max_attention": 4.13220739364624,
      "attention_bam_16_min_attention": -1.0770151615142822,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.593902132846461,
      "attention_bam_16_attention_skewness": 1.0765560329171318,
      "attention_bam_16_attention_sparsity": 0.499267578125,
      "attention_bam_16_attention_concentration_10": 0.8175682629296045,
      "attention_bam_16_attention_concentration_20": 1.2670330537574226,
      "attention_bam_16_attention_center_y": 0.4593543282510865,
      "attention_bam_16_attention_center_x": 0.4683427646880382,
      "attention_bam_16_attention_center_distance": 0.07285946993380263,
      "attention_bam_16_attention_spatial_variance": 41.3970609432355,
      "attention_bam_16_attention_spatial_std": 6.434054782424183,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 7.397427702040403,
      "attention_bam_16_peak_intensity_mean": 0.24710315465927124,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 274,
      "phase": "train",
      "loss": 0.008767685852944851,
      "timestamp": 1759543924.7607338,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008767685852944851,
      "ssim": 0.8759475946426392,
      "attention_bam_384_mean_attention": 0.11098432540893555,
      "attention_bam_384_std_attention": 0.40888330340385437,
      "attention_bam_384_max_attention": 3.0823147296905518,
      "attention_bam_384_min_attention": -1.1768184900283813,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.38497003116298245,
      "attention_bam_384_attention_skewness": 0.546983967175112,
      "attention_bam_384_attention_sparsity": 0.5201746622721354,
      "attention_bam_384_attention_concentration_10": 0.8039700509698797,
      "attention_bam_384_attention_concentration_20": 1.2910722367104668,
      "attention_bam_384_attention_center_y": 0.4808009032819593,
      "attention_bam_384_attention_center_x": 0.4814183901221643,
      "attention_bam_384_attention_center_distance": 0.03778575235299047,
      "attention_bam_384_attention_spatial_variance": 169.84981765685413,
      "attention_bam_384_attention_spatial_std": 13.032644307923627,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 17.45658471197269,
      "attention_bam_384_peak_intensity_mean": 0.3045421242713928,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18401744961738586,
      "attention_bam_16_std_attention": 0.5700114965438843,
      "attention_bam_16_max_attention": 2.8671224117279053,
      "attention_bam_16_min_attention": -1.0311490297317505,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.2590801989135243,
      "attention_bam_16_attention_skewness": 0.620502144442281,
      "attention_bam_16_attention_sparsity": 0.483642578125,
      "attention_bam_16_attention_concentration_10": 0.7049945413383386,
      "attention_bam_16_attention_concentration_20": 1.135498228939324,
      "attention_bam_16_attention_center_y": 0.45584765696949064,
      "attention_bam_16_attention_center_x": 0.4620450119544014,
      "attention_bam_16_attention_center_distance": 0.08234088307305552,
      "attention_bam_16_attention_spatial_variance": 41.834530065553714,
      "attention_bam_16_attention_spatial_std": 6.467961816952363,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 10.112037936043182,
      "attention_bam_16_peak_intensity_mean": 0.31398332118988037,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 275,
      "phase": "train",
      "loss": 0.005753647070378065,
      "timestamp": 1759543924.9148479,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005753647070378065,
      "ssim": 0.8811764717102051,
      "attention_bam_384_mean_attention": 0.11186736077070236,
      "attention_bam_384_std_attention": 0.428305059671402,
      "attention_bam_384_max_attention": 3.3597428798675537,
      "attention_bam_384_min_attention": -1.3765047788619995,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9180245502751414,
      "attention_bam_384_attention_skewness": 0.6114339972537735,
      "attention_bam_384_attention_sparsity": 0.5216700236002604,
      "attention_bam_384_attention_concentration_10": 0.8488804262023513,
      "attention_bam_384_attention_concentration_20": 1.333943702908256,
      "attention_bam_384_attention_center_y": 0.48121763084853275,
      "attention_bam_384_attention_center_x": 0.48664760466505314,
      "attention_bam_384_attention_center_distance": 0.03259030076948353,
      "attention_bam_384_attention_spatial_variance": 171.93367652232297,
      "attention_bam_384_attention_spatial_std": 13.11234824592159,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 18.545876810115043,
      "attention_bam_384_peak_intensity_mean": 0.3176390528678894,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18495222926139832,
      "attention_bam_16_std_attention": 0.5891148447990417,
      "attention_bam_16_max_attention": 2.9847495555877686,
      "attention_bam_16_min_attention": -1.1639724969863892,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.4798839941042363,
      "attention_bam_16_attention_skewness": 0.6549473715943667,
      "attention_bam_16_attention_sparsity": 0.485595703125,
      "attention_bam_16_attention_concentration_10": 0.7296113562866561,
      "attention_bam_16_attention_concentration_20": 1.1589897271295602,
      "attention_bam_16_attention_center_y": 0.45681256980744384,
      "attention_bam_16_attention_center_x": 0.4722631956281694,
      "attention_bam_16_attention_center_distance": 0.07258766346147413,
      "attention_bam_16_attention_spatial_variance": 43.21298360888489,
      "attention_bam_16_attention_spatial_std": 6.573658312453188,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.548300083761943,
      "attention_bam_16_peak_intensity_mean": 0.33034273982048035,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 276,
      "phase": "train",
      "loss": 0.006321682594716549,
      "timestamp": 1759543925.0552924,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006321682594716549,
      "ssim": 0.8695756196975708,
      "attention_bam_384_mean_attention": 0.10784256458282471,
      "attention_bam_384_std_attention": 0.3974257707595825,
      "attention_bam_384_max_attention": 2.766134023666382,
      "attention_bam_384_min_attention": -1.214680552482605,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.3652493493013793,
      "attention_bam_384_attention_skewness": 0.8210210526208309,
      "attention_bam_384_attention_sparsity": 0.5363667805989584,
      "attention_bam_384_attention_concentration_10": 0.8421918335175526,
      "attention_bam_384_attention_concentration_20": 1.3029860199919772,
      "attention_bam_384_attention_center_y": 0.4941248693917663,
      "attention_bam_384_attention_center_x": 0.4865659368930267,
      "attention_bam_384_attention_center_distance": 0.020736017516675948,
      "attention_bam_384_attention_spatial_variance": 171.11916208014682,
      "attention_bam_384_attention_spatial_std": 13.081252313144443,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 19.246407449967116,
      "attention_bam_384_peak_intensity_mean": 0.3344988524913788,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1787288784980774,
      "attention_bam_16_std_attention": 0.5782532691955566,
      "attention_bam_16_max_attention": 2.9020867347717285,
      "attention_bam_16_min_attention": -0.9856900572776794,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.2120430954381973,
      "attention_bam_16_attention_skewness": 0.9553807164134028,
      "attention_bam_16_attention_sparsity": 0.503173828125,
      "attention_bam_16_attention_concentration_10": 0.77328816072456,
      "attention_bam_16_attention_concentration_20": 1.1940810678783176,
      "attention_bam_16_attention_center_y": 0.493273563604582,
      "attention_bam_16_attention_center_x": 0.4759211474079475,
      "attention_bam_16_attention_center_distance": 0.035356359788060676,
      "attention_bam_16_attention_spatial_variance": 42.77221217705556,
      "attention_bam_16_attention_spatial_std": 6.540046802359717,
      "attention_bam_16_num_attention_peaks": 2,
      "attention_bam_16_peak_separation_mean": 9.946655237476724,
      "attention_bam_16_peak_intensity_mean": 0.29758769273757935,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 277,
      "phase": "train",
      "loss": 0.007199970539659262,
      "timestamp": 1759543925.1876006,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007199970539659262,
      "ssim": 0.8652420043945312,
      "attention_bam_384_mean_attention": 0.10891321301460266,
      "attention_bam_384_std_attention": 0.38016340136528015,
      "attention_bam_384_max_attention": 3.7052249908447266,
      "attention_bam_384_min_attention": -1.1311874389648438,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.3963635245100168,
      "attention_bam_384_attention_skewness": 0.7271017062740271,
      "attention_bam_384_attention_sparsity": 0.5264383951822916,
      "attention_bam_384_attention_concentration_10": 0.7838128900247113,
      "attention_bam_384_attention_concentration_20": 1.2351068717347489,
      "attention_bam_384_attention_center_y": 0.4811442764926955,
      "attention_bam_384_attention_center_x": 0.47550940850412265,
      "attention_bam_384_attention_center_distance": 0.043711037068499214,
      "attention_bam_384_attention_spatial_variance": 170.5842634047215,
      "attention_bam_384_attention_spatial_std": 13.060791071168756,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 17.405410205191462,
      "attention_bam_384_peak_intensity_mean": 0.2571030855178833,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18326427042484283,
      "attention_bam_16_std_attention": 0.5479277968406677,
      "attention_bam_16_max_attention": 3.252774238586426,
      "attention_bam_16_min_attention": -1.1528433561325073,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.2388925516071456,
      "attention_bam_16_attention_skewness": 0.8195625973779364,
      "attention_bam_16_attention_sparsity": 0.48583984375,
      "attention_bam_16_attention_concentration_10": 0.6957389737664861,
      "attention_bam_16_attention_concentration_20": 1.1011969843389875,
      "attention_bam_16_attention_center_y": 0.4589681368799967,
      "attention_bam_16_attention_center_x": 0.4493199756536857,
      "attention_bam_16_attention_center_distance": 0.09221798803749402,
      "attention_bam_16_attention_spatial_variance": 42.32146945839269,
      "attention_bam_16_attention_spatial_std": 6.505495327674342,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 7.888793698581982,
      "attention_bam_16_peak_intensity_mean": 0.3122337758541107,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 278,
      "phase": "train",
      "loss": 0.0042844247072935104,
      "timestamp": 1759543925.3208084,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0042844247072935104,
      "ssim": 0.9108481407165527,
      "attention_bam_384_mean_attention": 0.10785537213087082,
      "attention_bam_384_std_attention": 0.45620784163475037,
      "attention_bam_384_max_attention": 2.93451189994812,
      "attention_bam_384_min_attention": -1.2106592655181885,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9117449343852342,
      "attention_bam_384_attention_skewness": 0.8052225927920852,
      "attention_bam_384_attention_sparsity": 0.5418268839518229,
      "attention_bam_384_attention_concentration_10": 0.9678837130838736,
      "attention_bam_384_attention_concentration_20": 1.4902395000050368,
      "attention_bam_384_attention_center_y": 0.4813160057592265,
      "attention_bam_384_attention_center_x": 0.48682082134207183,
      "attention_bam_384_attention_center_distance": 0.032335194166321204,
      "attention_bam_384_attention_spatial_variance": 168.66713772336024,
      "attention_bam_384_attention_spatial_std": 12.98719129463181,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 17.772457197182327,
      "attention_bam_384_peak_intensity_mean": 0.3206435739994049,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17273667454719543,
      "attention_bam_16_std_attention": 0.6336904168128967,
      "attention_bam_16_max_attention": 3.157243251800537,
      "attention_bam_16_min_attention": -1.005469799041748,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6619003147757558,
      "attention_bam_16_attention_skewness": 0.8953195937220382,
      "attention_bam_16_attention_sparsity": 0.526123046875,
      "attention_bam_16_attention_concentration_10": 0.858808305116793,
      "attention_bam_16_attention_concentration_20": 1.356795910873028,
      "attention_bam_16_attention_center_y": 0.4606894941134732,
      "attention_bam_16_attention_center_x": 0.47810188795875724,
      "attention_bam_16_attention_center_distance": 0.06363714613377125,
      "attention_bam_16_attention_spatial_variance": 40.95453558335516,
      "attention_bam_16_attention_spatial_std": 6.399573078210386,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 7.964015337815233,
      "attention_bam_16_peak_intensity_mean": 0.29462531208992004,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 279,
      "phase": "train",
      "loss": 0.007103726267814636,
      "timestamp": 1759543925.4566958,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007103726267814636,
      "ssim": 0.8385519981384277,
      "attention_bam_384_mean_attention": 0.10551980137825012,
      "attention_bam_384_std_attention": 0.4078785479068756,
      "attention_bam_384_max_attention": 3.5503435134887695,
      "attention_bam_384_min_attention": -1.1814186573028564,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.6905950343323308,
      "attention_bam_384_attention_skewness": 0.877144494043817,
      "attention_bam_384_attention_sparsity": 0.5399729410807291,
      "attention_bam_384_attention_concentration_10": 0.8838073461128578,
      "attention_bam_384_attention_concentration_20": 1.359931974959875,
      "attention_bam_384_attention_center_y": 0.48084462190462623,
      "attention_bam_384_attention_center_x": 0.4814240004305398,
      "attention_bam_384_attention_center_distance": 0.03773582568279939,
      "attention_bam_384_attention_spatial_variance": 170.0680291588515,
      "attention_bam_384_attention_spatial_std": 13.041013348618714,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 18.03382516921364,
      "attention_bam_384_peak_intensity_mean": 0.2732861042022705,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17281505465507507,
      "attention_bam_16_std_attention": 0.5841394662857056,
      "attention_bam_16_max_attention": 3.254678249359131,
      "attention_bam_16_min_attention": -1.0404597520828247,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.8393713471540947,
      "attention_bam_16_attention_skewness": 1.0993219199295552,
      "attention_bam_16_attention_sparsity": 0.5234375,
      "attention_bam_16_attention_concentration_10": 0.8124134829160217,
      "attention_bam_16_attention_concentration_20": 1.2454379085106972,
      "attention_bam_16_attention_center_y": 0.46046121930516876,
      "attention_bam_16_attention_center_x": 0.4630652467378899,
      "attention_bam_16_attention_center_distance": 0.07651785644366826,
      "attention_bam_16_attention_spatial_variance": 42.10603489066761,
      "attention_bam_16_attention_spatial_std": 6.488916310961916,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.776534552242486,
      "attention_bam_16_peak_intensity_mean": 0.2942447066307068,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 280,
      "phase": "train",
      "loss": 0.00601707911118865,
      "timestamp": 1759543925.6317255,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00601707911118865,
      "ssim": 0.8738605976104736,
      "attention_bam_384_mean_attention": 0.11050865054130554,
      "attention_bam_384_std_attention": 0.4746311902999878,
      "attention_bam_384_max_attention": 5.266130447387695,
      "attention_bam_384_min_attention": -1.4268678426742554,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 4.430793124868322,
      "attention_bam_384_attention_skewness": 1.2354721202136565,
      "attention_bam_384_attention_sparsity": 0.5380783081054688,
      "attention_bam_384_attention_concentration_10": 0.9669656104523373,
      "attention_bam_384_attention_concentration_20": 1.4666296301786468,
      "attention_bam_384_attention_center_y": 0.4888522598014122,
      "attention_bam_384_attention_center_x": 0.49190843430472325,
      "attention_bam_384_attention_center_distance": 0.019480531149647293,
      "attention_bam_384_attention_spatial_variance": 173.24015702523033,
      "attention_bam_384_attention_spatial_std": 13.162072672084376,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 19.463390655496383,
      "attention_bam_384_peak_intensity_mean": 0.23255090415477753,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1801508665084839,
      "attention_bam_16_std_attention": 0.6688416600227356,
      "attention_bam_16_max_attention": 4.9141106605529785,
      "attention_bam_16_min_attention": -1.2207331657409668,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 4.541082358527253,
      "attention_bam_16_attention_skewness": 1.511450745692195,
      "attention_bam_16_attention_sparsity": 0.530517578125,
      "attention_bam_16_attention_concentration_10": 0.8801328732059799,
      "attention_bam_16_attention_concentration_20": 1.3392766747104625,
      "attention_bam_16_attention_center_y": 0.4812449233332817,
      "attention_bam_16_attention_center_x": 0.4887422104107744,
      "attention_bam_16_attention_center_distance": 0.030935116848324846,
      "attention_bam_16_attention_spatial_variance": 44.16226719003998,
      "attention_bam_16_attention_spatial_std": 6.645469674149449,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.05644549347911,
      "attention_bam_16_peak_intensity_mean": 0.23759222030639648,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 281,
      "phase": "train",
      "loss": 0.00874341931194067,
      "timestamp": 1759543925.7786102,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00874341931194067,
      "ssim": 0.8746334314346313,
      "attention_bam_384_mean_attention": 0.1088419035077095,
      "attention_bam_384_std_attention": 0.3828994333744049,
      "attention_bam_384_max_attention": 2.7591774463653564,
      "attention_bam_384_min_attention": -1.162682056427002,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6305410597330283,
      "attention_bam_384_attention_skewness": 0.5630726209257833,
      "attention_bam_384_attention_sparsity": 0.5247268676757812,
      "attention_bam_384_attention_concentration_10": 0.7877817364028358,
      "attention_bam_384_attention_concentration_20": 1.2467831314796631,
      "attention_bam_384_attention_center_y": 0.49138691189073264,
      "attention_bam_384_attention_center_x": 0.48424454019436786,
      "attention_bam_384_attention_center_distance": 0.025393692148440835,
      "attention_bam_384_attention_spatial_variance": 170.53947581224094,
      "attention_bam_384_attention_spatial_std": 13.059076376690694,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 15.373956375823886,
      "attention_bam_384_peak_intensity_mean": 0.32831308245658875,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17721474170684814,
      "attention_bam_16_std_attention": 0.5504648089408875,
      "attention_bam_16_max_attention": 2.6763861179351807,
      "attention_bam_16_min_attention": -1.0326368808746338,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.11390150858227033,
      "attention_bam_16_attention_skewness": 0.6355776870056123,
      "attention_bam_16_attention_sparsity": 0.502197265625,
      "attention_bam_16_attention_concentration_10": 0.7149622288569827,
      "attention_bam_16_attention_concentration_20": 1.1483918679231129,
      "attention_bam_16_attention_center_y": 0.4926957572719144,
      "attention_bam_16_attention_center_x": 0.47088820217696703,
      "attention_bam_16_attention_center_distance": 0.04244640701684746,
      "attention_bam_16_attention_spatial_variance": 42.86561016692998,
      "attention_bam_16_attention_spatial_std": 6.547183376607836,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 7.734654173231434,
      "attention_bam_16_peak_intensity_mean": 0.3330569565296173,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 282,
      "phase": "train",
      "loss": 0.005838240496814251,
      "timestamp": 1759543925.9191248,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005838240496814251,
      "ssim": 0.8795467019081116,
      "attention_bam_384_mean_attention": 0.10930278152227402,
      "attention_bam_384_std_attention": 0.41669920086860657,
      "attention_bam_384_max_attention": 2.8851168155670166,
      "attention_bam_384_min_attention": -1.173710584640503,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6679265789791184,
      "attention_bam_384_attention_skewness": 0.6201991828201177,
      "attention_bam_384_attention_sparsity": 0.5296478271484375,
      "attention_bam_384_attention_concentration_10": 0.854079397039349,
      "attention_bam_384_attention_concentration_20": 1.3425153174949602,
      "attention_bam_384_attention_center_y": 0.48236549645397087,
      "attention_bam_384_attention_center_x": 0.48394544872434764,
      "attention_bam_384_attention_center_distance": 0.03372608284332662,
      "attention_bam_384_attention_spatial_variance": 170.8788712765158,
      "attention_bam_384_attention_spatial_std": 13.072064537651114,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 19.051491346717313,
      "attention_bam_384_peak_intensity_mean": 0.3232164680957794,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19105303287506104,
      "attention_bam_16_std_attention": 0.5839591026306152,
      "attention_bam_16_max_attention": 2.6145684719085693,
      "attention_bam_16_min_attention": -1.0837881565093994,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.19810166974072496,
      "attention_bam_16_attention_skewness": 0.6583220258429175,
      "attention_bam_16_attention_sparsity": 0.48974609375,
      "attention_bam_16_attention_concentration_10": 0.7078157592026201,
      "attention_bam_16_attention_concentration_20": 1.1357862259622786,
      "attention_bam_16_attention_center_y": 0.46478964709212045,
      "attention_bam_16_attention_center_x": 0.47134275179587876,
      "attention_bam_16_attention_center_distance": 0.06420291000461009,
      "attention_bam_16_attention_spatial_variance": 42.71278447163609,
      "attention_bam_16_attention_spatial_std": 6.5355018530818345,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.65724090321784,
      "attention_bam_16_peak_intensity_mean": 0.36229902505874634,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 283,
      "phase": "train",
      "loss": 0.005617022514343262,
      "timestamp": 1759543926.0610194,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005617022514343262,
      "ssim": 0.9029982089996338,
      "attention_bam_384_mean_attention": 0.10860749334096909,
      "attention_bam_384_std_attention": 0.3931719660758972,
      "attention_bam_384_max_attention": 2.905618667602539,
      "attention_bam_384_min_attention": -1.1565375328063965,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8926471000814957,
      "attention_bam_384_attention_skewness": 0.6908624529518469,
      "attention_bam_384_attention_sparsity": 0.5308278401692709,
      "attention_bam_384_attention_concentration_10": 0.8100907106218401,
      "attention_bam_384_attention_concentration_20": 1.2831044560634228,
      "attention_bam_384_attention_center_y": 0.4850987454006492,
      "attention_bam_384_attention_center_x": 0.48534491067975893,
      "attention_bam_384_attention_center_distance": 0.02955736901751973,
      "attention_bam_384_attention_spatial_variance": 172.54394311984203,
      "attention_bam_384_attention_spatial_std": 13.135598316020554,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 19.240455468404253,
      "attention_bam_384_peak_intensity_mean": 0.31264936923980713,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1822628676891327,
      "attention_bam_16_std_attention": 0.5621171593666077,
      "attention_bam_16_max_attention": 2.9108948707580566,
      "attention_bam_16_min_attention": -0.984377384185791,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7297026956683652,
      "attention_bam_16_attention_skewness": 0.7665803251234051,
      "attention_bam_16_attention_sparsity": 0.49560546875,
      "attention_bam_16_attention_concentration_10": 0.712281303586908,
      "attention_bam_16_attention_concentration_20": 1.1385612863207806,
      "attention_bam_16_attention_center_y": 0.4713429855019758,
      "attention_bam_16_attention_center_x": 0.47477758426887084,
      "attention_bam_16_attention_center_distance": 0.05398879023008168,
      "attention_bam_16_attention_spatial_variance": 44.10948392126817,
      "attention_bam_16_attention_spatial_std": 6.641497114451543,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.4775226356551,
      "attention_bam_16_peak_intensity_mean": 0.30379894375801086,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 284,
      "phase": "train",
      "loss": 0.006003931164741516,
      "timestamp": 1759543926.1998408,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006003931164741516,
      "ssim": 0.9010028839111328,
      "attention_bam_384_mean_attention": 0.11045976728200912,
      "attention_bam_384_std_attention": 0.4095330834388733,
      "attention_bam_384_max_attention": 3.2148263454437256,
      "attention_bam_384_min_attention": -1.1917979717254639,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9110861772026899,
      "attention_bam_384_attention_skewness": 0.5946651771332033,
      "attention_bam_384_attention_sparsity": 0.5172780354817709,
      "attention_bam_384_attention_concentration_10": 0.8037445711235353,
      "attention_bam_384_attention_concentration_20": 1.284683023413886,
      "attention_bam_384_attention_center_y": 0.4796642760898941,
      "attention_bam_384_attention_center_x": 0.4791953057822558,
      "attention_bam_384_attention_center_distance": 0.04114309099817108,
      "attention_bam_384_attention_spatial_variance": 169.5946857576649,
      "attention_bam_384_attention_spatial_std": 13.022852443211699,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 16.63343564797573,
      "attention_bam_384_peak_intensity_mean": 0.2976626455783844,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19697806239128113,
      "attention_bam_16_std_attention": 0.572781503200531,
      "attention_bam_16_max_attention": 3.3076558113098145,
      "attention_bam_16_min_attention": -1.124763011932373,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.1467512279378864,
      "attention_bam_16_attention_skewness": 0.738855804633251,
      "attention_bam_16_attention_sparsity": 0.47216796875,
      "attention_bam_16_attention_concentration_10": 0.6608948621800541,
      "attention_bam_16_attention_concentration_20": 1.061442665658174,
      "attention_bam_16_attention_center_y": 0.4585423599239125,
      "attention_bam_16_attention_center_x": 0.45471265404600925,
      "attention_bam_16_attention_center_distance": 0.08682948375102616,
      "attention_bam_16_attention_spatial_variance": 41.57503769456052,
      "attention_bam_16_attention_spatial_std": 6.447870787675613,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 10.410958111950247,
      "attention_bam_16_peak_intensity_mean": 0.2955406904220581,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 285,
      "phase": "train",
      "loss": 0.007609107997268438,
      "timestamp": 1759543926.3387573,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007609107997268438,
      "ssim": 0.8807494640350342,
      "attention_bam_384_mean_attention": 0.11326507478952408,
      "attention_bam_384_std_attention": 0.3938257098197937,
      "attention_bam_384_max_attention": 2.8619794845581055,
      "attention_bam_384_min_attention": -1.1355836391448975,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0428368578410776,
      "attention_bam_384_attention_skewness": 0.6022273007550639,
      "attention_bam_384_attention_sparsity": 0.5174153645833334,
      "attention_bam_384_attention_concentration_10": 0.770049491143028,
      "attention_bam_384_attention_concentration_20": 1.2231927944372956,
      "attention_bam_384_attention_center_y": 0.4896119063067648,
      "attention_bam_384_attention_center_x": 0.4908495003170004,
      "attention_bam_384_attention_center_distance": 0.01957774936135448,
      "attention_bam_384_attention_spatial_variance": 170.33257493071793,
      "attention_bam_384_attention_spatial_std": 13.051152245327534,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 14.331184434452695,
      "attention_bam_384_peak_intensity_mean": 0.31748008728027344,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20664577186107635,
      "attention_bam_16_std_attention": 0.5631198883056641,
      "attention_bam_16_max_attention": 3.0889811515808105,
      "attention_bam_16_min_attention": -1.1254650354385376,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8748254587210775,
      "attention_bam_16_attention_skewness": 0.7173128307776556,
      "attention_bam_16_attention_sparsity": 0.4716796875,
      "attention_bam_16_attention_concentration_10": 0.633800635322089,
      "attention_bam_16_attention_concentration_20": 1.0223291961243137,
      "attention_bam_16_attention_center_y": 0.48278704936918904,
      "attention_bam_16_attention_center_x": 0.4914080649343234,
      "attention_bam_16_attention_center_distance": 0.02720687477795048,
      "attention_bam_16_attention_spatial_variance": 42.30621057933823,
      "attention_bam_16_attention_spatial_std": 6.504322453517986,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.479051443288471,
      "attention_bam_16_peak_intensity_mean": 0.32514938712120056,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 286,
      "phase": "train",
      "loss": 0.007826116867363453,
      "timestamp": 1759543926.476667,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007826116867363453,
      "ssim": 0.8843297958374023,
      "attention_bam_384_mean_attention": 0.10761425644159317,
      "attention_bam_384_std_attention": 0.45888975262641907,
      "attention_bam_384_max_attention": 3.1226367950439453,
      "attention_bam_384_min_attention": -1.264972448348999,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9682315679042159,
      "attention_bam_384_attention_skewness": 0.7225645876936913,
      "attention_bam_384_attention_sparsity": 0.5314127604166666,
      "attention_bam_384_attention_concentration_10": 0.9454185739131283,
      "attention_bam_384_attention_concentration_20": 1.473541573623328,
      "attention_bam_384_attention_center_y": 0.4841283246883489,
      "attention_bam_384_attention_center_x": 0.48705454435796874,
      "attention_bam_384_attention_center_distance": 0.028965320608557905,
      "attention_bam_384_attention_spatial_variance": 169.5550896878302,
      "attention_bam_384_attention_spatial_std": 13.021332101126605,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 15.992493663396635,
      "attention_bam_384_peak_intensity_mean": 0.31523221731185913,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16724538803100586,
      "attention_bam_16_std_attention": 0.6348360180854797,
      "attention_bam_16_max_attention": 3.699218511581421,
      "attention_bam_16_min_attention": -1.0891046524047852,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.1640617017844095,
      "attention_bam_16_attention_skewness": 0.9202128655751506,
      "attention_bam_16_attention_sparsity": 0.516845703125,
      "attention_bam_16_attention_concentration_10": 0.8721282064313769,
      "attention_bam_16_attention_concentration_20": 1.3710117245101925,
      "attention_bam_16_attention_center_y": 0.4680041847820603,
      "attention_bam_16_attention_center_x": 0.48180123267401015,
      "attention_bam_16_attention_center_distance": 0.05205626424641049,
      "attention_bam_16_attention_spatial_variance": 41.852662065839155,
      "attention_bam_16_attention_spatial_std": 6.4693633431613,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 8.497157518955275,
      "attention_bam_16_peak_intensity_mean": 0.2659158706665039,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 287,
      "phase": "train",
      "loss": 0.00612480565905571,
      "timestamp": 1759543926.6137402,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00612480565905571,
      "ssim": 0.8591628670692444,
      "attention_bam_384_mean_attention": 0.10419365018606186,
      "attention_bam_384_std_attention": 0.4071333408355713,
      "attention_bam_384_max_attention": 3.1938793659210205,
      "attention_bam_384_min_attention": -1.1788781881332397,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8730565982054523,
      "attention_bam_384_attention_skewness": 0.9025116262478992,
      "attention_bam_384_attention_sparsity": 0.5404027303059896,
      "attention_bam_384_attention_concentration_10": 0.8972533283193577,
      "attention_bam_384_attention_concentration_20": 1.3681077212739485,
      "attention_bam_384_attention_center_y": 0.4882753905387234,
      "attention_bam_384_attention_center_x": 0.48429316196779015,
      "attention_bam_384_attention_center_distance": 0.02771899089034559,
      "attention_bam_384_attention_spatial_variance": 172.1741568959402,
      "attention_bam_384_attention_spatial_std": 13.121515038132609,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 20.36295208584023,
      "attention_bam_384_peak_intensity_mean": 0.29491549730300903,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17137272655963898,
      "attention_bam_16_std_attention": 0.5992825031280518,
      "attention_bam_16_max_attention": 4.1681318283081055,
      "attention_bam_16_min_attention": -1.1297988891601562,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.886883571839955,
      "attention_bam_16_attention_skewness": 1.117602521244606,
      "attention_bam_16_attention_sparsity": 0.525390625,
      "attention_bam_16_attention_concentration_10": 0.8442301720942117,
      "attention_bam_16_attention_concentration_20": 1.2847972923732691,
      "attention_bam_16_attention_center_y": 0.47878659959914593,
      "attention_bam_16_attention_center_x": 0.46686892601876606,
      "attention_bam_16_attention_center_distance": 0.05563589524249523,
      "attention_bam_16_attention_spatial_variance": 43.52782976856049,
      "attention_bam_16_attention_spatial_std": 6.597562411115221,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.65560249943842,
      "attention_bam_16_peak_intensity_mean": 0.25061169266700745,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 288,
      "phase": "train",
      "loss": 0.010889618657529354,
      "timestamp": 1759543926.7516623,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.010889618657529354,
      "ssim": 0.8610310554504395,
      "attention_bam_384_mean_attention": 0.10566201061010361,
      "attention_bam_384_std_attention": 0.4266342520713806,
      "attention_bam_384_max_attention": 2.794137716293335,
      "attention_bam_384_min_attention": -1.153125286102295,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.47984995265808195,
      "attention_bam_384_attention_skewness": 0.6125327144669791,
      "attention_bam_384_attention_sparsity": 0.5294901529947916,
      "attention_bam_384_attention_concentration_10": 0.8987061837184239,
      "attention_bam_384_attention_concentration_20": 1.4100672922857087,
      "attention_bam_384_attention_center_y": 0.47756534837787634,
      "attention_bam_384_attention_center_x": 0.4818016401703582,
      "attention_bam_384_attention_center_distance": 0.04085324696753431,
      "attention_bam_384_attention_spatial_variance": 173.9482957300791,
      "attention_bam_384_attention_spatial_std": 13.188945967365212,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 19.864307366515476,
      "attention_bam_384_peak_intensity_mean": 0.32433879375457764,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17215004563331604,
      "attention_bam_16_std_attention": 0.6175438761711121,
      "attention_bam_16_max_attention": 3.0980305671691895,
      "attention_bam_16_min_attention": -1.1565607786178589,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6624999036965664,
      "attention_bam_16_attention_skewness": 0.7809930698636441,
      "attention_bam_16_attention_sparsity": 0.50439453125,
      "attention_bam_16_attention_concentration_10": 0.8203433732018068,
      "attention_bam_16_attention_concentration_20": 1.3008160623124478,
      "attention_bam_16_attention_center_y": 0.45102976453353044,
      "attention_bam_16_attention_center_x": 0.4639031774154452,
      "attention_bam_16_attention_center_distance": 0.08603562706626017,
      "attention_bam_16_attention_spatial_variance": 44.69561597019877,
      "attention_bam_16_attention_spatial_std": 6.6854779911535696,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 10.354138306730315,
      "attention_bam_16_peak_intensity_mean": 0.3195241689682007,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 289,
      "phase": "train",
      "loss": 0.006016659550368786,
      "timestamp": 1759543926.892614,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006016659550368786,
      "ssim": 0.9082765579223633,
      "attention_bam_384_mean_attention": 0.10563904047012329,
      "attention_bam_384_std_attention": 0.4387456178665161,
      "attention_bam_384_max_attention": 3.8911473751068115,
      "attention_bam_384_min_attention": -1.3163821697235107,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8950619875336363,
      "attention_bam_384_attention_skewness": 0.7912709273010198,
      "attention_bam_384_attention_sparsity": 0.5279973347981771,
      "attention_bam_384_attention_concentration_10": 0.910298351302878,
      "attention_bam_384_attention_concentration_20": 1.4186308900131193,
      "attention_bam_384_attention_center_y": 0.47992574589846765,
      "attention_bam_384_attention_center_x": 0.48027036687367,
      "attention_bam_384_attention_center_distance": 0.03980537905943033,
      "attention_bam_384_attention_spatial_variance": 171.05287662905974,
      "attention_bam_384_attention_spatial_std": 13.07871846279519,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 17.106996047763342,
      "attention_bam_384_peak_intensity_mean": 0.2725161015987396,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18136492371559143,
      "attention_bam_16_std_attention": 0.6358020305633545,
      "attention_bam_16_max_attention": 3.9344446659088135,
      "attention_bam_16_min_attention": -1.0967316627502441,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.7796572927123364,
      "attention_bam_16_attention_skewness": 0.9798821188787956,
      "attention_bam_16_attention_sparsity": 0.5068359375,
      "attention_bam_16_attention_concentration_10": 0.8099604689455526,
      "attention_bam_16_attention_concentration_20": 1.2705590757810477,
      "attention_bam_16_attention_center_y": 0.4534121994849361,
      "attention_bam_16_attention_center_x": 0.459630302366316,
      "attention_bam_16_attention_center_distance": 0.087179534798787,
      "attention_bam_16_attention_spatial_variance": 42.8752469046986,
      "attention_bam_16_attention_spatial_std": 6.547919280557649,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.010100232928437,
      "attention_bam_16_peak_intensity_mean": 0.2575945556163788,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 290,
      "phase": "train",
      "loss": 0.007052220404148102,
      "timestamp": 1759543927.0715816,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007052220404148102,
      "ssim": 0.8764683604240417,
      "attention_bam_384_mean_attention": 0.10720426589250565,
      "attention_bam_384_std_attention": 0.4140971004962921,
      "attention_bam_384_max_attention": 2.741729259490967,
      "attention_bam_384_min_attention": -1.2117165327072144,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8017471755195658,
      "attention_bam_384_attention_skewness": 0.6499005891120516,
      "attention_bam_384_attention_sparsity": 0.5306065877278646,
      "attention_bam_384_attention_concentration_10": 0.8656219898279331,
      "attention_bam_384_attention_concentration_20": 1.3543689567792287,
      "attention_bam_384_attention_center_y": 0.48433176992093996,
      "attention_bam_384_attention_center_x": 0.483544065337652,
      "attention_bam_384_attention_center_distance": 0.03213382079435399,
      "attention_bam_384_attention_spatial_variance": 170.1512186756267,
      "attention_bam_384_attention_spatial_std": 13.044202492894179,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 17.170353558391042,
      "attention_bam_384_peak_intensity_mean": 0.3394221067428589,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1930904984474182,
      "attention_bam_16_std_attention": 0.5948426127433777,
      "attention_bam_16_max_attention": 3.0393893718719482,
      "attention_bam_16_min_attention": -1.0636056661605835,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6864749679068183,
      "attention_bam_16_attention_skewness": 0.7856024313494433,
      "attention_bam_16_attention_sparsity": 0.4921875,
      "attention_bam_16_attention_concentration_10": 0.7239530936735236,
      "attention_bam_16_attention_concentration_20": 1.1483507901177252,
      "attention_bam_16_attention_center_y": 0.4690870395846885,
      "attention_bam_16_attention_center_x": 0.4688037950100204,
      "attention_bam_16_attention_center_distance": 0.062109811260628436,
      "attention_bam_16_attention_spatial_variance": 42.0043072939947,
      "attention_bam_16_attention_spatial_std": 6.481073004834516,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.261940208527806,
      "attention_bam_16_peak_intensity_mean": 0.3229106664657593,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 291,
      "phase": "train",
      "loss": 0.006305900868028402,
      "timestamp": 1759543927.2089617,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006305900868028402,
      "ssim": 0.8812080025672913,
      "attention_bam_384_mean_attention": 0.10858607292175293,
      "attention_bam_384_std_attention": 0.36082929372787476,
      "attention_bam_384_max_attention": 2.9504318237304688,
      "attention_bam_384_min_attention": -1.0993579626083374,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.38515721798164204,
      "attention_bam_384_attention_skewness": 0.40379595293916215,
      "attention_bam_384_attention_sparsity": 0.5129648844401041,
      "attention_bam_384_attention_concentration_10": 0.7359643065467867,
      "attention_bam_384_attention_concentration_20": 1.1744298957276207,
      "attention_bam_384_attention_center_y": 0.48256236582210443,
      "attention_bam_384_attention_center_x": 0.48465529121444323,
      "attention_bam_384_attention_center_distance": 0.032849084414505514,
      "attention_bam_384_attention_spatial_variance": 170.32210021183727,
      "attention_bam_384_attention_spatial_std": 13.050750944364744,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 17.209827644395503,
      "attention_bam_384_peak_intensity_mean": 0.29973068833351135,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20122724771499634,
      "attention_bam_16_std_attention": 0.5170508027076721,
      "attention_bam_16_max_attention": 2.4253804683685303,
      "attention_bam_16_min_attention": -1.006740927696228,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.14402411028659756,
      "attention_bam_16_attention_skewness": 0.48025783074559186,
      "attention_bam_16_attention_sparsity": 0.44921875,
      "attention_bam_16_attention_concentration_10": 0.5929879832263817,
      "attention_bam_16_attention_concentration_20": 0.9604498830315521,
      "attention_bam_16_attention_center_y": 0.4669484355346107,
      "attention_bam_16_attention_center_x": 0.4719454077399388,
      "attention_bam_16_attention_center_distance": 0.06131013065535043,
      "attention_bam_16_attention_spatial_variance": 42.17562532672028,
      "attention_bam_16_attention_spatial_std": 6.494276351274273,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.37279012966381,
      "attention_bam_16_peak_intensity_mean": 0.3566947281360626,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 292,
      "phase": "train",
      "loss": 0.009067369624972343,
      "timestamp": 1759543927.3526886,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.009067369624972343,
      "ssim": 0.8756670951843262,
      "attention_bam_384_mean_attention": 0.1060701385140419,
      "attention_bam_384_std_attention": 0.40555083751678467,
      "attention_bam_384_max_attention": 3.7971346378326416,
      "attention_bam_384_min_attention": -1.3890721797943115,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2155279724327794,
      "attention_bam_384_attention_skewness": 0.7131400634309571,
      "attention_bam_384_attention_sparsity": 0.5338083902994791,
      "attention_bam_384_attention_concentration_10": 0.8571813096294131,
      "attention_bam_384_attention_concentration_20": 1.338373775564261,
      "attention_bam_384_attention_center_y": 0.47716389132214493,
      "attention_bam_384_attention_center_x": 0.4842174456638362,
      "attention_bam_384_attention_center_distance": 0.03925753127543226,
      "attention_bam_384_attention_spatial_variance": 170.33175708421155,
      "attention_bam_384_attention_spatial_std": 13.051120912941215,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 18.259340357313896,
      "attention_bam_384_peak_intensity_mean": 0.28960275650024414,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18953511118888855,
      "attention_bam_16_std_attention": 0.6001272797584534,
      "attention_bam_16_max_attention": 3.2373015880584717,
      "attention_bam_16_min_attention": -1.0164364576339722,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8598307875726809,
      "attention_bam_16_attention_skewness": 0.7889766671060261,
      "attention_bam_16_attention_sparsity": 0.493408203125,
      "attention_bam_16_attention_concentration_10": 0.7367357454443751,
      "attention_bam_16_attention_concentration_20": 1.1679610323725849,
      "attention_bam_16_attention_center_y": 0.44367012537062267,
      "attention_bam_16_attention_center_x": 0.47031465550847334,
      "attention_bam_16_attention_center_distance": 0.09004748140111393,
      "attention_bam_16_attention_spatial_variance": 42.097349604842925,
      "attention_bam_16_attention_spatial_std": 6.488247036360663,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.719458304801412,
      "attention_bam_16_peak_intensity_mean": 0.28597694635391235,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 293,
      "phase": "train",
      "loss": 0.007823053747415543,
      "timestamp": 1759543927.500681,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007823053747415543,
      "ssim": 0.8416116833686829,
      "attention_bam_384_mean_attention": 0.10196942836046219,
      "attention_bam_384_std_attention": 0.41970327496528625,
      "attention_bam_384_max_attention": 3.1618731021881104,
      "attention_bam_384_min_attention": -1.2330228090286255,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4421141547011649,
      "attention_bam_384_attention_skewness": 0.8064427473315375,
      "attention_bam_384_attention_sparsity": 0.5393218994140625,
      "attention_bam_384_attention_concentration_10": 0.9218250451380072,
      "attention_bam_384_attention_concentration_20": 1.4312329809139115,
      "attention_bam_384_attention_center_y": 0.4800688269224725,
      "attention_bam_384_attention_center_x": 0.4811210429003144,
      "attention_bam_384_attention_center_distance": 0.03882439133890259,
      "attention_bam_384_attention_spatial_variance": 167.91551389769833,
      "attention_bam_384_attention_spatial_std": 12.958221864812252,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 16.767933110188796,
      "attention_bam_384_peak_intensity_mean": 0.30545157194137573,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16684311628341675,
      "attention_bam_16_std_attention": 0.6178342700004578,
      "attention_bam_16_max_attention": 3.3814632892608643,
      "attention_bam_16_min_attention": -1.1266841888427734,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.6855285460973013,
      "attention_bam_16_attention_skewness": 1.0804252537831947,
      "attention_bam_16_attention_sparsity": 0.52587890625,
      "attention_bam_16_attention_concentration_10": 0.8784390190796388,
      "attention_bam_16_attention_concentration_20": 1.3464328443698528,
      "attention_bam_16_attention_center_y": 0.458160301508664,
      "attention_bam_16_attention_center_x": 0.46218628300162456,
      "attention_bam_16_attention_center_distance": 0.07975509467211649,
      "attention_bam_16_attention_spatial_variance": 40.54034313162605,
      "attention_bam_16_attention_spatial_std": 6.367129897499034,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.525150879971466,
      "attention_bam_16_peak_intensity_mean": 0.29399827122688293,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 294,
      "phase": "train",
      "loss": 0.0074171749874949455,
      "timestamp": 1759543927.6436884,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0074171749874949455,
      "ssim": 0.8600530624389648,
      "attention_bam_384_mean_attention": 0.10400574654340744,
      "attention_bam_384_std_attention": 0.4158889055252075,
      "attention_bam_384_max_attention": 3.1198177337646484,
      "attention_bam_384_min_attention": -1.262702226638794,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.287900505167431,
      "attention_bam_384_attention_skewness": 0.7566630484908331,
      "attention_bam_384_attention_sparsity": 0.5349833170572916,
      "attention_bam_384_attention_concentration_10": 0.8854184048402539,
      "attention_bam_384_attention_concentration_20": 1.3888496375346058,
      "attention_bam_384_attention_center_y": 0.4871665164773035,
      "attention_bam_384_attention_center_x": 0.488061340284014,
      "attention_bam_384_attention_center_distance": 0.02478829946331249,
      "attention_bam_384_attention_spatial_variance": 169.71525444827523,
      "attention_bam_384_attention_spatial_std": 13.027480740660307,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 15.669072359857765,
      "attention_bam_384_peak_intensity_mean": 0.31355637311935425,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18360154330730438,
      "attention_bam_16_std_attention": 0.6107455492019653,
      "attention_bam_16_max_attention": 3.689667224884033,
      "attention_bam_16_min_attention": -1.087139368057251,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.4645632248542384,
      "attention_bam_16_attention_skewness": 1.0038297666602178,
      "attention_bam_16_attention_sparsity": 0.509765625,
      "attention_bam_16_attention_concentration_10": 0.7899365415418381,
      "attention_bam_16_attention_concentration_20": 1.22673589965524,
      "attention_bam_16_attention_center_y": 0.47902482971587507,
      "attention_bam_16_attention_center_x": 0.48330449509884693,
      "attention_bam_16_attention_center_distance": 0.037912996514453026,
      "attention_bam_16_attention_spatial_variance": 41.909854900335674,
      "attention_bam_16_attention_spatial_std": 6.473782117150351,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 7.349650023491817,
      "attention_bam_16_peak_intensity_mean": 0.2750545144081116,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 295,
      "phase": "train",
      "loss": 0.006683351006358862,
      "timestamp": 1759543927.7834778,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006683351006358862,
      "ssim": 0.8775516152381897,
      "attention_bam_384_mean_attention": 0.10579606890678406,
      "attention_bam_384_std_attention": 0.39568188786506653,
      "attention_bam_384_max_attention": 3.2237417697906494,
      "attention_bam_384_min_attention": -1.192570447921753,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.3177451826841056,
      "attention_bam_384_attention_skewness": 0.6591264124060036,
      "attention_bam_384_attention_sparsity": 0.5213114420572916,
      "attention_bam_384_attention_concentration_10": 0.8242208924294209,
      "attention_bam_384_attention_concentration_20": 1.2956813853727775,
      "attention_bam_384_attention_center_y": 0.4797765119896668,
      "attention_bam_384_attention_center_x": 0.47985281488627657,
      "attention_bam_384_attention_center_distance": 0.04037074523242615,
      "attention_bam_384_attention_spatial_variance": 170.0085662507307,
      "attention_bam_384_attention_spatial_std": 13.038733306986945,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 17.691982529652652,
      "attention_bam_384_peak_intensity_mean": 0.29514455795288086,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17423099279403687,
      "attention_bam_16_std_attention": 0.5932883024215698,
      "attention_bam_16_max_attention": 3.462345838546753,
      "attention_bam_16_min_attention": -1.118596076965332,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.8675456708783216,
      "attention_bam_16_attention_skewness": 0.9463938624560542,
      "attention_bam_16_attention_sparsity": 0.495849609375,
      "attention_bam_16_attention_concentration_10": 0.7833879725976579,
      "attention_bam_16_attention_concentration_20": 1.2153344501629326,
      "attention_bam_16_attention_center_y": 0.4543730612052837,
      "attention_bam_16_attention_center_x": 0.4545156966152426,
      "attention_bam_16_attention_center_distance": 0.09111135382786756,
      "attention_bam_16_attention_spatial_variance": 41.7340929731085,
      "attention_bam_16_attention_spatial_std": 6.460192951693355,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.43872351617181,
      "attention_bam_16_peak_intensity_mean": 0.27905508875846863,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 296,
      "phase": "train",
      "loss": 0.00709959864616394,
      "timestamp": 1759543927.9226236,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00709959864616394,
      "ssim": 0.8787769675254822,
      "attention_bam_384_mean_attention": 0.10210787504911423,
      "attention_bam_384_std_attention": 0.4269692301750183,
      "attention_bam_384_max_attention": 3.429677963256836,
      "attention_bam_384_min_attention": -1.1733160018920898,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.9852044863410114,
      "attention_bam_384_attention_skewness": 0.9024709104080105,
      "attention_bam_384_attention_sparsity": 0.5408401489257812,
      "attention_bam_384_attention_concentration_10": 0.9479246758892286,
      "attention_bam_384_attention_concentration_20": 1.4467818551606235,
      "attention_bam_384_attention_center_y": 0.48959564351262475,
      "attention_bam_384_attention_center_x": 0.4859052631601287,
      "attention_bam_384_attention_center_distance": 0.024775481448464816,
      "attention_bam_384_attention_spatial_variance": 173.2714986178176,
      "attention_bam_384_attention_spatial_std": 13.163263220714596,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 17.860455794121822,
      "attention_bam_384_peak_intensity_mean": 0.27995938062667847,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17023035883903503,
      "attention_bam_16_std_attention": 0.6166431307792664,
      "attention_bam_16_max_attention": 3.715714454650879,
      "attention_bam_16_min_attention": -1.1226446628570557,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.9906158752001497,
      "attention_bam_16_attention_skewness": 1.1322343223729034,
      "attention_bam_16_attention_sparsity": 0.5263671875,
      "attention_bam_16_attention_concentration_10": 0.8655003875062475,
      "attention_bam_16_attention_concentration_20": 1.325258145882338,
      "attention_bam_16_attention_center_y": 0.48212970147332457,
      "attention_bam_16_attention_center_x": 0.47251842947861444,
      "attention_bam_16_attention_center_distance": 0.04635912612969286,
      "attention_bam_16_attention_spatial_variance": 44.14058971851644,
      "attention_bam_16_attention_spatial_std": 6.643838477756397,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.373897327824187,
      "attention_bam_16_peak_intensity_mean": 0.2793448865413666,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 297,
      "phase": "train",
      "loss": 0.011334876529872417,
      "timestamp": 1759543928.060915,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.011334876529872417,
      "ssim": 0.8496127724647522,
      "attention_bam_384_mean_attention": 0.10807275027036667,
      "attention_bam_384_std_attention": 0.3411467671394348,
      "attention_bam_384_max_attention": 2.8458895683288574,
      "attention_bam_384_min_attention": -1.2088623046875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.877611192954094,
      "attention_bam_384_attention_skewness": 0.5187604675729439,
      "attention_bam_384_attention_sparsity": 0.5175501505533854,
      "attention_bam_384_attention_concentration_10": 0.7108911339768981,
      "attention_bam_384_attention_concentration_20": 1.1236595339680133,
      "attention_bam_384_attention_center_y": 0.4822877738880095,
      "attention_bam_384_attention_center_x": 0.48591062319649597,
      "attention_bam_384_attention_center_distance": 0.03200729581059282,
      "attention_bam_384_attention_spatial_variance": 169.7863818267197,
      "attention_bam_384_attention_spatial_std": 13.030210352358848,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 18.107758384837815,
      "attention_bam_384_peak_intensity_mean": 0.32844051718711853,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1921626776456833,
      "attention_bam_16_std_attention": 0.5244296789169312,
      "attention_bam_16_max_attention": 2.6109795570373535,
      "attention_bam_16_min_attention": -1.0761499404907227,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5228473226988557,
      "attention_bam_16_attention_skewness": 0.5771635283325763,
      "attention_bam_16_attention_sparsity": 0.4599609375,
      "attention_bam_16_attention_concentration_10": 0.6337592439763744,
      "attention_bam_16_attention_concentration_20": 1.0129759885614116,
      "attention_bam_16_attention_center_y": 0.46245478508154136,
      "attention_bam_16_attention_center_x": 0.47623015370905586,
      "attention_bam_16_attention_center_distance": 0.0628434365064222,
      "attention_bam_16_attention_spatial_variance": 41.916188667375636,
      "attention_bam_16_attention_spatial_std": 6.4742712846602,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.564372099106093,
      "attention_bam_16_peak_intensity_mean": 0.35311952233314514,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 298,
      "phase": "train",
      "loss": 0.007933060638606548,
      "timestamp": 1759543928.1970162,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007933060638606548,
      "ssim": 0.8827223181724548,
      "attention_bam_384_mean_attention": 0.10164809972047806,
      "attention_bam_384_std_attention": 0.4466158151626587,
      "attention_bam_384_max_attention": 3.0647268295288086,
      "attention_bam_384_min_attention": -1.2434699535369873,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5279478047380239,
      "attention_bam_384_attention_skewness": 0.642429871706665,
      "attention_bam_384_attention_sparsity": 0.5379079182942709,
      "attention_bam_384_attention_concentration_10": 0.9653261414197204,
      "attention_bam_384_attention_concentration_20": 1.5218889171108696,
      "attention_bam_384_attention_center_y": 0.484276516722976,
      "attention_bam_384_attention_center_x": 0.4849862314172969,
      "attention_bam_384_attention_center_distance": 0.030745444326527975,
      "attention_bam_384_attention_spatial_variance": 171.18506451906552,
      "attention_bam_384_attention_spatial_std": 13.0837710358698,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 19.629015331179563,
      "attention_bam_384_peak_intensity_mean": 0.313821017742157,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16620653867721558,
      "attention_bam_16_std_attention": 0.6458289623260498,
      "attention_bam_16_max_attention": 2.9032411575317383,
      "attention_bam_16_min_attention": -1.1415126323699951,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.3551698375067991,
      "attention_bam_16_attention_skewness": 0.8068114449380022,
      "attention_bam_16_attention_sparsity": 0.5322265625,
      "attention_bam_16_attention_concentration_10": 0.8947786305182244,
      "attention_bam_16_attention_concentration_20": 1.4220834410472474,
      "attention_bam_16_attention_center_y": 0.47048699816719436,
      "attention_bam_16_attention_center_x": 0.47404243225445114,
      "attention_bam_16_attention_center_distance": 0.055584397099329004,
      "attention_bam_16_attention_spatial_variance": 43.07890125289264,
      "attention_bam_16_attention_spatial_std": 6.5634519311786415,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.844058496379885,
      "attention_bam_16_peak_intensity_mean": 0.32871514558792114,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 299,
      "phase": "train",
      "loss": 0.011870298534631729,
      "timestamp": 1759543928.3356974,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.011870298534631729,
      "ssim": 0.8369264602661133,
      "attention_bam_384_mean_attention": 0.10185415297746658,
      "attention_bam_384_std_attention": 0.43510764837265015,
      "attention_bam_384_max_attention": 4.298584461212158,
      "attention_bam_384_min_attention": -1.2533984184265137,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.430468241655377,
      "attention_bam_384_attention_skewness": 1.1302402469588164,
      "attention_bam_384_attention_sparsity": 0.5443700154622396,
      "attention_bam_384_attention_concentration_10": 0.9678254360317394,
      "attention_bam_384_attention_concentration_20": 1.4584158256502397,
      "attention_bam_384_attention_center_y": 0.4789469524295687,
      "attention_bam_384_attention_center_x": 0.482760708653123,
      "attention_bam_384_attention_center_distance": 0.038481787332330396,
      "attention_bam_384_attention_spatial_variance": 168.3331944586463,
      "attention_bam_384_attention_spatial_std": 12.974328285450706,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 17.097736784125185,
      "attention_bam_384_peak_intensity_mean": 0.2448151409626007,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16851533949375153,
      "attention_bam_16_std_attention": 0.6363610625267029,
      "attention_bam_16_max_attention": 4.509824752807617,
      "attention_bam_16_min_attention": -1.22146737575531,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.7510885207922486,
      "attention_bam_16_attention_skewness": 1.437487136890687,
      "attention_bam_16_attention_sparsity": 0.535400390625,
      "attention_bam_16_attention_concentration_10": 0.9047324167361123,
      "attention_bam_16_attention_concentration_20": 1.3559233532623318,
      "attention_bam_16_attention_center_y": 0.45420692586072026,
      "attention_bam_16_attention_center_x": 0.46887935211405457,
      "attention_bam_16_attention_center_distance": 0.07830070707173174,
      "attention_bam_16_attention_spatial_variance": 40.90354555963985,
      "attention_bam_16_attention_spatial_std": 6.395587976069116,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.05399036488387,
      "attention_bam_16_peak_intensity_mean": 0.24105437099933624,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 300,
      "phase": "train",
      "loss": 0.0071727074682712555,
      "timestamp": 1759543928.5173607,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0071727074682712555,
      "ssim": 0.8606340885162354,
      "attention_bam_384_mean_attention": 0.1005764901638031,
      "attention_bam_384_std_attention": 0.4170495569705963,
      "attention_bam_384_max_attention": 3.152742385864258,
      "attention_bam_384_min_attention": -1.2712689638137817,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6483532565964989,
      "attention_bam_384_attention_skewness": 0.6660643869577004,
      "attention_bam_384_attention_sparsity": 0.5429458618164062,
      "attention_bam_384_attention_concentration_10": 0.9307536544773164,
      "attention_bam_384_attention_concentration_20": 1.4545099685793776,
      "attention_bam_384_attention_center_y": 0.48144640234439623,
      "attention_bam_384_attention_center_x": 0.4788150497864685,
      "attention_bam_384_attention_center_distance": 0.03982557222478628,
      "attention_bam_384_attention_spatial_variance": 169.84592163333895,
      "attention_bam_384_attention_spatial_std": 13.032494835346721,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 17.82942403210914,
      "attention_bam_384_peak_intensity_mean": 0.315595805644989,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16370637714862823,
      "attention_bam_16_std_attention": 0.6031689643859863,
      "attention_bam_16_max_attention": 2.946760654449463,
      "attention_bam_16_min_attention": -1.1086440086364746,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.1955877432484021,
      "attention_bam_16_attention_skewness": 0.7281209363545033,
      "attention_bam_16_attention_sparsity": 0.5244140625,
      "attention_bam_16_attention_concentration_10": 0.8326008503856617,
      "attention_bam_16_attention_concentration_20": 1.3477518828280213,
      "attention_bam_16_attention_center_y": 0.45968092374186553,
      "attention_bam_16_attention_center_x": 0.45460083754836345,
      "attention_bam_16_attention_center_distance": 0.08586864225803677,
      "attention_bam_16_attention_spatial_variance": 41.751434615013395,
      "attention_bam_16_attention_spatial_std": 6.461535004549105,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.31438028885099,
      "attention_bam_16_peak_intensity_mean": 0.3305731415748596,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 301,
      "phase": "train",
      "loss": 0.0070223696529865265,
      "timestamp": 1759543931.0811195,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0070223696529865265,
      "ssim": 0.8503623008728027,
      "attention_bam_384_mean_attention": 0.09735561162233353,
      "attention_bam_384_std_attention": 0.43511730432510376,
      "attention_bam_384_max_attention": 3.5294573307037354,
      "attention_bam_384_min_attention": -1.171644687652588,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.863033604689261,
      "attention_bam_384_attention_skewness": 0.9080049621916767,
      "attention_bam_384_attention_sparsity": 0.546844482421875,
      "attention_bam_384_attention_concentration_10": 0.9921144979909424,
      "attention_bam_384_attention_concentration_20": 1.534594057205126,
      "attention_bam_384_attention_center_y": 0.4818824022890206,
      "attention_bam_384_attention_center_x": 0.4838064013481892,
      "attention_bam_384_attention_center_distance": 0.03436509811168347,
      "attention_bam_384_attention_spatial_variance": 173.13249435278226,
      "attention_bam_384_attention_spatial_std": 13.157982153536395,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 19.60772468475614,
      "attention_bam_384_peak_intensity_mean": 0.2735111117362976,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16419623792171478,
      "attention_bam_16_std_attention": 0.6346510648727417,
      "attention_bam_16_max_attention": 3.738159656524658,
      "attention_bam_16_min_attention": -1.0976941585540771,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.4502472977842347,
      "attention_bam_16_attention_skewness": 1.2171117158568925,
      "attention_bam_16_attention_sparsity": 0.535400390625,
      "attention_bam_16_attention_concentration_10": 0.9049012784392718,
      "attention_bam_16_attention_concentration_20": 1.3946915257161632,
      "attention_bam_16_attention_center_y": 0.4624010542249406,
      "attention_bam_16_attention_center_x": 0.4686486717183805,
      "attention_bam_16_attention_center_distance": 0.06923274526432896,
      "attention_bam_16_attention_spatial_variance": 44.44509445606819,
      "attention_bam_16_attention_spatial_std": 6.666715417360201,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.773239626818059,
      "attention_bam_16_peak_intensity_mean": 0.27051863074302673,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 302,
      "phase": "train",
      "loss": 0.007318202406167984,
      "timestamp": 1759543931.217458,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007318202406167984,
      "ssim": 0.8618316650390625,
      "attention_bam_384_mean_attention": 0.10243486613035202,
      "attention_bam_384_std_attention": 0.43933600187301636,
      "attention_bam_384_max_attention": 2.843872308731079,
      "attention_bam_384_min_attention": -1.1271395683288574,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.23884120330272607,
      "attention_bam_384_attention_skewness": 0.5858151277991874,
      "attention_bam_384_attention_sparsity": 0.5320383707682291,
      "attention_bam_384_attention_concentration_10": 0.9400076478228477,
      "attention_bam_384_attention_concentration_20": 1.4853903400988862,
      "attention_bam_384_attention_center_y": 0.4929670188033688,
      "attention_bam_384_attention_center_x": 0.4864198648507077,
      "attention_bam_384_attention_center_distance": 0.021627893803383265,
      "attention_bam_384_attention_spatial_variance": 171.30014162843125,
      "attention_bam_384_attention_spatial_std": 13.088168001230395,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 14.168644185248144,
      "attention_bam_384_peak_intensity_mean": 0.31860315799713135,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18846651911735535,
      "attention_bam_16_std_attention": 0.6448796391487122,
      "attention_bam_16_max_attention": 2.758117437362671,
      "attention_bam_16_min_attention": -1.1027567386627197,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.06186815255482303,
      "attention_bam_16_attention_skewness": 0.6729584321320203,
      "attention_bam_16_attention_sparsity": 0.50048828125,
      "attention_bam_16_attention_concentration_10": 0.7789343800634309,
      "attention_bam_16_attention_concentration_20": 1.2580106190855314,
      "attention_bam_16_attention_center_y": 0.4995175548941519,
      "attention_bam_16_attention_center_x": 0.47736164834983785,
      "attention_bam_16_attention_center_distance": 0.03202273313496385,
      "attention_bam_16_attention_spatial_variance": 43.22112139069152,
      "attention_bam_16_attention_spatial_std": 6.574277252344285,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 7.3133897173176745,
      "attention_bam_16_peak_intensity_mean": 0.3608171045780182,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 303,
      "phase": "train",
      "loss": 0.006533412262797356,
      "timestamp": 1759543931.3503268,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006533412262797356,
      "ssim": 0.8644924163818359,
      "attention_bam_384_mean_attention": 0.10125088691711426,
      "attention_bam_384_std_attention": 0.42313411831855774,
      "attention_bam_384_max_attention": 2.9914045333862305,
      "attention_bam_384_min_attention": -1.1453880071640015,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.414528617620316,
      "attention_bam_384_attention_skewness": 0.5566548375416325,
      "attention_bam_384_attention_sparsity": 0.530487060546875,
      "attention_bam_384_attention_concentration_10": 0.9112502953222555,
      "attention_bam_384_attention_concentration_20": 1.4441809108251982,
      "attention_bam_384_attention_center_y": 0.4883427141651813,
      "attention_bam_384_attention_center_x": 0.48700946399746836,
      "attention_bam_384_attention_center_distance": 0.02468385458828239,
      "attention_bam_384_attention_spatial_variance": 171.63234865391064,
      "attention_bam_384_attention_spatial_std": 13.100852974287996,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 19.176724409571282,
      "attention_bam_384_peak_intensity_mean": 0.3049377202987671,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18135474622249603,
      "attention_bam_16_std_attention": 0.6242120265960693,
      "attention_bam_16_max_attention": 3.2149577140808105,
      "attention_bam_16_min_attention": -1.08748197555542,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.3244363184318808,
      "attention_bam_16_attention_skewness": 0.6892150296772301,
      "attention_bam_16_attention_sparsity": 0.497802734375,
      "attention_bam_16_attention_concentration_10": 0.7838705375535645,
      "attention_bam_16_attention_concentration_20": 1.2541991868537412,
      "attention_bam_16_attention_center_y": 0.4875235477002013,
      "attention_bam_16_attention_center_x": 0.48167925360393093,
      "attention_bam_16_attention_center_distance": 0.03134682154535704,
      "attention_bam_16_attention_spatial_variance": 43.7415135541293,
      "attention_bam_16_attention_spatial_std": 6.613736731540597,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.475344495197712,
      "attention_bam_16_peak_intensity_mean": 0.3141668438911438,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 304,
      "phase": "train",
      "loss": 0.008459458127617836,
      "timestamp": 1759543931.4822683,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008459458127617836,
      "ssim": 0.8879185318946838,
      "attention_bam_384_mean_attention": 0.10287415981292725,
      "attention_bam_384_std_attention": 0.44528326392173767,
      "attention_bam_384_max_attention": 3.9188344478607178,
      "attention_bam_384_min_attention": -1.5046082735061646,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.545352464534777,
      "attention_bam_384_attention_skewness": 0.9827795881451439,
      "attention_bam_384_attention_sparsity": 0.5316899617513021,
      "attention_bam_384_attention_concentration_10": 0.9343183799530546,
      "attention_bam_384_attention_concentration_20": 1.4497113267224786,
      "attention_bam_384_attention_center_y": 0.48595253231500907,
      "attention_bam_384_attention_center_x": 0.48225019364182886,
      "attention_bam_384_attention_center_distance": 0.03201209065692015,
      "attention_bam_384_attention_spatial_variance": 169.9691461775479,
      "attention_bam_384_attention_spatial_std": 13.037221566635582,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 18.847049439753828,
      "attention_bam_384_peak_intensity_mean": 0.2960245609283447,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1879751831293106,
      "attention_bam_16_std_attention": 0.6596384048461914,
      "attention_bam_16_max_attention": 5.175668716430664,
      "attention_bam_16_min_attention": -1.3246890306472778,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 4.937293273500863,
      "attention_bam_16_attention_skewness": 1.4107211370917567,
      "attention_bam_16_attention_sparsity": 0.499755859375,
      "attention_bam_16_attention_concentration_10": 0.8062005892814252,
      "attention_bam_16_attention_concentration_20": 1.2359755813664834,
      "attention_bam_16_attention_center_y": 0.47967587515617116,
      "attention_bam_16_attention_center_x": 0.460162482095442,
      "attention_bam_16_attention_center_distance": 0.0632471008578815,
      "attention_bam_16_attention_spatial_variance": 41.892398983734566,
      "attention_bam_16_attention_spatial_std": 6.472433775924985,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.242456392647803,
      "attention_bam_16_peak_intensity_mean": 0.24329720437526703,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 305,
      "phase": "train",
      "loss": 0.006644390523433685,
      "timestamp": 1759543931.6128054,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006644390523433685,
      "ssim": 0.8703994750976562,
      "attention_bam_384_mean_attention": 0.09862804412841797,
      "attention_bam_384_std_attention": 0.39785540103912354,
      "attention_bam_384_max_attention": 3.9413604736328125,
      "attention_bam_384_min_attention": -1.324613332748413,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.810133519774105,
      "attention_bam_384_attention_skewness": 0.8335587527036354,
      "attention_bam_384_attention_sparsity": 0.5455245971679688,
      "attention_bam_384_attention_concentration_10": 0.9094804871442941,
      "attention_bam_384_attention_concentration_20": 1.404789315792674,
      "attention_bam_384_attention_center_y": 0.48102479671969617,
      "attention_bam_384_attention_center_x": 0.48459914217885663,
      "attention_bam_384_attention_center_distance": 0.03456138773706652,
      "attention_bam_384_attention_spatial_variance": 170.4156023071181,
      "attention_bam_384_attention_spatial_std": 13.054332702483038,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 19.6759918327165,
      "attention_bam_384_peak_intensity_mean": 0.27363017201423645,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18136444687843323,
      "attention_bam_16_std_attention": 0.5869429707527161,
      "attention_bam_16_max_attention": 3.557314157485962,
      "attention_bam_16_min_attention": -1.0560181140899658,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.9694665020192383,
      "attention_bam_16_attention_skewness": 0.8396163692126019,
      "attention_bam_16_attention_sparsity": 0.501708984375,
      "attention_bam_16_attention_concentration_10": 0.7567561749548657,
      "attention_bam_16_attention_concentration_20": 1.1961580989394456,
      "attention_bam_16_attention_center_y": 0.4561224299445076,
      "attention_bam_16_attention_center_x": 0.4700566042237947,
      "attention_bam_16_attention_center_distance": 0.07512453799638456,
      "attention_bam_16_attention_spatial_variance": 42.611192767051215,
      "attention_bam_16_attention_spatial_std": 6.527724930406551,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.67891592643761,
      "attention_bam_16_peak_intensity_mean": 0.2771957814693451,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 306,
      "phase": "train",
      "loss": 0.01116839237511158,
      "timestamp": 1759543931.7452517,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.01116839237511158,
      "ssim": 0.834242582321167,
      "attention_bam_384_mean_attention": 0.10470960289239883,
      "attention_bam_384_std_attention": 0.36978721618652344,
      "attention_bam_384_max_attention": 3.139657735824585,
      "attention_bam_384_min_attention": -1.075124979019165,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9398837914910452,
      "attention_bam_384_attention_skewness": 0.5226372364425178,
      "attention_bam_384_attention_sparsity": 0.5255635579427084,
      "attention_bam_384_attention_concentration_10": 0.7957550813467065,
      "attention_bam_384_attention_concentration_20": 1.2410159600938657,
      "attention_bam_384_attention_center_y": 0.4811556801925007,
      "attention_bam_384_attention_center_x": 0.4834951847177627,
      "attention_bam_384_attention_center_distance": 0.03542646797263548,
      "attention_bam_384_attention_spatial_variance": 171.81922309484364,
      "attention_bam_384_attention_spatial_std": 13.107983181818767,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 19.51679712506312,
      "attention_bam_384_peak_intensity_mean": 0.2809595465660095,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20186293125152588,
      "attention_bam_16_std_attention": 0.5482591390609741,
      "attention_bam_16_max_attention": 2.8371007442474365,
      "attention_bam_16_min_attention": -1.1243139505386353,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7288308869421098,
      "attention_bam_16_attention_skewness": 0.6251783098049898,
      "attention_bam_16_attention_sparsity": 0.45556640625,
      "attention_bam_16_attention_concentration_10": 0.636912709658172,
      "attention_bam_16_attention_concentration_20": 1.0080822086760346,
      "attention_bam_16_attention_center_y": 0.4509800238383371,
      "attention_bam_16_attention_center_x": 0.4655160827658188,
      "attention_bam_16_attention_center_distance": 0.0847596438253944,
      "attention_bam_16_attention_spatial_variance": 42.969525526191966,
      "attention_bam_16_attention_spatial_std": 6.555114455613416,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 10.25270332399685,
      "attention_bam_16_peak_intensity_mean": 0.34545233845710754,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 307,
      "phase": "train",
      "loss": 0.006265030708163977,
      "timestamp": 1759543931.8761683,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006265030708163977,
      "ssim": 0.8647670745849609,
      "attention_bam_384_mean_attention": 0.10078122466802597,
      "attention_bam_384_std_attention": 0.38425275683403015,
      "attention_bam_384_max_attention": 2.6425395011901855,
      "attention_bam_384_min_attention": -1.1941722631454468,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1719619322216692,
      "attention_bam_384_attention_skewness": 0.774184538973679,
      "attention_bam_384_attention_sparsity": 0.5430577596028646,
      "attention_bam_384_attention_concentration_10": 0.8672095629654677,
      "attention_bam_384_attention_concentration_20": 1.3468453824897022,
      "attention_bam_384_attention_center_y": 0.47954457540861045,
      "attention_bam_384_attention_center_x": 0.4881378064304946,
      "attention_bam_384_attention_center_distance": 0.033440575099553525,
      "attention_bam_384_attention_spatial_variance": 171.92527200310533,
      "attention_bam_384_attention_spatial_std": 13.112027760918803,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 17.935677759561408,
      "attention_bam_384_peak_intensity_mean": 0.3421800434589386,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17839846014976501,
      "attention_bam_16_std_attention": 0.5909404754638672,
      "attention_bam_16_max_attention": 3.6711528301239014,
      "attention_bam_16_min_attention": -1.027941107749939,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.0203783756592575,
      "attention_bam_16_attention_skewness": 0.9016228266863511,
      "attention_bam_16_attention_sparsity": 0.507080078125,
      "attention_bam_16_attention_concentration_10": 0.7811042289987472,
      "attention_bam_16_attention_concentration_20": 1.2252346660632025,
      "attention_bam_16_attention_center_y": 0.45374579290028333,
      "attention_bam_16_attention_center_x": 0.4807008784587612,
      "attention_bam_16_attention_center_distance": 0.07087887931798847,
      "attention_bam_16_attention_spatial_variance": 43.59897485453585,
      "attention_bam_16_attention_spatial_std": 6.602951980329393,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.148570376930822,
      "attention_bam_16_peak_intensity_mean": 0.2688736319541931,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 308,
      "phase": "train",
      "loss": 0.006395432166755199,
      "timestamp": 1759543932.0080683,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006395432166755199,
      "ssim": 0.8488602638244629,
      "attention_bam_384_mean_attention": 0.10367768257856369,
      "attention_bam_384_std_attention": 0.34600311517715454,
      "attention_bam_384_max_attention": 2.3665709495544434,
      "attention_bam_384_min_attention": -1.114255666732788,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.40737571125298366,
      "attention_bam_384_attention_skewness": 0.4234327120934373,
      "attention_bam_384_attention_sparsity": 0.5247472127278646,
      "attention_bam_384_attention_concentration_10": 0.7335596089007419,
      "attention_bam_384_attention_concentration_20": 1.1822573905498515,
      "attention_bam_384_attention_center_y": 0.4814603613626854,
      "attention_bam_384_attention_center_x": 0.4872273017583052,
      "attention_bam_384_attention_center_distance": 0.031838970497665355,
      "attention_bam_384_attention_spatial_variance": 170.10879600432503,
      "attention_bam_384_attention_spatial_std": 13.042576279413705,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 17.133141621672053,
      "attention_bam_384_peak_intensity_mean": 0.3510180413722992,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20505475997924805,
      "attention_bam_16_std_attention": 0.5286514759063721,
      "attention_bam_16_max_attention": 2.4953103065490723,
      "attention_bam_16_min_attention": -1.1625702381134033,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.005865449257227429,
      "attention_bam_16_attention_skewness": 0.4361635410100422,
      "attention_bam_16_attention_sparsity": 0.454345703125,
      "attention_bam_16_attention_concentration_10": 0.58933705505413,
      "attention_bam_16_attention_concentration_20": 0.969901007125147,
      "attention_bam_16_attention_center_y": 0.4603203614245724,
      "attention_bam_16_attention_center_x": 0.48145088202775976,
      "attention_bam_16_attention_center_distance": 0.06194422483209631,
      "attention_bam_16_attention_spatial_variance": 42.118878990825735,
      "attention_bam_16_attention_spatial_std": 6.489905930814848,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 8.140903814039142,
      "attention_bam_16_peak_intensity_mean": 0.37442150712013245,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 309,
      "phase": "train",
      "loss": 0.008998104371130466,
      "timestamp": 1759543932.1403768,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008998104371130466,
      "ssim": 0.8342105150222778,
      "attention_bam_384_mean_attention": 0.09871754795312881,
      "attention_bam_384_std_attention": 0.4013669788837433,
      "attention_bam_384_max_attention": 2.4963555335998535,
      "attention_bam_384_min_attention": -1.1830217838287354,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5492882528864946,
      "attention_bam_384_attention_skewness": 0.6016125671414201,
      "attention_bam_384_attention_sparsity": 0.5349070231119791,
      "attention_bam_384_attention_concentration_10": 0.896724782771313,
      "attention_bam_384_attention_concentration_20": 1.4116211815074886,
      "attention_bam_384_attention_center_y": 0.48718677074603883,
      "attention_bam_384_attention_center_x": 0.4853955939049822,
      "attention_bam_384_attention_center_distance": 0.027476081281826156,
      "attention_bam_384_attention_spatial_variance": 170.1971214268151,
      "attention_bam_384_attention_spatial_std": 13.04596188200836,
      "attention_bam_384_num_attention_peaks": 18,
      "attention_bam_384_peak_separation_mean": 16.64718129607899,
      "attention_bam_384_peak_intensity_mean": 0.3540964126586914,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1769881546497345,
      "attention_bam_16_std_attention": 0.5888664722442627,
      "attention_bam_16_max_attention": 2.998115301132202,
      "attention_bam_16_min_attention": -1.1671444177627563,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7076358062592871,
      "attention_bam_16_attention_skewness": 0.7853205169481126,
      "attention_bam_16_attention_sparsity": 0.50244140625,
      "attention_bam_16_attention_concentration_10": 0.7694240374572857,
      "attention_bam_16_attention_concentration_20": 1.2198837058957261,
      "attention_bam_16_attention_center_y": 0.47867853833683793,
      "attention_bam_16_attention_center_x": 0.47604294513916484,
      "attention_bam_16_attention_center_distance": 0.04535515858331343,
      "attention_bam_16_attention_spatial_variance": 42.136439389626105,
      "attention_bam_16_attention_spatial_std": 6.491258690702914,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.08648306028742,
      "attention_bam_16_peak_intensity_mean": 0.33755582571029663,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 310,
      "phase": "train",
      "loss": 0.007873672991991043,
      "timestamp": 1759543932.3261507,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007873672991991043,
      "ssim": 0.8409045934677124,
      "attention_bam_384_mean_attention": 0.09628421068191528,
      "attention_bam_384_std_attention": 0.4457267224788666,
      "attention_bam_384_max_attention": 3.495121479034424,
      "attention_bam_384_min_attention": -1.3103201389312744,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.6337210734411576,
      "attention_bam_384_attention_skewness": 0.843579242060696,
      "attention_bam_384_attention_sparsity": 0.5466766357421875,
      "attention_bam_384_attention_concentration_10": 1.0272946960084928,
      "attention_bam_384_attention_concentration_20": 1.5792685028068671,
      "attention_bam_384_attention_center_y": 0.47876694072806075,
      "attention_bam_384_attention_center_x": 0.4842852845851872,
      "attention_bam_384_attention_center_distance": 0.03735759860093364,
      "attention_bam_384_attention_spatial_variance": 171.41868427795347,
      "attention_bam_384_attention_spatial_std": 13.092695836914316,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 18.234249644251825,
      "attention_bam_384_peak_intensity_mean": 0.29569268226623535,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16046161949634552,
      "attention_bam_16_std_attention": 0.6488566994667053,
      "attention_bam_16_max_attention": 3.6271839141845703,
      "attention_bam_16_min_attention": -1.1818634271621704,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.2310467490983834,
      "attention_bam_16_attention_skewness": 1.1447755866446245,
      "attention_bam_16_attention_sparsity": 0.528564453125,
      "attention_bam_16_attention_concentration_10": 0.9461094348439224,
      "attention_bam_16_attention_concentration_20": 1.4432037563031475,
      "attention_bam_16_attention_center_y": 0.45070943745028624,
      "attention_bam_16_attention_center_x": 0.4667311615615998,
      "attention_bam_16_attention_center_distance": 0.0840996452728264,
      "attention_bam_16_attention_spatial_variance": 43.24729565748099,
      "attention_bam_16_attention_spatial_std": 6.576267608414441,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 11.709650649627612,
      "attention_bam_16_peak_intensity_mean": 0.28233322501182556,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 311,
      "phase": "train",
      "loss": 0.008114340715110302,
      "timestamp": 1759543932.4671662,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008114340715110302,
      "ssim": 0.8753162622451782,
      "attention_bam_384_mean_attention": 0.09869829565286636,
      "attention_bam_384_std_attention": 0.39267241954803467,
      "attention_bam_384_max_attention": 2.6746737957000732,
      "attention_bam_384_min_attention": -1.280332326889038,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.07546961385935314,
      "attention_bam_384_attention_skewness": 0.41435625624137024,
      "attention_bam_384_attention_sparsity": 0.5337931315104166,
      "attention_bam_384_attention_concentration_10": 0.848086056016633,
      "attention_bam_384_attention_concentration_20": 1.374492415726364,
      "attention_bam_384_attention_center_y": 0.4853786450997677,
      "attention_bam_384_attention_center_x": 0.4832878129882804,
      "attention_bam_384_attention_center_distance": 0.03140322320505451,
      "attention_bam_384_attention_spatial_variance": 170.1810875271242,
      "attention_bam_384_attention_spatial_std": 13.045347351723686,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 16.60186073221297,
      "attention_bam_384_peak_intensity_mean": 0.35179707407951355,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17353926599025726,
      "attention_bam_16_std_attention": 0.5780152678489685,
      "attention_bam_16_max_attention": 2.271975517272949,
      "attention_bam_16_min_attention": -1.099057674407959,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.07711213147473517,
      "attention_bam_16_attention_skewness": 0.5849909325509872,
      "attention_bam_16_attention_sparsity": 0.50341796875,
      "attention_bam_16_attention_concentration_10": 0.7495891945153454,
      "attention_bam_16_attention_concentration_20": 1.221438769251948,
      "attention_bam_16_attention_center_y": 0.47347390894676145,
      "attention_bam_16_attention_center_x": 0.468763105819461,
      "attention_bam_16_attention_center_distance": 0.05795475933192878,
      "attention_bam_16_attention_spatial_variance": 42.10729742654793,
      "attention_bam_16_attention_spatial_std": 6.48901359426438,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.271543960594366,
      "attention_bam_16_peak_intensity_mean": 0.39629456400871277,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 312,
      "phase": "train",
      "loss": 0.007012590300291777,
      "timestamp": 1759543932.5960257,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007012590300291777,
      "ssim": 0.8861985206604004,
      "attention_bam_384_mean_attention": 0.09740543365478516,
      "attention_bam_384_std_attention": 0.3890796899795532,
      "attention_bam_384_max_attention": 2.9775187969207764,
      "attention_bam_384_min_attention": -1.2054316997528076,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.1307436349284306,
      "attention_bam_384_attention_skewness": 0.8780187056322958,
      "attention_bam_384_attention_sparsity": 0.5448735555013021,
      "attention_bam_384_attention_concentration_10": 0.893533725943026,
      "attention_bam_384_attention_concentration_20": 1.3740578422442082,
      "attention_bam_384_attention_center_y": 0.48673833637353886,
      "attention_bam_384_attention_center_x": 0.4879393654417095,
      "attention_bam_384_attention_center_distance": 0.02535076441017245,
      "attention_bam_384_attention_spatial_variance": 171.94558471732992,
      "attention_bam_384_attention_spatial_std": 13.11280232129387,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 16.741198987077638,
      "attention_bam_384_peak_intensity_mean": 0.3129202127456665,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1724708527326584,
      "attention_bam_16_std_attention": 0.600608229637146,
      "attention_bam_16_max_attention": 4.856626510620117,
      "attention_bam_16_min_attention": -1.1570100784301758,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.8018121512424976,
      "attention_bam_16_attention_skewness": 1.1780540850050056,
      "attention_bam_16_attention_sparsity": 0.510986328125,
      "attention_bam_16_attention_concentration_10": 0.8236118864027779,
      "attention_bam_16_attention_concentration_20": 1.266621987289665,
      "attention_bam_16_attention_center_y": 0.47568923067973296,
      "attention_bam_16_attention_center_x": 0.4813525353529261,
      "attention_bam_16_attention_center_distance": 0.04332993059553888,
      "attention_bam_16_attention_spatial_variance": 43.90055454597366,
      "attention_bam_16_attention_spatial_std": 6.625749357316021,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 10.977197350873551,
      "attention_bam_16_peak_intensity_mean": 0.22142735123634338,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 313,
      "phase": "train",
      "loss": 0.011203846894204617,
      "timestamp": 1759543932.7274058,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.011203846894204617,
      "ssim": 0.896660566329956,
      "attention_bam_384_mean_attention": 0.10141319036483765,
      "attention_bam_384_std_attention": 0.46897056698799133,
      "attention_bam_384_max_attention": 3.8797810077667236,
      "attention_bam_384_min_attention": -1.2407002449035645,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4155115697715042,
      "attention_bam_384_attention_skewness": 0.7163973900800229,
      "attention_bam_384_attention_sparsity": 0.534332275390625,
      "attention_bam_384_attention_concentration_10": 1.0100965990782087,
      "attention_bam_384_attention_concentration_20": 1.5659468412173823,
      "attention_bam_384_attention_center_y": 0.48657988706391875,
      "attention_bam_384_attention_center_x": 0.48997515226733956,
      "attention_bam_384_attention_center_distance": 0.023689533692337738,
      "attention_bam_384_attention_spatial_variance": 170.54504641125786,
      "attention_bam_384_attention_spatial_std": 13.059289659520454,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 20.80949041803902,
      "attention_bam_384_peak_intensity_mean": 0.26758912205696106,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1837712526321411,
      "attention_bam_16_std_attention": 0.6801888346672058,
      "attention_bam_16_max_attention": 3.8701791763305664,
      "attention_bam_16_min_attention": -1.1595220565795898,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.627419700963114,
      "attention_bam_16_attention_skewness": 0.972572404046093,
      "attention_bam_16_attention_sparsity": 0.5068359375,
      "attention_bam_16_attention_concentration_10": 0.8557543858966415,
      "attention_bam_16_attention_concentration_20": 1.3285553504819982,
      "attention_bam_16_attention_center_y": 0.4757054188288606,
      "attention_bam_16_attention_center_x": 0.49188714289315655,
      "attention_bam_16_attention_center_distance": 0.03622278632897094,
      "attention_bam_16_attention_spatial_variance": 42.91840771866095,
      "attention_bam_16_attention_spatial_std": 6.551214217125017,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 9.513122549566274,
      "attention_bam_16_peak_intensity_mean": 0.2873595654964447,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 314,
      "phase": "train",
      "loss": 0.0069246552884578705,
      "timestamp": 1759543932.8575807,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0069246552884578705,
      "ssim": 0.8690851330757141,
      "attention_bam_384_mean_attention": 0.09348160773515701,
      "attention_bam_384_std_attention": 0.4262956380844116,
      "attention_bam_384_max_attention": 3.6246399879455566,
      "attention_bam_384_min_attention": -1.278911828994751,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 4.1242752989518054,
      "attention_bam_384_attention_skewness": 1.3251860577880277,
      "attention_bam_384_attention_sparsity": 0.5606409708658854,
      "attention_bam_384_attention_concentration_10": 1.043447688016305,
      "attention_bam_384_attention_concentration_20": 1.5423732650011475,
      "attention_bam_384_attention_center_y": 0.4889647312012688,
      "attention_bam_384_attention_center_x": 0.4837068333432957,
      "attention_bam_384_attention_center_distance": 0.02782964021195357,
      "attention_bam_384_attention_spatial_variance": 171.51385482224222,
      "attention_bam_384_attention_spatial_std": 13.096329822596948,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 18.862168361070715,
      "attention_bam_384_peak_intensity_mean": 0.2810586094856262,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1696244180202484,
      "attention_bam_16_std_attention": 0.6364825963973999,
      "attention_bam_16_max_attention": 4.047296524047852,
      "attention_bam_16_min_attention": -1.0451316833496094,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 4.2049369317217105,
      "attention_bam_16_attention_skewness": 1.54623058142017,
      "attention_bam_16_attention_sparsity": 0.535400390625,
      "attention_bam_16_attention_concentration_10": 0.8970474472040738,
      "attention_bam_16_attention_concentration_20": 1.3440711666772776,
      "attention_bam_16_attention_center_y": 0.48550211998313936,
      "attention_bam_16_attention_center_x": 0.4703604356588288,
      "attention_bam_16_attention_center_distance": 0.046662453842842753,
      "attention_bam_16_attention_spatial_variance": 43.23763690006962,
      "attention_bam_16_attention_spatial_std": 6.575533202719732,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.391829329630342,
      "attention_bam_16_peak_intensity_mean": 0.24175667762756348,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 315,
      "phase": "train",
      "loss": 0.007649317383766174,
      "timestamp": 1759543932.9954746,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007649317383766174,
      "ssim": 0.8753081560134888,
      "attention_bam_384_mean_attention": 0.09671030193567276,
      "attention_bam_384_std_attention": 0.4016275703907013,
      "attention_bam_384_max_attention": 3.8165459632873535,
      "attention_bam_384_min_attention": -1.2250139713287354,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.1180975518954366,
      "attention_bam_384_attention_skewness": 0.7714645655272481,
      "attention_bam_384_attention_sparsity": 0.5312728881835938,
      "attention_bam_384_attention_concentration_10": 0.910836247678026,
      "attention_bam_384_attention_concentration_20": 1.4106965481264329,
      "attention_bam_384_attention_center_y": 0.4820048922369313,
      "attention_bam_384_attention_center_x": 0.4836199075749859,
      "attention_bam_384_attention_center_distance": 0.0344131175936287,
      "attention_bam_384_attention_spatial_variance": 169.36651649800828,
      "attention_bam_384_attention_spatial_std": 13.014089153606113,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 15.004061311842012,
      "attention_bam_384_peak_intensity_mean": 0.2662352919578552,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.190434992313385,
      "attention_bam_16_std_attention": 0.598889172077179,
      "attention_bam_16_max_attention": 4.158914089202881,
      "attention_bam_16_min_attention": -1.067198634147644,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.812544620235899,
      "attention_bam_16_attention_skewness": 0.9206601800277174,
      "attention_bam_16_attention_sparsity": 0.4912109375,
      "attention_bam_16_attention_concentration_10": 0.726927084416226,
      "attention_bam_16_attention_concentration_20": 1.1496269603720446,
      "attention_bam_16_attention_center_y": 0.4627373477555487,
      "attention_bam_16_attention_center_x": 0.46913475623322015,
      "attention_bam_16_attention_center_distance": 0.0684276044454817,
      "attention_bam_16_attention_spatial_variance": 41.330883929848426,
      "attention_bam_16_attention_spatial_std": 6.428910011024297,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 10.262552611070426,
      "attention_bam_16_peak_intensity_mean": 0.24415259063243866,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 316,
      "phase": "train",
      "loss": 0.0069442810490727425,
      "timestamp": 1759543933.1372695,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0069442810490727425,
      "ssim": 0.8758020401000977,
      "attention_bam_384_mean_attention": 0.09642928093671799,
      "attention_bam_384_std_attention": 0.36784645915031433,
      "attention_bam_384_max_attention": 3.1968283653259277,
      "attention_bam_384_min_attention": -1.1776516437530518,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1987022746277844,
      "attention_bam_384_attention_skewness": 0.7718616048022384,
      "attention_bam_384_attention_sparsity": 0.54681396484375,
      "attention_bam_384_attention_concentration_10": 0.8715902695495714,
      "attention_bam_384_attention_concentration_20": 1.3463223902113801,
      "attention_bam_384_attention_center_y": 0.48524802388238625,
      "attention_bam_384_attention_center_x": 0.48759675174740896,
      "attention_bam_384_attention_center_distance": 0.027256608981678154,
      "attention_bam_384_attention_spatial_variance": 169.92439549092092,
      "attention_bam_384_attention_spatial_std": 13.035505187407235,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 18.64228343448826,
      "attention_bam_384_peak_intensity_mean": 0.29236268997192383,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1831822693347931,
      "attention_bam_16_std_attention": 0.5537464022636414,
      "attention_bam_16_max_attention": 2.6980340480804443,
      "attention_bam_16_min_attention": -1.0180402994155884,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7181601966173758,
      "attention_bam_16_attention_skewness": 0.8448108181210033,
      "attention_bam_16_attention_sparsity": 0.507080078125,
      "attention_bam_16_attention_concentration_10": 0.7186492579432631,
      "attention_bam_16_attention_concentration_20": 1.1390741545915208,
      "attention_bam_16_attention_center_y": 0.4734282091557869,
      "attention_bam_16_attention_center_x": 0.4816132243391445,
      "attention_bam_16_attention_center_distance": 0.04569756203280945,
      "attention_bam_16_attention_spatial_variance": 42.13612009231072,
      "attention_bam_16_attention_spatial_std": 6.491234096249396,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.490760991641697,
      "attention_bam_16_peak_intensity_mean": 0.33133333921432495,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 317,
      "phase": "train",
      "loss": 0.011572396382689476,
      "timestamp": 1759543933.2820954,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.011572396382689476,
      "ssim": 0.8122907280921936,
      "attention_bam_384_mean_attention": 0.09389214962720871,
      "attention_bam_384_std_attention": 0.4011494815349579,
      "attention_bam_384_max_attention": 3.5551488399505615,
      "attention_bam_384_min_attention": -1.0945457220077515,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.7200562487447497,
      "attention_bam_384_attention_skewness": 0.8104278280415717,
      "attention_bam_384_attention_sparsity": 0.5384648640950521,
      "attention_bam_384_attention_concentration_10": 0.9422653119456987,
      "attention_bam_384_attention_concentration_20": 1.4603703351413646,
      "attention_bam_384_attention_center_y": 0.4836956585580563,
      "attention_bam_384_attention_center_x": 0.48047056610430194,
      "attention_bam_384_attention_center_distance": 0.03597861415179643,
      "attention_bam_384_attention_spatial_variance": 171.56725764980624,
      "attention_bam_384_attention_spatial_std": 13.09836851099427,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 16.240091708971484,
      "attention_bam_384_peak_intensity_mean": 0.25650784373283386,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1757974475622177,
      "attention_bam_16_std_attention": 0.5930270552635193,
      "attention_bam_16_max_attention": 3.752368211746216,
      "attention_bam_16_min_attention": -0.9870695471763611,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.1966026449790776,
      "attention_bam_16_attention_skewness": 1.072723374673734,
      "attention_bam_16_attention_sparsity": 0.509033203125,
      "attention_bam_16_attention_concentration_10": 0.786286274099666,
      "attention_bam_16_attention_concentration_20": 1.2302556111610499,
      "attention_bam_16_attention_center_y": 0.46564311042074635,
      "attention_bam_16_attention_center_x": 0.4559261423177425,
      "attention_bam_16_attention_center_distance": 0.07903038393626742,
      "attention_bam_16_attention_spatial_variance": 43.109430366848635,
      "attention_bam_16_attention_spatial_std": 6.5657772096568,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.872344724309295,
      "attention_bam_16_peak_intensity_mean": 0.24794892966747284,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 318,
      "phase": "train",
      "loss": 0.008895015344023705,
      "timestamp": 1759543933.4183602,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008895015344023705,
      "ssim": 0.8590158820152283,
      "attention_bam_384_mean_attention": 0.0970078706741333,
      "attention_bam_384_std_attention": 0.3615143895149231,
      "attention_bam_384_max_attention": 2.820298671722412,
      "attention_bam_384_min_attention": -1.0505549907684326,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.675045546432941,
      "attention_bam_384_attention_skewness": 0.6017587864744636,
      "attention_bam_384_attention_sparsity": 0.5428466796875,
      "attention_bam_384_attention_concentration_10": 0.8279904460070668,
      "attention_bam_384_attention_concentration_20": 1.3140711257151094,
      "attention_bam_384_attention_center_y": 0.4737477436421734,
      "attention_bam_384_attention_center_x": 0.4784980454292639,
      "attention_bam_384_attention_center_distance": 0.047989895066337565,
      "attention_bam_384_attention_spatial_variance": 171.97298680083273,
      "attention_bam_384_attention_spatial_std": 13.113847139601434,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 18.587067501544038,
      "attention_bam_384_peak_intensity_mean": 0.30140429735183716,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19380563497543335,
      "attention_bam_16_std_attention": 0.5415396690368652,
      "attention_bam_16_max_attention": 3.0574395656585693,
      "attention_bam_16_min_attention": -1.0103960037231445,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.33976907954730606,
      "attention_bam_16_attention_skewness": 0.6882001414253147,
      "attention_bam_16_attention_sparsity": 0.485107421875,
      "attention_bam_16_attention_concentration_10": 0.6468368322539421,
      "attention_bam_16_attention_concentration_20": 1.0566947325101645,
      "attention_bam_16_attention_center_y": 0.4391900072765296,
      "attention_bam_16_attention_center_x": 0.45421777749150377,
      "attention_bam_16_attention_center_distance": 0.10764633865437298,
      "attention_bam_16_attention_spatial_variance": 42.87698686086401,
      "attention_bam_16_attention_spatial_std": 6.54805214249734,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.224671931460255,
      "attention_bam_16_peak_intensity_mean": 0.31693655252456665,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 319,
      "phase": "train",
      "loss": 0.005566577892750502,
      "timestamp": 1759543933.5599625,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005566577892750502,
      "ssim": 0.9093701839447021,
      "attention_bam_384_mean_attention": 0.09281406551599503,
      "attention_bam_384_std_attention": 0.4109036922454834,
      "attention_bam_384_max_attention": 2.5220370292663574,
      "attention_bam_384_min_attention": -1.147373914718628,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7899345471025945,
      "attention_bam_384_attention_skewness": 0.7086524661328013,
      "attention_bam_384_attention_sparsity": 0.5478642781575521,
      "attention_bam_384_attention_concentration_10": 0.9821185340419039,
      "attention_bam_384_attention_concentration_20": 1.5280742633227002,
      "attention_bam_384_attention_center_y": 0.48400126837996627,
      "attention_bam_384_attention_center_x": 0.48687905543643945,
      "attention_bam_384_attention_center_distance": 0.02926153104982364,
      "attention_bam_384_attention_spatial_variance": 168.53783845270118,
      "attention_bam_384_attention_spatial_std": 12.98221238667359,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 15.759959398581637,
      "attention_bam_384_peak_intensity_mean": 0.3402157723903656,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1607854664325714,
      "attention_bam_16_std_attention": 0.6087384223937988,
      "attention_bam_16_max_attention": 2.8442935943603516,
      "attention_bam_16_min_attention": -1.05502450466156,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7090638322575682,
      "attention_bam_16_attention_skewness": 0.8901633150794632,
      "attention_bam_16_attention_sparsity": 0.53515625,
      "attention_bam_16_attention_concentration_10": 0.8736929026672389,
      "attention_bam_16_attention_concentration_20": 1.3794171154354948,
      "attention_bam_16_attention_center_y": 0.466769100887165,
      "attention_bam_16_attention_center_x": 0.4775241610281047,
      "attention_bam_16_attention_center_distance": 0.05673545616874841,
      "attention_bam_16_attention_spatial_variance": 41.30051881561326,
      "attention_bam_16_attention_spatial_std": 6.426547970381398,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 6.048118907460013,
      "attention_bam_16_peak_intensity_mean": 0.31991755962371826,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 320,
      "phase": "train",
      "loss": 0.009501512162387371,
      "timestamp": 1759543933.757881,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.009501512162387371,
      "ssim": 0.855942964553833,
      "attention_bam_384_mean_attention": 0.09432224184274673,
      "attention_bam_384_std_attention": 0.3806054890155792,
      "attention_bam_384_max_attention": 2.535313844680786,
      "attention_bam_384_min_attention": -1.1325438022613525,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5830122419886137,
      "attention_bam_384_attention_skewness": 0.6025779292189064,
      "attention_bam_384_attention_sparsity": 0.5425745646158854,
      "attention_bam_384_attention_concentration_10": 0.8859839735229194,
      "attention_bam_384_attention_concentration_20": 1.4054975213766123,
      "attention_bam_384_attention_center_y": 0.48209806097709934,
      "attention_bam_384_attention_center_x": 0.48394859014632885,
      "attention_bam_384_attention_center_distance": 0.034003740355148714,
      "attention_bam_384_attention_spatial_variance": 170.6222928515414,
      "attention_bam_384_attention_spatial_std": 13.062246853108443,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 19.14678019444598,
      "attention_bam_384_peak_intensity_mean": 0.3417705297470093,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17407235503196716,
      "attention_bam_16_std_attention": 0.5638018250465393,
      "attention_bam_16_max_attention": 2.6516168117523193,
      "attention_bam_16_min_attention": -0.9478774666786194,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.37963695378507145,
      "attention_bam_16_attention_skewness": 0.7031574972073696,
      "attention_bam_16_attention_sparsity": 0.502197265625,
      "attention_bam_16_attention_concentration_10": 0.7496304935145413,
      "attention_bam_16_attention_concentration_20": 1.191393996010272,
      "attention_bam_16_attention_center_y": 0.46297855758452594,
      "attention_bam_16_attention_center_x": 0.46795508170320704,
      "attention_bam_16_attention_center_distance": 0.06924541843574053,
      "attention_bam_16_attention_spatial_variance": 42.5279041723935,
      "attention_bam_16_attention_spatial_std": 6.521342206355491,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.842475957996966,
      "attention_bam_16_peak_intensity_mean": 0.3275522291660309,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 321,
      "phase": "train",
      "loss": 0.007429942488670349,
      "timestamp": 1759543933.9051833,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007429942488670349,
      "ssim": 0.8911676406860352,
      "attention_bam_384_mean_attention": 0.09528674930334091,
      "attention_bam_384_std_attention": 0.38562554121017456,
      "attention_bam_384_max_attention": 2.930536985397339,
      "attention_bam_384_min_attention": -1.2329453229904175,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.7341139545810886,
      "attention_bam_384_attention_skewness": 0.8284246046937016,
      "attention_bam_384_attention_sparsity": 0.5479965209960938,
      "attention_bam_384_attention_concentration_10": 0.9013623817981935,
      "attention_bam_384_attention_concentration_20": 1.4023398754650978,
      "attention_bam_384_attention_center_y": 0.4822116014907052,
      "attention_bam_384_attention_center_x": 0.48338092811819583,
      "attention_bam_384_attention_center_distance": 0.034427334248763895,
      "attention_bam_384_attention_spatial_variance": 172.30248076484824,
      "attention_bam_384_attention_spatial_std": 13.12640395404805,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 18.514444097851467,
      "attention_bam_384_peak_intensity_mean": 0.32092443108558655,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17938515543937683,
      "attention_bam_16_std_attention": 0.5732483267784119,
      "attention_bam_16_max_attention": 3.628350257873535,
      "attention_bam_16_min_attention": -1.0376174449920654,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.009503832673194,
      "attention_bam_16_attention_skewness": 1.0016952480653674,
      "attention_bam_16_attention_sparsity": 0.497802734375,
      "attention_bam_16_attention_concentration_10": 0.7515728505187563,
      "attention_bam_16_attention_concentration_20": 1.1636477273191912,
      "attention_bam_16_attention_center_y": 0.4630887491337735,
      "attention_bam_16_attention_center_x": 0.46652749963171586,
      "attention_bam_16_attention_center_distance": 0.07046770496354039,
      "attention_bam_16_attention_spatial_variance": 43.90066300685409,
      "attention_bam_16_attention_spatial_std": 6.6257575421120025,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.197247968037585,
      "attention_bam_16_peak_intensity_mean": 0.262064665555954,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 322,
      "phase": "train",
      "loss": 0.010180985555052757,
      "timestamp": 1759543934.0445876,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.010180985555052757,
      "ssim": 0.8464313745498657,
      "attention_bam_384_mean_attention": 0.09292592853307724,
      "attention_bam_384_std_attention": 0.4124753475189209,
      "attention_bam_384_max_attention": 3.1134238243103027,
      "attention_bam_384_min_attention": -1.1121301651000977,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.867753864549144,
      "attention_bam_384_attention_skewness": 1.1406371116346947,
      "attention_bam_384_attention_sparsity": 0.5622914632161459,
      "attention_bam_384_attention_concentration_10": 1.024402436116856,
      "attention_bam_384_attention_concentration_20": 1.5273229330469842,
      "attention_bam_384_attention_center_y": 0.4889513724177725,
      "attention_bam_384_attention_center_x": 0.4963852482828458,
      "attention_bam_384_attention_center_distance": 0.01644010957551244,
      "attention_bam_384_attention_spatial_variance": 168.5512668809679,
      "attention_bam_384_attention_spatial_std": 12.98272956203617,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 12.905313878602078,
      "attention_bam_384_peak_intensity_mean": 0.29265302419662476,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16318386793136597,
      "attention_bam_16_std_attention": 0.6259188652038574,
      "attention_bam_16_max_attention": 3.7562713623046875,
      "attention_bam_16_min_attention": -1.0593708753585815,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.063834671165793,
      "attention_bam_16_attention_skewness": 1.345770539597791,
      "attention_bam_16_attention_sparsity": 0.526611328125,
      "attention_bam_16_attention_concentration_10": 0.9181584215635246,
      "attention_bam_16_attention_concentration_20": 1.375321931579985,
      "attention_bam_16_attention_center_y": 0.48177407093067975,
      "attention_bam_16_attention_center_x": 0.49802551385786914,
      "attention_bam_16_attention_center_distance": 0.025926167706213716,
      "attention_bam_16_attention_spatial_variance": 41.57487034383431,
      "attention_bam_16_attention_spatial_std": 6.447857810454129,
      "attention_bam_16_num_attention_peaks": 2,
      "attention_bam_16_peak_separation_mean": 7.491295796283472,
      "attention_bam_16_peak_intensity_mean": 0.2744041681289673,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 323,
      "phase": "train",
      "loss": 0.008075258694589138,
      "timestamp": 1759543934.1811843,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008075258694589138,
      "ssim": 0.8476390838623047,
      "attention_bam_384_mean_attention": 0.09514684230089188,
      "attention_bam_384_std_attention": 0.39939478039741516,
      "attention_bam_384_max_attention": 3.0061354637145996,
      "attention_bam_384_min_attention": -1.1926391124725342,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9079850487806969,
      "attention_bam_384_attention_skewness": 0.6674470530055511,
      "attention_bam_384_attention_sparsity": 0.5394846598307291,
      "attention_bam_384_attention_concentration_10": 0.9244793817363636,
      "attention_bam_384_attention_concentration_20": 1.4493007002129707,
      "attention_bam_384_attention_center_y": 0.48421586061398075,
      "attention_bam_384_attention_center_x": 0.48085203333359133,
      "attention_bam_384_attention_center_distance": 0.035093694123451334,
      "attention_bam_384_attention_spatial_variance": 170.07198784742818,
      "attention_bam_384_attention_spatial_std": 13.041165126146826,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 15.234716044730968,
      "attention_bam_384_peak_intensity_mean": 0.30857256054878235,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17372119426727295,
      "attention_bam_16_std_attention": 0.5739588737487793,
      "attention_bam_16_max_attention": 2.9466335773468018,
      "attention_bam_16_min_attention": -1.0511895418167114,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8778297002077204,
      "attention_bam_16_attention_skewness": 0.7689276036935783,
      "attention_bam_16_attention_sparsity": 0.492431640625,
      "attention_bam_16_attention_concentration_10": 0.7612270025056356,
      "attention_bam_16_attention_concentration_20": 1.2016106730251317,
      "attention_bam_16_attention_center_y": 0.4695364975302883,
      "attention_bam_16_attention_center_x": 0.4619051060588441,
      "attention_bam_16_attention_center_distance": 0.06898182263625753,
      "attention_bam_16_attention_spatial_variance": 42.34065896559687,
      "attention_bam_16_attention_spatial_std": 6.506970029560369,
      "attention_bam_16_num_attention_peaks": 12,
      "attention_bam_16_peak_separation_mean": 7.640661948722642,
      "attention_bam_16_peak_intensity_mean": 0.30986180901527405,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 324,
      "phase": "train",
      "loss": 0.006482596974819899,
      "timestamp": 1759543934.3204715,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006482596974819899,
      "ssim": 0.8684033751487732,
      "attention_bam_384_mean_attention": 0.09400641173124313,
      "attention_bam_384_std_attention": 0.39586517214775085,
      "attention_bam_384_max_attention": 3.731178045272827,
      "attention_bam_384_min_attention": -1.2017889022827148,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.870503819408187,
      "attention_bam_384_attention_skewness": 1.037790299044064,
      "attention_bam_384_attention_sparsity": 0.5571645100911459,
      "attention_bam_384_attention_concentration_10": 0.9606001059915535,
      "attention_bam_384_attention_concentration_20": 1.4564059264531233,
      "attention_bam_384_attention_center_y": 0.48473577648691357,
      "attention_bam_384_attention_center_x": 0.48129660560762166,
      "attention_bam_384_attention_center_distance": 0.03414127945037532,
      "attention_bam_384_attention_spatial_variance": 168.35839114984108,
      "attention_bam_384_attention_spatial_std": 12.975299270145605,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 15.660902555725723,
      "attention_bam_384_peak_intensity_mean": 0.2639843821525574,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1721917986869812,
      "attention_bam_16_std_attention": 0.6230858564376831,
      "attention_bam_16_max_attention": 4.4362030029296875,
      "attention_bam_16_min_attention": -1.205179214477539,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.4866633230509905,
      "attention_bam_16_attention_skewness": 1.2859660703789468,
      "attention_bam_16_attention_sparsity": 0.505126953125,
      "attention_bam_16_attention_concentration_10": 0.8518505665878621,
      "attention_bam_16_attention_concentration_20": 1.2964355970724133,
      "attention_bam_16_attention_center_y": 0.4698127136268323,
      "attention_bam_16_attention_center_x": 0.46167243345376496,
      "attention_bam_16_attention_center_distance": 0.06899673348690807,
      "attention_bam_16_attention_spatial_variance": 41.018491966166174,
      "attention_bam_16_attention_spatial_std": 6.404568054612752,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.052585891648933,
      "attention_bam_16_peak_intensity_mean": 0.2533424198627472,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 325,
      "phase": "train",
      "loss": 0.0052403053268790245,
      "timestamp": 1759543934.46206,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0052403053268790245,
      "ssim": 0.9024872779846191,
      "attention_bam_384_mean_attention": 0.09396479278802872,
      "attention_bam_384_std_attention": 0.4220464527606964,
      "attention_bam_384_max_attention": 3.270840644836426,
      "attention_bam_384_min_attention": -1.3178515434265137,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.197911050879119,
      "attention_bam_384_attention_skewness": 0.7238942988804011,
      "attention_bam_384_attention_sparsity": 0.5400873819986979,
      "attention_bam_384_attention_concentration_10": 0.9809358601918138,
      "attention_bam_384_attention_concentration_20": 1.5272279609071262,
      "attention_bam_384_attention_center_y": 0.4839253724900123,
      "attention_bam_384_attention_center_x": 0.4842643194872622,
      "attention_bam_384_attention_center_distance": 0.031812113755103136,
      "attention_bam_384_attention_spatial_variance": 172.2493764672642,
      "attention_bam_384_attention_spatial_std": 13.124380993679823,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 19.93254035871246,
      "attention_bam_384_peak_intensity_mean": 0.3126530945301056,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.172644704580307,
      "attention_bam_16_std_attention": 0.6424238085746765,
      "attention_bam_16_max_attention": 3.555738925933838,
      "attention_bam_16_min_attention": -1.1410340070724487,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.839090242992616,
      "attention_bam_16_attention_skewness": 1.0211544391311405,
      "attention_bam_16_attention_sparsity": 0.503173828125,
      "attention_bam_16_attention_concentration_10": 0.8630882643484581,
      "attention_bam_16_attention_concentration_20": 1.3286123153724732,
      "attention_bam_16_attention_center_y": 0.4668570736364892,
      "attention_bam_16_attention_center_x": 0.4692447295807019,
      "attention_bam_16_attention_center_distance": 0.0639427904693133,
      "attention_bam_16_attention_spatial_variance": 43.5425702246109,
      "attention_bam_16_attention_spatial_std": 6.59867943035657,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.786336642047123,
      "attention_bam_16_peak_intensity_mean": 0.2812098264694214,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 326,
      "phase": "train",
      "loss": 0.006170285400003195,
      "timestamp": 1759543934.5944455,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006170285400003195,
      "ssim": 0.906389057636261,
      "attention_bam_384_mean_attention": 0.09333812445402145,
      "attention_bam_384_std_attention": 0.3934215307235718,
      "attention_bam_384_max_attention": 2.9647397994995117,
      "attention_bam_384_min_attention": -1.1423496007919312,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8026512567751518,
      "attention_bam_384_attention_skewness": 0.571045733502942,
      "attention_bam_384_attention_sparsity": 0.5375442504882812,
      "attention_bam_384_attention_concentration_10": 0.90747332589495,
      "attention_bam_384_attention_concentration_20": 1.4392308074638127,
      "attention_bam_384_attention_center_y": 0.4784561794298212,
      "attention_bam_384_attention_center_x": 0.4797434684858807,
      "attention_bam_384_attention_center_distance": 0.04182016914701727,
      "attention_bam_384_attention_spatial_variance": 169.5795575259305,
      "attention_bam_384_attention_spatial_std": 13.022271596228153,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 18.771133250208848,
      "attention_bam_384_peak_intensity_mean": 0.3052953779697418,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17431873083114624,
      "attention_bam_16_std_attention": 0.580204427242279,
      "attention_bam_16_max_attention": 2.817138671875,
      "attention_bam_16_min_attention": -1.213789463043213,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6689445822628146,
      "attention_bam_16_attention_skewness": 0.7341548631761677,
      "attention_bam_16_attention_sparsity": 0.49365234375,
      "attention_bam_16_attention_concentration_10": 0.7604590124365941,
      "attention_bam_16_attention_concentration_20": 1.211230028332377,
      "attention_bam_16_attention_center_y": 0.45729912782767496,
      "attention_bam_16_attention_center_x": 0.4594977236493254,
      "attention_bam_16_attention_center_distance": 0.08323219177534204,
      "attention_bam_16_attention_spatial_variance": 41.78270165671221,
      "attention_bam_16_attention_spatial_std": 6.463954026500514,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.59915885315012,
      "attention_bam_16_peak_intensity_mean": 0.35275954008102417,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 327,
      "phase": "train",
      "loss": 0.010269638150930405,
      "timestamp": 1759543934.7324421,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.010269638150930405,
      "ssim": 0.878352165222168,
      "attention_bam_384_mean_attention": 0.09272342920303345,
      "attention_bam_384_std_attention": 0.37386730313301086,
      "attention_bam_384_max_attention": 2.775155544281006,
      "attention_bam_384_min_attention": -1.24443781375885,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2512170745936633,
      "attention_bam_384_attention_skewness": 0.5982990171830613,
      "attention_bam_384_attention_sparsity": 0.5381647745768229,
      "attention_bam_384_attention_concentration_10": 0.8741715365775011,
      "attention_bam_384_attention_concentration_20": 1.382637553693993,
      "attention_bam_384_attention_center_y": 0.47983675332333264,
      "attention_bam_384_attention_center_x": 0.4816882326587157,
      "attention_bam_384_attention_center_distance": 0.03851953633431908,
      "attention_bam_384_attention_spatial_variance": 170.2070488842654,
      "attention_bam_384_attention_spatial_std": 13.046342356548267,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 17.174954969722297,
      "attention_bam_384_peak_intensity_mean": 0.3331241011619568,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17648935317993164,
      "attention_bam_16_std_attention": 0.58632892370224,
      "attention_bam_16_max_attention": 3.2893617153167725,
      "attention_bam_16_min_attention": -1.2125067710876465,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8076757078122285,
      "attention_bam_16_attention_skewness": 0.7288257034265504,
      "attention_bam_16_attention_sparsity": 0.49609375,
      "attention_bam_16_attention_concentration_10": 0.7541767139375579,
      "attention_bam_16_attention_concentration_20": 1.2046244511822555,
      "attention_bam_16_attention_center_y": 0.4559215442521609,
      "attention_bam_16_attention_center_x": 0.46410560744558466,
      "attention_bam_16_attention_center_distance": 0.08039051782349305,
      "attention_bam_16_attention_spatial_variance": 42.13098162977623,
      "attention_bam_16_attention_spatial_std": 6.490838284056708,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.16153868667524,
      "attention_bam_16_peak_intensity_mean": 0.30974194407463074,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 328,
      "phase": "train",
      "loss": 0.005208837799727917,
      "timestamp": 1759543934.870527,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005208837799727917,
      "ssim": 0.900772750377655,
      "attention_bam_384_mean_attention": 0.08812279254198074,
      "attention_bam_384_std_attention": 0.3901391327381134,
      "attention_bam_384_max_attention": 3.6727874279022217,
      "attention_bam_384_min_attention": -1.194007158279419,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.8035378100371497,
      "attention_bam_384_attention_skewness": 0.9862798527932197,
      "attention_bam_384_attention_sparsity": 0.5526707967122396,
      "attention_bam_384_attention_concentration_10": 0.9874828804973877,
      "attention_bam_384_attention_concentration_20": 1.5031116375861417,
      "attention_bam_384_attention_center_y": 0.47949213912384003,
      "attention_bam_384_attention_center_x": 0.4835430235590473,
      "attention_bam_384_attention_center_distance": 0.03718613804347001,
      "attention_bam_384_attention_spatial_variance": 171.57583124651026,
      "attention_bam_384_attention_spatial_std": 13.098695784180586,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 18.775132233260003,
      "attention_bam_384_peak_intensity_mean": 0.2660940885543823,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.15912029147148132,
      "attention_bam_16_std_attention": 0.587425172328949,
      "attention_bam_16_max_attention": 4.437987327575684,
      "attention_bam_16_min_attention": -0.9761785268783569,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.512590934905152,
      "attention_bam_16_attention_skewness": 1.201982556595764,
      "attention_bam_16_attention_sparsity": 0.5068359375,
      "attention_bam_16_attention_concentration_10": 0.8425534879593141,
      "attention_bam_16_attention_concentration_20": 1.2934384628484057,
      "attention_bam_16_attention_center_y": 0.45588687505444053,
      "attention_bam_16_attention_center_x": 0.4663012196620001,
      "attention_bam_16_attention_center_distance": 0.07850573977399752,
      "attention_bam_16_attention_spatial_variance": 43.216743607559565,
      "attention_bam_16_attention_spatial_std": 6.5739442960493335,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 10.012113889706344,
      "attention_bam_16_peak_intensity_mean": 0.2148776650428772,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 329,
      "phase": "train",
      "loss": 0.006177545990794897,
      "timestamp": 1759543935.0066097,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006177545990794897,
      "ssim": 0.882239580154419,
      "attention_bam_384_mean_attention": 0.08891400694847107,
      "attention_bam_384_std_attention": 0.37263697385787964,
      "attention_bam_384_max_attention": 2.645338535308838,
      "attention_bam_384_min_attention": -1.0927612781524658,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.271602191515182,
      "attention_bam_384_attention_skewness": 0.8027398790985455,
      "attention_bam_384_attention_sparsity": 0.55810546875,
      "attention_bam_384_attention_concentration_10": 0.940036715771592,
      "attention_bam_384_attention_concentration_20": 1.4590766400115063,
      "attention_bam_384_attention_center_y": 0.48211743688594283,
      "attention_bam_384_attention_center_x": 0.48599269099207715,
      "attention_bam_384_attention_center_distance": 0.03212446946399814,
      "attention_bam_384_attention_spatial_variance": 167.914707329859,
      "attention_bam_384_attention_spatial_std": 12.95819074291851,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 16.270694658827217,
      "attention_bam_384_peak_intensity_mean": 0.3194180727005005,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16059035062789917,
      "attention_bam_16_std_attention": 0.5793417096138,
      "attention_bam_16_max_attention": 3.1218011379241943,
      "attention_bam_16_min_attention": -1.0868051052093506,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.5058991993425357,
      "attention_bam_16_attention_skewness": 1.018261148796551,
      "attention_bam_16_attention_sparsity": 0.520263671875,
      "attention_bam_16_attention_concentration_10": 0.843873213364207,
      "attention_bam_16_attention_concentration_20": 1.31205463169883,
      "attention_bam_16_attention_center_y": 0.4636398289532189,
      "attention_bam_16_attention_center_x": 0.4750132629661918,
      "attention_bam_16_attention_center_distance": 0.062392292250691664,
      "attention_bam_16_attention_spatial_variance": 40.54538159439949,
      "attention_bam_16_attention_spatial_std": 6.367525547212158,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.24986609118634,
      "attention_bam_16_peak_intensity_mean": 0.298586905002594,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 330,
      "phase": "train",
      "loss": 0.008019557222723961,
      "timestamp": 1759543935.1889968,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008019557222723961,
      "ssim": 0.8900588154792786,
      "attention_bam_384_mean_attention": 0.09124460816383362,
      "attention_bam_384_std_attention": 0.3749200403690338,
      "attention_bam_384_max_attention": 3.071434259414673,
      "attention_bam_384_min_attention": -1.3176020383834839,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1877946461810422,
      "attention_bam_384_attention_skewness": 0.7267012314635477,
      "attention_bam_384_attention_sparsity": 0.5515619913736979,
      "attention_bam_384_attention_concentration_10": 0.9158068120537247,
      "attention_bam_384_attention_concentration_20": 1.4304651407625184,
      "attention_bam_384_attention_center_y": 0.49006075785819875,
      "attention_bam_384_attention_center_x": 0.4879769278150901,
      "attention_bam_384_attention_center_distance": 0.022060951888661185,
      "attention_bam_384_attention_spatial_variance": 171.84521902195024,
      "attention_bam_384_attention_spatial_std": 13.108974750984542,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 17.802732609949594,
      "attention_bam_384_peak_intensity_mean": 0.3224274516105652,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1700635552406311,
      "attention_bam_16_std_attention": 0.5917003750801086,
      "attention_bam_16_max_attention": 3.639392852783203,
      "attention_bam_16_min_attention": -1.042947769165039,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.1160613971778046,
      "attention_bam_16_attention_skewness": 0.905283092171684,
      "attention_bam_16_attention_sparsity": 0.51318359375,
      "attention_bam_16_attention_concentration_10": 0.8138816757109187,
      "attention_bam_16_attention_concentration_20": 1.2725418504629293,
      "attention_bam_16_attention_center_y": 0.49002490898177326,
      "attention_bam_16_attention_center_x": 0.482096622819842,
      "attention_bam_16_attention_center_distance": 0.028983904335920997,
      "attention_bam_16_attention_spatial_variance": 43.621395786371906,
      "attention_bam_16_attention_spatial_std": 6.604649558180351,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 10.530920962837023,
      "attention_bam_16_peak_intensity_mean": 0.26840561628341675,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 331,
      "phase": "train",
      "loss": 0.008668934926390648,
      "timestamp": 1759543935.3309753,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008668934926390648,
      "ssim": 0.8831793069839478,
      "attention_bam_384_mean_attention": 0.09198654443025589,
      "attention_bam_384_std_attention": 0.42207732796669006,
      "attention_bam_384_max_attention": 4.115329265594482,
      "attention_bam_384_min_attention": -1.406167984008789,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.222785614498415,
      "attention_bam_384_attention_skewness": 0.840698957912917,
      "attention_bam_384_attention_sparsity": 0.5444691975911459,
      "attention_bam_384_attention_concentration_10": 0.9973922393983464,
      "attention_bam_384_attention_concentration_20": 1.543752157879083,
      "attention_bam_384_attention_center_y": 0.4819350193750228,
      "attention_bam_384_attention_center_x": 0.48357427072369497,
      "attention_bam_384_attention_center_distance": 0.034529642547795523,
      "attention_bam_384_attention_spatial_variance": 170.86888039555083,
      "attention_bam_384_attention_spatial_std": 13.07168238581212,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 17.01880083117742,
      "attention_bam_384_peak_intensity_mean": 0.2718792259693146,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16673465073108673,
      "attention_bam_16_std_attention": 0.6448925733566284,
      "attention_bam_16_max_attention": 3.745587110519409,
      "attention_bam_16_min_attention": -1.2612749338150024,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.2631258341838176,
      "attention_bam_16_attention_skewness": 1.0829774780770554,
      "attention_bam_16_attention_sparsity": 0.50537109375,
      "attention_bam_16_attention_concentration_10": 0.8949673051254408,
      "attention_bam_16_attention_concentration_20": 1.367269014964108,
      "attention_bam_16_attention_center_y": 0.46098516000493733,
      "attention_bam_16_attention_center_x": 0.467696152796507,
      "attention_bam_16_attention_center_distance": 0.07163373903387933,
      "attention_bam_16_attention_spatial_variance": 42.660341538987375,
      "attention_bam_16_attention_spatial_std": 6.531488462746251,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.707855671498766,
      "attention_bam_16_peak_intensity_mean": 0.288750559091568,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 332,
      "phase": "train",
      "loss": 0.00806097686290741,
      "timestamp": 1759543935.4728467,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00806097686290741,
      "ssim": 0.8739746809005737,
      "attention_bam_384_mean_attention": 0.09164893627166748,
      "attention_bam_384_std_attention": 0.40441328287124634,
      "attention_bam_384_max_attention": 4.184585094451904,
      "attention_bam_384_min_attention": -1.1535589694976807,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.2901093403965387,
      "attention_bam_384_attention_skewness": 1.1337252206233,
      "attention_bam_384_attention_sparsity": 0.5572357177734375,
      "attention_bam_384_attention_concentration_10": 0.9929927146862454,
      "attention_bam_384_attention_concentration_20": 1.5056030533883609,
      "attention_bam_384_attention_center_y": 0.4843955704234548,
      "attention_bam_384_attention_center_x": 0.4883980171624549,
      "attention_bam_384_attention_center_distance": 0.027499244650428085,
      "attention_bam_384_attention_spatial_variance": 171.78095643224378,
      "attention_bam_384_attention_spatial_std": 13.106523430423637,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 16.6498125276844,
      "attention_bam_384_peak_intensity_mean": 0.2372186779975891,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.15928971767425537,
      "attention_bam_16_std_attention": 0.6254889965057373,
      "attention_bam_16_max_attention": 3.9524455070495605,
      "attention_bam_16_min_attention": -1.0327527523040771,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.7706421435310213,
      "attention_bam_16_attention_skewness": 1.4373426511810938,
      "attention_bam_16_attention_sparsity": 0.53173828125,
      "attention_bam_16_attention_concentration_10": 0.9244778550380339,
      "attention_bam_16_attention_concentration_20": 1.387030026493856,
      "attention_bam_16_attention_center_y": 0.46884637484054154,
      "attention_bam_16_attention_center_x": 0.48173871621395914,
      "attention_bam_16_attention_center_distance": 0.05106902869823083,
      "attention_bam_16_attention_spatial_variance": 43.45216794737722,
      "attention_bam_16_attention_spatial_std": 6.5918258432225905,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.969445726308479,
      "attention_bam_16_peak_intensity_mean": 0.2454664558172226,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 333,
      "phase": "train",
      "loss": 0.004555576480925083,
      "timestamp": 1759543935.6096683,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004555576480925083,
      "ssim": 0.9143176078796387,
      "attention_bam_384_mean_attention": 0.08738633990287781,
      "attention_bam_384_std_attention": 0.3996383249759674,
      "attention_bam_384_max_attention": 3.6296141147613525,
      "attention_bam_384_min_attention": -1.2253636121749878,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.4285126881420833,
      "attention_bam_384_attention_skewness": 1.0184863269636832,
      "attention_bam_384_attention_sparsity": 0.5617472330729166,
      "attention_bam_384_attention_concentration_10": 1.0297555975336103,
      "attention_bam_384_attention_concentration_20": 1.568109235877918,
      "attention_bam_384_attention_center_y": 0.4888884280563752,
      "attention_bam_384_attention_center_x": 0.4776463598070448,
      "attention_bam_384_attention_center_distance": 0.03530303842261887,
      "attention_bam_384_attention_spatial_variance": 171.32031626808651,
      "attention_bam_384_attention_spatial_std": 13.088938699072836,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 16.848505148503445,
      "attention_bam_384_peak_intensity_mean": 0.2725059390068054,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1410197913646698,
      "attention_bam_16_std_attention": 0.604537844657898,
      "attention_bam_16_max_attention": 3.94541597366333,
      "attention_bam_16_min_attention": -1.229792833328247,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.535344024082529,
      "attention_bam_16_attention_skewness": 1.3425235036181469,
      "attention_bam_16_attention_sparsity": 0.544189453125,
      "attention_bam_16_attention_concentration_10": 0.9949383315701347,
      "attention_bam_16_attention_concentration_20": 1.4998046213907819,
      "attention_bam_16_attention_center_y": 0.48028040846371567,
      "attention_bam_16_attention_center_x": 0.4549202262273805,
      "attention_bam_16_attention_center_distance": 0.06958517505544481,
      "attention_bam_16_attention_spatial_variance": 42.66207771030172,
      "attention_bam_16_attention_spatial_std": 6.531621369177926,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.860784808378444,
      "attention_bam_16_peak_intensity_mean": 0.26967695355415344,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 334,
      "phase": "train",
      "loss": 0.005239352583885193,
      "timestamp": 1759543935.9686992,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005239352583885193,
      "ssim": 0.904851496219635,
      "attention_bam_384_mean_attention": 0.08903732150793076,
      "attention_bam_384_std_attention": 0.3832722008228302,
      "attention_bam_384_max_attention": 2.8816258907318115,
      "attention_bam_384_min_attention": -1.134177803993225,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0592753694416164,
      "attention_bam_384_attention_skewness": 0.6834204167994993,
      "attention_bam_384_attention_sparsity": 0.5466435750325521,
      "attention_bam_384_attention_concentration_10": 0.9412525564023693,
      "attention_bam_384_attention_concentration_20": 1.4791072869046598,
      "attention_bam_384_attention_center_y": 0.4870297932518147,
      "attention_bam_384_attention_center_x": 0.4878743431889348,
      "attention_bam_384_attention_center_distance": 0.025110070338029825,
      "attention_bam_384_attention_spatial_variance": 171.17179047094558,
      "attention_bam_384_attention_spatial_std": 13.083263754543268,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 17.25927438640002,
      "attention_bam_384_peak_intensity_mean": 0.30748075246810913,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.162319615483284,
      "attention_bam_16_std_attention": 0.5804268717765808,
      "attention_bam_16_max_attention": 3.81874942779541,
      "attention_bam_16_min_attention": -1.0346177816390991,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.615670558091253,
      "attention_bam_16_attention_skewness": 0.943324545185436,
      "attention_bam_16_attention_sparsity": 0.50830078125,
      "attention_bam_16_attention_concentration_10": 0.8253131229458671,
      "attention_bam_16_attention_concentration_20": 1.2891134145918068,
      "attention_bam_16_attention_center_y": 0.47680520192372183,
      "attention_bam_16_attention_center_x": 0.4807430414157055,
      "attention_bam_16_attention_center_distance": 0.04263400313638283,
      "attention_bam_16_attention_spatial_variance": 42.978156176807815,
      "attention_bam_16_attention_spatial_std": 6.555772736818126,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.370675693902186,
      "attention_bam_16_peak_intensity_mean": 0.2484089881181717,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 335,
      "phase": "train",
      "loss": 0.004746016580611467,
      "timestamp": 1759543936.1036563,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004746016580611467,
      "ssim": 0.9147676825523376,
      "attention_bam_384_mean_attention": 0.0891038104891777,
      "attention_bam_384_std_attention": 0.3993186056613922,
      "attention_bam_384_max_attention": 3.502383232116699,
      "attention_bam_384_min_attention": -1.090889573097229,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.3479895990525037,
      "attention_bam_384_attention_skewness": 0.7059854928846768,
      "attention_bam_384_attention_sparsity": 0.5410130818684896,
      "attention_bam_384_attention_concentration_10": 0.9719739699598642,
      "attention_bam_384_attention_concentration_20": 1.5176766598471858,
      "attention_bam_384_attention_center_y": 0.4845126787112122,
      "attention_bam_384_attention_center_x": 0.4855736496973102,
      "attention_bam_384_attention_center_distance": 0.029932480811254467,
      "attention_bam_384_attention_spatial_variance": 168.9946447972368,
      "attention_bam_384_attention_spatial_std": 12.999794029031259,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 19.62407303538866,
      "attention_bam_384_peak_intensity_mean": 0.2615909278392792,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1596144437789917,
      "attention_bam_16_std_attention": 0.5978543162345886,
      "attention_bam_16_max_attention": 3.0186986923217773,
      "attention_bam_16_min_attention": -1.0243602991104126,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.0765437338423514,
      "attention_bam_16_attention_skewness": 0.9277873512362843,
      "attention_bam_16_attention_sparsity": 0.53173828125,
      "attention_bam_16_attention_concentration_10": 0.8762055218049277,
      "attention_bam_16_attention_concentration_20": 1.3664206579159948,
      "attention_bam_16_attention_center_y": 0.4728546184045944,
      "attention_bam_16_attention_center_x": 0.47332659445599745,
      "attention_bam_16_attention_center_distance": 0.05382085665009448,
      "attention_bam_16_attention_spatial_variance": 41.588754270699866,
      "attention_bam_16_attention_spatial_std": 6.448934351557617,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.946710505959805,
      "attention_bam_16_peak_intensity_mean": 0.31240788102149963,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 336,
      "phase": "train",
      "loss": 0.005105280317366123,
      "timestamp": 1759543936.2368996,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005105280317366123,
      "ssim": 0.9027783274650574,
      "attention_bam_384_mean_attention": 0.09129404276609421,
      "attention_bam_384_std_attention": 0.38376331329345703,
      "attention_bam_384_max_attention": 4.16811466217041,
      "attention_bam_384_min_attention": -1.1542398929595947,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.5268840632966443,
      "attention_bam_384_attention_skewness": 0.8193258465704448,
      "attention_bam_384_attention_sparsity": 0.5433883666992188,
      "attention_bam_384_attention_concentration_10": 0.9154080012759205,
      "attention_bam_384_attention_concentration_20": 1.4309540445171016,
      "attention_bam_384_attention_center_y": 0.48080410368279286,
      "attention_bam_384_attention_center_x": 0.4828387088831386,
      "attention_bam_384_attention_center_distance": 0.03641407278013904,
      "attention_bam_384_attention_spatial_variance": 170.4030358131676,
      "attention_bam_384_attention_spatial_std": 13.053851378546012,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 17.918354461264123,
      "attention_bam_384_peak_intensity_mean": 0.2362593412399292,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17544913291931152,
      "attention_bam_16_std_attention": 0.5817890167236328,
      "attention_bam_16_max_attention": 5.181231498718262,
      "attention_bam_16_min_attention": -1.0618184804916382,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 4.122707920033819,
      "attention_bam_16_attention_skewness": 1.1742592905983469,
      "attention_bam_16_attention_sparsity": 0.49853515625,
      "attention_bam_16_attention_concentration_10": 0.7584292832897356,
      "attention_bam_16_attention_concentration_20": 1.1922399430724981,
      "attention_bam_16_attention_center_y": 0.4588078901278783,
      "attention_bam_16_attention_center_x": 0.4655626686525157,
      "attention_bam_16_attention_center_distance": 0.07593049066156979,
      "attention_bam_16_attention_spatial_variance": 42.42150611606662,
      "attention_bam_16_attention_spatial_std": 6.513179416849087,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.140939131517046,
      "attention_bam_16_peak_intensity_mean": 0.20064692199230194,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 337,
      "phase": "train",
      "loss": 0.005771992262452841,
      "timestamp": 1759543936.3748107,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005771992262452841,
      "ssim": 0.8922358751296997,
      "attention_bam_384_mean_attention": 0.09017729014158249,
      "attention_bam_384_std_attention": 0.3768221139907837,
      "attention_bam_384_max_attention": 3.5043320655822754,
      "attention_bam_384_min_attention": -1.129162311553955,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2192499920681552,
      "attention_bam_384_attention_skewness": 0.7079053993316281,
      "attention_bam_384_attention_sparsity": 0.5481923421223959,
      "attention_bam_384_attention_concentration_10": 0.9294118463550788,
      "attention_bam_384_attention_concentration_20": 1.4418441201541332,
      "attention_bam_384_attention_center_y": 0.48041067953502975,
      "attention_bam_384_attention_center_x": 0.48395692069018376,
      "attention_bam_384_attention_center_distance": 0.035808431130680836,
      "attention_bam_384_attention_spatial_variance": 172.0897912141157,
      "attention_bam_384_attention_spatial_std": 13.118299859894792,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 18.44914755397197,
      "attention_bam_384_peak_intensity_mean": 0.2658328711986542,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17965975403785706,
      "attention_bam_16_std_attention": 0.5748655796051025,
      "attention_bam_16_max_attention": 3.136218309402466,
      "attention_bam_16_min_attention": -1.053871989250183,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.9444929312988348,
      "attention_bam_16_attention_skewness": 0.8307752107158544,
      "attention_bam_16_attention_sparsity": 0.495849609375,
      "attention_bam_16_attention_concentration_10": 0.7538388830994998,
      "attention_bam_16_attention_concentration_20": 1.1791399713958697,
      "attention_bam_16_attention_center_y": 0.45611841922193325,
      "attention_bam_16_attention_center_x": 0.4709690204879705,
      "attention_bam_16_attention_center_distance": 0.07440955453447995,
      "attention_bam_16_attention_spatial_variance": 43.5501534955644,
      "attention_bam_16_attention_spatial_std": 6.5992540105351605,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.731773270473274,
      "attention_bam_16_peak_intensity_mean": 0.30948877334594727,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 338,
      "phase": "train",
      "loss": 0.008142921142280102,
      "timestamp": 1759543936.5444856,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008142921142280102,
      "ssim": 0.8912855386734009,
      "attention_bam_384_mean_attention": 0.09109935164451599,
      "attention_bam_384_std_attention": 0.3871390223503113,
      "attention_bam_384_max_attention": 2.9353482723236084,
      "attention_bam_384_min_attention": -1.2247750759124756,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.31990709539749673,
      "attention_bam_384_attention_skewness": 0.49336790903388483,
      "attention_bam_384_attention_sparsity": 0.5396474202473959,
      "attention_bam_384_attention_concentration_10": 0.9024305040987689,
      "attention_bam_384_attention_concentration_20": 1.4549353073446374,
      "attention_bam_384_attention_center_y": 0.4885216642580278,
      "attention_bam_384_attention_center_x": 0.4820481858969193,
      "attention_bam_384_attention_center_distance": 0.03013369612234797,
      "attention_bam_384_attention_spatial_variance": 170.31553976047334,
      "attention_bam_384_attention_spatial_std": 13.050499598117819,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 18.056603219136104,
      "attention_bam_384_peak_intensity_mean": 0.31851622462272644,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18785353004932404,
      "attention_bam_16_std_attention": 0.5773499608039856,
      "attention_bam_16_max_attention": 2.864318609237671,
      "attention_bam_16_min_attention": -1.0907264947891235,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.49524812813721075,
      "attention_bam_16_attention_skewness": 0.7012254296920117,
      "attention_bam_16_attention_sparsity": 0.489013671875,
      "attention_bam_16_attention_concentration_10": 0.7149890172837415,
      "attention_bam_16_attention_concentration_20": 1.1402141586065488,
      "attention_bam_16_attention_center_y": 0.4819244839422642,
      "attention_bam_16_attention_center_x": 0.4650121022527398,
      "attention_bam_16_attention_center_distance": 0.05569339762532356,
      "attention_bam_16_attention_spatial_variance": 42.31971637522125,
      "attention_bam_16_attention_spatial_std": 6.505360587640108,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.454017776906023,
      "attention_bam_16_peak_intensity_mean": 0.33030200004577637,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 339,
      "phase": "train",
      "loss": 0.007110892795026302,
      "timestamp": 1759543936.7309113,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007110892795026302,
      "ssim": 0.844717264175415,
      "attention_bam_384_mean_attention": 0.08951488882303238,
      "attention_bam_384_std_attention": 0.390239953994751,
      "attention_bam_384_max_attention": 3.4499526023864746,
      "attention_bam_384_min_attention": -1.337125301361084,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4443467165683916,
      "attention_bam_384_attention_skewness": 0.7104675840743596,
      "attention_bam_384_attention_sparsity": 0.5474802652994791,
      "attention_bam_384_attention_concentration_10": 0.9517425853944266,
      "attention_bam_384_attention_concentration_20": 1.4868058157348945,
      "attention_bam_384_attention_center_y": 0.4809464431383325,
      "attention_bam_384_attention_center_x": 0.4857234393254037,
      "attention_bam_384_attention_center_distance": 0.03367070577746258,
      "attention_bam_384_attention_spatial_variance": 171.29404014528964,
      "attention_bam_384_attention_spatial_std": 13.087934907589114,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 18.101965903500133,
      "attention_bam_384_peak_intensity_mean": 0.3010588586330414,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16901573538780212,
      "attention_bam_16_std_attention": 0.5922678709030151,
      "attention_bam_16_max_attention": 4.033295631408691,
      "attention_bam_16_min_attention": -1.2403697967529297,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.1020408119489762,
      "attention_bam_16_attention_skewness": 0.8036318174043916,
      "attention_bam_16_attention_sparsity": 0.4970703125,
      "attention_bam_16_attention_concentration_10": 0.798235990189532,
      "attention_bam_16_attention_concentration_20": 1.2629377205138395,
      "attention_bam_16_attention_center_y": 0.4580696035818698,
      "attention_bam_16_attention_center_x": 0.4761606988755843,
      "attention_bam_16_attention_center_distance": 0.06821246838932177,
      "attention_bam_16_attention_spatial_variance": 43.04935504012483,
      "attention_bam_16_attention_spatial_std": 6.561200731582964,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 9.307807947115418,
      "attention_bam_16_peak_intensity_mean": 0.2696245610713959,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 340,
      "phase": "train",
      "loss": 0.007055600639432669,
      "timestamp": 1759543936.9380188,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007055600639432669,
      "ssim": 0.8807241916656494,
      "attention_bam_384_mean_attention": 0.08970112353563309,
      "attention_bam_384_std_attention": 0.3830152750015259,
      "attention_bam_384_max_attention": 3.2290327548980713,
      "attention_bam_384_min_attention": -1.1921241283416748,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8490128167452,
      "attention_bam_384_attention_skewness": 0.6193453744811224,
      "attention_bam_384_attention_sparsity": 0.5438664754231771,
      "attention_bam_384_attention_concentration_10": 0.9221862935178093,
      "attention_bam_384_attention_concentration_20": 1.464889683508653,
      "attention_bam_384_attention_center_y": 0.48796917902769343,
      "attention_bam_384_attention_center_x": 0.4817633635477377,
      "attention_bam_384_attention_center_distance": 0.03089710544240913,
      "attention_bam_384_attention_spatial_variance": 170.84535429490492,
      "attention_bam_384_attention_spatial_std": 13.070782466819074,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 17.703532360758366,
      "attention_bam_384_peak_intensity_mean": 0.2922220528125763,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17846207320690155,
      "attention_bam_16_std_attention": 0.5735647678375244,
      "attention_bam_16_max_attention": 2.8526101112365723,
      "attention_bam_16_min_attention": -1.1711289882659912,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.625042937800782,
      "attention_bam_16_attention_skewness": 0.7394225485425964,
      "attention_bam_16_attention_sparsity": 0.49755859375,
      "attention_bam_16_attention_concentration_10": 0.7415203767111491,
      "attention_bam_16_attention_concentration_20": 1.1825431993644036,
      "attention_bam_16_attention_center_y": 0.4770268928465169,
      "attention_bam_16_attention_center_x": 0.4633566179385839,
      "attention_bam_16_attention_center_distance": 0.06116373273737187,
      "attention_bam_16_attention_spatial_variance": 42.925221553872646,
      "attention_bam_16_attention_spatial_std": 6.5517342401743255,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.129357469079926,
      "attention_bam_16_peak_intensity_mean": 0.34362754225730896,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 341,
      "phase": "train",
      "loss": 0.006475442089140415,
      "timestamp": 1759543937.0970676,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006475442089140415,
      "ssim": 0.8981775641441345,
      "attention_bam_384_mean_attention": 0.08747246116399765,
      "attention_bam_384_std_attention": 0.37558844685554504,
      "attention_bam_384_max_attention": 2.8193395137786865,
      "attention_bam_384_min_attention": -1.1361479759216309,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1188367789487694,
      "attention_bam_384_attention_skewness": 0.6607344274975405,
      "attention_bam_384_attention_sparsity": 0.5499496459960938,
      "attention_bam_384_attention_concentration_10": 0.9429786675379922,
      "attention_bam_384_attention_concentration_20": 1.4707776005854039,
      "attention_bam_384_attention_center_y": 0.4870812753372226,
      "attention_bam_384_attention_center_x": 0.48123014492533783,
      "attention_bam_384_attention_center_distance": 0.03222424262683217,
      "attention_bam_384_attention_spatial_variance": 170.81628694038446,
      "attention_bam_384_attention_spatial_std": 13.069670498539145,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 18.406084193978906,
      "attention_bam_384_peak_intensity_mean": 0.3133202791213989,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17473240196704865,
      "attention_bam_16_std_attention": 0.5814787745475769,
      "attention_bam_16_max_attention": 3.185568332672119,
      "attention_bam_16_min_attention": -1.1582796573638916,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.9676443496703651,
      "attention_bam_16_attention_skewness": 0.7941800808275182,
      "attention_bam_16_attention_sparsity": 0.507080078125,
      "attention_bam_16_attention_concentration_10": 0.7671393191128802,
      "attention_bam_16_attention_concentration_20": 1.2199427379435013,
      "attention_bam_16_attention_center_y": 0.476446720553057,
      "attention_bam_16_attention_center_x": 0.4626167758638361,
      "attention_bam_16_attention_center_distance": 0.06248619718818638,
      "attention_bam_16_attention_spatial_variance": 42.766068312159724,
      "attention_bam_16_attention_spatial_std": 6.539577074410831,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.867082033162584,
      "attention_bam_16_peak_intensity_mean": 0.3099581003189087,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 342,
      "phase": "train",
      "loss": 0.006390205584466457,
      "timestamp": 1759543937.2449794,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006390205584466457,
      "ssim": 0.9044236540794373,
      "attention_bam_384_mean_attention": 0.08803600817918777,
      "attention_bam_384_std_attention": 0.3989402651786804,
      "attention_bam_384_max_attention": 2.615081548690796,
      "attention_bam_384_min_attention": -1.3097190856933594,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6438706627710347,
      "attention_bam_384_attention_skewness": 0.6144448151199694,
      "attention_bam_384_attention_sparsity": 0.5496978759765625,
      "attention_bam_384_attention_concentration_10": 0.9945349777332818,
      "attention_bam_384_attention_concentration_20": 1.560247777164849,
      "attention_bam_384_attention_center_y": 0.4794447785002634,
      "attention_bam_384_attention_center_x": 0.4835747285235307,
      "attention_bam_384_attention_center_distance": 0.037210393009989844,
      "attention_bam_384_attention_spatial_variance": 171.30478089546205,
      "attention_bam_384_attention_spatial_std": 13.088345231367564,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 18.58381573945596,
      "attention_bam_384_peak_intensity_mean": 0.35720986127853394,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17930221557617188,
      "attention_bam_16_std_attention": 0.6132933497428894,
      "attention_bam_16_max_attention": 3.0082552433013916,
      "attention_bam_16_min_attention": -1.0737183094024658,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.560174431450223,
      "attention_bam_16_attention_skewness": 0.7717797647029253,
      "attention_bam_16_attention_sparsity": 0.505615234375,
      "attention_bam_16_attention_concentration_10": 0.7893533723803761,
      "attention_bam_16_attention_concentration_20": 1.254296102093425,
      "attention_bam_16_attention_center_y": 0.45371103329930884,
      "attention_bam_16_attention_center_x": 0.4677348918436883,
      "attention_bam_16_attention_center_distance": 0.07979606058642474,
      "attention_bam_16_attention_spatial_variance": 43.26099278989167,
      "attention_bam_16_attention_spatial_std": 6.577308932222332,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.330281876782035,
      "attention_bam_16_peak_intensity_mean": 0.31002962589263916,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 343,
      "phase": "train",
      "loss": 0.006459344178438187,
      "timestamp": 1759543937.3806837,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006459344178438187,
      "ssim": 0.8918185234069824,
      "attention_bam_384_mean_attention": 0.08523597568273544,
      "attention_bam_384_std_attention": 0.33321306109428406,
      "attention_bam_384_max_attention": 2.67880916595459,
      "attention_bam_384_min_attention": -1.0421905517578125,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.020462319310787,
      "attention_bam_384_attention_skewness": 0.6521544284048021,
      "attention_bam_384_attention_sparsity": 0.5533599853515625,
      "attention_bam_384_attention_concentration_10": 0.8682927912312066,
      "attention_bam_384_attention_concentration_20": 1.3605691939072884,
      "attention_bam_384_attention_center_y": 0.48272001837619166,
      "attention_bam_384_attention_center_x": 0.4898859710522137,
      "attention_bam_384_attention_center_distance": 0.028315767567763824,
      "attention_bam_384_attention_spatial_variance": 169.97949841948702,
      "attention_bam_384_attention_spatial_std": 13.037618586976956,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 17.062523909126785,
      "attention_bam_384_peak_intensity_mean": 0.3054323196411133,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17739875614643097,
      "attention_bam_16_std_attention": 0.5204607844352722,
      "attention_bam_16_max_attention": 2.447056770324707,
      "attention_bam_16_min_attention": -0.9808704853057861,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5730062462665919,
      "attention_bam_16_attention_skewness": 0.6954944556768283,
      "attention_bam_16_attention_sparsity": 0.4814453125,
      "attention_bam_16_attention_concentration_10": 0.6850014392982805,
      "attention_bam_16_attention_concentration_20": 1.0846868159516692,
      "attention_bam_16_attention_center_y": 0.4648076401141891,
      "attention_bam_16_attention_center_x": 0.4830476073805666,
      "attention_bam_16_attention_center_distance": 0.05524284224867235,
      "attention_bam_16_attention_spatial_variance": 42.21250036257146,
      "attention_bam_16_attention_spatial_std": 6.497114772156289,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 10.366417523513709,
      "attention_bam_16_peak_intensity_mean": 0.34590572118759155,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 344,
      "phase": "train",
      "loss": 0.006005327217280865,
      "timestamp": 1759543937.5092933,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006005327217280865,
      "ssim": 0.8790727853775024,
      "attention_bam_384_mean_attention": 0.08516023308038712,
      "attention_bam_384_std_attention": 0.40359893441200256,
      "attention_bam_384_max_attention": 3.083557605743408,
      "attention_bam_384_min_attention": -1.2053861618041992,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.025167477536164,
      "attention_bam_384_attention_skewness": 0.9145291256097384,
      "attention_bam_384_attention_sparsity": 0.5613454182942709,
      "attention_bam_384_attention_concentration_10": 1.060910281819127,
      "attention_bam_384_attention_concentration_20": 1.6133028716205489,
      "attention_bam_384_attention_center_y": 0.4898538261450549,
      "attention_bam_384_attention_center_x": 0.4823340638122888,
      "attention_bam_384_attention_center_distance": 0.028810766920825088,
      "attention_bam_384_attention_spatial_variance": 172.81098371716243,
      "attention_bam_384_attention_spatial_std": 13.145759153322505,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 20.963890168774434,
      "attention_bam_384_peak_intensity_mean": 0.3037262558937073,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17257016897201538,
      "attention_bam_16_std_attention": 0.6136147379875183,
      "attention_bam_16_max_attention": 4.040210723876953,
      "attention_bam_16_min_attention": -1.2149899005889893,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.1849937839818674,
      "attention_bam_16_attention_skewness": 1.1129865309524987,
      "attention_bam_16_attention_sparsity": 0.51513671875,
      "attention_bam_16_attention_concentration_10": 0.839467409849873,
      "attention_bam_16_attention_concentration_20": 1.2925370443167914,
      "attention_bam_16_attention_center_y": 0.480875601428125,
      "attention_bam_16_attention_center_x": 0.466649309163932,
      "attention_bam_16_attention_center_distance": 0.05436931487482483,
      "attention_bam_16_attention_spatial_variance": 43.809553294531725,
      "attention_bam_16_attention_spatial_std": 6.61887855263501,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 10.583431822380557,
      "attention_bam_16_peak_intensity_mean": 0.2722387909889221,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 345,
      "phase": "train",
      "loss": 0.005240630358457565,
      "timestamp": 1759543937.6454282,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005240630358457565,
      "ssim": 0.8917165994644165,
      "attention_bam_384_mean_attention": 0.08441802114248276,
      "attention_bam_384_std_attention": 0.36152443289756775,
      "attention_bam_384_max_attention": 2.8993804454803467,
      "attention_bam_384_min_attention": -1.0239542722702026,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6004527759372329,
      "attention_bam_384_attention_skewness": 0.5805092927031584,
      "attention_bam_384_attention_sparsity": 0.5520579020182291,
      "attention_bam_384_attention_concentration_10": 0.9394996067212716,
      "attention_bam_384_attention_concentration_20": 1.4767823327361849,
      "attention_bam_384_attention_center_y": 0.48396697728625987,
      "attention_bam_384_attention_center_x": 0.47925899067661715,
      "attention_bam_384_attention_center_distance": 0.03707417659482031,
      "attention_bam_384_attention_spatial_variance": 170.61760371882238,
      "attention_bam_384_attention_spatial_std": 13.062067360062969,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 17.36882674379051,
      "attention_bam_384_peak_intensity_mean": 0.28403016924858093,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16992057859897614,
      "attention_bam_16_std_attention": 0.5478400588035583,
      "attention_bam_16_max_attention": 2.5288479328155518,
      "attention_bam_16_min_attention": -1.0143399238586426,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6106899550167606,
      "attention_bam_16_attention_skewness": 0.7241465679506599,
      "attention_bam_16_attention_sparsity": 0.507080078125,
      "attention_bam_16_attention_concentration_10": 0.7483630219786458,
      "attention_bam_16_attention_concentration_20": 1.1827971274852798,
      "attention_bam_16_attention_center_y": 0.47078365631740055,
      "attention_bam_16_attention_center_x": 0.45673520943724283,
      "attention_bam_16_attention_center_distance": 0.07383003238004181,
      "attention_bam_16_attention_spatial_variance": 42.53509958042363,
      "attention_bam_16_attention_spatial_std": 6.5218938645476,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.945185072076224,
      "attention_bam_16_peak_intensity_mean": 0.34218931198120117,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 346,
      "phase": "train",
      "loss": 0.007031592540442944,
      "timestamp": 1759543937.78143,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007031592540442944,
      "ssim": 0.8774844408035278,
      "attention_bam_384_mean_attention": 0.0849953219294548,
      "attention_bam_384_std_attention": 0.34248262643814087,
      "attention_bam_384_max_attention": 2.649137258529663,
      "attention_bam_384_min_attention": -1.1319864988327026,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.529450573764242,
      "attention_bam_384_attention_skewness": 0.7042485272546765,
      "attention_bam_384_attention_sparsity": 0.5493952433268229,
      "attention_bam_384_attention_concentration_10": 0.8926868553648379,
      "attention_bam_384_attention_concentration_20": 1.3825729095525048,
      "attention_bam_384_attention_center_y": 0.47683385304506465,
      "attention_bam_384_attention_center_x": 0.4797456925977699,
      "attention_bam_384_attention_center_distance": 0.043517980952284395,
      "attention_bam_384_attention_spatial_variance": 171.88203351448652,
      "attention_bam_384_attention_spatial_std": 13.110378847099977,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 18.621272059779802,
      "attention_bam_384_peak_intensity_mean": 0.3228822648525238,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1591290533542633,
      "attention_bam_16_std_attention": 0.5410990118980408,
      "attention_bam_16_max_attention": 2.9654645919799805,
      "attention_bam_16_min_attention": -1.1015139818191528,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.6356680153149163,
      "attention_bam_16_attention_skewness": 0.8941771485188975,
      "attention_bam_16_attention_sparsity": 0.49560546875,
      "attention_bam_16_attention_concentration_10": 0.7846517969309252,
      "attention_bam_16_attention_concentration_20": 1.2134422139776766,
      "attention_bam_16_attention_center_y": 0.44995382412256396,
      "attention_bam_16_attention_center_x": 0.45931073063819816,
      "attention_bam_16_attention_center_distance": 0.09121662525167795,
      "attention_bam_16_attention_spatial_variance": 43.28894166961276,
      "attention_bam_16_attention_spatial_std": 6.579433233160191,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 10.595741851108844,
      "attention_bam_16_peak_intensity_mean": 0.31735068559646606,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 347,
      "phase": "train",
      "loss": 0.004526897333562374,
      "timestamp": 1759543937.9221659,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004526897333562374,
      "ssim": 0.9045881032943726,
      "attention_bam_384_mean_attention": 0.08330711722373962,
      "attention_bam_384_std_attention": 0.4026254415512085,
      "attention_bam_384_max_attention": 3.25006103515625,
      "attention_bam_384_min_attention": -1.1877224445343018,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.042310871804596,
      "attention_bam_384_attention_skewness": 0.9307526620890939,
      "attention_bam_384_attention_sparsity": 0.5603205362955729,
      "attention_bam_384_attention_concentration_10": 1.0813407490532378,
      "attention_bam_384_attention_concentration_20": 1.6395035564757994,
      "attention_bam_384_attention_center_y": 0.48060894471486626,
      "attention_bam_384_attention_center_x": 0.491368527159883,
      "attention_bam_384_attention_center_distance": 0.03001717336661767,
      "attention_bam_384_attention_spatial_variance": 174.13609350019087,
      "attention_bam_384_attention_spatial_std": 13.19606356078171,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 20.239734458409703,
      "attention_bam_384_peak_intensity_mean": 0.29261770844459534,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16570696234703064,
      "attention_bam_16_std_attention": 0.6013049483299255,
      "attention_bam_16_max_attention": 3.430363178253174,
      "attention_bam_16_min_attention": -1.118168592453003,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.798906646877267,
      "attention_bam_16_attention_skewness": 1.0331478835374839,
      "attention_bam_16_attention_sparsity": 0.51904296875,
      "attention_bam_16_attention_concentration_10": 0.8469132331914178,
      "attention_bam_16_attention_concentration_20": 1.3120161260106007,
      "attention_bam_16_attention_center_y": 0.4607306282828456,
      "attention_bam_16_attention_center_x": 0.4840767147107623,
      "attention_bam_16_attention_center_distance": 0.059927198657412625,
      "attention_bam_16_attention_spatial_variance": 44.71435314869333,
      "attention_bam_16_attention_spatial_std": 6.686879178562547,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 10.443828962468666,
      "attention_bam_16_peak_intensity_mean": 0.2915099263191223,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 348,
      "phase": "train",
      "loss": 0.006842408329248428,
      "timestamp": 1759543938.0692418,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006842408329248428,
      "ssim": 0.84814453125,
      "attention_bam_384_mean_attention": 0.08566652983427048,
      "attention_bam_384_std_attention": 0.3167125880718231,
      "attention_bam_384_max_attention": 2.5335702896118164,
      "attention_bam_384_min_attention": -1.0330312252044678,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8057404313778269,
      "attention_bam_384_attention_skewness": 0.5173824865305285,
      "attention_bam_384_attention_sparsity": 0.5454661051432291,
      "attention_bam_384_attention_concentration_10": 0.8075408695448103,
      "attention_bam_384_attention_concentration_20": 1.2842131507306176,
      "attention_bam_384_attention_center_y": 0.48721942336080887,
      "attention_bam_384_attention_center_x": 0.4828925020938332,
      "attention_bam_384_attention_center_distance": 0.030199656416579936,
      "attention_bam_384_attention_spatial_variance": 168.9147467942724,
      "attention_bam_384_attention_spatial_std": 12.996720616919962,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 17.567148171002604,
      "attention_bam_384_peak_intensity_mean": 0.3181271255016327,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1901615709066391,
      "attention_bam_16_std_attention": 0.5095040202140808,
      "attention_bam_16_max_attention": 2.463226556777954,
      "attention_bam_16_min_attention": -1.0645229816436768,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5046154486057595,
      "attention_bam_16_attention_skewness": 0.5667019761719972,
      "attention_bam_16_attention_sparsity": 0.46435546875,
      "attention_bam_16_attention_concentration_10": 0.6188013393615526,
      "attention_bam_16_attention_concentration_20": 0.9951280124891762,
      "attention_bam_16_attention_center_y": 0.47693616486458756,
      "attention_bam_16_attention_center_x": 0.465688351316551,
      "attention_bam_16_attention_center_distance": 0.05846759318682294,
      "attention_bam_16_attention_spatial_variance": 41.64030845028208,
      "attention_bam_16_attention_spatial_std": 6.452930222021782,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 6.392443131469063,
      "attention_bam_16_peak_intensity_mean": 0.3724822700023651,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 349,
      "phase": "train",
      "loss": 0.007333978544920683,
      "timestamp": 1759543938.2210772,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007333978544920683,
      "ssim": 0.8711585402488708,
      "attention_bam_384_mean_attention": 0.08568909764289856,
      "attention_bam_384_std_attention": 0.38222557306289673,
      "attention_bam_384_max_attention": 2.6589670181274414,
      "attention_bam_384_min_attention": -1.1903412342071533,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8392148280680356,
      "attention_bam_384_attention_skewness": 0.6160634694526652,
      "attention_bam_384_attention_sparsity": 0.547149658203125,
      "attention_bam_384_attention_concentration_10": 0.9685292183966816,
      "attention_bam_384_attention_concentration_20": 1.521784490084871,
      "attention_bam_384_attention_center_y": 0.4802575089219946,
      "attention_bam_384_attention_center_x": 0.4843660609085143,
      "attention_bam_384_attention_center_distance": 0.0356142108007859,
      "attention_bam_384_attention_spatial_variance": 174.48496543685133,
      "attention_bam_384_attention_spatial_std": 13.209275734757426,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 20.004462944177323,
      "attention_bam_384_peak_intensity_mean": 0.34322312474250793,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17290884256362915,
      "attention_bam_16_std_attention": 0.5803070068359375,
      "attention_bam_16_max_attention": 3.179619312286377,
      "attention_bam_16_min_attention": -1.105214238166809,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7896864323614721,
      "attention_bam_16_attention_skewness": 0.7494762765542421,
      "attention_bam_16_attention_sparsity": 0.496337890625,
      "attention_bam_16_attention_concentration_10": 0.763435351216362,
      "attention_bam_16_attention_concentration_20": 1.216758062658604,
      "attention_bam_16_attention_center_y": 0.4608549017867888,
      "attention_bam_16_attention_center_x": 0.4697723509773897,
      "attention_bam_16_attention_center_distance": 0.06994354122513481,
      "attention_bam_16_attention_spatial_variance": 44.652413227176936,
      "attention_bam_16_attention_spatial_std": 6.682246121415832,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.678746904322328,
      "attention_bam_16_peak_intensity_mean": 0.3130894601345062,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 350,
      "phase": "train",
      "loss": 0.0077193863689899445,
      "timestamp": 1759543938.4146345,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0077193863689899445,
      "ssim": 0.8585973978042603,
      "attention_bam_384_mean_attention": 0.08660665899515152,
      "attention_bam_384_std_attention": 0.3515610694885254,
      "attention_bam_384_max_attention": 2.5225625038146973,
      "attention_bam_384_min_attention": -1.0158122777938843,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8612015514586866,
      "attention_bam_384_attention_skewness": 0.5942890726306707,
      "attention_bam_384_attention_sparsity": 0.5477040608723959,
      "attention_bam_384_attention_concentration_10": 0.894834225575183,
      "attention_bam_384_attention_concentration_20": 1.3987892103240267,
      "attention_bam_384_attention_center_y": 0.47924849602472064,
      "attention_bam_384_attention_center_x": 0.48781120953243184,
      "attention_bam_384_attention_center_distance": 0.03403502696629798,
      "attention_bam_384_attention_spatial_variance": 171.77954475096215,
      "attention_bam_384_attention_spatial_std": 13.106469576165892,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 19.06384148351804,
      "attention_bam_384_peak_intensity_mean": 0.31545135378837585,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18590380251407623,
      "attention_bam_16_std_attention": 0.5493387579917908,
      "attention_bam_16_max_attention": 2.5898263454437256,
      "attention_bam_16_min_attention": -1.0939853191375732,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.3309417295661512,
      "attention_bam_16_attention_skewness": 0.6253657093697096,
      "attention_bam_16_attention_sparsity": 0.474853515625,
      "attention_bam_16_attention_concentration_10": 0.6831426266761619,
      "attention_bam_16_attention_concentration_20": 1.0931189704591044,
      "attention_bam_16_attention_center_y": 0.45856832076068266,
      "attention_bam_16_attention_center_x": 0.4776865776948324,
      "attention_bam_16_attention_center_distance": 0.06655032471082963,
      "attention_bam_16_attention_spatial_variance": 43.308539940733866,
      "attention_bam_16_attention_spatial_std": 6.580922423242343,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.786422071680613,
      "attention_bam_16_peak_intensity_mean": 0.3552616536617279,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 351,
      "phase": "train",
      "loss": 0.005702599883079529,
      "timestamp": 1759543938.5665052,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005702599883079529,
      "ssim": 0.8950941562652588,
      "attention_bam_384_mean_attention": 0.08498245477676392,
      "attention_bam_384_std_attention": 0.33109596371650696,
      "attention_bam_384_max_attention": 2.2839913368225098,
      "attention_bam_384_min_attention": -1.0147656202316284,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.776065170828411,
      "attention_bam_384_attention_skewness": 0.5994910560402882,
      "attention_bam_384_attention_sparsity": 0.5518595377604166,
      "attention_bam_384_attention_concentration_10": 0.8617865166093753,
      "attention_bam_384_attention_concentration_20": 1.359125730278014,
      "attention_bam_384_attention_center_y": 0.48377368592658676,
      "attention_bam_384_attention_center_x": 0.47843616727929894,
      "attention_bam_384_attention_center_distance": 0.038165223699473484,
      "attention_bam_384_attention_spatial_variance": 171.57760288543156,
      "attention_bam_384_attention_spatial_std": 13.098763410544965,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 17.771195818612288,
      "attention_bam_384_peak_intensity_mean": 0.3378768861293793,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18202239274978638,
      "attention_bam_16_std_attention": 0.5200337767601013,
      "attention_bam_16_max_attention": 2.4969496726989746,
      "attention_bam_16_min_attention": -0.9683560132980347,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.4818231594210687,
      "attention_bam_16_attention_skewness": 0.6412777914110803,
      "attention_bam_16_attention_sparsity": 0.476806640625,
      "attention_bam_16_attention_concentration_10": 0.6653661272365763,
      "attention_bam_16_attention_concentration_20": 1.0628411086398308,
      "attention_bam_16_attention_center_y": 0.46876299618907824,
      "attention_bam_16_attention_center_x": 0.4563072652017148,
      "attention_bam_16_attention_center_distance": 0.07595795522836071,
      "attention_bam_16_attention_spatial_variance": 43.03382944166034,
      "attention_bam_16_attention_spatial_std": 6.560017487908119,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.557106279686845,
      "attention_bam_16_peak_intensity_mean": 0.34192293882369995,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 352,
      "phase": "train",
      "loss": 0.006950882729142904,
      "timestamp": 1759543938.713397,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006950882729142904,
      "ssim": 0.8868863582611084,
      "attention_bam_384_mean_attention": 0.08407794684171677,
      "attention_bam_384_std_attention": 0.3613116443157196,
      "attention_bam_384_max_attention": 2.956057548522949,
      "attention_bam_384_min_attention": -1.065475583076477,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0476988368573865,
      "attention_bam_384_attention_skewness": 0.6761427905627443,
      "attention_bam_384_attention_sparsity": 0.5537516276041666,
      "attention_bam_384_attention_concentration_10": 0.9480340608320129,
      "attention_bam_384_attention_concentration_20": 1.4772742874361802,
      "attention_bam_384_attention_center_y": 0.48614823077073294,
      "attention_bam_384_attention_center_x": 0.4822761554920108,
      "attention_bam_384_attention_center_distance": 0.03181214154766222,
      "attention_bam_384_attention_spatial_variance": 170.25358475913544,
      "attention_bam_384_attention_spatial_std": 13.04812571824534,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 17.77558122229063,
      "attention_bam_384_peak_intensity_mean": 0.2902357578277588,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17330940067768097,
      "attention_bam_16_std_attention": 0.5674704909324646,
      "attention_bam_16_max_attention": 3.452763557434082,
      "attention_bam_16_min_attention": -1.0769882202148438,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7571443347051825,
      "attention_bam_16_attention_skewness": 0.7302944381887462,
      "attention_bam_16_attention_sparsity": 0.498046875,
      "attention_bam_16_attention_concentration_10": 0.7518591693854422,
      "attention_bam_16_attention_concentration_20": 1.1968343499309546,
      "attention_bam_16_attention_center_y": 0.47315536076606457,
      "attention_bam_16_attention_center_x": 0.4664450300313417,
      "attention_bam_16_attention_center_distance": 0.060771221235017256,
      "attention_bam_16_attention_spatial_variance": 42.315908606021246,
      "attention_bam_16_attention_spatial_std": 6.5050679170951975,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.407985690297492,
      "attention_bam_16_peak_intensity_mean": 0.282260924577713,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 353,
      "phase": "train",
      "loss": 0.005286471452564001,
      "timestamp": 1759543938.855519,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005286471452564001,
      "ssim": 0.9123960733413696,
      "attention_bam_384_mean_attention": 0.08567920327186584,
      "attention_bam_384_std_attention": 0.3752945363521576,
      "attention_bam_384_max_attention": 3.576300621032715,
      "attention_bam_384_min_attention": -1.2655446529388428,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.039383961969201,
      "attention_bam_384_attention_skewness": 0.9171405529419397,
      "attention_bam_384_attention_sparsity": 0.5485967000325521,
      "attention_bam_384_attention_concentration_10": 0.9574598733340302,
      "attention_bam_384_attention_concentration_20": 1.471682023051591,
      "attention_bam_384_attention_center_y": 0.48882576807309175,
      "attention_bam_384_attention_center_x": 0.48108279374541624,
      "attention_bam_384_attention_center_distance": 0.031071663992609043,
      "attention_bam_384_attention_spatial_variance": 171.58638932504124,
      "attention_bam_384_attention_spatial_std": 13.099098798201394,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 19.351585289477697,
      "attention_bam_384_peak_intensity_mean": 0.28094321489334106,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17739005386829376,
      "attention_bam_16_std_attention": 0.5715633630752563,
      "attention_bam_16_max_attention": 3.826792001724243,
      "attention_bam_16_min_attention": -1.1187251806259155,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.3834247692889274,
      "attention_bam_16_attention_skewness": 1.1388253686520817,
      "attention_bam_16_attention_sparsity": 0.490234375,
      "attention_bam_16_attention_concentration_10": 0.7427801967986162,
      "attention_bam_16_attention_concentration_20": 1.1521155332996404,
      "attention_bam_16_attention_center_y": 0.4804287070370028,
      "attention_bam_16_attention_center_x": 0.46089167401850434,
      "attention_bam_16_attention_center_distance": 0.06184653053031176,
      "attention_bam_16_attention_spatial_variance": 43.18998676627469,
      "attention_bam_16_attention_spatial_std": 6.571908913418893,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 9.429397976416034,
      "attention_bam_16_peak_intensity_mean": 0.2617272734642029,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 354,
      "phase": "train",
      "loss": 0.008351600728929043,
      "timestamp": 1759543938.9934757,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008351600728929043,
      "ssim": 0.9020216464996338,
      "attention_bam_384_mean_attention": 0.08545640856027603,
      "attention_bam_384_std_attention": 0.31360486149787903,
      "attention_bam_384_max_attention": 3.2466049194335938,
      "attention_bam_384_min_attention": -0.9763290882110596,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5149057835152568,
      "attention_bam_384_attention_skewness": 0.614854359364817,
      "attention_bam_384_attention_sparsity": 0.5475031534830729,
      "attention_bam_384_attention_concentration_10": 0.8077638089425524,
      "attention_bam_384_attention_concentration_20": 1.2731510694083066,
      "attention_bam_384_attention_center_y": 0.47810642344385934,
      "attention_bam_384_attention_center_x": 0.49013722253945946,
      "attention_bam_384_attention_center_distance": 0.03395888907652129,
      "attention_bam_384_attention_spatial_variance": 172.12065350591692,
      "attention_bam_384_attention_spatial_std": 13.119476114003826,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 16.43199226539832,
      "attention_bam_384_peak_intensity_mean": 0.25550249218940735,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.20263531804084778,
      "attention_bam_16_std_attention": 0.4995884895324707,
      "attention_bam_16_max_attention": 2.4317853450775146,
      "attention_bam_16_min_attention": -1.0735976696014404,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.4747000591960586,
      "attention_bam_16_attention_skewness": 0.5431659863775131,
      "attention_bam_16_attention_sparsity": 0.449951171875,
      "attention_bam_16_attention_concentration_10": 0.5750435007114532,
      "attention_bam_16_attention_concentration_20": 0.93088081103543,
      "attention_bam_16_attention_center_y": 0.45456669536797883,
      "attention_bam_16_attention_center_x": 0.4852232969663978,
      "attention_bam_16_attention_center_distance": 0.06756531835682125,
      "attention_bam_16_attention_spatial_variance": 43.661745560239964,
      "attention_bam_16_attention_spatial_std": 6.607703501235506,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.874124911736208,
      "attention_bam_16_peak_intensity_mean": 0.3747045695781708,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 355,
      "phase": "train",
      "loss": 0.006188246887177229,
      "timestamp": 1759543939.1317217,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006188246887177229,
      "ssim": 0.8771512508392334,
      "attention_bam_384_mean_attention": 0.08640573173761368,
      "attention_bam_384_std_attention": 0.3758440613746643,
      "attention_bam_384_max_attention": 3.6593017578125,
      "attention_bam_384_min_attention": -1.107723355293274,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.002746118117921,
      "attention_bam_384_attention_skewness": 0.6667624227423831,
      "attention_bam_384_attention_sparsity": 0.5510381062825521,
      "attention_bam_384_attention_concentration_10": 0.9567873159061353,
      "attention_bam_384_attention_concentration_20": 1.4943631130594464,
      "attention_bam_384_attention_center_y": 0.4861143720168669,
      "attention_bam_384_attention_center_x": 0.4837489047138885,
      "attention_bam_384_attention_center_distance": 0.03022941489623127,
      "attention_bam_384_attention_spatial_variance": 171.7661784802834,
      "attention_bam_384_attention_spatial_std": 13.105959655068506,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 19.30523831908913,
      "attention_bam_384_peak_intensity_mean": 0.25345540046691895,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18194162845611572,
      "attention_bam_16_std_attention": 0.570575475692749,
      "attention_bam_16_max_attention": 3.2424139976501465,
      "attention_bam_16_min_attention": -1.1225757598876953,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7769491381503224,
      "attention_bam_16_attention_skewness": 0.7720745008453701,
      "attention_bam_16_attention_sparsity": 0.49560546875,
      "attention_bam_16_attention_concentration_10": 0.7324387529492469,
      "attention_bam_16_attention_concentration_20": 1.1631308734987942,
      "attention_bam_16_attention_center_y": 0.4740044492072481,
      "attention_bam_16_attention_center_x": 0.4696812511547105,
      "attention_bam_16_attention_center_distance": 0.05647999986831245,
      "attention_bam_16_attention_spatial_variance": 43.37862029406901,
      "attention_bam_16_attention_spatial_std": 6.586244779392048,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 10.707400784790032,
      "attention_bam_16_peak_intensity_mean": 0.30683672428131104,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 356,
      "phase": "train",
      "loss": 0.005966677330434322,
      "timestamp": 1759543939.2683105,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005966677330434322,
      "ssim": 0.8762794733047485,
      "attention_bam_384_mean_attention": 0.08410823345184326,
      "attention_bam_384_std_attention": 0.3432444930076599,
      "attention_bam_384_max_attention": 2.5183894634246826,
      "attention_bam_384_min_attention": -1.1885676383972168,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8505646254397754,
      "attention_bam_384_attention_skewness": 0.611276777892882,
      "attention_bam_384_attention_sparsity": 0.5561726888020834,
      "attention_bam_384_attention_concentration_10": 0.9060634879687035,
      "attention_bam_384_attention_concentration_20": 1.4171791502901483,
      "attention_bam_384_attention_center_y": 0.4758804948523778,
      "attention_bam_384_attention_center_x": 0.4869228829757148,
      "attention_bam_384_attention_center_distance": 0.03880107004279709,
      "attention_bam_384_attention_spatial_variance": 172.43537795323374,
      "attention_bam_384_attention_spatial_std": 13.131465186841632,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 16.486091353848767,
      "attention_bam_384_peak_intensity_mean": 0.34474900364875793,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18396683037281036,
      "attention_bam_16_std_attention": 0.5596998333930969,
      "attention_bam_16_max_attention": 2.5467936992645264,
      "attention_bam_16_min_attention": -1.1687921285629272,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.47813901716745155,
      "attention_bam_16_attention_skewness": 0.6824648362661876,
      "attention_bam_16_attention_sparsity": 0.492431640625,
      "attention_bam_16_attention_concentration_10": 0.705790509398485,
      "attention_bam_16_attention_concentration_20": 1.1208689915170664,
      "attention_bam_16_attention_center_y": 0.4474229690696108,
      "attention_bam_16_attention_center_x": 0.4770610555584176,
      "attention_bam_16_attention_center_distance": 0.0811238479554453,
      "attention_bam_16_attention_spatial_variance": 43.68948708619945,
      "attention_bam_16_attention_spatial_std": 6.609802348497226,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.917202133072882,
      "attention_bam_16_peak_intensity_mean": 0.37184327840805054,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 357,
      "phase": "train",
      "loss": 0.004834512248635292,
      "timestamp": 1759543939.4329498,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004834512248635292,
      "ssim": 0.9081484079360962,
      "attention_bam_384_mean_attention": 0.08271602541208267,
      "attention_bam_384_std_attention": 0.3572976589202881,
      "attention_bam_384_max_attention": 3.4523236751556396,
      "attention_bam_384_min_attention": -1.1883896589279175,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.0810857257921596,
      "attention_bam_384_attention_skewness": 0.8730629018779154,
      "attention_bam_384_attention_sparsity": 0.5648854573567709,
      "attention_bam_384_attention_concentration_10": 0.9734395184125499,
      "attention_bam_384_attention_concentration_20": 1.4853384412209591,
      "attention_bam_384_attention_center_y": 0.48718335452655737,
      "attention_bam_384_attention_center_x": 0.48098936197389053,
      "attention_bam_384_attention_center_distance": 0.032424396967458836,
      "attention_bam_384_attention_spatial_variance": 172.65976855837383,
      "attention_bam_384_attention_spatial_std": 13.1400064139396,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 18.39404367568687,
      "attention_bam_384_peak_intensity_mean": 0.28139474987983704,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17631679773330688,
      "attention_bam_16_std_attention": 0.571293830871582,
      "attention_bam_16_max_attention": 2.9135069847106934,
      "attention_bam_16_min_attention": -1.1201226711273193,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.124707798483887,
      "attention_bam_16_attention_skewness": 0.8812778903096075,
      "attention_bam_16_attention_sparsity": 0.50390625,
      "attention_bam_16_attention_concentration_10": 0.7655898793209306,
      "attention_bam_16_attention_concentration_20": 1.2009032809690023,
      "attention_bam_16_attention_center_y": 0.4755370885674123,
      "attention_bam_16_attention_center_x": 0.4615074482795644,
      "attention_bam_16_attention_center_distance": 0.06449977633618646,
      "attention_bam_16_attention_spatial_variance": 44.05449461538993,
      "attention_bam_16_attention_spatial_std": 6.637355995830714,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.650004028864368,
      "attention_bam_16_peak_intensity_mean": 0.3304544687271118,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 358,
      "phase": "train",
      "loss": 0.006828116253018379,
      "timestamp": 1759543939.6074011,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006828116253018379,
      "ssim": 0.9141057133674622,
      "attention_bam_384_mean_attention": 0.08567731827497482,
      "attention_bam_384_std_attention": 0.3455471694469452,
      "attention_bam_384_max_attention": 2.418905735015869,
      "attention_bam_384_min_attention": -1.0121911764144897,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6248780675299339,
      "attention_bam_384_attention_skewness": 0.4928387895615956,
      "attention_bam_384_attention_sparsity": 0.5425440470377604,
      "attention_bam_384_attention_concentration_10": 0.8713137978846425,
      "attention_bam_384_attention_concentration_20": 1.3832567246027316,
      "attention_bam_384_attention_center_y": 0.4844856740311744,
      "attention_bam_384_attention_center_x": 0.48224069213694365,
      "attention_bam_384_attention_center_distance": 0.03334928263221841,
      "attention_bam_384_attention_spatial_variance": 170.10657536454673,
      "attention_bam_384_attention_spatial_std": 13.042491148724109,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 16.068999750932125,
      "attention_bam_384_peak_intensity_mean": 0.3241845667362213,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1843881607055664,
      "attention_bam_16_std_attention": 0.5574651956558228,
      "attention_bam_16_max_attention": 2.3705639839172363,
      "attention_bam_16_min_attention": -1.0846490859985352,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.0436646102295466,
      "attention_bam_16_attention_skewness": 0.5096644094933689,
      "attention_bam_16_attention_sparsity": 0.469970703125,
      "attention_bam_16_attention_concentration_10": 0.6771842027762104,
      "attention_bam_16_attention_concentration_20": 1.0994559595396074,
      "attention_bam_16_attention_center_y": 0.4696452759773596,
      "attention_bam_16_attention_center_x": 0.46665786405507054,
      "attention_bam_16_attention_center_distance": 0.06376687697952313,
      "attention_bam_16_attention_spatial_variance": 42.287735898050805,
      "attention_bam_16_attention_spatial_std": 6.502902113522147,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.145965360718636,
      "attention_bam_16_peak_intensity_mean": 0.3810949921607971,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 359,
      "phase": "train",
      "loss": 0.0052306801080703735,
      "timestamp": 1759543939.9917634,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0052306801080703735,
      "ssim": 0.9076330065727234,
      "attention_bam_384_mean_attention": 0.08387303352355957,
      "attention_bam_384_std_attention": 0.3845202326774597,
      "attention_bam_384_max_attention": 3.4945292472839355,
      "attention_bam_384_min_attention": -1.2889069318771362,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.3965649455132318,
      "attention_bam_384_attention_skewness": 0.7632769598221282,
      "attention_bam_384_attention_sparsity": 0.5597050984700521,
      "attention_bam_384_attention_concentration_10": 1.0203994202961373,
      "attention_bam_384_attention_concentration_20": 1.5739284296358484,
      "attention_bam_384_attention_center_y": 0.4785180016556632,
      "attention_bam_384_attention_center_x": 0.48395696303801217,
      "attention_bam_384_attention_center_distance": 0.03791715410812884,
      "attention_bam_384_attention_spatial_variance": 169.40496355952416,
      "attention_bam_384_attention_spatial_std": 13.015566202033785,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 15.320664618006061,
      "attention_bam_384_peak_intensity_mean": 0.2880384027957916,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1711275279521942,
      "attention_bam_16_std_attention": 0.5981063842773438,
      "attention_bam_16_max_attention": 3.165821075439453,
      "attention_bam_16_min_attention": -1.0735785961151123,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7296893284092416,
      "attention_bam_16_attention_skewness": 0.7820056170254984,
      "attention_bam_16_attention_sparsity": 0.496826171875,
      "attention_bam_16_attention_concentration_10": 0.8083603574682479,
      "attention_bam_16_attention_concentration_20": 1.2701963589015537,
      "attention_bam_16_attention_center_y": 0.45280810160077806,
      "attention_bam_16_attention_center_x": 0.46991758770440956,
      "attention_bam_16_attention_center_distance": 0.07914577441713963,
      "attention_bam_16_attention_spatial_variance": 41.66946251943288,
      "attention_bam_16_attention_spatial_std": 6.455188805870272,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 7.401485340418871,
      "attention_bam_16_peak_intensity_mean": 0.29500341415405273,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 360,
      "phase": "train",
      "loss": 0.006844577845185995,
      "timestamp": 1759543940.163899,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006844577845185995,
      "ssim": 0.8692513704299927,
      "attention_bam_384_mean_attention": 0.08237548917531967,
      "attention_bam_384_std_attention": 0.378484308719635,
      "attention_bam_384_max_attention": 3.1849892139434814,
      "attention_bam_384_min_attention": -1.2563406229019165,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1730128264943955,
      "attention_bam_384_attention_skewness": 0.7336057478839317,
      "attention_bam_384_attention_sparsity": 0.5591481526692709,
      "attention_bam_384_attention_concentration_10": 1.0120895105070764,
      "attention_bam_384_attention_concentration_20": 1.5703326088156317,
      "attention_bam_384_attention_center_y": 0.4884322344284491,
      "attention_bam_384_attention_center_x": 0.4788990988273849,
      "attention_bam_384_attention_center_distance": 0.0340311983513607,
      "attention_bam_384_attention_spatial_variance": 171.8441508226577,
      "attention_bam_384_attention_spatial_std": 13.108934007868744,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 17.806408082833034,
      "attention_bam_384_peak_intensity_mean": 0.3049580454826355,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16940176486968994,
      "attention_bam_16_std_attention": 0.5804910659790039,
      "attention_bam_16_max_attention": 2.7588441371917725,
      "attention_bam_16_min_attention": -1.0844449996948242,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5454059134515306,
      "attention_bam_16_attention_skewness": 0.7638820895116,
      "attention_bam_16_attention_sparsity": 0.507568359375,
      "attention_bam_16_attention_concentration_10": 0.7980945360517472,
      "attention_bam_16_attention_concentration_20": 1.2581481409626247,
      "attention_bam_16_attention_center_y": 0.48025044657821486,
      "attention_bam_16_attention_center_x": 0.4563724038504998,
      "attention_bam_16_attention_center_distance": 0.06772609550452215,
      "attention_bam_16_attention_spatial_variance": 43.46688339278048,
      "attention_bam_16_attention_spatial_std": 6.592941937616354,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.0878753326377,
      "attention_bam_16_peak_intensity_mean": 0.32726430892944336,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 361,
      "phase": "train",
      "loss": 0.011831550858914852,
      "timestamp": 1759543940.3030024,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.011831550858914852,
      "ssim": 0.8813445568084717,
      "attention_bam_384_mean_attention": 0.08499836176633835,
      "attention_bam_384_std_attention": 0.340641051530838,
      "attention_bam_384_max_attention": 2.851144313812256,
      "attention_bam_384_min_attention": -1.244269609451294,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": -0.04150698504477912,
      "attention_bam_384_attention_skewness": 0.31266852704160103,
      "attention_bam_384_attention_sparsity": 0.5280507405598959,
      "attention_bam_384_attention_concentration_10": 0.8328621943228248,
      "attention_bam_384_attention_concentration_20": 1.357758892220044,
      "attention_bam_384_attention_center_y": 0.4803174418894302,
      "attention_bam_384_attention_center_x": 0.48363666409099587,
      "attention_bam_384_attention_center_distance": 0.036198393772289415,
      "attention_bam_384_attention_spatial_variance": 170.11450266865978,
      "attention_bam_384_attention_spatial_std": 13.042795048173524,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 15.927246244399326,
      "attention_bam_384_peak_intensity_mean": 0.32707855105400085,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17930343747138977,
      "attention_bam_16_std_attention": 0.544884204864502,
      "attention_bam_16_max_attention": 2.210548162460327,
      "attention_bam_16_min_attention": -1.1842095851898193,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.24126087387404693,
      "attention_bam_16_attention_skewness": 0.4038033433724849,
      "attention_bam_16_attention_sparsity": 0.46923828125,
      "attention_bam_16_attention_concentration_10": 0.6620602766502971,
      "attention_bam_16_attention_concentration_20": 1.0987311401554896,
      "attention_bam_16_attention_center_y": 0.45761831303809336,
      "attention_bam_16_attention_center_x": 0.4686955288700585,
      "attention_bam_16_attention_center_distance": 0.07451412352651526,
      "attention_bam_16_attention_spatial_variance": 42.273752703005016,
      "attention_bam_16_attention_spatial_std": 6.501826874271955,
      "attention_bam_16_num_attention_peaks": 11,
      "attention_bam_16_peak_separation_mean": 7.463940926371968,
      "attention_bam_16_peak_intensity_mean": 0.411963552236557,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 362,
      "phase": "train",
      "loss": 0.0058774324133992195,
      "timestamp": 1759543940.4362562,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0058774324133992195,
      "ssim": 0.8662694692611694,
      "attention_bam_384_mean_attention": 0.08237143605947495,
      "attention_bam_384_std_attention": 0.3868829607963562,
      "attention_bam_384_max_attention": 3.027933120727539,
      "attention_bam_384_min_attention": -1.1688138246536255,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8463544834502827,
      "attention_bam_384_attention_skewness": 0.6350059680880822,
      "attention_bam_384_attention_sparsity": 0.5594965616861979,
      "attention_bam_384_attention_concentration_10": 1.0308243205421757,
      "attention_bam_384_attention_concentration_20": 1.6072639645967335,
      "attention_bam_384_attention_center_y": 0.47572694292440537,
      "attention_bam_384_attention_center_x": 0.4892665395332325,
      "attention_bam_384_attention_center_distance": 0.03753367750132498,
      "attention_bam_384_attention_spatial_variance": 171.85145409251118,
      "attention_bam_384_attention_spatial_std": 13.10921256569254,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 19.619555096000365,
      "attention_bam_384_peak_intensity_mean": 0.2984011471271515,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16991060972213745,
      "attention_bam_16_std_attention": 0.6051156520843506,
      "attention_bam_16_max_attention": 2.7262532711029053,
      "attention_bam_16_min_attention": -1.2042111158370972,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.9116713938568473,
      "attention_bam_16_attention_skewness": 0.8617489791522475,
      "attention_bam_16_attention_sparsity": 0.50537109375,
      "attention_bam_16_attention_concentration_10": 0.8348677325956022,
      "attention_bam_16_attention_concentration_20": 1.2968909997508897,
      "attention_bam_16_attention_center_y": 0.44620996444545585,
      "attention_bam_16_attention_center_x": 0.48093488594434847,
      "attention_bam_16_attention_center_distance": 0.08070745317396807,
      "attention_bam_16_attention_spatial_variance": 43.326488120490325,
      "attention_bam_16_attention_spatial_std": 6.582285934270124,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 10.695350578526416,
      "attention_bam_16_peak_intensity_mean": 0.3469561040401459,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 363,
      "phase": "train",
      "loss": 0.007756564766168594,
      "timestamp": 1759543940.5722666,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007756564766168594,
      "ssim": 0.8643455505371094,
      "attention_bam_384_mean_attention": 0.08245506137609482,
      "attention_bam_384_std_attention": 0.3711036741733551,
      "attention_bam_384_max_attention": 2.910922050476074,
      "attention_bam_384_min_attention": -1.061651349067688,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.317424058937961,
      "attention_bam_384_attention_skewness": 0.664933819391797,
      "attention_bam_384_attention_sparsity": 0.5495885213216146,
      "attention_bam_384_attention_concentration_10": 0.9779886589456259,
      "attention_bam_384_attention_concentration_20": 1.521642283614796,
      "attention_bam_384_attention_center_y": 0.4895832748009133,
      "attention_bam_384_attention_center_x": 0.4836416532009675,
      "attention_bam_384_attention_center_distance": 0.027426398738102816,
      "attention_bam_384_attention_spatial_variance": 171.2692992040714,
      "attention_bam_384_attention_spatial_std": 13.086989692212315,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 20.03878248639904,
      "attention_bam_384_peak_intensity_mean": 0.2906757593154907,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1857522577047348,
      "attention_bam_16_std_attention": 0.5831208229064941,
      "attention_bam_16_max_attention": 3.39943265914917,
      "attention_bam_16_min_attention": -1.0071675777435303,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.6611108700454738,
      "attention_bam_16_attention_skewness": 0.9324589826248121,
      "attention_bam_16_attention_sparsity": 0.498779296875,
      "attention_bam_16_attention_concentration_10": 0.7332820028232732,
      "attention_bam_16_attention_concentration_20": 1.1557607670158676,
      "attention_bam_16_attention_center_y": 0.484179922510756,
      "attention_bam_16_attention_center_x": 0.46975218253772366,
      "attention_bam_16_attention_center_distance": 0.04827432677929076,
      "attention_bam_16_attention_spatial_variance": 43.119975263907016,
      "attention_bam_16_attention_spatial_std": 6.566580180269408,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.276064972597934,
      "attention_bam_16_peak_intensity_mean": 0.28000161051750183,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 364,
      "phase": "train",
      "loss": 0.005786431487649679,
      "timestamp": 1759543940.7094607,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005786431487649679,
      "ssim": 0.9056477546691895,
      "attention_bam_384_mean_attention": 0.07878029346466064,
      "attention_bam_384_std_attention": 0.4304857850074768,
      "attention_bam_384_max_attention": 3.3183510303497314,
      "attention_bam_384_min_attention": -1.1731544733047485,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.1117356421491413,
      "attention_bam_384_attention_skewness": 0.9770184931499769,
      "attention_bam_384_attention_sparsity": 0.5675710042317709,
      "attention_bam_384_attention_concentration_10": 1.2225920282296157,
      "attention_bam_384_attention_concentration_20": 1.8384418515144343,
      "attention_bam_384_attention_center_y": 0.4864203190811466,
      "attention_bam_384_attention_center_x": 0.484047937338415,
      "attention_bam_384_attention_center_distance": 0.02962688093664285,
      "attention_bam_384_attention_spatial_variance": 172.16762384934128,
      "attention_bam_384_attention_spatial_std": 13.121266091705529,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 17.80422678243021,
      "attention_bam_384_peak_intensity_mean": 0.2873988151550293,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1592068374156952,
      "attention_bam_16_std_attention": 0.6492524743080139,
      "attention_bam_16_max_attention": 3.7312145233154297,
      "attention_bam_16_min_attention": -1.1601530313491821,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.989624133046128,
      "attention_bam_16_attention_skewness": 1.1739629881018832,
      "attention_bam_16_attention_sparsity": 0.541015625,
      "attention_bam_16_attention_concentration_10": 0.9675825682472392,
      "attention_bam_16_attention_concentration_20": 1.476179850766239,
      "attention_bam_16_attention_center_y": 0.4764534918904192,
      "attention_bam_16_attention_center_x": 0.47117012174133205,
      "attention_bam_16_attention_center_distance": 0.05264218697136679,
      "attention_bam_16_attention_spatial_variance": 43.45825094644728,
      "attention_bam_16_attention_spatial_std": 6.592287231791958,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.686501133903722,
      "attention_bam_16_peak_intensity_mean": 0.28815820813179016,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 365,
      "phase": "train",
      "loss": 0.005899567157030106,
      "timestamp": 1759543940.8508742,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005899567157030106,
      "ssim": 0.9165538549423218,
      "attention_bam_384_mean_attention": 0.0808212012052536,
      "attention_bam_384_std_attention": 0.4326598346233368,
      "attention_bam_384_max_attention": 3.0845611095428467,
      "attention_bam_384_min_attention": -1.3603768348693848,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9801225738147781,
      "attention_bam_384_attention_skewness": 0.7019931085323766,
      "attention_bam_384_attention_sparsity": 0.5561040242513021,
      "attention_bam_384_attention_concentration_10": 1.1610604999905083,
      "attention_bam_384_attention_concentration_20": 1.8011467565560217,
      "attention_bam_384_attention_center_y": 0.4835281735109831,
      "attention_bam_384_attention_center_x": 0.4788380678695047,
      "attention_bam_384_attention_center_distance": 0.03792488469013366,
      "attention_bam_384_attention_spatial_variance": 173.01984699152908,
      "attention_bam_384_attention_spatial_std": 13.153700885740449,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 19.446442218675042,
      "attention_bam_384_peak_intensity_mean": 0.3288656175136566,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17207147181034088,
      "attention_bam_16_std_attention": 0.6634077429771423,
      "attention_bam_16_max_attention": 3.4620535373687744,
      "attention_bam_16_min_attention": -1.2381843328475952,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.9324538555478847,
      "attention_bam_16_attention_skewness": 0.9063809749403416,
      "attention_bam_16_attention_sparsity": 0.530029296875,
      "attention_bam_16_attention_concentration_10": 0.8901324362046331,
      "attention_bam_16_attention_concentration_20": 1.405112837618549,
      "attention_bam_16_attention_center_y": 0.4642431957613419,
      "attention_bam_16_attention_center_x": 0.4569377016173608,
      "attention_bam_16_attention_center_distance": 0.07915694020560887,
      "attention_bam_16_attention_spatial_variance": 43.733346496773294,
      "attention_bam_16_attention_spatial_std": 6.613119271325242,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 10.219229290775942,
      "attention_bam_16_peak_intensity_mean": 0.3049774169921875,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 366,
      "phase": "train",
      "loss": 0.007221630774438381,
      "timestamp": 1759543940.9907699,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007221630774438381,
      "ssim": 0.8809969425201416,
      "attention_bam_384_mean_attention": 0.07847640663385391,
      "attention_bam_384_std_attention": 0.39564013481140137,
      "attention_bam_384_max_attention": 2.7443323135375977,
      "attention_bam_384_min_attention": -1.155454158782959,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.3796873205926179,
      "attention_bam_384_attention_skewness": 0.517387503982789,
      "attention_bam_384_attention_sparsity": 0.5537567138671875,
      "attention_bam_384_attention_concentration_10": 1.074558837341959,
      "attention_bam_384_attention_concentration_20": 1.7012880498910015,
      "attention_bam_384_attention_center_y": 0.48293908366083504,
      "attention_bam_384_attention_center_x": 0.4864220497715957,
      "attention_bam_384_attention_center_distance": 0.030836199465466233,
      "attention_bam_384_attention_spatial_variance": 170.11917397031638,
      "attention_bam_384_attention_spatial_std": 13.042974122887632,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 17.320875801233218,
      "attention_bam_384_peak_intensity_mean": 0.31805598735809326,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16505354642868042,
      "attention_bam_16_std_attention": 0.626713216304779,
      "attention_bam_16_max_attention": 2.6714365482330322,
      "attention_bam_16_min_attention": -1.2878100872039795,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.2180160514818632,
      "attention_bam_16_attention_skewness": 0.6896103040384912,
      "attention_bam_16_attention_sparsity": 0.515380859375,
      "attention_bam_16_attention_concentration_10": 0.8650620282927535,
      "attention_bam_16_attention_concentration_20": 1.3757209370651493,
      "attention_bam_16_attention_center_y": 0.46867149442473893,
      "attention_bam_16_attention_center_x": 0.47357928072584454,
      "attention_bam_16_attention_center_distance": 0.0579573924282812,
      "attention_bam_16_attention_spatial_variance": 42.45679250776124,
      "attention_bam_16_attention_spatial_std": 6.515887699136722,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.084839118722021,
      "attention_bam_16_peak_intensity_mean": 0.37071579694747925,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 367,
      "phase": "train",
      "loss": 0.008600625209510326,
      "timestamp": 1759543941.127609,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008600625209510326,
      "ssim": 0.880416750907898,
      "attention_bam_384_mean_attention": 0.0783391147851944,
      "attention_bam_384_std_attention": 0.35904359817504883,
      "attention_bam_384_max_attention": 2.7824923992156982,
      "attention_bam_384_min_attention": -1.1858654022216797,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7522311362000549,
      "attention_bam_384_attention_skewness": 0.5734738511771162,
      "attention_bam_384_attention_sparsity": 0.5556106567382812,
      "attention_bam_384_attention_concentration_10": 0.9819201385867382,
      "attention_bam_384_attention_concentration_20": 1.5587787453090656,
      "attention_bam_384_attention_center_y": 0.4835795281697305,
      "attention_bam_384_attention_center_x": 0.4810747043087387,
      "attention_bam_384_attention_center_distance": 0.035434410172326763,
      "attention_bam_384_attention_spatial_variance": 171.10604886560276,
      "attention_bam_384_attention_spatial_std": 13.08075108186081,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 18.356359233932796,
      "attention_bam_384_peak_intensity_mean": 0.3226074278354645,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16888542473316193,
      "attention_bam_16_std_attention": 0.5772483944892883,
      "attention_bam_16_max_attention": 3.3284785747528076,
      "attention_bam_16_min_attention": -1.0761423110961914,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7842319937423654,
      "attention_bam_16_attention_skewness": 0.7690614916259957,
      "attention_bam_16_attention_sparsity": 0.499755859375,
      "attention_bam_16_attention_concentration_10": 0.7838432237735745,
      "attention_bam_16_attention_concentration_20": 1.2385887091151775,
      "attention_bam_16_attention_center_y": 0.4630023168572216,
      "attention_bam_16_attention_center_x": 0.46073787857526055,
      "attention_bam_16_attention_center_distance": 0.0762934169729527,
      "attention_bam_16_attention_spatial_variance": 42.96106258303218,
      "attention_bam_16_attention_spatial_std": 6.554468901675572,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 9.021508582947925,
      "attention_bam_16_peak_intensity_mean": 0.2884542644023895,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 368,
      "phase": "train",
      "loss": 0.005334790330380201,
      "timestamp": 1759543941.264313,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005334790330380201,
      "ssim": 0.8895823359489441,
      "attention_bam_384_mean_attention": 0.07770901173353195,
      "attention_bam_384_std_attention": 0.3643878698348999,
      "attention_bam_384_max_attention": 2.581942081451416,
      "attention_bam_384_min_attention": -1.023937702178955,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7397968800027246,
      "attention_bam_384_attention_skewness": 0.5677382499186597,
      "attention_bam_384_attention_sparsity": 0.5520273844401041,
      "attention_bam_384_attention_concentration_10": 1.0110576680305725,
      "attention_bam_384_attention_concentration_20": 1.5842767830257602,
      "attention_bam_384_attention_center_y": 0.48436844726932143,
      "attention_bam_384_attention_center_x": 0.48059719206540363,
      "attention_bam_384_attention_center_distance": 0.035236753440656826,
      "attention_bam_384_attention_spatial_variance": 171.30699360595065,
      "attention_bam_384_attention_spatial_std": 13.088429760897625,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 17.12151678203481,
      "attention_bam_384_peak_intensity_mean": 0.3094184696674347,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17766189575195312,
      "attention_bam_16_std_attention": 0.569835901260376,
      "attention_bam_16_max_attention": 3.3356406688690186,
      "attention_bam_16_min_attention": -1.1362870931625366,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.45937169318854343,
      "attention_bam_16_attention_skewness": 0.6616221268015281,
      "attention_bam_16_attention_sparsity": 0.500244140625,
      "attention_bam_16_attention_concentration_10": 0.7293620364703414,
      "attention_bam_16_attention_concentration_20": 1.181318340277499,
      "attention_bam_16_attention_center_y": 0.469418575694776,
      "attention_bam_16_attention_center_x": 0.4621221673850373,
      "attention_bam_16_attention_center_distance": 0.06884698564415548,
      "attention_bam_16_attention_spatial_variance": 42.97904707116905,
      "attention_bam_16_attention_spatial_std": 6.555840683784884,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.544358827603444,
      "attention_bam_16_peak_intensity_mean": 0.29718446731567383,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 369,
      "phase": "train",
      "loss": 0.010672328993678093,
      "timestamp": 1759543941.4217095,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.010672328993678093,
      "ssim": 0.8658046126365662,
      "attention_bam_384_mean_attention": 0.08053294569253922,
      "attention_bam_384_std_attention": 0.3631778955459595,
      "attention_bam_384_max_attention": 2.4150843620300293,
      "attention_bam_384_min_attention": -1.0934576988220215,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9410407929179501,
      "attention_bam_384_attention_skewness": 0.6234060383096421,
      "attention_bam_384_attention_sparsity": 0.5572331746419271,
      "attention_bam_384_attention_concentration_10": 0.9919385314251605,
      "attention_bam_384_attention_concentration_20": 1.5367580306757018,
      "attention_bam_384_attention_center_y": 0.4877903321901924,
      "attention_bam_384_attention_center_x": 0.48824627061709913,
      "attention_bam_384_attention_center_distance": 0.02396773424553597,
      "attention_bam_384_attention_spatial_variance": 170.25264582956893,
      "attention_bam_384_attention_spatial_std": 13.048089738715355,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 18.24005403407166,
      "attention_bam_384_peak_intensity_mean": 0.3366090953350067,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.19504840672016144,
      "attention_bam_16_std_attention": 0.5684558749198914,
      "attention_bam_16_max_attention": 2.9852521419525146,
      "attention_bam_16_min_attention": -1.153244137763977,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6409185101982016,
      "attention_bam_16_attention_skewness": 0.7362842871336104,
      "attention_bam_16_attention_sparsity": 0.487548828125,
      "attention_bam_16_attention_concentration_10": 0.6870347073368506,
      "attention_bam_16_attention_concentration_20": 1.0937273505901575,
      "attention_bam_16_attention_center_y": 0.47618477590090336,
      "attention_bam_16_attention_center_x": 0.4806858543645964,
      "attention_bam_16_attention_center_distance": 0.04336360502808258,
      "attention_bam_16_attention_spatial_variance": 42.44563759117919,
      "attention_bam_16_attention_spatial_std": 6.515031664633656,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.268242612926569,
      "attention_bam_16_peak_intensity_mean": 0.32414722442626953,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 370,
      "phase": "train",
      "loss": 0.00636272132396698,
      "timestamp": 1759543941.6546993,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00636272132396698,
      "ssim": 0.8561660051345825,
      "attention_bam_384_mean_attention": 0.07753352075815201,
      "attention_bam_384_std_attention": 0.36422812938690186,
      "attention_bam_384_max_attention": 3.040663719177246,
      "attention_bam_384_min_attention": -1.1377779245376587,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.013264317637315,
      "attention_bam_384_attention_skewness": 0.9287858256182123,
      "attention_bam_384_attention_sparsity": 0.5730361938476562,
      "attention_bam_384_attention_concentration_10": 1.0538708364531377,
      "attention_bam_384_attention_concentration_20": 1.6071309894143564,
      "attention_bam_384_attention_center_y": 0.48381469807803373,
      "attention_bam_384_attention_center_x": 0.4791500009574077,
      "attention_bam_384_attention_center_distance": 0.03732791069377727,
      "attention_bam_384_attention_spatial_variance": 171.91118394264808,
      "attention_bam_384_attention_spatial_std": 13.111490530929277,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 20.11811633836815,
      "attention_bam_384_peak_intensity_mean": 0.2979460656642914,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1771538257598877,
      "attention_bam_16_std_attention": 0.5675135850906372,
      "attention_bam_16_max_attention": 3.3752622604370117,
      "attention_bam_16_min_attention": -0.9802488088607788,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.8746286357949398,
      "attention_bam_16_attention_skewness": 1.0620311989134446,
      "attention_bam_16_attention_sparsity": 0.511474609375,
      "attention_bam_16_attention_concentration_10": 0.762432254372518,
      "attention_bam_16_attention_concentration_20": 1.1826170836551746,
      "attention_bam_16_attention_center_y": 0.46794084487624094,
      "attention_bam_16_attention_center_x": 0.4555188353998528,
      "attention_bam_16_attention_center_distance": 0.07754177495304886,
      "attention_bam_16_attention_spatial_variance": 43.357528290707315,
      "attention_bam_16_attention_spatial_std": 6.584643368528573,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.662938537722036,
      "attention_bam_16_peak_intensity_mean": 0.2763056755065918,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 371,
      "phase": "train",
      "loss": 0.009895386174321175,
      "timestamp": 1759543941.8314946,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.009895386174321175,
      "ssim": 0.8280746936798096,
      "attention_bam_384_mean_attention": 0.07897496968507767,
      "attention_bam_384_std_attention": 0.3756662607192993,
      "attention_bam_384_max_attention": 2.475174903869629,
      "attention_bam_384_min_attention": -1.0138428211212158,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6287806746618632,
      "attention_bam_384_attention_skewness": 0.6301709514749574,
      "attention_bam_384_attention_sparsity": 0.5581614176432291,
      "attention_bam_384_attention_concentration_10": 1.0261035353859225,
      "attention_bam_384_attention_concentration_20": 1.6155075780374404,
      "attention_bam_384_attention_center_y": 0.4823854474797098,
      "attention_bam_384_attention_center_x": 0.49094527521595227,
      "attention_bam_384_attention_center_distance": 0.028009302076449895,
      "attention_bam_384_attention_spatial_variance": 169.6065331153595,
      "attention_bam_384_attention_spatial_std": 13.023307303268226,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 14.519354142154027,
      "attention_bam_384_peak_intensity_mean": 0.3160082697868347,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17592331767082214,
      "attention_bam_16_std_attention": 0.5791336297988892,
      "attention_bam_16_max_attention": 2.687924385070801,
      "attention_bam_16_min_attention": -1.158364176750183,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6836266678989271,
      "attention_bam_16_attention_skewness": 0.8028028788078037,
      "attention_bam_16_attention_sparsity": 0.504150390625,
      "attention_bam_16_attention_concentration_10": 0.7665918403852817,
      "attention_bam_16_attention_concentration_20": 1.2144756900848177,
      "attention_bam_16_attention_center_y": 0.46647214737422504,
      "attention_bam_16_attention_center_x": 0.48264468954060913,
      "attention_bam_16_attention_center_distance": 0.05339145442554504,
      "attention_bam_16_attention_spatial_variance": 42.05565726672209,
      "attention_bam_16_attention_spatial_std": 6.485033328111899,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.170119871725834,
      "attention_bam_16_peak_intensity_mean": 0.35036346316337585,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 372,
      "phase": "train",
      "loss": 0.004438498523086309,
      "timestamp": 1759543942.0029626,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004438498523086309,
      "ssim": 0.9088386297225952,
      "attention_bam_384_mean_attention": 0.07553009688854218,
      "attention_bam_384_std_attention": 0.35631367564201355,
      "attention_bam_384_max_attention": 2.7624993324279785,
      "attention_bam_384_min_attention": -1.0882874727249146,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.85479552321938,
      "attention_bam_384_attention_skewness": 0.8730691583328739,
      "attention_bam_384_attention_sparsity": 0.5721206665039062,
      "attention_bam_384_attention_concentration_10": 1.0514321872425347,
      "attention_bam_384_attention_concentration_20": 1.6083472963717251,
      "attention_bam_384_attention_center_y": 0.48675262345968,
      "attention_bam_384_attention_center_x": 0.48203977287717975,
      "attention_bam_384_attention_center_distance": 0.031561455717514314,
      "attention_bam_384_attention_spatial_variance": 171.5602748452967,
      "attention_bam_384_attention_spatial_std": 13.0981019558292,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 16.996490597649423,
      "attention_bam_384_peak_intensity_mean": 0.3080998659133911,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16964609920978546,
      "attention_bam_16_std_attention": 0.5705799460411072,
      "attention_bam_16_max_attention": 3.5466721057891846,
      "attention_bam_16_min_attention": -0.9974924921989441,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.839432276289199,
      "attention_bam_16_attention_skewness": 1.0459915241095736,
      "attention_bam_16_attention_sparsity": 0.507080078125,
      "attention_bam_16_attention_concentration_10": 0.8037336238154504,
      "attention_bam_16_attention_concentration_20": 1.2319988911311983,
      "attention_bam_16_attention_center_y": 0.4750254093419509,
      "attention_bam_16_attention_center_x": 0.4661082591858709,
      "attention_bam_16_attention_center_distance": 0.05953789169846739,
      "attention_bam_16_attention_spatial_variance": 43.32950277108529,
      "attention_bam_16_attention_spatial_std": 6.5825149275246835,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.348471668280876,
      "attention_bam_16_peak_intensity_mean": 0.2701873183250427,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 373,
      "phase": "train",
      "loss": 0.009561968967318535,
      "timestamp": 1759543942.165823,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.009561968967318535,
      "ssim": 0.8523014783859253,
      "attention_bam_384_mean_attention": 0.07694701850414276,
      "attention_bam_384_std_attention": 0.37439781427383423,
      "attention_bam_384_max_attention": 3.338263511657715,
      "attention_bam_384_min_attention": -1.2287981510162354,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.3205689686116697,
      "attention_bam_384_attention_skewness": 0.6896906328658123,
      "attention_bam_384_attention_sparsity": 0.5620015462239584,
      "attention_bam_384_attention_concentration_10": 1.0567753980393861,
      "attention_bam_384_attention_concentration_20": 1.639465200260169,
      "attention_bam_384_attention_center_y": 0.48253308940724626,
      "attention_bam_384_attention_center_x": 0.47785437683262727,
      "attention_bam_384_attention_center_distance": 0.039887882649409415,
      "attention_bam_384_attention_spatial_variance": 171.8253518639036,
      "attention_bam_384_attention_spatial_std": 13.108216959750994,
      "attention_bam_384_num_attention_peaks": 21,
      "attention_bam_384_peak_separation_mean": 19.414248772423164,
      "attention_bam_384_peak_intensity_mean": 0.29290154576301575,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17020952701568604,
      "attention_bam_16_std_attention": 0.5910495519638062,
      "attention_bam_16_max_attention": 3.1030688285827637,
      "attention_bam_16_min_attention": -1.0930655002593994,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6007064902051704,
      "attention_bam_16_attention_skewness": 0.7086223060609075,
      "attention_bam_16_attention_sparsity": 0.49951171875,
      "attention_bam_16_attention_concentration_10": 0.7872222778512696,
      "attention_bam_16_attention_concentration_20": 1.2524712481286866,
      "attention_bam_16_attention_center_y": 0.4631871037323126,
      "attention_bam_16_attention_center_x": 0.45176140394946973,
      "attention_bam_16_attention_center_distance": 0.08581551701809817,
      "attention_bam_16_attention_spatial_variance": 43.428367579760824,
      "attention_bam_16_attention_spatial_std": 6.590020301923267,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 10.251006657437255,
      "attention_bam_16_peak_intensity_mean": 0.30696550011634827,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 374,
      "phase": "train",
      "loss": 0.006348118185997009,
      "timestamp": 1759543942.3196187,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006348118185997009,
      "ssim": 0.8911930322647095,
      "attention_bam_384_mean_attention": 0.07826673239469528,
      "attention_bam_384_std_attention": 0.3535018861293793,
      "attention_bam_384_max_attention": 2.774848222732544,
      "attention_bam_384_min_attention": -1.0728893280029297,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.9455827988796406,
      "attention_bam_384_attention_skewness": 0.8700999931416582,
      "attention_bam_384_attention_sparsity": 0.5681076049804688,
      "attention_bam_384_attention_concentration_10": 1.0069481363248707,
      "attention_bam_384_attention_concentration_20": 1.5376176249862128,
      "attention_bam_384_attention_center_y": 0.48729139785282655,
      "attention_bam_384_attention_center_x": 0.47721625552360314,
      "attention_bam_384_attention_center_distance": 0.0368946495010018,
      "attention_bam_384_attention_spatial_variance": 169.84911183149603,
      "attention_bam_384_attention_spatial_std": 13.032617228764758,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 20.971315285776328,
      "attention_bam_384_peak_intensity_mean": 0.30344894528388977,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18592306971549988,
      "attention_bam_16_std_attention": 0.5479030609130859,
      "attention_bam_16_max_attention": 3.1009814739227295,
      "attention_bam_16_min_attention": -0.9817640781402588,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.3901311271156782,
      "attention_bam_16_attention_skewness": 0.9364540304495481,
      "attention_bam_16_attention_sparsity": 0.48291015625,
      "attention_bam_16_attention_concentration_10": 0.7101076324939698,
      "attention_bam_16_attention_concentration_20": 1.1007575005750263,
      "attention_bam_16_attention_center_y": 0.47348315518681494,
      "attention_bam_16_attention_center_x": 0.4497755160475652,
      "attention_bam_16_attention_center_distance": 0.0803198835548822,
      "attention_bam_16_attention_spatial_variance": 41.90992716082581,
      "attention_bam_16_attention_spatial_std": 6.473787698158305,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.622108158577621,
      "attention_bam_16_peak_intensity_mean": 0.2969110906124115,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 375,
      "phase": "train",
      "loss": 0.015465393662452698,
      "timestamp": 1759543942.4657006,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.015465393662452698,
      "ssim": 0.8567320108413696,
      "attention_bam_384_mean_attention": 0.07401291280984879,
      "attention_bam_384_std_attention": 0.38315141201019287,
      "attention_bam_384_max_attention": 2.9520254135131836,
      "attention_bam_384_min_attention": -1.088369607925415,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1136821216431159,
      "attention_bam_384_attention_skewness": 0.6897745252649318,
      "attention_bam_384_attention_sparsity": 0.5599746704101562,
      "attention_bam_384_attention_concentration_10": 1.1106408146637226,
      "attention_bam_384_attention_concentration_20": 1.7280005787615598,
      "attention_bam_384_attention_center_y": 0.48497196809558335,
      "attention_bam_384_attention_center_x": 0.482937129312537,
      "attention_bam_384_attention_center_distance": 0.03215535100157509,
      "attention_bam_384_attention_spatial_variance": 172.09260793804447,
      "attention_bam_384_attention_spatial_std": 13.118407218029347,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 18.54808528724509,
      "attention_bam_384_peak_intensity_mean": 0.28937122225761414,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.15734368562698364,
      "attention_bam_16_std_attention": 0.6332917213439941,
      "attention_bam_16_max_attention": 3.300593376159668,
      "attention_bam_16_min_attention": -1.1329450607299805,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.9133011472500909,
      "attention_bam_16_attention_skewness": 0.8570060749707067,
      "attention_bam_16_attention_sparsity": 0.51318359375,
      "attention_bam_16_attention_concentration_10": 0.9267687682470226,
      "attention_bam_16_attention_concentration_20": 1.4331045018906057,
      "attention_bam_16_attention_center_y": 0.4689725453059565,
      "attention_bam_16_attention_center_x": 0.4665069781442716,
      "attention_bam_16_attention_center_distance": 0.06456756860559675,
      "attention_bam_16_attention_spatial_variance": 43.667160559648735,
      "attention_bam_16_attention_spatial_std": 6.608113237501968,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.552850994021359,
      "attention_bam_16_peak_intensity_mean": 0.29297342896461487,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 376,
      "phase": "train",
      "loss": 0.004731006920337677,
      "timestamp": 1759543942.5982022,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004731006920337677,
      "ssim": 0.9050285816192627,
      "attention_bam_384_mean_attention": 0.07804384082555771,
      "attention_bam_384_std_attention": 0.3771914839744568,
      "attention_bam_384_max_attention": 3.408421516418457,
      "attention_bam_384_min_attention": -1.2715489864349365,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9081913508210473,
      "attention_bam_384_attention_skewness": 0.646701465281464,
      "attention_bam_384_attention_sparsity": 0.5603561401367188,
      "attention_bam_384_attention_concentration_10": 1.0486410615475499,
      "attention_bam_384_attention_concentration_20": 1.644072119035371,
      "attention_bam_384_attention_center_y": 0.48469251790182694,
      "attention_bam_384_attention_center_x": 0.4871340153925254,
      "attention_bam_384_attention_center_distance": 0.028279058262455015,
      "attention_bam_384_attention_spatial_variance": 171.90657839291072,
      "attention_bam_384_attention_spatial_std": 13.111314899464153,
      "attention_bam_384_num_attention_peaks": 18,
      "attention_bam_384_peak_separation_mean": 19.920833524831984,
      "attention_bam_384_peak_intensity_mean": 0.2932051122188568,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17466501891613007,
      "attention_bam_16_std_attention": 0.5920640826225281,
      "attention_bam_16_max_attention": 3.2277424335479736,
      "attention_bam_16_min_attention": -1.1034060716629028,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5527196446393434,
      "attention_bam_16_attention_skewness": 0.7256859593248132,
      "attention_bam_16_attention_sparsity": 0.50244140625,
      "attention_bam_16_attention_concentration_10": 0.7824790721202644,
      "attention_bam_16_attention_concentration_20": 1.2375715678211765,
      "attention_bam_16_attention_center_y": 0.4684081631829468,
      "attention_bam_16_attention_center_x": 0.48020035909147485,
      "attention_bam_16_attention_center_distance": 0.05272703165515503,
      "attention_bam_16_attention_spatial_variance": 43.62729472117387,
      "attention_bam_16_attention_spatial_std": 6.605096117481854,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.138149569027972,
      "attention_bam_16_peak_intensity_mean": 0.3039076626300812,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 377,
      "phase": "train",
      "loss": 0.006971587426960468,
      "timestamp": 1759543942.7346282,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006971587426960468,
      "ssim": 0.8925967216491699,
      "attention_bam_384_mean_attention": 0.07653418183326721,
      "attention_bam_384_std_attention": 0.3844338059425354,
      "attention_bam_384_max_attention": 2.9697909355163574,
      "attention_bam_384_min_attention": -1.1418430805206299,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9895781239945554,
      "attention_bam_384_attention_skewness": 0.6494884706998936,
      "attention_bam_384_attention_sparsity": 0.5581232706705729,
      "attention_bam_384_attention_concentration_10": 1.0835403961714338,
      "attention_bam_384_attention_concentration_20": 1.6936869230644787,
      "attention_bam_384_attention_center_y": 0.48367375954843045,
      "attention_bam_384_attention_center_x": 0.48709490862871885,
      "attention_bam_384_attention_center_distance": 0.02943085151957317,
      "attention_bam_384_attention_spatial_variance": 170.7624427356626,
      "attention_bam_384_attention_spatial_std": 13.067610444747066,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 17.957863244506946,
      "attention_bam_384_peak_intensity_mean": 0.3006608784198761,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16852475702762604,
      "attention_bam_16_std_attention": 0.6125759482383728,
      "attention_bam_16_max_attention": 3.411003828048706,
      "attention_bam_16_min_attention": -1.183749794960022,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7549209417342198,
      "attention_bam_16_attention_skewness": 0.8102433944375655,
      "attention_bam_16_attention_sparsity": 0.511962890625,
      "attention_bam_16_attention_concentration_10": 0.844330056873547,
      "attention_bam_16_attention_concentration_20": 1.3250882332854441,
      "attention_bam_16_attention_center_y": 0.46629558360614193,
      "attention_bam_16_attention_center_x": 0.4768857214014444,
      "attention_bam_16_attention_center_distance": 0.05779718954382147,
      "attention_bam_16_attention_spatial_variance": 42.86432731892002,
      "attention_bam_16_attention_spatial_std": 6.54708540641712,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.346646351423788,
      "attention_bam_16_peak_intensity_mean": 0.3046891391277313,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 378,
      "phase": "train",
      "loss": 0.006746209226548672,
      "timestamp": 1759543942.9084034,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006746209226548672,
      "ssim": 0.8739376068115234,
      "attention_bam_384_mean_attention": 0.08086196333169937,
      "attention_bam_384_std_attention": 0.38800889253616333,
      "attention_bam_384_max_attention": 3.1277809143066406,
      "attention_bam_384_min_attention": -1.2431570291519165,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8439397586956314,
      "attention_bam_384_attention_skewness": 0.8470950953857577,
      "attention_bam_384_attention_sparsity": 0.5602900187174479,
      "attention_bam_384_attention_concentration_10": 1.0719355799929342,
      "attention_bam_384_attention_concentration_20": 1.619854047346785,
      "attention_bam_384_attention_center_y": 0.48726810791968705,
      "attention_bam_384_attention_center_x": 0.48502763730369153,
      "attention_bam_384_attention_center_distance": 0.027794701676921985,
      "attention_bam_384_attention_spatial_variance": 169.42421966084876,
      "attention_bam_384_attention_spatial_std": 13.016305914538455,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 17.825784941412653,
      "attention_bam_384_peak_intensity_mean": 0.3065609633922577,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1844722330570221,
      "attention_bam_16_std_attention": 0.6035844087600708,
      "attention_bam_16_max_attention": 3.3139753341674805,
      "attention_bam_16_min_attention": -1.161865234375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.5444438272146686,
      "attention_bam_16_attention_skewness": 1.009854458718796,
      "attention_bam_16_attention_sparsity": 0.506103515625,
      "attention_bam_16_attention_concentration_10": 0.7846043715578953,
      "attention_bam_16_attention_concentration_20": 1.2065844450951575,
      "attention_bam_16_attention_center_y": 0.4749117527510309,
      "attention_bam_16_attention_center_x": 0.47357915547206786,
      "attention_bam_16_attention_center_distance": 0.05152632677757198,
      "attention_bam_16_attention_spatial_variance": 41.859010087413466,
      "attention_bam_16_attention_spatial_std": 6.469853946374173,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.009212577674901,
      "attention_bam_16_peak_intensity_mean": 0.31003811955451965,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 379,
      "phase": "train",
      "loss": 0.00573860015720129,
      "timestamp": 1759543943.0985324,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00573860015720129,
      "ssim": 0.8906640410423279,
      "attention_bam_384_mean_attention": 0.07613474875688553,
      "attention_bam_384_std_attention": 0.37108364701271057,
      "attention_bam_384_max_attention": 3.1604576110839844,
      "attention_bam_384_min_attention": -1.0018352270126343,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7107575786881517,
      "attention_bam_384_attention_skewness": 0.6388891617705419,
      "attention_bam_384_attention_sparsity": 0.5658594767252604,
      "attention_bam_384_attention_concentration_10": 1.0682328034730366,
      "attention_bam_384_attention_concentration_20": 1.6650736726040647,
      "attention_bam_384_attention_center_y": 0.4851864061487248,
      "attention_bam_384_attention_center_x": 0.4792721502713241,
      "attention_bam_384_attention_center_distance": 0.03603016284073964,
      "attention_bam_384_attention_spatial_variance": 172.72662222070116,
      "attention_bam_384_attention_spatial_std": 13.142550065367876,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 17.43807302599072,
      "attention_bam_384_peak_intensity_mean": 0.2604508399963379,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.172396719455719,
      "attention_bam_16_std_attention": 0.5662845969200134,
      "attention_bam_16_max_attention": 2.884165048599243,
      "attention_bam_16_min_attention": -0.9893968105316162,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.376290598571007,
      "attention_bam_16_attention_skewness": 0.7042590269811978,
      "attention_bam_16_attention_sparsity": 0.50390625,
      "attention_bam_16_attention_concentration_10": 0.7660803357176641,
      "attention_bam_16_attention_concentration_20": 1.211849449061559,
      "attention_bam_16_attention_center_y": 0.47212732098086985,
      "attention_bam_16_attention_center_x": 0.4561211724264506,
      "attention_bam_16_attention_center_distance": 0.07351513782797031,
      "attention_bam_16_attention_spatial_variance": 43.90931148273984,
      "attention_bam_16_attention_spatial_std": 6.626410150506822,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.531596401352093,
      "attention_bam_16_peak_intensity_mean": 0.30166274309158325,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 380,
      "phase": "train",
      "loss": 0.005609977524727583,
      "timestamp": 1759543943.3030148,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005609977524727583,
      "ssim": 0.8899269104003906,
      "attention_bam_384_mean_attention": 0.07575662434101105,
      "attention_bam_384_std_attention": 0.3674870431423187,
      "attention_bam_384_max_attention": 3.3146204948425293,
      "attention_bam_384_min_attention": -1.1793441772460938,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.1374520982049097,
      "attention_bam_384_attention_skewness": 0.9166950941764872,
      "attention_bam_384_attention_sparsity": 0.5716044108072916,
      "attention_bam_384_attention_concentration_10": 1.0790601228452805,
      "attention_bam_384_attention_concentration_20": 1.642397764515861,
      "attention_bam_384_attention_center_y": 0.48567643208883793,
      "attention_bam_384_attention_center_x": 0.47737313429803574,
      "attention_bam_384_attention_center_distance": 0.03787188004840526,
      "attention_bam_384_attention_spatial_variance": 170.70699482980822,
      "attention_bam_384_attention_spatial_std": 13.06548869464163,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 20.020232234130443,
      "attention_bam_384_peak_intensity_mean": 0.2794254422187805,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16999492049217224,
      "attention_bam_16_std_attention": 0.5936526656150818,
      "attention_bam_16_max_attention": 3.380885124206543,
      "attention_bam_16_min_attention": -1.0818593502044678,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.9323464439620999,
      "attention_bam_16_attention_skewness": 1.069406023703205,
      "attention_bam_16_attention_sparsity": 0.515625,
      "attention_bam_16_attention_concentration_10": 0.825037609013125,
      "attention_bam_16_attention_concentration_20": 1.271322138877687,
      "attention_bam_16_attention_center_y": 0.4725295212527551,
      "attention_bam_16_attention_center_x": 0.4496057661361616,
      "attention_bam_16_attention_center_distance": 0.0811690336190603,
      "attention_bam_16_attention_spatial_variance": 42.70729395624841,
      "attention_bam_16_attention_spatial_std": 6.535081786500335,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.915435836792653,
      "attention_bam_16_peak_intensity_mean": 0.28154513239860535,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 381,
      "phase": "train",
      "loss": 0.006278488785028458,
      "timestamp": 1759543943.4670038,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006278488785028458,
      "ssim": 0.9011147618293762,
      "attention_bam_384_mean_attention": 0.07818055897951126,
      "attention_bam_384_std_attention": 0.33978328108787537,
      "attention_bam_384_max_attention": 2.8672921657562256,
      "attention_bam_384_min_attention": -1.0625547170639038,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.576256589310833,
      "attention_bam_384_attention_skewness": 0.7388283638056153,
      "attention_bam_384_attention_sparsity": 0.5598805745442709,
      "attention_bam_384_attention_concentration_10": 0.9587678389051397,
      "attention_bam_384_attention_concentration_20": 1.4779869534758125,
      "attention_bam_384_attention_center_y": 0.4886514920314179,
      "attention_bam_384_attention_center_x": 0.48391584740229,
      "attention_bam_384_attention_center_distance": 0.027838412235592507,
      "attention_bam_384_attention_spatial_variance": 172.99878250875955,
      "attention_bam_384_attention_spatial_std": 13.152900155812008,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 19.45743685518996,
      "attention_bam_384_peak_intensity_mean": 0.2909590005874634,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18868911266326904,
      "attention_bam_16_std_attention": 0.5427435040473938,
      "attention_bam_16_max_attention": 3.188417434692383,
      "attention_bam_16_min_attention": -0.9700373411178589,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.6308041664410613,
      "attention_bam_16_attention_skewness": 0.9265063157037147,
      "attention_bam_16_attention_sparsity": 0.47607421875,
      "attention_bam_16_attention_concentration_10": 0.689914767064667,
      "attention_bam_16_attention_concentration_20": 1.068325410846031,
      "attention_bam_16_attention_center_y": 0.47963094706436266,
      "attention_bam_16_attention_center_x": 0.46518849861974315,
      "attention_bam_16_attention_center_distance": 0.057039266226739285,
      "attention_bam_16_attention_spatial_variance": 44.225872694596305,
      "attention_bam_16_attention_spatial_std": 6.650253581225027,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.151850675668733,
      "attention_bam_16_peak_intensity_mean": 0.2824012339115143,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 382,
      "phase": "train",
      "loss": 0.006530970335006714,
      "timestamp": 1759543943.6053815,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006530970335006714,
      "ssim": 0.8892432451248169,
      "attention_bam_384_mean_attention": 0.0734432116150856,
      "attention_bam_384_std_attention": 0.378315269947052,
      "attention_bam_384_max_attention": 2.611027956008911,
      "attention_bam_384_min_attention": -1.0577949285507202,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4214936236460884,
      "attention_bam_384_attention_skewness": 0.8831487796789671,
      "attention_bam_384_attention_sparsity": 0.5788192749023438,
      "attention_bam_384_attention_concentration_10": 1.155420046648906,
      "attention_bam_384_attention_concentration_20": 1.7574806885825391,
      "attention_bam_384_attention_center_y": 0.4911975065505058,
      "attention_bam_384_attention_center_x": 0.488196576258431,
      "attention_bam_384_attention_center_distance": 0.020823289987483867,
      "attention_bam_384_attention_spatial_variance": 167.9915112607324,
      "attention_bam_384_attention_spatial_std": 12.961153932452635,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 13.679226048523322,
      "attention_bam_384_peak_intensity_mean": 0.31111273169517517,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16411620378494263,
      "attention_bam_16_std_attention": 0.5914339423179626,
      "attention_bam_16_max_attention": 2.6632537841796875,
      "attention_bam_16_min_attention": -1.1503714323043823,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7050122627142312,
      "attention_bam_16_attention_skewness": 0.8973462598904086,
      "attention_bam_16_attention_sparsity": 0.5341796875,
      "attention_bam_16_attention_concentration_10": 0.8544474621006736,
      "attention_bam_16_attention_concentration_20": 1.336730178126292,
      "attention_bam_16_attention_center_y": 0.4828174100076441,
      "attention_bam_16_attention_center_x": 0.47828171121973007,
      "attention_bam_16_attention_center_distance": 0.03916440900584631,
      "attention_bam_16_attention_spatial_variance": 41.41300043356494,
      "attention_bam_16_attention_spatial_std": 6.435293344795165,
      "attention_bam_16_num_attention_peaks": 2,
      "attention_bam_16_peak_separation_mean": 10.182494782714107,
      "attention_bam_16_peak_intensity_mean": 0.3551188111305237,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 383,
      "phase": "train",
      "loss": 0.005465355701744556,
      "timestamp": 1759543943.7431357,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005465355701744556,
      "ssim": 0.9032974243164062,
      "attention_bam_384_mean_attention": 0.07670231908559799,
      "attention_bam_384_std_attention": 0.31785568594932556,
      "attention_bam_384_max_attention": 2.480591297149658,
      "attention_bam_384_min_attention": -0.9850309491157532,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.14358023874771053,
      "attention_bam_384_attention_skewness": 0.38682524341603874,
      "attention_bam_384_attention_sparsity": 0.5549290974934896,
      "attention_bam_384_attention_concentration_10": 0.8794989734955477,
      "attention_bam_384_attention_concentration_20": 1.4188694537832705,
      "attention_bam_384_attention_center_y": 0.4814672878099995,
      "attention_bam_384_attention_center_x": 0.4846827322272585,
      "attention_bam_384_attention_center_distance": 0.034002356187160306,
      "attention_bam_384_attention_spatial_variance": 170.7461349509559,
      "attention_bam_384_attention_spatial_std": 13.06698645254352,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 17.21484000402742,
      "attention_bam_384_peak_intensity_mean": 0.30867740511894226,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.18257474899291992,
      "attention_bam_16_std_attention": 0.5025569200515747,
      "attention_bam_16_max_attention": 2.3145318031311035,
      "attention_bam_16_min_attention": -0.9809005856513977,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.02569614531649167,
      "attention_bam_16_attention_skewness": 0.4361028877547284,
      "attention_bam_16_attention_sparsity": 0.46435546875,
      "attention_bam_16_attention_concentration_10": 0.6271187305178529,
      "attention_bam_16_attention_concentration_20": 1.021245579622111,
      "attention_bam_16_attention_center_y": 0.46123434012653736,
      "attention_bam_16_attention_center_x": 0.4692350298850224,
      "attention_bam_16_attention_center_distance": 0.0699894245097137,
      "attention_bam_16_attention_spatial_variance": 42.76563041669476,
      "attention_bam_16_attention_spatial_std": 6.539543593913474,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.505865610043754,
      "attention_bam_16_peak_intensity_mean": 0.3659125566482544,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 384,
      "phase": "train",
      "loss": 0.005843363236635923,
      "timestamp": 1759543943.8764877,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005843363236635923,
      "ssim": 0.8951961994171143,
      "attention_bam_384_mean_attention": 0.07392700016498566,
      "attention_bam_384_std_attention": 0.38168737292289734,
      "attention_bam_384_max_attention": 2.8607871532440186,
      "attention_bam_384_min_attention": -1.3147624731063843,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.084026326590166,
      "attention_bam_384_attention_skewness": 0.9290106931571885,
      "attention_bam_384_attention_sparsity": 0.5754318237304688,
      "attention_bam_384_attention_concentration_10": 1.152918563149288,
      "attention_bam_384_attention_concentration_20": 1.7382855114906395,
      "attention_bam_384_attention_center_y": 0.4803533682717949,
      "attention_bam_384_attention_center_x": 0.48995921307927254,
      "attention_bam_384_attention_center_distance": 0.03120280565113227,
      "attention_bam_384_attention_spatial_variance": 171.0937603138825,
      "attention_bam_384_attention_spatial_std": 13.080281354538307,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 17.07531598159022,
      "attention_bam_384_peak_intensity_mean": 0.33495834469795227,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16133838891983032,
      "attention_bam_16_std_attention": 0.6211271286010742,
      "attention_bam_16_max_attention": 3.139643907546997,
      "attention_bam_16_min_attention": -1.1703437566757202,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.4965299097315814,
      "attention_bam_16_attention_skewness": 1.0284569011901155,
      "attention_bam_16_attention_sparsity": 0.52783203125,
      "attention_bam_16_attention_concentration_10": 0.9027993847970143,
      "attention_bam_16_attention_concentration_20": 1.3864960549278538,
      "attention_bam_16_attention_center_y": 0.45546507081291754,
      "attention_bam_16_attention_center_x": 0.48750488065786474,
      "attention_bam_16_attention_center_distance": 0.06541388117322885,
      "attention_bam_16_attention_spatial_variance": 43.10265053157104,
      "attention_bam_16_attention_spatial_std": 6.56526088830985,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.283852213491217,
      "attention_bam_16_peak_intensity_mean": 0.30528613924980164,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 385,
      "phase": "train",
      "loss": 0.007143436931073666,
      "timestamp": 1759543944.206457,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007143436931073666,
      "ssim": 0.8746391534805298,
      "attention_bam_384_mean_attention": 0.06995999068021774,
      "attention_bam_384_std_attention": 0.3504413068294525,
      "attention_bam_384_max_attention": 3.122953414916992,
      "attention_bam_384_min_attention": -1.0528059005737305,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5634836883862704,
      "attention_bam_384_attention_skewness": 0.848547072403863,
      "attention_bam_384_attention_sparsity": 0.5774154663085938,
      "attention_bam_384_attention_concentration_10": 1.1116727486338334,
      "attention_bam_384_attention_concentration_20": 1.6980117440021045,
      "attention_bam_384_attention_center_y": 0.48885942030660606,
      "attention_bam_384_attention_center_x": 0.488352428792086,
      "attention_bam_384_attention_center_distance": 0.022793789985357336,
      "attention_bam_384_attention_spatial_variance": 170.83283695083904,
      "attention_bam_384_attention_spatial_std": 13.070303628869492,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 19.987011192837286,
      "attention_bam_384_peak_intensity_mean": 0.26634901762008667,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16103588044643402,
      "attention_bam_16_std_attention": 0.5534308552742004,
      "attention_bam_16_max_attention": 2.7876040935516357,
      "attention_bam_16_min_attention": -1.1051239967346191,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.1053741516573679,
      "attention_bam_16_attention_skewness": 0.9091241335408722,
      "attention_bam_16_attention_sparsity": 0.51708984375,
      "attention_bam_16_attention_concentration_10": 0.8136789940780329,
      "attention_bam_16_attention_concentration_20": 1.2594267477128025,
      "attention_bam_16_attention_center_y": 0.4790487893047553,
      "attention_bam_16_attention_center_x": 0.4791345429496193,
      "attention_bam_16_attention_center_distance": 0.04181675567324218,
      "attention_bam_16_attention_spatial_variance": 42.65184243069056,
      "attention_bam_16_attention_spatial_std": 6.53083780465344,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.969767671444949,
      "attention_bam_16_peak_intensity_mean": 0.32868435978889465,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 386,
      "phase": "train",
      "loss": 0.005081228446215391,
      "timestamp": 1759543944.341228,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005081228446215391,
      "ssim": 0.8938370943069458,
      "attention_bam_384_mean_attention": 0.0707005187869072,
      "attention_bam_384_std_attention": 0.35541778802871704,
      "attention_bam_384_max_attention": 3.0556888580322266,
      "attention_bam_384_min_attention": -1.088330626487732,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.4596493736139893,
      "attention_bam_384_attention_skewness": 0.9754767927563364,
      "attention_bam_384_attention_sparsity": 0.5783233642578125,
      "attention_bam_384_attention_concentration_10": 1.117863741292037,
      "attention_bam_384_attention_concentration_20": 1.685082803060875,
      "attention_bam_384_attention_center_y": 0.49084525961670084,
      "attention_bam_384_attention_center_x": 0.4853584916771777,
      "attention_bam_384_attention_center_distance": 0.024420607586744563,
      "attention_bam_384_attention_spatial_variance": 173.63743738912046,
      "attention_bam_384_attention_spatial_std": 13.177155891508624,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 20.65078044724417,
      "attention_bam_384_peak_intensity_mean": 0.28516772389411926,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16363468766212463,
      "attention_bam_16_std_attention": 0.5673214197158813,
      "attention_bam_16_max_attention": 3.205228567123413,
      "attention_bam_16_min_attention": -1.096735954284668,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.644340162727235,
      "attention_bam_16_attention_skewness": 1.0173617371670893,
      "attention_bam_16_attention_sparsity": 0.51025390625,
      "attention_bam_16_attention_concentration_10": 0.8201242872103227,
      "attention_bam_16_attention_concentration_20": 1.260370366506659,
      "attention_bam_16_attention_center_y": 0.48658429629115013,
      "attention_bam_16_attention_center_x": 0.47120547999365353,
      "attention_bam_16_attention_center_distance": 0.04492450307793142,
      "attention_bam_16_attention_spatial_variance": 44.38765895809156,
      "attention_bam_16_attention_spatial_std": 6.662406393945926,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 11.154685899128326,
      "attention_bam_16_peak_intensity_mean": 0.3062683343887329,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 387,
      "phase": "train",
      "loss": 0.005136109888553619,
      "timestamp": 1759543944.4754517,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005136109888553619,
      "ssim": 0.9001578688621521,
      "attention_bam_384_mean_attention": 0.07218224555253983,
      "attention_bam_384_std_attention": 0.3888779580593109,
      "attention_bam_384_max_attention": 3.2876014709472656,
      "attention_bam_384_min_attention": -1.1084246635437012,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.79531816698848,
      "attention_bam_384_attention_skewness": 0.8945184757316479,
      "attention_bam_384_attention_sparsity": 0.5799357096354166,
      "attention_bam_384_attention_concentration_10": 1.2048634598211607,
      "attention_bam_384_attention_concentration_20": 1.8113706893496229,
      "attention_bam_384_attention_center_y": 0.4884323506962541,
      "attention_bam_384_attention_center_x": 0.486539393307908,
      "attention_bam_384_attention_center_distance": 0.025099738760937084,
      "attention_bam_384_attention_spatial_variance": 170.9599594917489,
      "attention_bam_384_attention_spatial_std": 13.075165753891952,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 15.325106955542905,
      "attention_bam_384_peak_intensity_mean": 0.2715282440185547,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16545820236206055,
      "attention_bam_16_std_attention": 0.6080968976020813,
      "attention_bam_16_max_attention": 3.352168321609497,
      "attention_bam_16_min_attention": -1.1346019506454468,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.2380767375398998,
      "attention_bam_16_attention_skewness": 0.9296518744416821,
      "attention_bam_16_attention_sparsity": 0.522216796875,
      "attention_bam_16_attention_concentration_10": 0.8661155836767106,
      "attention_bam_16_attention_concentration_20": 1.3403102493815044,
      "attention_bam_16_attention_center_y": 0.4790380138953246,
      "attention_bam_16_attention_center_x": 0.4750520663370784,
      "attention_bam_16_attention_center_distance": 0.0460826269976472,
      "attention_bam_16_attention_spatial_variance": 42.89598421675986,
      "attention_bam_16_attention_spatial_std": 6.549502593079864,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.160283193464707,
      "attention_bam_16_peak_intensity_mean": 0.2952892780303955,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 388,
      "phase": "train",
      "loss": 0.006555397063493729,
      "timestamp": 1759543944.6099665,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006555397063493729,
      "ssim": 0.8903377652168274,
      "attention_bam_384_mean_attention": 0.07377100735902786,
      "attention_bam_384_std_attention": 0.3384827673435211,
      "attention_bam_384_max_attention": 2.6784634590148926,
      "attention_bam_384_min_attention": -1.0420693159103394,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8644132584018007,
      "attention_bam_384_attention_skewness": 0.6180708930752231,
      "attention_bam_384_attention_sparsity": 0.5646692911783854,
      "attention_bam_384_attention_concentration_10": 0.9908937921495182,
      "attention_bam_384_attention_concentration_20": 1.5605641666278625,
      "attention_bam_384_attention_center_y": 0.48397713695836914,
      "attention_bam_384_attention_center_x": 0.4810020181447546,
      "attention_bam_384_attention_center_distance": 0.03514699004532521,
      "attention_bam_384_attention_spatial_variance": 170.37033339523984,
      "attention_bam_384_attention_spatial_std": 13.052598721911275,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 17.162101264668514,
      "attention_bam_384_peak_intensity_mean": 0.3022288680076599,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16792377829551697,
      "attention_bam_16_std_attention": 0.548581063747406,
      "attention_bam_16_max_attention": 2.7476866245269775,
      "attention_bam_16_min_attention": -1.1563200950622559,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6698742917198506,
      "attention_bam_16_attention_skewness": 0.6934671341061732,
      "attention_bam_16_attention_sparsity": 0.496337890625,
      "attention_bam_16_attention_concentration_10": 0.7422547118252313,
      "attention_bam_16_attention_concentration_20": 1.1890201535449885,
      "attention_bam_16_attention_center_y": 0.4681420054679689,
      "attention_bam_16_attention_center_x": 0.46087333147464626,
      "attention_bam_16_attention_center_distance": 0.07135584076297931,
      "attention_bam_16_attention_spatial_variance": 42.45037133084306,
      "attention_bam_16_attention_spatial_std": 6.515394948185648,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.532522229000456,
      "attention_bam_16_peak_intensity_mean": 0.34564128518104553,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 389,
      "phase": "train",
      "loss": 0.005376184359192848,
      "timestamp": 1759543944.74796,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005376184359192848,
      "ssim": 0.9168763756752014,
      "attention_bam_384_mean_attention": 0.0744004026055336,
      "attention_bam_384_std_attention": 0.33808812499046326,
      "attention_bam_384_max_attention": 2.9626474380493164,
      "attention_bam_384_min_attention": -1.0940263271331787,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5649211662012927,
      "attention_bam_384_attention_skewness": 0.470909035488416,
      "attention_bam_384_attention_sparsity": 0.55670166015625,
      "attention_bam_384_attention_concentration_10": 0.965490647435576,
      "attention_bam_384_attention_concentration_20": 1.5386397290027707,
      "attention_bam_384_attention_center_y": 0.48367532351550696,
      "attention_bam_384_attention_center_x": 0.4843939759455965,
      "attention_bam_384_attention_center_distance": 0.03193878673681829,
      "attention_bam_384_attention_spatial_variance": 172.36703752546518,
      "attention_bam_384_attention_spatial_std": 13.1288627658859,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 19.733787204859038,
      "attention_bam_384_peak_intensity_mean": 0.2915005385875702,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17698080837726593,
      "attention_bam_16_std_attention": 0.5447340607643127,
      "attention_bam_16_max_attention": 2.5262508392333984,
      "attention_bam_16_min_attention": -1.0810482501983643,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.028399831310860435,
      "attention_bam_16_attention_skewness": 0.48479155664280776,
      "attention_bam_16_attention_sparsity": 0.474609375,
      "attention_bam_16_attention_concentration_10": 0.6909212029460011,
      "attention_bam_16_attention_concentration_20": 1.1269780594761711,
      "attention_bam_16_attention_center_y": 0.4661969159367464,
      "attention_bam_16_attention_center_x": 0.4706258850341777,
      "attention_bam_16_attention_center_distance": 0.0633322527976502,
      "attention_bam_16_attention_spatial_variance": 43.91391585565318,
      "attention_bam_16_attention_spatial_std": 6.62675756729135,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.163675929266354,
      "attention_bam_16_peak_intensity_mean": 0.3632839620113373,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 390,
      "phase": "train",
      "loss": 0.007864909246563911,
      "timestamp": 1759543944.9569366,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007864909246563911,
      "ssim": 0.8912276029586792,
      "attention_bam_384_mean_attention": 0.07289600372314453,
      "attention_bam_384_std_attention": 0.33460211753845215,
      "attention_bam_384_max_attention": 2.58815860748291,
      "attention_bam_384_min_attention": -1.1371023654937744,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.151975867448801,
      "attention_bam_384_attention_skewness": 0.9242932185461431,
      "attention_bam_384_attention_sparsity": 0.5724461873372396,
      "attention_bam_384_attention_concentration_10": 1.0175664817645842,
      "attention_bam_384_attention_concentration_20": 1.5510998164059984,
      "attention_bam_384_attention_center_y": 0.4813478337595983,
      "attention_bam_384_attention_center_x": 0.4789254226333609,
      "attention_bam_384_attention_center_distance": 0.03980053056535901,
      "attention_bam_384_attention_spatial_variance": 171.6449115730883,
      "attention_bam_384_attention_spatial_std": 13.101332435026917,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 18.883205788430807,
      "attention_bam_384_peak_intensity_mean": 0.3279290199279785,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1584806591272354,
      "attention_bam_16_std_attention": 0.5533305406570435,
      "attention_bam_16_max_attention": 3.123699426651001,
      "attention_bam_16_min_attention": -1.006387710571289,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.5352935003106953,
      "attention_bam_16_attention_skewness": 0.964503830779138,
      "attention_bam_16_attention_sparsity": 0.5087890625,
      "attention_bam_16_attention_concentration_10": 0.814552867814382,
      "attention_bam_16_attention_concentration_20": 1.2605335153715984,
      "attention_bam_16_attention_center_y": 0.45991956056344885,
      "attention_bam_16_attention_center_x": 0.45300750362262243,
      "attention_bam_16_attention_center_distance": 0.08734685273328271,
      "attention_bam_16_attention_spatial_variance": 43.20045142717511,
      "attention_bam_16_attention_spatial_std": 6.572705031201013,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 8.83408674876462,
      "attention_bam_16_peak_intensity_mean": 0.2930105924606323,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 391,
      "phase": "train",
      "loss": 0.0054550389759242535,
      "timestamp": 1759543945.1331913,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0054550389759242535,
      "ssim": 0.8777284026145935,
      "attention_bam_384_mean_attention": 0.07227246463298798,
      "attention_bam_384_std_attention": 0.35643064975738525,
      "attention_bam_384_max_attention": 2.93994140625,
      "attention_bam_384_min_attention": -1.1852986812591553,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5853535542876083,
      "attention_bam_384_attention_skewness": 0.8210861698659864,
      "attention_bam_384_attention_sparsity": 0.5741856892903646,
      "attention_bam_384_attention_concentration_10": 1.0878562598649169,
      "attention_bam_384_attention_concentration_20": 1.6734453950955768,
      "attention_bam_384_attention_center_y": 0.4842966035662954,
      "attention_bam_384_attention_center_x": 0.4825643546352329,
      "attention_bam_384_attention_center_distance": 0.033184285101234626,
      "attention_bam_384_attention_spatial_variance": 170.45086565615762,
      "attention_bam_384_attention_spatial_std": 13.055683270367645,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 18.529542497358918,
      "attention_bam_384_peak_intensity_mean": 0.309338241815567,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.15883542597293854,
      "attention_bam_16_std_attention": 0.5843397378921509,
      "attention_bam_16_max_attention": 3.2556228637695312,
      "attention_bam_16_min_attention": -0.9821115136146545,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.9252697925288897,
      "attention_bam_16_attention_skewness": 0.8281935542484855,
      "attention_bam_16_attention_sparsity": 0.515380859375,
      "attention_bam_16_attention_concentration_10": 0.8390143222691748,
      "attention_bam_16_attention_concentration_20": 1.3209932391945944,
      "attention_bam_16_attention_center_y": 0.46834618313440324,
      "attention_bam_16_attention_center_x": 0.46527427061766446,
      "attention_bam_16_attention_center_distance": 0.06645058921177358,
      "attention_bam_16_attention_spatial_variance": 42.46794147133888,
      "attention_bam_16_attention_spatial_std": 6.516743164444866,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 8.435216292372296,
      "attention_bam_16_peak_intensity_mean": 0.2759203612804413,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 392,
      "phase": "train",
      "loss": 0.004088889807462692,
      "timestamp": 1759543945.3123584,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004088889807462692,
      "ssim": 0.9265896081924438,
      "attention_bam_384_mean_attention": 0.07241282612085342,
      "attention_bam_384_std_attention": 0.36592909693717957,
      "attention_bam_384_max_attention": 3.0635628700256348,
      "attention_bam_384_min_attention": -1.1309512853622437,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1643530261329644,
      "attention_bam_384_attention_skewness": 0.7157427808050466,
      "attention_bam_384_attention_sparsity": 0.5667190551757812,
      "attention_bam_384_attention_concentration_10": 1.0993288325433095,
      "attention_bam_384_attention_concentration_20": 1.7071089067572178,
      "attention_bam_384_attention_center_y": 0.486266746272505,
      "attention_bam_384_attention_center_x": 0.48244152043891136,
      "attention_bam_384_attention_center_distance": 0.03152467168555203,
      "attention_bam_384_attention_spatial_variance": 171.432997736304,
      "attention_bam_384_attention_spatial_std": 13.09324244548706,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 16.903702061596658,
      "attention_bam_384_peak_intensity_mean": 0.2879815399646759,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1594620943069458,
      "attention_bam_16_std_attention": 0.5931137204170227,
      "attention_bam_16_max_attention": 2.9191555976867676,
      "attention_bam_16_min_attention": -1.146378993988037,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6553684686945509,
      "attention_bam_16_attention_skewness": 0.7589277321024048,
      "attention_bam_16_attention_sparsity": 0.512451171875,
      "attention_bam_16_attention_concentration_10": 0.842761079928637,
      "attention_bam_16_attention_concentration_20": 1.337534341537386,
      "attention_bam_16_attention_center_y": 0.47383581198826613,
      "attention_bam_16_attention_center_x": 0.4651049202619074,
      "attention_bam_16_attention_center_distance": 0.06168032626763898,
      "attention_bam_16_attention_spatial_variance": 43.00302678823726,
      "attention_bam_16_attention_spatial_std": 6.557669310680225,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.825814830211199,
      "attention_bam_16_peak_intensity_mean": 0.32860153913497925,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 393,
      "phase": "train",
      "loss": 0.006012014113366604,
      "timestamp": 1759543945.4826164,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006012014113366604,
      "ssim": 0.8961381912231445,
      "attention_bam_384_mean_attention": 0.0737304836511612,
      "attention_bam_384_std_attention": 0.34317201375961304,
      "attention_bam_384_max_attention": 2.4878733158111572,
      "attention_bam_384_min_attention": -1.1292173862457275,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6552797797730432,
      "attention_bam_384_attention_skewness": 0.6195448869062495,
      "attention_bam_384_attention_sparsity": 0.5640665690104166,
      "attention_bam_384_attention_concentration_10": 1.0103809596755642,
      "attention_bam_384_attention_concentration_20": 1.584435283782894,
      "attention_bam_384_attention_center_y": 0.4789479755504668,
      "attention_bam_384_attention_center_x": 0.47858979330521073,
      "attention_bam_384_attention_center_distance": 0.04246374180727229,
      "attention_bam_384_attention_spatial_variance": 168.88745708174338,
      "attention_bam_384_attention_spatial_std": 12.995670705344276,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 16.47410322025717,
      "attention_bam_384_peak_intensity_mean": 0.3319104313850403,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1634809523820877,
      "attention_bam_16_std_attention": 0.5642662048339844,
      "attention_bam_16_max_attention": 2.2429933547973633,
      "attention_bam_16_min_attention": -1.1145081520080566,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.0797817342784155,
      "attention_bam_16_attention_skewness": 0.6520110750372073,
      "attention_bam_16_attention_sparsity": 0.51318359375,
      "attention_bam_16_attention_concentration_10": 0.7905818428267042,
      "attention_bam_16_attention_concentration_20": 1.2673609867114788,
      "attention_bam_16_attention_center_y": 0.45490984186366074,
      "attention_bam_16_attention_center_x": 0.4554426747592676,
      "attention_bam_16_attention_center_distance": 0.08964906684811048,
      "attention_bam_16_attention_spatial_variance": 41.51874582751325,
      "attention_bam_16_attention_spatial_std": 6.443504157483973,
      "attention_bam_16_num_attention_peaks": 2,
      "attention_bam_16_peak_separation_mean": 9.988969610970337,
      "attention_bam_16_peak_intensity_mean": 0.38014698028564453,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 394,
      "phase": "train",
      "loss": 0.004676739685237408,
      "timestamp": 1759543945.6387656,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004676739685237408,
      "ssim": 0.9123719930648804,
      "attention_bam_384_mean_attention": 0.0686466172337532,
      "attention_bam_384_std_attention": 0.34087592363357544,
      "attention_bam_384_max_attention": 2.6645467281341553,
      "attention_bam_384_min_attention": -1.0570592880249023,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.7019373021595774,
      "attention_bam_384_attention_skewness": 0.9016968947637032,
      "attention_bam_384_attention_sparsity": 0.5827204386393229,
      "attention_bam_384_attention_concentration_10": 1.1060247938006336,
      "attention_bam_384_attention_concentration_20": 1.6906904942618366,
      "attention_bam_384_attention_center_y": 0.4758751750059721,
      "attention_bam_384_attention_center_x": 0.48426185215675954,
      "attention_bam_384_attention_center_distance": 0.04073564725220817,
      "attention_bam_384_attention_spatial_variance": 172.62166931257053,
      "attention_bam_384_attention_spatial_std": 13.138556591672106,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 21.460516393549263,
      "attention_bam_384_peak_intensity_mean": 0.3054474890232086,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1446576863527298,
      "attention_bam_16_std_attention": 0.5622380375862122,
      "attention_bam_16_max_attention": 2.8608198165893555,
      "attention_bam_16_min_attention": -1.1163520812988281,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.0861011336464799,
      "attention_bam_16_attention_skewness": 0.9372004608529922,
      "attention_bam_16_attention_sparsity": 0.5390625,
      "attention_bam_16_attention_concentration_10": 0.8936593648696759,
      "attention_bam_16_attention_concentration_20": 1.407264643413448,
      "attention_bam_16_attention_center_y": 0.4488807651979268,
      "attention_bam_16_attention_center_x": 0.4681054600519227,
      "attention_bam_16_attention_center_distance": 0.08521077215057953,
      "attention_bam_16_attention_spatial_variance": 43.55238740428652,
      "attention_bam_16_attention_spatial_std": 6.599423263004618,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 10.478608419655245,
      "attention_bam_16_peak_intensity_mean": 0.32742395997047424,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 395,
      "phase": "train",
      "loss": 0.006535936146974564,
      "timestamp": 1759543945.7867901,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006535936146974564,
      "ssim": 0.9011385440826416,
      "attention_bam_384_mean_attention": 0.07621961086988449,
      "attention_bam_384_std_attention": 0.3150485157966614,
      "attention_bam_384_max_attention": 2.127408742904663,
      "attention_bam_384_min_attention": -0.9474049806594849,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8172018438497752,
      "attention_bam_384_attention_skewness": 0.5620703867360745,
      "attention_bam_384_attention_sparsity": 0.5583572387695312,
      "attention_bam_384_attention_concentration_10": 0.9064980240509964,
      "attention_bam_384_attention_concentration_20": 1.4143107144625915,
      "attention_bam_384_attention_center_y": 0.4809016584381581,
      "attention_bam_384_attention_center_x": 0.48835488693079776,
      "attention_bam_384_attention_center_distance": 0.03163401045733163,
      "attention_bam_384_attention_spatial_variance": 170.66124606328012,
      "attention_bam_384_attention_spatial_std": 13.063737828940083,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 14.43653851871349,
      "attention_bam_384_peak_intensity_mean": 0.33156365156173706,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17955712974071503,
      "attention_bam_16_std_attention": 0.5241329669952393,
      "attention_bam_16_max_attention": 2.5093231201171875,
      "attention_bam_16_min_attention": -1.0255835056304932,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.36939054893042034,
      "attention_bam_16_attention_skewness": 0.6057320609989736,
      "attention_bam_16_attention_sparsity": 0.47412109375,
      "attention_bam_16_attention_concentration_10": 0.6797641054275357,
      "attention_bam_16_attention_concentration_20": 1.078852934144399,
      "attention_bam_16_attention_center_y": 0.4600805332460536,
      "attention_bam_16_attention_center_x": 0.47889800117120146,
      "attention_bam_16_attention_center_distance": 0.06385699931080457,
      "attention_bam_16_attention_spatial_variance": 42.42697094171251,
      "attention_bam_16_attention_spatial_std": 6.513598923921592,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 7.83814576994045,
      "attention_bam_16_peak_intensity_mean": 0.3369206488132477,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 396,
      "phase": "train",
      "loss": 0.0055431886576116085,
      "timestamp": 1759543945.9310884,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0055431886576116085,
      "ssim": 0.9045227766036987,
      "attention_bam_384_mean_attention": 0.07585857063531876,
      "attention_bam_384_std_attention": 0.3309554159641266,
      "attention_bam_384_max_attention": 2.2906126976013184,
      "attention_bam_384_min_attention": -1.095337152481079,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9256633186711212,
      "attention_bam_384_attention_skewness": 0.6282191381101221,
      "attention_bam_384_attention_sparsity": 0.5646794637044271,
      "attention_bam_384_attention_concentration_10": 0.9435320619982709,
      "attention_bam_384_attention_concentration_20": 1.4935873645619098,
      "attention_bam_384_attention_center_y": 0.4846324852250886,
      "attention_bam_384_attention_center_x": 0.476694967613181,
      "attention_bam_384_attention_center_distance": 0.03947872958715372,
      "attention_bam_384_attention_spatial_variance": 170.6563121921971,
      "attention_bam_384_attention_spatial_std": 13.06354898916053,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 18.66411603342948,
      "attention_bam_384_peak_intensity_mean": 0.35174450278282166,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.17452314496040344,
      "attention_bam_16_std_attention": 0.5480206608772278,
      "attention_bam_16_max_attention": 2.429302215576172,
      "attention_bam_16_min_attention": -1.0948923826217651,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.39826546296924237,
      "attention_bam_16_attention_skewness": 0.6193487385724926,
      "attention_bam_16_attention_sparsity": 0.48681640625,
      "attention_bam_16_attention_concentration_10": 0.7149113092825653,
      "attention_bam_16_attention_concentration_20": 1.1488470421328267,
      "attention_bam_16_attention_center_y": 0.46968934486240393,
      "attention_bam_16_attention_center_x": 0.446005087572912,
      "attention_bam_16_attention_center_distance": 0.08756924554750005,
      "attention_bam_16_attention_spatial_variance": 42.63045124766192,
      "attention_bam_16_attention_spatial_std": 6.529199893376057,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.118748175804154,
      "attention_bam_16_peak_intensity_mean": 0.3758782148361206,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 397,
      "phase": "train",
      "loss": 0.005491956137120724,
      "timestamp": 1759543946.0753448,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005491956137120724,
      "ssim": 0.9142385721206665,
      "attention_bam_384_mean_attention": 0.07182154804468155,
      "attention_bam_384_std_attention": 0.356730192899704,
      "attention_bam_384_max_attention": 2.3168020248413086,
      "attention_bam_384_min_attention": -1.024713397026062,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.3473613572798637,
      "attention_bam_384_attention_skewness": 0.5634337837861,
      "attention_bam_384_attention_sparsity": 0.5614802042643229,
      "attention_bam_384_attention_concentration_10": 1.0583361019687823,
      "attention_bam_384_attention_concentration_20": 1.679614522902824,
      "attention_bam_384_attention_center_y": 0.4909218756408265,
      "attention_bam_384_attention_center_x": 0.481317462079102,
      "attention_bam_384_attention_center_distance": 0.029375144767180693,
      "attention_bam_384_attention_spatial_variance": 169.7088389165301,
      "attention_bam_384_attention_spatial_std": 13.027234507620184,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 19.798360151295647,
      "attention_bam_384_peak_intensity_mean": 0.330497682094574,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.15379725396633148,
      "attention_bam_16_std_attention": 0.5793054699897766,
      "attention_bam_16_max_attention": 2.3132591247558594,
      "attention_bam_16_min_attention": -1.0193759202957153,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.10220297007341772,
      "attention_bam_16_attention_skewness": 0.5844973797176916,
      "attention_bam_16_attention_sparsity": 0.516357421875,
      "attention_bam_16_attention_concentration_10": 0.8334445772866641,
      "attention_bam_16_attention_concentration_20": 1.356448631377325,
      "attention_bam_16_attention_center_y": 0.48812084803834643,
      "attention_bam_16_attention_center_x": 0.46160048237746915,
      "attention_bam_16_attention_center_distance": 0.05684429971371123,
      "attention_bam_16_attention_spatial_variance": 41.787311739626894,
      "attention_bam_16_attention_spatial_std": 6.464310615961063,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 11.079040654949258,
      "attention_bam_16_peak_intensity_mean": 0.3632911145687103,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 398,
      "phase": "train",
      "loss": 0.005101893097162247,
      "timestamp": 1759543946.2203155,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005101893097162247,
      "ssim": 0.9107556343078613,
      "attention_bam_384_mean_attention": 0.07195476442575455,
      "attention_bam_384_std_attention": 0.3352133631706238,
      "attention_bam_384_max_attention": 2.3449912071228027,
      "attention_bam_384_min_attention": -1.0264170169830322,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.25217388802862883,
      "attention_bam_384_attention_skewness": 0.4974026289674871,
      "attention_bam_384_attention_sparsity": 0.5678532918294271,
      "attention_bam_384_attention_concentration_10": 0.9967848480299426,
      "attention_bam_384_attention_concentration_20": 1.5921129373206102,
      "attention_bam_384_attention_center_y": 0.48805513293714636,
      "attention_bam_384_attention_center_x": 0.4932460036463977,
      "attention_bam_384_attention_center_distance": 0.019405994738416206,
      "attention_bam_384_attention_spatial_variance": 170.95743971110835,
      "attention_bam_384_attention_spatial_std": 13.07506939603413,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 17.08561258353049,
      "attention_bam_384_peak_intensity_mean": 0.3288954794406891,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1571393758058548,
      "attention_bam_16_std_attention": 0.544708788394928,
      "attention_bam_16_max_attention": 2.426205635070801,
      "attention_bam_16_min_attention": -0.9657952189445496,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.008210659085490679,
      "attention_bam_16_attention_skewness": 0.5848959079287622,
      "attention_bam_16_attention_sparsity": 0.506591796875,
      "attention_bam_16_attention_concentration_10": 0.7813332201601721,
      "attention_bam_16_attention_concentration_20": 1.2617792800392273,
      "attention_bam_16_attention_center_y": 0.4787663006695983,
      "attention_bam_16_attention_center_x": 0.49204396849988047,
      "attention_bam_16_attention_center_distance": 0.03206769166886809,
      "attention_bam_16_attention_spatial_variance": 42.86419331194549,
      "attention_bam_16_attention_spatial_std": 6.547075172315153,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.7789893167388,
      "attention_bam_16_peak_intensity_mean": 0.3351368010044098,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 399,
      "phase": "train",
      "loss": 0.007560409605503082,
      "timestamp": 1759543946.3592937,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007560409605503082,
      "ssim": 0.8719730973243713,
      "attention_bam_384_mean_attention": 0.06803945451974869,
      "attention_bam_384_std_attention": 0.3610355854034424,
      "attention_bam_384_max_attention": 2.797825813293457,
      "attention_bam_384_min_attention": -1.073253870010376,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2379959218910237,
      "attention_bam_384_attention_skewness": 0.7688834718129419,
      "attention_bam_384_attention_sparsity": 0.5756098429361979,
      "attention_bam_384_attention_concentration_10": 1.1502975729860576,
      "attention_bam_384_attention_concentration_20": 1.784160520338135,
      "attention_bam_384_attention_center_y": 0.48097994085510304,
      "attention_bam_384_attention_center_x": 0.482835122062456,
      "attention_bam_384_attention_center_distance": 0.036232462916179556,
      "attention_bam_384_attention_spatial_variance": 171.31111158180406,
      "attention_bam_384_attention_spatial_std": 13.088587073546329,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 18.14438215775142,
      "attention_bam_384_peak_intensity_mean": 0.298132985830307,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13852067291736603,
      "attention_bam_16_std_attention": 0.5813579559326172,
      "attention_bam_16_max_attention": 2.6654233932495117,
      "attention_bam_16_min_attention": -1.0331162214279175,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.49589444759645174,
      "attention_bam_16_attention_skewness": 0.7396756483596327,
      "attention_bam_16_attention_sparsity": 0.525634765625,
      "attention_bam_16_attention_concentration_10": 0.935164235218913,
      "attention_bam_16_attention_concentration_20": 1.487404696527612,
      "attention_bam_16_attention_center_y": 0.46191669160394155,
      "attention_bam_16_attention_center_x": 0.46210067622730644,
      "attention_bam_16_attention_center_distance": 0.07598285491894537,
      "attention_bam_16_attention_spatial_variance": 43.236112657275456,
      "attention_bam_16_attention_spatial_std": 6.5754172990978645,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 8.938762830542538,
      "attention_bam_16_peak_intensity_mean": 0.3196173310279846,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 400,
      "phase": "train",
      "loss": 0.005502568557858467,
      "timestamp": 1759543946.5528505,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005502568557858467,
      "ssim": 0.9102948904037476,
      "attention_bam_384_mean_attention": 0.06985162943601608,
      "attention_bam_384_std_attention": 0.37580910325050354,
      "attention_bam_384_max_attention": 2.3953285217285156,
      "attention_bam_384_min_attention": -1.004521369934082,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.660948897996545,
      "attention_bam_384_attention_skewness": 0.670288434887504,
      "attention_bam_384_attention_sparsity": 0.5653839111328125,
      "attention_bam_384_attention_concentration_10": 1.149982756155989,
      "attention_bam_384_attention_concentration_20": 1.8041105056599458,
      "attention_bam_384_attention_center_y": 0.47756396479724056,
      "attention_bam_384_attention_center_x": 0.4941513136209783,
      "attention_bam_384_attention_center_distance": 0.032789718143943075,
      "attention_bam_384_attention_spatial_variance": 168.57488130694637,
      "attention_bam_384_attention_spatial_std": 12.98363898554432,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 15.176310612513978,
      "attention_bam_384_peak_intensity_mean": 0.31812721490859985,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.15966522693634033,
      "attention_bam_16_std_attention": 0.6050500869750977,
      "attention_bam_16_max_attention": 2.643094778060913,
      "attention_bam_16_min_attention": -1.013293981552124,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.1588317806386339,
      "attention_bam_16_attention_skewness": 0.7194822380319246,
      "attention_bam_16_attention_sparsity": 0.51904296875,
      "attention_bam_16_attention_concentration_10": 0.8621590651884156,
      "attention_bam_16_attention_concentration_20": 1.3831029760817772,
      "attention_bam_16_attention_center_y": 0.4474363690646756,
      "attention_bam_16_attention_center_x": 0.4936207902624609,
      "attention_bam_16_attention_center_distance": 0.07488163478424474,
      "attention_bam_16_attention_spatial_variance": 41.231953973879094,
      "attention_bam_16_attention_spatial_std": 6.421211254419146,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 7.1781245134470835,
      "attention_bam_16_peak_intensity_mean": 0.3366173207759857,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 401,
      "phase": "train",
      "loss": 0.004474208224564791,
      "timestamp": 1759543948.886204,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004474208224564791,
      "ssim": 0.9186637997627258,
      "attention_bam_384_mean_attention": 0.06845364719629288,
      "attention_bam_384_std_attention": 0.36254191398620605,
      "attention_bam_384_max_attention": 2.6934502124786377,
      "attention_bam_384_min_attention": -1.0003225803375244,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8225646121815688,
      "attention_bam_384_attention_skewness": 0.6805253634916378,
      "attention_bam_384_attention_sparsity": 0.5731608072916666,
      "attention_bam_384_attention_concentration_10": 1.142943676831047,
      "attention_bam_384_attention_concentration_20": 1.7848900775958898,
      "attention_bam_384_attention_center_y": 0.4911044381257713,
      "attention_bam_384_attention_center_x": 0.48301459434853433,
      "attention_bam_384_attention_center_distance": 0.02711586348258424,
      "attention_bam_384_attention_spatial_variance": 170.4920307285233,
      "attention_bam_384_attention_spatial_std": 13.057259694458224,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 15.510860967418507,
      "attention_bam_384_peak_intensity_mean": 0.28714942932128906,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14984743297100067,
      "attention_bam_16_std_attention": 0.5798845291137695,
      "attention_bam_16_max_attention": 2.973865032196045,
      "attention_bam_16_min_attention": -1.1664360761642456,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5993828993665526,
      "attention_bam_16_attention_skewness": 0.7659561616573304,
      "attention_bam_16_attention_sparsity": 0.521728515625,
      "attention_bam_16_attention_concentration_10": 0.8803730992346588,
      "attention_bam_16_attention_concentration_20": 1.3875284143483455,
      "attention_bam_16_attention_center_y": 0.48310761176544087,
      "attention_bam_16_attention_center_x": 0.4693735795946489,
      "attention_bam_16_attention_center_distance": 0.04946373231191468,
      "attention_bam_16_attention_spatial_variance": 42.783731740602626,
      "attention_bam_16_attention_spatial_std": 6.540927437344235,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 7.641442604908685,
      "attention_bam_16_peak_intensity_mean": 0.30670058727264404,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 402,
      "phase": "train",
      "loss": 0.005535677075386047,
      "timestamp": 1759543949.0183017,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005535677075386047,
      "ssim": 0.9052488803863525,
      "attention_bam_384_mean_attention": 0.07013335078954697,
      "attention_bam_384_std_attention": 0.3505134582519531,
      "attention_bam_384_max_attention": 2.6115264892578125,
      "attention_bam_384_min_attention": -1.1211780309677124,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8460095494767783,
      "attention_bam_384_attention_skewness": 0.6683771374908503,
      "attention_bam_384_attention_sparsity": 0.56781005859375,
      "attention_bam_384_attention_concentration_10": 1.0797886188577321,
      "attention_bam_384_attention_concentration_20": 1.6885064478664398,
      "attention_bam_384_attention_center_y": 0.49234043895238994,
      "attention_bam_384_attention_center_x": 0.48476293940044807,
      "attention_bam_384_attention_center_distance": 0.024117914136860312,
      "attention_bam_384_attention_spatial_variance": 172.11747734048527,
      "attention_bam_384_attention_spatial_std": 13.11935506572199,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 17.44171389414067,
      "attention_bam_384_peak_intensity_mean": 0.32328546047210693,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16214074194431305,
      "attention_bam_16_std_attention": 0.5687049627304077,
      "attention_bam_16_max_attention": 2.5846457481384277,
      "attention_bam_16_min_attention": -1.0012061595916748,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.4353410253580674,
      "attention_bam_16_attention_skewness": 0.6971619521305021,
      "attention_bam_16_attention_sparsity": 0.506591796875,
      "attention_bam_16_attention_concentration_10": 0.7985199264548413,
      "attention_bam_16_attention_concentration_20": 1.2710151684186302,
      "attention_bam_16_attention_center_y": 0.4927363844512797,
      "attention_bam_16_attention_center_x": 0.47105933702372516,
      "attention_bam_16_attention_center_distance": 0.04219767966004616,
      "attention_bam_16_attention_spatial_variance": 43.9696034063324,
      "attention_bam_16_attention_spatial_std": 6.630957955403759,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.79086925040085,
      "attention_bam_16_peak_intensity_mean": 0.32924357056617737,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 403,
      "phase": "train",
      "loss": 0.00744163803756237,
      "timestamp": 1759543949.1540437,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00744163803756237,
      "ssim": 0.8996884822845459,
      "attention_bam_384_mean_attention": 0.07011664658784866,
      "attention_bam_384_std_attention": 0.32636260986328125,
      "attention_bam_384_max_attention": 2.4773354530334473,
      "attention_bam_384_min_attention": -1.0269067287445068,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0721537049606704,
      "attention_bam_384_attention_skewness": 0.7207393033206075,
      "attention_bam_384_attention_sparsity": 0.5781580607096354,
      "attention_bam_384_attention_concentration_10": 1.0250409011677422,
      "attention_bam_384_attention_concentration_20": 1.5974992110204036,
      "attention_bam_384_attention_center_y": 0.48364261532282243,
      "attention_bam_384_attention_center_x": 0.48899510332099044,
      "attention_bam_384_attention_center_distance": 0.02788088177919913,
      "attention_bam_384_attention_spatial_variance": 169.44950087959492,
      "attention_bam_384_attention_spatial_std": 13.01727701478289,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 16.37034122015322,
      "attention_bam_384_peak_intensity_mean": 0.3164554536342621,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16274884343147278,
      "attention_bam_16_std_attention": 0.5354726910591125,
      "attention_bam_16_max_attention": 2.5202465057373047,
      "attention_bam_16_min_attention": -0.9038474559783936,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.2513557047175401,
      "attention_bam_16_attention_skewness": 0.6811325012629742,
      "attention_bam_16_attention_sparsity": 0.509033203125,
      "attention_bam_16_attention_concentration_10": 0.75510424476682,
      "attention_bam_16_attention_concentration_20": 1.2145178169530195,
      "attention_bam_16_attention_center_y": 0.4663316460453933,
      "attention_bam_16_attention_center_x": 0.4824827371180392,
      "attention_bam_16_attention_center_distance": 0.05367331845318312,
      "attention_bam_16_attention_spatial_variance": 41.607380448033034,
      "attention_bam_16_attention_spatial_std": 6.450378318209951,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 10.016756471849735,
      "attention_bam_16_peak_intensity_mean": 0.316170871257782,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 404,
      "phase": "train",
      "loss": 0.006334761157631874,
      "timestamp": 1759543949.2886548,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006334761157631874,
      "ssim": 0.8950170278549194,
      "attention_bam_384_mean_attention": 0.06789322942495346,
      "attention_bam_384_std_attention": 0.3529687821865082,
      "attention_bam_384_max_attention": 3.9672229290008545,
      "attention_bam_384_min_attention": -1.2320359945297241,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.002658797544755,
      "attention_bam_384_attention_skewness": 0.9176047821117148,
      "attention_bam_384_attention_sparsity": 0.5713475545247396,
      "attention_bam_384_attention_concentration_10": 1.11508721523976,
      "attention_bam_384_attention_concentration_20": 1.7226847708833999,
      "attention_bam_384_attention_center_y": 0.4812904146975342,
      "attention_bam_384_attention_center_x": 0.48057432860949323,
      "attention_bam_384_attention_center_distance": 0.038141979265953085,
      "attention_bam_384_attention_spatial_variance": 170.29489115756184,
      "attention_bam_384_attention_spatial_std": 13.049708470213496,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 15.224258477041912,
      "attention_bam_384_peak_intensity_mean": 0.2516672909259796,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14567288756370544,
      "attention_bam_16_std_attention": 0.5689806938171387,
      "attention_bam_16_max_attention": 3.8775110244750977,
      "attention_bam_16_min_attention": -1.1092082262039185,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.177831717942075,
      "attention_bam_16_attention_skewness": 1.0107235506827696,
      "attention_bam_16_attention_sparsity": 0.53271484375,
      "attention_bam_16_attention_concentration_10": 0.8900503910369123,
      "attention_bam_16_attention_concentration_20": 1.4045070029844577,
      "attention_bam_16_attention_center_y": 0.46116393306955533,
      "attention_bam_16_attention_center_x": 0.4589866706126514,
      "attention_bam_16_attention_center_distance": 0.07987907463236074,
      "attention_bam_16_attention_spatial_variance": 42.42332829260061,
      "attention_bam_16_attention_spatial_std": 6.513319299143917,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.75850682824378,
      "attention_bam_16_peak_intensity_mean": 0.25449615716934204,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 405,
      "phase": "train",
      "loss": 0.006390692200511694,
      "timestamp": 1759543949.4242592,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006390692200511694,
      "ssim": 0.8899683952331543,
      "attention_bam_384_mean_attention": 0.07166945189237595,
      "attention_bam_384_std_attention": 0.340585321187973,
      "attention_bam_384_max_attention": 3.9281599521636963,
      "attention_bam_384_min_attention": -1.1527793407440186,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.137680700306163,
      "attention_bam_384_attention_skewness": 0.953876735144607,
      "attention_bam_384_attention_sparsity": 0.5745264689127604,
      "attention_bam_384_attention_concentration_10": 1.0452104468188952,
      "attention_bam_384_attention_concentration_20": 1.6025936993677714,
      "attention_bam_384_attention_center_y": 0.4898959640304178,
      "attention_bam_384_attention_center_x": 0.47903570029735537,
      "attention_bam_384_attention_center_distance": 0.03291180350260121,
      "attention_bam_384_attention_spatial_variance": 172.66475288825066,
      "attention_bam_384_attention_spatial_std": 13.140196074954538,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 19.618119969095417,
      "attention_bam_384_peak_intensity_mean": 0.2453678846359253,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1752401888370514,
      "attention_bam_16_std_attention": 0.5761812925338745,
      "attention_bam_16_max_attention": 3.6592459678649902,
      "attention_bam_16_min_attention": -0.9836110472679138,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.850936785319215,
      "attention_bam_16_attention_skewness": 1.1598204103667633,
      "attention_bam_16_attention_sparsity": 0.5009765625,
      "attention_bam_16_attention_concentration_10": 0.7720845021690589,
      "attention_bam_16_attention_concentration_20": 1.1909370357575508,
      "attention_bam_16_attention_center_y": 0.48687754437748837,
      "attention_bam_16_attention_center_x": 0.4509504863327696,
      "attention_bam_16_attention_center_distance": 0.07180603919666662,
      "attention_bam_16_attention_spatial_variance": 44.06909923835105,
      "attention_bam_16_attention_spatial_std": 6.638456088455436,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 10.149765557566083,
      "attention_bam_16_peak_intensity_mean": 0.2686818838119507,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 406,
      "phase": "train",
      "loss": 0.0056929560378193855,
      "timestamp": 1759543949.5718868,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0056929560378193855,
      "ssim": 0.8968849182128906,
      "attention_bam_384_mean_attention": 0.0683150365948677,
      "attention_bam_384_std_attention": 0.3311357796192169,
      "attention_bam_384_max_attention": 3.1375389099121094,
      "attention_bam_384_min_attention": -0.9240974187850952,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.3866824783048957,
      "attention_bam_384_attention_skewness": 0.6788001843570598,
      "attention_bam_384_attention_sparsity": 0.5730692545572916,
      "attention_bam_384_attention_concentration_10": 1.0530853154878637,
      "attention_bam_384_attention_concentration_20": 1.6276165266570033,
      "attention_bam_384_attention_center_y": 0.48071140092902753,
      "attention_bam_384_attention_center_x": 0.4844044002774653,
      "attention_bam_384_attention_center_distance": 0.035079132966088104,
      "attention_bam_384_attention_spatial_variance": 172.0671958672734,
      "attention_bam_384_attention_spatial_std": 13.117438616866991,
      "attention_bam_384_num_attention_peaks": 22,
      "attention_bam_384_peak_separation_mean": 18.306511337578566,
      "attention_bam_384_peak_intensity_mean": 0.24653972685337067,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.15285293757915497,
      "attention_bam_16_std_attention": 0.5526139140129089,
      "attention_bam_16_max_attention": 2.941638946533203,
      "attention_bam_16_min_attention": -1.017439603805542,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6548221530885039,
      "attention_bam_16_attention_skewness": 0.710754144507055,
      "attention_bam_16_attention_sparsity": 0.50634765625,
      "attention_bam_16_attention_concentration_10": 0.8164021635335419,
      "attention_bam_16_attention_concentration_20": 1.2978976849282746,
      "attention_bam_16_attention_center_y": 0.4607764555628242,
      "attention_bam_16_attention_center_x": 0.4704055081630679,
      "attention_bam_16_attention_center_distance": 0.06948842184567647,
      "attention_bam_16_attention_spatial_variance": 43.712811150101075,
      "attention_bam_16_attention_spatial_std": 6.611566467192255,
      "attention_bam_16_num_attention_peaks": 12,
      "attention_bam_16_peak_separation_mean": 9.081746909825835,
      "attention_bam_16_peak_intensity_mean": 0.29779288172721863,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 407,
      "phase": "train",
      "loss": 0.006673222407698631,
      "timestamp": 1759543949.7313242,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006673222407698631,
      "ssim": 0.9094975590705872,
      "attention_bam_384_mean_attention": 0.06782136112451553,
      "attention_bam_384_std_attention": 0.3862166702747345,
      "attention_bam_384_max_attention": 2.777526378631592,
      "attention_bam_384_min_attention": -1.0637212991714478,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1632025225051548,
      "attention_bam_384_attention_skewness": 0.7381482925177166,
      "attention_bam_384_attention_sparsity": 0.5737711588541666,
      "attention_bam_384_attention_concentration_10": 1.2506572499107858,
      "attention_bam_384_attention_concentration_20": 1.9047685030938915,
      "attention_bam_384_attention_center_y": 0.47927953544079877,
      "attention_bam_384_attention_center_x": 0.4881008578750569,
      "attention_bam_384_attention_center_distance": 0.03379133719930921,
      "attention_bam_384_attention_spatial_variance": 169.77499423836346,
      "attention_bam_384_attention_spatial_std": 13.029773376324066,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 15.489262314494578,
      "attention_bam_384_peak_intensity_mean": 0.2997617721557617,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.15129223465919495,
      "attention_bam_16_std_attention": 0.6303210258483887,
      "attention_bam_16_max_attention": 2.9682729244232178,
      "attention_bam_16_min_attention": -1.0593833923339844,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7533914264760502,
      "attention_bam_16_attention_skewness": 0.8482682469525312,
      "attention_bam_16_attention_sparsity": 0.52685546875,
      "attention_bam_16_attention_concentration_10": 0.9620811480138848,
      "attention_bam_16_attention_concentration_20": 1.4926152239726436,
      "attention_bam_16_attention_center_y": 0.45335069002525175,
      "attention_bam_16_attention_center_x": 0.4830049322101739,
      "attention_bam_16_attention_center_distance": 0.0702138227174811,
      "attention_bam_16_attention_spatial_variance": 41.94907283659789,
      "attention_bam_16_attention_spatial_std": 6.476810390662822,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 7.698521218287444,
      "attention_bam_16_peak_intensity_mean": 0.3130127787590027,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 408,
      "phase": "train",
      "loss": 0.007452243473380804,
      "timestamp": 1759543949.880189,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007452243473380804,
      "ssim": 0.8937329649925232,
      "attention_bam_384_mean_attention": 0.06375402957201004,
      "attention_bam_384_std_attention": 0.339703768491745,
      "attention_bam_384_max_attention": 2.3896679878234863,
      "attention_bam_384_min_attention": -1.031203031539917,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2782267482895362,
      "attention_bam_384_attention_skewness": 0.86354750154319,
      "attention_bam_384_attention_sparsity": 0.5907389322916666,
      "attention_bam_384_attention_concentration_10": 1.1857178851392136,
      "attention_bam_384_attention_concentration_20": 1.8169818397294835,
      "attention_bam_384_attention_center_y": 0.4881919300610129,
      "attention_bam_384_attention_center_x": 0.4815887174421291,
      "attention_bam_384_attention_center_distance": 0.030932372722110125,
      "attention_bam_384_attention_spatial_variance": 171.17934970327676,
      "attention_bam_384_attention_spatial_std": 13.083552640750018,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 18.342188191333324,
      "attention_bam_384_peak_intensity_mean": 0.32153770327568054,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14296624064445496,
      "attention_bam_16_std_attention": 0.5720537900924683,
      "attention_bam_16_max_attention": 2.5921669006347656,
      "attention_bam_16_min_attention": -1.0049769878387451,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7546454054914657,
      "attention_bam_16_attention_skewness": 0.9261469073356096,
      "attention_bam_16_attention_sparsity": 0.54638671875,
      "attention_bam_16_attention_concentration_10": 0.9334497704832581,
      "attention_bam_16_attention_concentration_20": 1.46310237052787,
      "attention_bam_16_attention_center_y": 0.4797024633732756,
      "attention_bam_16_attention_center_x": 0.46356219974744883,
      "attention_bam_16_attention_center_distance": 0.0589864947315576,
      "attention_bam_16_attention_spatial_variance": 43.234294431333204,
      "attention_bam_16_attention_spatial_std": 6.575279038286756,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.812974988956084,
      "attention_bam_16_peak_intensity_mean": 0.32711178064346313,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 409,
      "phase": "train",
      "loss": 0.006674950011074543,
      "timestamp": 1759543950.0373468,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006674950011074543,
      "ssim": 0.9109565019607544,
      "attention_bam_384_mean_attention": 0.06675258278846741,
      "attention_bam_384_std_attention": 0.37221935391426086,
      "attention_bam_384_max_attention": 3.0854721069335938,
      "attention_bam_384_min_attention": -1.1937147378921509,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1213555742619459,
      "attention_bam_384_attention_skewness": 0.664001173891806,
      "attention_bam_384_attention_sparsity": 0.5706278483072916,
      "attention_bam_384_attention_concentration_10": 1.2039809302276,
      "attention_bam_384_attention_concentration_20": 1.8519302302905274,
      "attention_bam_384_attention_center_y": 0.4898042481905475,
      "attention_bam_384_attention_center_x": 0.48274064882112944,
      "attention_bam_384_attention_center_distance": 0.02834919956808425,
      "attention_bam_384_attention_spatial_variance": 170.71915080819522,
      "attention_bam_384_attention_spatial_std": 13.065953880532229,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 18.247132802524874,
      "attention_bam_384_peak_intensity_mean": 0.2973466217517853,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1506887674331665,
      "attention_bam_16_std_attention": 0.6131342053413391,
      "attention_bam_16_max_attention": 3.4513022899627686,
      "attention_bam_16_min_attention": -1.273019790649414,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8366570420246218,
      "attention_bam_16_attention_skewness": 0.813583537738843,
      "attention_bam_16_attention_sparsity": 0.522705078125,
      "attention_bam_16_attention_concentration_10": 0.929560609413697,
      "attention_bam_16_attention_concentration_20": 1.4515392355720078,
      "attention_bam_16_attention_center_y": 0.486184078015863,
      "attention_bam_16_attention_center_x": 0.4652755318271603,
      "attention_bam_16_attention_center_distance": 0.05285202721104115,
      "attention_bam_16_attention_spatial_variance": 42.74590496676623,
      "attention_bam_16_attention_spatial_std": 6.538035252793168,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.22345648350785,
      "attention_bam_16_peak_intensity_mean": 0.31709083914756775,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 410,
      "phase": "train",
      "loss": 0.0070679448544979095,
      "timestamp": 1759543950.250151,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0070679448544979095,
      "ssim": 0.9050585031509399,
      "attention_bam_384_mean_attention": 0.06739525496959686,
      "attention_bam_384_std_attention": 0.3282133936882019,
      "attention_bam_384_max_attention": 2.6291284561157227,
      "attention_bam_384_min_attention": -0.9515621662139893,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.05667202823762052,
      "attention_bam_384_attention_skewness": 0.4127232731412864,
      "attention_bam_384_attention_sparsity": 0.5665359497070312,
      "attention_bam_384_attention_concentration_10": 1.0179671866885664,
      "attention_bam_384_attention_concentration_20": 1.6466478096950574,
      "attention_bam_384_attention_center_y": 0.4805068967356405,
      "attention_bam_384_attention_center_x": 0.48727318692763194,
      "attention_bam_384_attention_center_distance": 0.03292272302996765,
      "attention_bam_384_attention_spatial_variance": 168.64040776438807,
      "attention_bam_384_attention_spatial_std": 12.986162164565329,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 14.05545537183903,
      "attention_bam_384_peak_intensity_mean": 0.2857087254524231,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1664978712797165,
      "attention_bam_16_std_attention": 0.5340064764022827,
      "attention_bam_16_max_attention": 2.4974799156188965,
      "attention_bam_16_min_attention": -1.0500290393829346,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.009421858444646602,
      "attention_bam_16_attention_skewness": 0.5513096440697612,
      "attention_bam_16_attention_sparsity": 0.49951171875,
      "attention_bam_16_attention_concentration_10": 0.7206754599154019,
      "attention_bam_16_attention_concentration_20": 1.1751444021356157,
      "attention_bam_16_attention_center_y": 0.4594160019757175,
      "attention_bam_16_attention_center_x": 0.47924098519653163,
      "attention_bam_16_attention_center_distance": 0.06446700848101426,
      "attention_bam_16_attention_spatial_variance": 41.26244400444491,
      "attention_bam_16_attention_spatial_std": 6.4235849807132555,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 6.832731782017933,
      "attention_bam_16_peak_intensity_mean": 0.34839990735054016,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 411,
      "phase": "train",
      "loss": 0.005818738602101803,
      "timestamp": 1759543950.410526,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005818738602101803,
      "ssim": 0.9032853245735168,
      "attention_bam_384_mean_attention": 0.06566253304481506,
      "attention_bam_384_std_attention": 0.3474383056163788,
      "attention_bam_384_max_attention": 2.426764488220215,
      "attention_bam_384_min_attention": -1.057274580001831,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.45906648538073647,
      "attention_bam_384_attention_skewness": 0.5639574149802631,
      "attention_bam_384_attention_sparsity": 0.5683797200520834,
      "attention_bam_384_attention_concentration_10": 1.1244683846286467,
      "attention_bam_384_attention_concentration_20": 1.7734579844760157,
      "attention_bam_384_attention_center_y": 0.4821187247755004,
      "attention_bam_384_attention_center_x": 0.49059648850505816,
      "attention_bam_384_attention_center_distance": 0.028571525408693427,
      "attention_bam_384_attention_spatial_variance": 169.60969707624508,
      "attention_bam_384_attention_spatial_std": 13.023428775719745,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 17.06047887811952,
      "attention_bam_384_peak_intensity_mean": 0.3239966630935669,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1547260731458664,
      "attention_bam_16_std_attention": 0.5767087936401367,
      "attention_bam_16_max_attention": 2.4147377014160156,
      "attention_bam_16_min_attention": -1.010634183883667,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.1876919499133871,
      "attention_bam_16_attention_skewness": 0.6635417181962369,
      "attention_bam_16_attention_sparsity": 0.51416015625,
      "attention_bam_16_attention_concentration_10": 0.84342289118966,
      "attention_bam_16_attention_concentration_20": 1.3478949420555342,
      "attention_bam_16_attention_center_y": 0.464111760419184,
      "attention_bam_16_attention_center_x": 0.48957652599297824,
      "attention_bam_16_attention_center_distance": 0.052851008516112644,
      "attention_bam_16_attention_spatial_variance": 41.88503520065647,
      "attention_bam_16_attention_spatial_std": 6.471864893572522,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.468818193748431,
      "attention_bam_16_peak_intensity_mean": 0.3416298031806946,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 412,
      "phase": "train",
      "loss": 0.005075665656477213,
      "timestamp": 1759543950.5659218,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005075665656477213,
      "ssim": 0.9211661219596863,
      "attention_bam_384_mean_attention": 0.06402456015348434,
      "attention_bam_384_std_attention": 0.37684983015060425,
      "attention_bam_384_max_attention": 2.8505706787109375,
      "attention_bam_384_min_attention": -1.0363150835037231,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6627485202790555,
      "attention_bam_384_attention_skewness": 0.6891088060895891,
      "attention_bam_384_attention_sparsity": 0.5790506998697916,
      "attention_bam_384_attention_concentration_10": 1.2755748206761717,
      "attention_bam_384_attention_concentration_20": 1.9751273987284166,
      "attention_bam_384_attention_center_y": 0.4762586022001089,
      "attention_bam_384_attention_center_x": 0.4824612890312992,
      "attention_bam_384_attention_center_distance": 0.0417435109193345,
      "attention_bam_384_attention_spatial_variance": 169.8203314341605,
      "attention_bam_384_attention_spatial_std": 13.031513014004187,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 19.234539979442417,
      "attention_bam_384_peak_intensity_mean": 0.2863398492336273,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.15696752071380615,
      "attention_bam_16_std_attention": 0.5933883190155029,
      "attention_bam_16_max_attention": 2.7350356578826904,
      "attention_bam_16_min_attention": -1.071115493774414,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.41954486402687197,
      "attention_bam_16_attention_skewness": 0.7973951248989282,
      "attention_bam_16_attention_sparsity": 0.535888671875,
      "attention_bam_16_attention_concentration_10": 0.8694164143252341,
      "attention_bam_16_attention_concentration_20": 1.3790980976273628,
      "attention_bam_16_attention_center_y": 0.4483021227434758,
      "attention_bam_16_attention_center_x": 0.46180803936793263,
      "attention_bam_16_attention_center_distance": 0.09089880493991133,
      "attention_bam_16_attention_spatial_variance": 42.01795508328114,
      "attention_bam_16_attention_spatial_std": 6.482125815138205,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.53812266252708,
      "attention_bam_16_peak_intensity_mean": 0.3327525556087494,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 413,
      "phase": "train",
      "loss": 0.01031043566763401,
      "timestamp": 1759543950.7146645,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.01031043566763401,
      "ssim": 0.8852241039276123,
      "attention_bam_384_mean_attention": 0.06347092241048813,
      "attention_bam_384_std_attention": 0.35926079750061035,
      "attention_bam_384_max_attention": 3.019421100616455,
      "attention_bam_384_min_attention": -1.0536415576934814,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5194475331122268,
      "attention_bam_384_attention_skewness": 0.8174321577299987,
      "attention_bam_384_attention_sparsity": 0.5865605672200521,
      "attention_bam_384_attention_concentration_10": 1.2486041858962307,
      "attention_bam_384_attention_concentration_20": 1.8939991243017253,
      "attention_bam_384_attention_center_y": 0.4840129095920235,
      "attention_bam_384_attention_center_x": 0.47999248006797085,
      "attention_bam_384_attention_center_distance": 0.036218445950740585,
      "attention_bam_384_attention_spatial_variance": 170.32021434425226,
      "attention_bam_384_attention_spatial_std": 13.05067869285932,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 17.069323569332536,
      "attention_bam_384_peak_intensity_mean": 0.27613046765327454,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.15519562363624573,
      "attention_bam_16_std_attention": 0.5717530250549316,
      "attention_bam_16_max_attention": 2.9693515300750732,
      "attention_bam_16_min_attention": -1.0409035682678223,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.671799722500078,
      "attention_bam_16_attention_skewness": 0.8078004255852224,
      "attention_bam_16_attention_sparsity": 0.52783203125,
      "attention_bam_16_attention_concentration_10": 0.847485963023449,
      "attention_bam_16_attention_concentration_20": 1.3388855806058066,
      "attention_bam_16_attention_center_y": 0.4671146019235069,
      "attention_bam_16_attention_center_x": 0.45786051789369153,
      "attention_bam_16_attention_center_distance": 0.0755934568443236,
      "attention_bam_16_attention_spatial_variance": 42.22257068189481,
      "attention_bam_16_attention_spatial_std": 6.4978897098900354,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 8.919866307445107,
      "attention_bam_16_peak_intensity_mean": 0.30137529969215393,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 414,
      "phase": "train",
      "loss": 0.007508835755288601,
      "timestamp": 1759543950.8564796,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007508835755288601,
      "ssim": 0.9041894674301147,
      "attention_bam_384_mean_attention": 0.06283750385046005,
      "attention_bam_384_std_attention": 0.37763944268226624,
      "attention_bam_384_max_attention": 2.679713726043701,
      "attention_bam_384_min_attention": -1.1055080890655518,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7697292218603042,
      "attention_bam_384_attention_skewness": 0.7060502960356214,
      "attention_bam_384_attention_sparsity": 0.580535888671875,
      "attention_bam_384_attention_concentration_10": 1.301179895976514,
      "attention_bam_384_attention_concentration_20": 2.0109771184735727,
      "attention_bam_384_attention_center_y": 0.48224676863579213,
      "attention_bam_384_attention_center_x": 0.48182201232205646,
      "attention_bam_384_attention_center_distance": 0.03593372955568517,
      "attention_bam_384_attention_spatial_variance": 171.1506458440176,
      "attention_bam_384_attention_spatial_std": 13.082455650374573,
      "attention_bam_384_num_attention_peaks": 21,
      "attention_bam_384_peak_separation_mean": 17.81855216807697,
      "attention_bam_384_peak_intensity_mean": 0.31360405683517456,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14184851944446564,
      "attention_bam_16_std_attention": 0.6007087230682373,
      "attention_bam_16_max_attention": 2.4741244316101074,
      "attention_bam_16_min_attention": -0.9889365434646606,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.0936964914923828,
      "attention_bam_16_attention_skewness": 0.6913814101752783,
      "attention_bam_16_attention_sparsity": 0.529296875,
      "attention_bam_16_attention_concentration_10": 0.951216230012476,
      "attention_bam_16_attention_concentration_20": 1.5184833579291248,
      "attention_bam_16_attention_center_y": 0.4625020567585142,
      "attention_bam_16_attention_center_x": 0.4625974924448706,
      "attention_bam_16_attention_center_distance": 0.07490051159709396,
      "attention_bam_16_attention_spatial_variance": 43.06814807182246,
      "attention_bam_16_attention_spatial_std": 6.562632708892252,
      "attention_bam_16_num_attention_peaks": 15,
      "attention_bam_16_peak_separation_mean": 8.477334933201131,
      "attention_bam_16_peak_intensity_mean": 0.33132505416870117,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 415,
      "phase": "train",
      "loss": 0.0046932632103562355,
      "timestamp": 1759543950.991204,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0046932632103562355,
      "ssim": 0.9252849817276001,
      "attention_bam_384_mean_attention": 0.0634300634264946,
      "attention_bam_384_std_attention": 0.3678393065929413,
      "attention_bam_384_max_attention": 3.4943103790283203,
      "attention_bam_384_min_attention": -1.156124234199524,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.9047865782010387,
      "attention_bam_384_attention_skewness": 0.9249590102664632,
      "attention_bam_384_attention_sparsity": 0.5939229329427084,
      "attention_bam_384_attention_concentration_10": 1.290141414840128,
      "attention_bam_384_attention_concentration_20": 1.9553703285910526,
      "attention_bam_384_attention_center_y": 0.4795331764857409,
      "attention_bam_384_attention_center_x": 0.48531676261979706,
      "attention_bam_384_attention_center_distance": 0.03562269851449264,
      "attention_bam_384_attention_spatial_variance": 169.77463340192148,
      "attention_bam_384_attention_spatial_std": 13.029759529704355,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 18.605526690068256,
      "attention_bam_384_peak_intensity_mean": 0.2672289311885834,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.15002471208572388,
      "attention_bam_16_std_attention": 0.5953904986381531,
      "attention_bam_16_max_attention": 3.145430088043213,
      "attention_bam_16_min_attention": -1.1160309314727783,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.1054850334167563,
      "attention_bam_16_attention_skewness": 0.9675409113756336,
      "attention_bam_16_attention_sparsity": 0.5341796875,
      "attention_bam_16_attention_concentration_10": 0.9311519838767627,
      "attention_bam_16_attention_concentration_20": 1.4364316882146317,
      "attention_bam_16_attention_center_y": 0.45302543017435354,
      "attention_bam_16_attention_center_x": 0.47143078318453585,
      "attention_bam_16_attention_center_distance": 0.07775358975318805,
      "attention_bam_16_attention_spatial_variance": 42.16258482612894,
      "attention_bam_16_attention_spatial_std": 6.493272274141055,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.10944736611031,
      "attention_bam_16_peak_intensity_mean": 0.32051318883895874,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 416,
      "phase": "train",
      "loss": 0.005099842324852943,
      "timestamp": 1759543951.1249607,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005099842324852943,
      "ssim": 0.8956849575042725,
      "attention_bam_384_mean_attention": 0.06499819457530975,
      "attention_bam_384_std_attention": 0.35237210988998413,
      "attention_bam_384_max_attention": 2.621302604675293,
      "attention_bam_384_min_attention": -1.2568975687026978,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0730320799931254,
      "attention_bam_384_attention_skewness": 0.6927105476899544,
      "attention_bam_384_attention_sparsity": 0.5819753011067709,
      "attention_bam_384_attention_concentration_10": 1.1794615793448855,
      "attention_bam_384_attention_concentration_20": 1.826504552812569,
      "attention_bam_384_attention_center_y": 0.4837743377213273,
      "attention_bam_384_attention_center_x": 0.4838522314857498,
      "attention_bam_384_attention_center_distance": 0.032373524502943854,
      "attention_bam_384_attention_spatial_variance": 170.8348477088113,
      "attention_bam_384_attention_spatial_std": 13.070380549502424,
      "attention_bam_384_num_attention_peaks": 24,
      "attention_bam_384_peak_separation_mean": 19.051830511282105,
      "attention_bam_384_peak_intensity_mean": 0.3469492495059967,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.15598027408123016,
      "attention_bam_16_std_attention": 0.5683541893959045,
      "attention_bam_16_max_attention": 3.22951078414917,
      "attention_bam_16_min_attention": -1.119887351989746,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6003400171669657,
      "attention_bam_16_attention_skewness": 0.7067025535661846,
      "attention_bam_16_attention_sparsity": 0.50830078125,
      "attention_bam_16_attention_concentration_10": 0.8239186049015361,
      "attention_bam_16_attention_concentration_20": 1.3130133490004667,
      "attention_bam_16_attention_center_y": 0.46587707533281947,
      "attention_bam_16_attention_center_x": 0.46696835571785117,
      "attention_bam_16_attention_center_distance": 0.06716343516861675,
      "attention_bam_16_attention_spatial_variance": 42.855942204010276,
      "attention_bam_16_attention_spatial_std": 6.5464450050397796,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.589627661588521,
      "attention_bam_16_peak_intensity_mean": 0.29901373386383057,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 417,
      "phase": "train",
      "loss": 0.00561212282627821,
      "timestamp": 1759543951.2860067,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00561212282627821,
      "ssim": 0.9072489738464355,
      "attention_bam_384_mean_attention": 0.06530321389436722,
      "attention_bam_384_std_attention": 0.35939839482307434,
      "attention_bam_384_max_attention": 2.3117880821228027,
      "attention_bam_384_min_attention": -1.1402561664581299,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7588025706155506,
      "attention_bam_384_attention_skewness": 0.6472096235542301,
      "attention_bam_384_attention_sparsity": 0.5792465209960938,
      "attention_bam_384_attention_concentration_10": 1.2022732621221588,
      "attention_bam_384_attention_concentration_20": 1.8505230818183698,
      "attention_bam_384_attention_center_y": 0.48191549062169936,
      "attention_bam_384_attention_center_x": 0.4757970632178792,
      "attention_bam_384_attention_center_distance": 0.04272778085351919,
      "attention_bam_384_attention_spatial_variance": 171.76323310693544,
      "attention_bam_384_attention_spatial_std": 13.105847286876779,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 15.0171258224412,
      "attention_bam_384_peak_intensity_mean": 0.3512873947620392,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1543581485748291,
      "attention_bam_16_std_attention": 0.5827435255050659,
      "attention_bam_16_max_attention": 2.7201249599456787,
      "attention_bam_16_min_attention": -1.0330541133880615,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.38841529321184387,
      "attention_bam_16_attention_skewness": 0.7231378201078443,
      "attention_bam_16_attention_sparsity": 0.5185546875,
      "attention_bam_16_attention_concentration_10": 0.8629843224947492,
      "attention_bam_16_attention_concentration_20": 1.3687900142657197,
      "attention_bam_16_attention_center_y": 0.4611981933302404,
      "attention_bam_16_attention_center_x": 0.4422493570989489,
      "attention_bam_16_attention_center_distance": 0.09839427784502634,
      "attention_bam_16_attention_spatial_variance": 43.246334586343586,
      "attention_bam_16_attention_spatial_std": 6.576194536838428,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 7.378738813745478,
      "attention_bam_16_peak_intensity_mean": 0.32109373807907104,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 418,
      "phase": "train",
      "loss": 0.010100922547280788,
      "timestamp": 1759543951.4743066,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.010100922547280788,
      "ssim": 0.864697277545929,
      "attention_bam_384_mean_attention": 0.0644984021782875,
      "attention_bam_384_std_attention": 0.33850744366645813,
      "attention_bam_384_max_attention": 2.9403762817382812,
      "attention_bam_384_min_attention": -1.2172648906707764,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.8793076462500897,
      "attention_bam_384_attention_skewness": 1.0208219764214839,
      "attention_bam_384_attention_sparsity": 0.5935846964518229,
      "attention_bam_384_attention_concentration_10": 1.1693226688167493,
      "attention_bam_384_attention_concentration_20": 1.756020276246737,
      "attention_bam_384_attention_center_y": 0.47893723556554124,
      "attention_bam_384_attention_center_x": 0.4773038433411878,
      "attention_bam_384_attention_center_distance": 0.043789395353278075,
      "attention_bam_384_attention_spatial_variance": 173.85601690490589,
      "attention_bam_384_attention_spatial_std": 13.185447163631041,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 19.413634223470858,
      "attention_bam_384_peak_intensity_mean": 0.31506064534187317,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.15273678302764893,
      "attention_bam_16_std_attention": 0.5603343844413757,
      "attention_bam_16_max_attention": 3.1171164512634277,
      "attention_bam_16_min_attention": -1.033855676651001,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.2362508689756924,
      "attention_bam_16_attention_skewness": 0.8662487229392113,
      "attention_bam_16_attention_sparsity": 0.509521484375,
      "attention_bam_16_attention_concentration_10": 0.8420239742491548,
      "attention_bam_16_attention_concentration_20": 1.3125899024882113,
      "attention_bam_16_attention_center_y": 0.45293397831693777,
      "attention_bam_16_attention_center_x": 0.4492152780140567,
      "attention_bam_16_attention_center_distance": 0.09792138054847915,
      "attention_bam_16_attention_spatial_variance": 45.119463776780925,
      "attention_bam_16_attention_spatial_std": 6.717102334845058,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.91995372044908,
      "attention_bam_16_peak_intensity_mean": 0.3016561269760132,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 419,
      "phase": "train",
      "loss": 0.006461435463279486,
      "timestamp": 1759543951.6528733,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006461435463279486,
      "ssim": 0.9208564758300781,
      "attention_bam_384_mean_attention": 0.0675768181681633,
      "attention_bam_384_std_attention": 0.2944948673248291,
      "attention_bam_384_max_attention": 3.5544493198394775,
      "attention_bam_384_min_attention": -1.1696065664291382,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.3826453217308297,
      "attention_bam_384_attention_skewness": 1.0029197266835044,
      "attention_bam_384_attention_sparsity": 0.5869725545247396,
      "attention_bam_384_attention_concentration_10": 0.9687495268283551,
      "attention_bam_384_attention_concentration_20": 1.4765290139435723,
      "attention_bam_384_attention_center_y": 0.47871508422414194,
      "attention_bam_384_attention_center_x": 0.47974169674958433,
      "attention_bam_384_attention_center_distance": 0.041555901871362946,
      "attention_bam_384_attention_spatial_variance": 173.93284667933594,
      "attention_bam_384_attention_spatial_std": 13.188360272578844,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 17.95554105878904,
      "attention_bam_384_peak_intensity_mean": 0.27041181921958923,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16766193509101868,
      "attention_bam_16_std_attention": 0.5213701128959656,
      "attention_bam_16_max_attention": 2.8501908779144287,
      "attention_bam_16_min_attention": -1.0032706260681152,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7342538467052342,
      "attention_bam_16_attention_skewness": 0.6801902882729839,
      "attention_bam_16_attention_sparsity": 0.48974609375,
      "attention_bam_16_attention_concentration_10": 0.709171014037273,
      "attention_bam_16_attention_concentration_20": 1.1373560849213877,
      "attention_bam_16_attention_center_y": 0.45076771513682445,
      "attention_bam_16_attention_center_x": 0.4532007927515487,
      "attention_bam_16_attention_center_distance": 0.09606230969461813,
      "attention_bam_16_attention_spatial_variance": 45.33770840320484,
      "attention_bam_16_attention_spatial_std": 6.733328181754165,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 8.691109845552877,
      "attention_bam_16_peak_intensity_mean": 0.33085760474205017,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 420,
      "phase": "train",
      "loss": 0.005477496422827244,
      "timestamp": 1759543951.8550997,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005477496422827244,
      "ssim": 0.8911283016204834,
      "attention_bam_384_mean_attention": 0.06422793120145798,
      "attention_bam_384_std_attention": 0.3308728039264679,
      "attention_bam_384_max_attention": 2.9222917556762695,
      "attention_bam_384_min_attention": -1.1120905876159668,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.054425790158832,
      "attention_bam_384_attention_skewness": 0.830748239007007,
      "attention_bam_384_attention_sparsity": 0.5863723754882812,
      "attention_bam_384_attention_concentration_10": 1.132415101287632,
      "attention_bam_384_attention_concentration_20": 1.7208306900939927,
      "attention_bam_384_attention_center_y": 0.48074723234345995,
      "attention_bam_384_attention_center_x": 0.48121210292673394,
      "attention_bam_384_attention_center_distance": 0.03804350506649864,
      "attention_bam_384_attention_spatial_variance": 171.51198918449603,
      "attention_bam_384_attention_spatial_std": 13.09625859490015,
      "attention_bam_384_num_attention_peaks": 19,
      "attention_bam_384_peak_separation_mean": 18.629183012241388,
      "attention_bam_384_peak_intensity_mean": 0.30079519748687744,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1494043469429016,
      "attention_bam_16_std_attention": 0.5613480806350708,
      "attention_bam_16_max_attention": 3.3074824810028076,
      "attention_bam_16_min_attention": -1.0611492395401,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8990718286620196,
      "attention_bam_16_attention_skewness": 0.8111628103152516,
      "attention_bam_16_attention_sparsity": 0.518798828125,
      "attention_bam_16_attention_concentration_10": 0.8629747437512303,
      "attention_bam_16_attention_concentration_20": 1.350965794529803,
      "attention_bam_16_attention_center_y": 0.458969141512519,
      "attention_bam_16_attention_center_x": 0.4604537560805513,
      "attention_bam_16_attention_center_distance": 0.0805907780872753,
      "attention_bam_16_attention_spatial_variance": 43.2074324962449,
      "attention_bam_16_attention_spatial_std": 6.573236074890731,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 9.742570364216702,
      "attention_bam_16_peak_intensity_mean": 0.2915670871734619,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 421,
      "phase": "train",
      "loss": 0.005056542810052633,
      "timestamp": 1759543952.0112283,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005056542810052633,
      "ssim": 0.8913615942001343,
      "attention_bam_384_mean_attention": 0.06152493879199028,
      "attention_bam_384_std_attention": 0.3476621210575104,
      "attention_bam_384_max_attention": 3.5331406593322754,
      "attention_bam_384_min_attention": -0.961452841758728,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5542731804006689,
      "attention_bam_384_attention_skewness": 0.9095220950954799,
      "attention_bam_384_attention_sparsity": 0.5971247355143229,
      "attention_bam_384_attention_concentration_10": 1.2542475315670474,
      "attention_bam_384_attention_concentration_20": 1.9249644333556863,
      "attention_bam_384_attention_center_y": 0.48802407405076753,
      "attention_bam_384_attention_center_x": 0.48222846679316234,
      "attention_bam_384_attention_center_distance": 0.030306771351077084,
      "attention_bam_384_attention_spatial_variance": 168.5779654288584,
      "attention_bam_384_attention_spatial_std": 12.983757754550814,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 20.014156493059247,
      "attention_bam_384_peak_intensity_mean": 0.23300771415233612,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14670108258724213,
      "attention_bam_16_std_attention": 0.5721747279167175,
      "attention_bam_16_max_attention": 3.114739418029785,
      "attention_bam_16_min_attention": -0.956668496131897,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.1229362609433355,
      "attention_bam_16_attention_skewness": 0.9711349450179294,
      "attention_bam_16_attention_sparsity": 0.5419921875,
      "attention_bam_16_attention_concentration_10": 0.9093757068833215,
      "attention_bam_16_attention_concentration_20": 1.4318541000964053,
      "attention_bam_16_attention_center_y": 0.4780718234052676,
      "attention_bam_16_attention_center_x": 0.4646869001461899,
      "attention_bam_16_attention_center_distance": 0.05878537148058064,
      "attention_bam_16_attention_spatial_variance": 41.272591699940904,
      "attention_bam_16_attention_spatial_std": 6.4243748100450135,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 7.847073898839302,
      "attention_bam_16_peak_intensity_mean": 0.277373731136322,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 422,
      "phase": "train",
      "loss": 0.005490311421453953,
      "timestamp": 1759543952.1532257,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005490311421453953,
      "ssim": 0.8877569437026978,
      "attention_bam_384_mean_attention": 0.06285079568624496,
      "attention_bam_384_std_attention": 0.3217036724090576,
      "attention_bam_384_max_attention": 3.0345261096954346,
      "attention_bam_384_min_attention": -0.999558687210083,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8714190202023984,
      "attention_bam_384_attention_skewness": 0.913654423489959,
      "attention_bam_384_attention_sparsity": 0.604766845703125,
      "attention_bam_384_attention_concentration_10": 1.1492899692223673,
      "attention_bam_384_attention_concentration_20": 1.760209952379397,
      "attention_bam_384_attention_center_y": 0.4803357231792401,
      "attention_bam_384_attention_center_x": 0.47011140629269865,
      "attention_bam_384_attention_center_distance": 0.05059667610987125,
      "attention_bam_384_attention_spatial_variance": 171.29217608307053,
      "attention_bam_384_attention_spatial_std": 13.087863694395297,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 19.265844432566098,
      "attention_bam_384_peak_intensity_mean": 0.2727811336517334,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.15624000132083893,
      "attention_bam_16_std_attention": 0.548303484916687,
      "attention_bam_16_max_attention": 2.4261879920959473,
      "attention_bam_16_min_attention": -1.0440642833709717,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.1895254171922658,
      "attention_bam_16_attention_skewness": 0.7235187681192746,
      "attention_bam_16_attention_sparsity": 0.5244140625,
      "attention_bam_16_attention_concentration_10": 0.8108443333067703,
      "attention_bam_16_attention_concentration_20": 1.2953704064684397,
      "attention_bam_16_attention_center_y": 0.4571161183160662,
      "attention_bam_16_attention_center_x": 0.4336695802177936,
      "attention_bam_16_attention_center_distance": 0.11170274747530028,
      "attention_bam_16_attention_spatial_variance": 42.92711921464089,
      "attention_bam_16_attention_spatial_std": 6.551879059830156,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 9.195945333146861,
      "attention_bam_16_peak_intensity_mean": 0.36800673604011536,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 423,
      "phase": "train",
      "loss": 0.005489971488714218,
      "timestamp": 1759543952.2988558,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005489971488714218,
      "ssim": 0.9077005386352539,
      "attention_bam_384_mean_attention": 0.0611862950026989,
      "attention_bam_384_std_attention": 0.34287023544311523,
      "attention_bam_384_max_attention": 2.893479347229004,
      "attention_bam_384_min_attention": -1.0541894435882568,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.4881239068814507,
      "attention_bam_384_attention_skewness": 0.9958033166495519,
      "attention_bam_384_attention_sparsity": 0.5981369018554688,
      "attention_bam_384_attention_concentration_10": 1.243220076457291,
      "attention_bam_384_attention_concentration_20": 1.8722260665070587,
      "attention_bam_384_attention_center_y": 0.4815430715360019,
      "attention_bam_384_attention_center_x": 0.4872448954141213,
      "attention_bam_384_attention_center_distance": 0.03172856445923285,
      "attention_bam_384_attention_spatial_variance": 173.56759043966397,
      "attention_bam_384_attention_spatial_std": 13.174505320491695,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 21.19532598894715,
      "attention_bam_384_peak_intensity_mean": 0.288422554731369,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1472930908203125,
      "attention_bam_16_std_attention": 0.5673413276672363,
      "attention_bam_16_max_attention": 3.236112117767334,
      "attention_bam_16_min_attention": -1.0066391229629517,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.9964678822802169,
      "attention_bam_16_attention_skewness": 1.1089251891945016,
      "attention_bam_16_attention_sparsity": 0.53857421875,
      "attention_bam_16_attention_concentration_10": 0.913375274349048,
      "attention_bam_16_attention_concentration_20": 1.389667962656962,
      "attention_bam_16_attention_center_y": 0.46279296678145965,
      "attention_bam_16_attention_center_x": 0.47776657019738317,
      "attention_bam_16_attention_center_distance": 0.061297450545898816,
      "attention_bam_16_attention_spatial_variance": 44.7065900336265,
      "attention_bam_16_attention_spatial_std": 6.686298679660257,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 11.292458306221018,
      "attention_bam_16_peak_intensity_mean": 0.27477747201919556,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 424,
      "phase": "train",
      "loss": 0.004597052466124296,
      "timestamp": 1759543952.4457498,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004597052466124296,
      "ssim": 0.9158835411071777,
      "attention_bam_384_mean_attention": 0.0631122961640358,
      "attention_bam_384_std_attention": 0.31678155064582825,
      "attention_bam_384_max_attention": 2.9379076957702637,
      "attention_bam_384_min_attention": -1.0876368284225464,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.750245214203236,
      "attention_bam_384_attention_skewness": 0.7919058527926857,
      "attention_bam_384_attention_sparsity": 0.585723876953125,
      "attention_bam_384_attention_concentration_10": 1.0810835102021554,
      "attention_bam_384_attention_concentration_20": 1.6876292677637408,
      "attention_bam_384_attention_center_y": 0.48297872043376494,
      "attention_bam_384_attention_center_x": 0.4864860516004013,
      "attention_bam_384_attention_center_distance": 0.030735997118003087,
      "attention_bam_384_attention_spatial_variance": 171.68198633421454,
      "attention_bam_384_attention_spatial_std": 13.102747281933455,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 17.685867933330425,
      "attention_bam_384_peak_intensity_mean": 0.2900936007499695,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16248488426208496,
      "attention_bam_16_std_attention": 0.5395970344543457,
      "attention_bam_16_max_attention": 2.979139804840088,
      "attention_bam_16_min_attention": -1.0982109308242798,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.1694514247827739,
      "attention_bam_16_attention_skewness": 0.859519321607385,
      "attention_bam_16_attention_sparsity": 0.516357421875,
      "attention_bam_16_attention_concentration_10": 0.7629601723115068,
      "attention_bam_16_attention_concentration_20": 1.2118359057852195,
      "attention_bam_16_attention_center_y": 0.4629973285974334,
      "attention_bam_16_attention_center_x": 0.4734397792423739,
      "attention_bam_16_attention_center_distance": 0.06441495195403239,
      "attention_bam_16_attention_spatial_variance": 43.27511813639895,
      "attention_bam_16_attention_spatial_std": 6.578382638338922,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.936244488087363,
      "attention_bam_16_peak_intensity_mean": 0.3185442388057709,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 425,
      "phase": "train",
      "loss": 0.0053006685338914394,
      "timestamp": 1759543952.5935242,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0053006685338914394,
      "ssim": 0.909289538860321,
      "attention_bam_384_mean_attention": 0.06350795179605484,
      "attention_bam_384_std_attention": 0.3350037932395935,
      "attention_bam_384_max_attention": 2.413524627685547,
      "attention_bam_384_min_attention": -1.0424551963806152,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.872705376156782,
      "attention_bam_384_attention_skewness": 0.616896808045044,
      "attention_bam_384_attention_sparsity": 0.57745361328125,
      "attention_bam_384_attention_concentration_10": 1.1320431924720937,
      "attention_bam_384_attention_concentration_20": 1.7622407102100204,
      "attention_bam_384_attention_center_y": 0.4863306856750522,
      "attention_bam_384_attention_center_x": 0.4809253299715794,
      "attention_bam_384_attention_center_distance": 0.033187141811471206,
      "attention_bam_384_attention_spatial_variance": 172.12908396874386,
      "attention_bam_384_attention_spatial_std": 13.11979740578123,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 19.046571570397802,
      "attention_bam_384_peak_intensity_mean": 0.32459720969200134,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1647707223892212,
      "attention_bam_16_std_attention": 0.5579759478569031,
      "attention_bam_16_max_attention": 2.4274349212646484,
      "attention_bam_16_min_attention": -1.045210599899292,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.32620567912325216,
      "attention_bam_16_attention_skewness": 0.6114184428590076,
      "attention_bam_16_attention_sparsity": 0.49267578125,
      "attention_bam_16_attention_concentration_10": 0.7633673962426241,
      "attention_bam_16_attention_concentration_20": 1.2155871232357651,
      "attention_bam_16_attention_center_y": 0.4748411379471518,
      "attention_bam_16_attention_center_x": 0.4594600976522777,
      "attention_bam_16_attention_center_distance": 0.06747521059110678,
      "attention_bam_16_attention_spatial_variance": 43.63251265799224,
      "attention_bam_16_attention_spatial_std": 6.605491098926123,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.850081014440153,
      "attention_bam_16_peak_intensity_mean": 0.35187622904777527,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 426,
      "phase": "train",
      "loss": 0.006436137016862631,
      "timestamp": 1759543952.7318792,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006436137016862631,
      "ssim": 0.8895302414894104,
      "attention_bam_384_mean_attention": 0.06265486776828766,
      "attention_bam_384_std_attention": 0.3543722927570343,
      "attention_bam_384_max_attention": 2.575127601623535,
      "attention_bam_384_min_attention": -1.1491971015930176,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7492688762152704,
      "attention_bam_384_attention_skewness": 0.6634294335499498,
      "attention_bam_384_attention_sparsity": 0.5810165405273438,
      "attention_bam_384_attention_concentration_10": 1.219849848870898,
      "attention_bam_384_attention_concentration_20": 1.9013092580345476,
      "attention_bam_384_attention_center_y": 0.47843766609838717,
      "attention_bam_384_attention_center_x": 0.4856724725408063,
      "attention_bam_384_attention_center_distance": 0.036611809198087736,
      "attention_bam_384_attention_spatial_variance": 169.75116890491705,
      "attention_bam_384_attention_spatial_std": 13.028859079171784,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 18.553658468736753,
      "attention_bam_384_peak_intensity_mean": 0.32859236001968384,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14989465475082397,
      "attention_bam_16_std_attention": 0.590481698513031,
      "attention_bam_16_max_attention": 2.7461886405944824,
      "attention_bam_16_min_attention": -1.1203073263168335,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.23468574381631901,
      "attention_bam_16_attention_skewness": 0.6727277532266626,
      "attention_bam_16_attention_sparsity": 0.51953125,
      "attention_bam_16_attention_concentration_10": 0.8759352079433762,
      "attention_bam_16_attention_concentration_20": 1.40575837584173,
      "attention_bam_16_attention_center_y": 0.4488201166954953,
      "attention_bam_16_attention_center_x": 0.4738287618609997,
      "attention_bam_16_attention_center_distance": 0.08129347035021915,
      "attention_bam_16_attention_spatial_variance": 41.86084251209916,
      "attention_bam_16_attention_spatial_std": 6.469995557347715,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 7.951519562961422,
      "attention_bam_16_peak_intensity_mean": 0.3247341811656952,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 427,
      "phase": "train",
      "loss": 0.003969261422753334,
      "timestamp": 1759543953.109915,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.003969261422753334,
      "ssim": 0.93299400806427,
      "attention_bam_384_mean_attention": 0.061057865619659424,
      "attention_bam_384_std_attention": 0.35525384545326233,
      "attention_bam_384_max_attention": 2.360759735107422,
      "attention_bam_384_min_attention": -0.939545214176178,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.4649551914744894,
      "attention_bam_384_attention_skewness": 0.5994030245300105,
      "attention_bam_384_attention_sparsity": 0.5794576009114584,
      "attention_bam_384_attention_concentration_10": 1.2417265483573041,
      "attention_bam_384_attention_concentration_20": 1.9426899431616145,
      "attention_bam_384_attention_center_y": 0.4876572115822749,
      "attention_bam_384_attention_center_x": 0.48107619605407276,
      "attention_bam_384_attention_center_distance": 0.03195167543990834,
      "attention_bam_384_attention_spatial_variance": 170.1915612473273,
      "attention_bam_384_attention_spatial_std": 13.045748780630696,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 18.21051081477831,
      "attention_bam_384_peak_intensity_mean": 0.3068248927593231,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1445927768945694,
      "attention_bam_16_std_attention": 0.5960695147514343,
      "attention_bam_16_max_attention": 2.355464458465576,
      "attention_bam_16_min_attention": -0.9806403517723083,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.003024177536741668,
      "attention_bam_16_attention_skewness": 0.6583384009788837,
      "attention_bam_16_attention_sparsity": 0.5234375,
      "attention_bam_16_attention_concentration_10": 0.9232062346284156,
      "attention_bam_16_attention_concentration_20": 1.478893140842248,
      "attention_bam_16_attention_center_y": 0.48173216672062447,
      "attention_bam_16_attention_center_x": 0.46177513148015914,
      "attention_bam_16_attention_center_distance": 0.059914177054887115,
      "attention_bam_16_attention_spatial_variance": 42.38168330029952,
      "attention_bam_16_attention_spatial_std": 6.510121604109981,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.606304484407127,
      "attention_bam_16_peak_intensity_mean": 0.34918108582496643,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 428,
      "phase": "train",
      "loss": 0.0035355128347873688,
      "timestamp": 1759543953.2537143,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0035355128347873688,
      "ssim": 0.9250664710998535,
      "attention_bam_384_mean_attention": 0.06201803684234619,
      "attention_bam_384_std_attention": 0.3045594096183777,
      "attention_bam_384_max_attention": 2.8875679969787598,
      "attention_bam_384_min_attention": -1.0127469301223755,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.7496812649213318,
      "attention_bam_384_attention_skewness": 0.8569726184734161,
      "attention_bam_384_attention_sparsity": 0.5934702555338541,
      "attention_bam_384_attention_concentration_10": 1.0919091005194996,
      "attention_bam_384_attention_concentration_20": 1.6696417072718504,
      "attention_bam_384_attention_center_y": 0.48853399185410695,
      "attention_bam_384_attention_center_x": 0.48458281293461913,
      "attention_bam_384_attention_center_distance": 0.027172007647968625,
      "attention_bam_384_attention_spatial_variance": 173.31131599347026,
      "attention_bam_384_attention_spatial_std": 13.16477557702638,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 20.512098017720334,
      "attention_bam_384_peak_intensity_mean": 0.28079524636268616,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.15422363579273224,
      "attention_bam_16_std_attention": 0.5455399751663208,
      "attention_bam_16_max_attention": 3.490149974822998,
      "attention_bam_16_min_attention": -0.9802719354629517,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.0451039839320142,
      "attention_bam_16_attention_skewness": 0.8111637208360849,
      "attention_bam_16_attention_sparsity": 0.5068359375,
      "attention_bam_16_attention_concentration_10": 0.8141933161110493,
      "attention_bam_16_attention_concentration_20": 1.2781131527996406,
      "attention_bam_16_attention_center_y": 0.48296821631938847,
      "attention_bam_16_attention_center_x": 0.47424831188461875,
      "attention_bam_16_attention_center_distance": 0.043663052942619886,
      "attention_bam_16_attention_spatial_variance": 44.48833046278329,
      "attention_bam_16_attention_spatial_std": 6.669957305919079,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 10.471611000199625,
      "attention_bam_16_peak_intensity_mean": 0.2609519362449646,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 429,
      "phase": "train",
      "loss": 0.006004009395837784,
      "timestamp": 1759543953.403,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006004009395837784,
      "ssim": 0.9233877062797546,
      "attention_bam_384_mean_attention": 0.0605163536965847,
      "attention_bam_384_std_attention": 0.3177827298641205,
      "attention_bam_384_max_attention": 2.8913416862487793,
      "attention_bam_384_min_attention": -1.1767089366912842,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6271350057273981,
      "attention_bam_384_attention_skewness": 0.5223061178297589,
      "attention_bam_384_attention_sparsity": 0.5786794026692709,
      "attention_bam_384_attention_concentration_10": 1.1054296075088732,
      "attention_bam_384_attention_concentration_20": 1.750476195321958,
      "attention_bam_384_attention_center_y": 0.4836309467880761,
      "attention_bam_384_attention_center_x": 0.4871551857346373,
      "attention_bam_384_attention_center_distance": 0.029425674387053943,
      "attention_bam_384_attention_spatial_variance": 167.24632724542178,
      "attention_bam_384_attention_spatial_std": 12.932375158702357,
      "attention_bam_384_num_attention_peaks": 4,
      "attention_bam_384_peak_separation_mean": 13.517534123485738,
      "attention_bam_384_peak_intensity_mean": 0.308743953704834,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.15257978439331055,
      "attention_bam_16_std_attention": 0.5478156208992004,
      "attention_bam_16_max_attention": 2.950092077255249,
      "attention_bam_16_min_attention": -1.126699686050415,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.17523434566016993,
      "attention_bam_16_attention_skewness": 0.5793427088140332,
      "attention_bam_16_attention_sparsity": 0.50048828125,
      "attention_bam_16_attention_concentration_10": 0.797622744789305,
      "attention_bam_16_attention_concentration_20": 1.2886911179450218,
      "attention_bam_16_attention_center_y": 0.4659021437018454,
      "attention_bam_16_attention_center_x": 0.4802915622052778,
      "attention_bam_16_attention_center_distance": 0.055697151173790475,
      "attention_bam_16_attention_spatial_variance": 39.98987966900817,
      "attention_bam_16_attention_spatial_std": 6.323755187308263,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 5.195459700697203,
      "attention_bam_16_peak_intensity_mean": 0.3360452353954315,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 430,
      "phase": "train",
      "loss": 0.005570432171225548,
      "timestamp": 1759543953.599082,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005570432171225548,
      "ssim": 0.8905237913131714,
      "attention_bam_384_mean_attention": 0.060577791184186935,
      "attention_bam_384_std_attention": 0.3183056116104126,
      "attention_bam_384_max_attention": 2.64235258102417,
      "attention_bam_384_min_attention": -0.9703295230865479,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.5174900052980798,
      "attention_bam_384_attention_skewness": 0.9984788572660368,
      "attention_bam_384_attention_sparsity": 0.5961583455403646,
      "attention_bam_384_attention_concentration_10": 1.1681081869997523,
      "attention_bam_384_attention_concentration_20": 1.7502217134903344,
      "attention_bam_384_attention_center_y": 0.483690583093548,
      "attention_bam_384_attention_center_x": 0.48552890805058163,
      "attention_bam_384_attention_center_distance": 0.03083535574748516,
      "attention_bam_384_attention_spatial_variance": 169.04200807305384,
      "attention_bam_384_attention_spatial_std": 13.001615594727213,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 20.315845017857374,
      "attention_bam_384_peak_intensity_mean": 0.28812482953071594,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1535416692495346,
      "attention_bam_16_std_attention": 0.5616487264633179,
      "attention_bam_16_max_attention": 3.4566900730133057,
      "attention_bam_16_min_attention": -1.0172908306121826,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.5279405680235465,
      "attention_bam_16_attention_skewness": 0.9870408688208342,
      "attention_bam_16_attention_sparsity": 0.523193359375,
      "attention_bam_16_attention_concentration_10": 0.8565491075325999,
      "attention_bam_16_attention_concentration_20": 1.3265847936421873,
      "attention_bam_16_attention_center_y": 0.466546860769472,
      "attention_bam_16_attention_center_x": 0.4744579069379454,
      "attention_bam_16_attention_center_distance": 0.059523290271418144,
      "attention_bam_16_attention_spatial_variance": 41.450226868651,
      "attention_bam_16_attention_spatial_std": 6.4381850601431925,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.521890160520575,
      "attention_bam_16_peak_intensity_mean": 0.2746083736419678,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 431,
      "phase": "train",
      "loss": 0.006972470786422491,
      "timestamp": 1759543953.7531588,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006972470786422491,
      "ssim": 0.9046615362167358,
      "attention_bam_384_mean_attention": 0.06229434534907341,
      "attention_bam_384_std_attention": 0.3409346044063568,
      "attention_bam_384_max_attention": 2.6040070056915283,
      "attention_bam_384_min_attention": -1.029007911682129,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9874914184791725,
      "attention_bam_384_attention_skewness": 0.6722861602172633,
      "attention_bam_384_attention_sparsity": 0.5826746622721354,
      "attention_bam_384_attention_concentration_10": 1.1705098780779797,
      "attention_bam_384_attention_concentration_20": 1.8350715081464368,
      "attention_bam_384_attention_center_y": 0.47927521254908617,
      "attention_bam_384_attention_center_x": 0.48009039377177604,
      "attention_bam_384_attention_center_distance": 0.04064256967881066,
      "attention_bam_384_attention_spatial_variance": 171.89028123972324,
      "attention_bam_384_attention_spatial_std": 13.11069339278908,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 18.688162606431824,
      "attention_bam_384_peak_intensity_mean": 0.30416616797447205,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.15773066878318787,
      "attention_bam_16_std_attention": 0.5982916951179504,
      "attention_bam_16_max_attention": 3.1650726795196533,
      "attention_bam_16_min_attention": -0.9862582087516785,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6322537122183927,
      "attention_bam_16_attention_skewness": 0.7395148290625193,
      "attention_bam_16_attention_sparsity": 0.5107421875,
      "attention_bam_16_attention_concentration_10": 0.8493773243569173,
      "attention_bam_16_attention_concentration_20": 1.356661885723205,
      "attention_bam_16_attention_center_y": 0.452925871650062,
      "attention_bam_16_attention_center_x": 0.4540804398900215,
      "attention_bam_16_attention_center_distance": 0.0930008554863918,
      "attention_bam_16_attention_spatial_variance": 43.55210050475996,
      "attention_bam_16_attention_spatial_std": 6.599401526256753,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.085058445602263,
      "attention_bam_16_peak_intensity_mean": 0.27617529034614563,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 432,
      "phase": "train",
      "loss": 0.0052409702911973,
      "timestamp": 1759543953.9301124,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0052409702911973,
      "ssim": 0.9122403860092163,
      "attention_bam_384_mean_attention": 0.06100555136799812,
      "attention_bam_384_std_attention": 0.30753687024116516,
      "attention_bam_384_max_attention": 2.1973023414611816,
      "attention_bam_384_min_attention": -0.9086365699768066,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.4528587832994999,
      "attention_bam_384_attention_skewness": 0.4953484182622709,
      "attention_bam_384_attention_sparsity": 0.5798212687174479,
      "attention_bam_384_attention_concentration_10": 1.0709934180310858,
      "attention_bam_384_attention_concentration_20": 1.6927210789080098,
      "attention_bam_384_attention_center_y": 0.4846929571869578,
      "attention_bam_384_attention_center_x": 0.48165991473333986,
      "attention_bam_384_attention_center_distance": 0.03378355479426849,
      "attention_bam_384_attention_spatial_variance": 169.68973281927322,
      "attention_bam_384_attention_spatial_std": 13.026501173349397,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 17.877458082367642,
      "attention_bam_384_peak_intensity_mean": 0.31426334381103516,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16153497993946075,
      "attention_bam_16_std_attention": 0.5373907685279846,
      "attention_bam_16_max_attention": 2.7710225582122803,
      "attention_bam_16_min_attention": -1.0279545783996582,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.24443288506119032,
      "attention_bam_16_attention_skewness": 0.592836707346081,
      "attention_bam_16_attention_sparsity": 0.495361328125,
      "attention_bam_16_attention_concentration_10": 0.7481598744733646,
      "attention_bam_16_attention_concentration_20": 1.2092728064361542,
      "attention_bam_16_attention_center_y": 0.4702052903614228,
      "attention_bam_16_attention_center_x": 0.46219140643131645,
      "attention_bam_16_attention_center_distance": 0.06807664019454875,
      "attention_bam_16_attention_spatial_variance": 41.93831436743663,
      "attention_bam_16_attention_spatial_std": 6.475979799801466,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.739498386430721,
      "attention_bam_16_peak_intensity_mean": 0.31304532289505005,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 433,
      "phase": "train",
      "loss": 0.00588103337213397,
      "timestamp": 1759543954.0767376,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00588103337213397,
      "ssim": 0.9105565547943115,
      "attention_bam_384_mean_attention": 0.059295471757650375,
      "attention_bam_384_std_attention": 0.3300994336605072,
      "attention_bam_384_max_attention": 2.257739543914795,
      "attention_bam_384_min_attention": -1.00954270362854,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.4250377663925229,
      "attention_bam_384_attention_skewness": 0.5169607384857732,
      "attention_bam_384_attention_sparsity": 0.5799992879231771,
      "attention_bam_384_attention_concentration_10": 1.1561353872645301,
      "attention_bam_384_attention_concentration_20": 1.8556599628649189,
      "attention_bam_384_attention_center_y": 0.48136665798451217,
      "attention_bam_384_attention_center_x": 0.4811894425843374,
      "attention_bam_384_attention_center_distance": 0.037444318793485455,
      "attention_bam_384_attention_spatial_variance": 170.56265488589375,
      "attention_bam_384_attention_spatial_std": 13.059963816408288,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 17.429240203292796,
      "attention_bam_384_peak_intensity_mean": 0.3293496072292328,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.15234336256980896,
      "attention_bam_16_std_attention": 0.5620809197425842,
      "attention_bam_16_max_attention": 3.5879039764404297,
      "attention_bam_16_min_attention": -1.1141722202301025,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.12126855128590286,
      "attention_bam_16_attention_skewness": 0.5897302407754713,
      "attention_bam_16_attention_sparsity": 0.515380859375,
      "attention_bam_16_attention_concentration_10": 0.8158490314915143,
      "attention_bam_16_attention_concentration_20": 1.3240805822400021,
      "attention_bam_16_attention_center_y": 0.46192120066770204,
      "attention_bam_16_attention_center_x": 0.46067077942143575,
      "attention_bam_16_attention_center_distance": 0.07741811867911512,
      "attention_bam_16_attention_spatial_variance": 42.31343679366208,
      "attention_bam_16_attention_spatial_std": 6.5048779230406835,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.383743153908062,
      "attention_bam_16_peak_intensity_mean": 0.2720915973186493,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 434,
      "phase": "train",
      "loss": 0.005330045707523823,
      "timestamp": 1759543954.2129645,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005330045707523823,
      "ssim": 0.921607255935669,
      "attention_bam_384_mean_attention": 0.058003854006528854,
      "attention_bam_384_std_attention": 0.32747313380241394,
      "attention_bam_384_max_attention": 2.7387139797210693,
      "attention_bam_384_min_attention": -0.9616210460662842,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.142559476343844,
      "attention_bam_384_attention_skewness": 0.949371748657239,
      "attention_bam_384_attention_sparsity": 0.6009012858072916,
      "attention_bam_384_attention_concentration_10": 1.256710771744408,
      "attention_bam_384_attention_concentration_20": 1.8884794101030982,
      "attention_bam_384_attention_center_y": 0.489184483366673,
      "attention_bam_384_attention_center_x": 0.4782760705787946,
      "attention_bam_384_attention_center_distance": 0.0343192222972283,
      "attention_bam_384_attention_spatial_variance": 171.48515993086855,
      "attention_bam_384_attention_spatial_std": 13.095234244978917,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 16.261078359473153,
      "attention_bam_384_peak_intensity_mean": 0.2749491333961487,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14213302731513977,
      "attention_bam_16_std_attention": 0.5796219110488892,
      "attention_bam_16_max_attention": 3.8134005069732666,
      "attention_bam_16_min_attention": -0.9348526000976562,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.6732083170772452,
      "attention_bam_16_attention_skewness": 1.0401338945148861,
      "attention_bam_16_attention_sparsity": 0.537841796875,
      "attention_bam_16_attention_concentration_10": 0.9453149620748331,
      "attention_bam_16_attention_concentration_20": 1.452635697460975,
      "attention_bam_16_attention_center_y": 0.48664599849127604,
      "attention_bam_16_attention_center_x": 0.4510706111913473,
      "attention_bam_16_attention_center_distance": 0.07172746259952754,
      "attention_bam_16_attention_spatial_variance": 43.077732237024875,
      "attention_bam_16_attention_spatial_std": 6.563362875616804,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.49276222432391,
      "attention_bam_16_peak_intensity_mean": 0.2177148163318634,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 435,
      "phase": "train",
      "loss": 0.004702436737716198,
      "timestamp": 1759543954.3499568,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004702436737716198,
      "ssim": 0.9130774140357971,
      "attention_bam_384_mean_attention": 0.057851433753967285,
      "attention_bam_384_std_attention": 0.3358589708805084,
      "attention_bam_384_max_attention": 2.184293746948242,
      "attention_bam_384_min_attention": -1.0794198513031006,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.3974317320568916,
      "attention_bam_384_attention_skewness": 0.7561572850784116,
      "attention_bam_384_attention_sparsity": 0.5948588053385416,
      "attention_bam_384_attention_concentration_10": 1.2675679950045222,
      "attention_bam_384_attention_concentration_20": 1.931540670618069,
      "attention_bam_384_attention_center_y": 0.47710056273884077,
      "attention_bam_384_attention_center_x": 0.48543082808251364,
      "attention_bam_384_attention_center_distance": 0.03838345990759667,
      "attention_bam_384_attention_spatial_variance": 170.67034988819583,
      "attention_bam_384_attention_spatial_std": 13.064086263041737,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 15.235605752377387,
      "attention_bam_384_peak_intensity_mean": 0.35379505157470703,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.145128071308136,
      "attention_bam_16_std_attention": 0.5893958210945129,
      "attention_bam_16_max_attention": 2.8338682651519775,
      "attention_bam_16_min_attention": -1.1132848262786865,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8109936421571766,
      "attention_bam_16_attention_skewness": 0.9032135138597124,
      "attention_bam_16_attention_sparsity": 0.541259765625,
      "attention_bam_16_attention_concentration_10": 0.9385749400727997,
      "attention_bam_16_attention_concentration_20": 1.4678105792934986,
      "attention_bam_16_attention_center_y": 0.44921989415298624,
      "attention_bam_16_attention_center_x": 0.47437664020167675,
      "attention_bam_16_attention_center_distance": 0.08043849472967839,
      "attention_bam_16_attention_spatial_variance": 42.61179372915555,
      "attention_bam_16_attention_spatial_std": 6.527770961756819,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 7.503798090152995,
      "attention_bam_16_peak_intensity_mean": 0.3292786478996277,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 436,
      "phase": "train",
      "loss": 0.01195924635976553,
      "timestamp": 1759543954.4864604,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.01195924635976553,
      "ssim": 0.8353158831596375,
      "attention_bam_384_mean_attention": 0.060619015246629715,
      "attention_bam_384_std_attention": 0.3490019738674164,
      "attention_bam_384_max_attention": 3.242415189743042,
      "attention_bam_384_min_attention": -1.157973289489746,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.8711065260958675,
      "attention_bam_384_attention_skewness": 0.9725045064318791,
      "attention_bam_384_attention_sparsity": 0.57977294921875,
      "attention_bam_384_attention_concentration_10": 1.228649270497722,
      "attention_bam_384_attention_concentration_20": 1.8787327662063107,
      "attention_bam_384_attention_center_y": 0.488210512598093,
      "attention_bam_384_attention_center_x": 0.48782411264036624,
      "attention_bam_384_attention_center_distance": 0.023968489572528888,
      "attention_bam_384_attention_spatial_variance": 172.7954877460865,
      "attention_bam_384_attention_spatial_std": 13.145169749610938,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 19.007364562213866,
      "attention_bam_384_peak_intensity_mean": 0.2782304584980011,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.15449577569961548,
      "attention_bam_16_std_attention": 0.6287177801132202,
      "attention_bam_16_max_attention": 4.453814506530762,
      "attention_bam_16_min_attention": -1.0411547422409058,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.045149030707371,
      "attention_bam_16_attention_skewness": 1.2314474819121617,
      "attention_bam_16_attention_sparsity": 0.515869140625,
      "attention_bam_16_attention_concentration_10": 0.9435034754745659,
      "attention_bam_16_attention_concentration_20": 1.4195834196339032,
      "attention_bam_16_attention_center_y": 0.48119202982738807,
      "attention_bam_16_attention_center_x": 0.47915578159207234,
      "attention_bam_16_attention_center_distance": 0.03970443761221787,
      "attention_bam_16_attention_spatial_variance": 44.38354090183549,
      "attention_bam_16_attention_spatial_std": 6.662097335061646,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.93174010756427,
      "attention_bam_16_peak_intensity_mean": 0.22055955231189728,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 437,
      "phase": "train",
      "loss": 0.0054715401493012905,
      "timestamp": 1759543954.6225579,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0054715401493012905,
      "ssim": 0.9053046703338623,
      "attention_bam_384_mean_attention": 0.05990234389901161,
      "attention_bam_384_std_attention": 0.30530768632888794,
      "attention_bam_384_max_attention": 2.6487536430358887,
      "attention_bam_384_min_attention": -1.0284149646759033,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.673773371031782,
      "attention_bam_384_attention_skewness": 0.7576054075737949,
      "attention_bam_384_attention_sparsity": 0.5902582804361979,
      "attention_bam_384_attention_concentration_10": 1.1160748378821514,
      "attention_bam_384_attention_concentration_20": 1.6997308857793427,
      "attention_bam_384_attention_center_y": 0.4858449543702435,
      "attention_bam_384_attention_center_x": 0.4843609201748443,
      "attention_bam_384_attention_center_distance": 0.029831062151994568,
      "attention_bam_384_attention_spatial_variance": 170.9457580910927,
      "attention_bam_384_attention_spatial_std": 13.074622674903193,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 17.397795788090118,
      "attention_bam_384_peak_intensity_mean": 0.2980577051639557,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.15727278590202332,
      "attention_bam_16_std_attention": 0.5537109375,
      "attention_bam_16_max_attention": 3.999268054962158,
      "attention_bam_16_min_attention": -1.0297837257385254,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.6445465753383663,
      "attention_bam_16_attention_skewness": 0.8894026379081607,
      "attention_bam_16_attention_sparsity": 0.500244140625,
      "attention_bam_16_attention_concentration_10": 0.81478252003255,
      "attention_bam_16_attention_concentration_20": 1.260389555121334,
      "attention_bam_16_attention_center_y": 0.4748632369903747,
      "attention_bam_16_attention_center_x": 0.46981045746270006,
      "attention_bam_16_attention_center_distance": 0.05555655376665312,
      "attention_bam_16_attention_spatial_variance": 43.00376207953992,
      "attention_bam_16_attention_spatial_std": 6.557725373903661,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.823764008309901,
      "attention_bam_16_peak_intensity_mean": 0.24166777729988098,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 438,
      "phase": "train",
      "loss": 0.0059881797060370445,
      "timestamp": 1759543954.7723613,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0059881797060370445,
      "ssim": 0.9014291763305664,
      "attention_bam_384_mean_attention": 0.05899349972605705,
      "attention_bam_384_std_attention": 0.34252995252609253,
      "attention_bam_384_max_attention": 2.0061097145080566,
      "attention_bam_384_min_attention": -1.0125731229782104,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6883706287171028,
      "attention_bam_384_attention_skewness": 0.6565050393841242,
      "attention_bam_384_attention_sparsity": 0.5887069702148438,
      "attention_bam_384_attention_concentration_10": 1.260129359700929,
      "attention_bam_384_attention_concentration_20": 1.9486267529729848,
      "attention_bam_384_attention_center_y": 0.48449950159439614,
      "attention_bam_384_attention_center_x": 0.4827206104352732,
      "attention_bam_384_attention_center_distance": 0.03282812070623955,
      "attention_bam_384_attention_spatial_variance": 170.21992651948068,
      "attention_bam_384_attention_spatial_std": 13.046835881526244,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 17.16031936974169,
      "attention_bam_384_peak_intensity_mean": 0.35537415742874146,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14704976975917816,
      "attention_bam_16_std_attention": 0.607473611831665,
      "attention_bam_16_max_attention": 2.951516628265381,
      "attention_bam_16_min_attention": -1.0744656324386597,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6048554026573423,
      "attention_bam_16_attention_skewness": 0.8380473967361965,
      "attention_bam_16_attention_sparsity": 0.53271484375,
      "attention_bam_16_attention_concentration_10": 0.9542973931736713,
      "attention_bam_16_attention_concentration_20": 1.49304599564034,
      "attention_bam_16_attention_center_y": 0.4715671529114705,
      "attention_bam_16_attention_center_x": 0.46388039954869575,
      "attention_bam_16_attention_center_distance": 0.0650084968342071,
      "attention_bam_16_attention_spatial_variance": 42.15733412230745,
      "attention_bam_16_attention_spatial_std": 6.4928679427743985,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 10.24302595810849,
      "attention_bam_16_peak_intensity_mean": 0.30764394998550415,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 439,
      "phase": "train",
      "loss": 0.006980704143643379,
      "timestamp": 1759543954.9183545,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006980704143643379,
      "ssim": 0.8756940960884094,
      "attention_bam_384_mean_attention": 0.06078477203845978,
      "attention_bam_384_std_attention": 0.31197404861450195,
      "attention_bam_384_max_attention": 2.7635557651519775,
      "attention_bam_384_min_attention": -1.0849077701568604,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.8968828525460877,
      "attention_bam_384_attention_skewness": 0.9922359549361353,
      "attention_bam_384_attention_sparsity": 0.5929463704427084,
      "attention_bam_384_attention_concentration_10": 1.1224140437439243,
      "attention_bam_384_attention_concentration_20": 1.7099487962942417,
      "attention_bam_384_attention_center_y": 0.4794922347063055,
      "attention_bam_384_attention_center_x": 0.48595945999468976,
      "attention_bam_384_attention_center_distance": 0.035148405397172115,
      "attention_bam_384_attention_spatial_variance": 168.61052174481756,
      "attention_bam_384_attention_spatial_std": 12.985011426441547,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 14.244432263760476,
      "attention_bam_384_peak_intensity_mean": 0.3081274628639221,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16533246636390686,
      "attention_bam_16_std_attention": 0.5780062675476074,
      "attention_bam_16_max_attention": 3.7296054363250732,
      "attention_bam_16_min_attention": -1.1143009662628174,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.727936934373661,
      "attention_bam_16_attention_skewness": 1.1155020311375539,
      "attention_bam_16_attention_sparsity": 0.503173828125,
      "attention_bam_16_attention_concentration_10": 0.8115890603392967,
      "attention_bam_16_attention_concentration_20": 1.2495725657424297,
      "attention_bam_16_attention_center_y": 0.45488276276569645,
      "attention_bam_16_attention_center_x": 0.4749474236383573,
      "attention_bam_16_attention_center_distance": 0.07298214409035084,
      "attention_bam_16_attention_spatial_variance": 41.023403079245526,
      "attention_bam_16_attention_spatial_std": 6.404951450186451,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 7.520623886145269,
      "attention_bam_16_peak_intensity_mean": 0.28056249022483826,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 440,
      "phase": "train",
      "loss": 0.005367552395910025,
      "timestamp": 1759543955.107711,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005367552395910025,
      "ssim": 0.8883420825004578,
      "attention_bam_384_mean_attention": 0.057816993445158005,
      "attention_bam_384_std_attention": 0.3089495301246643,
      "attention_bam_384_max_attention": 2.921109199523926,
      "attention_bam_384_min_attention": -1.0064817667007446,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.040836993306737,
      "attention_bam_384_attention_skewness": 0.8456824074065926,
      "attention_bam_384_attention_sparsity": 0.5957514444986979,
      "attention_bam_384_attention_concentration_10": 1.162413666963461,
      "attention_bam_384_attention_concentration_20": 1.7759109931884514,
      "attention_bam_384_attention_center_y": 0.48433452446499936,
      "attention_bam_384_attention_center_x": 0.4784833191259223,
      "attention_bam_384_attention_center_distance": 0.0376397311248262,
      "attention_bam_384_attention_spatial_variance": 172.91365804486716,
      "attention_bam_384_attention_spatial_std": 13.149663799689602,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 20.663126012958937,
      "attention_bam_384_peak_intensity_mean": 0.2775265574455261,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1510610580444336,
      "attention_bam_16_std_attention": 0.5561345815658569,
      "attention_bam_16_max_attention": 3.2584805488586426,
      "attention_bam_16_min_attention": -1.0060654878616333,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.5654561182799815,
      "attention_bam_16_attention_skewness": 0.9569878669323815,
      "attention_bam_16_attention_sparsity": 0.513671875,
      "attention_bam_16_attention_concentration_10": 0.8521629910720299,
      "attention_bam_16_attention_concentration_20": 1.3216896097615292,
      "attention_bam_16_attention_center_y": 0.46849109434003045,
      "attention_bam_16_attention_center_x": 0.4551148556396477,
      "attention_bam_16_attention_center_distance": 0.07755626757572241,
      "attention_bam_16_attention_spatial_variance": 44.16429106196391,
      "attention_bam_16_attention_spatial_std": 6.645621946963573,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 11.01560309021034,
      "attention_bam_16_peak_intensity_mean": 0.27433401346206665,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 441,
      "phase": "train",
      "loss": 0.010996765457093716,
      "timestamp": 1759543955.2605517,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.010996765457093716,
      "ssim": 0.8167866468429565,
      "attention_bam_384_mean_attention": 0.05951407551765442,
      "attention_bam_384_std_attention": 0.30919063091278076,
      "attention_bam_384_max_attention": 2.4556210041046143,
      "attention_bam_384_min_attention": -1.0345324277877808,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.6665281567478454,
      "attention_bam_384_attention_skewness": 0.7749832737106567,
      "attention_bam_384_attention_sparsity": 0.591156005859375,
      "attention_bam_384_attention_concentration_10": 1.134284879206804,
      "attention_bam_384_attention_concentration_20": 1.7418961445241945,
      "attention_bam_384_attention_center_y": 0.484719398306917,
      "attention_bam_384_attention_center_x": 0.48308853778405453,
      "attention_bam_384_attention_center_distance": 0.0322333474024651,
      "attention_bam_384_attention_spatial_variance": 170.29083750441086,
      "attention_bam_384_attention_spatial_std": 13.049553153438277,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 18.13592937168267,
      "attention_bam_384_peak_intensity_mean": 0.3181935250759125,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.15619328618049622,
      "attention_bam_16_std_attention": 0.5507466197013855,
      "attention_bam_16_max_attention": 3.5060415267944336,
      "attention_bam_16_min_attention": -1.116589903831482,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.4162875478542967,
      "attention_bam_16_attention_skewness": 0.8898799842215291,
      "attention_bam_16_attention_sparsity": 0.5087890625,
      "attention_bam_16_attention_concentration_10": 0.8189330920423641,
      "attention_bam_16_attention_concentration_20": 1.2728040973840815,
      "attention_bam_16_attention_center_y": 0.4715644139457662,
      "attention_bam_16_attention_center_x": 0.46538668579106823,
      "attention_bam_16_attention_center_distance": 0.06335083385045492,
      "attention_bam_16_attention_spatial_variance": 42.35384696710601,
      "attention_bam_16_attention_spatial_std": 6.507983325662875,
      "attention_bam_16_num_attention_peaks": 11,
      "attention_bam_16_peak_separation_mean": 8.54261087171639,
      "attention_bam_16_peak_intensity_mean": 0.28005731105804443,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 442,
      "phase": "train",
      "loss": 0.003659032052382827,
      "timestamp": 1759543955.405288,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.003659032052382827,
      "ssim": 0.9223322868347168,
      "attention_bam_384_mean_attention": 0.05688090994954109,
      "attention_bam_384_std_attention": 0.36785081028938293,
      "attention_bam_384_max_attention": 3.8496901988983154,
      "attention_bam_384_min_attention": -1.0945239067077637,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 4.41851500605997,
      "attention_bam_384_attention_skewness": 1.266530153448797,
      "attention_bam_384_attention_sparsity": 0.6075159708658854,
      "attention_bam_384_attention_concentration_10": 1.4252668613397472,
      "attention_bam_384_attention_concentration_20": 2.117915163242047,
      "attention_bam_384_attention_center_y": 0.48427579000015497,
      "attention_bam_384_attention_center_x": 0.47725018859815627,
      "attention_bam_384_attention_center_distance": 0.03911022114329413,
      "attention_bam_384_attention_spatial_variance": 170.78388244515406,
      "attention_bam_384_attention_spatial_std": 13.068430756795326,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 20.1724331750117,
      "attention_bam_384_peak_intensity_mean": 0.2356095016002655,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13928942382335663,
      "attention_bam_16_std_attention": 0.6432340741157532,
      "attention_bam_16_max_attention": 4.81864595413208,
      "attention_bam_16_min_attention": -1.0997596979141235,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 4.274038565681364,
      "attention_bam_16_attention_skewness": 1.515163701372597,
      "attention_bam_16_attention_sparsity": 0.5615234375,
      "attention_bam_16_attention_concentration_10": 1.1061335290157448,
      "attention_bam_16_attention_concentration_20": 1.6304617624323008,
      "attention_bam_16_attention_center_y": 0.4681875261287924,
      "attention_bam_16_attention_center_x": 0.44941014959163944,
      "attention_bam_16_attention_center_distance": 0.08451469053539232,
      "attention_bam_16_attention_spatial_variance": 42.46361434136613,
      "attention_bam_16_attention_spatial_std": 6.516411155027446,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 10.059101614812302,
      "attention_bam_16_peak_intensity_mean": 0.21284076571464539,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 443,
      "phase": "train",
      "loss": 0.006527456920593977,
      "timestamp": 1759543955.5541327,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006527456920593977,
      "ssim": 0.8846682906150818,
      "attention_bam_384_mean_attention": 0.059726815670728683,
      "attention_bam_384_std_attention": 0.3379504382610321,
      "attention_bam_384_max_attention": 2.1221911907196045,
      "attention_bam_384_min_attention": -1.086643934249878,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.3208024432336041,
      "attention_bam_384_attention_skewness": 0.5637929022998818,
      "attention_bam_384_attention_sparsity": 0.5806376139322916,
      "attention_bam_384_attention_concentration_10": 1.2007373054357795,
      "attention_bam_384_attention_concentration_20": 1.8948555111531644,
      "attention_bam_384_attention_center_y": 0.49092050279540705,
      "attention_bam_384_attention_center_x": 0.4876723752314591,
      "attention_bam_384_attention_center_distance": 0.021652140860531723,
      "attention_bam_384_attention_spatial_variance": 171.6073898507795,
      "attention_bam_384_attention_spatial_std": 13.099900375605133,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 15.79494953928357,
      "attention_bam_384_peak_intensity_mean": 0.36872273683547974,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.15325281023979187,
      "attention_bam_16_std_attention": 0.5930297374725342,
      "attention_bam_16_max_attention": 2.427847146987915,
      "attention_bam_16_min_attention": -1.0637530088424683,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.1697656285600142,
      "attention_bam_16_attention_skewness": 0.7480789358980151,
      "attention_bam_16_attention_sparsity": 0.53369140625,
      "attention_bam_16_attention_concentration_10": 0.8837850336021296,
      "attention_bam_16_attention_concentration_20": 1.418427240181273,
      "attention_bam_16_attention_center_y": 0.4875669216969096,
      "attention_bam_16_attention_center_x": 0.48172747655366216,
      "attention_bam_16_attention_center_distance": 0.03125592901155692,
      "attention_bam_16_attention_spatial_variance": 43.41207518541968,
      "attention_bam_16_attention_spatial_std": 6.588784044527464,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.512365392571443,
      "attention_bam_16_peak_intensity_mean": 0.38422781229019165,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 444,
      "phase": "train",
      "loss": 0.006062397733330727,
      "timestamp": 1759543955.7012029,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006062397733330727,
      "ssim": 0.9184340834617615,
      "attention_bam_384_mean_attention": 0.058932334184646606,
      "attention_bam_384_std_attention": 0.34307464957237244,
      "attention_bam_384_max_attention": 3.05679988861084,
      "attention_bam_384_min_attention": -1.1273696422576904,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5443470896712146,
      "attention_bam_384_attention_skewness": 0.5853555151523554,
      "attention_bam_384_attention_sparsity": 0.5810724894205729,
      "attention_bam_384_attention_concentration_10": 1.2277700489330834,
      "attention_bam_384_attention_concentration_20": 1.9396189317397305,
      "attention_bam_384_attention_center_y": 0.48104345665551707,
      "attention_bam_384_attention_center_x": 0.4810209260286436,
      "attention_bam_384_attention_center_distance": 0.03793562400650549,
      "attention_bam_384_attention_spatial_variance": 170.89344129069795,
      "attention_bam_384_attention_spatial_std": 13.072621821604798,
      "attention_bam_384_num_attention_peaks": 18,
      "attention_bam_384_peak_separation_mean": 18.668035236192463,
      "attention_bam_384_peak_intensity_mean": 0.28730666637420654,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1422414481639862,
      "attention_bam_16_std_attention": 0.5976499915122986,
      "attention_bam_16_max_attention": 2.7565879821777344,
      "attention_bam_16_min_attention": -1.0438685417175293,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.26560610147983565,
      "attention_bam_16_attention_skewness": 0.7031755461393101,
      "attention_bam_16_attention_sparsity": 0.530517578125,
      "attention_bam_16_attention_concentration_10": 0.9279813175710557,
      "attention_bam_16_attention_concentration_20": 1.4931170828964369,
      "attention_bam_16_attention_center_y": 0.4576261708589183,
      "attention_bam_16_attention_center_x": 0.4599160415297972,
      "attention_bam_16_attention_center_distance": 0.08248957658660305,
      "attention_bam_16_attention_spatial_variance": 42.75612205628979,
      "attention_bam_16_attention_spatial_std": 6.538816563896695,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.408760685569964,
      "attention_bam_16_peak_intensity_mean": 0.3234311640262604,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 445,
      "phase": "train",
      "loss": 0.005038056988269091,
      "timestamp": 1759543955.8478484,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005038056988269091,
      "ssim": 0.9249613285064697,
      "attention_bam_384_mean_attention": 0.05817891284823418,
      "attention_bam_384_std_attention": 0.339594304561615,
      "attention_bam_384_max_attention": 3.039438486099243,
      "attention_bam_384_min_attention": -1.1171307563781738,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.114824245795699,
      "attention_bam_384_attention_skewness": 0.7347710951385177,
      "attention_bam_384_attention_sparsity": 0.5893198649088541,
      "attention_bam_384_attention_concentration_10": 1.2701388427618476,
      "attention_bam_384_attention_concentration_20": 1.948063009167965,
      "attention_bam_384_attention_center_y": 0.4772703474402259,
      "attention_bam_384_attention_center_x": 0.48956793304017565,
      "attention_bam_384_attention_center_distance": 0.035368492377886404,
      "attention_bam_384_attention_spatial_variance": 170.8311981421084,
      "attention_bam_384_attention_spatial_std": 13.07024093665103,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 18.47961768250273,
      "attention_bam_384_peak_intensity_mean": 0.28624531626701355,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14295358955860138,
      "attention_bam_16_std_attention": 0.6055866479873657,
      "attention_bam_16_max_attention": 3.403453826904297,
      "attention_bam_16_min_attention": -1.0878667831420898,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.194702567127095,
      "attention_bam_16_attention_skewness": 0.9856482069682089,
      "attention_bam_16_attention_sparsity": 0.546875,
      "attention_bam_16_attention_concentration_10": 0.989625528976674,
      "attention_bam_16_attention_concentration_20": 1.52353360148326,
      "attention_bam_16_attention_center_y": 0.44496613622850656,
      "attention_bam_16_attention_center_x": 0.48787066607823226,
      "attention_bam_16_attention_center_distance": 0.07969751442805532,
      "attention_bam_16_attention_spatial_variance": 42.784571540211175,
      "attention_bam_16_attention_spatial_std": 6.5409916327886535,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.923125371244717,
      "attention_bam_16_peak_intensity_mean": 0.28634098172187805,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 446,
      "phase": "train",
      "loss": 0.01085517555475235,
      "timestamp": 1759543955.992741,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.01085517555475235,
      "ssim": 0.8497087955474854,
      "attention_bam_384_mean_attention": 0.05827890709042549,
      "attention_bam_384_std_attention": 0.3429901599884033,
      "attention_bam_384_max_attention": 3.2518513202667236,
      "attention_bam_384_min_attention": -1.0958690643310547,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.2600647608914786,
      "attention_bam_384_attention_skewness": 0.9527097282098096,
      "attention_bam_384_attention_sparsity": 0.6041742960611979,
      "attention_bam_384_attention_concentration_10": 1.307176265697122,
      "attention_bam_384_attention_concentration_20": 1.966223231484375,
      "attention_bam_384_attention_center_y": 0.48341654561464653,
      "attention_bam_384_attention_center_x": 0.479555985193675,
      "attention_bam_384_attention_center_distance": 0.03722818020672876,
      "attention_bam_384_attention_spatial_variance": 170.74847360181326,
      "attention_bam_384_attention_spatial_std": 13.067075939238023,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 15.970664929804615,
      "attention_bam_384_peak_intensity_mean": 0.26730477809906006,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.15695703029632568,
      "attention_bam_16_std_attention": 0.5834233164787292,
      "attention_bam_16_max_attention": 3.2339589595794678,
      "attention_bam_16_min_attention": -1.173285722732544,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.268237856760999,
      "attention_bam_16_attention_skewness": 0.9571812765088853,
      "attention_bam_16_attention_sparsity": 0.5361328125,
      "attention_bam_16_attention_concentration_10": 0.8669498409086728,
      "attention_bam_16_attention_concentration_20": 1.3584877465419296,
      "attention_bam_16_attention_center_y": 0.4677560265178218,
      "attention_bam_16_attention_center_x": 0.45823427994234267,
      "attention_bam_16_attention_center_distance": 0.07461969174224739,
      "attention_bam_16_attention_spatial_variance": 42.615675203458835,
      "attention_bam_16_attention_spatial_std": 6.528068259711968,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.035846138407742,
      "attention_bam_16_peak_intensity_mean": 0.3013146221637726,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 447,
      "phase": "train",
      "loss": 0.004167267587035894,
      "timestamp": 1759543956.1375782,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004167267587035894,
      "ssim": 0.9373936057090759,
      "attention_bam_384_mean_attention": 0.05801255628466606,
      "attention_bam_384_std_attention": 0.3386349380016327,
      "attention_bam_384_max_attention": 2.3104615211486816,
      "attention_bam_384_min_attention": -1.1536246538162231,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.263089826973368,
      "attention_bam_384_attention_skewness": 0.7520818641597151,
      "attention_bam_384_attention_sparsity": 0.5935033162434896,
      "attention_bam_384_attention_concentration_10": 1.2759759646622206,
      "attention_bam_384_attention_concentration_20": 1.9511953881460382,
      "attention_bam_384_attention_center_y": 0.4875435537215072,
      "attention_bam_384_attention_center_x": 0.48006504883764956,
      "attention_bam_384_attention_center_distance": 0.03324350558332482,
      "attention_bam_384_attention_spatial_variance": 172.24639399126121,
      "attention_bam_384_attention_spatial_std": 13.124267369695774,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 20.420302741618023,
      "attention_bam_384_peak_intensity_mean": 0.3574860990047455,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1407589316368103,
      "attention_bam_16_std_attention": 0.5997606515884399,
      "attention_bam_16_max_attention": 2.5898513793945312,
      "attention_bam_16_min_attention": -1.1725016832351685,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.640169368046072,
      "attention_bam_16_attention_skewness": 0.8616896318301768,
      "attention_bam_16_attention_sparsity": 0.54248046875,
      "attention_bam_16_attention_concentration_10": 0.9850430417568736,
      "attention_bam_16_attention_concentration_20": 1.5381655129451366,
      "attention_bam_16_attention_center_y": 0.4776229666638497,
      "attention_bam_16_attention_center_x": 0.45723299427708175,
      "attention_bam_16_attention_center_distance": 0.06826050687522478,
      "attention_bam_16_attention_spatial_variance": 43.63365988071013,
      "attention_bam_16_attention_spatial_std": 6.6055779369189285,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.579740442272191,
      "attention_bam_16_peak_intensity_mean": 0.3741929531097412,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 448,
      "phase": "train",
      "loss": 0.010953711345791817,
      "timestamp": 1759543956.2811487,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.010953711345791817,
      "ssim": 0.8472774028778076,
      "attention_bam_384_mean_attention": 0.05848713591694832,
      "attention_bam_384_std_attention": 0.32468363642692566,
      "attention_bam_384_max_attention": 2.390763759613037,
      "attention_bam_384_min_attention": -1.1909619569778442,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5400591553519307,
      "attention_bam_384_attention_skewness": 0.7449525925972124,
      "attention_bam_384_attention_sparsity": 0.5938822428385416,
      "attention_bam_384_attention_concentration_10": 1.2096448955987666,
      "attention_bam_384_attention_concentration_20": 1.842661954768517,
      "attention_bam_384_attention_center_y": 0.47769528985000154,
      "attention_bam_384_attention_center_x": 0.47938551846993954,
      "attention_bam_384_attention_center_distance": 0.0429524607823265,
      "attention_bam_384_attention_spatial_variance": 170.37709839513857,
      "attention_bam_384_attention_spatial_std": 13.052857863132449,
      "attention_bam_384_num_attention_peaks": 18,
      "attention_bam_384_peak_separation_mean": 16.870769101612346,
      "attention_bam_384_peak_intensity_mean": 0.3578529953956604,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.15013636648654938,
      "attention_bam_16_std_attention": 0.5567853450775146,
      "attention_bam_16_max_attention": 3.203141212463379,
      "attention_bam_16_min_attention": -1.1594111919403076,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.729806775841654,
      "attention_bam_16_attention_skewness": 0.7476309849450192,
      "attention_bam_16_attention_sparsity": 0.5205078125,
      "attention_bam_16_attention_concentration_10": 0.8433143787241355,
      "attention_bam_16_attention_concentration_20": 1.3299442478013805,
      "attention_bam_16_attention_center_y": 0.44866713685654164,
      "attention_bam_16_attention_center_x": 0.45909865345126233,
      "attention_bam_16_attention_center_distance": 0.09282222781214595,
      "attention_bam_16_attention_spatial_variance": 42.25323062981148,
      "attention_bam_16_attention_spatial_std": 6.500248505235126,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 8.326150622116238,
      "attention_bam_16_peak_intensity_mean": 0.3158005177974701,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 449,
      "phase": "train",
      "loss": 0.005266267340630293,
      "timestamp": 1759543956.4243584,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005266267340630293,
      "ssim": 0.8993666172027588,
      "attention_bam_384_mean_attention": 0.05877775326371193,
      "attention_bam_384_std_attention": 0.32507646083831787,
      "attention_bam_384_max_attention": 2.455254077911377,
      "attention_bam_384_min_attention": -1.053301215171814,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1522512729550884,
      "attention_bam_384_attention_skewness": 0.7405155058989072,
      "attention_bam_384_attention_sparsity": 0.5897598266601562,
      "attention_bam_384_attention_concentration_10": 1.210479295053148,
      "attention_bam_384_attention_concentration_20": 1.8550428549388709,
      "attention_bam_384_attention_center_y": 0.4883116506029835,
      "attention_bam_384_attention_center_x": 0.48429706196146444,
      "attention_bam_384_attention_center_distance": 0.027683922217374597,
      "attention_bam_384_attention_spatial_variance": 173.09540188689516,
      "attention_bam_384_attention_spatial_std": 13.156572573694683,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 19.23213932739134,
      "attention_bam_384_peak_intensity_mean": 0.3219294548034668,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1515243649482727,
      "attention_bam_16_std_attention": 0.5829023122787476,
      "attention_bam_16_max_attention": 3.2827389240264893,
      "attention_bam_16_min_attention": -1.0296999216079712,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8385829548161099,
      "attention_bam_16_attention_skewness": 0.8154028956830908,
      "attention_bam_16_attention_sparsity": 0.517578125,
      "attention_bam_16_attention_concentration_10": 0.8754091505615677,
      "attention_bam_16_attention_concentration_20": 1.3746573283804635,
      "attention_bam_16_attention_center_y": 0.48142740406363155,
      "attention_bam_16_attention_center_x": 0.4711450166202012,
      "attention_bam_16_attention_center_distance": 0.048529401102096345,
      "attention_bam_16_attention_spatial_variance": 44.44917759887106,
      "attention_bam_16_attention_spatial_std": 6.667021643798005,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.203255499470966,
      "attention_bam_16_peak_intensity_mean": 0.2842797636985779,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 450,
      "phase": "train",
      "loss": 0.0053673069924116135,
      "timestamp": 1759543956.615601,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0053673069924116135,
      "ssim": 0.902483344078064,
      "attention_bam_384_mean_attention": 0.05782608315348625,
      "attention_bam_384_std_attention": 0.3396759629249573,
      "attention_bam_384_max_attention": 2.525181770324707,
      "attention_bam_384_min_attention": -1.1799049377441406,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.521121955932129,
      "attention_bam_384_attention_skewness": 0.8147687626417923,
      "attention_bam_384_attention_sparsity": 0.5972391764322916,
      "attention_bam_384_attention_concentration_10": 1.2812751461779732,
      "attention_bam_384_attention_concentration_20": 1.958170158756348,
      "attention_bam_384_attention_center_y": 0.47970046736850935,
      "attention_bam_384_attention_center_x": 0.48206103552159113,
      "attention_bam_384_attention_center_distance": 0.038311290023035474,
      "attention_bam_384_attention_spatial_variance": 171.27473234704502,
      "attention_bam_384_attention_spatial_std": 13.087197268592119,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 17.25527018991034,
      "attention_bam_384_peak_intensity_mean": 0.3375298082828522,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.15923155844211578,
      "attention_bam_16_std_attention": 0.5869020819664001,
      "attention_bam_16_max_attention": 3.331031560897827,
      "attention_bam_16_min_attention": -1.1032367944717407,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8519362913639821,
      "attention_bam_16_attention_skewness": 0.8911154373945412,
      "attention_bam_16_attention_sparsity": 0.530517578125,
      "attention_bam_16_attention_concentration_10": 0.8600985284238137,
      "attention_bam_16_attention_concentration_20": 1.3503703823419884,
      "attention_bam_16_attention_center_y": 0.45580756272354955,
      "attention_bam_16_attention_center_x": 0.4653122539526952,
      "attention_bam_16_attention_center_distance": 0.07945075504078379,
      "attention_bam_16_attention_spatial_variance": 43.05642986773266,
      "attention_bam_16_attention_spatial_std": 6.561739850659477,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.311524699077166,
      "attention_bam_16_peak_intensity_mean": 0.29282647371292114,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 451,
      "phase": "train",
      "loss": 0.004225119017064571,
      "timestamp": 1759543956.7589648,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004225119017064571,
      "ssim": 0.9224132299423218,
      "attention_bam_384_mean_attention": 0.05928528681397438,
      "attention_bam_384_std_attention": 0.299724817276001,
      "attention_bam_384_max_attention": 2.560213804244995,
      "attention_bam_384_min_attention": -1.267270565032959,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.2773257094774157,
      "attention_bam_384_attention_skewness": 0.8728867640115313,
      "attention_bam_384_attention_sparsity": 0.6079330444335938,
      "attention_bam_384_attention_concentration_10": 1.1275520800819245,
      "attention_bam_384_attention_concentration_20": 1.7042421876203604,
      "attention_bam_384_attention_center_y": 0.48199911105008536,
      "attention_bam_384_attention_center_x": 0.4887246370256939,
      "attention_bam_384_attention_center_distance": 0.030038835303304014,
      "attention_bam_384_attention_spatial_variance": 173.10988319868605,
      "attention_bam_384_attention_spatial_std": 13.157122907333733,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 20.75040285608896,
      "attention_bam_384_peak_intensity_mean": 0.3566970229148865,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16134385764598846,
      "attention_bam_16_std_attention": 0.5623513460159302,
      "attention_bam_16_max_attention": 2.9652585983276367,
      "attention_bam_16_min_attention": -1.051029920578003,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.4127724250410418,
      "attention_bam_16_attention_skewness": 0.9826315947485612,
      "attention_bam_16_attention_sparsity": 0.515625,
      "attention_bam_16_attention_concentration_10": 0.8329960010413683,
      "attention_bam_16_attention_concentration_20": 1.277960597538589,
      "attention_bam_16_attention_center_y": 0.463611760560643,
      "attention_bam_16_attention_center_x": 0.48560427804412515,
      "attention_bam_16_attention_center_distance": 0.05534149943987481,
      "attention_bam_16_attention_spatial_variance": 44.789123045677414,
      "attention_bam_16_attention_spatial_std": 6.692467635011575,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 10.352536443990715,
      "attention_bam_16_peak_intensity_mean": 0.3153650760650635,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 452,
      "phase": "train",
      "loss": 0.004149894695729017,
      "timestamp": 1759543956.9109848,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004149894695729017,
      "ssim": 0.9039568901062012,
      "attention_bam_384_mean_attention": 0.05593940615653992,
      "attention_bam_384_std_attention": 0.3375648856163025,
      "attention_bam_384_max_attention": 2.3357906341552734,
      "attention_bam_384_min_attention": -1.0766644477844238,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.734456797722145,
      "attention_bam_384_attention_skewness": 0.9622614699671487,
      "attention_bam_384_attention_sparsity": 0.6047159830729166,
      "attention_bam_384_attention_concentration_10": 1.3416816949600945,
      "attention_bam_384_attention_concentration_20": 2.023461364630334,
      "attention_bam_384_attention_center_y": 0.47935009018221836,
      "attention_bam_384_attention_center_x": 0.474370497172889,
      "attention_bam_384_attention_center_distance": 0.046546539949762246,
      "attention_bam_384_attention_spatial_variance": 172.41836750130597,
      "attention_bam_384_attention_spatial_std": 13.130817472697805,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 18.8158303078404,
      "attention_bam_384_peak_intensity_mean": 0.3434548079967499,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14858999848365784,
      "attention_bam_16_std_attention": 0.5930951833724976,
      "attention_bam_16_max_attention": 2.7516279220581055,
      "attention_bam_16_min_attention": -0.972067654132843,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8793626875847331,
      "attention_bam_16_attention_skewness": 0.90855999478477,
      "attention_bam_16_attention_sparsity": 0.521240234375,
      "attention_bam_16_attention_concentration_10": 0.9234570293035816,
      "attention_bam_16_attention_concentration_20": 1.4284197708763142,
      "attention_bam_16_attention_center_y": 0.45314066041180845,
      "attention_bam_16_attention_center_x": 0.44028910428153617,
      "attention_bam_16_attention_center_distance": 0.10734233809772095,
      "attention_bam_16_attention_spatial_variance": 43.635239972328364,
      "attention_bam_16_attention_spatial_std": 6.605697538665267,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.460407706034847,
      "attention_bam_16_peak_intensity_mean": 0.32311514019966125,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 453,
      "phase": "train",
      "loss": 0.0064625926315784454,
      "timestamp": 1759543957.2536926,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0064625926315784454,
      "ssim": 0.9138895273208618,
      "attention_bam_384_mean_attention": 0.05918775871396065,
      "attention_bam_384_std_attention": 0.2817324697971344,
      "attention_bam_384_max_attention": 2.4278316497802734,
      "attention_bam_384_min_attention": -0.9433819055557251,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4934896437246188,
      "attention_bam_384_attention_skewness": 0.7281980541222236,
      "attention_bam_384_attention_sparsity": 0.5967864990234375,
      "attention_bam_384_attention_concentration_10": 1.04621188025873,
      "attention_bam_384_attention_concentration_20": 1.6087221709835342,
      "attention_bam_384_attention_center_y": 0.4851781776259286,
      "attention_bam_384_attention_center_x": 0.47822256406254615,
      "attention_bam_384_attention_center_distance": 0.03725434563909104,
      "attention_bam_384_attention_spatial_variance": 173.91708262055673,
      "attention_bam_384_attention_spatial_std": 13.187762608591221,
      "attention_bam_384_num_attention_peaks": 19,
      "attention_bam_384_peak_separation_mean": 17.303590779771984,
      "attention_bam_384_peak_intensity_mean": 0.3019888401031494,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.16506652534008026,
      "attention_bam_16_std_attention": 0.5148159861564636,
      "attention_bam_16_max_attention": 2.5456838607788086,
      "attention_bam_16_min_attention": -1.0039129257202148,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6817052037446172,
      "attention_bam_16_attention_skewness": 0.6977413406226572,
      "attention_bam_16_attention_sparsity": 0.493408203125,
      "attention_bam_16_attention_concentration_10": 0.7169202739844316,
      "attention_bam_16_attention_concentration_20": 1.1406486361691317,
      "attention_bam_16_attention_center_y": 0.4707092348480955,
      "attention_bam_16_attention_center_x": 0.4526865858224552,
      "attention_bam_16_attention_center_distance": 0.07869571887110403,
      "attention_bam_16_attention_spatial_variance": 44.71035150750518,
      "attention_bam_16_attention_spatial_std": 6.686579955964422,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.750414881218676,
      "attention_bam_16_peak_intensity_mean": 0.339428573846817,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 454,
      "phase": "train",
      "loss": 0.006745694205164909,
      "timestamp": 1759543957.3961,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006745694205164909,
      "ssim": 0.9097203016281128,
      "attention_bam_384_mean_attention": 0.057141128927469254,
      "attention_bam_384_std_attention": 0.3230379521846771,
      "attention_bam_384_max_attention": 2.7551803588867188,
      "attention_bam_384_min_attention": -1.0678160190582275,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5374857511014532,
      "attention_bam_384_attention_skewness": 0.735053797564498,
      "attention_bam_384_attention_sparsity": 0.5896708170572916,
      "attention_bam_384_attention_concentration_10": 1.215467902592542,
      "attention_bam_384_attention_concentration_20": 1.8745279588560149,
      "attention_bam_384_attention_center_y": 0.47290324752219387,
      "attention_bam_384_attention_center_x": 0.48308800922528433,
      "attention_bam_384_attention_center_distance": 0.045171881227320174,
      "attention_bam_384_attention_spatial_variance": 172.87409937949246,
      "attention_bam_384_attention_spatial_std": 13.148159543430117,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 17.220700395044577,
      "attention_bam_384_peak_intensity_mean": 0.3000456690788269,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13913288712501526,
      "attention_bam_16_std_attention": 0.5721079707145691,
      "attention_bam_16_max_attention": 3.1491079330444336,
      "attention_bam_16_min_attention": -1.1219813823699951,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.9801538173051059,
      "attention_bam_16_attention_skewness": 0.8354203099893169,
      "attention_bam_16_attention_sparsity": 0.534912109375,
      "attention_bam_16_attention_concentration_10": 0.9238652465016931,
      "attention_bam_16_attention_concentration_20": 1.4576715343455562,
      "attention_bam_16_attention_center_y": 0.433944301204092,
      "attention_bam_16_attention_center_x": 0.4665411090603093,
      "attention_bam_16_attention_center_distance": 0.10471726434862437,
      "attention_bam_16_attention_spatial_variance": 43.840782073091894,
      "attention_bam_16_attention_spatial_std": 6.621237201089529,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 11.528341199128905,
      "attention_bam_16_peak_intensity_mean": 0.3171989917755127,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 455,
      "phase": "train",
      "loss": 0.00526857003569603,
      "timestamp": 1759543957.5436072,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00526857003569603,
      "ssim": 0.9166664481163025,
      "attention_bam_384_mean_attention": 0.05469471588730812,
      "attention_bam_384_std_attention": 0.341208815574646,
      "attention_bam_384_max_attention": 2.4868898391723633,
      "attention_bam_384_min_attention": -1.0822267532348633,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5830241604269264,
      "attention_bam_384_attention_skewness": 0.6143296041876514,
      "attention_bam_384_attention_sparsity": 0.5887807210286459,
      "attention_bam_384_attention_concentration_10": 1.317817253069609,
      "attention_bam_384_attention_concentration_20": 2.070221670959245,
      "attention_bam_384_attention_center_y": 0.47882318042256106,
      "attention_bam_384_attention_center_x": 0.4839574857958309,
      "attention_bam_384_attention_center_distance": 0.037571796587503446,
      "attention_bam_384_attention_spatial_variance": 171.92729423988783,
      "attention_bam_384_attention_spatial_std": 13.112104874500044,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 20.890103439206126,
      "attention_bam_384_peak_intensity_mean": 0.32268720865249634,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13980397582054138,
      "attention_bam_16_std_attention": 0.6002817749977112,
      "attention_bam_16_max_attention": 2.756068229675293,
      "attention_bam_16_min_attention": -1.1431832313537598,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.2901177826937018,
      "attention_bam_16_attention_skewness": 0.7593778235221137,
      "attention_bam_16_attention_sparsity": 0.548828125,
      "attention_bam_16_attention_concentration_10": 0.9644897733661766,
      "attention_bam_16_attention_concentration_20": 1.5480058485657,
      "attention_bam_16_attention_center_y": 0.4523634972237748,
      "attention_bam_16_attention_center_x": 0.46977583114568033,
      "attention_bam_16_attention_center_distance": 0.07978391792440052,
      "attention_bam_16_attention_spatial_variance": 43.49176309814707,
      "attention_bam_16_attention_spatial_std": 6.59482851165571,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 11.018334694169125,
      "attention_bam_16_peak_intensity_mean": 0.33699220418930054,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 456,
      "phase": "train",
      "loss": 0.0059547629207372665,
      "timestamp": 1759543957.6906862,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0059547629207372665,
      "ssim": 0.9290745258331299,
      "attention_bam_384_mean_attention": 0.05439576134085655,
      "attention_bam_384_std_attention": 0.31664738059043884,
      "attention_bam_384_max_attention": 2.105628252029419,
      "attention_bam_384_min_attention": -0.945726215839386,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9378067920641895,
      "attention_bam_384_attention_skewness": 0.7234232004567249,
      "attention_bam_384_attention_sparsity": 0.5963694254557291,
      "attention_bam_384_attention_concentration_10": 1.2660357712352406,
      "attention_bam_384_attention_concentration_20": 1.9442023070649195,
      "attention_bam_384_attention_center_y": 0.4887783767596095,
      "attention_bam_384_attention_center_x": 0.4838130070497432,
      "attention_bam_384_attention_center_distance": 0.027854750723025134,
      "attention_bam_384_attention_spatial_variance": 172.01785510155017,
      "attention_bam_384_attention_spatial_std": 13.115557750303651,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 18.876486916312647,
      "attention_bam_384_peak_intensity_mean": 0.3332849442958832,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1401386559009552,
      "attention_bam_16_std_attention": 0.5556948184967041,
      "attention_bam_16_max_attention": 2.4413909912109375,
      "attention_bam_16_min_attention": -0.9748512506484985,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.4619266041295318,
      "attention_bam_16_attention_skewness": 0.8171697664163687,
      "attention_bam_16_attention_sparsity": 0.5341796875,
      "attention_bam_16_attention_concentration_10": 0.9166604108108796,
      "attention_bam_16_attention_concentration_20": 1.442717915331971,
      "attention_bam_16_attention_center_y": 0.48356782204672294,
      "attention_bam_16_attention_center_x": 0.4711861897173656,
      "attention_bam_16_attention_center_distance": 0.046909532832715636,
      "attention_bam_16_attention_spatial_variance": 43.54637617264947,
      "attention_bam_16_attention_spatial_std": 6.598967811154216,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.951578476188695,
      "attention_bam_16_peak_intensity_mean": 0.34079957008361816,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 457,
      "phase": "train",
      "loss": 0.0055493442341685295,
      "timestamp": 1759543957.8345485,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0055493442341685295,
      "ssim": 0.8913739323616028,
      "attention_bam_384_mean_attention": 0.05313417315483093,
      "attention_bam_384_std_attention": 0.32364991307258606,
      "attention_bam_384_max_attention": 2.7272379398345947,
      "attention_bam_384_min_attention": -1.1861207485198975,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.8164632774329696,
      "attention_bam_384_attention_skewness": 1.109927342141368,
      "attention_bam_384_attention_sparsity": 0.6164016723632812,
      "attention_bam_384_attention_concentration_10": 1.3554561599616295,
      "attention_bam_384_attention_concentration_20": 2.0361963489543995,
      "attention_bam_384_attention_center_y": 0.4793002342502705,
      "attention_bam_384_attention_center_x": 0.47403278800467424,
      "attention_bam_384_attention_center_distance": 0.04696331336061933,
      "attention_bam_384_attention_spatial_variance": 172.7242008796443,
      "attention_bam_384_attention_spatial_std": 13.142457946656869,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 19.504946901076842,
      "attention_bam_384_peak_intensity_mean": 0.3190421760082245,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1284717172384262,
      "attention_bam_16_std_attention": 0.5801355242729187,
      "attention_bam_16_max_attention": 2.8961615562438965,
      "attention_bam_16_min_attention": -1.016916036605835,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.5556557100044337,
      "attention_bam_16_attention_skewness": 1.1322110678814996,
      "attention_bam_16_attention_sparsity": 0.564453125,
      "attention_bam_16_attention_concentration_10": 1.0625834605035087,
      "attention_bam_16_attention_concentration_20": 1.6292100842794641,
      "attention_bam_16_attention_center_y": 0.45160782164696084,
      "attention_bam_16_attention_center_x": 0.43752219118135316,
      "attention_bam_16_attention_center_distance": 0.11176116964788563,
      "attention_bam_16_attention_spatial_variance": 43.871002163910354,
      "attention_bam_16_attention_spatial_std": 6.623518865671808,
      "attention_bam_16_num_attention_peaks": 2,
      "attention_bam_16_peak_separation_mean": 13.737150533058372,
      "attention_bam_16_peak_intensity_mean": 0.29109886288642883,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 458,
      "phase": "train",
      "loss": 0.0062239645048975945,
      "timestamp": 1759543957.9817858,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0062239645048975945,
      "ssim": 0.9015982151031494,
      "attention_bam_384_mean_attention": 0.054681167006492615,
      "attention_bam_384_std_attention": 0.33223390579223633,
      "attention_bam_384_max_attention": 2.3370957374572754,
      "attention_bam_384_min_attention": -1.0784344673156738,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9506822890229714,
      "attention_bam_384_attention_skewness": 0.6652455872549203,
      "attention_bam_384_attention_sparsity": 0.5925369262695312,
      "attention_bam_384_attention_concentration_10": 1.3091633372759433,
      "attention_bam_384_attention_concentration_20": 2.01779798711352,
      "attention_bam_384_attention_center_y": 0.48502133357155414,
      "attention_bam_384_attention_center_x": 0.4768179036897633,
      "attention_bam_384_attention_center_distance": 0.039032551474679225,
      "attention_bam_384_attention_spatial_variance": 171.11057477584006,
      "attention_bam_384_attention_spatial_std": 13.080924079583983,
      "attention_bam_384_num_attention_peaks": 20,
      "attention_bam_384_peak_separation_mean": 17.97474948764002,
      "attention_bam_384_peak_intensity_mean": 0.3340100646018982,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14087897539138794,
      "attention_bam_16_std_attention": 0.5887486338615417,
      "attention_bam_16_max_attention": 3.3113369941711426,
      "attention_bam_16_min_attention": -1.1282380819320679,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.0000147907744417,
      "attention_bam_16_attention_skewness": 0.8882000439788207,
      "attention_bam_16_attention_sparsity": 0.53564453125,
      "attention_bam_16_attention_concentration_10": 0.9554108489707954,
      "attention_bam_16_attention_concentration_20": 1.4941871509503677,
      "attention_bam_16_attention_center_y": 0.4718646214731435,
      "attention_bam_16_attention_center_x": 0.4483897180832062,
      "attention_bam_16_attention_center_distance": 0.08312906500593434,
      "attention_bam_16_attention_spatial_variance": 42.686259262775124,
      "attention_bam_16_attention_spatial_std": 6.533472221015034,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.108990857292879,
      "attention_bam_16_peak_intensity_mean": 0.2870001792907715,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 459,
      "phase": "train",
      "loss": 0.007619913201779127,
      "timestamp": 1759543958.125158,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007619913201779127,
      "ssim": 0.8945345282554626,
      "attention_bam_384_mean_attention": 0.051493510603904724,
      "attention_bam_384_std_attention": 0.33969244360923767,
      "attention_bam_384_max_attention": 2.77506160736084,
      "attention_bam_384_min_attention": -1.2097551822662354,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.119305838040841,
      "attention_bam_384_attention_skewness": 0.9269161860999853,
      "attention_bam_384_attention_sparsity": 0.6119766235351562,
      "attention_bam_384_attention_concentration_10": 1.4699285126769372,
      "attention_bam_384_attention_concentration_20": 2.1715880938886523,
      "attention_bam_384_attention_center_y": 0.49005027992208783,
      "attention_bam_384_attention_center_x": 0.48427990493394146,
      "attention_bam_384_attention_center_distance": 0.0263103902865285,
      "attention_bam_384_attention_spatial_variance": 171.22751672982994,
      "attention_bam_384_attention_spatial_std": 13.08539325850889,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 16.770416007053065,
      "attention_bam_384_peak_intensity_mean": 0.3209707736968994,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12494631856679916,
      "attention_bam_16_std_attention": 0.5989223122596741,
      "attention_bam_16_max_attention": 2.959074020385742,
      "attention_bam_16_min_attention": -1.1868391036987305,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.673418568060569,
      "attention_bam_16_attention_skewness": 1.1231493474066812,
      "attention_bam_16_attention_sparsity": 0.561767578125,
      "attention_bam_16_attention_concentration_10": 1.138977905239703,
      "attention_bam_16_attention_concentration_20": 1.6990217835541828,
      "attention_bam_16_attention_center_y": 0.48671904885705414,
      "attention_bam_16_attention_center_x": 0.4716636541616269,
      "attention_bam_16_attention_center_distance": 0.044256799674924484,
      "attention_bam_16_attention_spatial_variance": 43.011302644469815,
      "attention_bam_16_attention_spatial_std": 6.558300286238029,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.439884559286662,
      "attention_bam_16_peak_intensity_mean": 0.3299803137779236,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 460,
      "phase": "train",
      "loss": 0.007361633237451315,
      "timestamp": 1759543958.3190274,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007361633237451315,
      "ssim": 0.9081522822380066,
      "attention_bam_384_mean_attention": 0.05068619176745415,
      "attention_bam_384_std_attention": 0.30920955538749695,
      "attention_bam_384_max_attention": 2.2204084396362305,
      "attention_bam_384_min_attention": -0.8494389653205872,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0019860790243138,
      "attention_bam_384_attention_skewness": 0.7656061750292623,
      "attention_bam_384_attention_sparsity": 0.6039708455403646,
      "attention_bam_384_attention_concentration_10": 1.3236121436092294,
      "attention_bam_384_attention_concentration_20": 2.0345865805178454,
      "attention_bam_384_attention_center_y": 0.4753478929757557,
      "attention_bam_384_attention_center_x": 0.489727905167336,
      "attention_bam_384_attention_center_distance": 0.03776883140861093,
      "attention_bam_384_attention_spatial_variance": 171.5492428006529,
      "attention_bam_384_attention_spatial_std": 13.097680817635347,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 16.361294025456683,
      "attention_bam_384_peak_intensity_mean": 0.29175204038619995,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1216110959649086,
      "attention_bam_16_std_attention": 0.5491563677787781,
      "attention_bam_16_max_attention": 2.559231758117676,
      "attention_bam_16_min_attention": -0.9489808082580566,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5403610223691304,
      "attention_bam_16_attention_skewness": 0.8340213440623251,
      "attention_bam_16_attention_sparsity": 0.5537109375,
      "attention_bam_16_attention_concentration_10": 1.0252437070034917,
      "attention_bam_16_attention_concentration_20": 1.6039072768850857,
      "attention_bam_16_attention_center_y": 0.44519152171315524,
      "attention_bam_16_attention_center_x": 0.48620375090168094,
      "attention_bam_16_attention_center_distance": 0.07992879057389024,
      "attention_bam_16_attention_spatial_variance": 42.96600867009572,
      "attention_bam_16_attention_spatial_std": 6.554846197287601,
      "attention_bam_16_num_attention_peaks": 2,
      "attention_bam_16_peak_separation_mean": 14.321605706856886,
      "attention_bam_16_peak_intensity_mean": 0.3135037422180176,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 461,
      "phase": "train",
      "loss": 0.006953877862542868,
      "timestamp": 1759543958.4831977,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006953877862542868,
      "ssim": 0.8789128661155701,
      "attention_bam_384_mean_attention": 0.05235092714428902,
      "attention_bam_384_std_attention": 0.35771140456199646,
      "attention_bam_384_max_attention": 3.661684036254883,
      "attention_bam_384_min_attention": -1.1354774236679077,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.1189001513102035,
      "attention_bam_384_attention_skewness": 0.967510105040116,
      "attention_bam_384_attention_sparsity": 0.5958201090494791,
      "attention_bam_384_attention_concentration_10": 1.4434818135043976,
      "attention_bam_384_attention_concentration_20": 2.1962815786571674,
      "attention_bam_384_attention_center_y": 0.489950137569636,
      "attention_bam_384_attention_center_x": 0.481531749153246,
      "attention_bam_384_attention_center_distance": 0.029734694355512452,
      "attention_bam_384_attention_spatial_variance": 170.75909207408657,
      "attention_bam_384_attention_spatial_std": 13.067482239287205,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 18.497504120799608,
      "attention_bam_384_peak_intensity_mean": 0.2515456974506378,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1319466084241867,
      "attention_bam_16_std_attention": 0.6341924071311951,
      "attention_bam_16_max_attention": 3.586122989654541,
      "attention_bam_16_min_attention": -1.1601109504699707,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.2130392726725736,
      "attention_bam_16_attention_skewness": 1.1703496993540161,
      "attention_bam_16_attention_sparsity": 0.550537109375,
      "attention_bam_16_attention_concentration_10": 1.1068449190046756,
      "attention_bam_16_attention_concentration_20": 1.6914385405005083,
      "attention_bam_16_attention_center_y": 0.4849074938817721,
      "attention_bam_16_attention_center_x": 0.46267961252342066,
      "attention_bam_16_attention_center_distance": 0.05693145110272117,
      "attention_bam_16_attention_spatial_variance": 42.75859040204959,
      "attention_bam_16_attention_spatial_std": 6.5390053067763745,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.110359770313645,
      "attention_bam_16_peak_intensity_mean": 0.2912265658378601,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 462,
      "phase": "train",
      "loss": 0.006473510526120663,
      "timestamp": 1759543958.634886,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006473510526120663,
      "ssim": 0.8853350877761841,
      "attention_bam_384_mean_attention": 0.05073842778801918,
      "attention_bam_384_std_attention": 0.3206842541694641,
      "attention_bam_384_max_attention": 3.1657538414001465,
      "attention_bam_384_min_attention": -1.1163897514343262,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.658467513083913,
      "attention_bam_384_attention_skewness": 1.0830180033614492,
      "attention_bam_384_attention_sparsity": 0.6077448527018229,
      "attention_bam_384_attention_concentration_10": 1.3591305722609792,
      "attention_bam_384_attention_concentration_20": 2.0466226366228786,
      "attention_bam_384_attention_center_y": 0.4801230896324388,
      "attention_bam_384_attention_center_x": 0.483514979876597,
      "attention_bam_384_attention_center_distance": 0.036519787902699094,
      "attention_bam_384_attention_spatial_variance": 171.02094342576407,
      "attention_bam_384_attention_spatial_std": 13.077497598002612,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 18.554505170665557,
      "attention_bam_384_peak_intensity_mean": 0.2773085832595825,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13181956112384796,
      "attention_bam_16_std_attention": 0.5770149230957031,
      "attention_bam_16_max_attention": 4.3304853439331055,
      "attention_bam_16_min_attention": -1.101331114768982,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.542622972656777,
      "attention_bam_16_attention_skewness": 1.3729734485358058,
      "attention_bam_16_attention_sparsity": 0.55029296875,
      "attention_bam_16_attention_concentration_10": 1.0249810626017102,
      "attention_bam_16_attention_concentration_20": 1.5312012611598422,
      "attention_bam_16_attention_center_y": 0.45596915463333276,
      "attention_bam_16_attention_center_x": 0.4688540782197608,
      "attention_bam_16_attention_center_distance": 0.07627298063199237,
      "attention_bam_16_attention_spatial_variance": 42.881003060401056,
      "attention_bam_16_attention_spatial_std": 6.548358806632472,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.90831770381161,
      "attention_bam_16_peak_intensity_mean": 0.23286406695842743,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 463,
      "phase": "train",
      "loss": 0.007813138887286186,
      "timestamp": 1759543958.7842867,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007813138887286186,
      "ssim": 0.910586953163147,
      "attention_bam_384_mean_attention": 0.05384102463722229,
      "attention_bam_384_std_attention": 0.3288491368293762,
      "attention_bam_384_max_attention": 2.2838737964630127,
      "attention_bam_384_min_attention": -1.0144598484039307,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.4342429116656472,
      "attention_bam_384_attention_skewness": 0.4795201128334109,
      "attention_bam_384_attention_sparsity": 0.5841903686523438,
      "attention_bam_384_attention_concentration_10": 1.2746978448520359,
      "attention_bam_384_attention_concentration_20": 2.0101132603225116,
      "attention_bam_384_attention_center_y": 0.4824765163531094,
      "attention_bam_384_attention_center_x": 0.48540164274518705,
      "attention_bam_384_attention_center_distance": 0.03225475201150963,
      "attention_bam_384_attention_spatial_variance": 171.34587942867947,
      "attention_bam_384_attention_spatial_std": 13.089915180347024,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 18.860749305386843,
      "attention_bam_384_peak_intensity_mean": 0.3255505859851837,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1507723331451416,
      "attention_bam_16_std_attention": 0.5819479823112488,
      "attention_bam_16_max_attention": 2.9691171646118164,
      "attention_bam_16_min_attention": -1.0386970043182373,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.3127320861262479,
      "attention_bam_16_attention_skewness": 0.6338213095285361,
      "attention_bam_16_attention_sparsity": 0.5087890625,
      "attention_bam_16_attention_concentration_10": 0.8610931236369971,
      "attention_bam_16_attention_concentration_20": 1.3772804541314179,
      "attention_bam_16_attention_center_y": 0.4649435047018817,
      "attention_bam_16_attention_center_x": 0.47319421377353893,
      "attention_bam_16_attention_center_distance": 0.06241006389687032,
      "attention_bam_16_attention_spatial_variance": 43.25537900077222,
      "attention_bam_16_attention_spatial_std": 6.576882164123988,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 10.404060398211712,
      "attention_bam_16_peak_intensity_mean": 0.30359938740730286,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 464,
      "phase": "train",
      "loss": 0.0063598016276955605,
      "timestamp": 1759543958.9305115,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0063598016276955605,
      "ssim": 0.8819195032119751,
      "attention_bam_384_mean_attention": 0.05262066051363945,
      "attention_bam_384_std_attention": 0.3386845290660858,
      "attention_bam_384_max_attention": 2.861067056655884,
      "attention_bam_384_min_attention": -1.053943157196045,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2306794818258915,
      "attention_bam_384_attention_skewness": 0.64662582763453,
      "attention_bam_384_attention_sparsity": 0.5852381388346354,
      "attention_bam_384_attention_concentration_10": 1.347615589216503,
      "attention_bam_384_attention_concentration_20": 2.0875340218141085,
      "attention_bam_384_attention_center_y": 0.48422582092062894,
      "attention_bam_384_attention_center_x": 0.48123531764319477,
      "attention_bam_384_attention_center_distance": 0.03466808415761866,
      "attention_bam_384_attention_spatial_variance": 170.62973700830287,
      "attention_bam_384_attention_spatial_std": 13.06253179932217,
      "attention_bam_384_num_attention_peaks": 18,
      "attention_bam_384_peak_separation_mean": 17.55262911211348,
      "attention_bam_384_peak_intensity_mean": 0.286695659160614,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13914954662322998,
      "attention_bam_16_std_attention": 0.5873274207115173,
      "attention_bam_16_max_attention": 3.0149550437927246,
      "attention_bam_16_min_attention": -1.0777244567871094,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6803841113188049,
      "attention_bam_16_attention_skewness": 0.7301078514781928,
      "attention_bam_16_attention_sparsity": 0.523193359375,
      "attention_bam_16_attention_concentration_10": 0.9332636765420256,
      "attention_bam_16_attention_concentration_20": 1.4783332233643462,
      "attention_bam_16_attention_center_y": 0.470213481569458,
      "attention_bam_16_attention_center_x": 0.4604105928065427,
      "attention_bam_16_attention_center_distance": 0.07006508177605143,
      "attention_bam_16_attention_spatial_variance": 42.54433634163145,
      "attention_bam_16_attention_spatial_std": 6.522601960999264,
      "attention_bam_16_num_attention_peaks": 11,
      "attention_bam_16_peak_separation_mean": 8.656927714838021,
      "attention_bam_16_peak_intensity_mean": 0.30673086643218994,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 465,
      "phase": "train",
      "loss": 0.008001413196325302,
      "timestamp": 1759543959.0770252,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008001413196325302,
      "ssim": 0.86655592918396,
      "attention_bam_384_mean_attention": 0.052068550139665604,
      "attention_bam_384_std_attention": 0.2833804786205292,
      "attention_bam_384_max_attention": 2.2446978092193604,
      "attention_bam_384_min_attention": -0.9873331189155579,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4835010947598084,
      "attention_bam_384_attention_skewness": 0.7304038366614194,
      "attention_bam_384_attention_sparsity": 0.6102116902669271,
      "attention_bam_384_attention_concentration_10": 1.1840553997863486,
      "attention_bam_384_attention_concentration_20": 1.8155205716335188,
      "attention_bam_384_attention_center_y": 0.4803769873054076,
      "attention_bam_384_attention_center_x": 0.48397303113783624,
      "attention_bam_384_attention_center_distance": 0.03583089053096226,
      "attention_bam_384_attention_spatial_variance": 171.1939322155861,
      "attention_bam_384_attention_spatial_std": 13.084109913004633,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 18.410411491532795,
      "attention_bam_384_peak_intensity_mean": 0.3224859833717346,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14375023543834686,
      "attention_bam_16_std_attention": 0.518943190574646,
      "attention_bam_16_max_attention": 2.99330472946167,
      "attention_bam_16_min_attention": -1.0258355140686035,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.2961633797601158,
      "attention_bam_16_attention_skewness": 0.8659249034686096,
      "attention_bam_16_attention_sparsity": 0.51806640625,
      "attention_bam_16_attention_concentration_10": 0.8337874854151189,
      "attention_bam_16_attention_concentration_20": 1.3010009935597902,
      "attention_bam_16_attention_center_y": 0.45679592977918715,
      "attention_bam_16_attention_center_x": 0.4695693514041,
      "attention_bam_16_attention_center_distance": 0.07473441051633549,
      "attention_bam_16_attention_spatial_variance": 42.8173896289053,
      "attention_bam_16_attention_spatial_std": 6.5434997997176785,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 10.385505383462926,
      "attention_bam_16_peak_intensity_mean": 0.29646533727645874,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 466,
      "phase": "train",
      "loss": 0.007906345650553703,
      "timestamp": 1759543959.2182431,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007906345650553703,
      "ssim": 0.8595348000526428,
      "attention_bam_384_mean_attention": 0.051328953355550766,
      "attention_bam_384_std_attention": 0.34467077255249023,
      "attention_bam_384_max_attention": 2.4830169677734375,
      "attention_bam_384_min_attention": -1.0032621622085571,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8081190818720452,
      "attention_bam_384_attention_skewness": 0.6984357238473681,
      "attention_bam_384_attention_sparsity": 0.5944569905598959,
      "attention_bam_384_attention_concentration_10": 1.4390236467736892,
      "attention_bam_384_attention_concentration_20": 2.219033832683091,
      "attention_bam_384_attention_center_y": 0.48791812818704083,
      "attention_bam_384_attention_center_x": 0.4860099000945722,
      "attention_bam_384_attention_center_distance": 0.02614171080356558,
      "attention_bam_384_attention_spatial_variance": 168.51701897704382,
      "attention_bam_384_attention_spatial_std": 12.981410515696814,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 19.20013950037191,
      "attention_bam_384_peak_intensity_mean": 0.3061991333961487,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.134344220161438,
      "attention_bam_16_std_attention": 0.6024022102355957,
      "attention_bam_16_max_attention": 3.4060001373291016,
      "attention_bam_16_min_attention": -1.0448594093322754,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6114174542588966,
      "attention_bam_16_attention_skewness": 0.8277182233080991,
      "attention_bam_16_attention_sparsity": 0.541748046875,
      "attention_bam_16_attention_concentration_10": 1.0190686500944837,
      "attention_bam_16_attention_concentration_20": 1.6098185739941586,
      "attention_bam_16_attention_center_y": 0.478613390146435,
      "attention_bam_16_attention_center_x": 0.4768781979417437,
      "attention_bam_16_attention_center_distance": 0.04454222292274577,
      "attention_bam_16_attention_spatial_variance": 41.006026404417455,
      "attention_bam_16_attention_spatial_std": 6.4035948032661665,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 7.687420534970583,
      "attention_bam_16_peak_intensity_mean": 0.2783466577529907,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 467,
      "phase": "train",
      "loss": 0.007155653089284897,
      "timestamp": 1759543959.3574748,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007155653089284897,
      "ssim": 0.8569502234458923,
      "attention_bam_384_mean_attention": 0.050457119941711426,
      "attention_bam_384_std_attention": 0.30525919795036316,
      "attention_bam_384_max_attention": 2.954801559448242,
      "attention_bam_384_min_attention": -0.9057026505470276,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8115308972622772,
      "attention_bam_384_attention_skewness": 0.8488140420252345,
      "attention_bam_384_attention_sparsity": 0.6114349365234375,
      "attention_bam_384_attention_concentration_10": 1.3256172256144902,
      "attention_bam_384_attention_concentration_20": 2.0125933713699546,
      "attention_bam_384_attention_center_y": 0.4859982856987479,
      "attention_bam_384_attention_center_x": 0.48197762606396194,
      "attention_bam_384_attention_center_distance": 0.032275500481457164,
      "attention_bam_384_attention_spatial_variance": 172.6222320484249,
      "attention_bam_384_attention_spatial_std": 13.138578007091365,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 19.09729035718142,
      "attention_bam_384_peak_intensity_mean": 0.2521149814128876,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13317260146141052,
      "attention_bam_16_std_attention": 0.5632205605506897,
      "attention_bam_16_max_attention": 4.127374649047852,
      "attention_bam_16_min_attention": -1.0039318799972534,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.699953959952448,
      "attention_bam_16_attention_skewness": 1.0132615164214718,
      "attention_bam_16_attention_sparsity": 0.534912109375,
      "attention_bam_16_attention_concentration_10": 0.9753641632832127,
      "attention_bam_16_attention_concentration_20": 1.5046233314430941,
      "attention_bam_16_attention_center_y": 0.4729384086959949,
      "attention_bam_16_attention_center_x": 0.46464663899042574,
      "attention_bam_16_attention_center_distance": 0.06296332041082792,
      "attention_bam_16_attention_spatial_variance": 44.020392627946876,
      "attention_bam_16_attention_spatial_std": 6.634786554814471,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.976629316186957,
      "attention_bam_16_peak_intensity_mean": 0.22911153733730316,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 468,
      "phase": "train",
      "loss": 0.005491488613188267,
      "timestamp": 1759543959.496218,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005491488613188267,
      "ssim": 0.8925900459289551,
      "attention_bam_384_mean_attention": 0.05199277400970459,
      "attention_bam_384_std_attention": 0.31940045952796936,
      "attention_bam_384_max_attention": 2.358044147491455,
      "attention_bam_384_min_attention": -0.9870190620422363,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8878339422773882,
      "attention_bam_384_attention_skewness": 0.6013583233358931,
      "attention_bam_384_attention_sparsity": 0.5965830485026041,
      "attention_bam_384_attention_concentration_10": 1.3042882713085,
      "attention_bam_384_attention_concentration_20": 2.02466484923562,
      "attention_bam_384_attention_center_y": 0.48642746535036924,
      "attention_bam_384_attention_center_x": 0.48396868336588267,
      "attention_bam_384_attention_center_distance": 0.029705784279791526,
      "attention_bam_384_attention_spatial_variance": 172.54753834244008,
      "attention_bam_384_attention_spatial_std": 13.135735165663172,
      "attention_bam_384_num_attention_peaks": 24,
      "attention_bam_384_peak_separation_mean": 20.662372651824302,
      "attention_bam_384_peak_intensity_mean": 0.3177291750907898,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14027249813079834,
      "attention_bam_16_std_attention": 0.567625880241394,
      "attention_bam_16_max_attention": 3.211786985397339,
      "attention_bam_16_min_attention": -1.0869665145874023,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6792499999416415,
      "attention_bam_16_attention_skewness": 0.7600630526048511,
      "attention_bam_16_attention_sparsity": 0.51904296875,
      "attention_bam_16_attention_concentration_10": 0.918670874495671,
      "attention_bam_16_attention_concentration_20": 1.4401085331412466,
      "attention_bam_16_attention_center_y": 0.474792305301465,
      "attention_bam_16_attention_center_x": 0.46959565401170783,
      "attention_bam_16_attention_center_distance": 0.05585431276079455,
      "attention_bam_16_attention_spatial_variance": 43.99108324825297,
      "attention_bam_16_attention_spatial_std": 6.632577421203085,
      "attention_bam_16_num_attention_peaks": 12,
      "attention_bam_16_peak_separation_mean": 10.29748134517955,
      "attention_bam_16_peak_intensity_mean": 0.29502072930336,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 469,
      "phase": "train",
      "loss": 0.005911023356020451,
      "timestamp": 1759543959.6627157,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005911023356020451,
      "ssim": 0.9049110412597656,
      "attention_bam_384_mean_attention": 0.05231064185500145,
      "attention_bam_384_std_attention": 0.2915458381175995,
      "attention_bam_384_max_attention": 2.367767333984375,
      "attention_bam_384_min_attention": -0.9006478190422058,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9004696125958,
      "attention_bam_384_attention_skewness": 0.5173634078154093,
      "attention_bam_384_attention_sparsity": 0.5887451171875,
      "attention_bam_384_attention_concentration_10": 1.165685912663727,
      "attention_bam_384_attention_concentration_20": 1.824514460063436,
      "attention_bam_384_attention_center_y": 0.48534274849912257,
      "attention_bam_384_attention_center_x": 0.48412843940814027,
      "attention_bam_384_attention_center_distance": 0.030552952629199312,
      "attention_bam_384_attention_spatial_variance": 170.07816580505326,
      "attention_bam_384_attention_spatial_std": 13.041401987710266,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 17.51328319143953,
      "attention_bam_384_peak_intensity_mean": 0.29591068625450134,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14885811507701874,
      "attention_bam_16_std_attention": 0.547660231590271,
      "attention_bam_16_max_attention": 2.6983461380004883,
      "attention_bam_16_min_attention": -1.0305215120315552,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5126113372566059,
      "attention_bam_16_attention_skewness": 0.6576790486769337,
      "attention_bam_16_attention_sparsity": 0.50830078125,
      "attention_bam_16_attention_concentration_10": 0.8184400751079594,
      "attention_bam_16_attention_concentration_20": 1.3058642707639185,
      "attention_bam_16_attention_center_y": 0.47272612414287724,
      "attention_bam_16_attention_center_x": 0.4685182884387934,
      "attention_bam_16_attention_center_distance": 0.058906068738165736,
      "attention_bam_16_attention_spatial_variance": 42.33317185915681,
      "attention_bam_16_attention_spatial_std": 6.506394689776882,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.707444798414485,
      "attention_bam_16_peak_intensity_mean": 0.3292213976383209,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 470,
      "phase": "train",
      "loss": 0.0069758109748363495,
      "timestamp": 1759543959.9007492,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0069758109748363495,
      "ssim": 0.8955323100090027,
      "attention_bam_384_mean_attention": 0.05114620551466942,
      "attention_bam_384_std_attention": 0.3190418779850006,
      "attention_bam_384_max_attention": 2.7089741230010986,
      "attention_bam_384_min_attention": -1.1067566871643066,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1227992582942923,
      "attention_bam_384_attention_skewness": 0.6668435064090695,
      "attention_bam_384_attention_sparsity": 0.6086552937825521,
      "attention_bam_384_attention_concentration_10": 1.3460259795696772,
      "attention_bam_384_attention_concentration_20": 2.0741846410786677,
      "attention_bam_384_attention_center_y": 0.4827518406882479,
      "attention_bam_384_attention_center_x": 0.48396544197595925,
      "attention_bam_384_attention_center_distance": 0.033304836005298405,
      "attention_bam_384_attention_spatial_variance": 171.26971992001594,
      "attention_bam_384_attention_spatial_std": 13.087005766026694,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 18.16327323403336,
      "attention_bam_384_peak_intensity_mean": 0.3053821921348572,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13908299803733826,
      "attention_bam_16_std_attention": 0.5649227499961853,
      "attention_bam_16_max_attention": 2.802572011947632,
      "attention_bam_16_min_attention": -1.0616692304611206,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.36319712650607316,
      "attention_bam_16_attention_skewness": 0.671776055987331,
      "attention_bam_16_attention_sparsity": 0.5234375,
      "attention_bam_16_attention_concentration_10": 0.9105209272645324,
      "attention_bam_16_attention_concentration_20": 1.4421851050916037,
      "attention_bam_16_attention_center_y": 0.464132749474361,
      "attention_bam_16_attention_center_x": 0.4670992357447111,
      "attention_bam_16_attention_center_distance": 0.06883196857349126,
      "attention_bam_16_attention_spatial_variance": 43.2212716203316,
      "attention_bam_16_attention_spatial_std": 6.574288677897526,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.31552099671996,
      "attention_bam_16_peak_intensity_mean": 0.31898441910743713,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 471,
      "phase": "train",
      "loss": 0.006130129098892212,
      "timestamp": 1759543960.0850468,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006130129098892212,
      "ssim": 0.8952063322067261,
      "attention_bam_384_mean_attention": 0.050987958908081055,
      "attention_bam_384_std_attention": 0.26241016387939453,
      "attention_bam_384_max_attention": 2.1231019496917725,
      "attention_bam_384_min_attention": -0.9192270040512085,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6543147374733511,
      "attention_bam_384_attention_skewness": 0.48772132087590236,
      "attention_bam_384_attention_sparsity": 0.6069361368815104,
      "attention_bam_384_attention_concentration_10": 1.0922087294271,
      "attention_bam_384_attention_concentration_20": 1.7209310028249911,
      "attention_bam_384_attention_center_y": 0.48717092935797845,
      "attention_bam_384_attention_center_x": 0.48601618052082257,
      "attention_bam_384_attention_center_distance": 0.026837744345015332,
      "attention_bam_384_attention_spatial_variance": 171.15511667396441,
      "attention_bam_384_attention_spatial_std": 13.082626520464627,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 18.721647242648842,
      "attention_bam_384_peak_intensity_mean": 0.3207758069038391,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14741471409797668,
      "attention_bam_16_std_attention": 0.5009947419166565,
      "attention_bam_16_max_attention": 2.9628350734710693,
      "attention_bam_16_min_attention": -1.11057448387146,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5644171465317784,
      "attention_bam_16_attention_skewness": 0.6221358422811784,
      "attention_bam_16_attention_sparsity": 0.49462890625,
      "attention_bam_16_attention_concentration_10": 0.7691727668607377,
      "attention_bam_16_attention_concentration_20": 1.2229765504808459,
      "attention_bam_16_attention_center_y": 0.47470169675994406,
      "attention_bam_16_attention_center_x": 0.4748035465455899,
      "attention_bam_16_attention_center_distance": 0.05049485941174761,
      "attention_bam_16_attention_spatial_variance": 43.01421438547859,
      "attention_bam_16_attention_spatial_std": 6.55852227147843,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 7.707183617595961,
      "attention_bam_16_peak_intensity_mean": 0.30475369095802307,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 472,
      "phase": "train",
      "loss": 0.009488769806921482,
      "timestamp": 1759543960.2546177,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.009488769806921482,
      "ssim": 0.8695255517959595,
      "attention_bam_384_mean_attention": 0.051430437713861465,
      "attention_bam_384_std_attention": 0.3406343162059784,
      "attention_bam_384_max_attention": 2.9326934814453125,
      "attention_bam_384_min_attention": -1.210458517074585,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.762697757243,
      "attention_bam_384_attention_skewness": 0.5290276506078907,
      "attention_bam_384_attention_sparsity": 0.5855840047200521,
      "attention_bam_384_attention_concentration_10": 1.3746492162922377,
      "attention_bam_384_attention_concentration_20": 2.154821444005612,
      "attention_bam_384_attention_center_y": 0.4807874393957698,
      "attention_bam_384_attention_center_x": 0.4833854167734799,
      "attention_bam_384_attention_center_distance": 0.03592121547949572,
      "attention_bam_384_attention_spatial_variance": 171.34573085259288,
      "attention_bam_384_attention_spatial_std": 13.089909505133825,
      "attention_bam_384_num_attention_peaks": 23,
      "attention_bam_384_peak_separation_mean": 19.481435184435334,
      "attention_bam_384_peak_intensity_mean": 0.30665323138237,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.15153002738952637,
      "attention_bam_16_std_attention": 0.5994123816490173,
      "attention_bam_16_max_attention": 3.1570510864257812,
      "attention_bam_16_min_attention": -1.197166919708252,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5230423159156308,
      "attention_bam_16_attention_skewness": 0.6839189806487461,
      "attention_bam_16_attention_sparsity": 0.516845703125,
      "attention_bam_16_attention_concentration_10": 0.88626609398427,
      "attention_bam_16_attention_concentration_20": 1.407482519412847,
      "attention_bam_16_attention_center_y": 0.45571110058215564,
      "attention_bam_16_attention_center_x": 0.46689288387322797,
      "attention_bam_16_attention_center_distance": 0.07819958759322844,
      "attention_bam_16_attention_spatial_variance": 43.078572982048314,
      "attention_bam_16_attention_spatial_std": 6.563426923646542,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 7.283404658474173,
      "attention_bam_16_peak_intensity_mean": 0.3083999752998352,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 473,
      "phase": "train",
      "loss": 0.00602470338344574,
      "timestamp": 1759543960.4179926,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00602470338344574,
      "ssim": 0.8824927806854248,
      "attention_bam_384_mean_attention": 0.04883098602294922,
      "attention_bam_384_std_attention": 0.3195963501930237,
      "attention_bam_384_max_attention": 2.3477628231048584,
      "attention_bam_384_min_attention": -0.9598603844642639,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.257661918814815,
      "attention_bam_384_attention_skewness": 0.8255298535949075,
      "attention_bam_384_attention_sparsity": 0.6116587320963541,
      "attention_bam_384_attention_concentration_10": 1.4337373013618036,
      "attention_bam_384_attention_concentration_20": 2.181485744649242,
      "attention_bam_384_attention_center_y": 0.4824406478247583,
      "attention_bam_384_attention_center_x": 0.4851098149827393,
      "attention_bam_384_attention_center_distance": 0.032559129554164054,
      "attention_bam_384_attention_spatial_variance": 172.5180111804584,
      "attention_bam_384_attention_spatial_std": 13.134611192588016,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 18.83344559397258,
      "attention_bam_384_peak_intensity_mean": 0.3091670274734497,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13074323534965515,
      "attention_bam_16_std_attention": 0.5687519907951355,
      "attention_bam_16_max_attention": 3.6790266036987305,
      "attention_bam_16_min_attention": -1.0624446868896484,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.276890713232457,
      "attention_bam_16_attention_skewness": 0.977840437431095,
      "attention_bam_16_attention_sparsity": 0.550048828125,
      "attention_bam_16_attention_concentration_10": 1.0096044804764273,
      "attention_bam_16_attention_concentration_20": 1.5550254557763337,
      "attention_bam_16_attention_center_y": 0.4632305332872693,
      "attention_bam_16_attention_center_x": 0.47217472174641983,
      "attention_bam_16_attention_center_distance": 0.06521103882361896,
      "attention_bam_16_attention_spatial_variance": 44.05940066464021,
      "attention_bam_16_attention_spatial_std": 6.637725564125125,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.58294732923279,
      "attention_bam_16_peak_intensity_mean": 0.257200688123703,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 474,
      "phase": "train",
      "loss": 0.008687647059559822,
      "timestamp": 1759543960.5732245,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008687647059559822,
      "ssim": 0.8392059803009033,
      "attention_bam_384_mean_attention": 0.0513966865837574,
      "attention_bam_384_std_attention": 0.29947739839553833,
      "attention_bam_384_max_attention": 2.1374027729034424,
      "attention_bam_384_min_attention": -0.9667574167251587,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8573221572672844,
      "attention_bam_384_attention_skewness": 0.5424636920456363,
      "attention_bam_384_attention_sparsity": 0.5978546142578125,
      "attention_bam_384_attention_concentration_10": 1.2318716948596082,
      "attention_bam_384_attention_concentration_20": 1.9172903265700556,
      "attention_bam_384_attention_center_y": 0.4839703464422365,
      "attention_bam_384_attention_center_x": 0.47582946878745364,
      "attention_bam_384_attention_center_distance": 0.04101620100103366,
      "attention_bam_384_attention_spatial_variance": 171.65102353676755,
      "attention_bam_384_attention_spatial_std": 13.101565690281737,
      "attention_bam_384_num_attention_peaks": 21,
      "attention_bam_384_peak_separation_mean": 17.207944491803076,
      "attention_bam_384_peak_intensity_mean": 0.3310885429382324,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.15245601534843445,
      "attention_bam_16_std_attention": 0.5474873781204224,
      "attention_bam_16_max_attention": 2.7108936309814453,
      "attention_bam_16_min_attention": -1.0382381677627563,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.31020948143100613,
      "attention_bam_16_attention_skewness": 0.5808072056017846,
      "attention_bam_16_attention_sparsity": 0.498291015625,
      "attention_bam_16_attention_concentration_10": 0.8018974895166836,
      "attention_bam_16_attention_concentration_20": 1.2811298827394868,
      "attention_bam_16_attention_center_y": 0.46379740785320384,
      "attention_bam_16_attention_center_x": 0.4443747157717163,
      "attention_bam_16_attention_center_distance": 0.09385946860732397,
      "attention_bam_16_attention_spatial_variance": 43.0589020693654,
      "attention_bam_16_attention_spatial_std": 6.561928227995595,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.317387255635026,
      "attention_bam_16_peak_intensity_mean": 0.3275652229785919,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 475,
      "phase": "train",
      "loss": 0.00618837121874094,
      "timestamp": 1759543960.7244668,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00618837121874094,
      "ssim": 0.8562726974487305,
      "attention_bam_384_mean_attention": 0.05132712796330452,
      "attention_bam_384_std_attention": 0.2730594277381897,
      "attention_bam_384_max_attention": 2.1090681552886963,
      "attention_bam_384_min_attention": -0.9070184826850891,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1067267831028795,
      "attention_bam_384_attention_skewness": 0.5794626101659902,
      "attention_bam_384_attention_sparsity": 0.6063893636067709,
      "attention_bam_384_attention_concentration_10": 1.137090608849319,
      "attention_bam_384_attention_concentration_20": 1.7627978705399956,
      "attention_bam_384_attention_center_y": 0.48201212043756203,
      "attention_bam_384_attention_center_x": 0.48674921486970346,
      "attention_bam_384_attention_center_distance": 0.03159579458478806,
      "attention_bam_384_attention_spatial_variance": 170.7938271705353,
      "attention_bam_384_attention_spatial_std": 13.068811237849268,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 19.300085131808807,
      "attention_bam_384_peak_intensity_mean": 0.3203255832195282,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.15520820021629333,
      "attention_bam_16_std_attention": 0.5224553346633911,
      "attention_bam_16_max_attention": 3.049427032470703,
      "attention_bam_16_min_attention": -1.0721014738082886,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8941440459808341,
      "attention_bam_16_attention_skewness": 0.6879454807638958,
      "attention_bam_16_attention_sparsity": 0.49755859375,
      "attention_bam_16_attention_concentration_10": 0.7563811907238331,
      "attention_bam_16_attention_concentration_20": 1.2036784145812822,
      "attention_bam_16_attention_center_y": 0.46048262139002355,
      "attention_bam_16_attention_center_x": 0.47733092718434816,
      "attention_bam_16_attention_center_distance": 0.06442841103931633,
      "attention_bam_16_attention_spatial_variance": 42.70910511579073,
      "attention_bam_16_attention_spatial_std": 6.53522035709514,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.660805924982508,
      "attention_bam_16_peak_intensity_mean": 0.29892659187316895,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 476,
      "phase": "train",
      "loss": 0.005394024308770895,
      "timestamp": 1759543960.8722126,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005394024308770895,
      "ssim": 0.9011296629905701,
      "attention_bam_384_mean_attention": 0.0496467761695385,
      "attention_bam_384_std_attention": 0.30303922295570374,
      "attention_bam_384_max_attention": 2.37428617477417,
      "attention_bam_384_min_attention": -0.9970146417617798,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4598310386250386,
      "attention_bam_384_attention_skewness": 0.661545933357213,
      "attention_bam_384_attention_sparsity": 0.6029815673828125,
      "attention_bam_384_attention_concentration_10": 1.2929535489771686,
      "attention_bam_384_attention_concentration_20": 1.9895702103876307,
      "attention_bam_384_attention_center_y": 0.4874552952155652,
      "attention_bam_384_attention_center_x": 0.4865548917302435,
      "attention_bam_384_attention_center_distance": 0.02600540538096246,
      "attention_bam_384_attention_spatial_variance": 169.41900539232947,
      "attention_bam_384_attention_spatial_std": 13.016105615441566,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 14.05114396228156,
      "attention_bam_384_peak_intensity_mean": 0.3149070143699646,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14920201897621155,
      "attention_bam_16_std_attention": 0.5582337975502014,
      "attention_bam_16_max_attention": 2.8084020614624023,
      "attention_bam_16_min_attention": -1.0398212671279907,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7147732459063998,
      "attention_bam_16_attention_skewness": 0.7643671136023582,
      "attention_bam_16_attention_sparsity": 0.51416015625,
      "attention_bam_16_attention_concentration_10": 0.8520539454545382,
      "attention_bam_16_attention_concentration_20": 1.3391189737533977,
      "attention_bam_16_attention_center_y": 0.47912615991984664,
      "attention_bam_16_attention_center_x": 0.47824174423741644,
      "attention_bam_16_attention_center_distance": 0.04264126859092767,
      "attention_bam_16_attention_spatial_variance": 41.67426294911364,
      "attention_bam_16_attention_spatial_std": 6.45556062237151,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 7.22434696231138,
      "attention_bam_16_peak_intensity_mean": 0.33727359771728516,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 477,
      "phase": "train",
      "loss": 0.00416377279907465,
      "timestamp": 1759543961.0122645,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00416377279907465,
      "ssim": 0.9295034408569336,
      "attention_bam_384_mean_attention": 0.04883630946278572,
      "attention_bam_384_std_attention": 0.2855750024318695,
      "attention_bam_384_max_attention": 2.539031744003296,
      "attention_bam_384_min_attention": -0.9589183330535889,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.519331967135848,
      "attention_bam_384_attention_skewness": 0.721874155931333,
      "attention_bam_384_attention_sparsity": 0.6140518188476562,
      "attention_bam_384_attention_concentration_10": 1.2676874645031746,
      "attention_bam_384_attention_concentration_20": 1.9387167353119181,
      "attention_bam_384_attention_center_y": 0.48684256352307054,
      "attention_bam_384_attention_center_x": 0.4877908763048608,
      "attention_bam_384_attention_center_distance": 0.025384280019241978,
      "attention_bam_384_attention_spatial_variance": 170.8239474823542,
      "attention_bam_384_attention_spatial_std": 13.069963560865585,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 18.851503094482403,
      "attention_bam_384_peak_intensity_mean": 0.2887532413005829,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14185748994350433,
      "attention_bam_16_std_attention": 0.555969774723053,
      "attention_bam_16_max_attention": 2.877553939819336,
      "attention_bam_16_min_attention": -0.985764741897583,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.984813679907576,
      "attention_bam_16_attention_skewness": 0.8662025962541999,
      "attention_bam_16_attention_sparsity": 0.53125,
      "attention_bam_16_attention_concentration_10": 0.9034833892445214,
      "attention_bam_16_attention_concentration_20": 1.4162711878406178,
      "attention_bam_16_attention_center_y": 0.479600059420351,
      "attention_bam_16_attention_center_x": 0.48044725203527916,
      "attention_bam_16_attention_center_distance": 0.03996166985062323,
      "attention_bam_16_attention_spatial_variance": 43.021647205893494,
      "attention_bam_16_attention_spatial_std": 6.559088900593854,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.114893294449985,
      "attention_bam_16_peak_intensity_mean": 0.29905226826667786,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 478,
      "phase": "train",
      "loss": 0.007027852348983288,
      "timestamp": 1759543961.3697498,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007027852348983288,
      "ssim": 0.8915594816207886,
      "attention_bam_384_mean_attention": 0.04784463718533516,
      "attention_bam_384_std_attention": 0.2892729640007019,
      "attention_bam_384_max_attention": 2.0996949672698975,
      "attention_bam_384_min_attention": -0.9777803421020508,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7790790641265333,
      "attention_bam_384_attention_skewness": 0.6355892319614582,
      "attention_bam_384_attention_sparsity": 0.6110738118489584,
      "attention_bam_384_attention_concentration_10": 1.292271664853693,
      "attention_bam_384_attention_concentration_20": 2.0102375337885445,
      "attention_bam_384_attention_center_y": 0.4861859436179538,
      "attention_bam_384_attention_center_x": 0.48066423258387114,
      "attention_bam_384_attention_center_distance": 0.03360654862662875,
      "attention_bam_384_attention_spatial_variance": 170.25875309657832,
      "attention_bam_384_attention_spatial_std": 13.048323765778434,
      "attention_bam_384_num_attention_peaks": 18,
      "attention_bam_384_peak_separation_mean": 18.881350792436578,
      "attention_bam_384_peak_intensity_mean": 0.33581793308258057,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1402958631515503,
      "attention_bam_16_std_attention": 0.5386689305305481,
      "attention_bam_16_max_attention": 2.617687940597534,
      "attention_bam_16_min_attention": -0.8855932354927063,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.34299242993445267,
      "attention_bam_16_attention_skewness": 0.7113228535874502,
      "attention_bam_16_attention_sparsity": 0.5263671875,
      "attention_bam_16_attention_concentration_10": 0.8718219123689404,
      "attention_bam_16_attention_concentration_20": 1.3785631075640796,
      "attention_bam_16_attention_center_y": 0.4734808876954777,
      "attention_bam_16_attention_center_x": 0.4596902858007805,
      "attention_bam_16_attention_center_distance": 0.06823688703688975,
      "attention_bam_16_attention_spatial_variance": 42.11578156688343,
      "attention_bam_16_attention_spatial_std": 6.489667292464493,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 8.110054027519482,
      "attention_bam_16_peak_intensity_mean": 0.28990891575813293,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 479,
      "phase": "train",
      "loss": 0.00965464860200882,
      "timestamp": 1759543961.5054874,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00965464860200882,
      "ssim": 0.8264632821083069,
      "attention_bam_384_mean_attention": 0.049301158636808395,
      "attention_bam_384_std_attention": 0.275629460811615,
      "attention_bam_384_max_attention": 2.0860557556152344,
      "attention_bam_384_min_attention": -0.8938586115837097,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7824601244144826,
      "attention_bam_384_attention_skewness": 0.5463738387052135,
      "attention_bam_384_attention_sparsity": 0.612884521484375,
      "attention_bam_384_attention_concentration_10": 1.199886878761987,
      "attention_bam_384_attention_concentration_20": 1.8595487200102763,
      "attention_bam_384_attention_center_y": 0.4858200008270761,
      "attention_bam_384_attention_center_x": 0.48600924756816116,
      "attention_bam_384_attention_center_distance": 0.028171387262721965,
      "attention_bam_384_attention_spatial_variance": 170.8988310442782,
      "attention_bam_384_attention_spatial_std": 13.072827966598437,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 16.95689585267774,
      "attention_bam_384_peak_intensity_mean": 0.319229394197464,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.15288585424423218,
      "attention_bam_16_std_attention": 0.5133805871009827,
      "attention_bam_16_max_attention": 2.8779640197753906,
      "attention_bam_16_min_attention": -1.0257073640823364,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5675237957505543,
      "attention_bam_16_attention_skewness": 0.6489997024705926,
      "attention_bam_16_attention_sparsity": 0.500244140625,
      "attention_bam_16_attention_concentration_10": 0.7638447422274679,
      "attention_bam_16_attention_concentration_20": 1.2197018400202264,
      "attention_bam_16_attention_center_y": 0.4740744568928796,
      "attention_bam_16_attention_center_x": 0.47385147910435876,
      "attention_bam_16_attention_center_distance": 0.05207454138883885,
      "attention_bam_16_attention_spatial_variance": 42.97798110888884,
      "attention_bam_16_attention_spatial_std": 6.55575938460899,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.1999403133597,
      "attention_bam_16_peak_intensity_mean": 0.3076702654361725,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 480,
      "phase": "train",
      "loss": 0.004216895438730717,
      "timestamp": 1759543961.6849613,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004216895438730717,
      "ssim": 0.9138777256011963,
      "attention_bam_384_mean_attention": 0.0459856241941452,
      "attention_bam_384_std_attention": 0.2971456050872803,
      "attention_bam_384_max_attention": 1.9060252904891968,
      "attention_bam_384_min_attention": -0.8791519403457642,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6647360112747922,
      "attention_bam_384_attention_skewness": 0.6550196375941285,
      "attention_bam_384_attention_sparsity": 0.6080602010091146,
      "attention_bam_384_attention_concentration_10": 1.3785231335611052,
      "attention_bam_384_attention_concentration_20": 2.141764496907424,
      "attention_bam_384_attention_center_y": 0.4818482789745079,
      "attention_bam_384_attention_center_x": 0.48135224374856045,
      "attention_bam_384_attention_center_distance": 0.03680282025607264,
      "attention_bam_384_attention_spatial_variance": 167.97211497292574,
      "attention_bam_384_attention_spatial_std": 12.960405663902876,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 14.87300036357698,
      "attention_bam_384_peak_intensity_mean": 0.3338468074798584,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1354059875011444,
      "attention_bam_16_std_attention": 0.5575054287910461,
      "attention_bam_16_max_attention": 2.6921470165252686,
      "attention_bam_16_min_attention": -1.003737211227417,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5420534736272589,
      "attention_bam_16_attention_skewness": 0.8296163253008291,
      "attention_bam_16_attention_sparsity": 0.540771484375,
      "attention_bam_16_attention_concentration_10": 0.9498352690976105,
      "attention_bam_16_attention_concentration_20": 1.4871079841553245,
      "attention_bam_16_attention_center_y": 0.46214967792543815,
      "attention_bam_16_attention_center_x": 0.4633182155058574,
      "attention_bam_16_attention_center_distance": 0.07454126635391681,
      "attention_bam_16_attention_spatial_variance": 41.05486750806292,
      "attention_bam_16_attention_spatial_std": 6.407407237569883,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 7.753955755794101,
      "attention_bam_16_peak_intensity_mean": 0.31374531984329224,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 481,
      "phase": "train",
      "loss": 0.0058935764245688915,
      "timestamp": 1759543961.8301723,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0058935764245688915,
      "ssim": 0.8939436674118042,
      "attention_bam_384_mean_attention": 0.04697342589497566,
      "attention_bam_384_std_attention": 0.2948317229747772,
      "attention_bam_384_max_attention": 1.895758032798767,
      "attention_bam_384_min_attention": -0.8912075757980347,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.37234127511380954,
      "attention_bam_384_attention_skewness": 0.483227165655923,
      "attention_bam_384_attention_sparsity": 0.5996627807617188,
      "attention_bam_384_attention_concentration_10": 1.3002121180071209,
      "attention_bam_384_attention_concentration_20": 2.055817912656178,
      "attention_bam_384_attention_center_y": 0.4803578192018241,
      "attention_bam_384_attention_center_x": 0.4881936022175694,
      "attention_bam_384_attention_center_distance": 0.032410069271916496,
      "attention_bam_384_attention_spatial_variance": 171.3821563875656,
      "attention_bam_384_attention_spatial_std": 13.09130079050839,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 19.227867317113173,
      "attention_bam_384_peak_intensity_mean": 0.34032201766967773,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1568131446838379,
      "attention_bam_16_std_attention": 0.5483593344688416,
      "attention_bam_16_max_attention": 2.4192521572113037,
      "attention_bam_16_min_attention": -1.059134602546692,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.08491508288250094,
      "attention_bam_16_attention_skewness": 0.616749262717615,
      "attention_bam_16_attention_sparsity": 0.512939453125,
      "attention_bam_16_attention_concentration_10": 0.7916359419205891,
      "attention_bam_16_attention_concentration_20": 1.2732817778437722,
      "attention_bam_16_attention_center_y": 0.45671095727210936,
      "attention_bam_16_attention_center_x": 0.47924370687669193,
      "attention_bam_16_attention_center_distance": 0.06789351846115838,
      "attention_bam_16_attention_spatial_variance": 43.12378052690617,
      "attention_bam_16_attention_spatial_std": 6.5668699185309105,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 10.339823291293621,
      "attention_bam_16_peak_intensity_mean": 0.3607088327407837,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 482,
      "phase": "train",
      "loss": 0.0062321750447154045,
      "timestamp": 1759543961.9694963,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0062321750447154045,
      "ssim": 0.8854104280471802,
      "attention_bam_384_mean_attention": 0.045536816120147705,
      "attention_bam_384_std_attention": 0.29609793424606323,
      "attention_bam_384_max_attention": 2.0177433490753174,
      "attention_bam_384_min_attention": -0.8526955246925354,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.087012207303217,
      "attention_bam_384_attention_skewness": 0.7490300050223161,
      "attention_bam_384_attention_sparsity": 0.6240386962890625,
      "attention_bam_384_attention_concentration_10": 1.418268473517092,
      "attention_bam_384_attention_concentration_20": 2.1676066987692213,
      "attention_bam_384_attention_center_y": 0.47924386424951027,
      "attention_bam_384_attention_center_x": 0.4752556042761858,
      "attention_bam_384_attention_center_distance": 0.04567498858301933,
      "attention_bam_384_attention_spatial_variance": 170.00418512059647,
      "attention_bam_384_attention_spatial_std": 13.038565301466127,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 16.880286683389276,
      "attention_bam_384_peak_intensity_mean": 0.3149721920490265,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1428387463092804,
      "attention_bam_16_std_attention": 0.5646360516548157,
      "attention_bam_16_max_attention": 2.7743797302246094,
      "attention_bam_16_min_attention": -1.0401437282562256,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.47332713169484286,
      "attention_bam_16_attention_skewness": 0.8057657192267597,
      "attention_bam_16_attention_sparsity": 0.534912109375,
      "attention_bam_16_attention_concentration_10": 0.9102703117577767,
      "attention_bam_16_attention_concentration_20": 1.444426547476153,
      "attention_bam_16_attention_center_y": 0.45530771381136786,
      "attention_bam_16_attention_center_x": 0.44395994540697353,
      "attention_bam_16_attention_center_distance": 0.10136950393048182,
      "attention_bam_16_attention_spatial_variance": 42.08512919310389,
      "attention_bam_16_attention_spatial_std": 6.487305233539107,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.343928866037603,
      "attention_bam_16_peak_intensity_mean": 0.326718807220459,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 483,
      "phase": "train",
      "loss": 0.00503028929233551,
      "timestamp": 1759543962.1402996,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00503028929233551,
      "ssim": 0.9076452255249023,
      "attention_bam_384_mean_attention": 0.04686780273914337,
      "attention_bam_384_std_attention": 0.29265618324279785,
      "attention_bam_384_max_attention": 2.2242255210876465,
      "attention_bam_384_min_attention": -0.9409754276275635,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2605676605281335,
      "attention_bam_384_attention_skewness": 0.643437983848961,
      "attention_bam_384_attention_sparsity": 0.6126912434895834,
      "attention_bam_384_attention_concentration_10": 1.3346363584811534,
      "attention_bam_384_attention_concentration_20": 2.040508767996298,
      "attention_bam_384_attention_center_y": 0.4868818880381271,
      "attention_bam_384_attention_center_x": 0.4791948838995581,
      "attention_bam_384_attention_center_distance": 0.03478326371682505,
      "attention_bam_384_attention_spatial_variance": 170.0928091833881,
      "attention_bam_384_attention_spatial_std": 13.041963394496555,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 15.718317247644132,
      "attention_bam_384_peak_intensity_mean": 0.31344351172447205,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1498212218284607,
      "attention_bam_16_std_attention": 0.5423035025596619,
      "attention_bam_16_max_attention": 2.7779932022094727,
      "attention_bam_16_min_attention": -1.0959361791610718,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.658159989844417,
      "attention_bam_16_attention_skewness": 0.7074908680848885,
      "attention_bam_16_attention_sparsity": 0.51318359375,
      "attention_bam_16_attention_concentration_10": 0.8291486197058295,
      "attention_bam_16_attention_concentration_20": 1.2999546861777604,
      "attention_bam_16_attention_center_y": 0.47514072893822074,
      "attention_bam_16_attention_center_x": 0.4563015343013005,
      "attention_bam_16_attention_center_distance": 0.07109907541091422,
      "attention_bam_16_attention_spatial_variance": 42.14112198337146,
      "attention_bam_16_attention_spatial_std": 6.491619365256366,
      "attention_bam_16_num_attention_peaks": 11,
      "attention_bam_16_peak_separation_mean": 8.21704652771457,
      "attention_bam_16_peak_intensity_mean": 0.3234011232852936,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 484,
      "phase": "train",
      "loss": 0.010294737294316292,
      "timestamp": 1759543962.3304164,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.010294737294316292,
      "ssim": 0.8693132996559143,
      "attention_bam_384_mean_attention": 0.04661661013960838,
      "attention_bam_384_std_attention": 0.31327781081199646,
      "attention_bam_384_max_attention": 2.4678561687469482,
      "attention_bam_384_min_attention": -1.0301488637924194,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.3545319778380014,
      "attention_bam_384_attention_skewness": 0.6998388073165724,
      "attention_bam_384_attention_sparsity": 0.6104660034179688,
      "attention_bam_384_attention_concentration_10": 1.4306062665073238,
      "attention_bam_384_attention_concentration_20": 2.195251803297264,
      "attention_bam_384_attention_center_y": 0.48163576423106746,
      "attention_bam_384_attention_center_x": 0.4854363842143078,
      "attention_bam_384_attention_center_distance": 0.03314646467212467,
      "attention_bam_384_attention_spatial_variance": 169.33935892144297,
      "attention_bam_384_attention_spatial_std": 13.013045720408538,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 16.78091043998031,
      "attention_bam_384_peak_intensity_mean": 0.3088884949684143,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1513427495956421,
      "attention_bam_16_std_attention": 0.5780278444290161,
      "attention_bam_16_max_attention": 2.744347095489502,
      "attention_bam_16_min_attention": -1.0618360042572021,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8561479455436185,
      "attention_bam_16_attention_skewness": 0.830349607751517,
      "attention_bam_16_attention_sparsity": 0.523681640625,
      "attention_bam_16_attention_concentration_10": 0.8775297249682197,
      "attention_bam_16_attention_concentration_20": 1.3741265640101121,
      "attention_bam_16_attention_center_y": 0.4603367339861395,
      "attention_bam_16_attention_center_x": 0.4726280590733906,
      "attention_bam_16_attention_center_distance": 0.06815273759690149,
      "attention_bam_16_attention_spatial_variance": 41.668191921440034,
      "attention_bam_16_attention_spatial_std": 6.455090388324553,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 7.965652664457524,
      "attention_bam_16_peak_intensity_mean": 0.326438844203949,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 485,
      "phase": "train",
      "loss": 0.004025357775390148,
      "timestamp": 1759543962.5134683,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004025357775390148,
      "ssim": 0.9297549724578857,
      "attention_bam_384_mean_attention": 0.04345246031880379,
      "attention_bam_384_std_attention": 0.34638339281082153,
      "attention_bam_384_max_attention": 3.0611960887908936,
      "attention_bam_384_min_attention": -1.1089569330215454,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.6635936080590765,
      "attention_bam_384_attention_skewness": 0.7903888897881874,
      "attention_bam_384_attention_sparsity": 0.6124471028645834,
      "attention_bam_384_attention_concentration_10": 1.7028635585902276,
      "attention_bam_384_attention_concentration_20": 2.581610985470137,
      "attention_bam_384_attention_center_y": 0.4845753955755486,
      "attention_bam_384_attention_center_x": 0.47860845660228485,
      "attention_bam_384_attention_center_distance": 0.03729655615702707,
      "attention_bam_384_attention_spatial_variance": 170.27733080899037,
      "attention_bam_384_attention_spatial_std": 13.049035627546978,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 17.429367358650982,
      "attention_bam_384_peak_intensity_mean": 0.2773002088069916,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.15506288409233093,
      "attention_bam_16_std_attention": 0.64023756980896,
      "attention_bam_16_max_attention": 3.43218994140625,
      "attention_bam_16_min_attention": -1.240581750869751,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.6184664796884078,
      "attention_bam_16_attention_skewness": 1.06986898559571,
      "attention_bam_16_attention_sparsity": 0.541748046875,
      "attention_bam_16_attention_concentration_10": 0.9711028941157839,
      "attention_bam_16_attention_concentration_20": 1.4895555431034884,
      "attention_bam_16_attention_center_y": 0.4699905776109242,
      "attention_bam_16_attention_center_x": 0.4534527023645058,
      "attention_bam_16_attention_center_distance": 0.0783226193291982,
      "attention_bam_16_attention_spatial_variance": 42.37314356432347,
      "attention_bam_16_attention_spatial_std": 6.5094656896187315,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.743911822864902,
      "attention_bam_16_peak_intensity_mean": 0.3017805516719818,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 486,
      "phase": "train",
      "loss": 0.0046217855997383595,
      "timestamp": 1759543962.68061,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0046217855997383595,
      "ssim": 0.9150972962379456,
      "attention_bam_384_mean_attention": 0.04507364332675934,
      "attention_bam_384_std_attention": 0.2935616970062256,
      "attention_bam_384_max_attention": 2.0948398113250732,
      "attention_bam_384_min_attention": -0.8572976589202881,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6691807259855498,
      "attention_bam_384_attention_skewness": 0.6160004953710919,
      "attention_bam_384_attention_sparsity": 0.6083958943684896,
      "attention_bam_384_attention_concentration_10": 1.3781169544661405,
      "attention_bam_384_attention_concentration_20": 2.146052635492688,
      "attention_bam_384_attention_center_y": 0.48394878246534584,
      "attention_bam_384_attention_center_x": 0.47414780679990476,
      "attention_bam_384_attention_center_distance": 0.04303434622716696,
      "attention_bam_384_attention_spatial_variance": 170.69618129282884,
      "attention_bam_384_attention_spatial_std": 13.065074867478902,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 18.079782043066317,
      "attention_bam_384_peak_intensity_mean": 0.3074823319911957,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1574271023273468,
      "attention_bam_16_std_attention": 0.5380779504776001,
      "attention_bam_16_max_attention": 2.367771863937378,
      "attention_bam_16_min_attention": -0.9377901554107666,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.29251693060004813,
      "attention_bam_16_attention_skewness": 0.7059789147941395,
      "attention_bam_16_attention_sparsity": 0.5078125,
      "attention_bam_16_attention_concentration_10": 0.7890509802566839,
      "attention_bam_16_attention_concentration_20": 1.2574392172116815,
      "attention_bam_16_attention_center_y": 0.46664770895533564,
      "attention_bam_16_attention_center_x": 0.44202134797586756,
      "attention_bam_16_attention_center_distance": 0.09459280531270267,
      "attention_bam_16_attention_spatial_variance": 42.61256683937914,
      "attention_bam_16_attention_spatial_std": 6.527830178503355,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.849799895376945,
      "attention_bam_16_peak_intensity_mean": 0.34514760971069336,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 487,
      "phase": "train",
      "loss": 0.006204537115991116,
      "timestamp": 1759543962.8413887,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006204537115991116,
      "ssim": 0.9011883735656738,
      "attention_bam_384_mean_attention": 0.04567959904670715,
      "attention_bam_384_std_attention": 0.295024573802948,
      "attention_bam_384_max_attention": 2.3393218517303467,
      "attention_bam_384_min_attention": -0.89769446849823,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.34325791223231494,
      "attention_bam_384_attention_skewness": 0.5023173138673057,
      "attention_bam_384_attention_sparsity": 0.5989125569661459,
      "attention_bam_384_attention_concentration_10": 1.3427875637271764,
      "attention_bam_384_attention_concentration_20": 2.114579452787367,
      "attention_bam_384_attention_center_y": 0.4907449682645572,
      "attention_bam_384_attention_center_x": 0.4763283355286003,
      "attention_bam_384_attention_center_distance": 0.035944493633116574,
      "attention_bam_384_attention_spatial_variance": 172.3925506041805,
      "attention_bam_384_attention_spatial_std": 13.129834370782463,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 18.762065471834713,
      "attention_bam_384_peak_intensity_mean": 0.2932909429073334,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1485598087310791,
      "attention_bam_16_std_attention": 0.5492145419120789,
      "attention_bam_16_max_attention": 2.4000606536865234,
      "attention_bam_16_min_attention": -1.1548771858215332,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.18109146541121257,
      "attention_bam_16_attention_skewness": 0.6458698031848211,
      "attention_bam_16_attention_sparsity": 0.517578125,
      "attention_bam_16_attention_concentration_10": 0.8406493989638852,
      "attention_bam_16_attention_concentration_20": 1.3383248007740196,
      "attention_bam_16_attention_center_y": 0.48549603474326175,
      "attention_bam_16_attention_center_x": 0.44817668681038714,
      "attention_bam_16_attention_center_distance": 0.0761054636424662,
      "attention_bam_16_attention_spatial_variance": 43.66871685824226,
      "attention_bam_16_attention_spatial_std": 6.608230993105663,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.931392385997666,
      "attention_bam_16_peak_intensity_mean": 0.3707243800163269,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 488,
      "phase": "train",
      "loss": 0.005695500876754522,
      "timestamp": 1759543962.9915864,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005695500876754522,
      "ssim": 0.9177566170692444,
      "attention_bam_384_mean_attention": 0.043953727930784225,
      "attention_bam_384_std_attention": 0.3139524459838867,
      "attention_bam_384_max_attention": 2.2521772384643555,
      "attention_bam_384_min_attention": -1.009824514389038,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6539438050493125,
      "attention_bam_384_attention_skewness": 0.5846889157322,
      "attention_bam_384_attention_sparsity": 0.6113332112630209,
      "attention_bam_384_attention_concentration_10": 1.504985956690093,
      "attention_bam_384_attention_concentration_20": 2.3343909981776636,
      "attention_bam_384_attention_center_y": 0.4857577883257894,
      "attention_bam_384_attention_center_x": 0.48365344586613973,
      "attention_bam_384_attention_center_distance": 0.030661064085391567,
      "attention_bam_384_attention_spatial_variance": 168.55302745430836,
      "attention_bam_384_attention_spatial_std": 12.982797366296232,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 17.765075807337304,
      "attention_bam_384_peak_intensity_mean": 0.3289368450641632,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.15318921208381653,
      "attention_bam_16_std_attention": 0.5690985918045044,
      "attention_bam_16_max_attention": 2.529097080230713,
      "attention_bam_16_min_attention": -1.069678783416748,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.4331213094720403,
      "attention_bam_16_attention_skewness": 0.7372462781444828,
      "attention_bam_16_attention_sparsity": 0.52685546875,
      "attention_bam_16_attention_concentration_10": 0.852269678637561,
      "attention_bam_16_attention_concentration_20": 1.3522659822588254,
      "attention_bam_16_attention_center_y": 0.47307301117773604,
      "attention_bam_16_attention_center_x": 0.47029770064991816,
      "attention_bam_16_attention_center_distance": 0.056697254143674373,
      "attention_bam_16_attention_spatial_variance": 41.25767884196178,
      "attention_bam_16_attention_spatial_std": 6.4232140585505775,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 7.660082584892916,
      "attention_bam_16_peak_intensity_mean": 0.3586534261703491,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 489,
      "phase": "train",
      "loss": 0.004604417830705643,
      "timestamp": 1759543963.14007,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004604417830705643,
      "ssim": 0.924854576587677,
      "attention_bam_384_mean_attention": 0.04370581731200218,
      "attention_bam_384_std_attention": 0.2775476276874542,
      "attention_bam_384_max_attention": 1.7467948198318481,
      "attention_bam_384_min_attention": -0.9326682686805725,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6410081500799811,
      "attention_bam_384_attention_skewness": 0.5126048742783942,
      "attention_bam_384_attention_sparsity": 0.6086095174153646,
      "attention_bam_384_attention_concentration_10": 1.321183324329794,
      "attention_bam_384_attention_concentration_20": 2.069884533072073,
      "attention_bam_384_attention_center_y": 0.4802874482118259,
      "attention_bam_384_attention_center_x": 0.48379556559542986,
      "attention_bam_384_attention_center_distance": 0.03608790357927328,
      "attention_bam_384_attention_spatial_variance": 169.7470914275879,
      "attention_bam_384_attention_spatial_std": 13.02870259955257,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 13.743269159391062,
      "attention_bam_384_peak_intensity_mean": 0.37005579471588135,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1558530330657959,
      "attention_bam_16_std_attention": 0.5260739326477051,
      "attention_bam_16_max_attention": 2.3093533515930176,
      "attention_bam_16_min_attention": -1.0593547821044922,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.13503672828106872,
      "attention_bam_16_attention_skewness": 0.5897488689798341,
      "attention_bam_16_attention_sparsity": 0.5009765625,
      "attention_bam_16_attention_concentration_10": 0.7645112590614451,
      "attention_bam_16_attention_concentration_20": 1.2270456787759354,
      "attention_bam_16_attention_center_y": 0.45775651101909565,
      "attention_bam_16_attention_center_x": 0.47014157968981324,
      "attention_bam_16_attention_center_distance": 0.07315787892906082,
      "attention_bam_16_attention_spatial_variance": 42.01781640886672,
      "attention_bam_16_attention_spatial_std": 6.482115118452211,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.639357604023,
      "attention_bam_16_peak_intensity_mean": 0.37276145815849304,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 490,
      "phase": "train",
      "loss": 0.011675293557345867,
      "timestamp": 1759543963.3304565,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.011675293557345867,
      "ssim": 0.8594568967819214,
      "attention_bam_384_mean_attention": 0.04248518869280815,
      "attention_bam_384_std_attention": 0.31898051500320435,
      "attention_bam_384_max_attention": 3.523083209991455,
      "attention_bam_384_min_attention": -1.0532702207565308,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.4564229832583306,
      "attention_bam_384_attention_skewness": 1.0203711447222978,
      "attention_bam_384_attention_sparsity": 0.6143824259440104,
      "attention_bam_384_attention_concentration_10": 1.5901385624744526,
      "attention_bam_384_attention_concentration_20": 2.396172608826075,
      "attention_bam_384_attention_center_y": 0.4865583725592895,
      "attention_bam_384_attention_center_x": 0.4782577560312034,
      "attention_bam_384_attention_center_distance": 0.036149758534561,
      "attention_bam_384_attention_spatial_variance": 172.8228223421815,
      "attention_bam_384_attention_spatial_std": 13.146209428659711,
      "attention_bam_384_num_attention_peaks": 18,
      "attention_bam_384_peak_separation_mean": 16.604326730658276,
      "attention_bam_384_peak_intensity_mean": 0.23976224660873413,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14937447011470795,
      "attention_bam_16_std_attention": 0.5755510926246643,
      "attention_bam_16_max_attention": 3.900683879852295,
      "attention_bam_16_min_attention": -1.0862115621566772,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.5656966173891096,
      "attention_bam_16_attention_skewness": 1.1145346341876008,
      "attention_bam_16_attention_sparsity": 0.52734375,
      "attention_bam_16_attention_concentration_10": 0.8905943137719424,
      "attention_bam_16_attention_concentration_20": 1.3720475270444146,
      "attention_bam_16_attention_center_y": 0.4709512925641066,
      "attention_bam_16_attention_center_x": 0.45170747713168424,
      "attention_bam_16_attention_center_distance": 0.07969937476144875,
      "attention_bam_16_attention_spatial_variance": 44.14240556626619,
      "attention_bam_16_attention_spatial_std": 6.6439751328753625,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 8.354247231680132,
      "attention_bam_16_peak_intensity_mean": 0.24690522253513336,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 491,
      "phase": "train",
      "loss": 0.007039022631943226,
      "timestamp": 1759543963.4743369,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007039022631943226,
      "ssim": 0.90085369348526,
      "attention_bam_384_mean_attention": 0.0447772741317749,
      "attention_bam_384_std_attention": 0.26748016476631165,
      "attention_bam_384_max_attention": 2.0604536533355713,
      "attention_bam_384_min_attention": -0.9440842270851135,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2581293386274135,
      "attention_bam_384_attention_skewness": 0.5861617089912013,
      "attention_bam_384_attention_sparsity": 0.6202290852864584,
      "attention_bam_384_attention_concentration_10": 1.2733761914769886,
      "attention_bam_384_attention_concentration_20": 1.948189299972182,
      "attention_bam_384_attention_center_y": 0.48159913521144193,
      "attention_bam_384_attention_center_x": 0.48266824004375347,
      "attention_bam_384_attention_center_distance": 0.0357486147465254,
      "attention_bam_384_attention_spatial_variance": 170.5315603347848,
      "attention_bam_384_attention_spatial_std": 13.058773308959184,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 19.079149693298326,
      "attention_bam_384_peak_intensity_mean": 0.3300967812538147,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1609194278717041,
      "attention_bam_16_std_attention": 0.5046002268791199,
      "attention_bam_16_max_attention": 2.3500471115112305,
      "attention_bam_16_min_attention": -1.0468748807907104,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5826752579295671,
      "attention_bam_16_attention_skewness": 0.6155343539868003,
      "attention_bam_16_attention_sparsity": 0.4853515625,
      "attention_bam_16_attention_concentration_10": 0.7212466386040558,
      "attention_bam_16_attention_concentration_20": 1.1387688996708458,
      "attention_bam_16_attention_center_y": 0.46039338997292106,
      "attention_bam_16_attention_center_x": 0.4637387730412203,
      "attention_bam_16_attention_center_distance": 0.07594155829838153,
      "attention_bam_16_attention_spatial_variance": 42.48256231871769,
      "attention_bam_16_attention_spatial_std": 6.517864858887279,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.614000189614842,
      "attention_bam_16_peak_intensity_mean": 0.35604995489120483,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 492,
      "phase": "train",
      "loss": 0.006921250373125076,
      "timestamp": 1759543963.6122665,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006921250373125076,
      "ssim": 0.9179993271827698,
      "attention_bam_384_mean_attention": 0.04162249714136124,
      "attention_bam_384_std_attention": 0.26612550020217896,
      "attention_bam_384_max_attention": 1.8529092073440552,
      "attention_bam_384_min_attention": -1.039412498474121,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.41159701405170024,
      "attention_bam_384_attention_skewness": 0.48996630848434014,
      "attention_bam_384_attention_sparsity": 0.6180089314778646,
      "attention_bam_384_attention_concentration_10": 1.3328388058035114,
      "attention_bam_384_attention_concentration_20": 2.104822055115024,
      "attention_bam_384_attention_center_y": 0.48036067935890353,
      "attention_bam_384_attention_center_x": 0.4903163800395176,
      "attention_bam_384_attention_center_distance": 0.030966931096989597,
      "attention_bam_384_attention_spatial_variance": 169.50570538075087,
      "attention_bam_384_attention_spatial_std": 13.019435678275418,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 13.23981617662311,
      "attention_bam_384_peak_intensity_mean": 0.3755408227443695,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.15527832508087158,
      "attention_bam_16_std_attention": 0.5061582922935486,
      "attention_bam_16_max_attention": 2.3172900676727295,
      "attention_bam_16_min_attention": -0.9965465664863586,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.026713986192125727,
      "attention_bam_16_attention_skewness": 0.5724951104149807,
      "attention_bam_16_attention_sparsity": 0.51025390625,
      "attention_bam_16_attention_concentration_10": 0.7377674906165359,
      "attention_bam_16_attention_concentration_20": 1.196995514230329,
      "attention_bam_16_attention_center_y": 0.453189062349092,
      "attention_bam_16_attention_center_x": 0.4937318876529839,
      "attention_bam_16_attention_center_distance": 0.06679151317573229,
      "attention_bam_16_attention_spatial_variance": 42.10463303380212,
      "attention_bam_16_attention_spatial_std": 6.488808290726589,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 7.259378297198476,
      "attention_bam_16_peak_intensity_mean": 0.3506695032119751,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 493,
      "phase": "train",
      "loss": 0.004601985216140747,
      "timestamp": 1759543963.7466536,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004601985216140747,
      "ssim": 0.9141566753387451,
      "attention_bam_384_mean_attention": 0.04205754026770592,
      "attention_bam_384_std_attention": 0.2846701741218567,
      "attention_bam_384_max_attention": 1.7874128818511963,
      "attention_bam_384_min_attention": -0.8478814959526062,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5411364476769376,
      "attention_bam_384_attention_skewness": 0.47514903570514766,
      "attention_bam_384_attention_sparsity": 0.6043268839518229,
      "attention_bam_384_attention_concentration_10": 1.4074610079401682,
      "attention_bam_384_attention_concentration_20": 2.1897889303792066,
      "attention_bam_384_attention_center_y": 0.48707175951436665,
      "attention_bam_384_attention_center_x": 0.4820452050609223,
      "attention_bam_384_attention_center_distance": 0.031289425157989055,
      "attention_bam_384_attention_spatial_variance": 169.24159402741495,
      "attention_bam_384_attention_spatial_std": 13.009288759475476,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 16.36897429890446,
      "attention_bam_384_peak_intensity_mean": 0.3367626368999481,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.15366068482398987,
      "attention_bam_16_std_attention": 0.5439272522926331,
      "attention_bam_16_max_attention": 2.9233310222625732,
      "attention_bam_16_min_attention": -1.0531302690505981,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.32377945498089256,
      "attention_bam_16_attention_skewness": 0.620977906574796,
      "attention_bam_16_attention_sparsity": 0.5048828125,
      "attention_bam_16_attention_concentration_10": 0.8060997223105375,
      "attention_bam_16_attention_concentration_20": 1.2717039982559768,
      "attention_bam_16_attention_center_y": 0.4772610012561917,
      "attention_bam_16_attention_center_x": 0.46342668040258944,
      "attention_bam_16_attention_center_distance": 0.0609043474678984,
      "attention_bam_16_attention_spatial_variance": 41.549813861525266,
      "attention_bam_16_attention_spatial_std": 6.4459145093249,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 8.780569483217802,
      "attention_bam_16_peak_intensity_mean": 0.3084149956703186,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 494,
      "phase": "train",
      "loss": 0.00806727446615696,
      "timestamp": 1759543963.8862317,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00806727446615696,
      "ssim": 0.8841913938522339,
      "attention_bam_384_mean_attention": 0.04418148100376129,
      "attention_bam_384_std_attention": 0.31411615014076233,
      "attention_bam_384_max_attention": 2.30261492729187,
      "attention_bam_384_min_attention": -1.0448075532913208,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6974323271499898,
      "attention_bam_384_attention_skewness": 0.5482891690686181,
      "attention_bam_384_attention_sparsity": 0.6078084309895834,
      "attention_bam_384_attention_concentration_10": 1.4853236801680325,
      "attention_bam_384_attention_concentration_20": 2.31553404661658,
      "attention_bam_384_attention_center_y": 0.48390489913289486,
      "attention_bam_384_attention_center_x": 0.48528503611074447,
      "attention_bam_384_attention_center_distance": 0.030840960885951098,
      "attention_bam_384_attention_spatial_variance": 171.45224876298286,
      "attention_bam_384_attention_spatial_std": 13.093977576083704,
      "attention_bam_384_num_attention_peaks": 24,
      "attention_bam_384_peak_separation_mean": 19.145180473920416,
      "attention_bam_384_peak_intensity_mean": 0.3262670040130615,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1614411175251007,
      "attention_bam_16_std_attention": 0.5704204440116882,
      "attention_bam_16_max_attention": 2.555245876312256,
      "attention_bam_16_min_attention": -1.1560137271881104,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.3800898792692897,
      "attention_bam_16_attention_skewness": 0.6488038509752496,
      "attention_bam_16_attention_sparsity": 0.50732421875,
      "attention_bam_16_attention_concentration_10": 0.7994541324378623,
      "attention_bam_16_attention_concentration_20": 1.2787696843023377,
      "attention_bam_16_attention_center_y": 0.4656462466073568,
      "attention_bam_16_attention_center_x": 0.4731902476095592,
      "attention_bam_16_attention_center_distance": 0.06162699401073023,
      "attention_bam_16_attention_spatial_variance": 43.360079504293466,
      "attention_bam_16_attention_spatial_std": 6.584837090186322,
      "attention_bam_16_num_attention_peaks": 11,
      "attention_bam_16_peak_separation_mean": 9.486675717074272,
      "attention_bam_16_peak_intensity_mean": 0.35833004117012024,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 495,
      "phase": "train",
      "loss": 0.005870684050023556,
      "timestamp": 1759543964.0257993,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005870684050023556,
      "ssim": 0.8961905241012573,
      "attention_bam_384_mean_attention": 0.04332420602440834,
      "attention_bam_384_std_attention": 0.3103293776512146,
      "attention_bam_384_max_attention": 1.872016191482544,
      "attention_bam_384_min_attention": -0.92485511302948,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.27554414206914446,
      "attention_bam_384_attention_skewness": 0.5098278316155127,
      "attention_bam_384_attention_sparsity": 0.5998942057291666,
      "attention_bam_384_attention_concentration_10": 1.4851201773832285,
      "attention_bam_384_attention_concentration_20": 2.3323464011547457,
      "attention_bam_384_attention_center_y": 0.48204365993948034,
      "attention_bam_384_attention_center_x": 0.48712654726333243,
      "attention_bam_384_attention_center_distance": 0.031245989622101483,
      "attention_bam_384_attention_spatial_variance": 173.06705014894172,
      "attention_bam_384_attention_spatial_std": 13.155495055258914,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 19.467674154533167,
      "attention_bam_384_peak_intensity_mean": 0.3474021255970001,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.15239250659942627,
      "attention_bam_16_std_attention": 0.5820981860160828,
      "attention_bam_16_max_attention": 2.795391082763672,
      "attention_bam_16_min_attention": -1.070251226425171,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.10017055734479063,
      "attention_bam_16_attention_skewness": 0.6190452782049846,
      "attention_bam_16_attention_sparsity": 0.5126953125,
      "attention_bam_16_attention_concentration_10": 0.8565639909090292,
      "attention_bam_16_attention_concentration_20": 1.3652989061556466,
      "attention_bam_16_attention_center_y": 0.4627429491212127,
      "attention_bam_16_attention_center_x": 0.47440048047425365,
      "attention_bam_16_attention_center_distance": 0.06392844812966465,
      "attention_bam_16_attention_spatial_variance": 44.28702880085474,
      "attention_bam_16_attention_spatial_std": 6.654850020913675,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 10.570079457726157,
      "attention_bam_16_peak_intensity_mean": 0.32013359665870667,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 496,
      "phase": "train",
      "loss": 0.004407546482980251,
      "timestamp": 1759543964.2113419,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004407546482980251,
      "ssim": 0.8984479904174805,
      "attention_bam_384_mean_attention": 0.04236902296543121,
      "attention_bam_384_std_attention": 0.29413676261901855,
      "attention_bam_384_max_attention": 3.1073968410491943,
      "attention_bam_384_min_attention": -0.9889864921569824,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.3623943149394835,
      "attention_bam_384_attention_skewness": 0.7496117113676858,
      "attention_bam_384_attention_sparsity": 0.6277542114257812,
      "attention_bam_384_attention_concentration_10": 1.500886692876752,
      "attention_bam_384_attention_concentration_20": 2.289774303923908,
      "attention_bam_384_attention_center_y": 0.4831776029785421,
      "attention_bam_384_attention_center_x": 0.48670577982528473,
      "attention_bam_384_attention_center_distance": 0.03032257679028487,
      "attention_bam_384_attention_spatial_variance": 170.94917236996588,
      "attention_bam_384_attention_spatial_std": 13.07475324317694,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 19.936663888707514,
      "attention_bam_384_peak_intensity_mean": 0.2538839876651764,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14314983785152435,
      "attention_bam_16_std_attention": 0.5599817633628845,
      "attention_bam_16_max_attention": 4.307660102844238,
      "attention_bam_16_min_attention": -1.0783354043960571,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.2303853280354051,
      "attention_bam_16_attention_skewness": 0.8817829368652987,
      "attention_bam_16_attention_sparsity": 0.52734375,
      "attention_bam_16_attention_concentration_10": 0.9037154887676903,
      "attention_bam_16_attention_concentration_20": 1.4092204929629395,
      "attention_bam_16_attention_center_y": 0.4641237281959904,
      "attention_bam_16_attention_center_x": 0.47765575637241675,
      "attention_bam_16_attention_center_distance": 0.059772436822401145,
      "attention_bam_16_attention_spatial_variance": 42.88830058692264,
      "attention_bam_16_attention_spatial_std": 6.548915985636298,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 10.368653490040785,
      "attention_bam_16_peak_intensity_mean": 0.22877033054828644,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 497,
      "phase": "train",
      "loss": 0.006212066859006882,
      "timestamp": 1759543964.398609,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006212066859006882,
      "ssim": 0.8847838640213013,
      "attention_bam_384_mean_attention": 0.04238035902380943,
      "attention_bam_384_std_attention": 0.285396933555603,
      "attention_bam_384_max_attention": 2.1675829887390137,
      "attention_bam_384_min_attention": -0.9952189922332764,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5190241073662918,
      "attention_bam_384_attention_skewness": 0.7681438011891846,
      "attention_bam_384_attention_sparsity": 0.6262232462565104,
      "attention_bam_384_attention_concentration_10": 1.444345968896357,
      "attention_bam_384_attention_concentration_20": 2.204345771996896,
      "attention_bam_384_attention_center_y": 0.4872856540060884,
      "attention_bam_384_attention_center_x": 0.47704770089792115,
      "attention_bam_384_attention_center_distance": 0.03710694350452985,
      "attention_bam_384_attention_spatial_variance": 170.29335984262295,
      "attention_bam_384_attention_spatial_std": 13.049649797700432,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 18.154844058328628,
      "attention_bam_384_peak_intensity_mean": 0.3272440433502197,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14567291736602783,
      "attention_bam_16_std_attention": 0.5690136551856995,
      "attention_bam_16_max_attention": 2.843106508255005,
      "attention_bam_16_min_attention": -1.0726162195205688,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.0219016490269075,
      "attention_bam_16_attention_skewness": 0.9176063357185591,
      "attention_bam_16_attention_sparsity": 0.524658203125,
      "attention_bam_16_attention_concentration_10": 0.9093643539540539,
      "attention_bam_16_attention_concentration_20": 1.4118570032488609,
      "attention_bam_16_attention_center_y": 0.4771098999231217,
      "attention_bam_16_attention_center_x": 0.44430560205003833,
      "attention_bam_16_attention_center_distance": 0.0851565927516854,
      "attention_bam_16_attention_spatial_variance": 42.218826798644116,
      "attention_bam_16_attention_spatial_std": 6.497601618954806,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.20300018461851,
      "attention_bam_16_peak_intensity_mean": 0.31301578879356384,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 498,
      "phase": "train",
      "loss": 0.004840695299208164,
      "timestamp": 1759543964.578785,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004840695299208164,
      "ssim": 0.9344547390937805,
      "attention_bam_384_mean_attention": 0.04163765907287598,
      "attention_bam_384_std_attention": 0.32368651032447815,
      "attention_bam_384_max_attention": 2.6748430728912354,
      "attention_bam_384_min_attention": -1.053170919418335,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.485021831104472,
      "attention_bam_384_attention_skewness": 0.780388531231877,
      "attention_bam_384_attention_sparsity": 0.6159184773763021,
      "attention_bam_384_attention_concentration_10": 1.6533958711479948,
      "attention_bam_384_attention_concentration_20": 2.5273742515583226,
      "attention_bam_384_attention_center_y": 0.4834722987543857,
      "attention_bam_384_attention_center_x": 0.4878186857976497,
      "attention_bam_384_attention_center_distance": 0.02903616104655235,
      "attention_bam_384_attention_spatial_variance": 172.56472154036226,
      "attention_bam_384_attention_spatial_std": 13.136389212426764,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 20.52246341666775,
      "attention_bam_384_peak_intensity_mean": 0.29462698101997375,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13059578835964203,
      "attention_bam_16_std_attention": 0.6096668243408203,
      "attention_bam_16_max_attention": 3.266162633895874,
      "attention_bam_16_min_attention": -1.1712665557861328,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7534660231561152,
      "attention_bam_16_attention_skewness": 0.9035601270156682,
      "attention_bam_16_attention_sparsity": 0.550048828125,
      "attention_bam_16_attention_concentration_10": 1.0685125228930106,
      "attention_bam_16_attention_concentration_20": 1.6693331400904363,
      "attention_bam_16_attention_center_y": 0.4660340475386773,
      "attention_bam_16_attention_center_x": 0.4795990770773543,
      "attention_bam_16_attention_center_distance": 0.05603362531017544,
      "attention_bam_16_attention_spatial_variance": 44.002674488206324,
      "attention_bam_16_attention_spatial_std": 6.633451174781218,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 10.467919717694446,
      "attention_bam_16_peak_intensity_mean": 0.2957534193992615,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 499,
      "phase": "train",
      "loss": 0.00782776903361082,
      "timestamp": 1759543964.7522893,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00782776903361082,
      "ssim": 0.9115690588951111,
      "attention_bam_384_mean_attention": 0.04004821926355362,
      "attention_bam_384_std_attention": 0.31574106216430664,
      "attention_bam_384_max_attention": 2.818840980529785,
      "attention_bam_384_min_attention": -1.0583107471466064,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.5617563140278428,
      "attention_bam_384_attention_skewness": 0.9433300658464441,
      "attention_bam_384_attention_sparsity": 0.6124954223632812,
      "attention_bam_384_attention_concentration_10": 1.6626058421712047,
      "attention_bam_384_attention_concentration_20": 2.5078230233843484,
      "attention_bam_384_attention_center_y": 0.47694806936030315,
      "attention_bam_384_attention_center_x": 0.4820000629894548,
      "attention_bam_384_attention_center_distance": 0.041361557963911104,
      "attention_bam_384_attention_spatial_variance": 168.7294315267632,
      "attention_bam_384_attention_spatial_std": 12.989589351737152,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 18.63541316309807,
      "attention_bam_384_peak_intensity_mean": 0.2838922441005707,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13058221340179443,
      "attention_bam_16_std_attention": 0.610530436038971,
      "attention_bam_16_max_attention": 3.439121961593628,
      "attention_bam_16_min_attention": -1.0790847539901733,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.001686954134054,
      "attention_bam_16_attention_skewness": 1.160495511997677,
      "attention_bam_16_attention_sparsity": 0.551025390625,
      "attention_bam_16_attention_concentration_10": 1.0850031905862765,
      "attention_bam_16_attention_concentration_20": 1.6502164043426972,
      "attention_bam_16_attention_center_y": 0.44294547348118274,
      "attention_bam_16_attention_center_x": 0.4622994206808123,
      "attention_bam_16_attention_center_distance": 0.09671145410228081,
      "attention_bam_16_attention_spatial_variance": 40.89833835934981,
      "attention_bam_16_attention_spatial_std": 6.395180869948074,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.434308263953001,
      "attention_bam_16_peak_intensity_mean": 0.26772868633270264,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 500,
      "phase": "train",
      "loss": 0.008344930596649647,
      "timestamp": 1759543964.9555776,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008344930596649647,
      "ssim": 0.8694294691085815,
      "attention_bam_384_mean_attention": 0.04224781692028046,
      "attention_bam_384_std_attention": 0.3128359019756317,
      "attention_bam_384_max_attention": 2.5804994106292725,
      "attention_bam_384_min_attention": -1.0463600158691406,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1708974977389994,
      "attention_bam_384_attention_skewness": 0.7347342572421559,
      "attention_bam_384_attention_sparsity": 0.6157735188802084,
      "attention_bam_384_attention_concentration_10": 1.5788579042361242,
      "attention_bam_384_attention_concentration_20": 2.4242957794071636,
      "attention_bam_384_attention_center_y": 0.49351331839694557,
      "attention_bam_384_attention_center_x": 0.4779712869942941,
      "attention_bam_384_attention_center_distance": 0.03247587519704932,
      "attention_bam_384_attention_spatial_variance": 172.1982362018447,
      "attention_bam_384_attention_spatial_std": 13.122432556574436,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 17.747679850897658,
      "attention_bam_384_peak_intensity_mean": 0.30261901021003723,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13186025619506836,
      "attention_bam_16_std_attention": 0.6031917929649353,
      "attention_bam_16_max_attention": 3.0575804710388184,
      "attention_bam_16_min_attention": -1.1385997533798218,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.9479072398998296,
      "attention_bam_16_attention_skewness": 0.9172515197406206,
      "attention_bam_16_attention_sparsity": 0.548095703125,
      "attention_bam_16_attention_concentration_10": 1.0410784640588928,
      "attention_bam_16_attention_concentration_20": 1.6269974026118943,
      "attention_bam_16_attention_center_y": 0.4968208436254387,
      "attention_bam_16_attention_center_x": 0.4486668873603463,
      "attention_bam_16_attention_center_distance": 0.07273507391251191,
      "attention_bam_16_attention_spatial_variance": 43.54796217848505,
      "attention_bam_16_attention_spatial_std": 6.599087980811064,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.618417021964625,
      "attention_bam_16_peak_intensity_mean": 0.3118155598640442,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 501,
      "phase": "train",
      "loss": 0.00574466772377491,
      "timestamp": 1759543967.5820541,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00574466772377491,
      "ssim": 0.894005298614502,
      "attention_bam_384_mean_attention": 0.04209393635392189,
      "attention_bam_384_std_attention": 0.29444727301597595,
      "attention_bam_384_max_attention": 2.0574638843536377,
      "attention_bam_384_min_attention": -1.128088355064392,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6141501282050039,
      "attention_bam_384_attention_skewness": 0.5447040193094672,
      "attention_bam_384_attention_sparsity": 0.6083780924479166,
      "attention_bam_384_attention_concentration_10": 1.453182906295079,
      "attention_bam_384_attention_concentration_20": 2.278710017864892,
      "attention_bam_384_attention_center_y": 0.48013369423392194,
      "attention_bam_384_attention_center_x": 0.4847463791965401,
      "attention_bam_384_attention_center_distance": 0.03542154859423993,
      "attention_bam_384_attention_spatial_variance": 170.69277946494302,
      "attention_bam_384_attention_spatial_std": 13.064944678985174,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 16.948440844204804,
      "attention_bam_384_peak_intensity_mean": 0.3687754273414612,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1454503983259201,
      "attention_bam_16_std_attention": 0.5648658275604248,
      "attention_bam_16_max_attention": 2.612816095352173,
      "attention_bam_16_min_attention": -1.186554193496704,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.31580662654367764,
      "attention_bam_16_attention_skewness": 0.6658322810392352,
      "attention_bam_16_attention_sparsity": 0.51953125,
      "attention_bam_16_attention_concentration_10": 0.8610913357088644,
      "attention_bam_16_attention_concentration_20": 1.3882911308851658,
      "attention_bam_16_attention_center_y": 0.4547170584553271,
      "attention_bam_16_attention_center_x": 0.4711909622753424,
      "attention_bam_16_attention_center_distance": 0.07590132343456213,
      "attention_bam_16_attention_spatial_variance": 42.54967081764751,
      "attention_bam_16_attention_spatial_std": 6.523010870575605,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.895214742066859,
      "attention_bam_16_peak_intensity_mean": 0.3499734103679657,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 502,
      "phase": "train",
      "loss": 0.005205304827541113,
      "timestamp": 1759543967.7169876,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005205304827541113,
      "ssim": 0.9145870208740234,
      "attention_bam_384_mean_attention": 0.04110821336507797,
      "attention_bam_384_std_attention": 0.2880333662033081,
      "attention_bam_384_max_attention": 2.380831241607666,
      "attention_bam_384_min_attention": -0.9346134662628174,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9784613335404413,
      "attention_bam_384_attention_skewness": 0.6046145197433725,
      "attention_bam_384_attention_sparsity": 0.6026382446289062,
      "attention_bam_384_attention_concentration_10": 1.4423981895495601,
      "attention_bam_384_attention_concentration_20": 2.257475780028186,
      "attention_bam_384_attention_center_y": 0.4814549620406576,
      "attention_bam_384_attention_center_x": 0.47847124357527604,
      "attention_bam_384_attention_center_distance": 0.04018471814281008,
      "attention_bam_384_attention_spatial_variance": 168.58739936321197,
      "attention_bam_384_attention_spatial_std": 12.984121047002448,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 16.438431067575223,
      "attention_bam_384_peak_intensity_mean": 0.2974148392677307,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13608777523040771,
      "attention_bam_16_std_attention": 0.5693738460540771,
      "attention_bam_16_max_attention": 2.932203531265259,
      "attention_bam_16_min_attention": -1.0965772867202759,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6300023162528787,
      "attention_bam_16_attention_skewness": 0.7630396087253007,
      "attention_bam_16_attention_sparsity": 0.52978515625,
      "attention_bam_16_attention_concentration_10": 0.9326091659951455,
      "attention_bam_16_attention_concentration_20": 1.4834137695765803,
      "attention_bam_16_attention_center_y": 0.4603502867571565,
      "attention_bam_16_attention_center_x": 0.451142108913376,
      "attention_bam_16_attention_center_distance": 0.08898531656034189,
      "attention_bam_16_attention_spatial_variance": 40.963155962843985,
      "attention_bam_16_attention_spatial_std": 6.400246554848023,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 6.639802496319172,
      "attention_bam_16_peak_intensity_mean": 0.32213160395622253,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 503,
      "phase": "train",
      "loss": 0.005630164872854948,
      "timestamp": 1759543967.8491907,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005630164872854948,
      "ssim": 0.8958464860916138,
      "attention_bam_384_mean_attention": 0.040701936930418015,
      "attention_bam_384_std_attention": 0.2828708291053772,
      "attention_bam_384_max_attention": 2.0551273822784424,
      "attention_bam_384_min_attention": -0.9793183207511902,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9358527634707685,
      "attention_bam_384_attention_skewness": 0.5813357478593553,
      "attention_bam_384_attention_sparsity": 0.6115086873372396,
      "attention_bam_384_attention_concentration_10": 1.4402555311666732,
      "attention_bam_384_attention_concentration_20": 2.2404156896747707,
      "attention_bam_384_attention_center_y": 0.4849577970622355,
      "attention_bam_384_attention_center_x": 0.48195440526644057,
      "attention_bam_384_attention_center_distance": 0.033223827549177964,
      "attention_bam_384_attention_spatial_variance": 172.01407209950725,
      "attention_bam_384_attention_spatial_std": 13.115413531395312,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 17.417586635039036,
      "attention_bam_384_peak_intensity_mean": 0.3399762511253357,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13901902735233307,
      "attention_bam_16_std_attention": 0.5532063841819763,
      "attention_bam_16_max_attention": 2.387819766998291,
      "attention_bam_16_min_attention": -1.0815234184265137,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5950270891159701,
      "attention_bam_16_attention_skewness": 0.7421085199593016,
      "attention_bam_16_attention_sparsity": 0.519287109375,
      "attention_bam_16_attention_concentration_10": 0.9035225060721388,
      "attention_bam_16_attention_concentration_20": 1.4137147379612554,
      "attention_bam_16_attention_center_y": 0.4703031921096417,
      "attention_bam_16_attention_center_x": 0.4629082311094421,
      "attention_bam_16_attention_center_distance": 0.06719672191866806,
      "attention_bam_16_attention_spatial_variance": 44.012779587314675,
      "attention_bam_16_attention_spatial_std": 6.634212808413269,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.06811761259234,
      "attention_bam_16_peak_intensity_mean": 0.3677377998828888,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 504,
      "phase": "train",
      "loss": 0.00535485427826643,
      "timestamp": 1759543967.984823,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00535485427826643,
      "ssim": 0.8908030986785889,
      "attention_bam_384_mean_attention": 0.04045231640338898,
      "attention_bam_384_std_attention": 0.2624918818473816,
      "attention_bam_384_max_attention": 1.517279028892517,
      "attention_bam_384_min_attention": -0.7639082670211792,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.030547165767094597,
      "attention_bam_384_attention_skewness": 0.3877591691931938,
      "attention_bam_384_attention_sparsity": 0.6002833048502604,
      "attention_bam_384_attention_concentration_10": 1.3108031100194395,
      "attention_bam_384_attention_concentration_20": 2.0987280772990466,
      "attention_bam_384_attention_center_y": 0.48945151532946596,
      "attention_bam_384_attention_center_x": 0.4804601552973889,
      "attention_bam_384_attention_center_distance": 0.03140305908177262,
      "attention_bam_384_attention_spatial_variance": 172.97469712723398,
      "attention_bam_384_attention_spatial_std": 13.151984531896089,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 18.031120080439333,
      "attention_bam_384_peak_intensity_mean": 0.3568239212036133,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1432294249534607,
      "attention_bam_16_std_attention": 0.5146234631538391,
      "attention_bam_16_max_attention": 2.036496639251709,
      "attention_bam_16_min_attention": -0.9680842161178589,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.18753948426497935,
      "attention_bam_16_attention_skewness": 0.48371678285715386,
      "attention_bam_16_attention_sparsity": 0.500732421875,
      "attention_bam_16_attention_concentration_10": 0.7897364159781091,
      "attention_bam_16_attention_concentration_20": 1.2812621853130202,
      "attention_bam_16_attention_center_y": 0.48284723590355066,
      "attention_bam_16_attention_center_x": 0.4605677118702032,
      "attention_bam_16_attention_center_distance": 0.06081320026605666,
      "attention_bam_16_attention_spatial_variance": 44.21746367118779,
      "attention_bam_16_attention_spatial_std": 6.649621317878769,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.95864677660542,
      "attention_bam_16_peak_intensity_mean": 0.38031986355781555,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 505,
      "phase": "train",
      "loss": 0.0066321543417871,
      "timestamp": 1759543968.1194992,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0066321543417871,
      "ssim": 0.8873618841171265,
      "attention_bam_384_mean_attention": 0.03985342010855675,
      "attention_bam_384_std_attention": 0.23726560175418854,
      "attention_bam_384_max_attention": 1.9413208961486816,
      "attention_bam_384_min_attention": -0.8802554607391357,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4891972502369253,
      "attention_bam_384_attention_skewness": 0.6014705941299923,
      "attention_bam_384_attention_sparsity": 0.6330083211263021,
      "attention_bam_384_attention_concentration_10": 1.2456911545288754,
      "attention_bam_384_attention_concentration_20": 1.9315368141757285,
      "attention_bam_384_attention_center_y": 0.4873174840572802,
      "attention_bam_384_attention_center_x": 0.4802603798228852,
      "attention_bam_384_attention_center_distance": 0.033181284344464386,
      "attention_bam_384_attention_spatial_variance": 172.99921177467363,
      "attention_bam_384_attention_spatial_std": 13.152916474100854,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 18.255241341478673,
      "attention_bam_384_peak_intensity_mean": 0.32942962646484375,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13772255182266235,
      "attention_bam_16_std_attention": 0.4869934022426605,
      "attention_bam_16_max_attention": 2.5990562438964844,
      "attention_bam_16_min_attention": -1.0184352397918701,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.2231668320293476,
      "attention_bam_16_attention_skewness": 0.7760359781622932,
      "attention_bam_16_attention_sparsity": 0.50634765625,
      "attention_bam_16_attention_concentration_10": 0.806295039674515,
      "attention_bam_16_attention_concentration_20": 1.2492031293801191,
      "attention_bam_16_attention_center_y": 0.47649434519559614,
      "attention_bam_16_attention_center_x": 0.45744765126601267,
      "attention_bam_16_attention_center_distance": 0.06874908276570194,
      "attention_bam_16_attention_spatial_variance": 44.60541673056002,
      "attention_bam_16_attention_spatial_std": 6.678728676219751,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 10.652581581851384,
      "attention_bam_16_peak_intensity_mean": 0.32305461168289185,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 506,
      "phase": "train",
      "loss": 0.004467520397156477,
      "timestamp": 1759543968.250938,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004467520397156477,
      "ssim": 0.9133530855178833,
      "attention_bam_384_mean_attention": 0.03612968698143959,
      "attention_bam_384_std_attention": 0.2865198254585266,
      "attention_bam_384_max_attention": 3.1615591049194336,
      "attention_bam_384_min_attention": -0.9903038144111633,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.660151477137841,
      "attention_bam_384_attention_skewness": 1.1210947500402646,
      "attention_bam_384_attention_sparsity": 0.6370722452799479,
      "attention_bam_384_attention_concentration_10": 1.6905249985999666,
      "attention_bam_384_attention_concentration_20": 2.5365913344287176,
      "attention_bam_384_attention_center_y": 0.47805611997952546,
      "attention_bam_384_attention_center_x": 0.4751528360446799,
      "attention_bam_384_attention_center_distance": 0.046881028721126414,
      "attention_bam_384_attention_spatial_variance": 170.2357826561127,
      "attention_bam_384_attention_spatial_std": 13.047443529523807,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 18.307121531628415,
      "attention_bam_384_peak_intensity_mean": 0.2499295175075531,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12753820419311523,
      "attention_bam_16_std_attention": 0.5530248284339905,
      "attention_bam_16_max_attention": 4.299389839172363,
      "attention_bam_16_min_attention": -0.8650423884391785,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.516162275338208,
      "attention_bam_16_attention_skewness": 1.3061619412342345,
      "attention_bam_16_attention_sparsity": 0.54345703125,
      "attention_bam_16_attention_concentration_10": 0.9999381932906874,
      "attention_bam_16_attention_concentration_20": 1.5240048304732812,
      "attention_bam_16_attention_center_y": 0.44676349122932074,
      "attention_bam_16_attention_center_x": 0.43593822897788814,
      "attention_bam_16_attention_center_distance": 0.11779674335549432,
      "attention_bam_16_attention_spatial_variance": 41.87318080817339,
      "attention_bam_16_attention_spatial_std": 6.470948988222159,
      "attention_bam_16_num_attention_peaks": 2,
      "attention_bam_16_peak_separation_mean": 5.166236541235795,
      "attention_bam_16_peak_intensity_mean": 0.2154088020324707,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 507,
      "phase": "train",
      "loss": 0.003983645234256983,
      "timestamp": 1759543968.3796296,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.003983645234256983,
      "ssim": 0.9323855638504028,
      "attention_bam_384_mean_attention": 0.03934592381119728,
      "attention_bam_384_std_attention": 0.2636426091194153,
      "attention_bam_384_max_attention": 1.8290938138961792,
      "attention_bam_384_min_attention": -0.9124823808670044,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7631702735013794,
      "attention_bam_384_attention_skewness": 0.5917890319831604,
      "attention_bam_384_attention_sparsity": 0.6236470540364584,
      "attention_bam_384_attention_concentration_10": 1.4119111301416722,
      "attention_bam_384_attention_concentration_20": 2.1910906696684305,
      "attention_bam_384_attention_center_y": 0.4886677869930415,
      "attention_bam_384_attention_center_x": 0.4824733381135969,
      "attention_bam_384_attention_center_distance": 0.02951619652039793,
      "attention_bam_384_attention_spatial_variance": 170.2605066604707,
      "attention_bam_384_attention_spatial_std": 13.048390960592448,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 15.533128864131843,
      "attention_bam_384_peak_intensity_mean": 0.34812891483306885,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1367286592721939,
      "attention_bam_16_std_attention": 0.5241044759750366,
      "attention_bam_16_max_attention": 2.451368808746338,
      "attention_bam_16_min_attention": -0.9554489850997925,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.30177601981506763,
      "attention_bam_16_attention_skewness": 0.6719629863747826,
      "attention_bam_16_attention_sparsity": 0.5234375,
      "attention_bam_16_attention_concentration_10": 0.8609967299361667,
      "attention_bam_16_attention_concentration_20": 1.37936790685555,
      "attention_bam_16_attention_center_y": 0.48287004650981297,
      "attention_bam_16_attention_center_x": 0.4644148347879552,
      "attention_bam_16_attention_center_distance": 0.05585229251775605,
      "attention_bam_16_attention_spatial_variance": 42.24765686384765,
      "attention_bam_16_attention_spatial_std": 6.49981975625845,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.153765851595466,
      "attention_bam_16_peak_intensity_mean": 0.31848809123039246,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 508,
      "phase": "train",
      "loss": 0.008322315290570259,
      "timestamp": 1759543968.5150535,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008322315290570259,
      "ssim": 0.8838673830032349,
      "attention_bam_384_mean_attention": 0.03999732807278633,
      "attention_bam_384_std_attention": 0.23972047865390778,
      "attention_bam_384_max_attention": 2.023902416229248,
      "attention_bam_384_min_attention": -0.8010561466217041,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.4481206904669697,
      "attention_bam_384_attention_skewness": 0.3188297908192176,
      "attention_bam_384_attention_sparsity": 0.6164703369140625,
      "attention_bam_384_attention_concentration_10": 1.202692298043352,
      "attention_bam_384_attention_concentration_20": 1.9293344721879968,
      "attention_bam_384_attention_center_y": 0.4825690041726436,
      "attention_bam_384_attention_center_x": 0.49638125421331464,
      "attention_bam_384_attention_center_distance": 0.025176772493787587,
      "attention_bam_384_attention_spatial_variance": 168.40063772700822,
      "attention_bam_384_attention_spatial_std": 12.9769271296023,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 13.431050612905219,
      "attention_bam_384_peak_intensity_mean": 0.29995182156562805,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.15129724144935608,
      "attention_bam_16_std_attention": 0.4846700131893158,
      "attention_bam_16_max_attention": 2.2777013778686523,
      "attention_bam_16_min_attention": -1.0234485864639282,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.026571610916470867,
      "attention_bam_16_attention_skewness": 0.43844905759706554,
      "attention_bam_16_attention_sparsity": 0.48291015625,
      "attention_bam_16_attention_concentration_10": 0.7015006619353451,
      "attention_bam_16_attention_concentration_20": 1.140237847730125,
      "attention_bam_16_attention_center_y": 0.4625596424867557,
      "attention_bam_16_attention_center_x": 0.5046730841662552,
      "attention_bam_16_attention_center_distance": 0.05335949936692539,
      "attention_bam_16_attention_spatial_variance": 41.08578082523028,
      "attention_bam_16_attention_spatial_std": 6.409819094579057,
      "attention_bam_16_num_attention_peaks": 2,
      "attention_bam_16_peak_separation_mean": 5.609848482802366,
      "attention_bam_16_peak_intensity_mean": 0.36146384477615356,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 509,
      "phase": "train",
      "loss": 0.0033841587137430906,
      "timestamp": 1759543968.673709,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0033841587137430906,
      "ssim": 0.9338296055793762,
      "attention_bam_384_mean_attention": 0.03638187423348427,
      "attention_bam_384_std_attention": 0.28583526611328125,
      "attention_bam_384_max_attention": 3.3344268798828125,
      "attention_bam_384_min_attention": -1.0620163679122925,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 5.073238319503343,
      "attention_bam_384_attention_skewness": 1.298525789722381,
      "attention_bam_384_attention_sparsity": 0.6426213582356771,
      "attention_bam_384_attention_concentration_10": 1.6891064528902178,
      "attention_bam_384_attention_concentration_20": 2.4877722984009534,
      "attention_bam_384_attention_center_y": 0.4842115925092947,
      "attention_bam_384_attention_center_x": 0.47959649929120207,
      "attention_bam_384_attention_center_distance": 0.0364849736814069,
      "attention_bam_384_attention_spatial_variance": 170.43587888500755,
      "attention_bam_384_attention_spatial_std": 13.055109301917298,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 21.799906558284537,
      "attention_bam_384_peak_intensity_mean": 0.2536717653274536,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1362379491329193,
      "attention_bam_16_std_attention": 0.5698172450065613,
      "attention_bam_16_max_attention": 3.8155555725097656,
      "attention_bam_16_min_attention": -1.042616367340088,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 4.2752378338460515,
      "attention_bam_16_attention_skewness": 1.4697137842285146,
      "attention_bam_16_attention_sparsity": 0.540283203125,
      "attention_bam_16_attention_concentration_10": 0.9730916459097172,
      "attention_bam_16_attention_concentration_20": 1.4666848376389592,
      "attention_bam_16_attention_center_y": 0.47094920137576485,
      "attention_bam_16_attention_center_x": 0.45331113956255886,
      "attention_bam_16_attention_center_distance": 0.07776629848016066,
      "attention_bam_16_attention_spatial_variance": 42.34261030644799,
      "attention_bam_16_attention_spatial_std": 6.507119970190191,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 10.815511502867096,
      "attention_bam_16_peak_intensity_mean": 0.2532293498516083,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 510,
      "phase": "train",
      "loss": 0.006482052616775036,
      "timestamp": 1759543968.8837132,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006482052616775036,
      "ssim": 0.8640092611312866,
      "attention_bam_384_mean_attention": 0.03735458105802536,
      "attention_bam_384_std_attention": 0.3058669865131378,
      "attention_bam_384_max_attention": 2.663329839706421,
      "attention_bam_384_min_attention": -1.131839394569397,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5906797704835451,
      "attention_bam_384_attention_skewness": 0.7599691607874124,
      "attention_bam_384_attention_sparsity": 0.6177113850911459,
      "attention_bam_384_attention_concentration_10": 1.7321089152588434,
      "attention_bam_384_attention_concentration_20": 2.63108192499213,
      "attention_bam_384_attention_center_y": 0.48749712566299996,
      "attention_bam_384_attention_center_x": 0.48124355643726463,
      "attention_bam_384_attention_center_distance": 0.03187870893900476,
      "attention_bam_384_attention_spatial_variance": 169.79996234522181,
      "attention_bam_384_attention_spatial_std": 13.030731458564473,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 17.28064473917061,
      "attention_bam_384_peak_intensity_mean": 0.30978164076805115,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14083045721054077,
      "attention_bam_16_std_attention": 0.5800075531005859,
      "attention_bam_16_max_attention": 3.136263847351074,
      "attention_bam_16_min_attention": -1.125784158706665,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.070650223579194,
      "attention_bam_16_attention_skewness": 0.9362308196348399,
      "attention_bam_16_attention_sparsity": 0.538818359375,
      "attention_bam_16_attention_concentration_10": 0.9478515013952749,
      "attention_bam_16_attention_concentration_20": 1.491080388319392,
      "attention_bam_16_attention_center_y": 0.48110837488383906,
      "attention_bam_16_attention_center_x": 0.4600440664740333,
      "attention_bam_16_attention_center_distance": 0.06250392185232913,
      "attention_bam_16_attention_spatial_variance": 41.8974946321518,
      "attention_bam_16_attention_spatial_std": 6.472827406331162,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 6.474230455815891,
      "attention_bam_16_peak_intensity_mean": 0.30325451493263245,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 511,
      "phase": "train",
      "loss": 0.0074663287959992886,
      "timestamp": 1759543969.0461752,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0074663287959992886,
      "ssim": 0.8517915606498718,
      "attention_bam_384_mean_attention": 0.03677112236618996,
      "attention_bam_384_std_attention": 0.32809093594551086,
      "attention_bam_384_max_attention": 2.515540361404419,
      "attention_bam_384_min_attention": -1.1003130674362183,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.2183372360999876,
      "attention_bam_384_attention_skewness": 0.932072803965215,
      "attention_bam_384_attention_sparsity": 0.6353912353515625,
      "attention_bam_384_attention_concentration_10": 1.9388341584812048,
      "attention_bam_384_attention_concentration_20": 2.8692682815450548,
      "attention_bam_384_attention_center_y": 0.482260848585692,
      "attention_bam_384_attention_center_x": 0.4807568496891271,
      "attention_bam_384_attention_center_distance": 0.03701287145809127,
      "attention_bam_384_attention_spatial_variance": 172.08340254099377,
      "attention_bam_384_attention_spatial_std": 13.118056355306367,
      "attention_bam_384_num_attention_peaks": 21,
      "attention_bam_384_peak_separation_mean": 18.653709329567267,
      "attention_bam_384_peak_intensity_mean": 0.3185233175754547,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13694307208061218,
      "attention_bam_16_std_attention": 0.6145592927932739,
      "attention_bam_16_max_attention": 3.0702571868896484,
      "attention_bam_16_min_attention": -1.0927674770355225,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.180528099064695,
      "attention_bam_16_attention_skewness": 0.9852704138310533,
      "attention_bam_16_attention_sparsity": 0.549072265625,
      "attention_bam_16_attention_concentration_10": 1.0323809527770722,
      "attention_bam_16_attention_concentration_20": 1.605054311711831,
      "attention_bam_16_attention_center_y": 0.4607275515884267,
      "attention_bam_16_attention_center_x": 0.45528585637848407,
      "attention_bam_16_attention_center_distance": 0.08416269772345987,
      "attention_bam_16_attention_spatial_variance": 43.7586259749233,
      "attention_bam_16_attention_spatial_std": 6.615030307936865,
      "attention_bam_16_num_attention_peaks": 12,
      "attention_bam_16_peak_separation_mean": 9.461120555390282,
      "attention_bam_16_peak_intensity_mean": 0.3033526539802551,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 512,
      "phase": "train",
      "loss": 0.005339013412594795,
      "timestamp": 1759543969.1991842,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005339013412594795,
      "ssim": 0.8930102586746216,
      "attention_bam_384_mean_attention": 0.03748540207743645,
      "attention_bam_384_std_attention": 0.28620532155036926,
      "attention_bam_384_max_attention": 4.503695964813232,
      "attention_bam_384_min_attention": -1.0276854038238525,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 7.737766002466143,
      "attention_bam_384_attention_skewness": 1.5367308905556873,
      "attention_bam_384_attention_sparsity": 0.6460444132486979,
      "attention_bam_384_attention_concentration_10": 1.6454074593242396,
      "attention_bam_384_attention_concentration_20": 2.4140405841737786,
      "attention_bam_384_attention_center_y": 0.483842501781556,
      "attention_bam_384_attention_center_x": 0.4878029438479708,
      "attention_bam_384_attention_center_distance": 0.028629807105699255,
      "attention_bam_384_attention_spatial_variance": 170.1321701737845,
      "attention_bam_384_attention_spatial_std": 13.043472320428501,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 18.09039047423304,
      "attention_bam_384_peak_intensity_mean": 0.19719833135604858,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1332276463508606,
      "attention_bam_16_std_attention": 0.5790430903434753,
      "attention_bam_16_max_attention": 4.260760307312012,
      "attention_bam_16_min_attention": -0.9430310726165771,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 6.899079382445828,
      "attention_bam_16_attention_skewness": 1.7737125528204352,
      "attention_bam_16_attention_sparsity": 0.543701171875,
      "attention_bam_16_attention_concentration_10": 1.0043958251221081,
      "attention_bam_16_attention_concentration_20": 1.4940397657373958,
      "attention_bam_16_attention_center_y": 0.4643952875504727,
      "attention_bam_16_attention_center_x": 0.4838783601143822,
      "attention_bam_16_attention_center_distance": 0.05527391466532955,
      "attention_bam_16_attention_spatial_variance": 42.53438798467004,
      "attention_bam_16_attention_spatial_std": 6.52183930993934,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.678198779258386,
      "attention_bam_16_peak_intensity_mean": 0.22230449318885803,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 513,
      "phase": "train",
      "loss": 0.007695695385336876,
      "timestamp": 1759543969.3500032,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007695695385336876,
      "ssim": 0.8934879302978516,
      "attention_bam_384_mean_attention": 0.038610491901636124,
      "attention_bam_384_std_attention": 0.28952905535697937,
      "attention_bam_384_max_attention": 2.1883840560913086,
      "attention_bam_384_min_attention": -1.1014697551727295,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8758256811525129,
      "attention_bam_384_attention_skewness": 0.6123711906155889,
      "attention_bam_384_attention_sparsity": 0.6178207397460938,
      "attention_bam_384_attention_concentration_10": 1.5663745155935627,
      "attention_bam_384_attention_concentration_20": 2.424370492472113,
      "attention_bam_384_attention_center_y": 0.4822126518345277,
      "attention_bam_384_attention_center_x": 0.48285707491473584,
      "attention_bam_384_attention_center_distance": 0.034936217174694494,
      "attention_bam_384_attention_spatial_variance": 169.05449168321312,
      "attention_bam_384_attention_spatial_std": 13.002095665053888,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 16.397602606851596,
      "attention_bam_384_peak_intensity_mean": 0.3473692536354065,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1371435821056366,
      "attention_bam_16_std_attention": 0.5601193308830261,
      "attention_bam_16_max_attention": 3.2811999320983887,
      "attention_bam_16_min_attention": -1.1249496936798096,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.3702669912110621,
      "attention_bam_16_attention_skewness": 0.6570277008642437,
      "attention_bam_16_attention_sparsity": 0.5146484375,
      "attention_bam_16_attention_concentration_10": 0.9076484073918533,
      "attention_bam_16_attention_concentration_20": 1.4401503767311576,
      "attention_bam_16_attention_center_y": 0.4595752584444972,
      "attention_bam_16_attention_center_x": 0.4629065806996443,
      "attention_bam_16_attention_center_distance": 0.07758970917874607,
      "attention_bam_16_attention_spatial_variance": 41.360326127675364,
      "attention_bam_16_attention_spatial_std": 6.431199431496069,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 7.744652546046129,
      "attention_bam_16_peak_intensity_mean": 0.2930150330066681,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 514,
      "phase": "train",
      "loss": 0.0034229401499032974,
      "timestamp": 1759543969.4986212,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0034229401499032974,
      "ssim": 0.93487548828125,
      "attention_bam_384_mean_attention": 0.03702085092663765,
      "attention_bam_384_std_attention": 0.31308695673942566,
      "attention_bam_384_max_attention": 2.259392738342285,
      "attention_bam_384_min_attention": -1.0024089813232422,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0668175040527634,
      "attention_bam_384_attention_skewness": 0.7535038207546738,
      "attention_bam_384_attention_sparsity": 0.6282018025716146,
      "attention_bam_384_attention_concentration_10": 1.7964569029079072,
      "attention_bam_384_attention_concentration_20": 2.7630822745640096,
      "attention_bam_384_attention_center_y": 0.48358690527173154,
      "attention_bam_384_attention_center_x": 0.48835585823913447,
      "attention_bam_384_attention_center_distance": 0.02845964567264486,
      "attention_bam_384_attention_spatial_variance": 172.13509578188538,
      "attention_bam_384_attention_spatial_std": 13.120026516051155,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 18.84787839032567,
      "attention_bam_384_peak_intensity_mean": 0.32111337780952454,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1303856372833252,
      "attention_bam_16_std_attention": 0.5933355093002319,
      "attention_bam_16_max_attention": 2.667759656906128,
      "attention_bam_16_min_attention": -1.067972183227539,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7893442842845846,
      "attention_bam_16_attention_skewness": 0.9397527580474269,
      "attention_bam_16_attention_sparsity": 0.55517578125,
      "attention_bam_16_attention_concentration_10": 1.0510129562757944,
      "attention_bam_16_attention_concentration_20": 1.63420305202681,
      "attention_bam_16_attention_center_y": 0.4661064538722305,
      "attention_bam_16_attention_center_x": 0.4821802049871696,
      "attention_bam_16_attention_center_distance": 0.05415380990132705,
      "attention_bam_16_attention_spatial_variance": 43.67526149658651,
      "attention_bam_16_attention_spatial_std": 6.6087261629293215,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.25921000573903,
      "attention_bam_16_peak_intensity_mean": 0.32503172755241394,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 515,
      "phase": "train",
      "loss": 0.004510511178523302,
      "timestamp": 1759543969.6397483,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004510511178523302,
      "ssim": 0.9179327487945557,
      "attention_bam_384_mean_attention": 0.038184408098459244,
      "attention_bam_384_std_attention": 0.30964434146881104,
      "attention_bam_384_max_attention": 3.84065842628479,
      "attention_bam_384_min_attention": -1.0553536415100098,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.615105347686951,
      "attention_bam_384_attention_skewness": 0.8621902677159252,
      "attention_bam_384_attention_sparsity": 0.6196517944335938,
      "attention_bam_384_attention_concentration_10": 1.7038307587971642,
      "attention_bam_384_attention_concentration_20": 2.579693079849475,
      "attention_bam_384_attention_center_y": 0.48581921157285257,
      "attention_bam_384_attention_center_x": 0.4829817534572568,
      "attention_bam_384_attention_center_distance": 0.03132779838434578,
      "attention_bam_384_attention_spatial_variance": 170.31198982691026,
      "attention_bam_384_attention_spatial_std": 13.050363589835735,
      "attention_bam_384_num_attention_peaks": 18,
      "attention_bam_384_peak_separation_mean": 18.418423347072476,
      "attention_bam_384_peak_intensity_mean": 0.22653132677078247,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1417485475540161,
      "attention_bam_16_std_attention": 0.5958802700042725,
      "attention_bam_16_max_attention": 3.93397855758667,
      "attention_bam_16_min_attention": -1.174480676651001,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.2789808143707093,
      "attention_bam_16_attention_skewness": 1.0515848877839684,
      "attention_bam_16_attention_sparsity": 0.528076171875,
      "attention_bam_16_attention_concentration_10": 0.9550161133760848,
      "attention_bam_16_attention_concentration_20": 1.4787642348028378,
      "attention_bam_16_attention_center_y": 0.47542194931338977,
      "attention_bam_16_attention_center_x": 0.46385309805622466,
      "attention_bam_16_attention_center_distance": 0.06181713509515774,
      "attention_bam_16_attention_spatial_variance": 42.36153097092514,
      "attention_bam_16_attention_spatial_std": 6.508573651033315,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.73163742384197,
      "attention_bam_16_peak_intensity_mean": 0.26754966378211975,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 516,
      "phase": "train",
      "loss": 0.003925540018826723,
      "timestamp": 1759543969.7781272,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.003925540018826723,
      "ssim": 0.9268591403961182,
      "attention_bam_384_mean_attention": 0.03788461163640022,
      "attention_bam_384_std_attention": 0.2590194046497345,
      "attention_bam_384_max_attention": 2.382833957672119,
      "attention_bam_384_min_attention": -0.8250116109848022,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8015809736127073,
      "attention_bam_384_attention_skewness": 0.73646536591908,
      "attention_bam_384_attention_sparsity": 0.6246871948242188,
      "attention_bam_384_attention_concentration_10": 1.4221207576053951,
      "attention_bam_384_attention_concentration_20": 2.2019608820020933,
      "attention_bam_384_attention_center_y": 0.47852982322597626,
      "attention_bam_384_attention_center_x": 0.4844242124685523,
      "attention_bam_384_attention_center_distance": 0.0375119620369991,
      "attention_bam_384_attention_spatial_variance": 169.56849086538546,
      "attention_bam_384_attention_spatial_std": 13.021846676465879,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 14.007748322454976,
      "attention_bam_384_peak_intensity_mean": 0.2730984389781952,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1468735784292221,
      "attention_bam_16_std_attention": 0.5200604796409607,
      "attention_bam_16_max_attention": 2.6714468002319336,
      "attention_bam_16_min_attention": -0.9317013621330261,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7368491778976791,
      "attention_bam_16_attention_skewness": 0.7853296976813191,
      "attention_bam_16_attention_sparsity": 0.5205078125,
      "attention_bam_16_attention_concentration_10": 0.8116317231131013,
      "attention_bam_16_attention_concentration_20": 1.288504795637171,
      "attention_bam_16_attention_center_y": 0.452003199621019,
      "attention_bam_16_attention_center_x": 0.4696155760355928,
      "attention_bam_16_attention_center_distance": 0.08033562181583703,
      "attention_bam_16_attention_spatial_variance": 41.444494974045035,
      "attention_bam_16_attention_spatial_std": 6.437739896426776,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 6.897016214302924,
      "attention_bam_16_peak_intensity_mean": 0.30596622824668884,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 517,
      "phase": "train",
      "loss": 0.005074966698884964,
      "timestamp": 1759543969.9158397,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005074966698884964,
      "ssim": 0.9231095314025879,
      "attention_bam_384_mean_attention": 0.03719796612858772,
      "attention_bam_384_std_attention": 0.27313414216041565,
      "attention_bam_384_max_attention": 2.20638370513916,
      "attention_bam_384_min_attention": -0.8346570730209351,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7693697980099583,
      "attention_bam_384_attention_skewness": 0.5912371851155133,
      "attention_bam_384_attention_sparsity": 0.6261444091796875,
      "attention_bam_384_attention_concentration_10": 1.5375213005782897,
      "attention_bam_384_attention_concentration_20": 2.386649805354654,
      "attention_bam_384_attention_center_y": 0.48575764689057077,
      "attention_bam_384_attention_center_x": 0.4809215116516326,
      "attention_bam_384_attention_center_distance": 0.03366996702559891,
      "attention_bam_384_attention_spatial_variance": 170.71223615814503,
      "attention_bam_384_attention_spatial_std": 13.065689272217712,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 17.885920465431436,
      "attention_bam_384_peak_intensity_mean": 0.29127758741378784,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1435164362192154,
      "attention_bam_16_std_attention": 0.5274376273155212,
      "attention_bam_16_max_attention": 2.396993637084961,
      "attention_bam_16_min_attention": -1.08890962600708,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.29907169600570427,
      "attention_bam_16_attention_skewness": 0.6394850258951349,
      "attention_bam_16_attention_sparsity": 0.51318359375,
      "attention_bam_16_attention_concentration_10": 0.8289601789870118,
      "attention_bam_16_attention_concentration_20": 1.3189909902202364,
      "attention_bam_16_attention_center_y": 0.47279450983864074,
      "attention_bam_16_attention_center_x": 0.46294451390303715,
      "attention_bam_16_attention_center_distance": 0.06501150274839096,
      "attention_bam_16_attention_spatial_variance": 42.77147551800233,
      "attention_bam_16_attention_spatial_std": 6.539990483020777,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.468047614980048,
      "attention_bam_16_peak_intensity_mean": 0.36178845167160034,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 518,
      "phase": "train",
      "loss": 0.010132252238690853,
      "timestamp": 1759543970.0548692,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.010132252238690853,
      "ssim": 0.9008253812789917,
      "attention_bam_384_mean_attention": 0.038237035274505615,
      "attention_bam_384_std_attention": 0.28632792830467224,
      "attention_bam_384_max_attention": 2.875491142272949,
      "attention_bam_384_min_attention": -1.0323797464370728,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.0838620277233417,
      "attention_bam_384_attention_skewness": 0.8486716090867049,
      "attention_bam_384_attention_sparsity": 0.6308542887369791,
      "attention_bam_384_attention_concentration_10": 1.607944109037331,
      "attention_bam_384_attention_concentration_20": 2.4185916791226254,
      "attention_bam_384_attention_center_y": 0.4860025687574117,
      "attention_bam_384_attention_center_x": 0.483605915886536,
      "attention_bam_384_attention_center_distance": 0.03048586804768134,
      "attention_bam_384_attention_spatial_variance": 169.2287642670089,
      "attention_bam_384_attention_spatial_std": 13.008795650136445,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 17.896739873273408,
      "attention_bam_384_peak_intensity_mean": 0.27463003993034363,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14375218749046326,
      "attention_bam_16_std_attention": 0.5836645364761353,
      "attention_bam_16_max_attention": 3.0635855197906494,
      "attention_bam_16_min_attention": -1.298812985420227,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.5350569632881266,
      "attention_bam_16_attention_skewness": 1.0588607268148191,
      "attention_bam_16_attention_sparsity": 0.546875,
      "attention_bam_16_attention_concentration_10": 0.9607929722572676,
      "attention_bam_16_attention_concentration_20": 1.4663336320527294,
      "attention_bam_16_attention_center_y": 0.47361544626469465,
      "attention_bam_16_attention_center_x": 0.46768732509689315,
      "attention_bam_16_attention_center_distance": 0.05899582417773459,
      "attention_bam_16_attention_spatial_variance": 41.795662751962944,
      "attention_bam_16_attention_spatial_std": 6.464956515860176,
      "attention_bam_16_num_attention_peaks": 2,
      "attention_bam_16_peak_separation_mean": 9.777117641961594,
      "attention_bam_16_peak_intensity_mean": 0.3494586944580078,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 519,
      "phase": "train",
      "loss": 0.004297995939850807,
      "timestamp": 1759543970.192262,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004297995939850807,
      "ssim": 0.9302446842193604,
      "attention_bam_384_mean_attention": 0.037165023386478424,
      "attention_bam_384_std_attention": 0.28585052490234375,
      "attention_bam_384_max_attention": 2.0652449131011963,
      "attention_bam_384_min_attention": -0.8771482706069946,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6691703374744717,
      "attention_bam_384_attention_skewness": 0.571544693258242,
      "attention_bam_384_attention_sparsity": 0.6123733520507812,
      "attention_bam_384_attention_concentration_10": 1.5793730744147996,
      "attention_bam_384_attention_concentration_20": 2.4692136750577753,
      "attention_bam_384_attention_center_y": 0.48595819844701515,
      "attention_bam_384_attention_center_x": 0.48621905270795734,
      "attention_bam_384_attention_center_distance": 0.027823971647464904,
      "attention_bam_384_attention_spatial_variance": 170.84877073119296,
      "attention_bam_384_attention_spatial_std": 13.070913155980838,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 15.750373449574028,
      "attention_bam_384_peak_intensity_mean": 0.3112219274044037,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13961313664913177,
      "attention_bam_16_std_attention": 0.5559907555580139,
      "attention_bam_16_max_attention": 2.7184975147247314,
      "attention_bam_16_min_attention": -1.012669324874878,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.43671099480387454,
      "attention_bam_16_attention_skewness": 0.7193165239369658,
      "attention_bam_16_attention_sparsity": 0.522705078125,
      "attention_bam_16_attention_concentration_10": 0.8943053675585364,
      "attention_bam_16_attention_concentration_20": 1.4255683921640538,
      "attention_bam_16_attention_center_y": 0.4748264534775526,
      "attention_bam_16_attention_center_x": 0.47775005956793415,
      "attention_bam_16_attention_center_distance": 0.0475135200495249,
      "attention_bam_16_attention_spatial_variance": 42.76417503040158,
      "attention_bam_16_attention_spatial_std": 6.539432317135914,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.176189257253657,
      "attention_bam_16_peak_intensity_mean": 0.3105843663215637,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 520,
      "phase": "train",
      "loss": 0.005080357193946838,
      "timestamp": 1759543970.4003527,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005080357193946838,
      "ssim": 0.9114465117454529,
      "attention_bam_384_mean_attention": 0.038018349558115005,
      "attention_bam_384_std_attention": 0.2802612781524658,
      "attention_bam_384_max_attention": 2.455679416656494,
      "attention_bam_384_min_attention": -1.008680820465088,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4721187913045402,
      "attention_bam_384_attention_skewness": 0.6902917468741174,
      "attention_bam_384_attention_sparsity": 0.6238657633463541,
      "attention_bam_384_attention_concentration_10": 1.5485037114061109,
      "attention_bam_384_attention_concentration_20": 2.372699878037713,
      "attention_bam_384_attention_center_y": 0.4862244433970382,
      "attention_bam_384_attention_center_x": 0.4824100181790987,
      "attention_bam_384_attention_center_distance": 0.03159662704090561,
      "attention_bam_384_attention_spatial_variance": 171.09094084933244,
      "attention_bam_384_attention_spatial_std": 13.080173578715707,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 18.65407520344097,
      "attention_bam_384_peak_intensity_mean": 0.30472737550735474,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14849460124969482,
      "attention_bam_16_std_attention": 0.5511244535446167,
      "attention_bam_16_max_attention": 2.6649067401885986,
      "attention_bam_16_min_attention": -0.9998157024383545,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7018533654728993,
      "attention_bam_16_attention_skewness": 0.7443782823655212,
      "attention_bam_16_attention_sparsity": 0.506591796875,
      "attention_bam_16_attention_concentration_10": 0.8511646006845898,
      "attention_bam_16_attention_concentration_20": 1.33050070522505,
      "attention_bam_16_attention_center_y": 0.4758578321287274,
      "attention_bam_16_attention_center_x": 0.4639933931556446,
      "attention_bam_16_attention_center_distance": 0.061307748384175534,
      "attention_bam_16_attention_spatial_variance": 43.13561341189585,
      "attention_bam_16_attention_spatial_std": 6.56777080993969,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.629120420641383,
      "attention_bam_16_peak_intensity_mean": 0.31616538763046265,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 521,
      "phase": "train",
      "loss": 0.004336233250796795,
      "timestamp": 1759543970.5761852,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004336233250796795,
      "ssim": 0.9068984985351562,
      "attention_bam_384_mean_attention": 0.03756597638130188,
      "attention_bam_384_std_attention": 0.25602489709854126,
      "attention_bam_384_max_attention": 2.2637720108032227,
      "attention_bam_384_min_attention": -0.9602563381195068,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4281622770505482,
      "attention_bam_384_attention_skewness": 0.7273326179807343,
      "attention_bam_384_attention_sparsity": 0.6362431844075521,
      "attention_bam_384_attention_concentration_10": 1.452835834314099,
      "attention_bam_384_attention_concentration_20": 2.225743121472294,
      "attention_bam_384_attention_center_y": 0.48777800904287627,
      "attention_bam_384_attention_center_x": 0.4798490759164257,
      "attention_bam_384_attention_center_distance": 0.03332977060761108,
      "attention_bam_384_attention_spatial_variance": 168.56225933398392,
      "attention_bam_384_attention_spatial_std": 12.983152904205662,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 10.462243879099654,
      "attention_bam_384_peak_intensity_mean": 0.31279996037483215,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.15100261569023132,
      "attention_bam_16_std_attention": 0.5301614999771118,
      "attention_bam_16_max_attention": 2.497097969055176,
      "attention_bam_16_min_attention": -1.1465415954589844,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6715070549145388,
      "attention_bam_16_attention_skewness": 0.7749676899950331,
      "attention_bam_16_attention_sparsity": 0.5224609375,
      "attention_bam_16_attention_concentration_10": 0.8129094911121356,
      "attention_bam_16_attention_concentration_20": 1.2843069609509083,
      "attention_bam_16_attention_center_y": 0.48140250068662377,
      "attention_bam_16_attention_center_x": 0.45387359884830275,
      "attention_bam_16_attention_center_distance": 0.07033508177173503,
      "attention_bam_16_attention_spatial_variance": 40.73237971240492,
      "attention_bam_16_attention_spatial_std": 6.382192390738854,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 6.131591924152941,
      "attention_bam_16_peak_intensity_mean": 0.36872562766075134,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 522,
      "phase": "train",
      "loss": 0.0051752193830907345,
      "timestamp": 1759543970.7336643,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0051752193830907345,
      "ssim": 0.9247634410858154,
      "attention_bam_384_mean_attention": 0.038268014788627625,
      "attention_bam_384_std_attention": 0.29192429780960083,
      "attention_bam_384_max_attention": 2.7079555988311768,
      "attention_bam_384_min_attention": -1.1696488857269287,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5646093055252068,
      "attention_bam_384_attention_skewness": 0.7643928932022724,
      "attention_bam_384_attention_sparsity": 0.6206080118815104,
      "attention_bam_384_attention_concentration_10": 1.6105308559327511,
      "attention_bam_384_attention_concentration_20": 2.4708094848503945,
      "attention_bam_384_attention_center_y": 0.4825260364373672,
      "attention_bam_384_attention_center_x": 0.4835055095874754,
      "attention_bam_384_attention_center_distance": 0.033982572491119176,
      "attention_bam_384_attention_spatial_variance": 171.09855534244394,
      "attention_bam_384_attention_spatial_std": 13.080464645510263,
      "attention_bam_384_num_attention_peaks": 25,
      "attention_bam_384_peak_separation_mean": 18.170741923491416,
      "attention_bam_384_peak_intensity_mean": 0.31659919023513794,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13738928735256195,
      "attention_bam_16_std_attention": 0.5762651562690735,
      "attention_bam_16_max_attention": 2.8337998390197754,
      "attention_bam_16_min_attention": -1.077378511428833,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6658634082159982,
      "attention_bam_16_attention_skewness": 0.8222766215449638,
      "attention_bam_16_attention_sparsity": 0.533935546875,
      "attention_bam_16_attention_concentration_10": 0.9527059484069328,
      "attention_bam_16_attention_concentration_20": 1.4979554858449704,
      "attention_bam_16_attention_center_y": 0.4638817110125367,
      "attention_bam_16_attention_center_x": 0.468567143049237,
      "attention_bam_16_attention_center_distance": 0.0677134446837412,
      "attention_bam_16_attention_spatial_variance": 42.94633186022164,
      "attention_bam_16_attention_spatial_std": 6.553345089358689,
      "attention_bam_16_num_attention_peaks": 12,
      "attention_bam_16_peak_separation_mean": 8.579098049739962,
      "attention_bam_16_peak_intensity_mean": 0.31889644265174866,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 523,
      "phase": "train",
      "loss": 0.0033614877611398697,
      "timestamp": 1759543970.8875165,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0033614877611398697,
      "ssim": 0.9358035326004028,
      "attention_bam_384_mean_attention": 0.035540621727705,
      "attention_bam_384_std_attention": 0.31139639019966125,
      "attention_bam_384_max_attention": 2.4056642055511475,
      "attention_bam_384_min_attention": -0.8960630893707275,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.0337483714169036,
      "attention_bam_384_attention_skewness": 0.9943394468512889,
      "attention_bam_384_attention_sparsity": 0.6408259073893229,
      "attention_bam_384_attention_concentration_10": 1.9399978128002904,
      "attention_bam_384_attention_concentration_20": 2.846384955986711,
      "attention_bam_384_attention_center_y": 0.4873390177697042,
      "attention_bam_384_attention_center_x": 0.48612664266443995,
      "attention_bam_384_attention_center_distance": 0.026562022317436772,
      "attention_bam_384_attention_spatial_variance": 174.3865035978967,
      "attention_bam_384_attention_spatial_std": 13.205548212698202,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 20.594732093724343,
      "attention_bam_384_peak_intensity_mean": 0.2861550450325012,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12754786014556885,
      "attention_bam_16_std_attention": 0.6001092791557312,
      "attention_bam_16_max_attention": 3.1361804008483887,
      "attention_bam_16_min_attention": -1.0087331533432007,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.3388064106306947,
      "attention_bam_16_attention_skewness": 1.1389518808575188,
      "attention_bam_16_attention_sparsity": 0.572021484375,
      "attention_bam_16_attention_concentration_10": 1.1259084544935707,
      "attention_bam_16_attention_concentration_20": 1.7076745012753194,
      "attention_bam_16_attention_center_y": 0.47888555449830644,
      "attention_bam_16_attention_center_x": 0.47425672850572237,
      "attention_bam_16_attention_center_distance": 0.04708579055452025,
      "attention_bam_16_attention_spatial_variance": 45.44775543338126,
      "attention_bam_16_attention_spatial_std": 6.741495044378603,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.292149647220004,
      "attention_bam_16_peak_intensity_mean": 0.283913254737854,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 524,
      "phase": "train",
      "loss": 0.00589883653447032,
      "timestamp": 1759543971.029559,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00589883653447032,
      "ssim": 0.8984434604644775,
      "attention_bam_384_mean_attention": 0.039560336619615555,
      "attention_bam_384_std_attention": 0.2618429362773895,
      "attention_bam_384_max_attention": 2.491941213607788,
      "attention_bam_384_min_attention": -0.8765014410018921,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9794560505442775,
      "attention_bam_384_attention_skewness": 0.5189766522554629,
      "attention_bam_384_attention_sparsity": 0.6236368815104166,
      "attention_bam_384_attention_concentration_10": 1.3768946697841842,
      "attention_bam_384_attention_concentration_20": 2.141587328092278,
      "attention_bam_384_attention_center_y": 0.4824779284826531,
      "attention_bam_384_attention_center_x": 0.4857277418008796,
      "attention_bam_384_attention_center_distance": 0.03195998574346929,
      "attention_bam_384_attention_spatial_variance": 169.96447431752102,
      "attention_bam_384_attention_spatial_std": 13.037042391490527,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 18.488167025975983,
      "attention_bam_384_peak_intensity_mean": 0.27471888065338135,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1659446656703949,
      "attention_bam_16_std_attention": 0.5178453326225281,
      "attention_bam_16_max_attention": 2.3954620361328125,
      "attention_bam_16_min_attention": -1.037614345550537,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.16250071862116755,
      "attention_bam_16_attention_skewness": 0.5204548615338989,
      "attention_bam_16_attention_sparsity": 0.486572265625,
      "attention_bam_16_attention_concentration_10": 0.7070002598591177,
      "attention_bam_16_attention_concentration_20": 1.1386147068739574,
      "attention_bam_16_attention_center_y": 0.4724569202166216,
      "attention_bam_16_attention_center_x": 0.47729848473872444,
      "attention_bam_16_attention_center_distance": 0.05047732241534756,
      "attention_bam_16_attention_spatial_variance": 41.976548643937235,
      "attention_bam_16_attention_spatial_std": 6.478931134372184,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.612735719373964,
      "attention_bam_16_peak_intensity_mean": 0.3551196753978729,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 525,
      "phase": "train",
      "loss": 0.00735954474657774,
      "timestamp": 1759543971.1694727,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00735954474657774,
      "ssim": 0.8893337845802307,
      "attention_bam_384_mean_attention": 0.03700830414891243,
      "attention_bam_384_std_attention": 0.2918848991394043,
      "attention_bam_384_max_attention": 2.5201563835144043,
      "attention_bam_384_min_attention": -0.9339861869812012,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.320717008879999,
      "attention_bam_384_attention_skewness": 0.6668097158985479,
      "attention_bam_384_attention_sparsity": 0.6197992960611979,
      "attention_bam_384_attention_concentration_10": 1.6492087514329492,
      "attention_bam_384_attention_concentration_20": 2.5184936937925633,
      "attention_bam_384_attention_center_y": 0.48108332004765386,
      "attention_bam_384_attention_center_x": 0.48817215804964087,
      "attention_bam_384_attention_center_distance": 0.0315511846250555,
      "attention_bam_384_attention_spatial_variance": 170.42558399703333,
      "attention_bam_384_attention_spatial_std": 13.05471501018055,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 20.301475414716247,
      "attention_bam_384_peak_intensity_mean": 0.28519073128700256,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1434580385684967,
      "attention_bam_16_std_attention": 0.5818918347358704,
      "attention_bam_16_max_attention": 2.6482863426208496,
      "attention_bam_16_min_attention": -1.1138643026351929,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8478740172148842,
      "attention_bam_16_attention_skewness": 0.8605840434487051,
      "attention_bam_16_attention_sparsity": 0.53173828125,
      "attention_bam_16_attention_concentration_10": 0.9362216179527907,
      "attention_bam_16_attention_concentration_20": 1.4562752030278672,
      "attention_bam_16_attention_center_y": 0.45732582376199754,
      "attention_bam_16_attention_center_x": 0.4827767818854167,
      "attention_bam_16_attention_center_distance": 0.06508032820775575,
      "attention_bam_16_attention_spatial_variance": 42.488290877246236,
      "attention_bam_16_attention_spatial_std": 6.518304294618827,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 9.514450695443267,
      "attention_bam_16_peak_intensity_mean": 0.3534531593322754,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 526,
      "phase": "train",
      "loss": 0.00466555543243885,
      "timestamp": 1759543971.3091984,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00466555543243885,
      "ssim": 0.909188985824585,
      "attention_bam_384_mean_attention": 0.0360313318669796,
      "attention_bam_384_std_attention": 0.2869051694869995,
      "attention_bam_384_max_attention": 2.7008216381073,
      "attention_bam_384_min_attention": -0.867205023765564,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2597529903467057,
      "attention_bam_384_attention_skewness": 0.6952055867958866,
      "attention_bam_384_attention_sparsity": 0.6255772908528646,
      "attention_bam_384_attention_concentration_10": 1.6559782924473898,
      "attention_bam_384_attention_concentration_20": 2.569090394894676,
      "attention_bam_384_attention_center_y": 0.4788283520069462,
      "attention_bam_384_attention_center_x": 0.48472220748702655,
      "attention_bam_384_attention_center_distance": 0.03692288241216407,
      "attention_bam_384_attention_spatial_variance": 171.03100440106144,
      "attention_bam_384_attention_spatial_std": 13.077882259795025,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 17.656775524516913,
      "attention_bam_384_peak_intensity_mean": 0.2543644309043884,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13460306823253632,
      "attention_bam_16_std_attention": 0.5744391679763794,
      "attention_bam_16_max_attention": 2.885343551635742,
      "attention_bam_16_min_attention": -1.0155874490737915,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8452536191292199,
      "attention_bam_16_attention_skewness": 0.8839261238004589,
      "attention_bam_16_attention_sparsity": 0.545654296875,
      "attention_bam_16_attention_concentration_10": 0.9749940745256127,
      "attention_bam_16_attention_concentration_20": 1.5244747100345775,
      "attention_bam_16_attention_center_y": 0.45143086362456963,
      "attention_bam_16_attention_center_x": 0.4727981096999879,
      "attention_bam_16_attention_center_distance": 0.07872615631604332,
      "attention_bam_16_attention_spatial_variance": 42.87458512790349,
      "attention_bam_16_attention_spatial_std": 6.547868746997262,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 7.535295052476316,
      "attention_bam_16_peak_intensity_mean": 0.2956760823726654,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 527,
      "phase": "train",
      "loss": 0.007574688643217087,
      "timestamp": 1759543971.4410315,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007574688643217087,
      "ssim": 0.9098178148269653,
      "attention_bam_384_mean_attention": 0.03799765929579735,
      "attention_bam_384_std_attention": 0.2608737051486969,
      "attention_bam_384_max_attention": 2.057060718536377,
      "attention_bam_384_min_attention": -0.8690564036369324,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.2841856607091895,
      "attention_bam_384_attention_skewness": 0.37253535594244946,
      "attention_bam_384_attention_sparsity": 0.6095352172851562,
      "attention_bam_384_attention_concentration_10": 1.3763396021841419,
      "attention_bam_384_attention_concentration_20": 2.198177005070072,
      "attention_bam_384_attention_center_y": 0.4813465993792297,
      "attention_bam_384_attention_center_x": 0.48242650709545287,
      "attention_bam_384_attention_center_distance": 0.036242985737522306,
      "attention_bam_384_attention_spatial_variance": 169.75139472691802,
      "attention_bam_384_attention_spatial_std": 13.028867745392077,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 18.485194614238093,
      "attention_bam_384_peak_intensity_mean": 0.31150662899017334,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1544083207845688,
      "attention_bam_16_std_attention": 0.5198863744735718,
      "attention_bam_16_max_attention": 2.194453239440918,
      "attention_bam_16_min_attention": -1.0707948207855225,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.17800312572935884,
      "attention_bam_16_attention_skewness": 0.3876384702923248,
      "attention_bam_16_attention_sparsity": 0.487548828125,
      "attention_bam_16_attention_concentration_10": 0.7289862728404747,
      "attention_bam_16_attention_concentration_20": 1.196843575267983,
      "attention_bam_16_attention_center_y": 0.460313529938405,
      "attention_bam_16_attention_center_x": 0.4635667190375045,
      "attention_bam_16_attention_center_distance": 0.07618923634795154,
      "attention_bam_16_attention_spatial_variance": 41.744781910631,
      "attention_bam_16_attention_spatial_std": 6.461020191164163,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 8.378366504194846,
      "attention_bam_16_peak_intensity_mean": 0.3803821802139282,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 528,
      "phase": "train",
      "loss": 0.004955681506544352,
      "timestamp": 1759543971.7827704,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004955681506544352,
      "ssim": 0.9295921921730042,
      "attention_bam_384_mean_attention": 0.036855440586805344,
      "attention_bam_384_std_attention": 0.3013337254524231,
      "attention_bam_384_max_attention": 2.949769973754883,
      "attention_bam_384_min_attention": -1.0199099779129028,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2109149853745995,
      "attention_bam_384_attention_skewness": 0.6600927886107731,
      "attention_bam_384_attention_sparsity": 0.6152292887369791,
      "attention_bam_384_attention_concentration_10": 1.6779355200406751,
      "attention_bam_384_attention_concentration_20": 2.617881449813422,
      "attention_bam_384_attention_center_y": 0.48020560195916473,
      "attention_bam_384_attention_center_x": 0.484719338300995,
      "attention_bam_384_attention_center_distance": 0.035364298826880795,
      "attention_bam_384_attention_spatial_variance": 172.94590860890457,
      "attention_bam_384_attention_spatial_std": 13.150890031055106,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 22.241549476493834,
      "attention_bam_384_peak_intensity_mean": 0.2687116861343384,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13770395517349243,
      "attention_bam_16_std_attention": 0.5935819149017334,
      "attention_bam_16_max_attention": 3.1753039360046387,
      "attention_bam_16_min_attention": -1.148208498954773,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.823224746951245,
      "attention_bam_16_attention_skewness": 0.8043143232992492,
      "attention_bam_16_attention_sparsity": 0.53369140625,
      "attention_bam_16_attention_concentration_10": 0.9607374878037545,
      "attention_bam_16_attention_concentration_20": 1.5232093257326722,
      "attention_bam_16_attention_center_y": 0.4563657173443299,
      "attention_bam_16_attention_center_x": 0.47061802799623853,
      "attention_bam_16_attention_center_distance": 0.07439423232623259,
      "attention_bam_16_attention_spatial_variance": 44.5422329553932,
      "attention_bam_16_attention_spatial_std": 6.673996775200989,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 10.848290094151093,
      "attention_bam_16_peak_intensity_mean": 0.30109062790870667,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 529,
      "phase": "train",
      "loss": 0.004394744522869587,
      "timestamp": 1759543971.9168544,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004394744522869587,
      "ssim": 0.9206101298332214,
      "attention_bam_384_mean_attention": 0.03573233634233475,
      "attention_bam_384_std_attention": 0.30361777544021606,
      "attention_bam_384_max_attention": 2.6292331218719482,
      "attention_bam_384_min_attention": -1.096983551979065,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.7768605212792616,
      "attention_bam_384_attention_skewness": 0.8402467561020194,
      "attention_bam_384_attention_sparsity": 0.6408665974934896,
      "attention_bam_384_attention_concentration_10": 1.823991385997572,
      "attention_bam_384_attention_concentration_20": 2.7645803138333056,
      "attention_bam_384_attention_center_y": 0.48955609257208416,
      "attention_bam_384_attention_center_x": 0.4914772648533897,
      "attention_bam_384_attention_center_distance": 0.0190636941195636,
      "attention_bam_384_attention_spatial_variance": 170.94363513656523,
      "attention_bam_384_attention_spatial_std": 13.074541488578681,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 17.370607598511402,
      "attention_bam_384_peak_intensity_mean": 0.30810433626174927,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13938483595848083,
      "attention_bam_16_std_attention": 0.6140041351318359,
      "attention_bam_16_max_attention": 3.065896987915039,
      "attention_bam_16_min_attention": -1.1732372045516968,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.2679941202000595,
      "attention_bam_16_attention_skewness": 1.0462196484672173,
      "attention_bam_16_attention_sparsity": 0.553466796875,
      "attention_bam_16_attention_concentration_10": 1.0337620716097538,
      "attention_bam_16_attention_concentration_20": 1.5958408194411966,
      "attention_bam_16_attention_center_y": 0.4887897330427258,
      "attention_bam_16_attention_center_x": 0.4968384247641942,
      "attention_bam_16_attention_center_distance": 0.01647213666923715,
      "attention_bam_16_attention_spatial_variance": 42.73324812762904,
      "attention_bam_16_attention_spatial_std": 6.53706724209175,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.758760563489314,
      "attention_bam_16_peak_intensity_mean": 0.34656330943107605,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 530,
      "phase": "train",
      "loss": 0.0044080642983317375,
      "timestamp": 1759543972.1082053,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0044080642983317375,
      "ssim": 0.918074905872345,
      "attention_bam_384_mean_attention": 0.035675108432769775,
      "attention_bam_384_std_attention": 0.2561062276363373,
      "attention_bam_384_max_attention": 2.0655157566070557,
      "attention_bam_384_min_attention": -0.8970534205436707,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5534768715855276,
      "attention_bam_384_attention_skewness": 0.45441095786765895,
      "attention_bam_384_attention_sparsity": 0.6229273478190104,
      "attention_bam_384_attention_concentration_10": 1.460862102475753,
      "attention_bam_384_attention_concentration_20": 2.3009869474422873,
      "attention_bam_384_attention_center_y": 0.47736183460689163,
      "attention_bam_384_attention_center_x": 0.4840185382671436,
      "attention_bam_384_attention_center_distance": 0.039189122253107,
      "attention_bam_384_attention_spatial_variance": 171.9190190127984,
      "attention_bam_384_attention_spatial_std": 13.111789313926547,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 18.62453145705516,
      "attention_bam_384_peak_intensity_mean": 0.31872838735580444,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.15439091622829437,
      "attention_bam_16_std_attention": 0.5132768750190735,
      "attention_bam_16_max_attention": 2.1838674545288086,
      "attention_bam_16_min_attention": -0.9630370140075684,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.0027219728832807988,
      "attention_bam_16_attention_skewness": 0.48227881987339855,
      "attention_bam_16_attention_sparsity": 0.4912109375,
      "attention_bam_16_attention_concentration_10": 0.7365277228459657,
      "attention_bam_16_attention_concentration_20": 1.1922294365441657,
      "attention_bam_16_attention_center_y": 0.44426729517872476,
      "attention_bam_16_attention_center_x": 0.4674764401222112,
      "attention_bam_16_attention_center_distance": 0.09125695955727992,
      "attention_bam_16_attention_spatial_variance": 43.57088207341999,
      "attention_bam_16_attention_spatial_std": 6.600824348020479,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 9.298356282403649,
      "attention_bam_16_peak_intensity_mean": 0.36962729692459106,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 531,
      "phase": "train",
      "loss": 0.004314960911870003,
      "timestamp": 1759543972.2567692,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004314960911870003,
      "ssim": 0.9185063242912292,
      "attention_bam_384_mean_attention": 0.03396815434098244,
      "attention_bam_384_std_attention": 0.2592674791812897,
      "attention_bam_384_max_attention": 2.5560789108276367,
      "attention_bam_384_min_attention": -0.8574444055557251,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.1836708469959634,
      "attention_bam_384_attention_skewness": 0.905286930664619,
      "attention_bam_384_attention_sparsity": 0.6604461669921875,
      "attention_bam_384_attention_concentration_10": 1.667369188818896,
      "attention_bam_384_attention_concentration_20": 2.482698375257858,
      "attention_bam_384_attention_center_y": 0.4892723012974318,
      "attention_bam_384_attention_center_x": 0.4866364525824655,
      "attention_bam_384_attention_center_distance": 0.02423501264838851,
      "attention_bam_384_attention_spatial_variance": 171.95727183839216,
      "attention_bam_384_attention_spatial_std": 13.113247951533294,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 16.775510172943402,
      "attention_bam_384_peak_intensity_mean": 0.2625790238380432,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.128524050116539,
      "attention_bam_16_std_attention": 0.5302460789680481,
      "attention_bam_16_max_attention": 2.5852510929107666,
      "attention_bam_16_min_attention": -1.0536051988601685,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.1280931399416243,
      "attention_bam_16_attention_skewness": 0.9577565989143603,
      "attention_bam_16_attention_sparsity": 0.545654296875,
      "attention_bam_16_attention_concentration_10": 0.971247937542412,
      "attention_bam_16_attention_concentration_20": 1.4905032438170067,
      "attention_bam_16_attention_center_y": 0.48179119957851835,
      "attention_bam_16_attention_center_x": 0.476325960427627,
      "attention_bam_16_attention_center_distance": 0.04223791099151647,
      "attention_bam_16_attention_spatial_variance": 43.93684721468067,
      "attention_bam_16_attention_spatial_std": 6.628487551069298,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.662122284021738,
      "attention_bam_16_peak_intensity_mean": 0.33338621258735657,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 532,
      "phase": "train",
      "loss": 0.008319149725139141,
      "timestamp": 1759543972.4158666,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008319149725139141,
      "ssim": 0.8924135565757751,
      "attention_bam_384_mean_attention": 0.03436567261815071,
      "attention_bam_384_std_attention": 0.26728036999702454,
      "attention_bam_384_max_attention": 2.7055482864379883,
      "attention_bam_384_min_attention": -0.9033043384552002,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2277200143014717,
      "attention_bam_384_attention_skewness": 0.7005015734398569,
      "attention_bam_384_attention_sparsity": 0.6342493693033854,
      "attention_bam_384_attention_concentration_10": 1.6397018900945535,
      "attention_bam_384_attention_concentration_20": 2.512402757529931,
      "attention_bam_384_attention_center_y": 0.48415228597457316,
      "attention_bam_384_attention_center_x": 0.4838730451466518,
      "attention_bam_384_attention_center_distance": 0.0319758881869962,
      "attention_bam_384_attention_spatial_variance": 169.69729608797846,
      "attention_bam_384_attention_spatial_std": 13.02679147326687,
      "attention_bam_384_num_attention_peaks": 20,
      "attention_bam_384_peak_separation_mean": 19.329881805145924,
      "attention_bam_384_peak_intensity_mean": 0.26309606432914734,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13568785786628723,
      "attention_bam_16_std_attention": 0.5395001769065857,
      "attention_bam_16_max_attention": 3.617159366607666,
      "attention_bam_16_min_attention": -0.93160080909729,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.1560943126030878,
      "attention_bam_16_attention_skewness": 0.863985741177302,
      "attention_bam_16_attention_sparsity": 0.529541015625,
      "attention_bam_16_attention_concentration_10": 0.9057173964113658,
      "attention_bam_16_attention_concentration_20": 1.4227026162462564,
      "attention_bam_16_attention_center_y": 0.4702883036701326,
      "attention_bam_16_attention_center_x": 0.46753892190420493,
      "attention_bam_16_attention_center_distance": 0.06223353581373251,
      "attention_bam_16_attention_spatial_variance": 41.56130252672912,
      "attention_bam_16_attention_spatial_std": 6.446805606401447,
      "attention_bam_16_num_attention_peaks": 11,
      "attention_bam_16_peak_separation_mean": 9.165372012120843,
      "attention_bam_16_peak_intensity_mean": 0.24399133026599884,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 533,
      "phase": "train",
      "loss": 0.005186122842133045,
      "timestamp": 1759543972.5822916,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005186122842133045,
      "ssim": 0.9010515213012695,
      "attention_bam_384_mean_attention": 0.033959127962589264,
      "attention_bam_384_std_attention": 0.2904089391231537,
      "attention_bam_384_max_attention": 2.299384355545044,
      "attention_bam_384_min_attention": -1.017651915550232,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.7610605082443866,
      "attention_bam_384_attention_skewness": 0.8608830971778547,
      "attention_bam_384_attention_sparsity": 0.6473185221354166,
      "attention_bam_384_attention_concentration_10": 1.8582789755335585,
      "attention_bam_384_attention_concentration_20": 2.7748617040029164,
      "attention_bam_384_attention_center_y": 0.48153318814059864,
      "attention_bam_384_attention_center_x": 0.48215407720795783,
      "attention_bam_384_attention_center_distance": 0.03631804236326778,
      "attention_bam_384_attention_spatial_variance": 171.01688826433838,
      "attention_bam_384_attention_spatial_std": 13.07734255360539,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 18.464462905703684,
      "attention_bam_384_peak_intensity_mean": 0.3194398880004883,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13304975628852844,
      "attention_bam_16_std_attention": 0.5765873193740845,
      "attention_bam_16_max_attention": 2.971076011657715,
      "attention_bam_16_min_attention": -1.1248071193695068,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.0534449827695695,
      "attention_bam_16_attention_skewness": 0.9500358346612547,
      "attention_bam_16_attention_sparsity": 0.549560546875,
      "attention_bam_16_attention_concentration_10": 1.0147546965156802,
      "attention_bam_16_attention_concentration_20": 1.555771659781295,
      "attention_bam_16_attention_center_y": 0.4620252048630486,
      "attention_bam_16_attention_center_x": 0.46228613591083495,
      "attention_bam_16_attention_center_distance": 0.0756891089950125,
      "attention_bam_16_attention_spatial_variance": 42.548342370612886,
      "attention_bam_16_attention_spatial_std": 6.522909042031238,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 10.439683627749574,
      "attention_bam_16_peak_intensity_mean": 0.3079851567745209,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 534,
      "phase": "train",
      "loss": 0.007345357444137335,
      "timestamp": 1759543972.7433844,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007345357444137335,
      "ssim": 0.9203646183013916,
      "attention_bam_384_mean_attention": 0.03250502049922943,
      "attention_bam_384_std_attention": 0.29620710015296936,
      "attention_bam_384_max_attention": 3.403977870941162,
      "attention_bam_384_min_attention": -0.8898268342018127,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.2404390612332543,
      "attention_bam_384_attention_skewness": 0.9020148670375449,
      "attention_bam_384_attention_sparsity": 0.6324539184570312,
      "attention_bam_384_attention_concentration_10": 1.915778656426977,
      "attention_bam_384_attention_concentration_20": 2.8944508242102924,
      "attention_bam_384_attention_center_y": 0.4819200050931502,
      "attention_bam_384_attention_center_x": 0.4813245333538672,
      "attention_bam_384_attention_center_distance": 0.03676028482703944,
      "attention_bam_384_attention_spatial_variance": 171.88660347725343,
      "attention_bam_384_attention_spatial_std": 13.110553133916715,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 18.03002458885971,
      "attention_bam_384_peak_intensity_mean": 0.22173506021499634,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12021896243095398,
      "attention_bam_16_std_attention": 0.5824840068817139,
      "attention_bam_16_max_attention": 3.8203585147857666,
      "attention_bam_16_min_attention": -0.9601196050643921,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.8380608738497486,
      "attention_bam_16_attention_skewness": 1.0154859940673622,
      "attention_bam_16_attention_sparsity": 0.54833984375,
      "attention_bam_16_attention_concentration_10": 1.0899018041717947,
      "attention_bam_16_attention_concentration_20": 1.6908579805843171,
      "attention_bam_16_attention_center_y": 0.4606139929506134,
      "attention_bam_16_attention_center_x": 0.45950971687620673,
      "attention_bam_16_attention_center_distance": 0.07988392302258658,
      "attention_bam_16_attention_spatial_variance": 43.475713761233884,
      "attention_bam_16_attention_spatial_std": 6.5936115870768335,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.60303754705278,
      "attention_bam_16_peak_intensity_mean": 0.22957324981689453,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 535,
      "phase": "train",
      "loss": 0.005743458401411772,
      "timestamp": 1759543972.8974516,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005743458401411772,
      "ssim": 0.8892192840576172,
      "attention_bam_384_mean_attention": 0.03268987312912941,
      "attention_bam_384_std_attention": 0.24520368874073029,
      "attention_bam_384_max_attention": 2.2840631008148193,
      "attention_bam_384_min_attention": -0.87238609790802,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.218934286099989,
      "attention_bam_384_attention_skewness": 0.6926757073874854,
      "attention_bam_384_attention_sparsity": 0.6502482096354166,
      "attention_bam_384_attention_concentration_10": 1.5893928000375397,
      "attention_bam_384_attention_concentration_20": 2.4412884851259795,
      "attention_bam_384_attention_center_y": 0.48850354010816693,
      "attention_bam_384_attention_center_x": 0.47513466652775094,
      "attention_bam_384_attention_center_distance": 0.03874153839822771,
      "attention_bam_384_attention_spatial_variance": 171.03181977416406,
      "attention_bam_384_attention_spatial_std": 13.077913433501694,
      "attention_bam_384_num_attention_peaks": 20,
      "attention_bam_384_peak_separation_mean": 18.26778477820598,
      "attention_bam_384_peak_intensity_mean": 0.2889849543571472,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13353504240512848,
      "attention_bam_16_std_attention": 0.5019713044166565,
      "attention_bam_16_max_attention": 2.8405730724334717,
      "attention_bam_16_min_attention": -0.9300709962844849,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7527270234487493,
      "attention_bam_16_attention_skewness": 0.7495158930156578,
      "attention_bam_16_attention_sparsity": 0.5224609375,
      "attention_bam_16_attention_concentration_10": 0.8479889548168129,
      "attention_bam_16_attention_concentration_20": 1.3484567396422615,
      "attention_bam_16_attention_center_y": 0.48419623887420427,
      "attention_bam_16_attention_center_x": 0.4364106236553272,
      "attention_bam_16_attention_center_distance": 0.09266463888264656,
      "attention_bam_16_attention_spatial_variance": 42.60170704442194,
      "attention_bam_16_attention_spatial_std": 6.526998318095535,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 7.626573331293999,
      "attention_bam_16_peak_intensity_mean": 0.27939897775650024,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 536,
      "phase": "train",
      "loss": 0.0058981794863939285,
      "timestamp": 1759543973.045611,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0058981794863939285,
      "ssim": 0.9235579371452332,
      "attention_bam_384_mean_attention": 0.03414676710963249,
      "attention_bam_384_std_attention": 0.24784117937088013,
      "attention_bam_384_max_attention": 2.2755327224731445,
      "attention_bam_384_min_attention": -0.9909228086471558,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9202743597004406,
      "attention_bam_384_attention_skewness": 0.5406020833244618,
      "attention_bam_384_attention_sparsity": 0.6333491007486979,
      "attention_bam_384_attention_concentration_10": 1.4949319983798957,
      "attention_bam_384_attention_concentration_20": 2.3332636813261547,
      "attention_bam_384_attention_center_y": 0.481965386936076,
      "attention_bam_384_attention_center_x": 0.4807047861463247,
      "attention_bam_384_attention_center_distance": 0.037351105633555766,
      "attention_bam_384_attention_spatial_variance": 171.72495526026114,
      "attention_bam_384_attention_spatial_std": 13.104386870825401,
      "attention_bam_384_num_attention_peaks": 19,
      "attention_bam_384_peak_separation_mean": 17.73367067773381,
      "attention_bam_384_peak_intensity_mean": 0.3179209530353546,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14327901601791382,
      "attention_bam_16_std_attention": 0.502246618270874,
      "attention_bam_16_max_attention": 2.3636436462402344,
      "attention_bam_16_min_attention": -0.9515314698219299,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.25972336481863856,
      "attention_bam_16_attention_skewness": 0.5559154624107934,
      "attention_bam_16_attention_sparsity": 0.497802734375,
      "attention_bam_16_attention_concentration_10": 0.7821895060359941,
      "attention_bam_16_attention_concentration_20": 1.2484719132601954,
      "attention_bam_16_attention_center_y": 0.45892534635473525,
      "attention_bam_16_attention_center_x": 0.45881231550870694,
      "attention_bam_16_attention_center_distance": 0.08226241579035669,
      "attention_bam_16_attention_spatial_variance": 43.17472127855482,
      "attention_bam_16_attention_spatial_std": 6.5707473911690455,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 9.5653144152517,
      "attention_bam_16_peak_intensity_mean": 0.34021881222724915,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 537,
      "phase": "train",
      "loss": 0.004714015871286392,
      "timestamp": 1759543973.189103,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004714015871286392,
      "ssim": 0.9178974628448486,
      "attention_bam_384_mean_attention": 0.033591631799936295,
      "attention_bam_384_std_attention": 0.26813095808029175,
      "attention_bam_384_max_attention": 1.9746345281600952,
      "attention_bam_384_min_attention": -0.9843751192092896,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9417777317321141,
      "attention_bam_384_attention_skewness": 0.7462765776052533,
      "attention_bam_384_attention_sparsity": 0.6478296915690104,
      "attention_bam_384_attention_concentration_10": 1.7130450989974517,
      "attention_bam_384_attention_concentration_20": 2.6303810864228403,
      "attention_bam_384_attention_center_y": 0.4846795457488815,
      "attention_bam_384_attention_center_x": 0.48321077250737543,
      "attention_bam_384_attention_center_distance": 0.03214325678146866,
      "attention_bam_384_attention_spatial_variance": 172.60958473891222,
      "attention_bam_384_attention_spatial_std": 13.13809669392459,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 19.3379010964643,
      "attention_bam_384_peak_intensity_mean": 0.34683263301849365,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12369415163993835,
      "attention_bam_16_std_attention": 0.5316258668899536,
      "attention_bam_16_max_attention": 2.823925495147705,
      "attention_bam_16_min_attention": -0.9497562050819397,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5979397800957664,
      "attention_bam_16_attention_skewness": 0.83404784112729,
      "attention_bam_16_attention_sparsity": 0.549560546875,
      "attention_bam_16_attention_concentration_10": 0.9787811646970146,
      "attention_bam_16_attention_concentration_20": 1.5487534354096582,
      "attention_bam_16_attention_center_y": 0.46875667605260884,
      "attention_bam_16_attention_center_x": 0.4663096842212302,
      "attention_bam_16_attention_center_distance": 0.06497973020188451,
      "attention_bam_16_attention_spatial_variance": 44.322735053971044,
      "attention_bam_16_attention_spatial_std": 6.657532204501233,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.665258410247986,
      "attention_bam_16_peak_intensity_mean": 0.28441694378852844,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 538,
      "phase": "train",
      "loss": 0.004845164716243744,
      "timestamp": 1759543973.331397,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004845164716243744,
      "ssim": 0.9230533838272095,
      "attention_bam_384_mean_attention": 0.03421163186430931,
      "attention_bam_384_std_attention": 0.24990393221378326,
      "attention_bam_384_max_attention": 1.8388688564300537,
      "attention_bam_384_min_attention": -0.7337722778320312,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7730201861127108,
      "attention_bam_384_attention_skewness": 0.6123371232777403,
      "attention_bam_384_attention_sparsity": 0.6404571533203125,
      "attention_bam_384_attention_concentration_10": 1.5294543042332955,
      "attention_bam_384_attention_concentration_20": 2.3816395329548583,
      "attention_bam_384_attention_center_y": 0.48404304417928956,
      "attention_bam_384_attention_center_x": 0.49288776069295587,
      "attention_bam_384_attention_center_distance": 0.024706613973783147,
      "attention_bam_384_attention_spatial_variance": 170.87236879999327,
      "attention_bam_384_attention_spatial_std": 13.071815818775647,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 18.176890736471883,
      "attention_bam_384_peak_intensity_mean": 0.30264154076576233,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1357988715171814,
      "attention_bam_16_std_attention": 0.5019258856773376,
      "attention_bam_16_max_attention": 2.6409528255462646,
      "attention_bam_16_min_attention": -0.8893963098526001,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.3997775357142159,
      "attention_bam_16_attention_skewness": 0.6961997717120884,
      "attention_bam_16_attention_sparsity": 0.5244140625,
      "attention_bam_16_attention_concentration_10": 0.8303276921908004,
      "attention_bam_16_attention_concentration_20": 1.3292624368431543,
      "attention_bam_16_attention_center_y": 0.46623428901822445,
      "attention_bam_16_attention_center_x": 0.4946209665295391,
      "attention_bam_16_attention_center_distance": 0.048354053380893255,
      "attention_bam_16_attention_spatial_variance": 42.46622171357357,
      "attention_bam_16_attention_spatial_std": 6.516611213934246,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.74611582944803,
      "attention_bam_16_peak_intensity_mean": 0.29680824279785156,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 539,
      "phase": "train",
      "loss": 0.004006868228316307,
      "timestamp": 1759543973.4683077,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004006868228316307,
      "ssim": 0.9275680780410767,
      "attention_bam_384_mean_attention": 0.033499956130981445,
      "attention_bam_384_std_attention": 0.27812299132347107,
      "attention_bam_384_max_attention": 2.171678066253662,
      "attention_bam_384_min_attention": -1.0484507083892822,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4109758927416225,
      "attention_bam_384_attention_skewness": 0.7479136349490879,
      "attention_bam_384_attention_sparsity": 0.639190673828125,
      "attention_bam_384_attention_concentration_10": 1.7596426207560534,
      "attention_bam_384_attention_concentration_20": 2.666916354110523,
      "attention_bam_384_attention_center_y": 0.4822188374680709,
      "attention_bam_384_attention_center_x": 0.4806589194577887,
      "attention_bam_384_attention_center_distance": 0.03715500336501619,
      "attention_bam_384_attention_spatial_variance": 171.14737951278926,
      "attention_bam_384_attention_spatial_std": 13.082330813459398,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 21.003408652930187,
      "attention_bam_384_peak_intensity_mean": 0.3415773808956146,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1347651183605194,
      "attention_bam_16_std_attention": 0.5532829165458679,
      "attention_bam_16_max_attention": 2.8844823837280273,
      "attention_bam_16_min_attention": -1.0952479839324951,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7891074089701466,
      "attention_bam_16_attention_skewness": 0.818964545013532,
      "attention_bam_16_attention_sparsity": 0.53466796875,
      "attention_bam_16_attention_concentration_10": 0.9391777958404081,
      "attention_bam_16_attention_concentration_20": 1.4663208510543926,
      "attention_bam_16_attention_center_y": 0.4622582226121396,
      "attention_bam_16_attention_center_x": 0.45695786252725185,
      "attention_bam_16_attention_center_distance": 0.08095761061960463,
      "attention_bam_16_attention_spatial_variance": 42.90081404285595,
      "attention_bam_16_attention_spatial_std": 6.549871299716961,
      "attention_bam_16_num_attention_peaks": 2,
      "attention_bam_16_peak_separation_mean": 12.18154434691008,
      "attention_bam_16_peak_intensity_mean": 0.31597745418548584,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 540,
      "phase": "train",
      "loss": 0.003584704827517271,
      "timestamp": 1759543973.6905262,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.003584704827517271,
      "ssim": 0.9291842579841614,
      "attention_bam_384_mean_attention": 0.03326917812228203,
      "attention_bam_384_std_attention": 0.24493665993213654,
      "attention_bam_384_max_attention": 1.886576533317566,
      "attention_bam_384_min_attention": -0.8685452342033386,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0080264452538579,
      "attention_bam_384_attention_skewness": 0.6487755718087602,
      "attention_bam_384_attention_sparsity": 0.6515401204427084,
      "attention_bam_384_attention_concentration_10": 1.5705635012862416,
      "attention_bam_384_attention_concentration_20": 2.404514621255452,
      "attention_bam_384_attention_center_y": 0.4795995118721255,
      "attention_bam_384_attention_center_x": 0.4763297424313723,
      "attention_bam_384_attention_center_distance": 0.04419187729030581,
      "attention_bam_384_attention_spatial_variance": 170.69883914356,
      "attention_bam_384_attention_spatial_std": 13.06517658294598,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 16.841736020307383,
      "attention_bam_384_peak_intensity_mean": 0.3339005708694458,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14810606837272644,
      "attention_bam_16_std_attention": 0.49428901076316833,
      "attention_bam_16_max_attention": 2.5120840072631836,
      "attention_bam_16_min_attention": -0.9645698070526123,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.426366959108321,
      "attention_bam_16_attention_skewness": 0.6452540198557001,
      "attention_bam_16_attention_sparsity": 0.507568359375,
      "attention_bam_16_attention_concentration_10": 0.7625663154867189,
      "attention_bam_16_attention_concentration_20": 1.2121908839820987,
      "attention_bam_16_attention_center_y": 0.4552946736034867,
      "attention_bam_16_attention_center_x": 0.4414539372877158,
      "attention_bam_16_attention_center_distance": 0.10417492661220838,
      "attention_bam_16_attention_spatial_variance": 42.24952920809793,
      "attention_bam_16_attention_spatial_std": 6.499963785137417,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 6.0230331100937695,
      "attention_bam_16_peak_intensity_mean": 0.331037312746048,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 541,
      "phase": "train",
      "loss": 0.0056081353686749935,
      "timestamp": 1759543973.8783069,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0056081353686749935,
      "ssim": 0.9174411296844482,
      "attention_bam_384_mean_attention": 0.03278477117419243,
      "attention_bam_384_std_attention": 0.2868509590625763,
      "attention_bam_384_max_attention": 2.159029006958008,
      "attention_bam_384_min_attention": -0.8346179127693176,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1364976285005541,
      "attention_bam_384_attention_skewness": 0.7043031596837024,
      "attention_bam_384_attention_sparsity": 0.6330973307291666,
      "attention_bam_384_attention_concentration_10": 1.8336838272972307,
      "attention_bam_384_attention_concentration_20": 2.818595681365733,
      "attention_bam_384_attention_center_y": 0.4900057733210932,
      "attention_bam_384_attention_center_x": 0.4893306231808958,
      "attention_bam_384_attention_center_distance": 0.020674630280486776,
      "attention_bam_384_attention_spatial_variance": 172.27442592042027,
      "attention_bam_384_attention_spatial_std": 13.125335268876764,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 20.334899060496813,
      "attention_bam_384_peak_intensity_mean": 0.2938542366027832,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1307775378227234,
      "attention_bam_16_std_attention": 0.574870228767395,
      "attention_bam_16_max_attention": 2.9729626178741455,
      "attention_bam_16_min_attention": -1.0279940366744995,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.619858866047136,
      "attention_bam_16_attention_skewness": 0.8083207322134429,
      "attention_bam_16_attention_sparsity": 0.54736328125,
      "attention_bam_16_attention_concentration_10": 0.99571426876705,
      "attention_bam_16_attention_concentration_20": 1.5717538944222351,
      "attention_bam_16_attention_center_y": 0.4867506960413049,
      "attention_bam_16_attention_center_x": 0.48694520958770465,
      "attention_bam_16_attention_center_distance": 0.02630481355565375,
      "attention_bam_16_attention_spatial_variance": 43.830285406207004,
      "attention_bam_16_attention_spatial_std": 6.620444502161996,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 6.9303098439867545,
      "attention_bam_16_peak_intensity_mean": 0.2970329523086548,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 542,
      "phase": "train",
      "loss": 0.0036042663268744946,
      "timestamp": 1759543974.0523763,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0036042663268744946,
      "ssim": 0.9298804998397827,
      "attention_bam_384_mean_attention": 0.03388400003314018,
      "attention_bam_384_std_attention": 0.29293838143348694,
      "attention_bam_384_max_attention": 2.7369089126586914,
      "attention_bam_384_min_attention": -1.0285824537277222,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.2327667555020634,
      "attention_bam_384_attention_skewness": 0.8985243333938365,
      "attention_bam_384_attention_sparsity": 0.6305770874023438,
      "attention_bam_384_attention_concentration_10": 1.8279945761704313,
      "attention_bam_384_attention_concentration_20": 2.764411771171011,
      "attention_bam_384_attention_center_y": 0.4815383320260997,
      "attention_bam_384_attention_center_x": 0.48291554878273424,
      "attention_bam_384_attention_center_distance": 0.035572788976229286,
      "attention_bam_384_attention_spatial_variance": 173.20908074353034,
      "attention_bam_384_attention_spatial_std": 13.160892095277218,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 19.51367938174228,
      "attention_bam_384_peak_intensity_mean": 0.29256075620651245,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13724669814109802,
      "attention_bam_16_std_attention": 0.5915567874908447,
      "attention_bam_16_max_attention": 3.3396992683410645,
      "attention_bam_16_min_attention": -1.0909044742584229,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.4432292214966207,
      "attention_bam_16_attention_skewness": 0.9955913997789726,
      "attention_bam_16_attention_sparsity": 0.5400390625,
      "attention_bam_16_attention_concentration_10": 0.9916245316294969,
      "attention_bam_16_attention_concentration_20": 1.5377836309925605,
      "attention_bam_16_attention_center_y": 0.4622299896266371,
      "attention_bam_16_attention_center_x": 0.4640384780952727,
      "attention_bam_16_attention_center_distance": 0.0737537082634917,
      "attention_bam_16_attention_spatial_variance": 44.755782635569396,
      "attention_bam_16_attention_spatial_std": 6.689976280643258,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.386386839367551,
      "attention_bam_16_peak_intensity_mean": 0.2955816388130188,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 543,
      "phase": "train",
      "loss": 0.007445786148309708,
      "timestamp": 1759543974.2135665,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007445786148309708,
      "ssim": 0.9133602380752563,
      "attention_bam_384_mean_attention": 0.033661339432001114,
      "attention_bam_384_std_attention": 0.31006887555122375,
      "attention_bam_384_max_attention": 2.128676414489746,
      "attention_bam_384_min_attention": -1.0765459537506104,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.43731388968752416,
      "attention_bam_384_attention_skewness": 0.5048425013791191,
      "attention_bam_384_attention_sparsity": 0.6069259643554688,
      "attention_bam_384_attention_concentration_10": 1.8693594326909342,
      "attention_bam_384_attention_concentration_20": 2.9241721445073376,
      "attention_bam_384_attention_center_y": 0.4817417272933972,
      "attention_bam_384_attention_center_x": 0.4791156905150506,
      "attention_bam_384_attention_center_distance": 0.03923057238664315,
      "attention_bam_384_attention_spatial_variance": 171.78888624641698,
      "attention_bam_384_attention_spatial_std": 13.106825940952179,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 18.697168149968952,
      "attention_bam_384_peak_intensity_mean": 0.3491731882095337,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1352727860212326,
      "attention_bam_16_std_attention": 0.624841034412384,
      "attention_bam_16_max_attention": 3.2428693771362305,
      "attention_bam_16_min_attention": -1.065848708152771,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.34370734058855046,
      "attention_bam_16_attention_skewness": 0.7366615941914328,
      "attention_bam_16_attention_sparsity": 0.5283203125,
      "attention_bam_16_attention_concentration_10": 1.033741451708116,
      "attention_bam_16_attention_concentration_20": 1.634850528219934,
      "attention_bam_16_attention_center_y": 0.45732294022910064,
      "attention_bam_16_attention_center_x": 0.44076591577610896,
      "attention_bam_16_attention_center_distance": 0.10324735507054826,
      "attention_bam_16_attention_spatial_variance": 43.68627327829369,
      "attention_bam_16_attention_spatial_std": 6.609559234797256,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.917189611458438,
      "attention_bam_16_peak_intensity_mean": 0.2947760820388794,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 544,
      "phase": "train",
      "loss": 0.006818145513534546,
      "timestamp": 1759543974.3654494,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006818145513534546,
      "ssim": 0.8973312377929688,
      "attention_bam_384_mean_attention": 0.03218621388077736,
      "attention_bam_384_std_attention": 0.2872559726238251,
      "attention_bam_384_max_attention": 2.6718552112579346,
      "attention_bam_384_min_attention": -1.029768466949463,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.5399154270138773,
      "attention_bam_384_attention_skewness": 0.9870355687557868,
      "attention_bam_384_attention_sparsity": 0.6454213460286459,
      "attention_bam_384_attention_concentration_10": 1.9145944384355038,
      "attention_bam_384_attention_concentration_20": 2.8561682891843265,
      "attention_bam_384_attention_center_y": 0.4857172585902691,
      "attention_bam_384_attention_center_x": 0.4818502605119063,
      "attention_bam_384_attention_center_distance": 0.032662202793532116,
      "attention_bam_384_attention_spatial_variance": 170.76166555056025,
      "attention_bam_384_attention_spatial_std": 13.067580707635223,
      "attention_bam_384_num_attention_peaks": 26,
      "attention_bam_384_peak_separation_mean": 19.77190710820374,
      "attention_bam_384_peak_intensity_mean": 0.29655277729034424,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12529174983501434,
      "attention_bam_16_std_attention": 0.5632323026657104,
      "attention_bam_16_max_attention": 3.0257551670074463,
      "attention_bam_16_min_attention": -1.0525262355804443,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.298304719764129,
      "attention_bam_16_attention_skewness": 0.9590092129433065,
      "attention_bam_16_attention_sparsity": 0.548583984375,
      "attention_bam_16_attention_concentration_10": 1.0245590398776974,
      "attention_bam_16_attention_concentration_20": 1.5950082936712366,
      "attention_bam_16_attention_center_y": 0.47536743883143745,
      "attention_bam_16_attention_center_x": 0.46221752246951414,
      "attention_bam_16_attention_center_distance": 0.06378524403127488,
      "attention_bam_16_attention_spatial_variance": 42.39868482159728,
      "attention_bam_16_attention_spatial_std": 6.511427249197927,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.222085797067564,
      "attention_bam_16_peak_intensity_mean": 0.2956390380859375,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 545,
      "phase": "train",
      "loss": 0.0045201522298157215,
      "timestamp": 1759543974.5169938,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0045201522298157215,
      "ssim": 0.9385251402854919,
      "attention_bam_384_mean_attention": 0.03294620290398598,
      "attention_bam_384_std_attention": 0.27098262310028076,
      "attention_bam_384_max_attention": 1.7169233560562134,
      "attention_bam_384_min_attention": -0.8686941862106323,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1450356989537163,
      "attention_bam_384_attention_skewness": 0.6789256165764588,
      "attention_bam_384_attention_sparsity": 0.6401570638020834,
      "attention_bam_384_attention_concentration_10": 1.7413745158341143,
      "attention_bam_384_attention_concentration_20": 2.641774662284171,
      "attention_bam_384_attention_center_y": 0.4824128702408769,
      "attention_bam_384_attention_center_x": 0.4895111763461065,
      "attention_bam_384_attention_center_distance": 0.02895936997956647,
      "attention_bam_384_attention_spatial_variance": 172.61045214287648,
      "attention_bam_384_attention_spatial_std": 13.138129704903832,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 19.744116680045817,
      "attention_bam_384_peak_intensity_mean": 0.35206902027130127,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13498808443546295,
      "attention_bam_16_std_attention": 0.5477010011672974,
      "attention_bam_16_max_attention": 2.475137710571289,
      "attention_bam_16_min_attention": -0.9867254495620728,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5053706319373141,
      "attention_bam_16_attention_skewness": 0.7463304594307291,
      "attention_bam_16_attention_sparsity": 0.524169921875,
      "attention_bam_16_attention_concentration_10": 0.9222783965695707,
      "attention_bam_16_attention_concentration_20": 1.4446183679716542,
      "attention_bam_16_attention_center_y": 0.4616080405601753,
      "attention_bam_16_attention_center_x": 0.488661928622214,
      "attention_bam_16_attention_center_distance": 0.05661262071653131,
      "attention_bam_16_attention_spatial_variance": 44.12008938328859,
      "attention_bam_16_attention_spatial_std": 6.642295490512944,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.199404806539077,
      "attention_bam_16_peak_intensity_mean": 0.3332654535770416,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 546,
      "phase": "train",
      "loss": 0.005336533300578594,
      "timestamp": 1759543974.663102,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005336533300578594,
      "ssim": 0.8999983072280884,
      "attention_bam_384_mean_attention": 0.033310119062662125,
      "attention_bam_384_std_attention": 0.2577837109565735,
      "attention_bam_384_max_attention": 1.7742942571640015,
      "attention_bam_384_min_attention": -0.7979726195335388,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.516310744778326,
      "attention_bam_384_attention_skewness": 0.4576857624366878,
      "attention_bam_384_attention_sparsity": 0.6322987874348959,
      "attention_bam_384_attention_concentration_10": 1.5812492087549117,
      "attention_bam_384_attention_concentration_20": 2.486149485557239,
      "attention_bam_384_attention_center_y": 0.48066656183371653,
      "attention_bam_384_attention_center_x": 0.48704354771146274,
      "attention_bam_384_attention_center_distance": 0.03291356824273687,
      "attention_bam_384_attention_spatial_variance": 172.99702208224576,
      "attention_bam_384_attention_spatial_std": 13.152833234031585,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 19.950259107677176,
      "attention_bam_384_peak_intensity_mean": 0.32908809185028076,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14679445326328278,
      "attention_bam_16_std_attention": 0.5279442667961121,
      "attention_bam_16_max_attention": 2.752408266067505,
      "attention_bam_16_min_attention": -1.0225272178649902,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.07515527491511742,
      "attention_bam_16_attention_skewness": 0.4798258209716817,
      "attention_bam_16_attention_sparsity": 0.500732421875,
      "attention_bam_16_attention_concentration_10": 0.7870231460799435,
      "attention_bam_16_attention_concentration_20": 1.2716299085514942,
      "attention_bam_16_attention_center_y": 0.4577911935298082,
      "attention_bam_16_attention_center_x": 0.47990320187414964,
      "attention_bam_16_attention_center_distance": 0.06611300384265245,
      "attention_bam_16_attention_spatial_variance": 44.30325031943055,
      "attention_bam_16_attention_spatial_std": 6.65606868349708,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 11.015051567393982,
      "attention_bam_16_peak_intensity_mean": 0.32579827308654785,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 547,
      "phase": "train",
      "loss": 0.0068284980952739716,
      "timestamp": 1759543974.8026958,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0068284980952739716,
      "ssim": 0.886949896812439,
      "attention_bam_384_mean_attention": 0.03159196674823761,
      "attention_bam_384_std_attention": 0.2958747446537018,
      "attention_bam_384_max_attention": 2.593748092651367,
      "attention_bam_384_min_attention": -0.9734417200088501,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2688984610890728,
      "attention_bam_384_attention_skewness": 0.6904859404996324,
      "attention_bam_384_attention_sparsity": 0.6319529215494791,
      "attention_bam_384_attention_concentration_10": 1.9482076561431152,
      "attention_bam_384_attention_concentration_20": 2.9816903377063535,
      "attention_bam_384_attention_center_y": 0.4816823074157693,
      "attention_bam_384_attention_center_x": 0.4836649769051647,
      "attention_bam_384_attention_center_distance": 0.034709388963771286,
      "attention_bam_384_attention_spatial_variance": 170.89984159910588,
      "attention_bam_384_attention_spatial_std": 13.072866617506119,
      "attention_bam_384_num_attention_peaks": 23,
      "attention_bam_384_peak_separation_mean": 17.22222520888114,
      "attention_bam_384_peak_intensity_mean": 0.28600648045539856,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13295818865299225,
      "attention_bam_16_std_attention": 0.5764890909194946,
      "attention_bam_16_max_attention": 3.1918516159057617,
      "attention_bam_16_min_attention": -1.014601230621338,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7910604349499679,
      "attention_bam_16_attention_skewness": 0.7788690766515457,
      "attention_bam_16_attention_sparsity": 0.534423828125,
      "attention_bam_16_attention_concentration_10": 0.9713261933773498,
      "attention_bam_16_attention_concentration_20": 1.5245512190965889,
      "attention_bam_16_attention_center_y": 0.46077123131222275,
      "attention_bam_16_attention_center_x": 0.46892044156620616,
      "attention_bam_16_attention_center_distance": 0.07077902578022303,
      "attention_bam_16_attention_spatial_variance": 42.70100478559119,
      "attention_bam_16_attention_spatial_std": 6.534600583478013,
      "attention_bam_16_num_attention_peaks": 13,
      "attention_bam_16_peak_separation_mean": 8.275268521846861,
      "attention_bam_16_peak_intensity_mean": 0.283199667930603,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 548,
      "phase": "train",
      "loss": 0.004387080203741789,
      "timestamp": 1759543974.9452555,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004387080203741789,
      "ssim": 0.9271346926689148,
      "attention_bam_384_mean_attention": 0.03163920342922211,
      "attention_bam_384_std_attention": 0.25920209288597107,
      "attention_bam_384_max_attention": 1.8986098766326904,
      "attention_bam_384_min_attention": -0.8081583976745605,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.3198572630503493,
      "attention_bam_384_attention_skewness": 0.6877347773722189,
      "attention_bam_384_attention_sparsity": 0.6403579711914062,
      "attention_bam_384_attention_concentration_10": 1.725665258931646,
      "attention_bam_384_attention_concentration_20": 2.606938382647442,
      "attention_bam_384_attention_center_y": 0.48485103461479373,
      "attention_bam_384_attention_center_x": 0.48388784678832875,
      "attention_bam_384_attention_center_distance": 0.03127595349013507,
      "attention_bam_384_attention_spatial_variance": 171.65325675904768,
      "attention_bam_384_attention_spatial_std": 13.101650917309913,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 17.997597548979083,
      "attention_bam_384_peak_intensity_mean": 0.3164285123348236,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1339930295944214,
      "attention_bam_16_std_attention": 0.5312967300415039,
      "attention_bam_16_max_attention": 2.5463972091674805,
      "attention_bam_16_min_attention": -0.9044462442398071,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8603190058928063,
      "attention_bam_16_attention_skewness": 0.7981711976483332,
      "attention_bam_16_attention_sparsity": 0.523193359375,
      "attention_bam_16_attention_concentration_10": 0.9059507657650886,
      "attention_bam_16_attention_concentration_20": 1.4088415189932046,
      "attention_bam_16_attention_center_y": 0.47254637588334764,
      "attention_bam_16_attention_center_x": 0.46973955729693895,
      "attention_bam_16_attention_center_distance": 0.05778227876648129,
      "attention_bam_16_attention_spatial_variance": 43.59764209752238,
      "attention_bam_16_attention_spatial_std": 6.602851058256758,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.53514152003991,
      "attention_bam_16_peak_intensity_mean": 0.3164553940296173,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 549,
      "phase": "train",
      "loss": 0.007387375459074974,
      "timestamp": 1759543975.0851133,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007387375459074974,
      "ssim": 0.8759499788284302,
      "attention_bam_384_mean_attention": 0.03334864601492882,
      "attention_bam_384_std_attention": 0.2770169973373413,
      "attention_bam_384_max_attention": 2.4706530570983887,
      "attention_bam_384_min_attention": -1.0189751386642456,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.7940950893543768,
      "attention_bam_384_attention_skewness": 0.7863934600502731,
      "attention_bam_384_attention_sparsity": 0.6356480916341146,
      "attention_bam_384_attention_concentration_10": 1.7541044648837398,
      "attention_bam_384_attention_concentration_20": 2.6579553763185966,
      "attention_bam_384_attention_center_y": 0.4787767714201475,
      "attention_bam_384_attention_center_x": 0.4838087493097426,
      "attention_bam_384_attention_center_distance": 0.0377513451486812,
      "attention_bam_384_attention_spatial_variance": 170.5590647226222,
      "attention_bam_384_attention_spatial_std": 13.059826366480612,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 18.518294908106995,
      "attention_bam_384_peak_intensity_mean": 0.30872148275375366,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14438703656196594,
      "attention_bam_16_std_attention": 0.5662583112716675,
      "attention_bam_16_max_attention": 3.2850282192230225,
      "attention_bam_16_min_attention": -1.0294901132583618,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8971382307886433,
      "attention_bam_16_attention_skewness": 0.7971370221012843,
      "attention_bam_16_attention_sparsity": 0.52587890625,
      "attention_bam_16_attention_concentration_10": 0.8818557945700326,
      "attention_bam_16_attention_concentration_20": 1.3998815230447583,
      "attention_bam_16_attention_center_y": 0.4491363826352871,
      "attention_bam_16_attention_center_x": 0.4700786737922769,
      "attention_bam_16_attention_center_distance": 0.0834552974166757,
      "attention_bam_16_attention_spatial_variance": 42.380759678228685,
      "attention_bam_16_attention_spatial_std": 6.5100506663334565,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 7.931125931243999,
      "attention_bam_16_peak_intensity_mean": 0.2810556888580322,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 550,
      "phase": "train",
      "loss": 0.004343504086136818,
      "timestamp": 1759543975.2667115,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004343504086136818,
      "ssim": 0.9355682134628296,
      "attention_bam_384_mean_attention": 0.031357541680336,
      "attention_bam_384_std_attention": 0.27695232629776,
      "attention_bam_384_max_attention": 1.9733822345733643,
      "attention_bam_384_min_attention": -0.8745105266571045,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9124280294666116,
      "attention_bam_384_attention_skewness": 0.6320909245969915,
      "attention_bam_384_attention_sparsity": 0.6310958862304688,
      "attention_bam_384_attention_concentration_10": 1.8351030641474322,
      "attention_bam_384_attention_concentration_20": 2.8236315335674718,
      "attention_bam_384_attention_center_y": 0.47612870825474873,
      "attention_bam_384_attention_center_x": 0.4838988371654375,
      "attention_bam_384_attention_center_distance": 0.040720658496934875,
      "attention_bam_384_attention_spatial_variance": 170.85685407733672,
      "attention_bam_384_attention_spatial_std": 13.07122236354874,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 16.148209713994053,
      "attention_bam_384_peak_intensity_mean": 0.32441070675849915,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12840722501277924,
      "attention_bam_16_std_attention": 0.5661190748214722,
      "attention_bam_16_max_attention": 2.5469884872436523,
      "attention_bam_16_min_attention": -0.963585615158081,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.30590933236964224,
      "attention_bam_16_attention_skewness": 0.701123049872926,
      "attention_bam_16_attention_sparsity": 0.533935546875,
      "attention_bam_16_attention_concentration_10": 0.9798659968762076,
      "attention_bam_16_attention_concentration_20": 1.557478633267294,
      "attention_bam_16_attention_center_y": 0.4402898066980481,
      "attention_bam_16_attention_center_x": 0.46879582569984374,
      "attention_bam_16_attention_center_distance": 0.09527861961543092,
      "attention_bam_16_attention_spatial_variance": 42.555044194079294,
      "attention_bam_16_attention_spatial_std": 6.523422736116317,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 8.638320342422729,
      "attention_bam_16_peak_intensity_mean": 0.3196021020412445,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 551,
      "phase": "train",
      "loss": 0.004598754923790693,
      "timestamp": 1759543975.403514,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004598754923790693,
      "ssim": 0.937492847442627,
      "attention_bam_384_mean_attention": 0.03198453411459923,
      "attention_bam_384_std_attention": 0.2771226167678833,
      "attention_bam_384_max_attention": 2.8349220752716064,
      "attention_bam_384_min_attention": -1.1870841979980469,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.638327385339399,
      "attention_bam_384_attention_skewness": 1.0180079264835646,
      "attention_bam_384_attention_sparsity": 0.6390329996744791,
      "attention_bam_384_attention_concentration_10": 1.805264268664733,
      "attention_bam_384_attention_concentration_20": 2.7117356957690077,
      "attention_bam_384_attention_center_y": 0.4851521137332891,
      "attention_bam_384_attention_center_x": 0.4880068972408541,
      "attention_bam_384_attention_center_distance": 0.026992378197580703,
      "attention_bam_384_attention_spatial_variance": 169.93845970610414,
      "attention_bam_384_attention_spatial_std": 13.036044634247926,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 17.737574741870766,
      "attention_bam_384_peak_intensity_mean": 0.3062498867511749,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1443454623222351,
      "attention_bam_16_std_attention": 0.5806984901428223,
      "attention_bam_16_max_attention": 3.2303810119628906,
      "attention_bam_16_min_attention": -1.1396428346633911,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.500099512461646,
      "attention_bam_16_attention_skewness": 1.1945857043265238,
      "attention_bam_16_attention_sparsity": 0.54052734375,
      "attention_bam_16_attention_concentration_10": 0.9436143394087866,
      "attention_bam_16_attention_concentration_20": 1.4297952070914355,
      "attention_bam_16_attention_center_y": 0.473327454581817,
      "attention_bam_16_attention_center_x": 0.48574924510921846,
      "attention_bam_16_attention_center_distance": 0.0427670128496758,
      "attention_bam_16_attention_spatial_variance": 41.87679202976203,
      "attention_bam_16_attention_spatial_std": 6.471228015590397,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.845388552829831,
      "attention_bam_16_peak_intensity_mean": 0.29792171716690063,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 552,
      "phase": "train",
      "loss": 0.003708828939124942,
      "timestamp": 1759543975.5417044,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.003708828939124942,
      "ssim": 0.9299152493476868,
      "attention_bam_384_mean_attention": 0.029788663610816002,
      "attention_bam_384_std_attention": 0.27708899974823,
      "attention_bam_384_max_attention": 2.346839189529419,
      "attention_bam_384_min_attention": -1.042889952659607,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.9854421973228114,
      "attention_bam_384_attention_skewness": 0.8589319437654793,
      "attention_bam_384_attention_sparsity": 0.6417160034179688,
      "attention_bam_384_attention_concentration_10": 1.9715439576455718,
      "attention_bam_384_attention_concentration_20": 2.951185293256891,
      "attention_bam_384_attention_center_y": 0.484933958246473,
      "attention_bam_384_attention_center_x": 0.47868392114602637,
      "attention_bam_384_attention_center_distance": 0.03691506011989796,
      "attention_bam_384_attention_spatial_variance": 171.84234753419236,
      "attention_bam_384_attention_spatial_std": 13.108865226791844,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 19.522175807400096,
      "attention_bam_384_peak_intensity_mean": 0.32110992074012756,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12945853173732758,
      "attention_bam_16_std_attention": 0.5631349086761475,
      "attention_bam_16_max_attention": 2.997450828552246,
      "attention_bam_16_min_attention": -1.027411937713623,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.2468374097211647,
      "attention_bam_16_attention_skewness": 0.9474212499432196,
      "attention_bam_16_attention_sparsity": 0.538330078125,
      "attention_bam_16_attention_concentration_10": 0.9979719871839458,
      "attention_bam_16_attention_concentration_20": 1.5430070736712502,
      "attention_bam_16_attention_center_y": 0.4692968877920619,
      "attention_bam_16_attention_center_x": 0.4488250814948591,
      "attention_bam_16_attention_center_distance": 0.08439849978833804,
      "attention_bam_16_attention_spatial_variance": 43.475018217746275,
      "attention_bam_16_attention_spatial_std": 6.593558843124574,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.505758127852305,
      "attention_bam_16_peak_intensity_mean": 0.29210901260375977,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 553,
      "phase": "train",
      "loss": 0.0037553408183157444,
      "timestamp": 1759543975.6897933,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0037553408183157444,
      "ssim": 0.9342750310897827,
      "attention_bam_384_mean_attention": 0.031160734593868256,
      "attention_bam_384_std_attention": 0.30379682779312134,
      "attention_bam_384_max_attention": 2.5788888931274414,
      "attention_bam_384_min_attention": -1.164115309715271,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.4002627947071167,
      "attention_bam_384_attention_skewness": 0.9318829737212022,
      "attention_bam_384_attention_sparsity": 0.6445643107096354,
      "attention_bam_384_attention_concentration_10": 2.0923362447120555,
      "attention_bam_384_attention_concentration_20": 3.080405474817739,
      "attention_bam_384_attention_center_y": 0.4828187258714968,
      "attention_bam_384_attention_center_x": 0.4796756424677009,
      "attention_bam_384_attention_center_distance": 0.03763710110461474,
      "attention_bam_384_attention_spatial_variance": 172.17043331217664,
      "attention_bam_384_attention_spatial_std": 13.121373148881052,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 20.920953391095242,
      "attention_bam_384_peak_intensity_mean": 0.32565492391586304,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13001829385757446,
      "attention_bam_16_std_attention": 0.6102213263511658,
      "attention_bam_16_max_attention": 3.026987075805664,
      "attention_bam_16_min_attention": -1.0705405473709106,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.4442522655452557,
      "attention_bam_16_attention_skewness": 1.0726174209592747,
      "attention_bam_16_attention_sparsity": 0.552978515625,
      "attention_bam_16_attention_concentration_10": 1.10028766653369,
      "attention_bam_16_attention_concentration_20": 1.669249247565895,
      "attention_bam_16_attention_center_y": 0.4631081574636171,
      "attention_bam_16_attention_center_x": 0.4487917949011808,
      "attention_bam_16_attention_center_distance": 0.08925568122166791,
      "attention_bam_16_attention_spatial_variance": 43.90610971037761,
      "attention_bam_16_attention_spatial_std": 6.6261685543289355,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 11.924152526625464,
      "attention_bam_16_peak_intensity_mean": 0.30731531977653503,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 554,
      "phase": "train",
      "loss": 0.004047587513923645,
      "timestamp": 1759543975.8821344,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004047587513923645,
      "ssim": 0.9399557709693909,
      "attention_bam_384_mean_attention": 0.03159276768565178,
      "attention_bam_384_std_attention": 0.23811618983745575,
      "attention_bam_384_max_attention": 1.5921508073806763,
      "attention_bam_384_min_attention": -0.859014093875885,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6237936347796196,
      "attention_bam_384_attention_skewness": 0.4062898771522983,
      "attention_bam_384_attention_sparsity": 0.62188720703125,
      "attention_bam_384_attention_concentration_10": 1.5073248188072241,
      "attention_bam_384_attention_concentration_20": 2.3627557389854,
      "attention_bam_384_attention_center_y": 0.4822705223703677,
      "attention_bam_384_attention_center_x": 0.4790676843264398,
      "attention_bam_384_attention_center_distance": 0.03879423195469153,
      "attention_bam_384_attention_spatial_variance": 170.69470282012026,
      "attention_bam_384_attention_spatial_std": 13.065018286252808,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 18.616069042923314,
      "attention_bam_384_peak_intensity_mean": 0.3668278157711029,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14558075368404388,
      "attention_bam_16_std_attention": 0.5039228200912476,
      "attention_bam_16_max_attention": 2.390204906463623,
      "attention_bam_16_min_attention": -0.946740984916687,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.0026829750455417134,
      "attention_bam_16_attention_skewness": 0.46230594798433167,
      "attention_bam_16_attention_sparsity": 0.497314453125,
      "attention_bam_16_attention_concentration_10": 0.7482397467406727,
      "attention_bam_16_attention_concentration_20": 1.2227042652535924,
      "attention_bam_16_attention_center_y": 0.4637231031093768,
      "attention_bam_16_attention_center_x": 0.4544886185334576,
      "attention_bam_16_attention_center_distance": 0.0823079472591322,
      "attention_bam_16_attention_spatial_variance": 42.66286526962834,
      "attention_bam_16_attention_spatial_std": 6.531681657094775,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.501293281883292,
      "attention_bam_16_peak_intensity_mean": 0.34523722529411316,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 555,
      "phase": "train",
      "loss": 0.005603001918643713,
      "timestamp": 1759543976.075972,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005603001918643713,
      "ssim": 0.892641544342041,
      "attention_bam_384_mean_attention": 0.03172174468636513,
      "attention_bam_384_std_attention": 0.24822697043418884,
      "attention_bam_384_max_attention": 1.8512860536575317,
      "attention_bam_384_min_attention": -0.9332340359687805,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8116931751560674,
      "attention_bam_384_attention_skewness": 0.7523652594163348,
      "attention_bam_384_attention_sparsity": 0.6612625122070312,
      "attention_bam_384_attention_concentration_10": 1.6738834001233442,
      "attention_bam_384_attention_concentration_20": 2.505247649682741,
      "attention_bam_384_attention_center_y": 0.4809169527724103,
      "attention_bam_384_attention_center_x": 0.48319170102047115,
      "attention_bam_384_attention_center_distance": 0.03596335930014461,
      "attention_bam_384_attention_spatial_variance": 169.8991008206517,
      "attention_bam_384_attention_spatial_std": 13.034534929204483,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 18.671951830520623,
      "attention_bam_384_peak_intensity_mean": 0.35405415296554565,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14544415473937988,
      "attention_bam_16_std_attention": 0.5132918953895569,
      "attention_bam_16_max_attention": 2.637216091156006,
      "attention_bam_16_min_attention": -1.127248764038086,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.1182930418616719,
      "attention_bam_16_attention_skewness": 0.8204315570562921,
      "attention_bam_16_attention_sparsity": 0.5107421875,
      "attention_bam_16_attention_concentration_10": 0.8227668465053347,
      "attention_bam_16_attention_concentration_20": 1.2754201794103304,
      "attention_bam_16_attention_center_y": 0.45877194490998296,
      "attention_bam_16_attention_center_x": 0.4670320635663378,
      "attention_bam_16_attention_center_distance": 0.07465436838122026,
      "attention_bam_16_attention_spatial_variance": 41.967790489553664,
      "attention_bam_16_attention_spatial_std": 6.478255204108099,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.720942063175139,
      "attention_bam_16_peak_intensity_mean": 0.3390064537525177,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 556,
      "phase": "train",
      "loss": 0.0035138707607984543,
      "timestamp": 1759543976.2653887,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0035138707607984543,
      "ssim": 0.9450418949127197,
      "attention_bam_384_mean_attention": 0.03214917704463005,
      "attention_bam_384_std_attention": 0.26071006059646606,
      "attention_bam_384_max_attention": 2.241438388824463,
      "attention_bam_384_min_attention": -0.9118607044219971,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.3998024491329906,
      "attention_bam_384_attention_skewness": 0.6650022001170195,
      "attention_bam_384_attention_sparsity": 0.6334406534830729,
      "attention_bam_384_attention_concentration_10": 1.6649791899836106,
      "attention_bam_384_attention_concentration_20": 2.5807950563630992,
      "attention_bam_384_attention_center_y": 0.48372341845962674,
      "attention_bam_384_attention_center_x": 0.4861923015979265,
      "attention_bam_384_attention_center_distance": 0.030185415080897695,
      "attention_bam_384_attention_spatial_variance": 169.21793432381466,
      "attention_bam_384_attention_spatial_std": 13.008379388832978,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 18.832617492303555,
      "attention_bam_384_peak_intensity_mean": 0.3060407042503357,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14323993027210236,
      "attention_bam_16_std_attention": 0.5304055213928223,
      "attention_bam_16_max_attention": 2.7285306453704834,
      "attention_bam_16_min_attention": -1.0009583234786987,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7474860404295902,
      "attention_bam_16_attention_skewness": 0.748612851017131,
      "attention_bam_16_attention_sparsity": 0.509521484375,
      "attention_bam_16_attention_concentration_10": 0.8442692138740734,
      "attention_bam_16_attention_concentration_20": 1.3270899060170043,
      "attention_bam_16_attention_center_y": 0.4681778595700259,
      "attention_bam_16_attention_center_x": 0.4764199821184567,
      "attention_bam_16_attention_center_distance": 0.056011889181474574,
      "attention_bam_16_attention_spatial_variance": 41.41843816007412,
      "attention_bam_16_attention_spatial_std": 6.435715823439854,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 7.072856941555813,
      "attention_bam_16_peak_intensity_mean": 0.32393521070480347,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 557,
      "phase": "train",
      "loss": 0.004331430420279503,
      "timestamp": 1759543976.4507246,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004331430420279503,
      "ssim": 0.9241428971290588,
      "attention_bam_384_mean_attention": 0.031876467168331146,
      "attention_bam_384_std_attention": 0.27397724986076355,
      "attention_bam_384_max_attention": 1.7784756422042847,
      "attention_bam_384_min_attention": -1.1235612630844116,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5221214192296122,
      "attention_bam_384_attention_skewness": 0.5358663917428953,
      "attention_bam_384_attention_sparsity": 0.628387451171875,
      "attention_bam_384_attention_concentration_10": 1.7533596968500857,
      "attention_bam_384_attention_concentration_20": 2.754801127930673,
      "attention_bam_384_attention_center_y": 0.4825897144574007,
      "attention_bam_384_attention_center_x": 0.48002347907147735,
      "attention_bam_384_attention_center_distance": 0.037474776345764786,
      "attention_bam_384_attention_spatial_variance": 172.1855273788654,
      "attention_bam_384_attention_spatial_std": 13.121948307277597,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 18.54517519430836,
      "attention_bam_384_peak_intensity_mean": 0.40103933215141296,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.141000896692276,
      "attention_bam_16_std_attention": 0.5660163164138794,
      "attention_bam_16_max_attention": 2.782919406890869,
      "attention_bam_16_min_attention": -1.0225608348846436,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.26718106896873417,
      "attention_bam_16_attention_skewness": 0.6499911272299644,
      "attention_bam_16_attention_sparsity": 0.52294921875,
      "attention_bam_16_attention_concentration_10": 0.8924685148766306,
      "attention_bam_16_attention_concentration_20": 1.425071414128802,
      "attention_bam_16_attention_center_y": 0.46284081692292856,
      "attention_bam_16_attention_center_x": 0.45133622722725286,
      "attention_bam_16_attention_center_distance": 0.08659061920823616,
      "attention_bam_16_attention_spatial_variance": 44.04277742966409,
      "attention_bam_16_attention_spatial_std": 6.63647326745645,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 10.551391009728219,
      "attention_bam_16_peak_intensity_mean": 0.3139198124408722,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 558,
      "phase": "train",
      "loss": 0.0052916668355464935,
      "timestamp": 1759543976.6171958,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0052916668355464935,
      "ssim": 0.8977606892585754,
      "attention_bam_384_mean_attention": 0.031201034784317017,
      "attention_bam_384_std_attention": 0.2631109654903412,
      "attention_bam_384_max_attention": 2.0055532455444336,
      "attention_bam_384_min_attention": -0.9525265693664551,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.9006397426467814,
      "attention_bam_384_attention_skewness": 0.832881377765127,
      "attention_bam_384_attention_sparsity": 0.6490580240885416,
      "attention_bam_384_attention_concentration_10": 1.7974720763714578,
      "attention_bam_384_attention_concentration_20": 2.694956920195498,
      "attention_bam_384_attention_center_y": 0.48203835417115465,
      "attention_bam_384_attention_center_x": 0.4826789033986902,
      "attention_bam_384_attention_center_distance": 0.03528855645539455,
      "attention_bam_384_attention_spatial_variance": 171.39436832875865,
      "attention_bam_384_attention_spatial_std": 13.091767196553667,
      "attention_bam_384_num_attention_peaks": 18,
      "attention_bam_384_peak_separation_mean": 19.53228653404095,
      "attention_bam_384_peak_intensity_mean": 0.3404301106929779,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14343439042568207,
      "attention_bam_16_std_attention": 0.534824788570404,
      "attention_bam_16_max_attention": 2.748732328414917,
      "attention_bam_16_min_attention": -0.9335617423057556,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.0421789846752132,
      "attention_bam_16_attention_skewness": 0.8650572158096191,
      "attention_bam_16_attention_sparsity": 0.529541015625,
      "attention_bam_16_attention_concentration_10": 0.856513679638858,
      "attention_bam_16_attention_concentration_20": 1.3417977399693632,
      "attention_bam_16_attention_center_y": 0.4616542648026719,
      "attention_bam_16_attention_center_x": 0.4641274978840568,
      "attention_bam_16_attention_center_distance": 0.07425943463132417,
      "attention_bam_16_attention_spatial_variance": 43.14032615557114,
      "attention_bam_16_attention_spatial_std": 6.568129578165395,
      "attention_bam_16_num_attention_peaks": 12,
      "attention_bam_16_peak_separation_mean": 10.214628611978037,
      "attention_bam_16_peak_intensity_mean": 0.3105117678642273,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 559,
      "phase": "train",
      "loss": 0.0053056590259075165,
      "timestamp": 1759543976.7832468,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0053056590259075165,
      "ssim": 0.9304206371307373,
      "attention_bam_384_mean_attention": 0.03014056384563446,
      "attention_bam_384_std_attention": 0.26719942688941956,
      "attention_bam_384_max_attention": 2.677030563354492,
      "attention_bam_384_min_attention": -0.953333854675293,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.675550126826896,
      "attention_bam_384_attention_skewness": 1.0918817931340201,
      "attention_bam_384_attention_sparsity": 0.6568552652994791,
      "attention_bam_384_attention_concentration_10": 1.8906082087992857,
      "attention_bam_384_attention_concentration_20": 2.791063491566748,
      "attention_bam_384_attention_center_y": 0.49058774066796773,
      "attention_bam_384_attention_center_x": 0.48822283258156157,
      "attention_bam_384_attention_center_distance": 0.02132098957062529,
      "attention_bam_384_attention_spatial_variance": 170.9617257827712,
      "attention_bam_384_attention_spatial_std": 13.075233297450994,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 18.491167486887278,
      "attention_bam_384_peak_intensity_mean": 0.274008572101593,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1335591971874237,
      "attention_bam_16_std_attention": 0.5593782067298889,
      "attention_bam_16_max_attention": 3.5138864517211914,
      "attention_bam_16_min_attention": -1.0868847370147705,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.3891506744112174,
      "attention_bam_16_attention_skewness": 1.3695660535441145,
      "attention_bam_16_attention_sparsity": 0.546630859375,
      "attention_bam_16_attention_concentration_10": 0.9939617355870507,
      "attention_bam_16_attention_concentration_20": 1.4799590672769296,
      "attention_bam_16_attention_center_y": 0.49139761096078505,
      "attention_bam_16_attention_center_x": 0.48316525275690647,
      "attention_bam_16_attention_center_distance": 0.02673611085856919,
      "attention_bam_16_attention_spatial_variance": 42.91669911517176,
      "attention_bam_16_attention_spatial_std": 6.551083812253646,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 10.690620383995107,
      "attention_bam_16_peak_intensity_mean": 0.276115357875824,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 560,
      "phase": "train",
      "loss": 0.003976567182689905,
      "timestamp": 1759543977.0052025,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.003976567182689905,
      "ssim": 0.9317276477813721,
      "attention_bam_384_mean_attention": 0.030869469046592712,
      "attention_bam_384_std_attention": 0.2878356873989105,
      "attention_bam_384_max_attention": 2.5848348140716553,
      "attention_bam_384_min_attention": -0.9852144718170166,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.7868604371894419,
      "attention_bam_384_attention_skewness": 0.8054147597290395,
      "attention_bam_384_attention_sparsity": 0.6386845906575521,
      "attention_bam_384_attention_concentration_10": 1.9561668875072482,
      "attention_bam_384_attention_concentration_20": 2.9725339891799036,
      "attention_bam_384_attention_center_y": 0.4860468333040742,
      "attention_bam_384_attention_center_x": 0.4816179877641553,
      "attention_bam_384_attention_center_distance": 0.03263707200969584,
      "attention_bam_384_attention_spatial_variance": 169.33641311026784,
      "attention_bam_384_attention_spatial_std": 13.012932533071393,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 18.76145963638492,
      "attention_bam_384_peak_intensity_mean": 0.2871514856815338,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13286009430885315,
      "attention_bam_16_std_attention": 0.5875067710876465,
      "attention_bam_16_max_attention": 3.2295665740966797,
      "attention_bam_16_min_attention": -1.1260088682174683,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.682708019959735,
      "attention_bam_16_attention_skewness": 1.0542198708490198,
      "attention_bam_16_attention_sparsity": 0.544921875,
      "attention_bam_16_attention_concentration_10": 1.025295953700783,
      "attention_bam_16_attention_concentration_20": 1.5688085247841785,
      "attention_bam_16_attention_center_y": 0.4739855951808946,
      "attention_bam_16_attention_center_x": 0.4616802053231748,
      "attention_bam_16_attention_center_distance": 0.06550047209244124,
      "attention_bam_16_attention_spatial_variance": 41.37401095387497,
      "attention_bam_16_attention_spatial_std": 6.432263283936298,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.295077233828623,
      "attention_bam_16_peak_intensity_mean": 0.2934681177139282,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 561,
      "phase": "train",
      "loss": 0.0037082924973219633,
      "timestamp": 1759543977.1684325,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0037082924973219633,
      "ssim": 0.9236125946044922,
      "attention_bam_384_mean_attention": 0.028660783544182777,
      "attention_bam_384_std_attention": 0.2589319348335266,
      "attention_bam_384_max_attention": 1.9766387939453125,
      "attention_bam_384_min_attention": -1.0476220846176147,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.6874993953760606,
      "attention_bam_384_attention_skewness": 0.8290194425472996,
      "attention_bam_384_attention_sparsity": 0.6540247599283854,
      "attention_bam_384_attention_concentration_10": 1.9219552672361508,
      "attention_bam_384_attention_concentration_20": 2.8962902010969453,
      "attention_bam_384_attention_center_y": 0.48781444320917244,
      "attention_bam_384_attention_center_x": 0.48413049138843545,
      "attention_bam_384_attention_center_distance": 0.028295904222166324,
      "attention_bam_384_attention_spatial_variance": 169.45836757340513,
      "attention_bam_384_attention_spatial_std": 13.01761758438944,
      "attention_bam_384_num_attention_peaks": 19,
      "attention_bam_384_peak_separation_mean": 17.20683820548269,
      "attention_bam_384_peak_intensity_mean": 0.35977238416671753,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12503808736801147,
      "attention_bam_16_std_attention": 0.5360361337661743,
      "attention_bam_16_max_attention": 2.5029261112213135,
      "attention_bam_16_min_attention": -1.0148142576217651,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8445135160267347,
      "attention_bam_16_attention_skewness": 0.8505732561843549,
      "attention_bam_16_attention_sparsity": 0.53857421875,
      "attention_bam_16_attention_concentration_10": 0.9769108314221892,
      "attention_bam_16_attention_concentration_20": 1.5228967041700636,
      "attention_bam_16_attention_center_y": 0.4813180494134069,
      "attention_bam_16_attention_center_x": 0.4696210991039568,
      "attention_bam_16_attention_center_distance": 0.05043595735923969,
      "attention_bam_16_attention_spatial_variance": 41.1988046552207,
      "attention_bam_16_attention_spatial_std": 6.418629499762445,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 8.209956507109919,
      "attention_bam_16_peak_intensity_mean": 0.3353549540042877,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 562,
      "phase": "train",
      "loss": 0.005378022789955139,
      "timestamp": 1759543977.318613,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005378022789955139,
      "ssim": 0.9095364809036255,
      "attention_bam_384_mean_attention": 0.029131615534424782,
      "attention_bam_384_std_attention": 0.2889152765274048,
      "attention_bam_384_max_attention": 2.187300682067871,
      "attention_bam_384_min_attention": -1.0815153121948242,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5230541660596062,
      "attention_bam_384_attention_skewness": 0.7710417675726416,
      "attention_bam_384_attention_sparsity": 0.6484324137369791,
      "attention_bam_384_attention_concentration_10": 2.110931191620824,
      "attention_bam_384_attention_concentration_20": 3.171538332083897,
      "attention_bam_384_attention_center_y": 0.48086826849264813,
      "attention_bam_384_attention_center_x": 0.47895553133708757,
      "attention_bam_384_attention_center_distance": 0.04022170587565135,
      "attention_bam_384_attention_spatial_variance": 171.5473257942432,
      "attention_bam_384_attention_spatial_std": 13.097607636291569,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 17.09163921013726,
      "attention_bam_384_peak_intensity_mean": 0.3453139066696167,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12119530886411667,
      "attention_bam_16_std_attention": 0.5908471345901489,
      "attention_bam_16_max_attention": 2.9333720207214355,
      "attention_bam_16_min_attention": -1.1283875703811646,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.164776743058205,
      "attention_bam_16_attention_skewness": 0.9909934694310699,
      "attention_bam_16_attention_sparsity": 0.56103515625,
      "attention_bam_16_attention_concentration_10": 1.1254551131330979,
      "attention_bam_16_attention_concentration_20": 1.7380179790593995,
      "attention_bam_16_attention_center_y": 0.45622537261405777,
      "attention_bam_16_attention_center_x": 0.4505490914888983,
      "attention_bam_16_attention_center_distance": 0.0933981836584784,
      "attention_bam_16_attention_spatial_variance": 43.448951546692726,
      "attention_bam_16_attention_spatial_std": 6.5915818698316055,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.17325133020529,
      "attention_bam_16_peak_intensity_mean": 0.3208578824996948,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 563,
      "phase": "train",
      "loss": 0.007304251194000244,
      "timestamp": 1759543977.4650066,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007304251194000244,
      "ssim": 0.9201080799102783,
      "attention_bam_384_mean_attention": 0.02862331084907055,
      "attention_bam_384_std_attention": 0.28480297327041626,
      "attention_bam_384_max_attention": 2.3972244262695312,
      "attention_bam_384_min_attention": -0.967722475528717,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8265528517160616,
      "attention_bam_384_attention_skewness": 0.8196911928020328,
      "attention_bam_384_attention_sparsity": 0.6375045776367188,
      "attention_bam_384_attention_concentration_10": 2.0725433953051824,
      "attention_bam_384_attention_concentration_20": 3.1426687121407095,
      "attention_bam_384_attention_center_y": 0.47830188693261205,
      "attention_bam_384_attention_center_x": 0.486827985498005,
      "attention_bam_384_attention_center_distance": 0.035897355800279175,
      "attention_bam_384_attention_spatial_variance": 171.1198140096157,
      "attention_bam_384_attention_spatial_std": 13.081277231586208,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 19.347805597051412,
      "attention_bam_384_peak_intensity_mean": 0.29996392130851746,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1300240010023117,
      "attention_bam_16_std_attention": 0.5814037919044495,
      "attention_bam_16_max_attention": 3.530932903289795,
      "attention_bam_16_min_attention": -1.0789350271224976,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.5326233723069471,
      "attention_bam_16_attention_skewness": 0.9860177780138021,
      "attention_bam_16_attention_sparsity": 0.543212890625,
      "attention_bam_16_attention_concentration_10": 1.0154169898762588,
      "attention_bam_16_attention_concentration_20": 1.5722206756867458,
      "attention_bam_16_attention_center_y": 0.4485390264864561,
      "attention_bam_16_attention_center_x": 0.47896784243430274,
      "attention_bam_16_attention_center_distance": 0.07862039744023153,
      "attention_bam_16_attention_spatial_variance": 42.71721678902708,
      "attention_bam_16_attention_spatial_std": 6.53584093969759,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.72626625209242,
      "attention_bam_16_peak_intensity_mean": 0.2674708366394043,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 564,
      "phase": "train",
      "loss": 0.004455124493688345,
      "timestamp": 1759543977.6058993,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004455124493688345,
      "ssim": 0.9300780296325684,
      "attention_bam_384_mean_attention": 0.029093416407704353,
      "attention_bam_384_std_attention": 0.2662774920463562,
      "attention_bam_384_max_attention": 2.153892755508423,
      "attention_bam_384_min_attention": -0.9736398458480835,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.1456433608901433,
      "attention_bam_384_attention_skewness": 0.8571901403234535,
      "attention_bam_384_attention_sparsity": 0.6545308430989584,
      "attention_bam_384_attention_concentration_10": 1.945037614310134,
      "attention_bam_384_attention_concentration_20": 2.90581470558129,
      "attention_bam_384_attention_center_y": 0.48251273964185326,
      "attention_bam_384_attention_center_x": 0.4809607382053083,
      "attention_bam_384_attention_center_distance": 0.03655947933219007,
      "attention_bam_384_attention_spatial_variance": 171.4533719991331,
      "attention_bam_384_attention_spatial_std": 13.094020467340545,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 16.607795087853933,
      "attention_bam_384_peak_intensity_mean": 0.3244726359844208,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13342434167861938,
      "attention_bam_16_std_attention": 0.5574275255203247,
      "attention_bam_16_max_attention": 2.9769885540008545,
      "attention_bam_16_min_attention": -0.9820612668991089,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.4560614785375607,
      "attention_bam_16_attention_skewness": 1.0109293791445686,
      "attention_bam_16_attention_sparsity": 0.537109375,
      "attention_bam_16_attention_concentration_10": 0.9832485216410383,
      "attention_bam_16_attention_concentration_20": 1.4894808506715873,
      "attention_bam_16_attention_center_y": 0.46600224137981705,
      "attention_bam_16_attention_center_x": 0.4567438955938183,
      "attention_bam_16_attention_center_distance": 0.0778066598639823,
      "attention_bam_16_attention_spatial_variance": 43.30863100898109,
      "attention_bam_16_attention_spatial_std": 6.58092934234832,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 10.305094338820364,
      "attention_bam_16_peak_intensity_mean": 0.2883749008178711,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 565,
      "phase": "train",
      "loss": 0.00487444456666708,
      "timestamp": 1759543977.745994,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00487444456666708,
      "ssim": 0.9197316765785217,
      "attention_bam_384_mean_attention": 0.030591249465942383,
      "attention_bam_384_std_attention": 0.29217034578323364,
      "attention_bam_384_max_attention": 2.40863037109375,
      "attention_bam_384_min_attention": -1.1161115169525146,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8616709155475615,
      "attention_bam_384_attention_skewness": 0.717673057273374,
      "attention_bam_384_attention_sparsity": 0.6293055216471354,
      "attention_bam_384_attention_concentration_10": 1.972740123450339,
      "attention_bam_384_attention_concentration_20": 2.980891181961894,
      "attention_bam_384_attention_center_y": 0.4842894901696231,
      "attention_bam_384_attention_center_x": 0.48036848422570483,
      "attention_bam_384_attention_center_distance": 0.03555886755021228,
      "attention_bam_384_attention_spatial_variance": 171.5423495172021,
      "attention_bam_384_attention_spatial_std": 13.097417665982944,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 21.03250560331888,
      "attention_bam_384_peak_intensity_mean": 0.33116745948791504,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13893060386180878,
      "attention_bam_16_std_attention": 0.5914265513420105,
      "attention_bam_16_max_attention": 2.9912569522857666,
      "attention_bam_16_min_attention": -1.2352008819580078,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.1827377122968548,
      "attention_bam_16_attention_skewness": 0.8897564507758122,
      "attention_bam_16_attention_sparsity": 0.53076171875,
      "attention_bam_16_attention_concentration_10": 0.9746650256304984,
      "attention_bam_16_attention_concentration_20": 1.5100976835088404,
      "attention_bam_16_attention_center_y": 0.47099115308521133,
      "attention_bam_16_attention_center_x": 0.45563488014789644,
      "attention_bam_16_attention_center_distance": 0.07496368532585838,
      "attention_bam_16_attention_spatial_variance": 43.0864632834355,
      "attention_bam_16_attention_spatial_std": 6.564027977045459,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.974735077105104,
      "attention_bam_16_peak_intensity_mean": 0.332001656293869,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 566,
      "phase": "train",
      "loss": 0.004561197012662888,
      "timestamp": 1759543977.8849788,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004561197012662888,
      "ssim": 0.9219897985458374,
      "attention_bam_384_mean_attention": 0.030416933819651604,
      "attention_bam_384_std_attention": 0.28783220052719116,
      "attention_bam_384_max_attention": 2.1718170642852783,
      "attention_bam_384_min_attention": -0.8480808734893799,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7922561758391491,
      "attention_bam_384_attention_skewness": 0.6523834635115613,
      "attention_bam_384_attention_sparsity": 0.6304575602213541,
      "attention_bam_384_attention_concentration_10": 1.9563856223409286,
      "attention_bam_384_attention_concentration_20": 3.0384160000301192,
      "attention_bam_384_attention_center_y": 0.48570141265164035,
      "attention_bam_384_attention_center_x": 0.4848294821754824,
      "attention_bam_384_attention_center_distance": 0.029482001669584014,
      "attention_bam_384_attention_spatial_variance": 172.55473495661158,
      "attention_bam_384_attention_spatial_std": 13.13600909548298,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 17.179694302466434,
      "attention_bam_384_peak_intensity_mean": 0.2919919788837433,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1274426281452179,
      "attention_bam_16_std_attention": 0.5828573703765869,
      "attention_bam_16_max_attention": 2.651799440383911,
      "attention_bam_16_min_attention": -1.0287432670593262,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.42155679766742393,
      "attention_bam_16_attention_skewness": 0.7652675827301977,
      "attention_bam_16_attention_sparsity": 0.542724609375,
      "attention_bam_16_attention_concentration_10": 1.0252608292320542,
      "attention_bam_16_attention_concentration_20": 1.6212210889332606,
      "attention_bam_16_attention_center_y": 0.475034073867448,
      "attention_bam_16_attention_center_x": 0.4719513676801777,
      "attention_bam_16_attention_center_distance": 0.05310410987237471,
      "attention_bam_16_attention_spatial_variance": 44.24082829306362,
      "attention_bam_16_attention_spatial_std": 6.651377924390075,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.399716398319372,
      "attention_bam_16_peak_intensity_mean": 0.3205740749835968,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 567,
      "phase": "train",
      "loss": 0.0033419374376535416,
      "timestamp": 1759543978.020816,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0033419374376535416,
      "ssim": 0.9299187064170837,
      "attention_bam_384_mean_attention": 0.02872641384601593,
      "attention_bam_384_std_attention": 0.2967490255832672,
      "attention_bam_384_max_attention": 3.8413476943969727,
      "attention_bam_384_min_attention": -1.1496285200119019,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 7.964531308716168,
      "attention_bam_384_attention_skewness": 1.612352904393224,
      "attention_bam_384_attention_sparsity": 0.6631393432617188,
      "attention_bam_384_attention_concentration_10": 2.2079729694894734,
      "attention_bam_384_attention_concentration_20": 3.1751282249434185,
      "attention_bam_384_attention_center_y": 0.48704250996797194,
      "attention_bam_384_attention_center_x": 0.47995319398005726,
      "attention_bam_384_attention_center_distance": 0.033757102349915025,
      "attention_bam_384_attention_spatial_variance": 172.3019103203405,
      "attention_bam_384_attention_spatial_std": 13.126382225135016,
      "attention_bam_384_num_attention_peaks": 20,
      "attention_bam_384_peak_separation_mean": 20.014849797028752,
      "attention_bam_384_peak_intensity_mean": 0.23808681964874268,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12422045320272446,
      "attention_bam_16_std_attention": 0.6131131649017334,
      "attention_bam_16_max_attention": 5.671030044555664,
      "attention_bam_16_min_attention": -1.0427836179733276,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 7.870485802815638,
      "attention_bam_16_attention_skewness": 1.9033348531377086,
      "attention_bam_16_attention_sparsity": 0.554443359375,
      "attention_bam_16_attention_concentration_10": 1.156769732232973,
      "attention_bam_16_attention_concentration_20": 1.6746690840150509,
      "attention_bam_16_attention_center_y": 0.47907231435487396,
      "attention_bam_16_attention_center_x": 0.4523667402834087,
      "attention_bam_16_attention_center_distance": 0.07357846774280442,
      "attention_bam_16_attention_spatial_variance": 44.07952515221189,
      "attention_bam_16_attention_spatial_std": 6.639241308478845,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 10.182281195191788,
      "attention_bam_16_peak_intensity_mean": 0.17640390992164612,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 568,
      "phase": "train",
      "loss": 0.005133302416652441,
      "timestamp": 1759543978.1575594,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005133302416652441,
      "ssim": 0.9286226630210876,
      "attention_bam_384_mean_attention": 0.03207434341311455,
      "attention_bam_384_std_attention": 0.2565511465072632,
      "attention_bam_384_max_attention": 1.8918002843856812,
      "attention_bam_384_min_attention": -0.8316009044647217,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.4678071006309725,
      "attention_bam_384_attention_skewness": 0.4756977625218107,
      "attention_bam_384_attention_sparsity": 0.6209767659505209,
      "attention_bam_384_attention_concentration_10": 1.6158779239709686,
      "attention_bam_384_attention_concentration_20": 2.5383448509628117,
      "attention_bam_384_attention_center_y": 0.48502548060890843,
      "attention_bam_384_attention_center_x": 0.483810591223026,
      "attention_bam_384_attention_center_distance": 0.031187599700590624,
      "attention_bam_384_attention_spatial_variance": 171.63935816879345,
      "attention_bam_384_attention_spatial_std": 13.101120492873632,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 18.641551092707047,
      "attention_bam_384_peak_intensity_mean": 0.3197539746761322,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14075486361980438,
      "attention_bam_16_std_attention": 0.5330467820167542,
      "attention_bam_16_max_attention": 2.3451452255249023,
      "attention_bam_16_min_attention": -1.0582071542739868,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.15187550887630952,
      "attention_bam_16_attention_skewness": 0.5626327545177697,
      "attention_bam_16_attention_sparsity": 0.509033203125,
      "attention_bam_16_attention_concentration_10": 0.8384625433601001,
      "attention_bam_16_attention_concentration_20": 1.3425509842715908,
      "attention_bam_16_attention_center_y": 0.47199667783309673,
      "attention_bam_16_attention_center_x": 0.4685377704637882,
      "attention_bam_16_attention_center_distance": 0.05956606315298425,
      "attention_bam_16_attention_spatial_variance": 43.3137462543997,
      "attention_bam_16_attention_spatial_std": 6.581317972442883,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.14783922427555,
      "attention_bam_16_peak_intensity_mean": 0.35438868403434753,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 569,
      "phase": "train",
      "loss": 0.00477485079318285,
      "timestamp": 1759543978.3268194,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00477485079318285,
      "ssim": 0.9031161069869995,
      "attention_bam_384_mean_attention": 0.02946046181023121,
      "attention_bam_384_std_attention": 0.280752032995224,
      "attention_bam_384_max_attention": 2.2829790115356445,
      "attention_bam_384_min_attention": -0.8492809534072876,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.501668895585878,
      "attention_bam_384_attention_skewness": 0.8335680360473061,
      "attention_bam_384_attention_sparsity": 0.6439183553059896,
      "attention_bam_384_attention_concentration_10": 2.0254389750275648,
      "attention_bam_384_attention_concentration_20": 3.0641131870229597,
      "attention_bam_384_attention_center_y": 0.48206990810381967,
      "attention_bam_384_attention_center_x": 0.48104460365611595,
      "attention_bam_384_attention_center_distance": 0.03689973566190425,
      "attention_bam_384_attention_spatial_variance": 170.15793598737332,
      "attention_bam_384_attention_spatial_std": 13.044459973006676,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 18.785147177089424,
      "attention_bam_384_peak_intensity_mean": 0.28484615683555603,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12557902932167053,
      "attention_bam_16_std_attention": 0.5868839025497437,
      "attention_bam_16_max_attention": 2.8270673751831055,
      "attention_bam_16_min_attention": -0.9653301239013672,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7696999022912365,
      "attention_bam_16_attention_skewness": 0.9270843904288399,
      "attention_bam_16_attention_sparsity": 0.556396484375,
      "attention_bam_16_attention_concentration_10": 1.08087223369669,
      "attention_bam_16_attention_concentration_20": 1.6740195688390471,
      "attention_bam_16_attention_center_y": 0.4628609201082884,
      "attention_bam_16_attention_center_x": 0.4592208156250589,
      "attention_bam_16_attention_center_distance": 0.07800324523362318,
      "attention_bam_16_attention_spatial_variance": 42.08593206767252,
      "attention_bam_16_attention_spatial_std": 6.487367113681214,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.293993545891642,
      "attention_bam_16_peak_intensity_mean": 0.30230048298835754,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 570,
      "phase": "train",
      "loss": 0.005305183585733175,
      "timestamp": 1759543978.5710154,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005305183585733175,
      "ssim": 0.8996365070343018,
      "attention_bam_384_mean_attention": 0.031419526785612106,
      "attention_bam_384_std_attention": 0.23812563717365265,
      "attention_bam_384_max_attention": 2.344951629638672,
      "attention_bam_384_min_attention": -0.7882422208786011,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.9224113173692583,
      "attention_bam_384_attention_skewness": 0.7328094257278639,
      "attention_bam_384_attention_sparsity": 0.6470794677734375,
      "attention_bam_384_attention_concentration_10": 1.5814522164415916,
      "attention_bam_384_attention_concentration_20": 2.410216223443592,
      "attention_bam_384_attention_center_y": 0.4838324096353281,
      "attention_bam_384_attention_center_x": 0.48307461648528943,
      "attention_bam_384_attention_center_distance": 0.03310164906224064,
      "attention_bam_384_attention_spatial_variance": 171.16070522670034,
      "attention_bam_384_attention_spatial_std": 13.082840105523736,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 19.09763639354625,
      "attention_bam_384_peak_intensity_mean": 0.26392626762390137,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14258445799350739,
      "attention_bam_16_std_attention": 0.515861988067627,
      "attention_bam_16_max_attention": 2.7433228492736816,
      "attention_bam_16_min_attention": -1.0493499040603638,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.2391105287076503,
      "attention_bam_16_attention_skewness": 0.8527111863270884,
      "attention_bam_16_attention_sparsity": 0.525146484375,
      "attention_bam_16_attention_concentration_10": 0.8371973106703874,
      "attention_bam_16_attention_concentration_20": 1.3045267158332758,
      "attention_bam_16_attention_center_y": 0.46788256241489606,
      "attention_bam_16_attention_center_x": 0.46543234637033964,
      "attention_bam_16_attention_center_distance": 0.06673009028156963,
      "attention_bam_16_attention_spatial_variance": 42.99290135633642,
      "attention_bam_16_attention_spatial_std": 6.556897235456448,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.206116268118711,
      "attention_bam_16_peak_intensity_mean": 0.3171156048774719,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 571,
      "phase": "train",
      "loss": 0.0037810057401657104,
      "timestamp": 1759543978.7557032,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0037810057401657104,
      "ssim": 0.9312288165092468,
      "attention_bam_384_mean_attention": 0.029421770945191383,
      "attention_bam_384_std_attention": 0.2690688967704773,
      "attention_bam_384_max_attention": 2.118042469024658,
      "attention_bam_384_min_attention": -0.8799208998680115,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.482938598678052,
      "attention_bam_384_attention_skewness": 0.7224276779131398,
      "attention_bam_384_attention_sparsity": 0.6425399780273438,
      "attention_bam_384_attention_concentration_10": 1.9006760492506005,
      "attention_bam_384_attention_concentration_20": 2.8965073180259546,
      "attention_bam_384_attention_center_y": 0.48167903186780797,
      "attention_bam_384_attention_center_x": 0.47542784968735835,
      "attention_bam_384_attention_center_distance": 0.04334624422687278,
      "attention_bam_384_attention_spatial_variance": 171.6281714209503,
      "attention_bam_384_attention_spatial_std": 13.100693547326046,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 15.125624606618281,
      "attention_bam_384_peak_intensity_mean": 0.3042239844799042,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1307350993156433,
      "attention_bam_16_std_attention": 0.5673993825912476,
      "attention_bam_16_max_attention": 3.307433605194092,
      "attention_bam_16_min_attention": -0.9543535709381104,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.1027164903530613,
      "attention_bam_16_attention_skewness": 0.8855471814909928,
      "attention_bam_16_attention_sparsity": 0.537109375,
      "attention_bam_16_attention_concentration_10": 0.9887340080449233,
      "attention_bam_16_attention_concentration_20": 1.5341168912770171,
      "attention_bam_16_attention_center_y": 0.46139831284626576,
      "attention_bam_16_attention_center_x": 0.43959803348854504,
      "attention_bam_16_attention_center_distance": 0.10137541920569992,
      "attention_bam_16_attention_spatial_variance": 43.00845508315423,
      "attention_bam_16_attention_spatial_std": 6.5580831866601255,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 7.998097451806107,
      "attention_bam_16_peak_intensity_mean": 0.2677370309829712,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 572,
      "phase": "train",
      "loss": 0.003673507599160075,
      "timestamp": 1759543978.9264393,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.003673507599160075,
      "ssim": 0.943139910697937,
      "attention_bam_384_mean_attention": 0.030651694163680077,
      "attention_bam_384_std_attention": 0.24417133629322052,
      "attention_bam_384_max_attention": 1.9591296911239624,
      "attention_bam_384_min_attention": -0.7783194184303284,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1636863039149032,
      "attention_bam_384_attention_skewness": 0.714316232283222,
      "attention_bam_384_attention_sparsity": 0.6464945475260416,
      "attention_bam_384_attention_concentration_10": 1.6708786791626584,
      "attention_bam_384_attention_concentration_20": 2.575431441347492,
      "attention_bam_384_attention_center_y": 0.4845825683279343,
      "attention_bam_384_attention_center_x": 0.4834497286341109,
      "attention_bam_384_attention_center_distance": 0.03198776896400822,
      "attention_bam_384_attention_spatial_variance": 173.73137984103738,
      "attention_bam_384_attention_spatial_std": 13.18072000465215,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 19.867084713978752,
      "attention_bam_384_peak_intensity_mean": 0.300702303647995,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12865473330020905,
      "attention_bam_16_std_attention": 0.5160353183746338,
      "attention_bam_16_max_attention": 2.322399377822876,
      "attention_bam_16_min_attention": -0.8940184712409973,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.38569556014873196,
      "attention_bam_16_attention_skewness": 0.751121547517674,
      "attention_bam_16_attention_sparsity": 0.539794921875,
      "attention_bam_16_attention_concentration_10": 0.9090564570327894,
      "attention_bam_16_attention_concentration_20": 1.4464963753535645,
      "attention_bam_16_attention_center_y": 0.4721744691541069,
      "attention_bam_16_attention_center_x": 0.4677647697592465,
      "attention_bam_16_attention_center_distance": 0.060222424984886426,
      "attention_bam_16_attention_spatial_variance": 44.88165117868287,
      "attention_bam_16_attention_spatial_std": 6.699376924661194,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 11.368215016961276,
      "attention_bam_16_peak_intensity_mean": 0.3343866169452667,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 573,
      "phase": "train",
      "loss": 0.005216180346906185,
      "timestamp": 1759543979.0842466,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005216180346906185,
      "ssim": 0.9174809455871582,
      "attention_bam_384_mean_attention": 0.030986512079834938,
      "attention_bam_384_std_attention": 0.25276827812194824,
      "attention_bam_384_max_attention": 1.705071210861206,
      "attention_bam_384_min_attention": -0.8464275002479553,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5989739679322521,
      "attention_bam_384_attention_skewness": 0.4708633396850116,
      "attention_bam_384_attention_sparsity": 0.6323216756184896,
      "attention_bam_384_attention_concentration_10": 1.6643855829253065,
      "attention_bam_384_attention_concentration_20": 2.5898534385909513,
      "attention_bam_384_attention_center_y": 0.4803321584104787,
      "attention_bam_384_attention_center_x": 0.4790691312319813,
      "attention_bam_384_attention_center_distance": 0.04061835201419485,
      "attention_bam_384_attention_spatial_variance": 170.51998331560284,
      "attention_bam_384_attention_spatial_std": 13.058330035483207,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 20.131401433619782,
      "attention_bam_384_peak_intensity_mean": 0.3512297570705414,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1486486792564392,
      "attention_bam_16_std_attention": 0.5325261354446411,
      "attention_bam_16_max_attention": 2.2192115783691406,
      "attention_bam_16_min_attention": -1.04745614528656,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.24678659716143514,
      "attention_bam_16_attention_skewness": 0.5843925876431515,
      "attention_bam_16_attention_sparsity": 0.505859375,
      "attention_bam_16_attention_concentration_10": 0.8059799948622813,
      "attention_bam_16_attention_concentration_20": 1.2831469326481346,
      "attention_bam_16_attention_center_y": 0.4562615722997175,
      "attention_bam_16_attention_center_x": 0.4520969721768438,
      "attention_bam_16_attention_center_distance": 0.09173603580184744,
      "attention_bam_16_attention_spatial_variance": 42.53060268720378,
      "attention_bam_16_attention_spatial_std": 6.52154910180118,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.159900449280752,
      "attention_bam_16_peak_intensity_mean": 0.37515589594841003,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 574,
      "phase": "train",
      "loss": 0.00683264946565032,
      "timestamp": 1759543979.2364664,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00683264946565032,
      "ssim": 0.9137556552886963,
      "attention_bam_384_mean_attention": 0.029118424281477928,
      "attention_bam_384_std_attention": 0.26035863161087036,
      "attention_bam_384_max_attention": 1.510333776473999,
      "attention_bam_384_min_attention": -0.8070358633995056,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.4968844409909803,
      "attention_bam_384_attention_skewness": 0.5093017185008165,
      "attention_bam_384_attention_sparsity": 0.6352793375651041,
      "attention_bam_384_attention_concentration_10": 1.8404858287148051,
      "attention_bam_384_attention_concentration_20": 2.8481546447597417,
      "attention_bam_384_attention_center_y": 0.48188072361664364,
      "attention_bam_384_attention_center_x": 0.4816482168225983,
      "attention_bam_384_attention_center_distance": 0.03647180068071277,
      "attention_bam_384_attention_spatial_variance": 168.49315148202697,
      "attention_bam_384_attention_spatial_std": 12.980491188010836,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 16.025030780714495,
      "attention_bam_384_peak_intensity_mean": 0.36065083742141724,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1265307515859604,
      "attention_bam_16_std_attention": 0.5375255942344666,
      "attention_bam_16_max_attention": 2.1688485145568848,
      "attention_bam_16_min_attention": -1.043597936630249,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.05162583561612433,
      "attention_bam_16_attention_skewness": 0.5903157585901267,
      "attention_bam_16_attention_sparsity": 0.526123046875,
      "attention_bam_16_attention_concentration_10": 0.939199077629857,
      "attention_bam_16_attention_concentration_20": 1.503456641358947,
      "attention_bam_16_attention_center_y": 0.46364042008800627,
      "attention_bam_16_attention_center_x": 0.4607551499162114,
      "attention_bam_16_attention_center_distance": 0.07565946483389502,
      "attention_bam_16_attention_spatial_variance": 40.866816363681004,
      "attention_bam_16_attention_spatial_std": 6.392715883228426,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.072581427153523,
      "attention_bam_16_peak_intensity_mean": 0.3636746406555176,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 575,
      "phase": "train",
      "loss": 0.004901761654764414,
      "timestamp": 1759543979.3803945,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004901761654764414,
      "ssim": 0.9243810772895813,
      "attention_bam_384_mean_attention": 0.02830774150788784,
      "attention_bam_384_std_attention": 0.25222331285476685,
      "attention_bam_384_max_attention": 1.6437036991119385,
      "attention_bam_384_min_attention": -0.8689585328102112,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0123941940148748,
      "attention_bam_384_attention_skewness": 0.647548616184115,
      "attention_bam_384_attention_sparsity": 0.6480484008789062,
      "attention_bam_384_attention_concentration_10": 1.860398859397381,
      "attention_bam_384_attention_concentration_20": 2.8476449180292502,
      "attention_bam_384_attention_center_y": 0.4811470392513472,
      "attention_bam_384_attention_center_x": 0.4831667944277759,
      "attention_bam_384_attention_center_distance": 0.035743277377067686,
      "attention_bam_384_attention_spatial_variance": 169.6432052461606,
      "attention_bam_384_attention_spatial_std": 13.024715169483,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 17.72923759845552,
      "attention_bam_384_peak_intensity_mean": 0.3596268594264984,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12517651915550232,
      "attention_bam_16_std_attention": 0.5436064600944519,
      "attention_bam_16_max_attention": 2.4432969093322754,
      "attention_bam_16_min_attention": -1.0588045120239258,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7309606566865297,
      "attention_bam_16_attention_skewness": 0.8283773552035253,
      "attention_bam_16_attention_sparsity": 0.539306640625,
      "attention_bam_16_attention_concentration_10": 0.9876550719566088,
      "attention_bam_16_attention_concentration_20": 1.5407922000105656,
      "attention_bam_16_attention_center_y": 0.45562684753018556,
      "attention_bam_16_attention_center_x": 0.4633482900387437,
      "attention_bam_16_attention_center_distance": 0.081391946815314,
      "attention_bam_16_attention_spatial_variance": 41.50221395371531,
      "attention_bam_16_attention_spatial_std": 6.442221197204836,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 10.148966782932147,
      "attention_bam_16_peak_intensity_mean": 0.35315507650375366,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 576,
      "phase": "train",
      "loss": 0.004810911603271961,
      "timestamp": 1759543979.5242503,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004810911603271961,
      "ssim": 0.904138445854187,
      "attention_bam_384_mean_attention": 0.028362968936562538,
      "attention_bam_384_std_attention": 0.2845567762851715,
      "attention_bam_384_max_attention": 1.7036792039871216,
      "attention_bam_384_min_attention": -0.8747462034225464,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1853514183643066,
      "attention_bam_384_attention_skewness": 0.7960682122635856,
      "attention_bam_384_attention_sparsity": 0.6489079793294271,
      "attention_bam_384_attention_concentration_10": 2.159805051292059,
      "attention_bam_384_attention_concentration_20": 3.2287141301006734,
      "attention_bam_384_attention_center_y": 0.4814132199428732,
      "attention_bam_384_attention_center_x": 0.4880032715192411,
      "attention_bam_384_attention_center_distance": 0.03128545627390008,
      "attention_bam_384_attention_spatial_variance": 171.1770571738569,
      "attention_bam_384_attention_spatial_std": 13.083465029335956,
      "attention_bam_384_num_attention_peaks": 19,
      "attention_bam_384_peak_separation_mean": 17.70605909197206,
      "attention_bam_384_peak_intensity_mean": 0.3591652810573578,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12558628618717194,
      "attention_bam_16_std_attention": 0.5852090120315552,
      "attention_bam_16_max_attention": 2.878737211227417,
      "attention_bam_16_min_attention": -1.0028014183044434,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.4920538064470472,
      "attention_bam_16_attention_skewness": 0.8521822908777664,
      "attention_bam_16_attention_sparsity": 0.549072265625,
      "attention_bam_16_attention_concentration_10": 1.0668289203588595,
      "attention_bam_16_attention_concentration_20": 1.6740335404962186,
      "attention_bam_16_attention_center_y": 0.46076895563126874,
      "attention_bam_16_attention_center_x": 0.4850715024316145,
      "attention_bam_16_attention_center_distance": 0.05936219136640177,
      "attention_bam_16_attention_spatial_variance": 42.87176429706412,
      "attention_bam_16_attention_spatial_std": 6.547653342768241,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 7.736827510080882,
      "attention_bam_16_peak_intensity_mean": 0.30090755224227905,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 577,
      "phase": "train",
      "loss": 0.005796205252408981,
      "timestamp": 1759543979.6687136,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005796205252408981,
      "ssim": 0.9250290989875793,
      "attention_bam_384_mean_attention": 0.028935031965374947,
      "attention_bam_384_std_attention": 0.25497180223464966,
      "attention_bam_384_max_attention": 2.1749107837677,
      "attention_bam_384_min_attention": -1.0222113132476807,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.2339311232239174,
      "attention_bam_384_attention_skewness": 0.8488878754518111,
      "attention_bam_384_attention_sparsity": 0.6572469075520834,
      "attention_bam_384_attention_concentration_10": 1.8648762061726583,
      "attention_bam_384_attention_concentration_20": 2.807164462677852,
      "attention_bam_384_attention_center_y": 0.48073719319211916,
      "attention_bam_384_attention_center_x": 0.47959008782127555,
      "attention_bam_384_attention_center_distance": 0.03968929934531435,
      "attention_bam_384_attention_spatial_variance": 170.8732664400747,
      "attention_bam_384_attention_spatial_std": 13.071850153672765,
      "attention_bam_384_num_attention_peaks": 19,
      "attention_bam_384_peak_separation_mean": 18.673251668305802,
      "attention_bam_384_peak_intensity_mean": 0.33150312304496765,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13258475065231323,
      "attention_bam_16_std_attention": 0.5331299304962158,
      "attention_bam_16_max_attention": 2.8904061317443848,
      "attention_bam_16_min_attention": -1.1836607456207275,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.118301537138473,
      "attention_bam_16_attention_skewness": 0.8598483562395165,
      "attention_bam_16_attention_sparsity": 0.53271484375,
      "attention_bam_16_attention_concentration_10": 0.913360236415159,
      "attention_bam_16_attention_concentration_20": 1.4339667766772768,
      "attention_bam_16_attention_center_y": 0.45787199680577156,
      "attention_bam_16_attention_center_x": 0.45397875791349573,
      "attention_bam_16_attention_center_distance": 0.08823517865701358,
      "attention_bam_16_attention_spatial_variance": 42.54100976274415,
      "attention_bam_16_attention_spatial_std": 6.522346952036832,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.032713971513067,
      "attention_bam_16_peak_intensity_mean": 0.327181875705719,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 578,
      "phase": "train",
      "loss": 0.008431753143668175,
      "timestamp": 1759543979.809367,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008431753143668175,
      "ssim": 0.9044517278671265,
      "attention_bam_384_mean_attention": 0.028248362243175507,
      "attention_bam_384_std_attention": 0.23829060792922974,
      "attention_bam_384_max_attention": 1.6308677196502686,
      "attention_bam_384_min_attention": -0.7767351269721985,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.087559429120959,
      "attention_bam_384_attention_skewness": 0.7055440181019963,
      "attention_bam_384_attention_sparsity": 0.6648203531901041,
      "attention_bam_384_attention_concentration_10": 1.7838372899292934,
      "attention_bam_384_attention_concentration_20": 2.736265366117435,
      "attention_bam_384_attention_center_y": 0.48121682598365406,
      "attention_bam_384_attention_center_x": 0.47885808751415887,
      "attention_bam_384_attention_center_distance": 0.03999470189130801,
      "attention_bam_384_attention_spatial_variance": 169.42612450240256,
      "attention_bam_384_attention_spatial_std": 13.016379085690557,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 15.465681260964061,
      "attention_bam_384_peak_intensity_mean": 0.3422805070877075,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12882548570632935,
      "attention_bam_16_std_attention": 0.5215710401535034,
      "attention_bam_16_max_attention": 2.8053407669067383,
      "attention_bam_16_min_attention": -1.0137388706207275,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.607528178212486,
      "attention_bam_16_attention_skewness": 0.7925239656875652,
      "attention_bam_16_attention_sparsity": 0.542236328125,
      "attention_bam_16_attention_concentration_10": 0.9240279609676768,
      "attention_bam_16_attention_concentration_20": 1.4575612596209369,
      "attention_bam_16_attention_center_y": 0.46016597986764035,
      "attention_bam_16_attention_center_x": 0.4555157635674611,
      "attention_bam_16_attention_center_distance": 0.0844463906971903,
      "attention_bam_16_attention_spatial_variance": 41.740835872828484,
      "attention_bam_16_attention_spatial_std": 6.4607148112905035,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.324571007537932,
      "attention_bam_16_peak_intensity_mean": 0.3091248571872711,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 579,
      "phase": "train",
      "loss": 0.004541898146271706,
      "timestamp": 1759543979.9811416,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004541898146271706,
      "ssim": 0.9075412750244141,
      "attention_bam_384_mean_attention": 0.027804439887404442,
      "attention_bam_384_std_attention": 0.24104347825050354,
      "attention_bam_384_max_attention": 1.7568374872207642,
      "attention_bam_384_min_attention": -0.7328320741653442,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8956830743117195,
      "attention_bam_384_attention_skewness": 0.5983667773573992,
      "attention_bam_384_attention_sparsity": 0.6498540242513021,
      "attention_bam_384_attention_concentration_10": 1.7874383259183335,
      "attention_bam_384_attention_concentration_20": 2.7671867008515405,
      "attention_bam_384_attention_center_y": 0.48271921380596344,
      "attention_bam_384_attention_center_x": 0.4900098563553516,
      "attention_bam_384_attention_center_distance": 0.028228657124444063,
      "attention_bam_384_attention_spatial_variance": 171.88807340916352,
      "attention_bam_384_attention_spatial_std": 13.11060919290799,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 18.738257717955445,
      "attention_bam_384_peak_intensity_mean": 0.3096233904361725,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13902634382247925,
      "attention_bam_16_std_attention": 0.5283348560333252,
      "attention_bam_16_max_attention": 2.4913330078125,
      "attention_bam_16_min_attention": -0.9241737127304077,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5738041246244556,
      "attention_bam_16_attention_skewness": 0.7652045009177724,
      "attention_bam_16_attention_sparsity": 0.53271484375,
      "attention_bam_16_attention_concentration_10": 0.8655142605878084,
      "attention_bam_16_attention_concentration_20": 1.3640369135549701,
      "attention_bam_16_attention_center_y": 0.4671362706227417,
      "attention_bam_16_attention_center_x": 0.49169379207421354,
      "attention_bam_16_attention_center_distance": 0.047937830545156435,
      "attention_bam_16_attention_spatial_variance": 43.12091684841516,
      "attention_bam_16_attention_spatial_std": 6.566651875074174,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.574098434335545,
      "attention_bam_16_peak_intensity_mean": 0.3122497498989105,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 580,
      "phase": "train",
      "loss": 0.003787132678553462,
      "timestamp": 1759543980.2346702,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.003787132678553462,
      "ssim": 0.9326911568641663,
      "attention_bam_384_mean_attention": 0.026535697281360626,
      "attention_bam_384_std_attention": 0.26663684844970703,
      "attention_bam_384_max_attention": 1.9784464836120605,
      "attention_bam_384_min_attention": -0.8744391202926636,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0353840310686726,
      "attention_bam_384_attention_skewness": 0.6865262250070887,
      "attention_bam_384_attention_sparsity": 0.6445897420247396,
      "attention_bam_384_attention_concentration_10": 2.080923130801231,
      "attention_bam_384_attention_concentration_20": 3.193390388836739,
      "attention_bam_384_attention_center_y": 0.47794074921842145,
      "attention_bam_384_attention_center_x": 0.48017130367368555,
      "attention_bam_384_attention_center_distance": 0.04194729414505232,
      "attention_bam_384_attention_spatial_variance": 170.8408548359867,
      "attention_bam_384_attention_spatial_std": 13.070610346727758,
      "attention_bam_384_num_attention_peaks": 18,
      "attention_bam_384_peak_separation_mean": 18.758930817081445,
      "attention_bam_384_peak_intensity_mean": 0.3218459486961365,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12835904955863953,
      "attention_bam_16_std_attention": 0.563630998134613,
      "attention_bam_16_max_attention": 2.8075101375579834,
      "attention_bam_16_min_attention": -1.018389105796814,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.9386351290349952,
      "attention_bam_16_attention_skewness": 0.8986517707671698,
      "attention_bam_16_attention_sparsity": 0.540771484375,
      "attention_bam_16_attention_concentration_10": 1.007053376855549,
      "attention_bam_16_attention_concentration_20": 1.5607803780279708,
      "attention_bam_16_attention_center_y": 0.44527799872120827,
      "attention_bam_16_attention_center_x": 0.45795713402242927,
      "attention_bam_16_attention_center_distance": 0.09759200790601717,
      "attention_bam_16_attention_spatial_variance": 42.158253250713415,
      "attention_bam_16_attention_spatial_std": 6.492938722236135,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.726786131519528,
      "attention_bam_16_peak_intensity_mean": 0.3262121081352234,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 581,
      "phase": "train",
      "loss": 0.008652172982692719,
      "timestamp": 1759543980.630976,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008652172982692719,
      "ssim": 0.8901054263114929,
      "attention_bam_384_mean_attention": 0.025185054168105125,
      "attention_bam_384_std_attention": 0.24970704317092896,
      "attention_bam_384_max_attention": 2.2034006118774414,
      "attention_bam_384_min_attention": -0.8757328987121582,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.690399418266698,
      "attention_bam_384_attention_skewness": 0.7509568614857981,
      "attention_bam_384_attention_sparsity": 0.6591364542643229,
      "attention_bam_384_attention_concentration_10": 2.0755596034312283,
      "attention_bam_384_attention_concentration_20": 3.135701354973077,
      "attention_bam_384_attention_center_y": 0.4813054117813749,
      "attention_bam_384_attention_center_x": 0.48479518473072114,
      "attention_bam_384_attention_center_distance": 0.034078557364913525,
      "attention_bam_384_attention_spatial_variance": 170.5464253060326,
      "attention_bam_384_attention_spatial_std": 13.059342453049947,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 18.075985639917082,
      "attention_bam_384_peak_intensity_mean": 0.2956599295139313,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13015279173851013,
      "attention_bam_16_std_attention": 0.545665442943573,
      "attention_bam_16_max_attention": 2.706252098083496,
      "attention_bam_16_min_attention": -0.9888995289802551,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.287751740503892,
      "attention_bam_16_attention_skewness": 0.9567231923508122,
      "attention_bam_16_attention_sparsity": 0.54052734375,
      "attention_bam_16_attention_concentration_10": 0.9750659632538544,
      "attention_bam_16_attention_concentration_20": 1.4997915141286395,
      "attention_bam_16_attention_center_y": 0.4576890669489326,
      "attention_bam_16_attention_center_x": 0.47334332968026593,
      "attention_bam_16_attention_center_distance": 0.07072189375556766,
      "attention_bam_16_attention_spatial_variance": 42.46443377578904,
      "attention_bam_16_attention_spatial_std": 6.516474029395732,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.58930635738663,
      "attention_bam_16_peak_intensity_mean": 0.31014880537986755,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 582,
      "phase": "train",
      "loss": 0.0034857853315770626,
      "timestamp": 1759543980.7636638,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0034857853315770626,
      "ssim": 0.9398664832115173,
      "attention_bam_384_mean_attention": 0.02583000250160694,
      "attention_bam_384_std_attention": 0.2606976628303528,
      "attention_bam_384_max_attention": 2.0519917011260986,
      "attention_bam_384_min_attention": -0.8560804128646851,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.3484769479239613,
      "attention_bam_384_attention_skewness": 0.6763310558350484,
      "attention_bam_384_attention_sparsity": 0.6501592000325521,
      "attention_bam_384_attention_concentration_10": 2.097194441859713,
      "attention_bam_384_attention_concentration_20": 3.178300573630933,
      "attention_bam_384_attention_center_y": 0.4834484968894163,
      "attention_bam_384_attention_center_x": 0.4827143324160243,
      "attention_bam_384_attention_center_distance": 0.03384513433400345,
      "attention_bam_384_attention_spatial_variance": 170.81120699322284,
      "attention_bam_384_attention_spatial_std": 13.06947615603712,
      "attention_bam_384_num_attention_peaks": 22,
      "attention_bam_384_peak_separation_mean": 18.252432828032113,
      "attention_bam_384_peak_intensity_mean": 0.30621451139450073,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14035314321517944,
      "attention_bam_16_std_attention": 0.5606078505516052,
      "attention_bam_16_max_attention": 2.868583917617798,
      "attention_bam_16_min_attention": -1.0523879528045654,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.040531134829183,
      "attention_bam_16_attention_skewness": 0.849557625175495,
      "attention_bam_16_attention_sparsity": 0.528564453125,
      "attention_bam_16_attention_concentration_10": 0.9075340749438163,
      "attention_bam_16_attention_concentration_20": 1.4157586734566778,
      "attention_bam_16_attention_center_y": 0.46429742119578826,
      "attention_bam_16_attention_center_x": 0.4651018796716822,
      "attention_bam_16_attention_center_distance": 0.07060528217804524,
      "attention_bam_16_attention_spatial_variance": 42.5681106850886,
      "attention_bam_16_attention_spatial_std": 6.5244241650193615,
      "attention_bam_16_num_attention_peaks": 12,
      "attention_bam_16_peak_separation_mean": 10.16875306939661,
      "attention_bam_16_peak_intensity_mean": 0.3058335483074188,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 583,
      "phase": "train",
      "loss": 0.011593992821872234,
      "timestamp": 1759543980.905883,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.011593992821872234,
      "ssim": 0.8908383846282959,
      "attention_bam_384_mean_attention": 0.02623196505010128,
      "attention_bam_384_std_attention": 0.26281118392944336,
      "attention_bam_384_max_attention": 2.816887617111206,
      "attention_bam_384_min_attention": -1.0278244018554688,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.075131837390752,
      "attention_bam_384_attention_skewness": 0.7924654997772573,
      "attention_bam_384_attention_sparsity": 0.6443150838216146,
      "attention_bam_384_attention_concentration_10": 2.0563759090730787,
      "attention_bam_384_attention_concentration_20": 3.1407814750881844,
      "attention_bam_384_attention_center_y": 0.4821069083742882,
      "attention_bam_384_attention_center_x": 0.4808829418641612,
      "attention_bam_384_attention_center_distance": 0.03703038319259356,
      "attention_bam_384_attention_spatial_variance": 171.70652142932246,
      "attention_bam_384_attention_spatial_std": 13.103683506149043,
      "attention_bam_384_num_attention_peaks": 22,
      "attention_bam_384_peak_separation_mean": 19.3824928127848,
      "attention_bam_384_peak_intensity_mean": 0.27889010310173035,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1483244001865387,
      "attention_bam_16_std_attention": 0.5613092184066772,
      "attention_bam_16_max_attention": 3.797041893005371,
      "attention_bam_16_min_attention": -1.0905377864837646,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.4653394290266917,
      "attention_bam_16_attention_skewness": 0.8570101358069461,
      "attention_bam_16_attention_sparsity": 0.51318359375,
      "attention_bam_16_attention_concentration_10": 0.8582817236390163,
      "attention_bam_16_attention_concentration_20": 1.3434556487388425,
      "attention_bam_16_attention_center_y": 0.46154950436723935,
      "attention_bam_16_attention_center_x": 0.45759645514001174,
      "attention_bam_16_attention_center_distance": 0.08095061742936842,
      "attention_bam_16_attention_spatial_variance": 43.44028641399197,
      "attention_bam_16_attention_spatial_std": 6.590924549256498,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 9.408754887886206,
      "attention_bam_16_peak_intensity_mean": 0.25859004259109497,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 584,
      "phase": "train",
      "loss": 0.004066925495862961,
      "timestamp": 1759543981.0466163,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004066925495862961,
      "ssim": 0.9319102764129639,
      "attention_bam_384_mean_attention": 0.026725882664322853,
      "attention_bam_384_std_attention": 0.27030742168426514,
      "attention_bam_384_max_attention": 3.4553122520446777,
      "attention_bam_384_min_attention": -1.09244966506958,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.4546064139814536,
      "attention_bam_384_attention_skewness": 0.9315428810963543,
      "attention_bam_384_attention_sparsity": 0.6391016642252604,
      "attention_bam_384_attention_concentration_10": 2.0711015120697547,
      "attention_bam_384_attention_concentration_20": 3.142512839104542,
      "attention_bam_384_attention_center_y": 0.48102835779421804,
      "attention_bam_384_attention_center_x": 0.48113833994884064,
      "attention_bam_384_attention_center_distance": 0.03783346211674813,
      "attention_bam_384_attention_spatial_variance": 171.51021940365618,
      "attention_bam_384_attention_spatial_std": 13.09619102654112,
      "attention_bam_384_num_attention_peaks": 18,
      "attention_bam_384_peak_separation_mean": 16.869173664850578,
      "attention_bam_384_peak_intensity_mean": 0.24990235269069672,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14107680320739746,
      "attention_bam_16_std_attention": 0.5717883706092834,
      "attention_bam_16_max_attention": 4.452011585235596,
      "attention_bam_16_min_attention": -1.0503952503204346,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.7814024892821525,
      "attention_bam_16_attention_skewness": 1.223026552108816,
      "attention_bam_16_attention_sparsity": 0.52880859375,
      "attention_bam_16_attention_concentration_10": 0.9241900504978483,
      "attention_bam_16_attention_concentration_20": 1.4194912407501945,
      "attention_bam_16_attention_center_y": 0.45583164167971063,
      "attention_bam_16_attention_center_x": 0.45561569070233876,
      "attention_bam_16_attention_center_distance": 0.08855293093444093,
      "attention_bam_16_attention_spatial_variance": 43.29246909617883,
      "attention_bam_16_attention_spatial_std": 6.579701292321622,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 7.714557364802589,
      "attention_bam_16_peak_intensity_mean": 0.22305326163768768,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 585,
      "phase": "train",
      "loss": 0.004517015069723129,
      "timestamp": 1759543981.2357605,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004517015069723129,
      "ssim": 0.9241864681243896,
      "attention_bam_384_mean_attention": 0.026005210354924202,
      "attention_bam_384_std_attention": 0.24919389188289642,
      "attention_bam_384_max_attention": 1.7935820817947388,
      "attention_bam_384_min_attention": -0.8376278877258301,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.7856354009816693,
      "attention_bam_384_attention_skewness": 0.8152150652052712,
      "attention_bam_384_attention_sparsity": 0.6645533243815104,
      "attention_bam_384_attention_concentration_10": 2.0460857861742303,
      "attention_bam_384_attention_concentration_20": 3.0276140543625814,
      "attention_bam_384_attention_center_y": 0.48777940692808397,
      "attention_bam_384_attention_center_x": 0.48090257960250393,
      "attention_bam_384_attention_center_distance": 0.03206413450782855,
      "attention_bam_384_attention_spatial_variance": 170.56771234249666,
      "attention_bam_384_attention_spatial_std": 13.060157439422262,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 20.512391732292482,
      "attention_bam_384_peak_intensity_mean": 0.3419194519519806,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13305091857910156,
      "attention_bam_16_std_attention": 0.5358606576919556,
      "attention_bam_16_max_attention": 2.6837522983551025,
      "attention_bam_16_min_attention": -0.9088969826698303,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.2712910353663025,
      "attention_bam_16_attention_skewness": 0.9895454429383428,
      "attention_bam_16_attention_sparsity": 0.54833984375,
      "attention_bam_16_attention_concentration_10": 0.9498595346887649,
      "attention_bam_16_attention_concentration_20": 1.4569758679865112,
      "attention_bam_16_attention_center_y": 0.48422231912599834,
      "attention_bam_16_attention_center_x": 0.4559599342240367,
      "attention_bam_16_attention_center_distance": 0.06615833443056154,
      "attention_bam_16_attention_spatial_variance": 42.200296203669176,
      "attention_bam_16_attention_spatial_std": 6.496175505916476,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.799496379462983,
      "attention_bam_16_peak_intensity_mean": 0.30791881680488586,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 586,
      "phase": "train",
      "loss": 0.0072548119351267815,
      "timestamp": 1759543981.4286742,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0072548119351267815,
      "ssim": 0.8694518804550171,
      "attention_bam_384_mean_attention": 0.02722024917602539,
      "attention_bam_384_std_attention": 0.27208179235458374,
      "attention_bam_384_max_attention": 2.13100004196167,
      "attention_bam_384_min_attention": -1.1460154056549072,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4095932205135862,
      "attention_bam_384_attention_skewness": 0.7647567619296484,
      "attention_bam_384_attention_sparsity": 0.6444066365559896,
      "attention_bam_384_attention_concentration_10": 2.1130738883516504,
      "attention_bam_384_attention_concentration_20": 3.179257174970023,
      "attention_bam_384_attention_center_y": 0.48132586694677015,
      "attention_bam_384_attention_center_x": 0.48199014524319955,
      "attention_bam_384_attention_center_distance": 0.03669000173482632,
      "attention_bam_384_attention_spatial_variance": 172.10592099853028,
      "attention_bam_384_attention_spatial_std": 13.118914627305502,
      "attention_bam_384_num_attention_peaks": 21,
      "attention_bam_384_peak_separation_mean": 18.585713581352813,
      "attention_bam_384_peak_intensity_mean": 0.3655235469341278,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14006313681602478,
      "attention_bam_16_std_attention": 0.578244686126709,
      "attention_bam_16_max_attention": 3.0761871337890625,
      "attention_bam_16_min_attention": -1.1635334491729736,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5355495792267861,
      "attention_bam_16_attention_skewness": 0.7816066658720892,
      "attention_bam_16_attention_sparsity": 0.53173828125,
      "attention_bam_16_attention_concentration_10": 0.9436226139201982,
      "attention_bam_16_attention_concentration_20": 1.486517868306777,
      "attention_bam_16_attention_center_y": 0.4597182449926668,
      "attention_bam_16_attention_center_x": 0.46103129334894355,
      "attention_bam_16_attention_center_distance": 0.0792613384258291,
      "attention_bam_16_attention_spatial_variance": 43.77091557519316,
      "attention_bam_16_attention_spatial_std": 6.615959157612232,
      "attention_bam_16_num_attention_peaks": 11,
      "attention_bam_16_peak_separation_mean": 9.830388042531311,
      "attention_bam_16_peak_intensity_mean": 0.31777873635292053,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 587,
      "phase": "train",
      "loss": 0.0066881063394248486,
      "timestamp": 1759543981.6213434,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0066881063394248486,
      "ssim": 0.8919017314910889,
      "attention_bam_384_mean_attention": 0.026093265041708946,
      "attention_bam_384_std_attention": 0.245174840092659,
      "attention_bam_384_max_attention": 2.5510597229003906,
      "attention_bam_384_min_attention": -0.9196978211402893,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.6327538695170167,
      "attention_bam_384_attention_skewness": 0.6592730879779077,
      "attention_bam_384_attention_sparsity": 0.6434453328450521,
      "attention_bam_384_attention_concentration_10": 1.9075765789962043,
      "attention_bam_384_attention_concentration_20": 2.926592361171182,
      "attention_bam_384_attention_center_y": 0.48022115527733594,
      "attention_bam_384_attention_center_x": 0.4802635876868988,
      "attention_bam_384_attention_center_distance": 0.039515279818216856,
      "attention_bam_384_attention_spatial_variance": 170.8203639506069,
      "attention_bam_384_attention_spatial_std": 13.069826469797022,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 20.9329255468373,
      "attention_bam_384_peak_intensity_mean": 0.2783154547214508,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14377570152282715,
      "attention_bam_16_std_attention": 0.5376101732254028,
      "attention_bam_16_max_attention": 2.6448075771331787,
      "attention_bam_16_min_attention": -1.0098830461502075,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.9404852249194944,
      "attention_bam_16_attention_skewness": 0.7939044134565061,
      "attention_bam_16_attention_sparsity": 0.509521484375,
      "attention_bam_16_attention_concentration_10": 0.8520857481709717,
      "attention_bam_16_attention_concentration_20": 1.3316354746315977,
      "attention_bam_16_attention_center_y": 0.4541548074806583,
      "attention_bam_16_attention_center_x": 0.4536768691278771,
      "attention_bam_16_attention_center_distance": 0.09216956255653308,
      "attention_bam_16_attention_spatial_variance": 42.54824343785623,
      "attention_bam_16_attention_spatial_std": 6.522901458542528,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 10.731459034151806,
      "attention_bam_16_peak_intensity_mean": 0.3240756690502167,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 588,
      "phase": "train",
      "loss": 0.004753489047288895,
      "timestamp": 1759543981.8031292,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004753489047288895,
      "ssim": 0.8949393630027771,
      "attention_bam_384_mean_attention": 0.027382662519812584,
      "attention_bam_384_std_attention": 0.23431013524532318,
      "attention_bam_384_max_attention": 2.117854356765747,
      "attention_bam_384_min_attention": -0.8558592796325684,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.6887672759863905,
      "attention_bam_384_attention_skewness": 0.695526552584177,
      "attention_bam_384_attention_sparsity": 0.65667724609375,
      "attention_bam_384_attention_concentration_10": 1.7762957072340526,
      "attention_bam_384_attention_concentration_20": 2.7012478826746795,
      "attention_bam_384_attention_center_y": 0.48248032546304304,
      "attention_bam_384_attention_center_x": 0.4831638980918665,
      "attention_bam_384_attention_center_distance": 0.034362576252136706,
      "attention_bam_384_attention_spatial_variance": 171.0095226130008,
      "attention_bam_384_attention_spatial_std": 13.077060931761418,
      "attention_bam_384_num_attention_peaks": 18,
      "attention_bam_384_peak_separation_mean": 18.031608652263856,
      "attention_bam_384_peak_intensity_mean": 0.3042113184928894,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.15876340866088867,
      "attention_bam_16_std_attention": 0.518985390663147,
      "attention_bam_16_max_attention": 3.6680479049682617,
      "attention_bam_16_min_attention": -0.9250723123550415,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.5327602439244785,
      "attention_bam_16_attention_skewness": 0.8466360512977388,
      "attention_bam_16_attention_sparsity": 0.505126953125,
      "attention_bam_16_attention_concentration_10": 0.7554558516001816,
      "attention_bam_16_attention_concentration_20": 1.183762869743413,
      "attention_bam_16_attention_center_y": 0.46172372289348723,
      "attention_bam_16_attention_center_x": 0.4687837842185143,
      "attention_bam_16_attention_center_distance": 0.06985020424953431,
      "attention_bam_16_attention_spatial_variance": 42.81063923420303,
      "attention_bam_16_attention_spatial_std": 6.542983970193037,
      "attention_bam_16_num_attention_peaks": 11,
      "attention_bam_16_peak_separation_mean": 10.190339311030472,
      "attention_bam_16_peak_intensity_mean": 0.24854569137096405,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 589,
      "phase": "train",
      "loss": 0.004926861263811588,
      "timestamp": 1759543981.9757779,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004926861263811588,
      "ssim": 0.9006902575492859,
      "attention_bam_384_mean_attention": 0.024926401674747467,
      "attention_bam_384_std_attention": 0.25017452239990234,
      "attention_bam_384_max_attention": 2.185215473175049,
      "attention_bam_384_min_attention": -0.9618797898292542,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.9655470970994884,
      "attention_bam_384_attention_skewness": 0.864411857785123,
      "attention_bam_384_attention_sparsity": 0.6762491861979166,
      "attention_bam_384_attention_concentration_10": 2.1594357505112876,
      "attention_bam_384_attention_concentration_20": 3.2109878799711575,
      "attention_bam_384_attention_center_y": 0.48237302674186266,
      "attention_bam_384_attention_center_x": 0.4840176827418707,
      "attention_bam_384_attention_center_distance": 0.033649506718006636,
      "attention_bam_384_attention_spatial_variance": 171.41949325857794,
      "attention_bam_384_attention_spatial_std": 13.09272673122669,
      "attention_bam_384_num_attention_peaks": 19,
      "attention_bam_384_peak_separation_mean": 19.809169185148395,
      "attention_bam_384_peak_intensity_mean": 0.32710909843444824,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13500651717185974,
      "attention_bam_16_std_attention": 0.5461091995239258,
      "attention_bam_16_max_attention": 2.726078510284424,
      "attention_bam_16_min_attention": -1.07074773311615,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.1081131589089201,
      "attention_bam_16_attention_skewness": 0.9653066542062183,
      "attention_bam_16_attention_sparsity": 0.541015625,
      "attention_bam_16_attention_concentration_10": 0.9622546421324832,
      "attention_bam_16_attention_concentration_20": 1.466730072619201,
      "attention_bam_16_attention_center_y": 0.46266042152039016,
      "attention_bam_16_attention_center_x": 0.4698994750825232,
      "attention_bam_16_attention_center_distance": 0.06782751243179397,
      "attention_bam_16_attention_spatial_variance": 43.12624760160169,
      "attention_bam_16_attention_spatial_std": 6.567057758357367,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.960398961328112,
      "attention_bam_16_peak_intensity_mean": 0.3482104241847992,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 590,
      "phase": "train",
      "loss": 0.004300559870898724,
      "timestamp": 1759543982.1850004,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004300559870898724,
      "ssim": 0.9389376640319824,
      "attention_bam_384_mean_attention": 0.025849662721157074,
      "attention_bam_384_std_attention": 0.2679331302642822,
      "attention_bam_384_max_attention": 2.5815274715423584,
      "attention_bam_384_min_attention": -1.0454474687576294,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0981232580245344,
      "attention_bam_384_attention_skewness": 0.6204283986868535,
      "attention_bam_384_attention_sparsity": 0.6400553385416666,
      "attention_bam_384_attention_concentration_10": 2.125598540183867,
      "attention_bam_384_attention_concentration_20": 3.2664125077585093,
      "attention_bam_384_attention_center_y": 0.4774479077797696,
      "attention_bam_384_attention_center_x": 0.4821180862000162,
      "attention_bam_384_attention_center_distance": 0.04070281819873968,
      "attention_bam_384_attention_spatial_variance": 171.71324664150163,
      "attention_bam_384_attention_spatial_std": 13.103940118968097,
      "attention_bam_384_num_attention_peaks": 22,
      "attention_bam_384_peak_separation_mean": 19.161686082060122,
      "attention_bam_384_peak_intensity_mean": 0.30245497822761536,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1347552239894867,
      "attention_bam_16_std_attention": 0.5783349871635437,
      "attention_bam_16_max_attention": 2.670043468475342,
      "attention_bam_16_min_attention": -1.0202420949935913,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.21725572567867157,
      "attention_bam_16_attention_skewness": 0.665392013570023,
      "attention_bam_16_attention_sparsity": 0.526123046875,
      "attention_bam_16_attention_concentration_10": 0.9565242439784816,
      "attention_bam_16_attention_concentration_20": 1.5174682387843532,
      "attention_bam_16_attention_center_y": 0.4408658776763007,
      "attention_bam_16_attention_center_x": 0.4606196776060153,
      "attention_bam_16_attention_center_distance": 0.10047541206532476,
      "attention_bam_16_attention_spatial_variance": 43.24452598973847,
      "attention_bam_16_attention_spatial_std": 6.576057024519972,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 8.704442435737475,
      "attention_bam_16_peak_intensity_mean": 0.3357502520084381,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 591,
      "phase": "train",
      "loss": 0.0041409144178032875,
      "timestamp": 1759543982.3366923,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0041409144178032875,
      "ssim": 0.9267662763595581,
      "attention_bam_384_mean_attention": 0.025857804343104362,
      "attention_bam_384_std_attention": 0.26606690883636475,
      "attention_bam_384_max_attention": 1.9873911142349243,
      "attention_bam_384_min_attention": -0.9324405193328857,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9037890707000571,
      "attention_bam_384_attention_skewness": 0.6006909196618111,
      "attention_bam_384_attention_sparsity": 0.6386439005533854,
      "attention_bam_384_attention_concentration_10": 2.0821961620755784,
      "attention_bam_384_attention_concentration_20": 3.2384932874216577,
      "attention_bam_384_attention_center_y": 0.4825150847962495,
      "attention_bam_384_attention_center_x": 0.48189856800446923,
      "attention_bam_384_attention_center_distance": 0.03559168723090184,
      "attention_bam_384_attention_spatial_variance": 171.90897130269576,
      "attention_bam_384_attention_spatial_std": 13.111406152762402,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 20.678746193798098,
      "attention_bam_384_peak_intensity_mean": 0.3389853239059448,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14560364186763763,
      "attention_bam_16_std_attention": 0.5703458786010742,
      "attention_bam_16_max_attention": 2.796961545944214,
      "attention_bam_16_min_attention": -1.0234780311584473,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.3245377321399361,
      "attention_bam_16_attention_skewness": 0.7194501477435834,
      "attention_bam_16_attention_sparsity": 0.53173828125,
      "attention_bam_16_attention_concentration_10": 0.8827391865515648,
      "attention_bam_16_attention_concentration_20": 1.4157580954999354,
      "attention_bam_16_attention_center_y": 0.4635679181023675,
      "attention_bam_16_attention_center_x": 0.46197897791113407,
      "attention_bam_16_attention_center_distance": 0.0744700572321229,
      "attention_bam_16_attention_spatial_variance": 43.562167286931114,
      "attention_bam_16_attention_spatial_std": 6.600164186361663,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.898069759842253,
      "attention_bam_16_peak_intensity_mean": 0.32708540558815,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 592,
      "phase": "train",
      "loss": 0.003908107057213783,
      "timestamp": 1759543982.4835207,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.003908107057213783,
      "ssim": 0.929291844367981,
      "attention_bam_384_mean_attention": 0.025893351063132286,
      "attention_bam_384_std_attention": 0.2564173936843872,
      "attention_bam_384_max_attention": 1.8659230470657349,
      "attention_bam_384_min_attention": -0.949719250202179,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9353914774004579,
      "attention_bam_384_attention_skewness": 0.6011483338078699,
      "attention_bam_384_attention_sparsity": 0.6487325032552084,
      "attention_bam_384_attention_concentration_10": 2.0464302841710795,
      "attention_bam_384_attention_concentration_20": 3.1335087914460247,
      "attention_bam_384_attention_center_y": 0.48502677200949895,
      "attention_bam_384_attention_center_x": 0.4820401709811538,
      "attention_bam_384_attention_center_distance": 0.03306820269811207,
      "attention_bam_384_attention_spatial_variance": 172.24794689783943,
      "attention_bam_384_attention_spatial_std": 13.124326531210636,
      "attention_bam_384_num_attention_peaks": 21,
      "attention_bam_384_peak_separation_mean": 19.00922675418007,
      "attention_bam_384_peak_intensity_mean": 0.35226693749427795,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14052826166152954,
      "attention_bam_16_std_attention": 0.55536949634552,
      "attention_bam_16_max_attention": 2.7400364875793457,
      "attention_bam_16_min_attention": -1.0332717895507812,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.3833664092089277,
      "attention_bam_16_attention_skewness": 0.665350411263324,
      "attention_bam_16_attention_sparsity": 0.51318359375,
      "attention_bam_16_attention_concentration_10": 0.8868771771843141,
      "attention_bam_16_attention_concentration_20": 1.4038310231921471,
      "attention_bam_16_attention_center_y": 0.472021956247489,
      "attention_bam_16_attention_center_x": 0.459386642528705,
      "attention_bam_16_attention_center_distance": 0.06974547637386405,
      "attention_bam_16_attention_spatial_variance": 43.88180812769601,
      "attention_bam_16_attention_spatial_std": 6.624334542253735,
      "attention_bam_16_num_attention_peaks": 12,
      "attention_bam_16_peak_separation_mean": 10.186502134331679,
      "attention_bam_16_peak_intensity_mean": 0.32170796394348145,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 593,
      "phase": "train",
      "loss": 0.007304709404706955,
      "timestamp": 1759543982.6259575,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007304709404706955,
      "ssim": 0.8824862241744995,
      "attention_bam_384_mean_attention": 0.024070965126156807,
      "attention_bam_384_std_attention": 0.24466629326343536,
      "attention_bam_384_max_attention": 2.3595266342163086,
      "attention_bam_384_min_attention": -0.9134083390235901,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.0534070314223127,
      "attention_bam_384_attention_skewness": 0.881813931866423,
      "attention_bam_384_attention_sparsity": 0.6699879964192709,
      "attention_bam_384_attention_concentration_10": 2.1646381217302184,
      "attention_bam_384_attention_concentration_20": 3.2214784780095984,
      "attention_bam_384_attention_center_y": 0.4788472502957871,
      "attention_bam_384_attention_center_x": 0.47899844191820196,
      "attention_bam_384_attention_center_distance": 0.04215457891883667,
      "attention_bam_384_attention_spatial_variance": 168.99301689139247,
      "attention_bam_384_attention_spatial_std": 12.999731416125199,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 17.517157050833678,
      "attention_bam_384_peak_intensity_mean": 0.29001864790916443,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13670766353607178,
      "attention_bam_16_std_attention": 0.546509325504303,
      "attention_bam_16_max_attention": 2.73073410987854,
      "attention_bam_16_min_attention": -0.9752645492553711,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.0990795421975461,
      "attention_bam_16_attention_skewness": 0.9697874363882024,
      "attention_bam_16_attention_sparsity": 0.53564453125,
      "attention_bam_16_attention_concentration_10": 0.9432255074226362,
      "attention_bam_16_attention_concentration_20": 1.4436322961198849,
      "attention_bam_16_attention_center_y": 0.4500396933358759,
      "attention_bam_16_attention_center_x": 0.4526402321301118,
      "attention_bam_16_attention_center_distance": 0.09735481348821966,
      "attention_bam_16_attention_spatial_variance": 40.78808343300552,
      "attention_bam_16_attention_spatial_std": 6.386554895482033,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 10.548674015381243,
      "attention_bam_16_peak_intensity_mean": 0.3015890419483185,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 594,
      "phase": "train",
      "loss": 0.00703053455799818,
      "timestamp": 1759543982.7769132,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00703053455799818,
      "ssim": 0.8523913621902466,
      "attention_bam_384_mean_attention": 0.025090953335165977,
      "attention_bam_384_std_attention": 0.2815667390823364,
      "attention_bam_384_max_attention": 2.9928536415100098,
      "attention_bam_384_min_attention": -1.1061444282531738,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.0363869580345106,
      "attention_bam_384_attention_skewness": 0.9899602649985991,
      "attention_bam_384_attention_sparsity": 0.6483968098958334,
      "attention_bam_384_attention_concentration_10": 2.3425608673559974,
      "attention_bam_384_attention_concentration_20": 3.4946783870659,
      "attention_bam_384_attention_center_y": 0.47768419279315466,
      "attention_bam_384_attention_center_x": 0.4855935715508674,
      "attention_bam_384_attention_center_distance": 0.037564356295644606,
      "attention_bam_384_attention_spatial_variance": 170.81070952975557,
      "attention_bam_384_attention_spatial_std": 13.069457124523405,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 16.637945798121745,
      "attention_bam_384_peak_intensity_mean": 0.2815231382846832,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.134184330701828,
      "attention_bam_16_std_attention": 0.6122416853904724,
      "attention_bam_16_max_attention": 3.7286696434020996,
      "attention_bam_16_min_attention": -1.1328407526016235,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.489748525697715,
      "attention_bam_16_attention_skewness": 1.1693603574327702,
      "attention_bam_16_attention_sparsity": 0.53564453125,
      "attention_bam_16_attention_concentration_10": 1.043392206807522,
      "attention_bam_16_attention_concentration_20": 1.595039532637317,
      "attention_bam_16_attention_center_y": 0.4455691812982365,
      "attention_bam_16_attention_center_x": 0.4744394994966236,
      "attention_bam_16_attention_center_distance": 0.08504179220274403,
      "attention_bam_16_attention_spatial_variance": 42.50609022080485,
      "attention_bam_16_attention_spatial_std": 6.519669487083287,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 8.182916404014788,
      "attention_bam_16_peak_intensity_mean": 0.2665850520133972,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 595,
      "phase": "train",
      "loss": 0.004754948895424604,
      "timestamp": 1759543982.931469,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004754948895424604,
      "ssim": 0.9180959463119507,
      "attention_bam_384_mean_attention": 0.026593981310725212,
      "attention_bam_384_std_attention": 0.25357502698898315,
      "attention_bam_384_max_attention": 2.537144184112549,
      "attention_bam_384_min_attention": -0.9943921566009521,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.180813331062632,
      "attention_bam_384_attention_skewness": 0.8296005623073173,
      "attention_bam_384_attention_sparsity": 0.6696599324544271,
      "attention_bam_384_attention_concentration_10": 2.027580671955339,
      "attention_bam_384_attention_concentration_20": 3.0263900835885678,
      "attention_bam_384_attention_center_y": 0.48427238292224034,
      "attention_bam_384_attention_center_x": 0.4818709947287354,
      "attention_bam_384_attention_center_distance": 0.03394167854040742,
      "attention_bam_384_attention_spatial_variance": 171.51645888134567,
      "attention_bam_384_attention_spatial_std": 13.096429241642383,
      "attention_bam_384_num_attention_peaks": 24,
      "attention_bam_384_peak_separation_mean": 19.101334007946313,
      "attention_bam_384_peak_intensity_mean": 0.2950249910354614,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14001980423927307,
      "attention_bam_16_std_attention": 0.5518549084663391,
      "attention_bam_16_max_attention": 3.038125991821289,
      "attention_bam_16_min_attention": -1.0774887800216675,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7656695810573475,
      "attention_bam_16_attention_skewness": 0.7867164586353004,
      "attention_bam_16_attention_sparsity": 0.523193359375,
      "attention_bam_16_attention_concentration_10": 0.8917124546354576,
      "attention_bam_16_attention_concentration_20": 1.4044160794598348,
      "attention_bam_16_attention_center_y": 0.46771571322705907,
      "attention_bam_16_attention_center_x": 0.4609123827326905,
      "attention_bam_16_attention_center_distance": 0.07169542518282686,
      "attention_bam_16_attention_spatial_variance": 43.22857500287226,
      "attention_bam_16_attention_spatial_std": 6.574844104834141,
      "attention_bam_16_num_attention_peaks": 14,
      "attention_bam_16_peak_separation_mean": 9.21839257918116,
      "attention_bam_16_peak_intensity_mean": 0.30331891775131226,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 596,
      "phase": "train",
      "loss": 0.005704134702682495,
      "timestamp": 1759543983.095023,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005704134702682495,
      "ssim": 0.9117562770843506,
      "attention_bam_384_mean_attention": 0.027206389233469963,
      "attention_bam_384_std_attention": 0.23943737149238586,
      "attention_bam_384_max_attention": 2.025806427001953,
      "attention_bam_384_min_attention": -0.8208673000335693,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0689477508232104,
      "attention_bam_384_attention_skewness": 0.6285079524712637,
      "attention_bam_384_attention_sparsity": 0.6585566202799479,
      "attention_bam_384_attention_concentration_10": 1.8308768469957386,
      "attention_bam_384_attention_concentration_20": 2.819716106423998,
      "attention_bam_384_attention_center_y": 0.49031529967471726,
      "attention_bam_384_attention_center_x": 0.48494084553700945,
      "attention_bam_384_attention_center_distance": 0.02532080383916513,
      "attention_bam_384_attention_spatial_variance": 172.80298197336202,
      "attention_bam_384_attention_spatial_std": 13.1454548028344,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 19.202341734260816,
      "attention_bam_384_peak_intensity_mean": 0.3021283447742462,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.15311318635940552,
      "attention_bam_16_std_attention": 0.5357345938682556,
      "attention_bam_16_max_attention": 2.4752769470214844,
      "attention_bam_16_min_attention": -1.0800412893295288,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.3078393060852669,
      "attention_bam_16_attention_skewness": 0.6962975037317036,
      "attention_bam_16_attention_sparsity": 0.51123046875,
      "attention_bam_16_attention_concentration_10": 0.7993235591564118,
      "attention_bam_16_attention_concentration_20": 1.277586671333285,
      "attention_bam_16_attention_center_y": 0.48780234623272145,
      "attention_bam_16_attention_center_x": 0.4707408504513669,
      "attention_bam_16_attention_center_distance": 0.044830360019426176,
      "attention_bam_16_attention_spatial_variance": 44.292247167596216,
      "attention_bam_16_attention_spatial_std": 6.655242081817627,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 10.377447259712937,
      "attention_bam_16_peak_intensity_mean": 0.35870361328125,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 597,
      "phase": "train",
      "loss": 0.0060783615335822105,
      "timestamp": 1759543983.2735293,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0060783615335822105,
      "ssim": 0.8973195552825928,
      "attention_bam_384_mean_attention": 0.028927693143486977,
      "attention_bam_384_std_attention": 0.25612324476242065,
      "attention_bam_384_max_attention": 2.2458667755126953,
      "attention_bam_384_min_attention": -1.0375908613204956,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4091896032205664,
      "attention_bam_384_attention_skewness": 0.6430043272635027,
      "attention_bam_384_attention_sparsity": 0.6522293090820312,
      "attention_bam_384_attention_concentration_10": 1.844215762799821,
      "attention_bam_384_attention_concentration_20": 2.8087883852655824,
      "attention_bam_384_attention_center_y": 0.48413553633141926,
      "attention_bam_384_attention_center_x": 0.4815294261982205,
      "attention_bam_384_attention_center_distance": 0.034433800372851736,
      "attention_bam_384_attention_spatial_variance": 172.4249883645434,
      "attention_bam_384_attention_spatial_std": 13.131069581894058,
      "attention_bam_384_num_attention_peaks": 21,
      "attention_bam_384_peak_separation_mean": 20.147238913535663,
      "attention_bam_384_peak_intensity_mean": 0.32994192838668823,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.15592128038406372,
      "attention_bam_16_std_attention": 0.5626893043518066,
      "attention_bam_16_max_attention": 3.003650188446045,
      "attention_bam_16_min_attention": -1.0086923837661743,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5578391884696021,
      "attention_bam_16_attention_skewness": 0.7041507028098403,
      "attention_bam_16_attention_sparsity": 0.508056640625,
      "attention_bam_16_attention_concentration_10": 0.8186776188027053,
      "attention_bam_16_attention_concentration_20": 1.3002243947921837,
      "attention_bam_16_attention_center_y": 0.46725081261110946,
      "attention_bam_16_attention_center_x": 0.4592833766496063,
      "attention_bam_16_attention_center_distance": 0.07389658573561426,
      "attention_bam_16_attention_spatial_variance": 44.281525165949304,
      "attention_bam_16_attention_spatial_std": 6.654436502510885,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 11.140721300960283,
      "attention_bam_16_peak_intensity_mean": 0.30930110812187195,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 598,
      "phase": "train",
      "loss": 0.0056765154004096985,
      "timestamp": 1759543983.4650085,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0056765154004096985,
      "ssim": 0.8839290142059326,
      "attention_bam_384_mean_attention": 0.027371294796466827,
      "attention_bam_384_std_attention": 0.2514088451862335,
      "attention_bam_384_max_attention": 2.4626569747924805,
      "attention_bam_384_min_attention": -0.89157634973526,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.768740706125711,
      "attention_bam_384_attention_skewness": 0.7822329357646196,
      "attention_bam_384_attention_sparsity": 0.6625823974609375,
      "attention_bam_384_attention_concentration_10": 1.9374091915527205,
      "attention_bam_384_attention_concentration_20": 2.922348769938395,
      "attention_bam_384_attention_center_y": 0.4875201735663874,
      "attention_bam_384_attention_center_x": 0.48114242585392364,
      "attention_bam_384_attention_center_distance": 0.03197981145935241,
      "attention_bam_384_attention_spatial_variance": 169.79070783546564,
      "attention_bam_384_attention_spatial_std": 13.030376350492169,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 18.803064449025378,
      "attention_bam_384_peak_intensity_mean": 0.2815634310245514,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1512618362903595,
      "attention_bam_16_std_attention": 0.5575355291366577,
      "attention_bam_16_max_attention": 3.0507616996765137,
      "attention_bam_16_min_attention": -1.1023098230361938,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.018616284906967,
      "attention_bam_16_attention_skewness": 0.855013992547309,
      "attention_bam_16_attention_sparsity": 0.522216796875,
      "attention_bam_16_attention_concentration_10": 0.8464700556753776,
      "attention_bam_16_attention_concentration_20": 1.3340835049695965,
      "attention_bam_16_attention_center_y": 0.47898043475621055,
      "attention_bam_16_attention_center_x": 0.45986831630723474,
      "attention_bam_16_attention_center_distance": 0.06406830978032872,
      "attention_bam_16_attention_spatial_variance": 41.900456367382276,
      "attention_bam_16_attention_spatial_std": 6.473056184475944,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.646945561815881,
      "attention_bam_16_peak_intensity_mean": 0.3154430389404297,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 599,
      "phase": "train",
      "loss": 0.006811391096562147,
      "timestamp": 1759543983.651733,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006811391096562147,
      "ssim": 0.909548819065094,
      "attention_bam_384_mean_attention": 0.026507122442126274,
      "attention_bam_384_std_attention": 0.26515719294548035,
      "attention_bam_384_max_attention": 2.2742738723754883,
      "attention_bam_384_min_attention": -0.9767173528671265,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.9691945329894605,
      "attention_bam_384_attention_skewness": 1.058390688758693,
      "attention_bam_384_attention_sparsity": 0.6751022338867188,
      "attention_bam_384_attention_concentration_10": 2.1698791278339877,
      "attention_bam_384_attention_concentration_20": 3.1831822895813873,
      "attention_bam_384_attention_center_y": 0.4879086032100719,
      "attention_bam_384_attention_center_x": 0.4806065347026251,
      "attention_bam_384_attention_center_distance": 0.03232053132521085,
      "attention_bam_384_attention_spatial_variance": 171.03521455128381,
      "attention_bam_384_attention_spatial_std": 13.07804322332985,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 21.878574339156017,
      "attention_bam_384_peak_intensity_mean": 0.31946223974227905,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1319054365158081,
      "attention_bam_16_std_attention": 0.5917159914970398,
      "attention_bam_16_max_attention": 3.2368247509002686,
      "attention_bam_16_min_attention": -1.008456826210022,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.8154282750249964,
      "attention_bam_16_attention_skewness": 1.111025573443236,
      "attention_bam_16_attention_sparsity": 0.55029296875,
      "attention_bam_16_attention_concentration_10": 1.0534546675232017,
      "attention_bam_16_attention_concentration_20": 1.6015068417954592,
      "attention_bam_16_attention_center_y": 0.47929651951403374,
      "attention_bam_16_attention_center_x": 0.45589885921203677,
      "attention_bam_16_attention_center_distance": 0.06889912514731286,
      "attention_bam_16_attention_spatial_variance": 42.78882777529868,
      "attention_bam_16_attention_spatial_std": 6.541316975601983,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 11.14247640736424,
      "attention_bam_16_peak_intensity_mean": 0.2882743775844574,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 600,
      "phase": "train",
      "loss": 0.005124570336192846,
      "timestamp": 1759543983.868088,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005124570336192846,
      "ssim": 0.9043611884117126,
      "attention_bam_384_mean_attention": 0.025796959176659584,
      "attention_bam_384_std_attention": 0.22801107168197632,
      "attention_bam_384_max_attention": 1.896383285522461,
      "attention_bam_384_min_attention": -0.9112383127212524,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2395743100144738,
      "attention_bam_384_attention_skewness": 0.6435005399381949,
      "attention_bam_384_attention_sparsity": 0.665557861328125,
      "attention_bam_384_attention_concentration_10": 1.845960442957553,
      "attention_bam_384_attention_concentration_20": 2.8173252767698127,
      "attention_bam_384_attention_center_y": 0.4819124925878437,
      "attention_bam_384_attention_center_x": 0.4819859892115991,
      "attention_bam_384_attention_center_distance": 0.0361015930138667,
      "attention_bam_384_attention_spatial_variance": 172.23693529415314,
      "attention_bam_384_attention_spatial_std": 13.123907013315552,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 20.32692587670044,
      "attention_bam_384_peak_intensity_mean": 0.3399866223335266,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1421014368534088,
      "attention_bam_16_std_attention": 0.5085057020187378,
      "attention_bam_16_max_attention": 2.6959993839263916,
      "attention_bam_16_min_attention": -0.9247680902481079,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.672038103376313,
      "attention_bam_16_attention_skewness": 0.7472849181573384,
      "attention_bam_16_attention_sparsity": 0.525390625,
      "attention_bam_16_attention_concentration_10": 0.8259650055760477,
      "attention_bam_16_attention_concentration_20": 1.2981124897090033,
      "attention_bam_16_attention_center_y": 0.45771562431436175,
      "attention_bam_16_attention_center_x": 0.4630038433249532,
      "attention_bam_16_attention_center_distance": 0.07945670564337291,
      "attention_bam_16_attention_spatial_variance": 44.05366456710021,
      "attention_bam_16_attention_spatial_std": 6.637293467001457,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 10.029403383809457,
      "attention_bam_16_peak_intensity_mean": 0.30221492052078247,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 601,
      "phase": "train",
      "loss": 0.004263824783265591,
      "timestamp": 1759543986.3187299,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004263824783265591,
      "ssim": 0.8967917561531067,
      "attention_bam_384_mean_attention": 0.025903115049004555,
      "attention_bam_384_std_attention": 0.2512844502925873,
      "attention_bam_384_max_attention": 1.8080658912658691,
      "attention_bam_384_min_attention": -0.8824764490127563,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.308770734560044,
      "attention_bam_384_attention_skewness": 0.7110235817197347,
      "attention_bam_384_attention_sparsity": 0.6585566202799479,
      "attention_bam_384_attention_concentration_10": 2.0381744073693704,
      "attention_bam_384_attention_concentration_20": 3.0822629245762534,
      "attention_bam_384_attention_center_y": 0.482757128524001,
      "attention_bam_384_attention_center_x": 0.48347628391451464,
      "attention_bam_384_attention_center_distance": 0.033774244921583305,
      "attention_bam_384_attention_spatial_variance": 173.95113265603413,
      "attention_bam_384_attention_spatial_std": 13.189053516307913,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 20.95281124522927,
      "attention_bam_384_peak_intensity_mean": 0.3440283238887787,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.136830672621727,
      "attention_bam_16_std_attention": 0.561665952205658,
      "attention_bam_16_max_attention": 2.7121245861053467,
      "attention_bam_16_min_attention": -1.0337337255477905,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7539621985872671,
      "attention_bam_16_attention_skewness": 0.8328847243916015,
      "attention_bam_16_attention_sparsity": 0.53369140625,
      "attention_bam_16_attention_concentration_10": 0.9388960649220648,
      "attention_bam_16_attention_concentration_20": 1.4666282822452832,
      "attention_bam_16_attention_center_y": 0.46375908374000424,
      "attention_bam_16_attention_center_x": 0.46752079962539783,
      "attention_bam_16_attention_center_distance": 0.06882299714975484,
      "attention_bam_16_attention_spatial_variance": 45.03112195699067,
      "attention_bam_16_attention_spatial_std": 6.710523225277644,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 10.266543117737333,
      "attention_bam_16_peak_intensity_mean": 0.31898972392082214,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 602,
      "phase": "train",
      "loss": 0.007933175191283226,
      "timestamp": 1759543986.450321,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007933175191283226,
      "ssim": 0.8564987182617188,
      "attention_bam_384_mean_attention": 0.02356851100921631,
      "attention_bam_384_std_attention": 0.2230963408946991,
      "attention_bam_384_max_attention": 2.048280715942383,
      "attention_bam_384_min_attention": -0.9157317876815796,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.524761168775453,
      "attention_bam_384_attention_skewness": 0.7079926492763873,
      "attention_bam_384_attention_sparsity": 0.6702499389648438,
      "attention_bam_384_attention_concentration_10": 1.9646697301204012,
      "attention_bam_384_attention_concentration_20": 2.988765993782191,
      "attention_bam_384_attention_center_y": 0.4879753091930096,
      "attention_bam_384_attention_center_x": 0.4808657649227792,
      "attention_bam_384_attention_center_distance": 0.03195972906625043,
      "attention_bam_384_attention_spatial_variance": 170.84054576569508,
      "attention_bam_384_attention_spatial_std": 13.070598523621445,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 18.684411394657236,
      "attention_bam_384_peak_intensity_mean": 0.32199037075042725,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1327267587184906,
      "attention_bam_16_std_attention": 0.5118907690048218,
      "attention_bam_16_max_attention": 2.849898338317871,
      "attention_bam_16_min_attention": -1.067582368850708,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.0097196829951764,
      "attention_bam_16_attention_skewness": 0.8424910926171821,
      "attention_bam_16_attention_sparsity": 0.529541015625,
      "attention_bam_16_attention_concentration_10": 0.8812083606453813,
      "attention_bam_16_attention_concentration_20": 1.3772503009129473,
      "attention_bam_16_attention_center_y": 0.48054520690242564,
      "attention_bam_16_attention_center_x": 0.45872905164586303,
      "attention_bam_16_attention_center_distance": 0.06452565617673744,
      "attention_bam_16_attention_spatial_variance": 42.66950758023955,
      "attention_bam_16_attention_spatial_std": 6.532190105947587,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 10.545010032370564,
      "attention_bam_16_peak_intensity_mean": 0.3125021457672119,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 603,
      "phase": "train",
      "loss": 0.005039401352405548,
      "timestamp": 1759543986.5853548,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005039401352405548,
      "ssim": 0.9016311168670654,
      "attention_bam_384_mean_attention": 0.02391391433775425,
      "attention_bam_384_std_attention": 0.2548387348651886,
      "attention_bam_384_max_attention": 2.1373157501220703,
      "attention_bam_384_min_attention": -0.8866884112358093,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2515547995846985,
      "attention_bam_384_attention_skewness": 0.6800917317822311,
      "attention_bam_384_attention_sparsity": 0.6518834431966146,
      "attention_bam_384_attention_concentration_10": 2.199249268925923,
      "attention_bam_384_attention_concentration_20": 3.3517585497295648,
      "attention_bam_384_attention_center_y": 0.48507899212671657,
      "attention_bam_384_attention_center_x": 0.4855033581282986,
      "attention_bam_384_attention_center_distance": 0.029420710443867692,
      "attention_bam_384_attention_spatial_variance": 169.46491428400554,
      "attention_bam_384_attention_spatial_std": 13.017869037749824,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 18.563693019059066,
      "attention_bam_384_peak_intensity_mean": 0.30627232789993286,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13674737513065338,
      "attention_bam_16_std_attention": 0.5700659155845642,
      "attention_bam_16_max_attention": 2.9214086532592773,
      "attention_bam_16_min_attention": -1.1744320392608643,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7820125144851566,
      "attention_bam_16_attention_skewness": 0.8159936523602892,
      "attention_bam_16_attention_sparsity": 0.5390625,
      "attention_bam_16_attention_concentration_10": 0.945737919104707,
      "attention_bam_16_attention_concentration_20": 1.4854262756218128,
      "attention_bam_16_attention_center_y": 0.47086664516970433,
      "attention_bam_16_attention_center_x": 0.47298112192573877,
      "attention_bam_16_attention_center_distance": 0.056192030325655715,
      "attention_bam_16_attention_spatial_variance": 41.660810457135625,
      "attention_bam_16_attention_spatial_std": 6.454518607699232,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.931295459100706,
      "attention_bam_16_peak_intensity_mean": 0.32891732454299927,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 604,
      "phase": "train",
      "loss": 0.004977102391421795,
      "timestamp": 1759543986.7227464,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004977102391421795,
      "ssim": 0.9017561674118042,
      "attention_bam_384_mean_attention": 0.023264849558472633,
      "attention_bam_384_std_attention": 0.2646574378013611,
      "attention_bam_384_max_attention": 1.7606558799743652,
      "attention_bam_384_min_attention": -0.8721349239349365,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9613422435939962,
      "attention_bam_384_attention_skewness": 0.6580426713747977,
      "attention_bam_384_attention_sparsity": 0.6520055135091146,
      "attention_bam_384_attention_concentration_10": 2.355010735862688,
      "attention_bam_384_attention_concentration_20": 3.603142554395417,
      "attention_bam_384_attention_center_y": 0.48175280983499263,
      "attention_bam_384_attention_center_x": 0.4834564387602117,
      "attention_bam_384_attention_center_distance": 0.034832437968438754,
      "attention_bam_384_attention_spatial_variance": 171.2118573640797,
      "attention_bam_384_attention_spatial_std": 13.08479489193773,
      "attention_bam_384_num_attention_peaks": 20,
      "attention_bam_384_peak_separation_mean": 19.849860717500146,
      "attention_bam_384_peak_intensity_mean": 0.3453267216682434,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12957020103931427,
      "attention_bam_16_std_attention": 0.5738899111747742,
      "attention_bam_16_max_attention": 2.6310439109802246,
      "attention_bam_16_min_attention": -1.0912435054779053,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.39119720862735763,
      "attention_bam_16_attention_skewness": 0.745371140571549,
      "attention_bam_16_attention_sparsity": 0.5361328125,
      "attention_bam_16_attention_concentration_10": 0.9900016203952957,
      "attention_bam_16_attention_concentration_20": 1.5697715860060646,
      "attention_bam_16_attention_center_y": 0.46122718689869496,
      "attention_bam_16_attention_center_x": 0.4679824523907294,
      "attention_bam_16_attention_center_distance": 0.07111194541988908,
      "attention_bam_16_attention_spatial_variance": 42.86173402456411,
      "attention_bam_16_attention_spatial_std": 6.546887353893002,
      "attention_bam_16_num_attention_peaks": 13,
      "attention_bam_16_peak_separation_mean": 9.748306857326883,
      "attention_bam_16_peak_intensity_mean": 0.3337392508983612,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 605,
      "phase": "train",
      "loss": 0.003860009601339698,
      "timestamp": 1759543986.8625247,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.003860009601339698,
      "ssim": 0.9357795119285583,
      "attention_bam_384_mean_attention": 0.02323243021965027,
      "attention_bam_384_std_attention": 0.25381192564964294,
      "attention_bam_384_max_attention": 2.229207754135132,
      "attention_bam_384_min_attention": -0.7885056138038635,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4132730463640657,
      "attention_bam_384_attention_skewness": 0.74802214656519,
      "attention_bam_384_attention_sparsity": 0.6543757120768229,
      "attention_bam_384_attention_concentration_10": 2.250889293962908,
      "attention_bam_384_attention_concentration_20": 3.4496257033391307,
      "attention_bam_384_attention_center_y": 0.4880898487670169,
      "attention_bam_384_attention_center_x": 0.4869682567959125,
      "attention_bam_384_attention_center_distance": 0.02496709968457731,
      "attention_bam_384_attention_spatial_variance": 169.26748116451196,
      "attention_bam_384_attention_spatial_std": 13.010283669640412,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 14.508492398452795,
      "attention_bam_384_peak_intensity_mean": 0.27570870518684387,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12938761711120605,
      "attention_bam_16_std_attention": 0.5542991757392883,
      "attention_bam_16_max_attention": 2.9378249645233154,
      "attention_bam_16_min_attention": -0.9799365997314453,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.336841190055817,
      "attention_bam_16_attention_skewness": 0.966319148129241,
      "attention_bam_16_attention_sparsity": 0.539306640625,
      "attention_bam_16_attention_concentration_10": 0.9804848661392207,
      "attention_bam_16_attention_concentration_20": 1.5241373543773395,
      "attention_bam_16_attention_center_y": 0.4797751484698527,
      "attention_bam_16_attention_center_x": 0.4773297267320561,
      "attention_bam_16_attention_center_distance": 0.04296477416348778,
      "attention_bam_16_attention_spatial_variance": 41.56286716321528,
      "attention_bam_16_attention_spatial_std": 6.446926955008508,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 7.186590982915507,
      "attention_bam_16_peak_intensity_mean": 0.30297988653182983,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 606,
      "phase": "train",
      "loss": 0.008665907196700573,
      "timestamp": 1759543987.0002935,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008665907196700573,
      "ssim": 0.8621037006378174,
      "attention_bam_384_mean_attention": 0.02331666089594364,
      "attention_bam_384_std_attention": 0.26415422558784485,
      "attention_bam_384_max_attention": 2.4023213386535645,
      "attention_bam_384_min_attention": -0.9686673879623413,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.027321919871863,
      "attention_bam_384_attention_skewness": 0.928679068890565,
      "attention_bam_384_attention_sparsity": 0.6705678304036459,
      "attention_bam_384_attention_concentration_10": 2.4266002082515117,
      "attention_bam_384_attention_concentration_20": 3.6112783601394187,
      "attention_bam_384_attention_center_y": 0.48064326015397263,
      "attention_bam_384_attention_center_x": 0.48936677106558557,
      "attention_bam_384_attention_center_distance": 0.03123296127614069,
      "attention_bam_384_attention_spatial_variance": 173.01127027346436,
      "attention_bam_384_attention_spatial_std": 13.153374862500664,
      "attention_bam_384_num_attention_peaks": 22,
      "attention_bam_384_peak_separation_mean": 20.05189678306004,
      "attention_bam_384_peak_intensity_mean": 0.3035375475883484,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12643232941627502,
      "attention_bam_16_std_attention": 0.5805351734161377,
      "attention_bam_16_max_attention": 2.981832265853882,
      "attention_bam_16_min_attention": -1.0906639099121094,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.0386403486165658,
      "attention_bam_16_attention_skewness": 0.9128023832440646,
      "attention_bam_16_attention_sparsity": 0.5439453125,
      "attention_bam_16_attention_concentration_10": 1.0497646949081476,
      "attention_bam_16_attention_concentration_20": 1.615683233259666,
      "attention_bam_16_attention_center_y": 0.4574955317019652,
      "attention_bam_16_attention_center_x": 0.48536571781589954,
      "attention_bam_16_attention_center_distance": 0.06357345421388591,
      "attention_bam_16_attention_spatial_variance": 44.158200431538155,
      "attention_bam_16_attention_spatial_std": 6.6451636873397,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.887496679462405,
      "attention_bam_16_peak_intensity_mean": 0.3125230669975281,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 607,
      "phase": "train",
      "loss": 0.004312546458095312,
      "timestamp": 1759543987.1396866,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004312546458095312,
      "ssim": 0.9242440462112427,
      "attention_bam_384_mean_attention": 0.022829413414001465,
      "attention_bam_384_std_attention": 0.25784340500831604,
      "attention_bam_384_max_attention": 2.9662346839904785,
      "attention_bam_384_min_attention": -1.0907764434814453,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.972300583906013,
      "attention_bam_384_attention_skewness": 0.9118422242124957,
      "attention_bam_384_attention_sparsity": 0.6595993041992188,
      "attention_bam_384_attention_concentration_10": 2.328746033649787,
      "attention_bam_384_attention_concentration_20": 3.52540659958077,
      "attention_bam_384_attention_center_y": 0.4841366787122449,
      "attention_bam_384_attention_center_x": 0.4842963006641846,
      "attention_bam_384_attention_center_distance": 0.03156742419356487,
      "attention_bam_384_attention_spatial_variance": 170.1873933967347,
      "attention_bam_384_attention_spatial_std": 13.045589039853077,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 19.171483069036004,
      "attention_bam_384_peak_intensity_mean": 0.27878695726394653,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12607574462890625,
      "attention_bam_16_std_attention": 0.5689849853515625,
      "attention_bam_16_max_attention": 3.8264575004577637,
      "attention_bam_16_min_attention": -1.1233561038970947,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.4420356480944143,
      "attention_bam_16_attention_skewness": 1.0785385787275874,
      "attention_bam_16_attention_sparsity": 0.5517578125,
      "attention_bam_16_attention_concentration_10": 1.020362731636822,
      "attention_bam_16_attention_concentration_20": 1.5839402893036696,
      "attention_bam_16_attention_center_y": 0.47017607495338387,
      "attention_bam_16_attention_center_x": 0.4705879528534329,
      "attention_bam_16_attention_center_distance": 0.0592374041048063,
      "attention_bam_16_attention_spatial_variance": 42.05934991575331,
      "attention_bam_16_attention_spatial_std": 6.485318027340934,
      "attention_bam_16_num_attention_peaks": 11,
      "attention_bam_16_peak_separation_mean": 8.725599278154519,
      "attention_bam_16_peak_intensity_mean": 0.2613790035247803,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 608,
      "phase": "train",
      "loss": 0.004833977669477463,
      "timestamp": 1759543987.2790222,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004833977669477463,
      "ssim": 0.9086246490478516,
      "attention_bam_384_mean_attention": 0.022991562262177467,
      "attention_bam_384_std_attention": 0.2448672652244568,
      "attention_bam_384_max_attention": 2.2385973930358887,
      "attention_bam_384_min_attention": -0.8647912740707397,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.61903389048281,
      "attention_bam_384_attention_skewness": 0.8261710284028875,
      "attention_bam_384_attention_sparsity": 0.6685663859049479,
      "attention_bam_384_attention_concentration_10": 2.2525025314240317,
      "attention_bam_384_attention_concentration_20": 3.3920177807966385,
      "attention_bam_384_attention_center_y": 0.486343777054944,
      "attention_bam_384_attention_center_x": 0.482523136237707,
      "attention_bam_384_attention_center_distance": 0.03136664445205524,
      "attention_bam_384_attention_spatial_variance": 172.91373595334096,
      "attention_bam_384_attention_spatial_std": 13.14966676206439,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 19.99591483799493,
      "attention_bam_384_peak_intensity_mean": 0.2902734875679016,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13939818739891052,
      "attention_bam_16_std_attention": 0.5417555570602417,
      "attention_bam_16_max_attention": 3.0914571285247803,
      "attention_bam_16_min_attention": -0.946137011051178,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.0947357439557637,
      "attention_bam_16_attention_skewness": 0.9183966339718176,
      "attention_bam_16_attention_sparsity": 0.534912109375,
      "attention_bam_16_attention_concentration_10": 0.9084800254339784,
      "attention_bam_16_attention_concentration_20": 1.4058795572618943,
      "attention_bam_16_attention_center_y": 0.47565848934445343,
      "attention_bam_16_attention_center_x": 0.46552975287009174,
      "attention_bam_16_attention_center_distance": 0.059677585041471574,
      "attention_bam_16_attention_spatial_variance": 44.30995214703473,
      "attention_bam_16_attention_spatial_std": 6.656572101843015,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.789548214351225,
      "attention_bam_16_peak_intensity_mean": 0.28711244463920593,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 609,
      "phase": "train",
      "loss": 0.0038741030730307102,
      "timestamp": 1759543987.4207375,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0038741030730307102,
      "ssim": 0.9184188842773438,
      "attention_bam_384_mean_attention": 0.022490398958325386,
      "attention_bam_384_std_attention": 0.25071045756340027,
      "attention_bam_384_max_attention": 2.3391733169555664,
      "attention_bam_384_min_attention": -0.9609460234642029,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.4748081907429595,
      "attention_bam_384_attention_skewness": 0.9349444536560174,
      "attention_bam_384_attention_sparsity": 0.6684036254882812,
      "attention_bam_384_attention_concentration_10": 2.343613744555966,
      "attention_bam_384_attention_concentration_20": 3.497833605768944,
      "attention_bam_384_attention_center_y": 0.4871043879985886,
      "attention_bam_384_attention_center_x": 0.47769950534460237,
      "attention_bam_384_attention_center_distance": 0.03643099973281997,
      "attention_bam_384_attention_spatial_variance": 170.58717224816075,
      "attention_bam_384_attention_spatial_std": 13.0609024285522,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 17.80469374648811,
      "attention_bam_384_peak_intensity_mean": 0.30080646276474,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1287516951560974,
      "attention_bam_16_std_attention": 0.5596917867660522,
      "attention_bam_16_max_attention": 2.981395959854126,
      "attention_bam_16_min_attention": -1.0726969242095947,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.5192171416346394,
      "attention_bam_16_attention_skewness": 1.001861013594901,
      "attention_bam_16_attention_sparsity": 0.543212890625,
      "attention_bam_16_attention_concentration_10": 0.9944651739665462,
      "attention_bam_16_attention_concentration_20": 1.537437705256957,
      "attention_bam_16_attention_center_y": 0.47702517227745783,
      "attention_bam_16_attention_center_x": 0.44867163843443764,
      "attention_bam_16_attention_center_distance": 0.07952915704174905,
      "attention_bam_16_attention_spatial_variance": 42.3707464149915,
      "attention_bam_16_attention_spatial_std": 6.509281559050239,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.426604804230076,
      "attention_bam_16_peak_intensity_mean": 0.3000728189945221,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 610,
      "phase": "train",
      "loss": 0.004176418762654066,
      "timestamp": 1759543987.6150515,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004176418762654066,
      "ssim": 0.9185161590576172,
      "attention_bam_384_mean_attention": 0.02349029667675495,
      "attention_bam_384_std_attention": 0.204905703663826,
      "attention_bam_384_max_attention": 2.0380425453186035,
      "attention_bam_384_min_attention": -0.7986763119697571,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.1664434048744274,
      "attention_bam_384_attention_skewness": 1.055833136972169,
      "attention_bam_384_attention_sparsity": 0.7050806681315104,
      "attention_bam_384_attention_concentration_10": 1.8866041694156934,
      "attention_bam_384_attention_concentration_20": 2.7769378110088057,
      "attention_bam_384_attention_center_y": 0.49199296633973094,
      "attention_bam_384_attention_center_x": 0.48370566715667906,
      "attention_bam_384_attention_center_distance": 0.025675586491669827,
      "attention_bam_384_attention_spatial_variance": 169.97807280598866,
      "attention_bam_384_attention_spatial_std": 13.037563913783458,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 17.605173770463836,
      "attention_bam_384_peak_intensity_mean": 0.29198652505874634,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12985146045684814,
      "attention_bam_16_std_attention": 0.5004783868789673,
      "attention_bam_16_max_attention": 2.893322229385376,
      "attention_bam_16_min_attention": -0.9803529977798462,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.7444893270169466,
      "attention_bam_16_attention_skewness": 1.0007161157263413,
      "attention_bam_16_attention_sparsity": 0.540283203125,
      "attention_bam_16_attention_concentration_10": 0.8939045812956833,
      "attention_bam_16_attention_concentration_20": 1.3816756680572302,
      "attention_bam_16_attention_center_y": 0.49160665760471794,
      "attention_bam_16_attention_center_x": 0.4686858878699463,
      "attention_bam_16_attention_center_distance": 0.04584804935998946,
      "attention_bam_16_attention_spatial_variance": 41.964042535730016,
      "attention_bam_16_attention_spatial_std": 6.477965925792603,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 7.025479777216026,
      "attention_bam_16_peak_intensity_mean": 0.30159991979599,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 611,
      "phase": "train",
      "loss": 0.004687659442424774,
      "timestamp": 1759543987.7762163,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004687659442424774,
      "ssim": 0.9023908972740173,
      "attention_bam_384_mean_attention": 0.022448183968663216,
      "attention_bam_384_std_attention": 0.24897795915603638,
      "attention_bam_384_max_attention": 1.9776573181152344,
      "attention_bam_384_min_attention": -0.7912357449531555,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.6396651624051204,
      "attention_bam_384_attention_skewness": 0.839703371025124,
      "attention_bam_384_attention_sparsity": 0.6698455810546875,
      "attention_bam_384_attention_concentration_10": 2.3515079878094793,
      "attention_bam_384_attention_concentration_20": 3.5279403878757214,
      "attention_bam_384_attention_center_y": 0.48003635312484344,
      "attention_bam_384_attention_center_x": 0.4883485716265724,
      "attention_bam_384_attention_center_distance": 0.032689538990235446,
      "attention_bam_384_attention_spatial_variance": 171.86202927732984,
      "attention_bam_384_attention_spatial_std": 13.109615908840725,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 19.852704462644983,
      "attention_bam_384_peak_intensity_mean": 0.3061245381832123,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.11979646980762482,
      "attention_bam_16_std_attention": 0.557790219783783,
      "attention_bam_16_max_attention": 3.1935534477233887,
      "attention_bam_16_min_attention": -1.0156214237213135,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.2088458829681619,
      "attention_bam_16_attention_skewness": 0.9918277402987569,
      "attention_bam_16_attention_sparsity": 0.5556640625,
      "attention_bam_16_attention_concentration_10": 1.0783086559046757,
      "attention_bam_16_attention_concentration_20": 1.6633531958804757,
      "attention_bam_16_attention_center_y": 0.45901703675435745,
      "attention_bam_16_attention_center_x": 0.4796104833250984,
      "attention_bam_16_attention_center_distance": 0.0647353947486192,
      "attention_bam_16_attention_spatial_variance": 43.27431456467033,
      "attention_bam_16_attention_spatial_std": 6.578321561361251,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.707177511248748,
      "attention_bam_16_peak_intensity_mean": 0.27529171109199524,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 612,
      "phase": "train",
      "loss": 0.005674741696566343,
      "timestamp": 1759543987.937395,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005674741696566343,
      "ssim": 0.9039648175239563,
      "attention_bam_384_mean_attention": 0.023942118510603905,
      "attention_bam_384_std_attention": 0.2388017326593399,
      "attention_bam_384_max_attention": 1.9130781888961792,
      "attention_bam_384_min_attention": -0.899179995059967,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5452111926176562,
      "attention_bam_384_attention_skewness": 0.7200841531962621,
      "attention_bam_384_attention_sparsity": 0.6738484700520834,
      "attention_bam_384_attention_concentration_10": 2.0994602904223076,
      "attention_bam_384_attention_concentration_20": 3.155553573147886,
      "attention_bam_384_attention_center_y": 0.4876386301536955,
      "attention_bam_384_attention_center_x": 0.481141033643807,
      "attention_bam_384_attention_center_distance": 0.03188931095214022,
      "attention_bam_384_attention_spatial_variance": 172.61157394402207,
      "attention_bam_384_attention_spatial_std": 13.138172397408328,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 19.83644778201763,
      "attention_bam_384_peak_intensity_mean": 0.33460402488708496,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1413256675004959,
      "attention_bam_16_std_attention": 0.534898042678833,
      "attention_bam_16_max_attention": 2.775139808654785,
      "attention_bam_16_min_attention": -1.150383472442627,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7226693111717215,
      "attention_bam_16_attention_skewness": 0.7814816028145427,
      "attention_bam_16_attention_sparsity": 0.52880859375,
      "attention_bam_16_attention_concentration_10": 0.8677979862157998,
      "attention_bam_16_attention_concentration_20": 1.3627404721615284,
      "attention_bam_16_attention_center_y": 0.47922377606182054,
      "attention_bam_16_attention_center_x": 0.46054131839684753,
      "attention_bam_16_attention_center_distance": 0.06306566474696583,
      "attention_bam_16_attention_spatial_variance": 43.82376627950197,
      "attention_bam_16_attention_spatial_std": 6.619952135741011,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 9.829195297516957,
      "attention_bam_16_peak_intensity_mean": 0.34504860639572144,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 613,
      "phase": "train",
      "loss": 0.005793293472379446,
      "timestamp": 1759543988.0937324,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005793293472379446,
      "ssim": 0.922629177570343,
      "attention_bam_384_mean_attention": 0.0244423970580101,
      "attention_bam_384_std_attention": 0.24155156314373016,
      "attention_bam_384_max_attention": 1.9238876104354858,
      "attention_bam_384_min_attention": -0.9548885226249695,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.126458896201692,
      "attention_bam_384_attention_skewness": 0.5968652848119755,
      "attention_bam_384_attention_sparsity": 0.6530303955078125,
      "attention_bam_384_attention_concentration_10": 2.008137325158356,
      "attention_bam_384_attention_concentration_20": 3.09892419167739,
      "attention_bam_384_attention_center_y": 0.4850082913358747,
      "attention_bam_384_attention_center_x": 0.47823457234315303,
      "attention_bam_384_attention_center_distance": 0.03737606639964801,
      "attention_bam_384_attention_spatial_variance": 171.69093962597796,
      "attention_bam_384_attention_spatial_std": 13.10308893452143,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 17.778044291242626,
      "attention_bam_384_peak_intensity_mean": 0.3440644145011902,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1335069239139557,
      "attention_bam_16_std_attention": 0.5419586896896362,
      "attention_bam_16_max_attention": 2.4849767684936523,
      "attention_bam_16_min_attention": -1.0437434911727905,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.38724994721640993,
      "attention_bam_16_attention_skewness": 0.6464137200690463,
      "attention_bam_16_attention_sparsity": 0.520751953125,
      "attention_bam_16_attention_concentration_10": 0.8980887656711187,
      "attention_bam_16_attention_concentration_20": 1.4287581737019097,
      "attention_bam_16_attention_center_y": 0.47109633214042773,
      "attention_bam_16_attention_center_x": 0.449793695800179,
      "attention_bam_16_attention_center_distance": 0.08192795612172235,
      "attention_bam_16_attention_spatial_variance": 43.38991977865064,
      "attention_bam_16_attention_spatial_std": 6.587102532878219,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.23267980736504,
      "attention_bam_16_peak_intensity_mean": 0.3425102233886719,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 614,
      "phase": "train",
      "loss": 0.004377854987978935,
      "timestamp": 1759543988.2384217,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004377854987978935,
      "ssim": 0.9249887466430664,
      "attention_bam_384_mean_attention": 0.022464051842689514,
      "attention_bam_384_std_attention": 0.2636001706123352,
      "attention_bam_384_max_attention": 2.34169864654541,
      "attention_bam_384_min_attention": -0.8627942800521851,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.1519577828645557,
      "attention_bam_384_attention_skewness": 0.9144712814607424,
      "attention_bam_384_attention_sparsity": 0.6650263468424479,
      "attention_bam_384_attention_concentration_10": 2.4832228551134037,
      "attention_bam_384_attention_concentration_20": 3.695464412035675,
      "attention_bam_384_attention_center_y": 0.480982576450303,
      "attention_bam_384_attention_center_x": 0.4821051597098757,
      "attention_bam_384_attention_center_distance": 0.03692933000956353,
      "attention_bam_384_attention_spatial_variance": 171.35005224968265,
      "attention_bam_384_attention_spatial_std": 13.090074570058134,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 20.18787426001272,
      "attention_bam_384_peak_intensity_mean": 0.2803381085395813,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12442445755004883,
      "attention_bam_16_std_attention": 0.5931171774864197,
      "attention_bam_16_max_attention": 3.0970139503479004,
      "attention_bam_16_min_attention": -1.1292729377746582,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.6141968850433726,
      "attention_bam_16_attention_skewness": 1.050185890121776,
      "attention_bam_16_attention_sparsity": 0.55224609375,
      "attention_bam_16_attention_concentration_10": 1.088363881873508,
      "attention_bam_16_attention_concentration_20": 1.6804810643618802,
      "attention_bam_16_attention_center_y": 0.4600199588613179,
      "attention_bam_16_attention_center_x": 0.46397902169050736,
      "attention_bam_16_attention_center_distance": 0.07610406779960781,
      "attention_bam_16_attention_spatial_variance": 43.02699706090797,
      "attention_bam_16_attention_spatial_std": 6.5594967078967255,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 10.270641798123615,
      "attention_bam_16_peak_intensity_mean": 0.3081224262714386,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 615,
      "phase": "train",
      "loss": 0.005398658569902182,
      "timestamp": 1759543988.3797905,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005398658569902182,
      "ssim": 0.9252169132232666,
      "attention_bam_384_mean_attention": 0.023670336231589317,
      "attention_bam_384_std_attention": 0.25585702061653137,
      "attention_bam_384_max_attention": 2.1303486824035645,
      "attention_bam_384_min_attention": -0.9031658172607422,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2155159430895859,
      "attention_bam_384_attention_skewness": 0.6429391546220731,
      "attention_bam_384_attention_sparsity": 0.6424306233723959,
      "attention_bam_384_attention_concentration_10": 2.1800989955212873,
      "attention_bam_384_attention_concentration_20": 3.373586602613369,
      "attention_bam_384_attention_center_y": 0.480347877140855,
      "attention_bam_384_attention_center_x": 0.48617176195654566,
      "attention_bam_384_attention_center_distance": 0.0339831164038076,
      "attention_bam_384_attention_spatial_variance": 171.21436563056878,
      "attention_bam_384_attention_spatial_std": 13.08489073819758,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 19.664916322090434,
      "attention_bam_384_peak_intensity_mean": 0.31058865785598755,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1361425220966339,
      "attention_bam_16_std_attention": 0.5833594799041748,
      "attention_bam_16_max_attention": 3.217853546142578,
      "attention_bam_16_min_attention": -1.0627965927124023,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.777583833930636,
      "attention_bam_16_attention_skewness": 0.7707212666011222,
      "attention_bam_16_attention_sparsity": 0.523193359375,
      "attention_bam_16_attention_concentration_10": 0.9490802145539752,
      "attention_bam_16_attention_concentration_20": 1.5068023733444602,
      "attention_bam_16_attention_center_y": 0.45518036203799167,
      "attention_bam_16_attention_center_x": 0.4755139168923014,
      "attention_bam_16_attention_center_distance": 0.07222697851914646,
      "attention_bam_16_attention_spatial_variance": 43.08253032755238,
      "attention_bam_16_attention_spatial_std": 6.5637283861805535,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.750751175360048,
      "attention_bam_16_peak_intensity_mean": 0.29068443179130554,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 616,
      "phase": "train",
      "loss": 0.00481975544244051,
      "timestamp": 1759543988.5232656,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00481975544244051,
      "ssim": 0.9129524230957031,
      "attention_bam_384_mean_attention": 0.022764824330806732,
      "attention_bam_384_std_attention": 0.2285013347864151,
      "attention_bam_384_max_attention": 1.7299365997314453,
      "attention_bam_384_min_attention": -0.7692986726760864,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2586327511920867,
      "attention_bam_384_attention_skewness": 0.7250439563497894,
      "attention_bam_384_attention_sparsity": 0.6719792683919271,
      "attention_bam_384_attention_concentration_10": 2.0933187102468787,
      "attention_bam_384_attention_concentration_20": 3.1969930383218035,
      "attention_bam_384_attention_center_y": 0.48192611110789574,
      "attention_bam_384_attention_center_x": 0.4891989767156358,
      "attention_bam_384_attention_center_distance": 0.029776754815577462,
      "attention_bam_384_attention_spatial_variance": 172.00464665372408,
      "attention_bam_384_attention_spatial_std": 13.115054199419996,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 16.554824296664467,
      "attention_bam_384_peak_intensity_mean": 0.3216650187969208,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13276566565036774,
      "attention_bam_16_std_attention": 0.5307483673095703,
      "attention_bam_16_max_attention": 2.9799628257751465,
      "attention_bam_16_min_attention": -0.971420168876648,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.0459486816591967,
      "attention_bam_16_attention_skewness": 0.8841533630303503,
      "attention_bam_16_attention_sparsity": 0.5380859375,
      "attention_bam_16_attention_concentration_10": 0.9200136075432467,
      "attention_bam_16_attention_concentration_20": 1.4371026895767531,
      "attention_bam_16_attention_center_y": 0.4633476226234765,
      "attention_bam_16_attention_center_x": 0.48383417546467694,
      "attention_bam_16_attention_center_distance": 0.05665210764407523,
      "attention_bam_16_attention_spatial_variance": 43.48478121188996,
      "attention_bam_16_attention_spatial_std": 6.594299144859138,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.354920817083498,
      "attention_bam_16_peak_intensity_mean": 0.3024348020553589,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 617,
      "phase": "train",
      "loss": 0.005497611593455076,
      "timestamp": 1759543988.6651664,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005497611593455076,
      "ssim": 0.9041759371757507,
      "attention_bam_384_mean_attention": 0.022460684180259705,
      "attention_bam_384_std_attention": 0.2375584989786148,
      "attention_bam_384_max_attention": 2.2130093574523926,
      "attention_bam_384_min_attention": -0.8273383378982544,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8277714855483849,
      "attention_bam_384_attention_skewness": 0.7681921845456445,
      "attention_bam_384_attention_sparsity": 0.6664377848307291,
      "attention_bam_384_attention_concentration_10": 2.1878356003923094,
      "attention_bam_384_attention_concentration_20": 3.324758902881351,
      "attention_bam_384_attention_center_y": 0.48659594221364816,
      "attention_bam_384_attention_center_x": 0.4853386394324313,
      "attention_bam_384_attention_center_distance": 0.02809356719365195,
      "attention_bam_384_attention_spatial_variance": 169.98683058000518,
      "attention_bam_384_attention_spatial_std": 13.037899776421247,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 18.406950283153236,
      "attention_bam_384_peak_intensity_mean": 0.2849026322364807,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13823428750038147,
      "attention_bam_16_std_attention": 0.5468361973762512,
      "attention_bam_16_max_attention": 3.2613930702209473,
      "attention_bam_16_min_attention": -0.9854780435562134,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.6330498049881381,
      "attention_bam_16_attention_skewness": 0.9310957291087596,
      "attention_bam_16_attention_sparsity": 0.529052734375,
      "attention_bam_16_attention_concentration_10": 0.8981737238308393,
      "attention_bam_16_attention_concentration_20": 1.4124485029307243,
      "attention_bam_16_attention_center_y": 0.47661054224717647,
      "attention_bam_16_attention_center_x": 0.4732329037147267,
      "attention_bam_16_attention_center_distance": 0.050270153719999856,
      "attention_bam_16_attention_spatial_variance": 42.05403686835377,
      "attention_bam_16_attention_spatial_std": 6.484908393212179,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.681423771914378,
      "attention_bam_16_peak_intensity_mean": 0.27742916345596313,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 618,
      "phase": "train",
      "loss": 0.005861382000148296,
      "timestamp": 1759543988.8037667,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005861382000148296,
      "ssim": 0.9243111610412598,
      "attention_bam_384_mean_attention": 0.021215880289673805,
      "attention_bam_384_std_attention": 0.2793809473514557,
      "attention_bam_384_max_attention": 1.7747149467468262,
      "attention_bam_384_min_attention": -0.8554984331130981,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7485274127567965,
      "attention_bam_384_attention_skewness": 0.6823287104430158,
      "attention_bam_384_attention_sparsity": 0.6445414225260416,
      "attention_bam_384_attention_concentration_10": 2.7309069021003145,
      "attention_bam_384_attention_concentration_20": 4.159207889076636,
      "attention_bam_384_attention_center_y": 0.48510104242581764,
      "attention_bam_384_attention_center_x": 0.4848680462134777,
      "attention_bam_384_attention_center_distance": 0.030031815203038693,
      "attention_bam_384_attention_spatial_variance": 168.94438081041991,
      "attention_bam_384_attention_spatial_std": 12.99786062436507,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 19.45828252595551,
      "attention_bam_384_peak_intensity_mean": 0.3328993022441864,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12560966610908508,
      "attention_bam_16_std_attention": 0.6136218309402466,
      "attention_bam_16_max_attention": 2.887982130050659,
      "attention_bam_16_min_attention": -1.0777004957199097,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.562747726998575,
      "attention_bam_16_attention_skewness": 0.8947808617670061,
      "attention_bam_16_attention_sparsity": 0.565673828125,
      "attention_bam_16_attention_concentration_10": 1.1208144423629673,
      "attention_bam_16_attention_concentration_20": 1.7542254471502166,
      "attention_bam_16_attention_center_y": 0.4703986220560182,
      "attention_bam_16_attention_center_x": 0.47165338541184765,
      "attention_bam_16_attention_center_distance": 0.05796157580314228,
      "attention_bam_16_attention_spatial_variance": 41.44837598969975,
      "attention_bam_16_attention_spatial_std": 6.438041316246716,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.528828585977957,
      "attention_bam_16_peak_intensity_mean": 0.30522045493125916,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 619,
      "phase": "train",
      "loss": 0.0045821769163012505,
      "timestamp": 1759543988.969617,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0045821769163012505,
      "ssim": 0.9340413808822632,
      "attention_bam_384_mean_attention": 0.020942360162734985,
      "attention_bam_384_std_attention": 0.2442653477191925,
      "attention_bam_384_max_attention": 2.0153534412384033,
      "attention_bam_384_min_attention": -0.89366614818573,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.2522172482458114,
      "attention_bam_384_attention_skewness": 0.9598159323263223,
      "attention_bam_384_attention_sparsity": 0.6941579182942709,
      "attention_bam_384_attention_concentration_10": 2.5150239999741766,
      "attention_bam_384_attention_concentration_20": 3.7332632237006793,
      "attention_bam_384_attention_center_y": 0.4922260937946286,
      "attention_bam_384_attention_center_x": 0.4893987212093658,
      "attention_bam_384_attention_center_distance": 0.018591435107955627,
      "attention_bam_384_attention_spatial_variance": 170.8296194658947,
      "attention_bam_384_attention_spatial_std": 13.070180544502616,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 20.471304450840243,
      "attention_bam_384_peak_intensity_mean": 0.31819090247154236,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13694854080677032,
      "attention_bam_16_std_attention": 0.5657800436019897,
      "attention_bam_16_max_attention": 2.815783739089966,
      "attention_bam_16_min_attention": -1.0497483015060425,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.61116534061137,
      "attention_bam_16_attention_skewness": 1.1400581224940387,
      "attention_bam_16_attention_sparsity": 0.56201171875,
      "attention_bam_16_attention_concentration_10": 0.9935766007643373,
      "attention_bam_16_attention_concentration_20": 1.507482812859226,
      "attention_bam_16_attention_center_y": 0.4953878966669795,
      "attention_bam_16_attention_center_x": 0.4878461902247481,
      "attention_bam_16_attention_center_distance": 0.018384046845429148,
      "attention_bam_16_attention_spatial_variance": 42.76056675800926,
      "attention_bam_16_attention_spatial_std": 6.5391564255650945,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 10.079268961101285,
      "attention_bam_16_peak_intensity_mean": 0.2993626892566681,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 620,
      "phase": "train",
      "loss": 0.004462413024157286,
      "timestamp": 1759543989.2249193,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004462413024157286,
      "ssim": 0.9130830764770508,
      "attention_bam_384_mean_attention": 0.02078852988779545,
      "attention_bam_384_std_attention": 0.2561398148536682,
      "attention_bam_384_max_attention": 2.0892696380615234,
      "attention_bam_384_min_attention": -0.9506003856658936,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4485668533226406,
      "attention_bam_384_attention_skewness": 0.7801599115177303,
      "attention_bam_384_attention_sparsity": 0.6683019002278646,
      "attention_bam_384_attention_concentration_10": 2.580851537243272,
      "attention_bam_384_attention_concentration_20": 3.9050845716207427,
      "attention_bam_384_attention_center_y": 0.48435631076631785,
      "attention_bam_384_attention_center_x": 0.47977065385730816,
      "attention_bam_384_attention_center_distance": 0.03616494043133111,
      "attention_bam_384_attention_spatial_variance": 171.094916948537,
      "attention_bam_384_attention_spatial_std": 13.080325567375493,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 19.648855370449496,
      "attention_bam_384_peak_intensity_mean": 0.3219227194786072,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12719401717185974,
      "attention_bam_16_std_attention": 0.5838558673858643,
      "attention_bam_16_max_attention": 3.1352379322052,
      "attention_bam_16_min_attention": -1.0991594791412354,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.2094919694759483,
      "attention_bam_16_attention_skewness": 0.9523948220905615,
      "attention_bam_16_attention_sparsity": 0.551513671875,
      "attention_bam_16_attention_concentration_10": 1.0509096579094583,
      "attention_bam_16_attention_concentration_20": 1.6240835413073185,
      "attention_bam_16_attention_center_y": 0.4698801341505579,
      "attention_bam_16_attention_center_x": 0.4557885190270432,
      "attention_bam_16_attention_center_distance": 0.07565528889126667,
      "attention_bam_16_attention_spatial_variance": 43.03466851028307,
      "attention_bam_16_attention_spatial_std": 6.560081440827017,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.222932993026102,
      "attention_bam_16_peak_intensity_mean": 0.29255175590515137,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 621,
      "phase": "train",
      "loss": 0.005844519939273596,
      "timestamp": 1759543989.4126966,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005844519939273596,
      "ssim": 0.917097270488739,
      "attention_bam_384_mean_attention": 0.01933358423411846,
      "attention_bam_384_std_attention": 0.2471022754907608,
      "attention_bam_384_max_attention": 1.4997495412826538,
      "attention_bam_384_min_attention": -0.8701652884483337,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9543685083721893,
      "attention_bam_384_attention_skewness": 0.6613501692781846,
      "attention_bam_384_attention_sparsity": 0.6723276774088541,
      "attention_bam_384_attention_concentration_10": 2.6627139709829013,
      "attention_bam_384_attention_concentration_20": 4.024205850692538,
      "attention_bam_384_attention_center_y": 0.4823276916476346,
      "attention_bam_384_attention_center_x": 0.48363716181979377,
      "attention_bam_384_attention_center_distance": 0.034060327532561926,
      "attention_bam_384_attention_spatial_variance": 170.83818006564312,
      "attention_bam_384_attention_spatial_std": 13.070508026302694,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 17.49811334791198,
      "attention_bam_384_peak_intensity_mean": 0.3761212229728699,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12531080842018127,
      "attention_bam_16_std_attention": 0.5594932436943054,
      "attention_bam_16_max_attention": 2.545315980911255,
      "attention_bam_16_min_attention": -1.0363550186157227,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5935967458641236,
      "attention_bam_16_attention_skewness": 0.8015999110712388,
      "attention_bam_16_attention_sparsity": 0.537109375,
      "attention_bam_16_attention_concentration_10": 1.0096928865441126,
      "attention_bam_16_attention_concentration_20": 1.5732410357259592,
      "attention_bam_16_attention_center_y": 0.4618949537499084,
      "attention_bam_16_attention_center_x": 0.4664211276450542,
      "attention_bam_16_attention_center_distance": 0.07182666939725607,
      "attention_bam_16_attention_spatial_variance": 42.846590310765556,
      "attention_bam_16_attention_spatial_std": 6.545730693418845,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.548578829449152,
      "attention_bam_16_peak_intensity_mean": 0.3263893723487854,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 622,
      "phase": "train",
      "loss": 0.005364540033042431,
      "timestamp": 1759543989.5847259,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005364540033042431,
      "ssim": 0.9138234853744507,
      "attention_bam_384_mean_attention": 0.01844436675310135,
      "attention_bam_384_std_attention": 0.24058036506175995,
      "attention_bam_384_max_attention": 2.2265162467956543,
      "attention_bam_384_min_attention": -0.9749965667724609,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.100533678474622,
      "attention_bam_384_attention_skewness": 0.938423341907701,
      "attention_bam_384_attention_sparsity": 0.6838709513346354,
      "attention_bam_384_attention_concentration_10": 2.782406088959433,
      "attention_bam_384_attention_concentration_20": 4.0950125378931705,
      "attention_bam_384_attention_center_y": 0.48461216522386585,
      "attention_bam_384_attention_center_x": 0.4774119324773536,
      "attention_bam_384_attention_center_distance": 0.038652457968549346,
      "attention_bam_384_attention_spatial_variance": 172.44702187237132,
      "attention_bam_384_attention_spatial_std": 13.131908538836665,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 16.513051181506157,
      "attention_bam_384_peak_intensity_mean": 0.31008094549179077,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1210600882768631,
      "attention_bam_16_std_attention": 0.5536636114120483,
      "attention_bam_16_max_attention": 2.792294502258301,
      "attention_bam_16_min_attention": -0.9729421138763428,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.5226074549238309,
      "attention_bam_16_attention_skewness": 1.1195451347158332,
      "attention_bam_16_attention_sparsity": 0.57373046875,
      "attention_bam_16_attention_concentration_10": 1.0810154347191985,
      "attention_bam_16_attention_concentration_20": 1.6443905587969017,
      "attention_bam_16_attention_center_y": 0.46981448924863,
      "attention_bam_16_attention_center_x": 0.44449337141141565,
      "attention_bam_16_attention_center_distance": 0.0893549201397676,
      "attention_bam_16_attention_spatial_variance": 43.96491725992796,
      "attention_bam_16_attention_spatial_std": 6.630604592337561,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 9.731825423542471,
      "attention_bam_16_peak_intensity_mean": 0.29375073313713074,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 623,
      "phase": "train",
      "loss": 0.00468820333480835,
      "timestamp": 1759543989.750318,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00468820333480835,
      "ssim": 0.9133881330490112,
      "attention_bam_384_mean_attention": 0.018967757001519203,
      "attention_bam_384_std_attention": 0.2401266098022461,
      "attention_bam_384_max_attention": 2.0613646507263184,
      "attention_bam_384_min_attention": -0.8926105499267578,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.094427249708116,
      "attention_bam_384_attention_skewness": 0.6264026386217694,
      "attention_bam_384_attention_sparsity": 0.6681060791015625,
      "attention_bam_384_attention_concentration_10": 2.5834754841516734,
      "attention_bam_384_attention_concentration_20": 3.950484901456295,
      "attention_bam_384_attention_center_y": 0.4799674919424649,
      "attention_bam_384_attention_center_x": 0.4793148464518935,
      "attention_bam_384_attention_center_distance": 0.04072289175350768,
      "attention_bam_384_attention_spatial_variance": 171.96263833690452,
      "attention_bam_384_attention_spatial_std": 13.113452571192093,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 14.54323732677727,
      "attention_bam_384_peak_intensity_mean": 0.30985862016677856,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13948646187782288,
      "attention_bam_16_std_attention": 0.5501716136932373,
      "attention_bam_16_max_attention": 3.3258461952209473,
      "attention_bam_16_min_attention": -1.1094062328338623,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8962884111327543,
      "attention_bam_16_attention_skewness": 0.8194248037494338,
      "attention_bam_16_attention_sparsity": 0.53173828125,
      "attention_bam_16_attention_concentration_10": 0.9061704059055276,
      "attention_bam_16_attention_concentration_20": 1.416591441413086,
      "attention_bam_16_attention_center_y": 0.4563458835432562,
      "attention_bam_16_attention_center_x": 0.4526335141167992,
      "attention_bam_16_attention_center_distance": 0.09109627729542419,
      "attention_bam_16_attention_spatial_variance": 43.69700623337028,
      "attention_bam_16_attention_spatial_std": 6.610371111622273,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 10.896482976364505,
      "attention_bam_16_peak_intensity_mean": 0.2943171560764313,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 624,
      "phase": "train",
      "loss": 0.0046985759399831295,
      "timestamp": 1759543989.9061759,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0046985759399831295,
      "ssim": 0.9246224164962769,
      "attention_bam_384_mean_attention": 0.017834661528468132,
      "attention_bam_384_std_attention": 0.2504057288169861,
      "attention_bam_384_max_attention": 1.9387761354446411,
      "attention_bam_384_min_attention": -0.9298382997512817,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.285116414477164,
      "attention_bam_384_attention_skewness": 0.6898193654033795,
      "attention_bam_384_attention_sparsity": 0.6672948201497396,
      "attention_bam_384_attention_concentration_10": 2.8808955293258087,
      "attention_bam_384_attention_concentration_20": 4.364288168113152,
      "attention_bam_384_attention_center_y": 0.48621554800467426,
      "attention_bam_384_attention_center_x": 0.48594652900014,
      "attention_bam_384_attention_center_distance": 0.0278392228323761,
      "attention_bam_384_attention_spatial_variance": 171.24563642614092,
      "attention_bam_384_attention_spatial_std": 13.086085603653252,
      "attention_bam_384_num_attention_peaks": 20,
      "attention_bam_384_peak_separation_mean": 17.184354440155328,
      "attention_bam_384_peak_intensity_mean": 0.33257728815078735,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13072898983955383,
      "attention_bam_16_std_attention": 0.5660390853881836,
      "attention_bam_16_max_attention": 2.992669105529785,
      "attention_bam_16_min_attention": -1.0509215593338013,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7658636531758285,
      "attention_bam_16_attention_skewness": 0.8213409019468225,
      "attention_bam_16_attention_sparsity": 0.540771484375,
      "attention_bam_16_attention_concentration_10": 0.981590489244611,
      "attention_bam_16_attention_concentration_20": 1.5422629513608703,
      "attention_bam_16_attention_center_y": 0.4748712402919137,
      "attention_bam_16_attention_center_x": 0.47564755097828104,
      "attention_bam_16_attention_center_distance": 0.04948729812430989,
      "attention_bam_16_attention_spatial_variance": 43.204254779021774,
      "attention_bam_16_attention_spatial_std": 6.572994354099338,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.54049563253759,
      "attention_bam_16_peak_intensity_mean": 0.303434282541275,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 625,
      "phase": "train",
      "loss": 0.0039309910498559475,
      "timestamp": 1759543990.055013,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0039309910498559475,
      "ssim": 0.9267184138298035,
      "attention_bam_384_mean_attention": 0.018177587538957596,
      "attention_bam_384_std_attention": 0.24103456735610962,
      "attention_bam_384_max_attention": 2.3051342964172363,
      "attention_bam_384_min_attention": -1.0288347005844116,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.86401265171697,
      "attention_bam_384_attention_skewness": 0.6568170075372533,
      "attention_bam_384_attention_sparsity": 0.6730194091796875,
      "attention_bam_384_attention_concentration_10": 2.680605227557739,
      "attention_bam_384_attention_concentration_20": 4.081939938350109,
      "attention_bam_384_attention_center_y": 0.4839071396709858,
      "attention_bam_384_attention_center_x": 0.4842509081621196,
      "attention_bam_384_attention_center_distance": 0.031843807790123045,
      "attention_bam_384_attention_spatial_variance": 171.68746849676833,
      "attention_bam_384_attention_spatial_std": 13.102956479236598,
      "attention_bam_384_num_attention_peaks": 30,
      "attention_bam_384_peak_separation_mean": 19.967681789252584,
      "attention_bam_384_peak_intensity_mean": 0.31799381971359253,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1403300166130066,
      "attention_bam_16_std_attention": 0.5455760359764099,
      "attention_bam_16_max_attention": 2.937939405441284,
      "attention_bam_16_min_attention": -1.18658447265625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7261445994563132,
      "attention_bam_16_attention_skewness": 0.7544786718782873,
      "attention_bam_16_attention_sparsity": 0.52880859375,
      "attention_bam_16_attention_concentration_10": 0.8834554761739938,
      "attention_bam_16_attention_concentration_20": 1.3953684397171893,
      "attention_bam_16_attention_center_y": 0.46645742840158083,
      "attention_bam_16_attention_center_x": 0.46926467083703705,
      "attention_bam_16_attention_center_distance": 0.06433917264296701,
      "attention_bam_16_attention_spatial_variance": 43.69647034810215,
      "attention_bam_16_attention_spatial_std": 6.61033057782303,
      "attention_bam_16_num_attention_peaks": 13,
      "attention_bam_16_peak_separation_mean": 10.861235761798854,
      "attention_bam_16_peak_intensity_mean": 0.32887348532676697,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 626,
      "phase": "train",
      "loss": 0.003787615103647113,
      "timestamp": 1759543990.1987371,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.003787615103647113,
      "ssim": 0.9339066743850708,
      "attention_bam_384_mean_attention": 0.018577327951788902,
      "attention_bam_384_std_attention": 0.24473561346530914,
      "attention_bam_384_max_attention": 2.0650634765625,
      "attention_bam_384_min_attention": -0.9590574502944946,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.708888800161441,
      "attention_bam_384_attention_skewness": 0.7354733829787103,
      "attention_bam_384_attention_sparsity": 0.6762924194335938,
      "attention_bam_384_attention_concentration_10": 2.7247972168697565,
      "attention_bam_384_attention_concentration_20": 4.097519585145657,
      "attention_bam_384_attention_center_y": 0.47781540204642275,
      "attention_bam_384_attention_center_x": 0.48221072531417264,
      "attention_bam_384_attention_center_distance": 0.040214790319226625,
      "attention_bam_384_attention_spatial_variance": 171.62184745748158,
      "attention_bam_384_attention_spatial_std": 13.100452185229393,
      "attention_bam_384_num_attention_peaks": 20,
      "attention_bam_384_peak_separation_mean": 17.202993015247348,
      "attention_bam_384_peak_intensity_mean": 0.330815851688385,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12811177968978882,
      "attention_bam_16_std_attention": 0.5586051940917969,
      "attention_bam_16_max_attention": 3.3015098571777344,
      "attention_bam_16_min_attention": -0.9693412780761719,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.0500011741481208,
      "attention_bam_16_attention_skewness": 0.8770900037574568,
      "attention_bam_16_attention_sparsity": 0.541015625,
      "attention_bam_16_attention_concentration_10": 0.9961272174444561,
      "attention_bam_16_attention_concentration_20": 1.5473151529998581,
      "attention_bam_16_attention_center_y": 0.44241871557076623,
      "attention_bam_16_attention_center_x": 0.46114027353024095,
      "attention_bam_16_attention_center_distance": 0.09824136254984263,
      "attention_bam_16_attention_spatial_variance": 43.4874673033775,
      "attention_bam_16_attention_spatial_std": 6.594502809414634,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 8.165923580057461,
      "attention_bam_16_peak_intensity_mean": 0.2669374346733093,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 627,
      "phase": "train",
      "loss": 0.0064760493114590645,
      "timestamp": 1759543990.3427763,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0064760493114590645,
      "ssim": 0.9036127328872681,
      "attention_bam_384_mean_attention": 0.019426459446549416,
      "attention_bam_384_std_attention": 0.2278793901205063,
      "attention_bam_384_max_attention": 1.602518081665039,
      "attention_bam_384_min_attention": -0.7821270227432251,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.802488066938873,
      "attention_bam_384_attention_skewness": 0.6006333895190903,
      "attention_bam_384_attention_sparsity": 0.6689402262369791,
      "attention_bam_384_attention_concentration_10": 2.39690232552831,
      "attention_bam_384_attention_concentration_20": 3.6959545269357914,
      "attention_bam_384_attention_center_y": 0.48761411262450505,
      "attention_bam_384_attention_center_x": 0.4846249600419961,
      "attention_bam_384_attention_center_distance": 0.02792139179155155,
      "attention_bam_384_attention_spatial_variance": 170.3675852948613,
      "attention_bam_384_attention_spatial_std": 13.052493451247592,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 21.02985759292657,
      "attention_bam_384_peak_intensity_mean": 0.34001028537750244,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13234034180641174,
      "attention_bam_16_std_attention": 0.538720965385437,
      "attention_bam_16_max_attention": 2.4520344734191895,
      "attention_bam_16_min_attention": -0.9021064639091492,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.18661745056123324,
      "attention_bam_16_attention_skewness": 0.7047537329457452,
      "attention_bam_16_attention_sparsity": 0.54736328125,
      "attention_bam_16_attention_concentration_10": 0.9100196932457292,
      "attention_bam_16_attention_concentration_20": 1.4642221048438333,
      "attention_bam_16_attention_center_y": 0.47985409686162567,
      "attention_bam_16_attention_center_x": 0.47065562580260256,
      "attention_bam_16_attention_center_distance": 0.05033785276107127,
      "attention_bam_16_attention_spatial_variance": 42.633638725174094,
      "attention_bam_16_attention_spatial_std": 6.529443982849848,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.42818266802538,
      "attention_bam_16_peak_intensity_mean": 0.32157275080680847,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 628,
      "phase": "train",
      "loss": 0.004488258622586727,
      "timestamp": 1759543990.486018,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004488258622586727,
      "ssim": 0.9168039560317993,
      "attention_bam_384_mean_attention": 0.019021963700652122,
      "attention_bam_384_std_attention": 0.22212524712085724,
      "attention_bam_384_max_attention": 1.627978801727295,
      "attention_bam_384_min_attention": -0.8194292783737183,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.373824310453001,
      "attention_bam_384_attention_skewness": 0.7196293928659139,
      "attention_bam_384_attention_sparsity": 0.6774546305338541,
      "attention_bam_384_attention_concentration_10": 2.4122976981604802,
      "attention_bam_384_attention_concentration_20": 3.652889194367754,
      "attention_bam_384_attention_center_y": 0.4887683085021408,
      "attention_bam_384_attention_center_x": 0.4889072294371993,
      "attention_bam_384_attention_center_distance": 0.022324894295920893,
      "attention_bam_384_attention_spatial_variance": 172.19111819530144,
      "attention_bam_384_attention_spatial_std": 13.122161338563911,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 20.720735844573174,
      "attention_bam_384_peak_intensity_mean": 0.34881970286369324,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13367055356502533,
      "attention_bam_16_std_attention": 0.5221817493438721,
      "attention_bam_16_max_attention": 2.5842065811157227,
      "attention_bam_16_min_attention": -1.0347305536270142,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8509758252983612,
      "attention_bam_16_attention_skewness": 0.833447095484956,
      "attention_bam_16_attention_sparsity": 0.541015625,
      "attention_bam_16_attention_concentration_10": 0.8990065636241618,
      "attention_bam_16_attention_concentration_20": 1.4038106549014828,
      "attention_bam_16_attention_center_y": 0.4843321410657371,
      "attention_bam_16_attention_center_x": 0.4862875495947018,
      "attention_bam_16_attention_center_distance": 0.029445308614505162,
      "attention_bam_16_attention_spatial_variance": 43.791985180600285,
      "attention_bam_16_attention_spatial_std": 6.617551297919819,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 10.413771587092471,
      "attention_bam_16_peak_intensity_mean": 0.32970568537712097,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 629,
      "phase": "train",
      "loss": 0.0033748128917068243,
      "timestamp": 1759543990.6295042,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0033748128917068243,
      "ssim": 0.9375853538513184,
      "attention_bam_384_mean_attention": 0.01768469624221325,
      "attention_bam_384_std_attention": 0.2501646876335144,
      "attention_bam_384_max_attention": 2.1229782104492188,
      "attention_bam_384_min_attention": -1.1176648139953613,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2018822629744967,
      "attention_bam_384_attention_skewness": 0.6778401747748922,
      "attention_bam_384_attention_sparsity": 0.6666437784830729,
      "attention_bam_384_attention_concentration_10": 2.902662748937342,
      "attention_bam_384_attention_concentration_20": 4.4040439843836205,
      "attention_bam_384_attention_center_y": 0.48466089003321866,
      "attention_bam_384_attention_center_x": 0.4795425994637652,
      "attention_bam_384_attention_center_distance": 0.03616057331605654,
      "attention_bam_384_attention_spatial_variance": 171.9740613955158,
      "attention_bam_384_attention_spatial_std": 13.11388811129315,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 20.487405731769794,
      "attention_bam_384_peak_intensity_mean": 0.35491055250167847,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12912839651107788,
      "attention_bam_16_std_attention": 0.5729426145553589,
      "attention_bam_16_max_attention": 3.141101360321045,
      "attention_bam_16_min_attention": -1.1396372318267822,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.9645124491350554,
      "attention_bam_16_attention_skewness": 0.8729611510113822,
      "attention_bam_16_attention_sparsity": 0.5419921875,
      "attention_bam_16_attention_concentration_10": 1.004497291589495,
      "attention_bam_16_attention_concentration_20": 1.5659649697476514,
      "attention_bam_16_attention_center_y": 0.4711151823320417,
      "attention_bam_16_attention_center_x": 0.45036806343903846,
      "attention_bam_16_attention_center_distance": 0.0812115979217563,
      "attention_bam_16_attention_spatial_variance": 43.82619945858669,
      "attention_bam_16_attention_spatial_std": 6.62013590937427,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 10.316695999368855,
      "attention_bam_16_peak_intensity_mean": 0.3073076009750366,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 630,
      "phase": "train",
      "loss": 0.006434867158532143,
      "timestamp": 1759543990.8159246,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006434867158532143,
      "ssim": 0.9135901927947998,
      "attention_bam_384_mean_attention": 0.018513360992074013,
      "attention_bam_384_std_attention": 0.23271526396274567,
      "attention_bam_384_max_attention": 2.1255345344543457,
      "attention_bam_384_min_attention": -0.954193115234375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.988226814132057,
      "attention_bam_384_attention_skewness": 0.8729727639138815,
      "attention_bam_384_attention_sparsity": 0.689239501953125,
      "attention_bam_384_attention_concentration_10": 2.659302667498665,
      "attention_bam_384_attention_concentration_20": 3.969733035126248,
      "attention_bam_384_attention_center_y": 0.4869286300485832,
      "attention_bam_384_attention_center_x": 0.4780032026204183,
      "attention_bam_384_attention_center_distance": 0.036186179885839685,
      "attention_bam_384_attention_spatial_variance": 171.50117292204462,
      "attention_bam_384_attention_spatial_std": 13.095845636003984,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 20.593477419128273,
      "attention_bam_384_peak_intensity_mean": 0.31962156295776367,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1308417022228241,
      "attention_bam_16_std_attention": 0.5474111437797546,
      "attention_bam_16_max_attention": 2.7392563819885254,
      "attention_bam_16_min_attention": -0.9762362241744995,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.2573513217389678,
      "attention_bam_16_attention_skewness": 1.0130328013098935,
      "attention_bam_16_attention_sparsity": 0.55419921875,
      "attention_bam_16_attention_concentration_10": 0.9774222556310668,
      "attention_bam_16_attention_concentration_20": 1.512364705133296,
      "attention_bam_16_attention_center_y": 0.48009531008779327,
      "attention_bam_16_attention_center_x": 0.44535223998274714,
      "attention_bam_16_attention_center_distance": 0.08225052407619496,
      "attention_bam_16_attention_spatial_variance": 43.2560120159988,
      "attention_bam_16_attention_spatial_std": 6.57693028821188,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 10.461033556603718,
      "attention_bam_16_peak_intensity_mean": 0.29276102781295776,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 631,
      "phase": "train",
      "loss": 0.005707621108740568,
      "timestamp": 1759543990.9631872,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005707621108740568,
      "ssim": 0.9222478866577148,
      "attention_bam_384_mean_attention": 0.017931386828422546,
      "attention_bam_384_std_attention": 0.24412888288497925,
      "attention_bam_384_max_attention": 1.8218744993209839,
      "attention_bam_384_min_attention": -0.8553375601768494,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5130674124355554,
      "attention_bam_384_attention_skewness": 0.7274158661385735,
      "attention_bam_384_attention_sparsity": 0.6792246500651041,
      "attention_bam_384_attention_concentration_10": 2.8315877968916077,
      "attention_bam_384_attention_concentration_20": 4.243278999125576,
      "attention_bam_384_attention_center_y": 0.4842287735679236,
      "attention_bam_384_attention_center_x": 0.4885640323923347,
      "attention_bam_384_attention_center_distance": 0.02755042425427947,
      "attention_bam_384_attention_spatial_variance": 170.62384523075895,
      "attention_bam_384_attention_spatial_std": 13.062306275338935,
      "attention_bam_384_num_attention_peaks": 21,
      "attention_bam_384_peak_separation_mean": 18.81380879832008,
      "attention_bam_384_peak_intensity_mean": 0.3295672833919525,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1285756528377533,
      "attention_bam_16_std_attention": 0.5545060038566589,
      "attention_bam_16_max_attention": 2.7272799015045166,
      "attention_bam_16_min_attention": -1.0481362342834473,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.9258490463656379,
      "attention_bam_16_attention_skewness": 0.8796980410109414,
      "attention_bam_16_attention_sparsity": 0.5517578125,
      "attention_bam_16_attention_concentration_10": 0.9932767507181681,
      "attention_bam_16_attention_concentration_20": 1.53895606752592,
      "attention_bam_16_attention_center_y": 0.47001247302137544,
      "attention_bam_16_attention_center_x": 0.48451787617905295,
      "attention_bam_16_attention_center_distance": 0.047727307326118275,
      "attention_bam_16_attention_spatial_variance": 42.5327195642661,
      "attention_bam_16_attention_spatial_std": 6.521711398418831,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 8.512758066629631,
      "attention_bam_16_peak_intensity_mean": 0.3090619444847107,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 632,
      "phase": "train",
      "loss": 0.004883655346930027,
      "timestamp": 1759543991.1092272,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004883655346930027,
      "ssim": 0.9349073171615601,
      "attention_bam_384_mean_attention": 0.016773443669080734,
      "attention_bam_384_std_attention": 0.2504562437534332,
      "attention_bam_384_max_attention": 2.011138439178467,
      "attention_bam_384_min_attention": -0.813732385635376,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5915723440991147,
      "attention_bam_384_attention_skewness": 0.7776523990609576,
      "attention_bam_384_attention_sparsity": 0.6723225911458334,
      "attention_bam_384_attention_concentration_10": 3.0726661509584803,
      "attention_bam_384_attention_concentration_20": 4.643565428786081,
      "attention_bam_384_attention_center_y": 0.48723705472064693,
      "attention_bam_384_attention_center_x": 0.4871522519934607,
      "attention_bam_384_attention_center_distance": 0.025610833685895337,
      "attention_bam_384_attention_spatial_variance": 172.24643779886478,
      "attention_bam_384_attention_spatial_std": 13.124269038649915,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 20.426931054301928,
      "attention_bam_384_peak_intensity_mean": 0.3012273907661438,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.11580060422420502,
      "attention_bam_16_std_attention": 0.5745992064476013,
      "attention_bam_16_max_attention": 3.266117811203003,
      "attention_bam_16_min_attention": -0.991527795791626,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.4244407043785348,
      "attention_bam_16_attention_skewness": 1.0147918275065662,
      "attention_bam_16_attention_sparsity": 0.560546875,
      "attention_bam_16_attention_concentration_10": 1.1361755712839714,
      "attention_bam_16_attention_concentration_20": 1.7408899755360718,
      "attention_bam_16_attention_center_y": 0.4779355192564079,
      "attention_bam_16_attention_center_x": 0.4791844327493147,
      "attention_bam_16_attention_center_distance": 0.042898231908836224,
      "attention_bam_16_attention_spatial_variance": 43.956085060638635,
      "attention_bam_16_attention_spatial_std": 6.6299385412414376,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 12.38041468878876,
      "attention_bam_16_peak_intensity_mean": 0.27800706028938293,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 633,
      "phase": "train",
      "loss": 0.0045061660930514336,
      "timestamp": 1759543991.2571914,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0045061660930514336,
      "ssim": 0.9089269638061523,
      "attention_bam_384_mean_attention": 0.01829764060676098,
      "attention_bam_384_std_attention": 0.2650267481803894,
      "attention_bam_384_max_attention": 1.8281110525131226,
      "attention_bam_384_min_attention": -0.8139618039131165,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6535686221513819,
      "attention_bam_384_attention_skewness": 0.6437094204587918,
      "attention_bam_384_attention_sparsity": 0.6664683024088541,
      "attention_bam_384_attention_concentration_10": 2.989936958465447,
      "attention_bam_384_attention_concentration_20": 4.597060088799964,
      "attention_bam_384_attention_center_y": 0.4845473520596321,
      "attention_bam_384_attention_center_x": 0.483891891932038,
      "attention_bam_384_attention_center_distance": 0.031567561638431864,
      "attention_bam_384_attention_spatial_variance": 171.74850421943714,
      "attention_bam_384_attention_spatial_std": 13.105285354368943,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 18.876555144622046,
      "attention_bam_384_peak_intensity_mean": 0.3178654909133911,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.11959075927734375,
      "attention_bam_16_std_attention": 0.6010593771934509,
      "attention_bam_16_max_attention": 2.8546295166015625,
      "attention_bam_16_min_attention": -0.9160556793212891,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.41992357927751156,
      "attention_bam_16_attention_skewness": 0.8524632352582205,
      "attention_bam_16_attention_sparsity": 0.5625,
      "attention_bam_16_attention_concentration_10": 1.1426173743785877,
      "attention_bam_16_attention_concentration_20": 1.8009928229297405,
      "attention_bam_16_attention_center_y": 0.47130098032912604,
      "attention_bam_16_attention_center_x": 0.466986588372861,
      "attention_bam_16_attention_center_distance": 0.061863059693683546,
      "attention_bam_16_attention_spatial_variance": 43.53647681887047,
      "attention_bam_16_attention_spatial_std": 6.59821770017256,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 10.341130796760316,
      "attention_bam_16_peak_intensity_mean": 0.288296639919281,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 634,
      "phase": "train",
      "loss": 0.005055582616478205,
      "timestamp": 1759543991.430482,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005055582616478205,
      "ssim": 0.9111520051956177,
      "attention_bam_384_mean_attention": 0.01838548295199871,
      "attention_bam_384_std_attention": 0.22402192652225494,
      "attention_bam_384_max_attention": 1.6375563144683838,
      "attention_bam_384_min_attention": -0.8042445182800293,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8964112796835026,
      "attention_bam_384_attention_skewness": 0.7489885911196569,
      "attention_bam_384_attention_sparsity": 0.6938298543294271,
      "attention_bam_384_attention_concentration_10": 2.5558675848257226,
      "attention_bam_384_attention_concentration_20": 3.7850077404655362,
      "attention_bam_384_attention_center_y": 0.4816990587090312,
      "attention_bam_384_attention_center_x": 0.48653324332646536,
      "attention_bam_384_attention_center_distance": 0.03213340901428534,
      "attention_bam_384_attention_spatial_variance": 172.8967848799971,
      "attention_bam_384_attention_spatial_std": 13.14902220243,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 21.649036429172103,
      "attention_bam_384_peak_intensity_mean": 0.3405621647834778,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1311173141002655,
      "attention_bam_16_std_attention": 0.5300579071044922,
      "attention_bam_16_max_attention": 2.364853858947754,
      "attention_bam_16_min_attention": -0.9899605512619019,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8843418167602088,
      "attention_bam_16_attention_skewness": 0.8710081259472454,
      "attention_bam_16_attention_sparsity": 0.542724609375,
      "attention_bam_16_attention_concentration_10": 0.9414718539171866,
      "attention_bam_16_attention_concentration_20": 1.4564551465816267,
      "attention_bam_16_attention_center_y": 0.4616217143310986,
      "attention_bam_16_attention_center_x": 0.47713974989244673,
      "attention_bam_16_attention_center_distance": 0.06317410618067645,
      "attention_bam_16_attention_spatial_variance": 44.43760283074105,
      "attention_bam_16_attention_spatial_std": 6.666153525890403,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.369214846018563,
      "attention_bam_16_peak_intensity_mean": 0.34581637382507324,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 635,
      "phase": "train",
      "loss": 0.004628119058907032,
      "timestamp": 1759543991.6255493,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004628119058907032,
      "ssim": 0.9210084080696106,
      "attention_bam_384_mean_attention": 0.018412895500659943,
      "attention_bam_384_std_attention": 0.2381357103586197,
      "attention_bam_384_max_attention": 2.3802647590637207,
      "attention_bam_384_min_attention": -0.9168145656585693,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.041174865200011,
      "attention_bam_384_attention_skewness": 0.7765962870474453,
      "attention_bam_384_attention_sparsity": 0.6813456217447916,
      "attention_bam_384_attention_concentration_10": 2.688286812627129,
      "attention_bam_384_attention_concentration_20": 4.00892256566101,
      "attention_bam_384_attention_center_y": 0.4860347046205967,
      "attention_bam_384_attention_center_x": 0.4752126512628058,
      "attention_bam_384_attention_center_distance": 0.04023536087705103,
      "attention_bam_384_attention_spatial_variance": 169.87332350675396,
      "attention_bam_384_attention_spatial_std": 13.033546083347922,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 11.603206176059697,
      "attention_bam_384_peak_intensity_mean": 0.28590306639671326,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12956741452217102,
      "attention_bam_16_std_attention": 0.5534747838973999,
      "attention_bam_16_max_attention": 3.328594446182251,
      "attention_bam_16_min_attention": -0.9878731966018677,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.0471315907211487,
      "attention_bam_16_attention_skewness": 0.8547264482465161,
      "attention_bam_16_attention_sparsity": 0.53173828125,
      "attention_bam_16_attention_concentration_10": 0.9776412567690048,
      "attention_bam_16_attention_concentration_20": 1.5112227292213267,
      "attention_bam_16_attention_center_y": 0.47653940038269693,
      "attention_bam_16_attention_center_x": 0.43593835686260934,
      "attention_bam_16_attention_center_distance": 0.09648102254708739,
      "attention_bam_16_attention_spatial_variance": 41.47697483386112,
      "attention_bam_16_attention_spatial_std": 6.440262015932358,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 6.870052089208287,
      "attention_bam_16_peak_intensity_mean": 0.26460832357406616,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 636,
      "phase": "train",
      "loss": 0.005724993534386158,
      "timestamp": 1759543991.8118725,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005724993534386158,
      "ssim": 0.8814550638198853,
      "attention_bam_384_mean_attention": 0.01820254884660244,
      "attention_bam_384_std_attention": 0.2092161327600479,
      "attention_bam_384_max_attention": 1.6497955322265625,
      "attention_bam_384_min_attention": -0.8091633319854736,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8935520154094858,
      "attention_bam_384_attention_skewness": 0.5397661051647874,
      "attention_bam_384_attention_sparsity": 0.6788609822591146,
      "attention_bam_384_attention_concentration_10": 2.3114067701255987,
      "attention_bam_384_attention_concentration_20": 3.5793835548542945,
      "attention_bam_384_attention_center_y": 0.4845702684570586,
      "attention_bam_384_attention_center_x": 0.4826343408037023,
      "attention_bam_384_attention_center_distance": 0.03285248041805061,
      "attention_bam_384_attention_spatial_variance": 171.8164306463831,
      "attention_bam_384_attention_spatial_std": 13.107876664295523,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 18.93334214214475,
      "attention_bam_384_peak_intensity_mean": 0.33801552653312683,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14219924807548523,
      "attention_bam_16_std_attention": 0.49596479535102844,
      "attention_bam_16_max_attention": 2.979722261428833,
      "attention_bam_16_min_attention": -1.0083109140396118,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.39483719186153854,
      "attention_bam_16_attention_skewness": 0.6130853104946671,
      "attention_bam_16_attention_sparsity": 0.52001953125,
      "attention_bam_16_attention_concentration_10": 0.7806807309647236,
      "attention_bam_16_attention_concentration_20": 1.254434376363665,
      "attention_bam_16_attention_center_y": 0.47153581847615245,
      "attention_bam_16_attention_center_x": 0.46435028991533683,
      "attention_bam_16_attention_center_distance": 0.06451529212431854,
      "attention_bam_16_attention_spatial_variance": 43.6274519936298,
      "attention_bam_16_attention_spatial_std": 6.605108022858506,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.889488960538895,
      "attention_bam_16_peak_intensity_mean": 0.29262423515319824,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 637,
      "phase": "train",
      "loss": 0.005623748525977135,
      "timestamp": 1759543991.9901998,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005623748525977135,
      "ssim": 0.9192184209823608,
      "attention_bam_384_mean_attention": 0.017159784212708473,
      "attention_bam_384_std_attention": 0.21521633863449097,
      "attention_bam_384_max_attention": 1.591880440711975,
      "attention_bam_384_min_attention": -0.7248082160949707,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8328246258681142,
      "attention_bam_384_attention_skewness": 0.5785118568651559,
      "attention_bam_384_attention_sparsity": 0.6710255940755209,
      "attention_bam_384_attention_concentration_10": 2.514285234607115,
      "attention_bam_384_attention_concentration_20": 3.8881898132960933,
      "attention_bam_384_attention_center_y": 0.48083229084099066,
      "attention_bam_384_attention_center_x": 0.4847231119895583,
      "attention_bam_384_attention_center_distance": 0.03466365190478197,
      "attention_bam_384_attention_spatial_variance": 172.5721814481846,
      "attention_bam_384_attention_spatial_std": 13.136673149933532,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 22.31640493259752,
      "attention_bam_384_peak_intensity_mean": 0.3236205279827118,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1207614541053772,
      "attention_bam_16_std_attention": 0.5126512050628662,
      "attention_bam_16_max_attention": 2.5238029956817627,
      "attention_bam_16_min_attention": -0.8663187623023987,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5810180939106147,
      "attention_bam_16_attention_skewness": 0.7792204633498369,
      "attention_bam_16_attention_sparsity": 0.54345703125,
      "attention_bam_16_attention_concentration_10": 0.9498866261645705,
      "attention_bam_16_attention_concentration_20": 1.506179292491271,
      "attention_bam_16_attention_center_y": 0.457738883449761,
      "attention_bam_16_attention_center_x": 0.4727672827767209,
      "attention_bam_16_attention_center_distance": 0.07110025118712263,
      "attention_bam_16_attention_spatial_variance": 44.4137401922962,
      "attention_bam_16_attention_spatial_std": 6.664363449894986,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.755703747835081,
      "attention_bam_16_peak_intensity_mean": 0.2960973083972931,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 638,
      "phase": "train",
      "loss": 0.004418565426021814,
      "timestamp": 1759543992.1585383,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004418565426021814,
      "ssim": 0.9295251369476318,
      "attention_bam_384_mean_attention": 0.016821928322315216,
      "attention_bam_384_std_attention": 0.25001442432403564,
      "attention_bam_384_max_attention": 2.409756660461426,
      "attention_bam_384_min_attention": -1.1527104377746582,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.176033809229396,
      "attention_bam_384_attention_skewness": 0.6284298889014721,
      "attention_bam_384_attention_sparsity": 0.6588846842447916,
      "attention_bam_384_attention_concentration_10": 2.9560638869368514,
      "attention_bam_384_attention_concentration_20": 4.487507682615968,
      "attention_bam_384_attention_center_y": 0.48546602680143497,
      "attention_bam_384_attention_center_x": 0.481735117891248,
      "attention_bam_384_attention_center_distance": 0.03301037095772222,
      "attention_bam_384_attention_spatial_variance": 171.9812382900899,
      "attention_bam_384_attention_spatial_std": 13.114161745612638,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 17.403835895334378,
      "attention_bam_384_peak_intensity_mean": 0.32916373014450073,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1387888640165329,
      "attention_bam_16_std_attention": 0.575368344783783,
      "attention_bam_16_max_attention": 3.334144115447998,
      "attention_bam_16_min_attention": -1.2372500896453857,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.2266918423683908,
      "attention_bam_16_attention_skewness": 0.8491641945133667,
      "attention_bam_16_attention_sparsity": 0.52880859375,
      "attention_bam_16_attention_concentration_10": 0.9374570201584875,
      "attention_bam_16_attention_concentration_20": 1.4670901097373514,
      "attention_bam_16_attention_center_y": 0.47321016176924874,
      "attention_bam_16_attention_center_x": 0.45875816848522505,
      "attention_bam_16_attention_center_distance": 0.06954975340176132,
      "attention_bam_16_attention_spatial_variance": 43.89832419656127,
      "attention_bam_16_attention_spatial_std": 6.625581045958254,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 11.09292849081854,
      "attention_bam_16_peak_intensity_mean": 0.31020715832710266,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 639,
      "phase": "train",
      "loss": 0.004342454951256514,
      "timestamp": 1759543992.3197656,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004342454951256514,
      "ssim": 0.9326871633529663,
      "attention_bam_384_mean_attention": 0.015880700200796127,
      "attention_bam_384_std_attention": 0.21516360342502594,
      "attention_bam_384_max_attention": 1.641798496246338,
      "attention_bam_384_min_attention": -0.8618543148040771,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.528915346582985,
      "attention_bam_384_attention_skewness": 0.6682706477869272,
      "attention_bam_384_attention_sparsity": 0.7008539835611979,
      "attention_bam_384_attention_concentration_10": 2.7879284334744723,
      "attention_bam_384_attention_concentration_20": 4.203647104822021,
      "attention_bam_384_attention_center_y": 0.48538734204788947,
      "attention_bam_384_attention_center_x": 0.478134329388382,
      "attention_bam_384_attention_center_distance": 0.037192400399037255,
      "attention_bam_384_attention_spatial_variance": 171.5155429933153,
      "attention_bam_384_attention_spatial_std": 13.096394274506068,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 18.549341826615393,
      "attention_bam_384_peak_intensity_mean": 0.3552773594856262,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1286991387605667,
      "attention_bam_16_std_attention": 0.5171626806259155,
      "attention_bam_16_max_attention": 2.6602683067321777,
      "attention_bam_16_min_attention": -0.8928397297859192,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5453177056616005,
      "attention_bam_16_attention_skewness": 0.7578806310095133,
      "attention_bam_16_attention_sparsity": 0.54150390625,
      "attention_bam_16_attention_concentration_10": 0.9134047435854642,
      "attention_bam_16_attention_concentration_20": 1.4428795997527801,
      "attention_bam_16_attention_center_y": 0.4741026806674365,
      "attention_bam_16_attention_center_x": 0.44444901254527974,
      "attention_bam_16_attention_center_distance": 0.0866785250890583,
      "attention_bam_16_attention_spatial_variance": 43.3549311404399,
      "attention_bam_16_attention_spatial_std": 6.584446152900022,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 11.320753172096339,
      "attention_bam_16_peak_intensity_mean": 0.30551961064338684,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 640,
      "phase": "train",
      "loss": 0.005290786735713482,
      "timestamp": 1759543992.5183413,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005290786735713482,
      "ssim": 0.9097683429718018,
      "attention_bam_384_mean_attention": 0.015522162429988384,
      "attention_bam_384_std_attention": 0.21015696227550507,
      "attention_bam_384_max_attention": 1.5766733884811401,
      "attention_bam_384_min_attention": -0.8913202285766602,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1489161043151013,
      "attention_bam_384_attention_skewness": 0.5481070888036297,
      "attention_bam_384_attention_sparsity": 0.6876754760742188,
      "attention_bam_384_attention_concentration_10": 2.722363732242076,
      "attention_bam_384_attention_concentration_20": 4.152999784954847,
      "attention_bam_384_attention_center_y": 0.48824443824649705,
      "attention_bam_384_attention_center_x": 0.48329416552143445,
      "attention_bam_384_attention_center_distance": 0.028888687674093156,
      "attention_bam_384_attention_spatial_variance": 172.17058619666312,
      "attention_bam_384_attention_spatial_std": 13.12137897466052,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 19.583420183528375,
      "attention_bam_384_peak_intensity_mean": 0.3749486804008484,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13638588786125183,
      "attention_bam_16_std_attention": 0.5015444159507751,
      "attention_bam_16_max_attention": 2.771531343460083,
      "attention_bam_16_min_attention": -0.9932726621627808,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.2879655558308878,
      "attention_bam_16_attention_skewness": 0.6246136206757267,
      "attention_bam_16_attention_sparsity": 0.5224609375,
      "attention_bam_16_attention_concentration_10": 0.8271837103255928,
      "attention_bam_16_attention_concentration_20": 1.319863576874212,
      "attention_bam_16_attention_center_y": 0.4865950751307711,
      "attention_bam_16_attention_center_x": 0.46644387351918853,
      "attention_bam_16_attention_center_distance": 0.05110196933868376,
      "attention_bam_16_attention_spatial_variance": 44.13569022964314,
      "attention_bam_16_attention_spatial_std": 6.643469743262412,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 7.498304838495903,
      "attention_bam_16_peak_intensity_mean": 0.3166521191596985,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 641,
      "phase": "train",
      "loss": 0.006121938582509756,
      "timestamp": 1759543992.6726403,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006121938582509756,
      "ssim": 0.8842024803161621,
      "attention_bam_384_mean_attention": 0.015271175652742386,
      "attention_bam_384_std_attention": 0.22228874266147614,
      "attention_bam_384_max_attention": 1.938141107559204,
      "attention_bam_384_min_attention": -0.9292067289352417,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.76350972884073,
      "attention_bam_384_attention_skewness": 0.6916627446294774,
      "attention_bam_384_attention_sparsity": 0.6922760009765625,
      "attention_bam_384_attention_concentration_10": 2.9854989947482293,
      "attention_bam_384_attention_concentration_20": 4.46886255663298,
      "attention_bam_384_attention_center_y": 0.48500161920327867,
      "attention_bam_384_attention_center_x": 0.4814397925568093,
      "attention_bam_384_attention_center_distance": 0.033747080669525496,
      "attention_bam_384_attention_spatial_variance": 171.15375208201968,
      "attention_bam_384_attention_spatial_std": 13.08257436753255,
      "attention_bam_384_num_attention_peaks": 24,
      "attention_bam_384_peak_separation_mean": 17.81035932076775,
      "attention_bam_384_peak_intensity_mean": 0.3311423361301422,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14463284611701965,
      "attention_bam_16_std_attention": 0.514150857925415,
      "attention_bam_16_max_attention": 2.8249094486236572,
      "attention_bam_16_min_attention": -1.088077425956726,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6512352017113177,
      "attention_bam_16_attention_skewness": 0.6847074208819941,
      "attention_bam_16_attention_sparsity": 0.519287109375,
      "attention_bam_16_attention_concentration_10": 0.8052969221633448,
      "attention_bam_16_attention_concentration_20": 1.2747238708124882,
      "attention_bam_16_attention_center_y": 0.47258511166463685,
      "attention_bam_16_attention_center_x": 0.45946372900742827,
      "attention_bam_16_attention_center_distance": 0.0692064356606182,
      "attention_bam_16_attention_spatial_variance": 43.21146153382773,
      "attention_bam_16_attention_spatial_std": 6.573542540657034,
      "attention_bam_16_num_attention_peaks": 12,
      "attention_bam_16_peak_separation_mean": 9.709147933696261,
      "attention_bam_16_peak_intensity_mean": 0.31830018758773804,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 642,
      "phase": "train",
      "loss": 0.003791491035372019,
      "timestamp": 1759543992.810091,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.003791491035372019,
      "ssim": 0.9209359884262085,
      "attention_bam_384_mean_attention": 0.01621214486658573,
      "attention_bam_384_std_attention": 0.22971321642398834,
      "attention_bam_384_max_attention": 1.8858890533447266,
      "attention_bam_384_min_attention": -0.8141549229621887,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.7373934357045675,
      "attention_bam_384_attention_skewness": 0.7362484437670193,
      "attention_bam_384_attention_sparsity": 0.6767578125,
      "attention_bam_384_attention_concentration_10": 2.8917227543631965,
      "attention_bam_384_attention_concentration_20": 4.356243198389214,
      "attention_bam_384_attention_center_y": 0.47839880420352116,
      "attention_bam_384_attention_center_x": 0.4801860138469897,
      "attention_bam_384_attention_center_distance": 0.04145372618015173,
      "attention_bam_384_attention_spatial_variance": 170.4838536649631,
      "attention_bam_384_attention_spatial_std": 13.05694656743923,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 18.496953251045298,
      "attention_bam_384_peak_intensity_mean": 0.3160646855831146,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13256561756134033,
      "attention_bam_16_std_attention": 0.5508320927619934,
      "attention_bam_16_max_attention": 2.713622570037842,
      "attention_bam_16_min_attention": -1.0438295602798462,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.1103732462988516,
      "attention_bam_16_attention_skewness": 0.895515419288944,
      "attention_bam_16_attention_sparsity": 0.536376953125,
      "attention_bam_16_attention_concentration_10": 0.9509957366504684,
      "attention_bam_16_attention_concentration_20": 1.4781661602132719,
      "attention_bam_16_attention_center_y": 0.4495688856848997,
      "attention_bam_16_attention_center_x": 0.45562042517043627,
      "attention_bam_16_attention_center_distance": 0.09500362049012193,
      "attention_bam_16_attention_spatial_variance": 42.19380227486732,
      "attention_bam_16_attention_spatial_std": 6.495675659611348,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.644071864525712,
      "attention_bam_16_peak_intensity_mean": 0.32854485511779785,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 643,
      "phase": "train",
      "loss": 0.0069684735499322414,
      "timestamp": 1759543992.95073,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0069684735499322414,
      "ssim": 0.872283935546875,
      "attention_bam_384_mean_attention": 0.016141707077622414,
      "attention_bam_384_std_attention": 0.24269996583461761,
      "attention_bam_384_max_attention": 1.8861234188079834,
      "attention_bam_384_min_attention": -0.9866102337837219,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2521234810252304,
      "attention_bam_384_attention_skewness": 0.6491303238570809,
      "attention_bam_384_attention_sparsity": 0.6659088134765625,
      "attention_bam_384_attention_concentration_10": 3.0367574660778485,
      "attention_bam_384_attention_concentration_20": 4.624630827903651,
      "attention_bam_384_attention_center_y": 0.4839422738331843,
      "attention_bam_384_attention_center_x": 0.4823813385863919,
      "attention_bam_384_attention_center_distance": 0.033712543649383746,
      "attention_bam_384_attention_spatial_variance": 169.86335857946332,
      "attention_bam_384_attention_spatial_std": 13.033163797768497,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 17.124663760356825,
      "attention_bam_384_peak_intensity_mean": 0.35321810841560364,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1311596930027008,
      "attention_bam_16_std_attention": 0.5682142972946167,
      "attention_bam_16_max_attention": 3.120476722717285,
      "attention_bam_16_min_attention": -1.0451411008834839,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.0923451531084352,
      "attention_bam_16_attention_skewness": 0.8780136133096987,
      "attention_bam_16_attention_sparsity": 0.5380859375,
      "attention_bam_16_attention_concentration_10": 0.982751945055871,
      "attention_bam_16_attention_concentration_20": 1.5322410485176126,
      "attention_bam_16_attention_center_y": 0.46849874216963594,
      "attention_bam_16_attention_center_x": 0.4627614237366355,
      "attention_bam_16_attention_center_distance": 0.06897884903385224,
      "attention_bam_16_attention_spatial_variance": 41.813687976719585,
      "attention_bam_16_attention_spatial_std": 6.466350437203321,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 10.044869971903998,
      "attention_bam_16_peak_intensity_mean": 0.28684473037719727,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 644,
      "phase": "train",
      "loss": 0.006437025964260101,
      "timestamp": 1759543993.090805,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006437025964260101,
      "ssim": 0.904447078704834,
      "attention_bam_384_mean_attention": 0.015399510972201824,
      "attention_bam_384_std_attention": 0.23906446993350983,
      "attention_bam_384_max_attention": 1.7035200595855713,
      "attention_bam_384_min_attention": -0.8020888566970825,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5397212120190593,
      "attention_bam_384_attention_skewness": 0.8663294580294034,
      "attention_bam_384_attention_sparsity": 0.6882985432942709,
      "attention_bam_384_attention_concentration_10": 3.2896010135637637,
      "attention_bam_384_attention_concentration_20": 4.882660270782378,
      "attention_bam_384_attention_center_y": 0.47936483086476805,
      "attention_bam_384_attention_center_x": 0.48801167807966933,
      "attention_bam_384_attention_center_distance": 0.03374996496902211,
      "attention_bam_384_attention_spatial_variance": 167.29931803034438,
      "attention_bam_384_attention_spatial_std": 12.934423761047277,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 19.24583919797614,
      "attention_bam_384_peak_intensity_mean": 0.3335261344909668,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.10978260636329651,
      "attention_bam_16_std_attention": 0.5717352628707886,
      "attention_bam_16_max_attention": 2.6261775493621826,
      "attention_bam_16_min_attention": -1.037125587463379,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.0227779908536405,
      "attention_bam_16_attention_skewness": 1.0243872570073478,
      "attention_bam_16_attention_sparsity": 0.5703125,
      "attention_bam_16_attention_concentration_10": 1.2151514797515577,
      "attention_bam_16_attention_concentration_20": 1.8509132003802633,
      "attention_bam_16_attention_center_y": 0.4559128472797576,
      "attention_bam_16_attention_center_x": 0.48083054018263227,
      "attention_bam_16_attention_center_distance": 0.06798742861246704,
      "attention_bam_16_attention_spatial_variance": 40.29817165282943,
      "attention_bam_16_attention_spatial_std": 6.348084093081111,
      "attention_bam_16_num_attention_peaks": 1,
      "attention_bam_16_peak_separation_mean": 0.0,
      "attention_bam_16_peak_intensity_mean": 0.3229137063026428,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 645,
      "phase": "train",
      "loss": 0.0034530735574662685,
      "timestamp": 1759543993.258579,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0034530735574662685,
      "ssim": 0.9311099648475647,
      "attention_bam_384_mean_attention": 0.013952787034213543,
      "attention_bam_384_std_attention": 0.23547761142253876,
      "attention_bam_384_max_attention": 2.246163845062256,
      "attention_bam_384_min_attention": -0.8464311957359314,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 4.318587936043773,
      "attention_bam_384_attention_skewness": 1.3594891776415179,
      "attention_bam_384_attention_sparsity": 0.7146886189778646,
      "attention_bam_384_attention_concentration_10": 3.651625610916829,
      "attention_bam_384_attention_concentration_20": 5.231608573228483,
      "attention_bam_384_attention_center_y": 0.4788765168069473,
      "attention_bam_384_attention_center_x": 0.479810076286504,
      "attention_bam_384_attention_center_distance": 0.04132395338696351,
      "attention_bam_384_attention_spatial_variance": 170.65395540967077,
      "attention_bam_384_attention_spatial_std": 13.06345878432166,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 19.38176918462902,
      "attention_bam_384_peak_intensity_mean": 0.2882322669029236,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.10738181322813034,
      "attention_bam_16_std_attention": 0.5705993175506592,
      "attention_bam_16_max_attention": 3.5103988647460938,
      "attention_bam_16_min_attention": -0.9659894704818726,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.0611657072725045,
      "attention_bam_16_attention_skewness": 1.425895129917649,
      "attention_bam_16_attention_sparsity": 0.5927734375,
      "attention_bam_16_attention_concentration_10": 1.2598027981312658,
      "attention_bam_16_attention_concentration_20": 1.8820201264539713,
      "attention_bam_16_attention_center_y": 0.45028294430883276,
      "attention_bam_16_attention_center_x": 0.45773850698420765,
      "attention_bam_16_attention_center_distance": 0.09228021909946346,
      "attention_bam_16_attention_spatial_variance": 42.36517623228729,
      "attention_bam_16_attention_spatial_std": 6.508853680356265,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.508809770840216,
      "attention_bam_16_peak_intensity_mean": 0.24970796704292297,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 646,
      "phase": "train",
      "loss": 0.0038551781326532364,
      "timestamp": 1759543993.4385426,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0038551781326532364,
      "ssim": 0.9143103957176208,
      "attention_bam_384_mean_attention": 0.0159372016787529,
      "attention_bam_384_std_attention": 0.24766644835472107,
      "attention_bam_384_max_attention": 1.7959840297698975,
      "attention_bam_384_min_attention": -0.8660966753959656,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.011806475087421,
      "attention_bam_384_attention_skewness": 0.9321141245481729,
      "attention_bam_384_attention_sparsity": 0.6863581339518229,
      "attention_bam_384_attention_concentration_10": 3.290496036796047,
      "attention_bam_384_attention_concentration_20": 4.856749670602247,
      "attention_bam_384_attention_center_y": 0.4840205367114101,
      "attention_bam_384_attention_center_x": 0.48140873963145125,
      "attention_bam_384_attention_center_distance": 0.03466924311497335,
      "attention_bam_384_attention_spatial_variance": 171.01984878641827,
      "attention_bam_384_attention_spatial_std": 13.077455745917026,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 16.77231288732268,
      "attention_bam_384_peak_intensity_mean": 0.3336028456687927,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12022137641906738,
      "attention_bam_16_std_attention": 0.5935675501823425,
      "attention_bam_16_max_attention": 3.2602601051330566,
      "attention_bam_16_min_attention": -1.0342711210250854,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.323171814257389,
      "attention_bam_16_attention_skewness": 1.0434666154967862,
      "attention_bam_16_attention_sparsity": 0.5625,
      "attention_bam_16_attention_concentration_10": 1.1457478507238892,
      "attention_bam_16_attention_concentration_20": 1.7544072077701016,
      "attention_bam_16_attention_center_y": 0.46949165571745327,
      "attention_bam_16_attention_center_x": 0.4613816017366784,
      "attention_bam_16_attention_center_distance": 0.06960085854767771,
      "attention_bam_16_attention_spatial_variance": 42.774873053993446,
      "attention_bam_16_attention_spatial_std": 6.540250228698704,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.266625445020246,
      "attention_bam_16_peak_intensity_mean": 0.2756258547306061,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 647,
      "phase": "train",
      "loss": 0.004378320649266243,
      "timestamp": 1759543993.6215508,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004378320649266243,
      "ssim": 0.9303902983665466,
      "attention_bam_384_mean_attention": 0.018165498971939087,
      "attention_bam_384_std_attention": 0.2098454385995865,
      "attention_bam_384_max_attention": 2.0739552974700928,
      "attention_bam_384_min_attention": -0.8587286472320557,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.7719934006481317,
      "attention_bam_384_attention_skewness": 0.664042852946863,
      "attention_bam_384_attention_sparsity": 0.6900355021158854,
      "attention_bam_384_attention_concentration_10": 2.3510053324944296,
      "attention_bam_384_attention_concentration_20": 3.572303441044677,
      "attention_bam_384_attention_center_y": 0.48441186853163665,
      "attention_bam_384_attention_center_x": 0.48505283738872335,
      "attention_bam_384_attention_center_distance": 0.030542020653615127,
      "attention_bam_384_attention_spatial_variance": 173.69864558226803,
      "attention_bam_384_attention_spatial_std": 13.17947819840634,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 20.008518009002497,
      "attention_bam_384_peak_intensity_mean": 0.30272358655929565,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13870923221111298,
      "attention_bam_16_std_attention": 0.5257986187934875,
      "attention_bam_16_max_attention": 2.5320422649383545,
      "attention_bam_16_min_attention": -1.0530288219451904,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8369710657948848,
      "attention_bam_16_attention_skewness": 0.7488289052663112,
      "attention_bam_16_attention_sparsity": 0.5126953125,
      "attention_bam_16_attention_concentration_10": 0.8554854377281783,
      "attention_bam_16_attention_concentration_20": 1.3441557764669252,
      "attention_bam_16_attention_center_y": 0.469062996365465,
      "attention_bam_16_attention_center_x": 0.4729966181184016,
      "attention_bam_16_attention_center_distance": 0.05807376045903465,
      "attention_bam_16_attention_spatial_variance": 45.18678951659791,
      "attention_bam_16_attention_spatial_std": 6.72211198334258,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 10.57824986854628,
      "attention_bam_16_peak_intensity_mean": 0.34566354751586914,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 648,
      "phase": "train",
      "loss": 0.0061302571557462215,
      "timestamp": 1759543993.802481,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0061302571557462215,
      "ssim": 0.9026368260383606,
      "attention_bam_384_mean_attention": 0.02012758143246174,
      "attention_bam_384_std_attention": 0.19163738191127777,
      "attention_bam_384_max_attention": 1.4581265449523926,
      "attention_bam_384_min_attention": -0.7304823398590088,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8360263465136586,
      "attention_bam_384_attention_skewness": 0.4481927253740855,
      "attention_bam_384_attention_sparsity": 0.6852849324544271,
      "attention_bam_384_attention_concentration_10": 1.9083969399691563,
      "attention_bam_384_attention_concentration_20": 2.9691177095662376,
      "attention_bam_384_attention_center_y": 0.47835766002744307,
      "attention_bam_384_attention_center_x": 0.4795169232634025,
      "attention_bam_384_attention_center_distance": 0.04214136476397216,
      "attention_bam_384_attention_spatial_variance": 170.55596763900698,
      "attention_bam_384_attention_spatial_std": 13.05970779301769,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 17.996547643736395,
      "attention_bam_384_peak_intensity_mean": 0.35198473930358887,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.153133362531662,
      "attention_bam_16_std_attention": 0.4879024624824524,
      "attention_bam_16_max_attention": 2.217456340789795,
      "attention_bam_16_min_attention": -1.042633056640625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.28137374374157265,
      "attention_bam_16_attention_skewness": 0.5350426438024617,
      "attention_bam_16_attention_sparsity": 0.4892578125,
      "attention_bam_16_attention_concentration_10": 0.7228112082803967,
      "attention_bam_16_attention_concentration_20": 1.1567554501759119,
      "attention_bam_16_attention_center_y": 0.4530122149642536,
      "attention_bam_16_attention_center_x": 0.45306540794817907,
      "attention_bam_16_attention_center_distance": 0.09392239215050228,
      "attention_bam_16_attention_spatial_variance": 42.3626940691762,
      "attention_bam_16_attention_spatial_std": 6.50866300165988,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.970931103152699,
      "attention_bam_16_peak_intensity_mean": 0.37834611535072327,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 649,
      "phase": "train",
      "loss": 0.007739218883216381,
      "timestamp": 1759543993.982226,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007739218883216381,
      "ssim": 0.8442357182502747,
      "attention_bam_384_mean_attention": 0.019050607457756996,
      "attention_bam_384_std_attention": 0.2448834329843521,
      "attention_bam_384_max_attention": 2.35620379447937,
      "attention_bam_384_min_attention": -0.9143893718719482,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.9247855178318485,
      "attention_bam_384_attention_skewness": 0.784557428742844,
      "attention_bam_384_attention_sparsity": 0.6762619018554688,
      "attention_bam_384_attention_concentration_10": 2.666695173080038,
      "attention_bam_384_attention_concentration_20": 3.9958572701901964,
      "attention_bam_384_attention_center_y": 0.48169930890062057,
      "attention_bam_384_attention_center_x": 0.487657161672923,
      "attention_bam_384_attention_center_distance": 0.031217333412169156,
      "attention_bam_384_attention_spatial_variance": 170.84161184310128,
      "attention_bam_384_attention_spatial_std": 13.070639305064663,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 18.04507421937407,
      "attention_bam_384_peak_intensity_mean": 0.28954336047172546,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13419581949710846,
      "attention_bam_16_std_attention": 0.5830739736557007,
      "attention_bam_16_max_attention": 3.226583480834961,
      "attention_bam_16_min_attention": -1.0101032257080078,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.1779309713190234,
      "attention_bam_16_attention_skewness": 0.8699417680754578,
      "attention_bam_16_attention_sparsity": 0.53515625,
      "attention_bam_16_attention_concentration_10": 0.9840674752525609,
      "attention_bam_16_attention_concentration_20": 1.5249978096998194,
      "attention_bam_16_attention_center_y": 0.4581877726585519,
      "attention_bam_16_attention_center_x": 0.4790955302555553,
      "attention_bam_16_attention_center_distance": 0.06610989654430487,
      "attention_bam_16_attention_spatial_variance": 42.67254826176947,
      "attention_bam_16_attention_spatial_std": 6.5324228477471875,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 7.988557034645722,
      "attention_bam_16_peak_intensity_mean": 0.27972692251205444,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 650,
      "phase": "train",
      "loss": 0.006674581672996283,
      "timestamp": 1759543994.1967769,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006674581672996283,
      "ssim": 0.9156516194343567,
      "attention_bam_384_mean_attention": 0.01988641358911991,
      "attention_bam_384_std_attention": 0.20057283341884613,
      "attention_bam_384_max_attention": 2.466102123260498,
      "attention_bam_384_min_attention": -0.9255231022834778,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 5.803574697331497,
      "attention_bam_384_attention_skewness": 1.1863260505277364,
      "attention_bam_384_attention_sparsity": 0.7103703816731771,
      "attention_bam_384_attention_concentration_10": 2.085644305166567,
      "attention_bam_384_attention_concentration_20": 3.093929653803759,
      "attention_bam_384_attention_center_y": 0.485065205411292,
      "attention_bam_384_attention_center_x": 0.48234511197859375,
      "attention_bam_384_attention_center_distance": 0.0327030017110141,
      "attention_bam_384_attention_spatial_variance": 171.76849239325276,
      "attention_bam_384_attention_spatial_std": 13.106047931899713,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 19.4322406957024,
      "attention_bam_384_peak_intensity_mean": 0.28231000900268555,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.15000569820404053,
      "attention_bam_16_std_attention": 0.5122287273406982,
      "attention_bam_16_max_attention": 3.5051872730255127,
      "attention_bam_16_min_attention": -0.9905455112457275,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.2034568225723516,
      "attention_bam_16_attention_skewness": 1.1184497000686437,
      "attention_bam_16_attention_sparsity": 0.511474609375,
      "attention_bam_16_attention_concentration_10": 0.7813847758704111,
      "attention_bam_16_attention_concentration_20": 1.2210241039775398,
      "attention_bam_16_attention_center_y": 0.4730731507063349,
      "attention_bam_16_attention_center_x": 0.46269479687807974,
      "attention_bam_16_attention_center_distance": 0.06506509652419618,
      "attention_bam_16_attention_spatial_variance": 43.54926086409727,
      "attention_bam_16_attention_spatial_std": 6.599186378948337,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.687696468523713,
      "attention_bam_16_peak_intensity_mean": 0.26048603653907776,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 651,
      "phase": "train",
      "loss": 0.004788173362612724,
      "timestamp": 1759543994.363453,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004788173362612724,
      "ssim": 0.9264184236526489,
      "attention_bam_384_mean_attention": 0.018234392628073692,
      "attention_bam_384_std_attention": 0.22902889549732208,
      "attention_bam_384_max_attention": 1.7915375232696533,
      "attention_bam_384_min_attention": -0.9942153096199036,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5808302746811442,
      "attention_bam_384_attention_skewness": 0.6941259168802599,
      "attention_bam_384_attention_sparsity": 0.6818033854166666,
      "attention_bam_384_attention_concentration_10": 2.5908856366227284,
      "attention_bam_384_attention_concentration_20": 3.9046669862321433,
      "attention_bam_384_attention_center_y": 0.4847874913133724,
      "attention_bam_384_attention_center_x": 0.4773874600551567,
      "attention_bam_384_attention_center_distance": 0.03854211678924379,
      "attention_bam_384_attention_spatial_variance": 171.44371720670273,
      "attention_bam_384_attention_spatial_std": 13.0936517903411,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 18.00043901391548,
      "attention_bam_384_peak_intensity_mean": 0.3656889796257019,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12828460335731506,
      "attention_bam_16_std_attention": 0.5581070184707642,
      "attention_bam_16_max_attention": 2.832137107849121,
      "attention_bam_16_min_attention": -1.119065284729004,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5866432553841001,
      "attention_bam_16_attention_skewness": 0.7333175090937063,
      "attention_bam_16_attention_sparsity": 0.534423828125,
      "attention_bam_16_attention_concentration_10": 0.9652195588775533,
      "attention_bam_16_attention_concentration_20": 1.5312801645049974,
      "attention_bam_16_attention_center_y": 0.46955162933341393,
      "attention_bam_16_attention_center_x": 0.44809750743104215,
      "attention_bam_16_attention_center_distance": 0.08509961235070983,
      "attention_bam_16_attention_spatial_variance": 43.19543596453939,
      "attention_bam_16_attention_spatial_std": 6.572323482950257,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.787038415774417,
      "attention_bam_16_peak_intensity_mean": 0.3244435489177704,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 652,
      "phase": "train",
      "loss": 0.008605124428868294,
      "timestamp": 1759543994.5208256,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008605124428868294,
      "ssim": 0.8966678380966187,
      "attention_bam_384_mean_attention": 0.01905481331050396,
      "attention_bam_384_std_attention": 0.18605825304985046,
      "attention_bam_384_max_attention": 1.4746959209442139,
      "attention_bam_384_min_attention": -0.797173261642456,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.2443963152841775,
      "attention_bam_384_attention_skewness": 0.792196813516169,
      "attention_bam_384_attention_sparsity": 0.7253875732421875,
      "attention_bam_384_attention_concentration_10": 2.0767419300196033,
      "attention_bam_384_attention_concentration_20": 3.076975752689188,
      "attention_bam_384_attention_center_y": 0.49165191111649487,
      "attention_bam_384_attention_center_x": 0.47838304802035647,
      "attention_bam_384_attention_center_distance": 0.032771426606027276,
      "attention_bam_384_attention_spatial_variance": 171.78066831750687,
      "attention_bam_384_attention_spatial_std": 13.106512439146687,
      "attention_bam_384_num_attention_peaks": 4,
      "attention_bam_384_peak_separation_mean": 18.86859128677351,
      "attention_bam_384_peak_intensity_mean": 0.36491918563842773,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13494600355625153,
      "attention_bam_16_std_attention": 0.47340768575668335,
      "attention_bam_16_max_attention": 1.9853485822677612,
      "attention_bam_16_min_attention": -0.9240787625312805,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5853876778821414,
      "attention_bam_16_attention_skewness": 0.7474334836479491,
      "attention_bam_16_attention_sparsity": 0.521484375,
      "attention_bam_16_attention_concentration_10": 0.8230225175818653,
      "attention_bam_16_attention_concentration_20": 1.2797287521633636,
      "attention_bam_16_attention_center_y": 0.49815067448282496,
      "attention_bam_16_attention_center_x": 0.45288866127179445,
      "attention_bam_16_attention_center_distance": 0.06667680618674225,
      "attention_bam_16_attention_spatial_variance": 43.316027091818256,
      "attention_bam_16_attention_spatial_std": 6.58149125136684,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.53177103736872,
      "attention_bam_16_peak_intensity_mean": 0.3844850957393646,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 653,
      "phase": "train",
      "loss": 0.005145469214767218,
      "timestamp": 1759543994.6711242,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005145469214767218,
      "ssim": 0.9170013070106506,
      "attention_bam_384_mean_attention": 0.015463209711015224,
      "attention_bam_384_std_attention": 0.2539602518081665,
      "attention_bam_384_max_attention": 2.1707897186279297,
      "attention_bam_384_min_attention": -0.9007125496864319,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.325275501828668,
      "attention_bam_384_attention_skewness": 1.0217142522355065,
      "attention_bam_384_attention_sparsity": 0.6874364217122396,
      "attention_bam_384_attention_concentration_10": 3.4982212981450536,
      "attention_bam_384_attention_concentration_20": 5.139516251228938,
      "attention_bam_384_attention_center_y": 0.47949746986771613,
      "attention_bam_384_attention_center_x": 0.4816010717295008,
      "attention_bam_384_attention_center_distance": 0.038958293169187565,
      "attention_bam_384_attention_spatial_variance": 172.34865163975647,
      "attention_bam_384_attention_spatial_std": 13.128162538594518,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 21.357306108069498,
      "attention_bam_384_peak_intensity_mean": 0.3055703938007355,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.11021371185779572,
      "attention_bam_16_std_attention": 0.6126851439476013,
      "attention_bam_16_max_attention": 2.8901023864746094,
      "attention_bam_16_min_attention": -1.1040116548538208,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.2682446311057198,
      "attention_bam_16_attention_skewness": 1.1284511739484504,
      "attention_bam_16_attention_sparsity": 0.588623046875,
      "attention_bam_16_attention_concentration_10": 1.3130808211417744,
      "attention_bam_16_attention_concentration_20": 1.9848070329698968,
      "attention_bam_16_attention_center_y": 0.4532741158481948,
      "attention_bam_16_attention_center_x": 0.45958053079021116,
      "attention_bam_16_attention_center_distance": 0.0873732423682329,
      "attention_bam_16_attention_spatial_variance": 43.9604893952254,
      "attention_bam_16_attention_spatial_std": 6.630270687930124,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 10.062132730200645,
      "attention_bam_16_peak_intensity_mean": 0.3152449131011963,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 654,
      "phase": "train",
      "loss": 0.00863906554877758,
      "timestamp": 1759543994.810592,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00863906554877758,
      "ssim": 0.9031054377555847,
      "attention_bam_384_mean_attention": 0.017174599692225456,
      "attention_bam_384_std_attention": 0.2394404411315918,
      "attention_bam_384_max_attention": 2.213819980621338,
      "attention_bam_384_min_attention": -0.818860650062561,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 4.724915064156805,
      "attention_bam_384_attention_skewness": 1.4605939133691135,
      "attention_bam_384_attention_sparsity": 0.7162933349609375,
      "attention_bam_384_attention_concentration_10": 3.075117632262065,
      "attention_bam_384_attention_concentration_20": 4.360230424609188,
      "attention_bam_384_attention_center_y": 0.4851959269517155,
      "attention_bam_384_attention_center_x": 0.4785435269973462,
      "attention_bam_384_attention_center_distance": 0.036865724257975865,
      "attention_bam_384_attention_spatial_variance": 169.30992842038677,
      "attention_bam_384_attention_spatial_std": 13.01191486370806,
      "attention_bam_384_num_attention_peaks": 4,
      "attention_bam_384_peak_separation_mean": 16.75053320552654,
      "attention_bam_384_peak_intensity_mean": 0.2797134220600128,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12281672656536102,
      "attention_bam_16_std_attention": 0.5950215458869934,
      "attention_bam_16_max_attention": 3.0649096965789795,
      "attention_bam_16_min_attention": -1.025658369064331,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.2296081406795967,
      "attention_bam_16_attention_skewness": 1.34387126945649,
      "attention_bam_16_attention_sparsity": 0.588134765625,
      "attention_bam_16_attention_concentration_10": 1.1769906447049858,
      "attention_bam_16_attention_concentration_20": 1.7399448756043736,
      "attention_bam_16_attention_center_y": 0.47061009942799803,
      "attention_bam_16_attention_center_x": 0.45396585580251786,
      "attention_bam_16_attention_center_distance": 0.07723870386829054,
      "attention_bam_16_attention_spatial_variance": 41.51642675925555,
      "attention_bam_16_attention_spatial_std": 6.443324201004909,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.3641117399153,
      "attention_bam_16_peak_intensity_mean": 0.2971925437450409,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 655,
      "phase": "train",
      "loss": 0.00479161599650979,
      "timestamp": 1759543994.9520621,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00479161599650979,
      "ssim": 0.9208251237869263,
      "attention_bam_384_mean_attention": 0.017500482499599457,
      "attention_bam_384_std_attention": 0.21440644562244415,
      "attention_bam_384_max_attention": 1.5428428649902344,
      "attention_bam_384_min_attention": -0.8495261669158936,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5415669854790472,
      "attention_bam_384_attention_skewness": 0.7277214730471788,
      "attention_bam_384_attention_sparsity": 0.6930287679036459,
      "attention_bam_384_attention_concentration_10": 2.544349954761882,
      "attention_bam_384_attention_concentration_20": 3.8263974597712833,
      "attention_bam_384_attention_center_y": 0.4758851992549583,
      "attention_bam_384_attention_center_x": 0.4791252992069402,
      "attention_bam_384_attention_center_distance": 0.04510602505592429,
      "attention_bam_384_attention_spatial_variance": 170.9629312531485,
      "attention_bam_384_attention_spatial_std": 13.075279394840804,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 17.365942147477753,
      "attention_bam_384_peak_intensity_mean": 0.3715883195400238,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12613996863365173,
      "attention_bam_16_std_attention": 0.5331101417541504,
      "attention_bam_16_max_attention": 2.372291326522827,
      "attention_bam_16_min_attention": -1.1179778575897217,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.330449715597521,
      "attention_bam_16_attention_skewness": 0.7022594719341432,
      "attention_bam_16_attention_sparsity": 0.535400390625,
      "attention_bam_16_attention_concentration_10": 0.9401777413224354,
      "attention_bam_16_attention_concentration_20": 1.4982490481227682,
      "attention_bam_16_attention_center_y": 0.447050997389188,
      "attention_bam_16_attention_center_x": 0.455953719662073,
      "attention_bam_16_attention_center_distance": 0.09740299470844857,
      "attention_bam_16_attention_spatial_variance": 42.26582449227171,
      "attention_bam_16_attention_spatial_std": 6.5012171546774,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.478337804155823,
      "attention_bam_16_peak_intensity_mean": 0.37603312730789185,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 656,
      "phase": "train",
      "loss": 0.01046934723854065,
      "timestamp": 1759543995.0925975,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.01046934723854065,
      "ssim": 0.8972196578979492,
      "attention_bam_384_mean_attention": 0.014178809709846973,
      "attention_bam_384_std_attention": 0.24321210384368896,
      "attention_bam_384_max_attention": 2.563194990158081,
      "attention_bam_384_min_attention": -0.9205471277236938,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.291704783115181,
      "attention_bam_384_attention_skewness": 1.0947491023802807,
      "attention_bam_384_attention_sparsity": 0.6851476033528646,
      "attention_bam_384_attention_concentration_10": 3.5607915233448413,
      "attention_bam_384_attention_concentration_20": 5.287350833556956,
      "attention_bam_384_attention_center_y": 0.48590591473085415,
      "attention_bam_384_attention_center_x": 0.4881959997957703,
      "attention_bam_384_attention_center_distance": 0.02599914077024121,
      "attention_bam_384_attention_spatial_variance": 170.8114254974581,
      "attention_bam_384_attention_spatial_std": 13.069484515368542,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 17.204438857977078,
      "attention_bam_384_peak_intensity_mean": 0.2729251980781555,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1064327135682106,
      "attention_bam_16_std_attention": 0.5901629328727722,
      "attention_bam_16_max_attention": 3.5195186138153076,
      "attention_bam_16_min_attention": -1.0109708309173584,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.6554943241738025,
      "attention_bam_16_attention_skewness": 1.2506970527056755,
      "attention_bam_16_attention_sparsity": 0.56396484375,
      "attention_bam_16_attention_concentration_10": 1.2628383432948054,
      "attention_bam_16_attention_concentration_20": 1.917748051307493,
      "attention_bam_16_attention_center_y": 0.47985168601446077,
      "attention_bam_16_attention_center_x": 0.4877981416836161,
      "attention_bam_16_attention_center_distance": 0.03331185683305517,
      "attention_bam_16_attention_spatial_variance": 42.81626012044062,
      "attention_bam_16_attention_spatial_std": 6.543413491476801,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 8.635170692679532,
      "attention_bam_16_peak_intensity_mean": 0.25302016735076904,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 657,
      "phase": "train",
      "loss": 0.004905460402369499,
      "timestamp": 1759543995.234727,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004905460402369499,
      "ssim": 0.9165377616882324,
      "attention_bam_384_mean_attention": 0.01572774536907673,
      "attention_bam_384_std_attention": 0.2384548932313919,
      "attention_bam_384_max_attention": 2.403372287750244,
      "attention_bam_384_min_attention": -0.8136547803878784,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.577904146200872,
      "attention_bam_384_attention_skewness": 1.0317385915516177,
      "attention_bam_384_attention_sparsity": 0.6836217244466146,
      "attention_bam_384_attention_concentration_10": 3.184063861526507,
      "attention_bam_384_attention_concentration_20": 4.751298018341628,
      "attention_bam_384_attention_center_y": 0.47477953357741814,
      "attention_bam_384_attention_center_x": 0.483341027422815,
      "attention_bam_384_attention_center_distance": 0.04274560313997174,
      "attention_bam_384_attention_spatial_variance": 172.42781017657774,
      "attention_bam_384_attention_spatial_std": 13.131177029367084,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 19.249147244052214,
      "attention_bam_384_peak_intensity_mean": 0.2637098431587219,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.11426861584186554,
      "attention_bam_16_std_attention": 0.5831542611122131,
      "attention_bam_16_max_attention": 3.4244601726531982,
      "attention_bam_16_min_attention": -0.9961951971054077,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.7847431938550464,
      "attention_bam_16_attention_skewness": 1.0812470424265088,
      "attention_bam_16_attention_sparsity": 0.557373046875,
      "attention_bam_16_attention_concentration_10": 1.161252025648739,
      "attention_bam_16_attention_concentration_20": 1.794148924964246,
      "attention_bam_16_attention_center_y": 0.44322665667795785,
      "attention_bam_16_attention_center_x": 0.4688030285772715,
      "attention_bam_16_attention_center_distance": 0.091612919808431,
      "attention_bam_16_attention_spatial_variance": 43.720866023082195,
      "attention_bam_16_attention_spatial_std": 6.6121755892506515,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.551672058901854,
      "attention_bam_16_peak_intensity_mean": 0.26442641019821167,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 658,
      "phase": "train",
      "loss": 0.00659693218767643,
      "timestamp": 1759543995.371952,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00659693218767643,
      "ssim": 0.8919872045516968,
      "attention_bam_384_mean_attention": 0.014737366698682308,
      "attention_bam_384_std_attention": 0.25300267338752747,
      "attention_bam_384_max_attention": 2.01397967338562,
      "attention_bam_384_min_attention": -1.0483708381652832,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.075003526957752,
      "attention_bam_384_attention_skewness": 1.1737971434576646,
      "attention_bam_384_attention_sparsity": 0.6933720906575521,
      "attention_bam_384_attention_concentration_10": 3.701869255337456,
      "attention_bam_384_attention_concentration_20": 5.347424670925745,
      "attention_bam_384_attention_center_y": 0.48574387184799445,
      "attention_bam_384_attention_center_x": 0.4856783715619081,
      "attention_bam_384_attention_center_distance": 0.028577831653404658,
      "attention_bam_384_attention_spatial_variance": 170.9867196271539,
      "attention_bam_384_attention_spatial_std": 13.076189033015464,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 18.08247037347293,
      "attention_bam_384_peak_intensity_mean": 0.35604265332221985,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.11020433902740479,
      "attention_bam_16_std_attention": 0.6102461814880371,
      "attention_bam_16_max_attention": 3.1852474212646484,
      "attention_bam_16_min_attention": -1.0688858032226562,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.7375764283917512,
      "attention_bam_16_attention_skewness": 1.182939868936628,
      "attention_bam_16_attention_sparsity": 0.579345703125,
      "attention_bam_16_attention_concentration_10": 1.2880913851137257,
      "attention_bam_16_attention_concentration_20": 1.9521936295419915,
      "attention_bam_16_attention_center_y": 0.4747282504370795,
      "attention_bam_16_attention_center_x": 0.47525056026977625,
      "attention_bam_16_attention_center_distance": 0.05002391613880205,
      "attention_bam_16_attention_spatial_variance": 42.84948047693066,
      "attention_bam_16_attention_spatial_std": 6.545951456964118,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.742999179618371,
      "attention_bam_16_peak_intensity_mean": 0.29691535234451294,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 659,
      "phase": "train",
      "loss": 0.005843844264745712,
      "timestamp": 1759543995.560048,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005843844264745712,
      "ssim": 0.8869799375534058,
      "attention_bam_384_mean_attention": 0.014773099683225155,
      "attention_bam_384_std_attention": 0.21804463863372803,
      "attention_bam_384_max_attention": 2.0301501750946045,
      "attention_bam_384_min_attention": -0.8379794955253601,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.5149554204647746,
      "attention_bam_384_attention_skewness": 1.0863733893268301,
      "attention_bam_384_attention_sparsity": 0.7033716837565104,
      "attention_bam_384_attention_concentration_10": 3.0647231528304575,
      "attention_bam_384_attention_concentration_20": 4.528136515887855,
      "attention_bam_384_attention_center_y": 0.49245795301116213,
      "attention_bam_384_attention_center_x": 0.48266803894664945,
      "attention_bam_384_attention_center_distance": 0.026731230676371735,
      "attention_bam_384_attention_spatial_variance": 169.13788722989787,
      "attention_bam_384_attention_spatial_std": 13.005302273684293,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 17.279175653439538,
      "attention_bam_384_peak_intensity_mean": 0.2980523705482483,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12062787264585495,
      "attention_bam_16_std_attention": 0.548768162727356,
      "attention_bam_16_max_attention": 2.8730719089508057,
      "attention_bam_16_min_attention": -0.8940271735191345,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.7015062781461605,
      "attention_bam_16_attention_skewness": 1.2687649488770014,
      "attention_bam_16_attention_sparsity": 0.556884765625,
      "attention_bam_16_attention_concentration_10": 1.0580333443081484,
      "attention_bam_16_attention_concentration_20": 1.5944817665999165,
      "attention_bam_16_attention_center_y": 0.49712322856722624,
      "attention_bam_16_attention_center_x": 0.46420233104971365,
      "attention_bam_16_attention_center_distance": 0.05078875694778755,
      "attention_bam_16_attention_spatial_variance": 41.07497306962576,
      "attention_bam_16_attention_spatial_std": 6.4089759766772225,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 7.942113812377085,
      "attention_bam_16_peak_intensity_mean": 0.27803319692611694,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 660,
      "phase": "train",
      "loss": 0.006650158204138279,
      "timestamp": 1759543995.819904,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006650158204138279,
      "ssim": 0.8631182909011841,
      "attention_bam_384_mean_attention": 0.01790837198495865,
      "attention_bam_384_std_attention": 0.20203866064548492,
      "attention_bam_384_max_attention": 1.1698863506317139,
      "attention_bam_384_min_attention": -0.7565039992332458,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.063502215425709,
      "attention_bam_384_attention_skewness": 0.2843766104124781,
      "attention_bam_384_attention_sparsity": 0.6712290445963541,
      "attention_bam_384_attention_concentration_10": 2.1909815787621487,
      "attention_bam_384_attention_concentration_20": 3.4829900387740462,
      "attention_bam_384_attention_center_y": 0.4803126192267169,
      "attention_bam_384_attention_center_x": 0.4767770079855163,
      "attention_bam_384_attention_center_distance": 0.04305578520517329,
      "attention_bam_384_attention_spatial_variance": 170.50238336481112,
      "attention_bam_384_attention_spatial_std": 13.057656120637084,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 16.265557812555166,
      "attention_bam_384_peak_intensity_mean": 0.40812447667121887,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14432135224342346,
      "attention_bam_16_std_attention": 0.5134598612785339,
      "attention_bam_16_max_attention": 1.9033561944961548,
      "attention_bam_16_min_attention": -1.0395740270614624,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.3114390795659703,
      "attention_bam_16_attention_skewness": 0.3376934986958437,
      "attention_bam_16_attention_sparsity": 0.49267578125,
      "attention_bam_16_attention_concentration_10": 0.7671032897138056,
      "attention_bam_16_attention_concentration_20": 1.2536404356023942,
      "attention_bam_16_attention_center_y": 0.46099738902731857,
      "attention_bam_16_attention_center_x": 0.45184014726284016,
      "attention_bam_16_attention_center_distance": 0.08764217110901865,
      "attention_bam_16_attention_spatial_variance": 42.3438252705693,
      "attention_bam_16_attention_spatial_std": 6.507213326038213,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 7.903013021350027,
      "attention_bam_16_peak_intensity_mean": 0.4246886372566223,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 661,
      "phase": "train",
      "loss": 0.00424885842949152,
      "timestamp": 1759543996.028565,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00424885842949152,
      "ssim": 0.9285033941268921,
      "attention_bam_384_mean_attention": 0.015986740589141846,
      "attention_bam_384_std_attention": 0.2252967208623886,
      "attention_bam_384_max_attention": 1.5931730270385742,
      "attention_bam_384_min_attention": -0.7487173080444336,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2268174916568624,
      "attention_bam_384_attention_skewness": 0.6625044039799755,
      "attention_bam_384_attention_sparsity": 0.6810938517252604,
      "attention_bam_384_attention_concentration_10": 2.885785737450343,
      "attention_bam_384_attention_concentration_20": 4.365851332081109,
      "attention_bam_384_attention_center_y": 0.48487414563038195,
      "attention_bam_384_attention_center_x": 0.4848564051938759,
      "attention_bam_384_attention_center_distance": 0.030269454374433714,
      "attention_bam_384_attention_spatial_variance": 170.85073014911137,
      "attention_bam_384_attention_spatial_std": 13.070988109133577,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 17.10896229387851,
      "attention_bam_384_peak_intensity_mean": 0.33015090227127075,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13082760572433472,
      "attention_bam_16_std_attention": 0.5621551871299744,
      "attention_bam_16_max_attention": 2.429018259048462,
      "attention_bam_16_min_attention": -0.9907284379005432,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.42511288195674535,
      "attention_bam_16_attention_skewness": 0.7390527048753474,
      "attention_bam_16_attention_sparsity": 0.53271484375,
      "attention_bam_16_attention_concentration_10": 0.9766713911877526,
      "attention_bam_16_attention_concentration_20": 1.5227199313769226,
      "attention_bam_16_attention_center_y": 0.4767165307251746,
      "attention_bam_16_attention_center_x": 0.4748618617469746,
      "attention_bam_16_attention_center_distance": 0.04845711374607359,
      "attention_bam_16_attention_spatial_variance": 42.58184053197456,
      "attention_bam_16_attention_spatial_std": 6.525476268593317,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 8.67778311344591,
      "attention_bam_16_peak_intensity_mean": 0.3389589488506317,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 662,
      "phase": "train",
      "loss": 0.0067260051146149635,
      "timestamp": 1759543996.2120352,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0067260051146149635,
      "ssim": 0.902096152305603,
      "attention_bam_384_mean_attention": 0.017061827704310417,
      "attention_bam_384_std_attention": 0.19021724164485931,
      "attention_bam_384_max_attention": 1.5322941541671753,
      "attention_bam_384_min_attention": -0.7007138729095459,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.106914150806448,
      "attention_bam_384_attention_skewness": 0.5238288884085128,
      "attention_bam_384_attention_sparsity": 0.7103144327799479,
      "attention_bam_384_attention_concentration_10": 2.2689049686214338,
      "attention_bam_384_attention_concentration_20": 3.4696890443681214,
      "attention_bam_384_attention_center_y": 0.4854165332562816,
      "attention_bam_384_attention_center_x": 0.491545358554937,
      "attention_bam_384_attention_center_distance": 0.023839398659769848,
      "attention_bam_384_attention_spatial_variance": 169.89920399119228,
      "attention_bam_384_attention_spatial_std": 13.034538886788143,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 16.038911720335463,
      "attention_bam_384_peak_intensity_mean": 0.3248908519744873,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13529452681541443,
      "attention_bam_16_std_attention": 0.48661893606185913,
      "attention_bam_16_max_attention": 2.0147132873535156,
      "attention_bam_16_min_attention": -0.9299013018608093,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.3001565806973101,
      "attention_bam_16_attention_skewness": 0.5475632898540679,
      "attention_bam_16_attention_sparsity": 0.507080078125,
      "attention_bam_16_attention_concentration_10": 0.8073153453219728,
      "attention_bam_16_attention_concentration_20": 1.2763051378805144,
      "attention_bam_16_attention_center_y": 0.47271917955710996,
      "attention_bam_16_attention_center_x": 0.4917742461749294,
      "attention_bam_16_attention_center_distance": 0.040296555436609496,
      "attention_bam_16_attention_spatial_variance": 42.04086660998853,
      "attention_bam_16_attention_spatial_std": 6.483892859231137,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 7.2354067041645544,
      "attention_bam_16_peak_intensity_mean": 0.3769235908985138,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 663,
      "phase": "train",
      "loss": 0.006937102414667606,
      "timestamp": 1759543996.3906498,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006937102414667606,
      "ssim": 0.8708611726760864,
      "attention_bam_384_mean_attention": 0.015374928712844849,
      "attention_bam_384_std_attention": 0.2412634938955307,
      "attention_bam_384_max_attention": 2.6068813800811768,
      "attention_bam_384_min_attention": -1.1630316972732544,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 5.549605627811442,
      "attention_bam_384_attention_skewness": 1.303051361211658,
      "attention_bam_384_attention_sparsity": 0.7077789306640625,
      "attention_bam_384_attention_concentration_10": 3.3109722806371065,
      "attention_bam_384_attention_concentration_20": 4.720379261744053,
      "attention_bam_384_attention_center_y": 0.4897957076033019,
      "attention_bam_384_attention_center_x": 0.4791046752418748,
      "attention_bam_384_attention_center_distance": 0.03288592951597482,
      "attention_bam_384_attention_spatial_variance": 171.72261508734076,
      "attention_bam_384_attention_spatial_std": 13.104297580845024,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 19.208229259441904,
      "attention_bam_384_peak_intensity_mean": 0.31552499532699585,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13086123764514923,
      "attention_bam_16_std_attention": 0.5923550128936768,
      "attention_bam_16_max_attention": 3.9747536182403564,
      "attention_bam_16_min_attention": -1.162894606590271,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.718588022636987,
      "attention_bam_16_attention_skewness": 1.389091775984765,
      "attention_bam_16_attention_sparsity": 0.544921875,
      "attention_bam_16_attention_concentration_10": 1.068001875190236,
      "attention_bam_16_attention_concentration_20": 1.5749005146513568,
      "attention_bam_16_attention_center_y": 0.48862868089586203,
      "attention_bam_16_attention_center_x": 0.4497059427859741,
      "attention_bam_16_attention_center_distance": 0.07292186351452964,
      "attention_bam_16_attention_spatial_variance": 43.573583411562254,
      "attention_bam_16_attention_spatial_std": 6.601028966120529,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.435588528823008,
      "attention_bam_16_peak_intensity_mean": 0.2559870481491089,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 664,
      "phase": "train",
      "loss": 0.006590710487216711,
      "timestamp": 1759543996.7857344,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006590710487216711,
      "ssim": 0.930252194404602,
      "attention_bam_384_mean_attention": 0.017341798171401024,
      "attention_bam_384_std_attention": 0.22073495388031006,
      "attention_bam_384_max_attention": 1.242716670036316,
      "attention_bam_384_min_attention": -0.7743470668792725,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.4766310339278066,
      "attention_bam_384_attention_skewness": 0.5313531499692458,
      "attention_bam_384_attention_sparsity": 0.6828867594401041,
      "attention_bam_384_attention_concentration_10": 2.5945225868266624,
      "attention_bam_384_attention_concentration_20": 4.018963928216741,
      "attention_bam_384_attention_center_y": 0.4777314806214073,
      "attention_bam_384_attention_center_x": 0.4771198942969185,
      "attention_bam_384_attention_center_distance": 0.04515276718649572,
      "attention_bam_384_attention_spatial_variance": 168.79008715950746,
      "attention_bam_384_attention_spatial_std": 12.991923920632674,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 15.127416490411566,
      "attention_bam_384_peak_intensity_mean": 0.3995357155799866,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13996616005897522,
      "attention_bam_16_std_attention": 0.5460415482521057,
      "attention_bam_16_max_attention": 2.069979190826416,
      "attention_bam_16_min_attention": -0.9433610439300537,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.07946857451792688,
      "attention_bam_16_attention_skewness": 0.5886353024303925,
      "attention_bam_16_attention_sparsity": 0.521728515625,
      "attention_bam_16_attention_concentration_10": 0.8704608872228256,
      "attention_bam_16_attention_concentration_20": 1.4031348976702906,
      "attention_bam_16_attention_center_y": 0.44970428784998306,
      "attention_bam_16_attention_center_x": 0.450140857787775,
      "attention_bam_16_attention_center_distance": 0.10015580585084657,
      "attention_bam_16_attention_spatial_variance": 41.17092130249018,
      "attention_bam_16_attention_spatial_std": 6.416457067766461,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.946417527564098,
      "attention_bam_16_peak_intensity_mean": 0.3758944571018219,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 665,
      "phase": "train",
      "loss": 0.005563563667237759,
      "timestamp": 1759543996.925954,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005563563667237759,
      "ssim": 0.8967026472091675,
      "attention_bam_384_mean_attention": 0.016934078186750412,
      "attention_bam_384_std_attention": 0.1988036036491394,
      "attention_bam_384_max_attention": 1.5921132564544678,
      "attention_bam_384_min_attention": -0.7872973680496216,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4405129453762626,
      "attention_bam_384_attention_skewness": 0.8189918507129149,
      "attention_bam_384_attention_sparsity": 0.7068659464518229,
      "attention_bam_384_attention_concentration_10": 2.49316992933838,
      "attention_bam_384_attention_concentration_20": 3.748161507104266,
      "attention_bam_384_attention_center_y": 0.4717375121912036,
      "attention_bam_384_attention_center_x": 0.4740181566031441,
      "attention_bam_384_attention_center_distance": 0.05429225365447837,
      "attention_bam_384_attention_spatial_variance": 171.0019988643246,
      "attention_bam_384_attention_spatial_std": 13.07677325888633,
      "attention_bam_384_num_attention_peaks": 4,
      "attention_bam_384_peak_separation_mean": 9.668615369565247,
      "attention_bam_384_peak_intensity_mean": 0.3489203453063965,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12914249300956726,
      "attention_bam_16_std_attention": 0.5110094547271729,
      "attention_bam_16_max_attention": 2.112452507019043,
      "attention_bam_16_min_attention": -0.9262036681175232,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.1405944258837728,
      "attention_bam_16_attention_skewness": 0.7252421631396649,
      "attention_bam_16_attention_sparsity": 0.53955078125,
      "attention_bam_16_attention_concentration_10": 0.8987942915430495,
      "attention_bam_16_attention_concentration_20": 1.437055520899941,
      "attention_bam_16_attention_center_y": 0.4315571790168308,
      "attention_bam_16_attention_center_x": 0.43928707997094235,
      "attention_bam_16_attention_center_distance": 0.1293868494290582,
      "attention_bam_16_attention_spatial_variance": 42.13843012247793,
      "attention_bam_16_attention_spatial_std": 6.491412028401673,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 5.026737891422684,
      "attention_bam_16_peak_intensity_mean": 0.3782714605331421,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 666,
      "phase": "train",
      "loss": 0.013486395590007305,
      "timestamp": 1759543997.0719137,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.013486395590007305,
      "ssim": 0.8484799861907959,
      "attention_bam_384_mean_attention": 0.0148795610293746,
      "attention_bam_384_std_attention": 0.22253142297267914,
      "attention_bam_384_max_attention": 1.7287142276763916,
      "attention_bam_384_min_attention": -0.795842170715332,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5398660360202365,
      "attention_bam_384_attention_skewness": 0.8015811186970199,
      "attention_bam_384_attention_sparsity": 0.6995824178059896,
      "attention_bam_384_attention_concentration_10": 3.143482740183426,
      "attention_bam_384_attention_concentration_20": 4.711812164375234,
      "attention_bam_384_attention_center_y": 0.4768464459831666,
      "attention_bam_384_attention_center_x": 0.4858710944389528,
      "attention_bam_384_attention_center_distance": 0.038359171940056565,
      "attention_bam_384_attention_spatial_variance": 175.05412062766993,
      "attention_bam_384_attention_spatial_std": 13.230801964645602,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 24.8699815549216,
      "attention_bam_384_peak_intensity_mean": 0.3362591564655304,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.125216543674469,
      "attention_bam_16_std_attention": 0.5430185198783875,
      "attention_bam_16_max_attention": 2.3315138816833496,
      "attention_bam_16_min_attention": -0.9452841281890869,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6724656392918553,
      "attention_bam_16_attention_skewness": 0.8847545552439774,
      "attention_bam_16_attention_sparsity": 0.556396484375,
      "attention_bam_16_attention_concentration_10": 1.0036103170761843,
      "attention_bam_16_attention_concentration_20": 1.5675042900324379,
      "attention_bam_16_attention_center_y": 0.44832862831042347,
      "attention_bam_16_attention_center_x": 0.47359744452006275,
      "attention_bam_16_attention_center_distance": 0.08206126477399107,
      "attention_bam_16_attention_spatial_variance": 45.196378499151805,
      "attention_bam_16_attention_spatial_std": 6.722825187311641,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 13.616496178076474,
      "attention_bam_16_peak_intensity_mean": 0.36192208528518677,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 667,
      "phase": "train",
      "loss": 0.005195057950913906,
      "timestamp": 1759543997.2081115,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005195057950913906,
      "ssim": 0.9019833207130432,
      "attention_bam_384_mean_attention": 0.01789785362780094,
      "attention_bam_384_std_attention": 0.23082514107227325,
      "attention_bam_384_max_attention": 1.7996091842651367,
      "attention_bam_384_min_attention": -0.9143648147583008,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.307800092801937,
      "attention_bam_384_attention_skewness": 0.6831587171211508,
      "attention_bam_384_attention_sparsity": 0.6862716674804688,
      "attention_bam_384_attention_concentration_10": 2.684914498149829,
      "attention_bam_384_attention_concentration_20": 4.041428529398023,
      "attention_bam_384_attention_center_y": 0.48030011717361576,
      "attention_bam_384_attention_center_x": 0.482341153128495,
      "attention_bam_384_attention_center_distance": 0.03741444256445711,
      "attention_bam_384_attention_spatial_variance": 171.73005656048514,
      "attention_bam_384_attention_spatial_std": 13.104581510314823,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 17.893166338901587,
      "attention_bam_384_peak_intensity_mean": 0.34762582182884216,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14080190658569336,
      "attention_bam_16_std_attention": 0.5695295333862305,
      "attention_bam_16_max_attention": 2.447496175765991,
      "attention_bam_16_min_attention": -1.0882562398910522,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.3482380946168271,
      "attention_bam_16_attention_skewness": 0.7124423108456197,
      "attention_bam_16_attention_sparsity": 0.52978515625,
      "attention_bam_16_attention_concentration_10": 0.9152399985617661,
      "attention_bam_16_attention_concentration_20": 1.4477476903261872,
      "attention_bam_16_attention_center_y": 0.4583416340224423,
      "attention_bam_16_attention_center_x": 0.4648037063047943,
      "attention_bam_16_attention_center_distance": 0.07712585229090584,
      "attention_bam_16_attention_spatial_variance": 43.627541426532915,
      "attention_bam_16_attention_spatial_std": 6.6051147928353915,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.026031269390806,
      "attention_bam_16_peak_intensity_mean": 0.35923853516578674,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 668,
      "phase": "train",
      "loss": 0.0055603450164198875,
      "timestamp": 1759543997.3741758,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0055603450164198875,
      "ssim": 0.9176080226898193,
      "attention_bam_384_mean_attention": 0.018628276884555817,
      "attention_bam_384_std_attention": 0.16681475937366486,
      "attention_bam_384_max_attention": 1.34730064868927,
      "attention_bam_384_min_attention": -0.6522195339202881,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5038365810438723,
      "attention_bam_384_attention_skewness": 0.4819331928403856,
      "attention_bam_384_attention_sparsity": 0.7323582967122396,
      "attention_bam_384_attention_concentration_10": 1.8373095436622127,
      "attention_bam_384_attention_concentration_20": 2.7822692042808486,
      "attention_bam_384_attention_center_y": 0.4909126899081309,
      "attention_bam_384_attention_center_x": 0.4796744554336839,
      "attention_bam_384_attention_center_distance": 0.03148672630246233,
      "attention_bam_384_attention_spatial_variance": 172.0598256757404,
      "attention_bam_384_attention_spatial_std": 13.117157682811486,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 18.7920250425091,
      "attention_bam_384_peak_intensity_mean": 0.3399714529514313,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.15860110521316528,
      "attention_bam_16_std_attention": 0.4333987236022949,
      "attention_bam_16_max_attention": 2.0090079307556152,
      "attention_bam_16_min_attention": -0.9544022083282471,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5755249682398205,
      "attention_bam_16_attention_skewness": 0.5085256727112908,
      "attention_bam_16_attention_sparsity": 0.472900390625,
      "attention_bam_16_attention_concentration_10": 0.6337347818391408,
      "attention_bam_16_attention_concentration_20": 1.0101832660782495,
      "attention_bam_16_attention_center_y": 0.4855147625571562,
      "attention_bam_16_attention_center_x": 0.45814014175839485,
      "attention_bam_16_attention_center_distance": 0.06264295388601726,
      "attention_bam_16_attention_spatial_variance": 43.4558004000973,
      "attention_bam_16_attention_spatial_std": 6.592101364519307,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 7.779232807030746,
      "attention_bam_16_peak_intensity_mean": 0.3868960440158844,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 669,
      "phase": "train",
      "loss": 0.005503316875547171,
      "timestamp": 1759543997.5661836,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005503316875547171,
      "ssim": 0.8959907293319702,
      "attention_bam_384_mean_attention": 0.017011890187859535,
      "attention_bam_384_std_attention": 0.21875742077827454,
      "attention_bam_384_max_attention": 1.4795111417770386,
      "attention_bam_384_min_attention": -0.866826057434082,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7521623634955033,
      "attention_bam_384_attention_skewness": 0.47759563857676224,
      "attention_bam_384_attention_sparsity": 0.6822967529296875,
      "attention_bam_384_attention_concentration_10": 2.58949922129772,
      "attention_bam_384_attention_concentration_20": 3.989796335469106,
      "attention_bam_384_attention_center_y": 0.4865992529068437,
      "attention_bam_384_attention_center_x": 0.4795337343057172,
      "attention_bam_384_attention_center_distance": 0.03459618632519236,
      "attention_bam_384_attention_spatial_variance": 170.28432686535217,
      "attention_bam_384_attention_spatial_std": 13.049303692739784,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 16.631785840106406,
      "attention_bam_384_peak_intensity_mean": 0.37917137145996094,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14350786805152893,
      "attention_bam_16_std_attention": 0.5472055077552795,
      "attention_bam_16_max_attention": 2.4497268199920654,
      "attention_bam_16_min_attention": -1.0621352195739746,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.050836149272580844,
      "attention_bam_16_attention_skewness": 0.5310388331277452,
      "attention_bam_16_attention_sparsity": 0.510986328125,
      "attention_bam_16_attention_concentration_10": 0.8379402220891333,
      "attention_bam_16_attention_concentration_20": 1.352833505503611,
      "attention_bam_16_attention_center_y": 0.472825336680436,
      "attention_bam_16_attention_center_x": 0.4570865103235317,
      "attention_bam_16_attention_center_distance": 0.0718335565421065,
      "attention_bam_16_attention_spatial_variance": 42.374542748996,
      "attention_bam_16_attention_spatial_std": 6.509573161812993,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 8.155880763424877,
      "attention_bam_16_peak_intensity_mean": 0.34365150332450867,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 670,
      "phase": "train",
      "loss": 0.004754239227622747,
      "timestamp": 1759543997.827872,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004754239227622747,
      "ssim": 0.915036678314209,
      "attention_bam_384_mean_attention": 0.016119396314024925,
      "attention_bam_384_std_attention": 0.22829435765743256,
      "attention_bam_384_max_attention": 1.931799292564392,
      "attention_bam_384_min_attention": -0.8354679942131042,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.539048033729455,
      "attention_bam_384_attention_skewness": 0.7036333697429855,
      "attention_bam_384_attention_sparsity": 0.6938120524088541,
      "attention_bam_384_attention_concentration_10": 2.93707043157518,
      "attention_bam_384_attention_concentration_20": 4.400209474541038,
      "attention_bam_384_attention_center_y": 0.48732801685534843,
      "attention_bam_384_attention_center_x": 0.4845000066500624,
      "attention_bam_384_attention_center_distance": 0.028313563910834113,
      "attention_bam_384_attention_spatial_variance": 170.71355344954299,
      "attention_bam_384_attention_spatial_std": 13.065739682449784,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 17.85450425912751,
      "attention_bam_384_peak_intensity_mean": 0.3115759789943695,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1340002715587616,
      "attention_bam_16_std_attention": 0.5769294500350952,
      "attention_bam_16_max_attention": 2.829352378845215,
      "attention_bam_16_min_attention": -1.031899094581604,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6143749183638207,
      "attention_bam_16_attention_skewness": 0.8069804558931265,
      "attention_bam_16_attention_sparsity": 0.53759765625,
      "attention_bam_16_attention_concentration_10": 0.9805646994696915,
      "attention_bam_16_attention_concentration_20": 1.5422612755131622,
      "attention_bam_16_attention_center_y": 0.4761535147830927,
      "attention_bam_16_attention_center_x": 0.4706740881771455,
      "attention_bam_16_attention_center_distance": 0.05345397948594688,
      "attention_bam_16_attention_spatial_variance": 42.8232256599527,
      "attention_bam_16_attention_spatial_std": 6.543945725627062,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.747355982731642,
      "attention_bam_16_peak_intensity_mean": 0.31435757875442505,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 671,
      "phase": "train",
      "loss": 0.006567013915628195,
      "timestamp": 1759543997.9987814,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006567013915628195,
      "ssim": 0.9119417667388916,
      "attention_bam_384_mean_attention": 0.016706062480807304,
      "attention_bam_384_std_attention": 0.19920620322227478,
      "attention_bam_384_max_attention": 1.3731337785720825,
      "attention_bam_384_min_attention": -0.7979093790054321,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9262717225090502,
      "attention_bam_384_attention_skewness": 0.4250513397664228,
      "attention_bam_384_attention_sparsity": 0.6935704549153646,
      "attention_bam_384_attention_concentration_10": 2.3865623646691088,
      "attention_bam_384_attention_concentration_20": 3.660187112669511,
      "attention_bam_384_attention_center_y": 0.48288904283262407,
      "attention_bam_384_attention_center_x": 0.4804534005346084,
      "attention_bam_384_attention_center_distance": 0.03673838335703467,
      "attention_bam_384_attention_spatial_variance": 169.3666696048572,
      "attention_bam_384_attention_spatial_std": 13.014095035954563,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 16.07348606766576,
      "attention_bam_384_peak_intensity_mean": 0.37584778666496277,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.139539435505867,
      "attention_bam_16_std_attention": 0.5111817717552185,
      "attention_bam_16_max_attention": 2.0759520530700684,
      "attention_bam_16_min_attention": -1.0856447219848633,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.32149440160375864,
      "attention_bam_16_attention_skewness": 0.5790858154386805,
      "attention_bam_16_attention_sparsity": 0.512451171875,
      "attention_bam_16_attention_concentration_10": 0.825275329258879,
      "attention_bam_16_attention_concentration_20": 1.3069496780802081,
      "attention_bam_16_attention_center_y": 0.465348752452034,
      "attention_bam_16_attention_center_x": 0.46426833043705185,
      "attention_bam_16_attention_center_distance": 0.07039120920095257,
      "attention_bam_16_attention_spatial_variance": 41.78581995445128,
      "attention_bam_16_attention_spatial_std": 6.4641952286770605,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.030228326639714,
      "attention_bam_16_peak_intensity_mean": 0.3922952115535736,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 672,
      "phase": "train",
      "loss": 0.004321408458054066,
      "timestamp": 1759543998.15988,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004321408458054066,
      "ssim": 0.9205312728881836,
      "attention_bam_384_mean_attention": 0.014687386341392994,
      "attention_bam_384_std_attention": 0.19635288417339325,
      "attention_bam_384_max_attention": 1.3834006786346436,
      "attention_bam_384_min_attention": -0.6920026540756226,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8303420608133267,
      "attention_bam_384_attention_skewness": 0.5022368311937108,
      "attention_bam_384_attention_sparsity": 0.6967798868815104,
      "attention_bam_384_attention_concentration_10": 2.6931344895718836,
      "attention_bam_384_attention_concentration_20": 4.094394533029611,
      "attention_bam_384_attention_center_y": 0.4886245092115192,
      "attention_bam_384_attention_center_x": 0.4873704178096205,
      "attention_bam_384_attention_center_distance": 0.024037809258847343,
      "attention_bam_384_attention_spatial_variance": 169.57177716864425,
      "attention_bam_384_attention_spatial_std": 13.02197286007939,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 15.77449695989962,
      "attention_bam_384_peak_intensity_mean": 0.34737148880958557,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1262551099061966,
      "attention_bam_16_std_attention": 0.505955159664154,
      "attention_bam_16_max_attention": 2.036947727203369,
      "attention_bam_16_min_attention": -0.9263595938682556,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.1341891454128783,
      "attention_bam_16_attention_skewness": 0.5979510777506409,
      "attention_bam_16_attention_sparsity": 0.523193359375,
      "attention_bam_16_attention_concentration_10": 0.9020853935762251,
      "attention_bam_16_attention_concentration_20": 1.424756076361031,
      "attention_bam_16_attention_center_y": 0.47771911770923653,
      "attention_bam_16_attention_center_x": 0.47645313835376607,
      "attention_bam_16_attention_center_distance": 0.04584522677535229,
      "attention_bam_16_attention_spatial_variance": 41.60880494569915,
      "attention_bam_16_attention_spatial_std": 6.450488736963979,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 7.228367876018727,
      "attention_bam_16_peak_intensity_mean": 0.3710900545120239,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 673,
      "phase": "train",
      "loss": 0.006275384686887264,
      "timestamp": 1759543998.3231337,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006275384686887264,
      "ssim": 0.9026945233345032,
      "attention_bam_384_mean_attention": 0.015247084200382233,
      "attention_bam_384_std_attention": 0.21327117085456848,
      "attention_bam_384_max_attention": 2.0864992141723633,
      "attention_bam_384_min_attention": -0.8195309042930603,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9175583090452233,
      "attention_bam_384_attention_skewness": 0.48693196823366985,
      "attention_bam_384_attention_sparsity": 0.6815923055013021,
      "attention_bam_384_attention_concentration_10": 2.781328841601886,
      "attention_bam_384_attention_concentration_20": 4.276623979292092,
      "attention_bam_384_attention_center_y": 0.4836722652191225,
      "attention_bam_384_attention_center_x": 0.48353619623906313,
      "attention_bam_384_attention_center_distance": 0.03279182085073399,
      "attention_bam_384_attention_spatial_variance": 170.90775343512385,
      "attention_bam_384_attention_spatial_std": 13.073169219249166,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 19.92726621888283,
      "attention_bam_384_peak_intensity_mean": 0.28967177867889404,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13681593537330627,
      "attention_bam_16_std_attention": 0.5450482964515686,
      "attention_bam_16_max_attention": 2.816551923751831,
      "attention_bam_16_min_attention": -1.0248414278030396,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.3802762361479459,
      "attention_bam_16_attention_skewness": 0.6165544816030916,
      "attention_bam_16_attention_sparsity": 0.5185546875,
      "attention_bam_16_attention_concentration_10": 0.8710627341902484,
      "attention_bam_16_attention_concentration_20": 1.4004598563698147,
      "attention_bam_16_attention_center_y": 0.4703001564765069,
      "attention_bam_16_attention_center_x": 0.4670097579099406,
      "attention_bam_16_attention_center_distance": 0.06277637738004163,
      "attention_bam_16_attention_spatial_variance": 42.64746937140481,
      "attention_bam_16_attention_spatial_std": 6.53050299528335,
      "attention_bam_16_num_attention_peaks": 12,
      "attention_bam_16_peak_separation_mean": 9.800859718717511,
      "attention_bam_16_peak_intensity_mean": 0.30753016471862793,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 674,
      "phase": "train",
      "loss": 0.006496758200228214,
      "timestamp": 1759543998.4760468,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006496758200228214,
      "ssim": 0.8922092914581299,
      "attention_bam_384_mean_attention": 0.013405215926468372,
      "attention_bam_384_std_attention": 0.21216268837451935,
      "attention_bam_384_max_attention": 1.6639567613601685,
      "attention_bam_384_min_attention": -0.7592021226882935,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6606650776647842,
      "attention_bam_384_attention_skewness": 0.4296709189273845,
      "attention_bam_384_attention_sparsity": 0.6797510782877604,
      "attention_bam_384_attention_concentration_10": 3.0766025529926613,
      "attention_bam_384_attention_concentration_20": 4.803798984475439,
      "attention_bam_384_attention_center_y": 0.4806962564162517,
      "attention_bam_384_attention_center_x": 0.4888521646888005,
      "attention_bam_384_attention_center_distance": 0.03152487108531075,
      "attention_bam_384_attention_spatial_variance": 170.79902947892847,
      "attention_bam_384_attention_spatial_std": 13.069010271590136,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 21.492635142490148,
      "attention_bam_384_peak_intensity_mean": 0.31844639778137207,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13357751071453094,
      "attention_bam_16_std_attention": 0.5469894409179688,
      "attention_bam_16_max_attention": 2.7968215942382812,
      "attention_bam_16_min_attention": -0.9208430051803589,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.23448851621593558,
      "attention_bam_16_attention_skewness": 0.6516383259437364,
      "attention_bam_16_attention_sparsity": 0.5244140625,
      "attention_bam_16_attention_concentration_10": 0.919893554759473,
      "attention_bam_16_attention_concentration_20": 1.4558448099320773,
      "attention_bam_16_attention_center_y": 0.4590518062021628,
      "attention_bam_16_attention_center_x": 0.48322715091499396,
      "attention_bam_16_attention_center_distance": 0.06257927838723647,
      "attention_bam_16_attention_spatial_variance": 42.029350471668415,
      "attention_bam_16_attention_spatial_std": 6.4830047409876554,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.383471054607323,
      "attention_bam_16_peak_intensity_mean": 0.28392264246940613,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 675,
      "phase": "train",
      "loss": 0.004846028983592987,
      "timestamp": 1759543998.622306,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004846028983592987,
      "ssim": 0.9025055170059204,
      "attention_bam_384_mean_attention": 0.01415231078863144,
      "attention_bam_384_std_attention": 0.21012067794799805,
      "attention_bam_384_max_attention": 1.7031023502349854,
      "attention_bam_384_min_attention": -0.7704981565475464,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0868531345654064,
      "attention_bam_384_attention_skewness": 0.5478734038623485,
      "attention_bam_384_attention_sparsity": 0.6937484741210938,
      "attention_bam_384_attention_concentration_10": 2.9775780283541766,
      "attention_bam_384_attention_concentration_20": 4.56428239634605,
      "attention_bam_384_attention_center_y": 0.48754417136432454,
      "attention_bam_384_attention_center_x": 0.48570997658672227,
      "attention_bam_384_attention_center_distance": 0.02680867158787762,
      "attention_bam_384_attention_spatial_variance": 171.54583583856083,
      "attention_bam_384_attention_spatial_std": 13.097550757243159,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 18.099571825939876,
      "attention_bam_384_peak_intensity_mean": 0.3193950653076172,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1332487016916275,
      "attention_bam_16_std_attention": 0.5404191613197327,
      "attention_bam_16_max_attention": 2.5527384281158447,
      "attention_bam_16_min_attention": -0.9876437187194824,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5222178986053816,
      "attention_bam_16_attention_skewness": 0.7253886419446309,
      "attention_bam_16_attention_sparsity": 0.5302734375,
      "attention_bam_16_attention_concentration_10": 0.9099798941231046,
      "attention_bam_16_attention_concentration_20": 1.443392984382594,
      "attention_bam_16_attention_center_y": 0.48008755063051317,
      "attention_bam_16_attention_center_x": 0.476225924785809,
      "attention_bam_16_attention_center_distance": 0.04385686473477983,
      "attention_bam_16_attention_spatial_variance": 43.37735541815398,
      "attention_bam_16_attention_spatial_std": 6.586148754633013,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.855908929096824,
      "attention_bam_16_peak_intensity_mean": 0.3195476830005646,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 676,
      "phase": "train",
      "loss": 0.0056564039550721645,
      "timestamp": 1759543998.7582698,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0056564039550721645,
      "ssim": 0.9155501127243042,
      "attention_bam_384_mean_attention": 0.014186055399477482,
      "attention_bam_384_std_attention": 0.19747468829154968,
      "attention_bam_384_max_attention": 1.3682506084442139,
      "attention_bam_384_min_attention": -0.65619957447052,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.1263730523270703,
      "attention_bam_384_attention_skewness": 0.3394245068723102,
      "attention_bam_384_attention_sparsity": 0.6750055948893229,
      "attention_bam_384_attention_concentration_10": 2.6827257869507037,
      "attention_bam_384_attention_concentration_20": 4.252790739866367,
      "attention_bam_384_attention_center_y": 0.4835778703971359,
      "attention_bam_384_attention_center_x": 0.4905990228076447,
      "attention_bam_384_attention_center_distance": 0.026760594644530955,
      "attention_bam_384_attention_spatial_variance": 170.5577015907269,
      "attention_bam_384_attention_spatial_std": 13.059774178397072,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 13.175486726911203,
      "attention_bam_384_peak_intensity_mean": 0.3330676257610321,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13212046027183533,
      "attention_bam_16_std_attention": 0.5199348330497742,
      "attention_bam_16_max_attention": 1.9914385080337524,
      "attention_bam_16_min_attention": -0.981131911277771,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.31536359237839795,
      "attention_bam_16_attention_skewness": 0.4512447523346909,
      "attention_bam_16_attention_sparsity": 0.519775390625,
      "attention_bam_16_attention_concentration_10": 0.8476132622873955,
      "attention_bam_16_attention_concentration_20": 1.3874429393952397,
      "attention_bam_16_attention_center_y": 0.46720119703250185,
      "attention_bam_16_attention_center_x": 0.4840314248777554,
      "attention_bam_16_attention_center_distance": 0.051589860777783346,
      "attention_bam_16_attention_spatial_variance": 42.40669996086765,
      "attention_bam_16_attention_spatial_std": 6.512042687273145,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 7.379133021383721,
      "attention_bam_16_peak_intensity_mean": 0.3793294429779053,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 677,
      "phase": "train",
      "loss": 0.009296555072069168,
      "timestamp": 1759543998.9088404,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.009296555072069168,
      "ssim": 0.8930491209030151,
      "attention_bam_384_mean_attention": 0.013372321613132954,
      "attention_bam_384_std_attention": 0.22367611527442932,
      "attention_bam_384_max_attention": 1.9758471250534058,
      "attention_bam_384_min_attention": -0.8534367680549622,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.831224126713697,
      "attention_bam_384_attention_skewness": 0.78493582620571,
      "attention_bam_384_attention_sparsity": 0.6977564493815104,
      "attention_bam_384_attention_concentration_10": 3.45921891505335,
      "attention_bam_384_attention_concentration_20": 5.155799486210407,
      "attention_bam_384_attention_center_y": 0.48505464981980134,
      "attention_bam_384_attention_center_x": 0.4744873894974629,
      "attention_bam_384_attention_center_distance": 0.041815231355641955,
      "attention_bam_384_attention_spatial_variance": 170.34328579679058,
      "attention_bam_384_attention_spatial_std": 13.051562580656409,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 15.249921421048176,
      "attention_bam_384_peak_intensity_mean": 0.30834925174713135,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12939061224460602,
      "attention_bam_16_std_attention": 0.5640079379081726,
      "attention_bam_16_max_attention": 2.7631683349609375,
      "attention_bam_16_min_attention": -1.0588271617889404,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.9970382053314566,
      "attention_bam_16_attention_skewness": 0.898294371344638,
      "attention_bam_16_attention_sparsity": 0.538818359375,
      "attention_bam_16_attention_concentration_10": 1.0014597057113386,
      "attention_bam_16_attention_concentration_20": 1.5512711416632998,
      "attention_bam_16_attention_center_y": 0.4723388474994788,
      "attention_bam_16_attention_center_x": 0.444698573444902,
      "attention_bam_16_attention_center_distance": 0.08744583622661503,
      "attention_bam_16_attention_spatial_variance": 42.20588377056773,
      "attention_bam_16_attention_spatial_std": 6.496605557563714,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 6.630592496424413,
      "attention_bam_16_peak_intensity_mean": 0.3218601644039154,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 678,
      "phase": "train",
      "loss": 0.005933429580181837,
      "timestamp": 1759543999.0548391,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005933429580181837,
      "ssim": 0.9201325178146362,
      "attention_bam_384_mean_attention": 0.013348163105547428,
      "attention_bam_384_std_attention": 0.19022877514362335,
      "attention_bam_384_max_attention": 1.3185052871704102,
      "attention_bam_384_min_attention": -0.7201698422431946,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.546665792554661,
      "attention_bam_384_attention_skewness": 0.3319413551055443,
      "attention_bam_384_attention_sparsity": 0.6867141723632812,
      "attention_bam_384_attention_concentration_10": 2.7359155581381973,
      "attention_bam_384_attention_concentration_20": 4.291909444655557,
      "attention_bam_384_attention_center_y": 0.4817603795318876,
      "attention_bam_384_attention_center_x": 0.48085236927770875,
      "attention_bam_384_attention_center_distance": 0.03739827581849239,
      "attention_bam_384_attention_spatial_variance": 170.6535474878018,
      "attention_bam_384_attention_spatial_std": 13.063443171224108,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 15.892093774282737,
      "attention_bam_384_peak_intensity_mean": 0.3624969720840454,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14167603850364685,
      "attention_bam_16_std_attention": 0.5043113231658936,
      "attention_bam_16_max_attention": 2.3161802291870117,
      "attention_bam_16_min_attention": -1.0581982135772705,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.009921685388210033,
      "attention_bam_16_attention_skewness": 0.5004518507003629,
      "attention_bam_16_attention_sparsity": 0.505859375,
      "attention_bam_16_attention_concentration_10": 0.7857531638897223,
      "attention_bam_16_attention_concentration_20": 1.2747536264528612,
      "attention_bam_16_attention_center_y": 0.46111225601928196,
      "attention_bam_16_attention_center_x": 0.45804204319643504,
      "attention_bam_16_attention_center_distance": 0.08090397729456437,
      "attention_bam_16_attention_spatial_variance": 42.59952094047572,
      "attention_bam_16_attention_spatial_std": 6.526830849690815,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.558425938737345,
      "attention_bam_16_peak_intensity_mean": 0.36284270882606506,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 679,
      "phase": "train",
      "loss": 0.004531344398856163,
      "timestamp": 1759543999.2370722,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004531344398856163,
      "ssim": 0.9276819229125977,
      "attention_bam_384_mean_attention": 0.013423070311546326,
      "attention_bam_384_std_attention": 0.20406144857406616,
      "attention_bam_384_max_attention": 2.5220119953155518,
      "attention_bam_384_min_attention": -0.9231770634651184,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5251768069891156,
      "attention_bam_384_attention_skewness": 0.57244499423462,
      "attention_bam_384_attention_sparsity": 0.6840438842773438,
      "attention_bam_384_attention_concentration_10": 2.9817459973796585,
      "attention_bam_384_attention_concentration_20": 4.60045492540816,
      "attention_bam_384_attention_center_y": 0.47925103822792575,
      "attention_bam_384_attention_center_x": 0.4869105344548073,
      "attention_bam_384_attention_center_distance": 0.03469448148849569,
      "attention_bam_384_attention_spatial_variance": 170.44429483697883,
      "attention_bam_384_attention_spatial_std": 13.055431622010007,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 16.75736203722742,
      "attention_bam_384_peak_intensity_mean": 0.2740590274333954,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1376439929008484,
      "attention_bam_16_std_attention": 0.5348131060600281,
      "attention_bam_16_max_attention": 2.65712308883667,
      "attention_bam_16_min_attention": -1.0139508247375488,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7151118095455038,
      "attention_bam_16_attention_skewness": 0.6892640607723639,
      "attention_bam_16_attention_sparsity": 0.52197265625,
      "attention_bam_16_attention_concentration_10": 0.8633986176508618,
      "attention_bam_16_attention_concentration_20": 1.3758001942350275,
      "attention_bam_16_attention_center_y": 0.452121966889418,
      "attention_bam_16_attention_center_x": 0.48026737590009766,
      "attention_bam_16_attention_center_distance": 0.07323499857863083,
      "attention_bam_16_attention_spatial_variance": 42.400936149714944,
      "attention_bam_16_attention_spatial_std": 6.51160012206792,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 7.867174485336344,
      "attention_bam_16_peak_intensity_mean": 0.3233117461204529,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 680,
      "phase": "train",
      "loss": 0.01181081309914589,
      "timestamp": 1759543999.4884615,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.01181081309914589,
      "ssim": 0.8096381425857544,
      "attention_bam_384_mean_attention": 0.01395114604383707,
      "attention_bam_384_std_attention": 0.19083982706069946,
      "attention_bam_384_max_attention": 2.930048942565918,
      "attention_bam_384_min_attention": -1.1507714986801147,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 8.835262920675946,
      "attention_bam_384_attention_skewness": 1.4192360984304009,
      "attention_bam_384_attention_sparsity": 0.7412007649739584,
      "attention_bam_384_attention_concentration_10": 2.757687775469125,
      "attention_bam_384_attention_concentration_20": 3.948309502476437,
      "attention_bam_384_attention_center_y": 0.47966600890814826,
      "attention_bam_384_attention_center_x": 0.4797585953603019,
      "attention_bam_384_attention_center_distance": 0.04057550136502314,
      "attention_bam_384_attention_spatial_variance": 170.13899446154633,
      "attention_bam_384_attention_spatial_std": 13.04373391562195,
      "attention_bam_384_num_attention_peaks": 4,
      "attention_bam_384_peak_separation_mean": 18.336064571376387,
      "attention_bam_384_peak_intensity_mean": 0.2876971662044525,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12250346690416336,
      "attention_bam_16_std_attention": 0.5096232891082764,
      "attention_bam_16_max_attention": 3.6611645221710205,
      "attention_bam_16_min_attention": -1.0721595287322998,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 5.839706863923219,
      "attention_bam_16_attention_skewness": 1.4673874049839204,
      "attention_bam_16_attention_sparsity": 0.523193359375,
      "attention_bam_16_attention_concentration_10": 0.9322066833340784,
      "attention_bam_16_attention_concentration_20": 1.3907634998750025,
      "attention_bam_16_attention_center_y": 0.4508423787046459,
      "attention_bam_16_attention_center_x": 0.44904455946296284,
      "attention_bam_16_attention_center_distance": 0.10012920305026882,
      "attention_bam_16_attention_spatial_variance": 41.95591826470769,
      "attention_bam_16_attention_spatial_std": 6.477338825837945,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.188703741887387,
      "attention_bam_16_peak_intensity_mean": 0.2603685259819031,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 681,
      "phase": "train",
      "loss": 0.0035948525182902813,
      "timestamp": 1759543999.6771555,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0035948525182902813,
      "ssim": 0.9391701221466064,
      "attention_bam_384_mean_attention": 0.011750467121601105,
      "attention_bam_384_std_attention": 0.20614606142044067,
      "attention_bam_384_max_attention": 1.9405372142791748,
      "attention_bam_384_min_attention": -0.7047135829925537,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1824848647138193,
      "attention_bam_384_attention_skewness": 0.6069441221417566,
      "attention_bam_384_attention_sparsity": 0.6950734456380209,
      "attention_bam_384_attention_concentration_10": 3.537710803411992,
      "attention_bam_384_attention_concentration_20": 5.353052809506518,
      "attention_bam_384_attention_center_y": 0.4772707420527408,
      "attention_bam_384_attention_center_x": 0.48945312568785515,
      "attention_bam_384_attention_center_distance": 0.035436019093268,
      "attention_bam_384_attention_spatial_variance": 169.08758535608766,
      "attention_bam_384_attention_spatial_std": 13.003368231196395,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 17.360111696515336,
      "attention_bam_384_peak_intensity_mean": 0.2722782492637634,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13074052333831787,
      "attention_bam_16_std_attention": 0.532863438129425,
      "attention_bam_16_max_attention": 2.3845860958099365,
      "attention_bam_16_min_attention": -1.019474983215332,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.4083673429642629,
      "attention_bam_16_attention_skewness": 0.7152431597266037,
      "attention_bam_16_attention_sparsity": 0.526123046875,
      "attention_bam_16_attention_concentration_10": 0.9245474733376419,
      "attention_bam_16_attention_concentration_20": 1.4465190187661106,
      "attention_bam_16_attention_center_y": 0.45210634461447174,
      "attention_bam_16_attention_center_x": 0.48035459222691196,
      "attention_bam_16_attention_center_distance": 0.07320852781962833,
      "attention_bam_16_attention_spatial_variance": 41.47999819259924,
      "attention_bam_16_attention_spatial_std": 6.440496734926525,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 6.830935965215774,
      "attention_bam_16_peak_intensity_mean": 0.3364892303943634,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 682,
      "phase": "train",
      "loss": 0.003663885872811079,
      "timestamp": 1759543999.8569689,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.003663885872811079,
      "ssim": 0.9386368989944458,
      "attention_bam_384_mean_attention": 0.011724825017154217,
      "attention_bam_384_std_attention": 0.20408380031585693,
      "attention_bam_384_max_attention": 2.3109354972839355,
      "attention_bam_384_min_attention": -0.78244948387146,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.560134484005241,
      "attention_bam_384_attention_skewness": 0.5283056500609208,
      "attention_bam_384_attention_sparsity": 0.6861801147460938,
      "attention_bam_384_attention_concentration_10": 3.3604539933729805,
      "attention_bam_384_attention_concentration_20": 5.228107039160978,
      "attention_bam_384_attention_center_y": 0.48021454957118115,
      "attention_bam_384_attention_center_x": 0.48517171459635006,
      "attention_bam_384_attention_center_distance": 0.034966901397846105,
      "attention_bam_384_attention_spatial_variance": 169.9396918430309,
      "attention_bam_384_attention_spatial_std": 13.036091893011145,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 18.685293331145598,
      "attention_bam_384_peak_intensity_mean": 0.25721073150634766,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1367987096309662,
      "attention_bam_16_std_attention": 0.5274943709373474,
      "attention_bam_16_max_attention": 2.636686086654663,
      "attention_bam_16_min_attention": -1.0122809410095215,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8132260811679051,
      "attention_bam_16_attention_skewness": 0.730749729217442,
      "attention_bam_16_attention_sparsity": 0.51806640625,
      "attention_bam_16_attention_concentration_10": 0.8686072271594184,
      "attention_bam_16_attention_concentration_20": 1.3768861638335397,
      "attention_bam_16_attention_center_y": 0.45935030314203695,
      "attention_bam_16_attention_center_x": 0.4692520378965619,
      "attention_bam_16_attention_center_distance": 0.07208099649919882,
      "attention_bam_16_attention_spatial_variance": 42.14104607388941,
      "attention_bam_16_attention_spatial_std": 6.491613518524452,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 9.538042780710882,
      "attention_bam_16_peak_intensity_mean": 0.31708431243896484,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 683,
      "phase": "train",
      "loss": 0.006415450479835272,
      "timestamp": 1759544000.0325265,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006415450479835272,
      "ssim": 0.9094251394271851,
      "attention_bam_384_mean_attention": 0.013079768978059292,
      "attention_bam_384_std_attention": 0.20892979204654694,
      "attention_bam_384_max_attention": 1.3819741010665894,
      "attention_bam_384_min_attention": -0.7496160268783569,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.600800639923659,
      "attention_bam_384_attention_skewness": 0.407480603973019,
      "attention_bam_384_attention_sparsity": 0.6887842814127604,
      "attention_bam_384_attention_concentration_10": 3.1396130395380197,
      "attention_bam_384_attention_concentration_20": 4.874991609869399,
      "attention_bam_384_attention_center_y": 0.48817913598779383,
      "attention_bam_384_attention_center_x": 0.4811043806482627,
      "attention_bam_384_attention_center_distance": 0.03152069976002497,
      "attention_bam_384_attention_spatial_variance": 172.9069015002719,
      "attention_bam_384_attention_spatial_std": 13.149406887775278,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 18.738591483945488,
      "attention_bam_384_peak_intensity_mean": 0.3590230941772461,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12986168265342712,
      "attention_bam_16_std_attention": 0.5380568504333496,
      "attention_bam_16_max_attention": 2.6761577129364014,
      "attention_bam_16_min_attention": -1.1420302391052246,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.07757350642622995,
      "attention_bam_16_attention_skewness": 0.4572590270366578,
      "attention_bam_16_attention_sparsity": 0.515869140625,
      "attention_bam_16_attention_concentration_10": 0.8824404150441052,
      "attention_bam_16_attention_concentration_20": 1.4343183546931855,
      "attention_bam_16_attention_center_y": 0.47858018823398996,
      "attention_bam_16_attention_center_x": 0.4603476678386321,
      "attention_bam_16_attention_center_distance": 0.06373563809873957,
      "attention_bam_16_attention_spatial_variance": 43.97825801918154,
      "attention_bam_16_attention_spatial_std": 6.631610514737845,
      "attention_bam_16_num_attention_peaks": 11,
      "attention_bam_16_peak_separation_mean": 9.5892851187502,
      "attention_bam_16_peak_intensity_mean": 0.3426908254623413,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 684,
      "phase": "train",
      "loss": 0.005237901117652655,
      "timestamp": 1759544000.18893,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005237901117652655,
      "ssim": 0.9047320485115051,
      "attention_bam_384_mean_attention": 0.012495486997067928,
      "attention_bam_384_std_attention": 0.20084547996520996,
      "attention_bam_384_max_attention": 1.625402569770813,
      "attention_bam_384_min_attention": -0.7368291020393372,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7542864404148717,
      "attention_bam_384_attention_skewness": 0.4159268391278126,
      "attention_bam_384_attention_sparsity": 0.6949234008789062,
      "attention_bam_384_attention_concentration_10": 3.15387358952402,
      "attention_bam_384_attention_concentration_20": 4.8739380454142935,
      "attention_bam_384_attention_center_y": 0.4843971393999049,
      "attention_bam_384_attention_center_x": 0.48128925339801126,
      "attention_bam_384_attention_center_distance": 0.034454064994128994,
      "attention_bam_384_attention_spatial_variance": 170.29690624647887,
      "attention_bam_384_attention_spatial_std": 13.049785678181802,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 17.716994033088515,
      "attention_bam_384_peak_intensity_mean": 0.32063451409339905,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1409113109111786,
      "attention_bam_16_std_attention": 0.519192636013031,
      "attention_bam_16_max_attention": 2.2662088871002197,
      "attention_bam_16_min_attention": -0.9890929460525513,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.1316842731777541,
      "attention_bam_16_attention_skewness": 0.5601649853879785,
      "attention_bam_16_attention_sparsity": 0.510009765625,
      "attention_bam_16_attention_concentration_10": 0.8249371483586924,
      "attention_bam_16_attention_concentration_20": 1.3165582708959898,
      "attention_bam_16_attention_center_y": 0.47159080427161054,
      "attention_bam_16_attention_center_x": 0.4586953080663833,
      "attention_bam_16_attention_center_distance": 0.07089654402952122,
      "attention_bam_16_attention_spatial_variance": 42.337980596663236,
      "attention_bam_16_attention_spatial_std": 6.5067642186161345,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 9.644129973122611,
      "attention_bam_16_peak_intensity_mean": 0.36212867498397827,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 685,
      "phase": "train",
      "loss": 0.003937866538763046,
      "timestamp": 1759544000.3422666,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.003937866538763046,
      "ssim": 0.9201376438140869,
      "attention_bam_384_mean_attention": 0.01202002540230751,
      "attention_bam_384_std_attention": 0.20161157846450806,
      "attention_bam_384_max_attention": 2.130133867263794,
      "attention_bam_384_min_attention": -0.9518685340881348,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.7891137817676261,
      "attention_bam_384_attention_skewness": 0.6180972477518248,
      "attention_bam_384_attention_sparsity": 0.7090962727864584,
      "attention_bam_384_attention_concentration_10": 3.3526419907441647,
      "attention_bam_384_attention_concentration_20": 5.051173045556459,
      "attention_bam_384_attention_center_y": 0.4829989911157458,
      "attention_bam_384_attention_center_x": 0.48449847797083223,
      "attention_bam_384_attention_center_distance": 0.03253710153972735,
      "attention_bam_384_attention_spatial_variance": 171.61397770818328,
      "attention_bam_384_attention_spatial_std": 13.100151820043282,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 19.801726384543464,
      "attention_bam_384_peak_intensity_mean": 0.3154868483543396,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1345667541027069,
      "attention_bam_16_std_attention": 0.5273578763008118,
      "attention_bam_16_max_attention": 3.0302867889404297,
      "attention_bam_16_min_attention": -1.0047484636306763,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7846465086047227,
      "attention_bam_16_attention_skewness": 0.6888812759078803,
      "attention_bam_16_attention_sparsity": 0.51171875,
      "attention_bam_16_attention_concentration_10": 0.8825370500343614,
      "attention_bam_16_attention_concentration_20": 1.3733836938114545,
      "attention_bam_16_attention_center_y": 0.4669943477389759,
      "attention_bam_16_attention_center_x": 0.4688892157642774,
      "attention_bam_16_attention_center_distance": 0.06414443041975398,
      "attention_bam_16_attention_spatial_variance": 43.59120864578307,
      "attention_bam_16_attention_spatial_std": 6.602363868023564,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.103151454358454,
      "attention_bam_16_peak_intensity_mean": 0.2840616703033447,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 686,
      "phase": "train",
      "loss": 0.0030729302670806646,
      "timestamp": 1759544000.4941294,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0030729302670806646,
      "ssim": 0.9418480396270752,
      "attention_bam_384_mean_attention": 0.012369230389595032,
      "attention_bam_384_std_attention": 0.21170255541801453,
      "attention_bam_384_max_attention": 2.0927939414978027,
      "attention_bam_384_min_attention": -1.0082682371139526,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.6461602993257287,
      "attention_bam_384_attention_skewness": 0.5904840672875722,
      "attention_bam_384_attention_sparsity": 0.6902058919270834,
      "attention_bam_384_attention_concentration_10": 3.3953799911987392,
      "attention_bam_384_attention_concentration_20": 5.158463691458742,
      "attention_bam_384_attention_center_y": 0.4828054104921704,
      "attention_bam_384_attention_center_x": 0.48361139060854735,
      "attention_bam_384_attention_center_distance": 0.03359286906855005,
      "attention_bam_384_attention_spatial_variance": 171.11775281624688,
      "attention_bam_384_attention_spatial_std": 13.081198447246601,
      "attention_bam_384_num_attention_peaks": 20,
      "attention_bam_384_peak_separation_mean": 18.015309545072043,
      "attention_bam_384_peak_intensity_mean": 0.33342963457107544,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13567222654819489,
      "attention_bam_16_std_attention": 0.5430145859718323,
      "attention_bam_16_max_attention": 2.8260276317596436,
      "attention_bam_16_min_attention": -1.069469690322876,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6769360155845114,
      "attention_bam_16_attention_skewness": 0.672228430175958,
      "attention_bam_16_attention_sparsity": 0.522216796875,
      "attention_bam_16_attention_concentration_10": 0.882541687569218,
      "attention_bam_16_attention_concentration_20": 1.4065115478830537,
      "attention_bam_16_attention_center_y": 0.46100343162081675,
      "attention_bam_16_attention_center_x": 0.46492140482901323,
      "attention_bam_16_attention_center_distance": 0.07417870563069015,
      "attention_bam_16_attention_spatial_variance": 42.81316677080934,
      "attention_bam_16_attention_spatial_std": 6.543177115958985,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.657568053710483,
      "attention_bam_16_peak_intensity_mean": 0.31329694390296936,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 687,
      "phase": "train",
      "loss": 0.004600099287927151,
      "timestamp": 1759544000.6379468,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004600099287927151,
      "ssim": 0.9071743488311768,
      "attention_bam_384_mean_attention": 0.010582993738353252,
      "attention_bam_384_std_attention": 0.192062109708786,
      "attention_bam_384_max_attention": 1.6136841773986816,
      "attention_bam_384_min_attention": -0.8133367300033569,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.321384984605726,
      "attention_bam_384_attention_skewness": 0.5689721888241159,
      "attention_bam_384_attention_sparsity": 0.7177505493164062,
      "attention_bam_384_attention_concentration_10": 3.6606305247448216,
      "attention_bam_384_attention_concentration_20": 5.535268309291236,
      "attention_bam_384_attention_center_y": 0.47678781312419294,
      "attention_bam_384_attention_center_x": 0.4824774333966315,
      "attention_bam_384_attention_center_distance": 0.04113018258959894,
      "attention_bam_384_attention_spatial_variance": 170.69318593992605,
      "attention_bam_384_attention_spatial_std": 13.064960234915606,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 18.477246492290526,
      "attention_bam_384_peak_intensity_mean": 0.34487995505332947,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12209515273571014,
      "attention_bam_16_std_attention": 0.5005596876144409,
      "attention_bam_16_max_attention": 2.7115957736968994,
      "attention_bam_16_min_attention": -1.086849331855774,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6480227058466883,
      "attention_bam_16_attention_skewness": 0.73129740317027,
      "attention_bam_16_attention_sparsity": 0.53515625,
      "attention_bam_16_attention_concentration_10": 0.9280064102980943,
      "attention_bam_16_attention_concentration_20": 1.4641007499767957,
      "attention_bam_16_attention_center_y": 0.44892342362024523,
      "attention_bam_16_attention_center_x": 0.4613805839365319,
      "attention_bam_16_attention_center_distance": 0.09055689870749968,
      "attention_bam_16_attention_spatial_variance": 42.762936229281024,
      "attention_bam_16_attention_spatial_std": 6.5393375986625,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 10.812508486883733,
      "attention_bam_16_peak_intensity_mean": 0.3357606530189514,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 688,
      "phase": "train",
      "loss": 0.0034326259046792984,
      "timestamp": 1759544000.7815754,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0034326259046792984,
      "ssim": 0.9398496747016907,
      "attention_bam_384_mean_attention": 0.011068885214626789,
      "attention_bam_384_std_attention": 0.2060195356607437,
      "attention_bam_384_max_attention": 1.4657721519470215,
      "attention_bam_384_min_attention": -0.765872597694397,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.35077220730471126,
      "attention_bam_384_attention_skewness": 0.3799176051469647,
      "attention_bam_384_attention_sparsity": 0.6758270263671875,
      "attention_bam_384_attention_concentration_10": 3.5551721569198644,
      "attention_bam_384_attention_concentration_20": 5.611763903416424,
      "attention_bam_384_attention_center_y": 0.4784118939686673,
      "attention_bam_384_attention_center_x": 0.4897525142092303,
      "attention_bam_384_attention_center_distance": 0.03379518566459104,
      "attention_bam_384_attention_spatial_variance": 171.29379305380854,
      "attention_bam_384_attention_spatial_std": 13.08792546791922,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 20.519463854799298,
      "attention_bam_384_peak_intensity_mean": 0.34905317425727844,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13221213221549988,
      "attention_bam_16_std_attention": 0.5359309911727905,
      "attention_bam_16_max_attention": 2.3654863834381104,
      "attention_bam_16_min_attention": -1.0275511741638184,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.13777522808072762,
      "attention_bam_16_attention_skewness": 0.5163766121473741,
      "attention_bam_16_attention_sparsity": 0.517333984375,
      "attention_bam_16_attention_concentration_10": 0.871240873296668,
      "attention_bam_16_attention_concentration_20": 1.4175039441363402,
      "attention_bam_16_attention_center_y": 0.45153423979499213,
      "attention_bam_16_attention_center_x": 0.48554227260118704,
      "attention_bam_16_attention_center_distance": 0.07152560092425245,
      "attention_bam_16_attention_spatial_variance": 42.511420143961026,
      "attention_bam_16_attention_spatial_std": 6.5200782314295145,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.97969580387473,
      "attention_bam_16_peak_intensity_mean": 0.34749653935432434,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 689,
      "phase": "train",
      "loss": 0.005281367339193821,
      "timestamp": 1759544000.922829,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005281367339193821,
      "ssim": 0.9069474935531616,
      "attention_bam_384_mean_attention": 0.01195556204766035,
      "attention_bam_384_std_attention": 0.21092106401920319,
      "attention_bam_384_max_attention": 2.094700813293457,
      "attention_bam_384_min_attention": -0.7246038913726807,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1376529647180291,
      "attention_bam_384_attention_skewness": 0.5237214426583825,
      "attention_bam_384_attention_sparsity": 0.6814804077148438,
      "attention_bam_384_attention_concentration_10": 3.437512269036061,
      "attention_bam_384_attention_concentration_20": 5.325238240143057,
      "attention_bam_384_attention_center_y": 0.4839139142361165,
      "attention_bam_384_attention_center_x": 0.49078495492083596,
      "attention_bam_384_attention_center_distance": 0.026217521279252934,
      "attention_bam_384_attention_spatial_variance": 171.835573081346,
      "attention_bam_384_attention_spatial_std": 13.108606832205549,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 17.844938966688048,
      "attention_bam_384_peak_intensity_mean": 0.26411131024360657,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14131098985671997,
      "attention_bam_16_std_attention": 0.5459794998168945,
      "attention_bam_16_max_attention": 2.722161054611206,
      "attention_bam_16_min_attention": -1.1181879043579102,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.35016538091501515,
      "attention_bam_16_attention_skewness": 0.5996912653374813,
      "attention_bam_16_attention_sparsity": 0.508544921875,
      "attention_bam_16_attention_concentration_10": 0.855826554678662,
      "attention_bam_16_attention_concentration_20": 1.3622268596296208,
      "attention_bam_16_attention_center_y": 0.46719100875300157,
      "attention_bam_16_attention_center_x": 0.48448387117978037,
      "attention_bam_16_attention_center_distance": 0.05132601991604784,
      "attention_bam_16_attention_spatial_variance": 43.29547510579367,
      "attention_bam_16_attention_spatial_std": 6.579929718909897,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.285333573396587,
      "attention_bam_16_peak_intensity_mean": 0.3324449956417084,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 690,
      "phase": "train",
      "loss": 0.0035931598395109177,
      "timestamp": 1759544001.1175098,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0035931598395109177,
      "ssim": 0.9352667331695557,
      "attention_bam_384_mean_attention": 0.009232057258486748,
      "attention_bam_384_std_attention": 0.18980686366558075,
      "attention_bam_384_max_attention": 2.3780694007873535,
      "attention_bam_384_min_attention": -0.8541911244392395,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.0523871699280614,
      "attention_bam_384_attention_skewness": 0.8571667636150453,
      "attention_bam_384_attention_sparsity": 0.7232818603515625,
      "attention_bam_384_attention_concentration_10": 4.13455967471102,
      "attention_bam_384_attention_concentration_20": 6.194238600414471,
      "attention_bam_384_attention_center_y": 0.47842590425900683,
      "attention_bam_384_attention_center_x": 0.48239352741978647,
      "attention_bam_384_attention_center_distance": 0.03938094675752096,
      "attention_bam_384_attention_spatial_variance": 169.8482232160445,
      "attention_bam_384_attention_spatial_std": 13.032583136740179,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 17.31512316246903,
      "attention_bam_384_peak_intensity_mean": 0.26981788873672485,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12470843642950058,
      "attention_bam_16_std_attention": 0.5097096562385559,
      "attention_bam_16_max_attention": 2.936842679977417,
      "attention_bam_16_min_attention": -1.0479652881622314,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.2300571760742427,
      "attention_bam_16_attention_skewness": 0.8944779474448366,
      "attention_bam_16_attention_sparsity": 0.546142578125,
      "attention_bam_16_attention_concentration_10": 0.9309183733701737,
      "attention_bam_16_attention_concentration_20": 1.4641464019219064,
      "attention_bam_16_attention_center_y": 0.4486106867534421,
      "attention_bam_16_attention_center_x": 0.4614748348642263,
      "attention_bam_16_attention_center_distance": 0.09083005961345045,
      "attention_bam_16_attention_spatial_variance": 41.823182104541026,
      "attention_bam_16_attention_spatial_std": 6.467084513483725,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.698494843931368,
      "attention_bam_16_peak_intensity_mean": 0.30875134468078613,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 691,
      "phase": "train",
      "loss": 0.008294979110360146,
      "timestamp": 1759544001.2806141,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008294979110360146,
      "ssim": 0.9084333777427673,
      "attention_bam_384_mean_attention": 0.00945639330893755,
      "attention_bam_384_std_attention": 0.20082378387451172,
      "attention_bam_384_max_attention": 2.4832208156585693,
      "attention_bam_384_min_attention": -0.789100170135498,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.7189883281632303,
      "attention_bam_384_attention_skewness": 0.6916988763725699,
      "attention_bam_384_attention_sparsity": 0.7101160685221354,
      "attention_bam_384_attention_concentration_10": 4.210864610074642,
      "attention_bam_384_attention_concentration_20": 6.329879319153058,
      "attention_bam_384_attention_center_y": 0.48058159402419054,
      "attention_bam_384_attention_center_x": 0.4819116583535306,
      "attention_bam_384_attention_center_distance": 0.037530323584023396,
      "attention_bam_384_attention_spatial_variance": 170.736676506331,
      "attention_bam_384_attention_spatial_std": 13.06662452610968,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 18.802447518976564,
      "attention_bam_384_peak_intensity_mean": 0.24661216139793396,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13017380237579346,
      "attention_bam_16_std_attention": 0.5226359367370605,
      "attention_bam_16_max_attention": 2.8409676551818848,
      "attention_bam_16_min_attention": -1.0154880285263062,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.0159769679844501,
      "attention_bam_16_attention_skewness": 0.7567925940672051,
      "attention_bam_16_attention_sparsity": 0.51513671875,
      "attention_bam_16_attention_concentration_10": 0.9044208920897395,
      "attention_bam_16_attention_concentration_20": 1.4058862961135696,
      "attention_bam_16_attention_center_y": 0.4555684252392979,
      "attention_bam_16_attention_center_x": 0.46195074282294674,
      "attention_bam_16_attention_center_distance": 0.08272739337657627,
      "attention_bam_16_attention_spatial_variance": 42.59652304187035,
      "attention_bam_16_attention_spatial_std": 6.526601186059276,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.74368659153018,
      "attention_bam_16_peak_intensity_mean": 0.3031972646713257,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 692,
      "phase": "train",
      "loss": 0.004365058615803719,
      "timestamp": 1759544001.4525774,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004365058615803719,
      "ssim": 0.9525926113128662,
      "attention_bam_384_mean_attention": 0.012097354047000408,
      "attention_bam_384_std_attention": 0.18266351521015167,
      "attention_bam_384_max_attention": 1.4056334495544434,
      "attention_bam_384_min_attention": -0.6825746297836304,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7492976981137507,
      "attention_bam_384_attention_skewness": 0.43314748966658095,
      "attention_bam_384_attention_sparsity": 0.6991449991861979,
      "attention_bam_384_attention_concentration_10": 2.9490123049686336,
      "attention_bam_384_attention_concentration_20": 4.595014861299162,
      "attention_bam_384_attention_center_y": 0.4861987413970395,
      "attention_bam_384_attention_center_x": 0.47529721585513435,
      "attention_bam_384_attention_center_distance": 0.04001755323688885,
      "attention_bam_384_attention_spatial_variance": 171.7578172538713,
      "attention_bam_384_attention_spatial_std": 13.105640665525334,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 18.229771292185752,
      "attention_bam_384_peak_intensity_mean": 0.3343910276889801,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1434624195098877,
      "attention_bam_16_std_attention": 0.49043330550193787,
      "attention_bam_16_max_attention": 1.87727952003479,
      "attention_bam_16_min_attention": -1.0484098196029663,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.14263090349591456,
      "attention_bam_16_attention_skewness": 0.44538398799769074,
      "attention_bam_16_attention_sparsity": 0.502197265625,
      "attention_bam_16_attention_concentration_10": 0.7507618721048854,
      "attention_bam_16_attention_concentration_20": 1.2277457517760237,
      "attention_bam_16_attention_center_y": 0.47404855633072596,
      "attention_bam_16_attention_center_x": 0.4504029531755226,
      "attention_bam_16_attention_center_distance": 0.0791624214160849,
      "attention_bam_16_attention_spatial_variance": 43.42143298674343,
      "attention_bam_16_attention_spatial_std": 6.589494137393509,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 10.41845617074154,
      "attention_bam_16_peak_intensity_mean": 0.41257810592651367,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 693,
      "phase": "train",
      "loss": 0.003965869080275297,
      "timestamp": 1759544001.617269,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.003965869080275297,
      "ssim": 0.9457584023475647,
      "attention_bam_384_mean_attention": 0.011220208369195461,
      "attention_bam_384_std_attention": 0.19237740337848663,
      "attention_bam_384_max_attention": 1.6698689460754395,
      "attention_bam_384_min_attention": -0.8802637457847595,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.3445870430293585,
      "attention_bam_384_attention_skewness": 0.5149467424719204,
      "attention_bam_384_attention_sparsity": 0.7017873128255209,
      "attention_bam_384_attention_concentration_10": 3.3735554668873,
      "attention_bam_384_attention_concentration_20": 5.143128068025093,
      "attention_bam_384_attention_center_y": 0.48660975351107427,
      "attention_bam_384_attention_center_x": 0.4808385923719151,
      "attention_bam_384_attention_center_distance": 0.03305928744918188,
      "attention_bam_384_attention_spatial_variance": 171.4782125657524,
      "attention_bam_384_attention_spatial_std": 13.094968979182516,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 18.709099394430787,
      "attention_bam_384_peak_intensity_mean": 0.35404568910598755,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14128267765045166,
      "attention_bam_16_std_attention": 0.5163854360580444,
      "attention_bam_16_max_attention": 2.3998770713806152,
      "attention_bam_16_min_attention": -1.042051076889038,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.20043671003791452,
      "attention_bam_16_attention_skewness": 0.5507392463175742,
      "attention_bam_16_attention_sparsity": 0.508544921875,
      "attention_bam_16_attention_concentration_10": 0.809699229629138,
      "attention_bam_16_attention_concentration_20": 1.3024786632859773,
      "attention_bam_16_attention_center_y": 0.4733881128332447,
      "attention_bam_16_attention_center_x": 0.4554393553945868,
      "attention_bam_16_attention_center_distance": 0.07340086629224554,
      "attention_bam_16_attention_spatial_variance": 43.25034720011251,
      "attention_bam_16_attention_spatial_std": 6.576499616065716,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.746852516504115,
      "attention_bam_16_peak_intensity_mean": 0.3576628267765045,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 694,
      "phase": "train",
      "loss": 0.003136915620416403,
      "timestamp": 1759544001.7803237,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.003136915620416403,
      "ssim": 0.9511573910713196,
      "attention_bam_384_mean_attention": 0.010840225964784622,
      "attention_bam_384_std_attention": 0.20617538690567017,
      "attention_bam_384_max_attention": 1.4597573280334473,
      "attention_bam_384_min_attention": -0.7355682849884033,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5429574970495907,
      "attention_bam_384_attention_skewness": 0.42710016564896347,
      "attention_bam_384_attention_sparsity": 0.6886494954427084,
      "attention_bam_384_attention_concentration_10": 3.7050289110550634,
      "attention_bam_384_attention_concentration_20": 5.7631880488811555,
      "attention_bam_384_attention_center_y": 0.4815175280324664,
      "attention_bam_384_attention_center_x": 0.4870157987943251,
      "attention_bam_384_attention_center_distance": 0.03194342658451391,
      "attention_bam_384_attention_spatial_variance": 169.1182910091539,
      "attention_bam_384_attention_spatial_std": 13.004548858347755,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 18.528968730565214,
      "attention_bam_384_peak_intensity_mean": 0.3424733877182007,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13393130898475647,
      "attention_bam_16_std_attention": 0.5388025641441345,
      "attention_bam_16_max_attention": 2.279660224914551,
      "attention_bam_16_min_attention": -1.0822370052337646,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.06338080719306927,
      "attention_bam_16_attention_skewness": 0.5658811415116394,
      "attention_bam_16_attention_sparsity": 0.52001953125,
      "attention_bam_16_attention_concentration_10": 0.8874294640968863,
      "attention_bam_16_attention_concentration_20": 1.4147144107126446,
      "attention_bam_16_attention_center_y": 0.46258678486545185,
      "attention_bam_16_attention_center_x": 0.47736006841687767,
      "attention_bam_16_attention_center_distance": 0.06184359576855864,
      "attention_bam_16_attention_spatial_variance": 41.51871484641875,
      "attention_bam_16_attention_spatial_std": 6.4435017534271495,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.028082843339975,
      "attention_bam_16_peak_intensity_mean": 0.363163560628891,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 695,
      "phase": "train",
      "loss": 0.00527485366910696,
      "timestamp": 1759544001.940272,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00527485366910696,
      "ssim": 0.9013262987136841,
      "attention_bam_384_mean_attention": 0.011404088698327541,
      "attention_bam_384_std_attention": 0.21915042400360107,
      "attention_bam_384_max_attention": 2.217083692550659,
      "attention_bam_384_min_attention": -0.9247728586196899,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.6642302751858917,
      "attention_bam_384_attention_skewness": 0.8550197215099204,
      "attention_bam_384_attention_sparsity": 0.7024256388346354,
      "attention_bam_384_attention_concentration_10": 3.904299588886286,
      "attention_bam_384_attention_concentration_20": 5.817453696910463,
      "attention_bam_384_attention_center_y": 0.48300998948482726,
      "attention_bam_384_attention_center_x": 0.4851529310911971,
      "attention_bam_384_attention_center_distance": 0.03190911821058117,
      "attention_bam_384_attention_spatial_variance": 173.23370433997022,
      "attention_bam_384_attention_spatial_std": 13.161827545594504,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 18.502209420698918,
      "attention_bam_384_peak_intensity_mean": 0.30324244499206543,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1403433233499527,
      "attention_bam_16_std_attention": 0.5679846405982971,
      "attention_bam_16_max_attention": 2.823643922805786,
      "attention_bam_16_min_attention": -0.9823952913284302,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.9885972711301259,
      "attention_bam_16_attention_skewness": 0.8591135057544564,
      "attention_bam_16_attention_sparsity": 0.529296875,
      "attention_bam_16_attention_concentration_10": 0.922375112809745,
      "attention_bam_16_attention_concentration_20": 1.4433498002197558,
      "attention_bam_16_attention_center_y": 0.4642153517678508,
      "attention_bam_16_attention_center_x": 0.471425936569015,
      "attention_bam_16_attention_center_distance": 0.06476137969587453,
      "attention_bam_16_attention_spatial_variance": 44.6304761706729,
      "attention_bam_16_attention_spatial_std": 6.680604476443198,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.72381664784639,
      "attention_bam_16_peak_intensity_mean": 0.31334006786346436,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 696,
      "phase": "train",
      "loss": 0.005585352890193462,
      "timestamp": 1759544002.1009927,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005585352890193462,
      "ssim": 0.9178429245948792,
      "attention_bam_384_mean_attention": 0.010505887679755688,
      "attention_bam_384_std_attention": 0.20841388404369354,
      "attention_bam_384_max_attention": 1.3760693073272705,
      "attention_bam_384_min_attention": -0.7963801026344299,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6362208734466108,
      "attention_bam_384_attention_skewness": 0.42773769171202425,
      "attention_bam_384_attention_sparsity": 0.6900787353515625,
      "attention_bam_384_attention_concentration_10": 3.8916474734488724,
      "attention_bam_384_attention_concentration_20": 5.978659784124874,
      "attention_bam_384_attention_center_y": 0.47912786711445343,
      "attention_bam_384_attention_center_x": 0.48037953219504137,
      "attention_bam_384_attention_center_distance": 0.04051194115510469,
      "attention_bam_384_attention_spatial_variance": 170.90336783779966,
      "attention_bam_384_attention_spatial_std": 13.073001485420235,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 16.866290788359525,
      "attention_bam_384_peak_intensity_mean": 0.3772093653678894,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1386958509683609,
      "attention_bam_16_std_attention": 0.5353692173957825,
      "attention_bam_16_max_attention": 2.386359214782715,
      "attention_bam_16_min_attention": -1.0265836715698242,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.01243575509442918,
      "attention_bam_16_attention_skewness": 0.5091404288383841,
      "attention_bam_16_attention_sparsity": 0.505615234375,
      "attention_bam_16_attention_concentration_10": 0.8439782949942013,
      "attention_bam_16_attention_concentration_20": 1.3582084164079984,
      "attention_bam_16_attention_center_y": 0.45689798386706215,
      "attention_bam_16_attention_center_x": 0.4528652177736293,
      "attention_bam_16_attention_center_distance": 0.09032686743435116,
      "attention_bam_16_attention_spatial_variance": 42.68695640905226,
      "attention_bam_16_attention_spatial_std": 6.533525572694444,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 8.716921409500184,
      "attention_bam_16_peak_intensity_mean": 0.3476465344429016,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 697,
      "phase": "train",
      "loss": 0.003997453022748232,
      "timestamp": 1759544002.2535994,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.003997453022748232,
      "ssim": 0.9213318824768066,
      "attention_bam_384_mean_attention": 0.00921634677797556,
      "attention_bam_384_std_attention": 0.21551133692264557,
      "attention_bam_384_max_attention": 2.9016618728637695,
      "attention_bam_384_min_attention": -0.9497652649879456,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 4.662610053503848,
      "attention_bam_384_attention_skewness": 1.1063880351803614,
      "attention_bam_384_attention_sparsity": 0.7248789469401041,
      "attention_bam_384_attention_concentration_10": 4.811215547098595,
      "attention_bam_384_attention_concentration_20": 6.912056791272419,
      "attention_bam_384_attention_center_y": 0.48687604245292276,
      "attention_bam_384_attention_center_x": 0.4815657647205288,
      "attention_bam_384_attention_center_distance": 0.03200185282249719,
      "attention_bam_384_attention_spatial_variance": 171.18355309402583,
      "attention_bam_384_attention_spatial_std": 13.083713276208167,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 18.954233966776783,
      "attention_bam_384_peak_intensity_mean": 0.2539088726043701,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12554392218589783,
      "attention_bam_16_std_attention": 0.5571578741073608,
      "attention_bam_16_max_attention": 3.4312386512756348,
      "attention_bam_16_min_attention": -1.0879217386245728,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.663370043647298,
      "attention_bam_16_attention_skewness": 1.2180575547446026,
      "attention_bam_16_attention_sparsity": 0.552001953125,
      "attention_bam_16_attention_concentration_10": 1.0426187907136142,
      "attention_bam_16_attention_concentration_20": 1.5613006832841585,
      "attention_bam_16_attention_center_y": 0.47474829227114096,
      "attention_bam_16_attention_center_x": 0.4610778580315384,
      "attention_bam_16_attention_center_distance": 0.06561374670961566,
      "attention_bam_16_attention_spatial_variance": 43.359506288251104,
      "attention_bam_16_attention_spatial_std": 6.584793564588878,
      "attention_bam_16_num_attention_peaks": 11,
      "attention_bam_16_peak_separation_mean": 9.478581934441102,
      "attention_bam_16_peak_intensity_mean": 0.28134140372276306,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 698,
      "phase": "train",
      "loss": 0.0076745301485061646,
      "timestamp": 1759544002.3982093,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0076745301485061646,
      "ssim": 0.8908342123031616,
      "attention_bam_384_mean_attention": 0.010096653364598751,
      "attention_bam_384_std_attention": 0.20712320506572723,
      "attention_bam_384_max_attention": 1.513206124305725,
      "attention_bam_384_min_attention": -0.7823933959007263,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9739235350648565,
      "attention_bam_384_attention_skewness": 0.6373583523835559,
      "attention_bam_384_attention_sparsity": 0.6984786987304688,
      "attention_bam_384_attention_concentration_10": 4.144092307617537,
      "attention_bam_384_attention_concentration_20": 6.314429929565068,
      "attention_bam_384_attention_center_y": 0.47893309189677274,
      "attention_bam_384_attention_center_x": 0.48763075099498027,
      "attention_bam_384_attention_center_distance": 0.03454889109589492,
      "attention_bam_384_attention_spatial_variance": 171.78705812759358,
      "attention_bam_384_attention_spatial_std": 13.106756201577626,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 17.597239658094654,
      "attention_bam_384_peak_intensity_mean": 0.34885647892951965,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12812748551368713,
      "attention_bam_16_std_attention": 0.5400252342224121,
      "attention_bam_16_max_attention": 2.2272961139678955,
      "attention_bam_16_min_attention": -0.9844940900802612,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.18543392516001278,
      "attention_bam_16_attention_skewness": 0.7079110701268202,
      "attention_bam_16_attention_sparsity": 0.53955078125,
      "attention_bam_16_attention_concentration_10": 0.9485073541801637,
      "attention_bam_16_attention_concentration_20": 1.5137292710408445,
      "attention_bam_16_attention_center_y": 0.455556473790585,
      "attention_bam_16_attention_center_x": 0.48036342107418223,
      "attention_bam_16_attention_center_distance": 0.06871422347428263,
      "attention_bam_16_attention_spatial_variance": 43.49316858228238,
      "attention_bam_16_attention_spatial_std": 6.594935070361374,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.520418826488966,
      "attention_bam_16_peak_intensity_mean": 0.36753717064857483,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 699,
      "phase": "train",
      "loss": 0.0040137614123523235,
      "timestamp": 1759544002.546103,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0040137614123523235,
      "ssim": 0.9182267785072327,
      "attention_bam_384_mean_attention": 0.009324868209660053,
      "attention_bam_384_std_attention": 0.2010611593723297,
      "attention_bam_384_max_attention": 2.1079609394073486,
      "attention_bam_384_min_attention": -0.902259111404419,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.4870734459468906,
      "attention_bam_384_attention_skewness": 0.817716704013064,
      "attention_bam_384_attention_sparsity": 0.7151514689127604,
      "attention_bam_384_attention_concentration_10": 4.354031546683883,
      "attention_bam_384_attention_concentration_20": 6.496294765352935,
      "attention_bam_384_attention_center_y": 0.4805576137105676,
      "attention_bam_384_attention_center_x": 0.48455119232508853,
      "attention_bam_384_attention_center_distance": 0.03511899893800825,
      "attention_bam_384_attention_spatial_variance": 171.75267539852243,
      "attention_bam_384_attention_spatial_std": 13.105444494503894,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 18.454367356141635,
      "attention_bam_384_peak_intensity_mean": 0.3136569559574127,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1374237984418869,
      "attention_bam_16_std_attention": 0.5354748368263245,
      "attention_bam_16_max_attention": 3.2573976516723633,
      "attention_bam_16_min_attention": -0.9685982465744019,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.7887512644886252,
      "attention_bam_16_attention_skewness": 1.0100126552622204,
      "attention_bam_16_attention_sparsity": 0.53466796875,
      "attention_bam_16_attention_concentration_10": 0.9032377846929568,
      "attention_bam_16_attention_concentration_20": 1.3901365757197852,
      "attention_bam_16_attention_center_y": 0.45400361658248667,
      "attention_bam_16_attention_center_x": 0.4693623627192127,
      "attention_bam_16_attention_center_distance": 0.07815794400622347,
      "attention_bam_16_attention_spatial_variance": 43.59486734776388,
      "attention_bam_16_attention_spatial_std": 6.602640937364676,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.977891223396025,
      "attention_bam_16_peak_intensity_mean": 0.283535897731781,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 700,
      "phase": "train",
      "loss": 0.0036422000266611576,
      "timestamp": 1759544002.7334173,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0036422000266611576,
      "ssim": 0.9273797273635864,
      "attention_bam_384_mean_attention": 0.008875597268342972,
      "attention_bam_384_std_attention": 0.21063442528247833,
      "attention_bam_384_max_attention": 1.9365642070770264,
      "attention_bam_384_min_attention": -0.827730119228363,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6614779865658869,
      "attention_bam_384_attention_skewness": 0.47110865344335656,
      "attention_bam_384_attention_sparsity": 0.6855087280273438,
      "attention_bam_384_attention_concentration_10": 4.594440212226651,
      "attention_bam_384_attention_concentration_20": 7.155553037198414,
      "attention_bam_384_attention_center_y": 0.48573261416689606,
      "attention_bam_384_attention_center_x": 0.48134529449897095,
      "attention_bam_384_attention_center_distance": 0.03321314004549339,
      "attention_bam_384_attention_spatial_variance": 171.47171336011823,
      "attention_bam_384_attention_spatial_std": 13.094720820243486,
      "attention_bam_384_num_attention_peaks": 18,
      "attention_bam_384_peak_separation_mean": 19.031710671616775,
      "attention_bam_384_peak_intensity_mean": 0.3071640729904175,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12943269312381744,
      "attention_bam_16_std_attention": 0.5509190559387207,
      "attention_bam_16_max_attention": 2.6274728775024414,
      "attention_bam_16_min_attention": -0.9608531594276428,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.3305789580629721,
      "attention_bam_16_attention_skewness": 0.6748454700301298,
      "attention_bam_16_attention_sparsity": 0.527099609375,
      "attention_bam_16_attention_concentration_10": 0.9398938370303026,
      "attention_bam_16_attention_concentration_20": 1.5067362369465742,
      "attention_bam_16_attention_center_y": 0.4679501694215603,
      "attention_bam_16_attention_center_x": 0.46109460514898,
      "attention_bam_16_attention_center_distance": 0.07128564215352853,
      "attention_bam_16_attention_spatial_variance": 43.223974589151375,
      "attention_bam_16_attention_spatial_std": 6.574494245883205,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 8.447094076093535,
      "attention_bam_16_peak_intensity_mean": 0.3090043365955353,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 701,
      "phase": "train",
      "loss": 0.0034724248107522726,
      "timestamp": 1759544005.292159,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0034724248107522726,
      "ssim": 0.9217484593391418,
      "attention_bam_384_mean_attention": 0.008559552021324635,
      "attention_bam_384_std_attention": 0.18083159625530243,
      "attention_bam_384_max_attention": 1.6223236322402954,
      "attention_bam_384_min_attention": -0.670590877532959,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4901367221366346,
      "attention_bam_384_attention_skewness": 0.6748955835827875,
      "attention_bam_384_attention_sparsity": 0.7352142333984375,
      "attention_bam_384_attention_concentration_10": 4.290111440310251,
      "attention_bam_384_attention_concentration_20": 6.452341096894008,
      "attention_bam_384_attention_center_y": 0.4884519912857132,
      "attention_bam_384_attention_center_x": 0.48668974863877856,
      "attention_bam_384_attention_center_distance": 0.024920645921169087,
      "attention_bam_384_attention_spatial_variance": 170.48320554563998,
      "attention_bam_384_attention_spatial_std": 13.056921748468893,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 16.688324147565346,
      "attention_bam_384_peak_intensity_mean": 0.3030681014060974,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12374168634414673,
      "attention_bam_16_std_attention": 0.49049434065818787,
      "attention_bam_16_max_attention": 2.175391674041748,
      "attention_bam_16_min_attention": -0.9408189058303833,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5388688861771187,
      "attention_bam_16_attention_skewness": 0.7108306288485743,
      "attention_bam_16_attention_sparsity": 0.5322265625,
      "attention_bam_16_attention_concentration_10": 0.9021793162866469,
      "attention_bam_16_attention_concentration_20": 1.414468211341714,
      "attention_bam_16_attention_center_y": 0.48079608069323265,
      "attention_bam_16_attention_center_x": 0.4762435268939001,
      "attention_bam_16_attention_center_distance": 0.04320093821161017,
      "attention_bam_16_attention_spatial_variance": 42.346798991150145,
      "attention_bam_16_attention_spatial_std": 6.507441816193991,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.020778926687408,
      "attention_bam_16_peak_intensity_mean": 0.36001211404800415,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 702,
      "phase": "train",
      "loss": 0.003162046428769827,
      "timestamp": 1759544005.4322183,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.003162046428769827,
      "ssim": 0.9406396746635437,
      "attention_bam_384_mean_attention": 0.008047846145927906,
      "attention_bam_384_std_attention": 0.20944786071777344,
      "attention_bam_384_max_attention": 1.8036932945251465,
      "attention_bam_384_min_attention": -0.854349672794342,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2567525144633027,
      "attention_bam_384_attention_skewness": 0.6431885078051183,
      "attention_bam_384_attention_sparsity": 0.7050628662109375,
      "attention_bam_384_attention_concentration_10": 5.2149313174906515,
      "attention_bam_384_attention_concentration_20": 7.8950893552610255,
      "attention_bam_384_attention_center_y": 0.4840643559214674,
      "attention_bam_384_attention_center_x": 0.4835033330078124,
      "attention_bam_384_attention_center_distance": 0.03243716307104562,
      "attention_bam_384_attention_spatial_variance": 172.04911064011685,
      "attention_bam_384_attention_spatial_std": 13.116749240574695,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 19.01537698163486,
      "attention_bam_384_peak_intensity_mean": 0.3273613452911377,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12750235199928284,
      "attention_bam_16_std_attention": 0.5501739382743835,
      "attention_bam_16_max_attention": 2.5555567741394043,
      "attention_bam_16_min_attention": -1.0038447380065918,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5498899053895645,
      "attention_bam_16_attention_skewness": 0.7643181872533732,
      "attention_bam_16_attention_sparsity": 0.533935546875,
      "attention_bam_16_attention_concentration_10": 0.9714101661023237,
      "attention_bam_16_attention_concentration_20": 1.5207014799385976,
      "attention_bam_16_attention_center_y": 0.46831350566558794,
      "attention_bam_16_attention_center_x": 0.4662396337706152,
      "attention_bam_16_attention_center_distance": 0.06547971061553207,
      "attention_bam_16_attention_spatial_variance": 43.67115918964969,
      "attention_bam_16_attention_spatial_std": 6.608415785167402,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 10.25791261949909,
      "attention_bam_16_peak_intensity_mean": 0.3260728418827057,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 703,
      "phase": "train",
      "loss": 0.003630832303315401,
      "timestamp": 1759544005.5680277,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.003630832303315401,
      "ssim": 0.9383691549301147,
      "attention_bam_384_mean_attention": 0.009312347508966923,
      "attention_bam_384_std_attention": 0.21384815871715546,
      "attention_bam_384_max_attention": 2.6560564041137695,
      "attention_bam_384_min_attention": -0.9406625032424927,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.222576751173162,
      "attention_bam_384_attention_skewness": 0.925608230946422,
      "attention_bam_384_attention_sparsity": 0.7130889892578125,
      "attention_bam_384_attention_concentration_10": 4.671316082716642,
      "attention_bam_384_attention_concentration_20": 6.89042073697599,
      "attention_bam_384_attention_center_y": 0.48383612098746803,
      "attention_bam_384_attention_center_x": 0.487740028669278,
      "attention_bam_384_attention_center_distance": 0.028690691234680852,
      "attention_bam_384_attention_spatial_variance": 172.09864274329203,
      "attention_bam_384_attention_spatial_std": 13.118637228892794,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 19.310658924553696,
      "attention_bam_384_peak_intensity_mean": 0.26630228757858276,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1335192322731018,
      "attention_bam_16_std_attention": 0.5633729696273804,
      "attention_bam_16_max_attention": 3.2153286933898926,
      "attention_bam_16_min_attention": -0.9818738102912903,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.866429028581833,
      "attention_bam_16_attention_skewness": 1.0380592517943437,
      "attention_bam_16_attention_sparsity": 0.535400390625,
      "attention_bam_16_attention_concentration_10": 0.9695680647085023,
      "attention_bam_16_attention_concentration_20": 1.4864838592618363,
      "attention_bam_16_attention_center_y": 0.46654011931281847,
      "attention_bam_16_attention_center_x": 0.48344582498170807,
      "attention_bam_16_attention_center_distance": 0.05279402098981786,
      "attention_bam_16_attention_spatial_variance": 44.05667169139885,
      "attention_bam_16_attention_spatial_std": 6.637519995555482,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 10.6011362159429,
      "attention_bam_16_peak_intensity_mean": 0.2691025137901306,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 704,
      "phase": "train",
      "loss": 0.003402472473680973,
      "timestamp": 1759544005.702999,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.003402472473680973,
      "ssim": 0.9447330236434937,
      "attention_bam_384_mean_attention": 0.008829993195831776,
      "attention_bam_384_std_attention": 0.2152252495288849,
      "attention_bam_384_max_attention": 1.8758631944656372,
      "attention_bam_384_min_attention": -0.7732127904891968,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.3019384350089922,
      "attention_bam_384_attention_skewness": 0.6711384601715529,
      "attention_bam_384_attention_sparsity": 0.6965688069661459,
      "attention_bam_384_attention_concentration_10": 4.898786502302773,
      "attention_bam_384_attention_concentration_20": 7.384789722726364,
      "attention_bam_384_attention_center_y": 0.48531522548840833,
      "attention_bam_384_attention_center_x": 0.48217293827081975,
      "attention_bam_384_attention_center_distance": 0.032663335174237654,
      "attention_bam_384_attention_spatial_variance": 171.60765448555858,
      "attention_bam_384_attention_spatial_std": 13.09991047624214,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 18.449991945785293,
      "attention_bam_384_peak_intensity_mean": 0.29766321182250977,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1246708407998085,
      "attention_bam_16_std_attention": 0.5564761161804199,
      "attention_bam_16_max_attention": 2.346179962158203,
      "attention_bam_16_min_attention": -0.9619218111038208,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6602871144862386,
      "attention_bam_16_attention_skewness": 0.8444193430526359,
      "attention_bam_16_attention_sparsity": 0.54541015625,
      "attention_bam_16_attention_concentration_10": 1.0230726197321358,
      "attention_bam_16_attention_concentration_20": 1.5859333843270842,
      "attention_bam_16_attention_center_y": 0.4707575921494762,
      "attention_bam_16_attention_center_x": 0.4636655257352601,
      "attention_bam_16_attention_center_distance": 0.06595926677869338,
      "attention_bam_16_attention_spatial_variance": 43.47046901384943,
      "attention_bam_16_attention_spatial_std": 6.593213860769984,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.77874061001199,
      "attention_bam_16_peak_intensity_mean": 0.3368279039859772,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 705,
      "phase": "train",
      "loss": 0.009471681900322437,
      "timestamp": 1759544005.8369415,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.009471681900322437,
      "ssim": 0.8705776929855347,
      "attention_bam_384_mean_attention": 0.0098806107416749,
      "attention_bam_384_std_attention": 0.18864578008651733,
      "attention_bam_384_max_attention": 1.4881088733673096,
      "attention_bam_384_min_attention": -0.8585238456726074,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.646755763991833,
      "attention_bam_384_attention_skewness": 0.5787148324628067,
      "attention_bam_384_attention_sparsity": 0.7311375935872396,
      "attention_bam_384_attention_concentration_10": 3.863301863437454,
      "attention_bam_384_attention_concentration_20": 5.776177437508376,
      "attention_bam_384_attention_center_y": 0.4828835451767231,
      "attention_bam_384_attention_center_x": 0.4827557159874059,
      "attention_bam_384_attention_center_distance": 0.034360976610809155,
      "attention_bam_384_attention_spatial_variance": 170.93344430909517,
      "attention_bam_384_attention_spatial_std": 13.074151762508158,
      "attention_bam_384_num_attention_peaks": 18,
      "attention_bam_384_peak_separation_mean": 18.675976611806174,
      "attention_bam_384_peak_intensity_mean": 0.3751000165939331,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14329341053962708,
      "attention_bam_16_std_attention": 0.5027565360069275,
      "attention_bam_16_max_attention": 2.5551986694335938,
      "attention_bam_16_min_attention": -1.2108118534088135,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6043840667449274,
      "attention_bam_16_attention_skewness": 0.6911072728433869,
      "attention_bam_16_attention_sparsity": 0.515869140625,
      "attention_bam_16_attention_concentration_10": 0.8116505921395848,
      "attention_bam_16_attention_concentration_20": 1.2680077842953308,
      "attention_bam_16_attention_center_y": 0.4612560932303746,
      "attention_bam_16_attention_center_x": 0.4655600518462321,
      "attention_bam_16_attention_center_distance": 0.07331030405894721,
      "attention_bam_16_attention_spatial_variance": 42.777323819419,
      "attention_bam_16_attention_spatial_std": 6.540437586233738,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 9.825159057491797,
      "attention_bam_16_peak_intensity_mean": 0.3694801926612854,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 706,
      "phase": "train",
      "loss": 0.005155015271157026,
      "timestamp": 1759544005.974955,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005155015271157026,
      "ssim": 0.905682384967804,
      "attention_bam_384_mean_attention": 0.010172258131206036,
      "attention_bam_384_std_attention": 0.16270895302295685,
      "attention_bam_384_max_attention": 1.1042394638061523,
      "attention_bam_384_min_attention": -0.7068150043487549,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.4988784857314137,
      "attention_bam_384_attention_skewness": 0.32067870529416137,
      "attention_bam_384_attention_sparsity": 0.7277806599934896,
      "attention_bam_384_attention_concentration_10": 3.0930344908287877,
      "attention_bam_384_attention_concentration_20": 4.822600496863807,
      "attention_bam_384_attention_center_y": 0.48308195204663923,
      "attention_bam_384_attention_center_x": 0.47848377953764354,
      "attention_bam_384_attention_center_distance": 0.03870834766654194,
      "attention_bam_384_attention_spatial_variance": 172.27337023839428,
      "attention_bam_384_attention_spatial_std": 13.125295053384296,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 16.86527790199076,
      "attention_bam_384_peak_intensity_mean": 0.3966873586177826,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13609817624092102,
      "attention_bam_16_std_attention": 0.4475782513618469,
      "attention_bam_16_max_attention": 1.8099260330200195,
      "attention_bam_16_min_attention": -0.9785741567611694,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.09576873616428694,
      "attention_bam_16_attention_skewness": 0.3663624619896152,
      "attention_bam_16_attention_sparsity": 0.489990234375,
      "attention_bam_16_attention_concentration_10": 0.7149149593111682,
      "attention_bam_16_attention_concentration_20": 1.1690210670653722,
      "attention_bam_16_attention_center_y": 0.4664281933176508,
      "attention_bam_16_attention_center_x": 0.4532726775113886,
      "attention_bam_16_attention_center_distance": 0.08136963648526045,
      "attention_bam_16_attention_spatial_variance": 43.75553393089907,
      "attention_bam_16_attention_spatial_std": 6.614796590289007,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.019978517244185,
      "attention_bam_16_peak_intensity_mean": 0.3978136479854584,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 707,
      "phase": "train",
      "loss": 0.003365512704476714,
      "timestamp": 1759544006.1251063,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.003365512704476714,
      "ssim": 0.9458556771278381,
      "attention_bam_384_mean_attention": 0.009264321066439152,
      "attention_bam_384_std_attention": 0.2001083493232727,
      "attention_bam_384_max_attention": 1.5491726398468018,
      "attention_bam_384_min_attention": -1.0038695335388184,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9045434248299151,
      "attention_bam_384_attention_skewness": 0.487357365620972,
      "attention_bam_384_attention_sparsity": 0.6999231974283854,
      "attention_bam_384_attention_concentration_10": 4.249064118947934,
      "attention_bam_384_attention_concentration_20": 6.503257840452983,
      "attention_bam_384_attention_center_y": 0.4863155899941952,
      "attention_bam_384_attention_center_x": 0.48897064140762,
      "attention_bam_384_attention_center_distance": 0.024855978281543335,
      "attention_bam_384_attention_spatial_variance": 172.46491529401993,
      "attention_bam_384_attention_spatial_std": 13.132589816712464,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 20.090431091315338,
      "attention_bam_384_peak_intensity_mean": 0.4014960527420044,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12718288600444794,
      "attention_bam_16_std_attention": 0.5397850871086121,
      "attention_bam_16_max_attention": 3.4379265308380127,
      "attention_bam_16_min_attention": -1.0019927024841309,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5484582446569211,
      "attention_bam_16_attention_skewness": 0.6892712364997992,
      "attention_bam_16_attention_sparsity": 0.523681640625,
      "attention_bam_16_attention_concentration_10": 0.9407863341533428,
      "attention_bam_16_attention_concentration_20": 1.4960709887202108,
      "attention_bam_16_attention_center_y": 0.4774404906061962,
      "attention_bam_16_attention_center_x": 0.4892310574191591,
      "attention_bam_16_attention_center_distance": 0.0353525554493185,
      "attention_bam_16_attention_spatial_variance": 44.36675754565011,
      "attention_bam_16_attention_spatial_std": 6.660837600906519,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.708633830444729,
      "attention_bam_16_peak_intensity_mean": 0.2674919068813324,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 708,
      "phase": "train",
      "loss": 0.007035715039819479,
      "timestamp": 1759544006.2882411,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007035715039819479,
      "ssim": 0.9077545404434204,
      "attention_bam_384_mean_attention": 0.010017127729952335,
      "attention_bam_384_std_attention": 0.16378836333751678,
      "attention_bam_384_max_attention": 1.5425455570220947,
      "attention_bam_384_min_attention": -0.6648776531219482,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7351971125159982,
      "attention_bam_384_attention_skewness": 0.38066856956651707,
      "attention_bam_384_attention_sparsity": 0.7301152547200521,
      "attention_bam_384_attention_concentration_10": 3.189975228262342,
      "attention_bam_384_attention_concentration_20": 4.947643921281693,
      "attention_bam_384_attention_center_y": 0.48388074479582144,
      "attention_bam_384_attention_center_x": 0.4781127560012005,
      "attention_bam_384_attention_center_distance": 0.03844169190346392,
      "attention_bam_384_attention_spatial_variance": 168.80063113280607,
      "attention_bam_384_attention_spatial_std": 12.992329703821639,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 15.67378419436823,
      "attention_bam_384_peak_intensity_mean": 0.30684271454811096,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14229190349578857,
      "attention_bam_16_std_attention": 0.45260900259017944,
      "attention_bam_16_max_attention": 2.0656235218048096,
      "attention_bam_16_min_attention": -0.9548043012619019,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.009887800658739287,
      "attention_bam_16_attention_skewness": 0.46036508785023583,
      "attention_bam_16_attention_sparsity": 0.496337890625,
      "attention_bam_16_attention_concentration_10": 0.7068271098735909,
      "attention_bam_16_attention_concentration_20": 1.148542870431882,
      "attention_bam_16_attention_center_y": 0.4668734607242843,
      "attention_bam_16_attention_center_x": 0.45162071954951893,
      "attention_bam_16_attention_center_distance": 0.08292071371245949,
      "attention_bam_16_attention_spatial_variance": 41.13161576802467,
      "attention_bam_16_attention_spatial_std": 6.41339346742617,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 6.831702238000502,
      "attention_bam_16_peak_intensity_mean": 0.36753007769584656,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 709,
      "phase": "train",
      "loss": 0.004488523118197918,
      "timestamp": 1759544006.4549232,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004488523118197918,
      "ssim": 0.9339773654937744,
      "attention_bam_384_mean_attention": 0.008389734663069248,
      "attention_bam_384_std_attention": 0.19152681529521942,
      "attention_bam_384_max_attention": 1.4877965450286865,
      "attention_bam_384_min_attention": -0.8315384387969971,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.502395319369347,
      "attention_bam_384_attention_skewness": 0.6073913488915492,
      "attention_bam_384_attention_sparsity": 0.7243576049804688,
      "attention_bam_384_attention_concentration_10": 4.568134971364375,
      "attention_bam_384_attention_concentration_20": 6.8722216790874215,
      "attention_bam_384_attention_center_y": 0.49076770730472224,
      "attention_bam_384_attention_center_x": 0.4829978792676469,
      "attention_bam_384_attention_center_distance": 0.027360823737920953,
      "attention_bam_384_attention_spatial_variance": 171.17786097401083,
      "attention_bam_384_attention_spatial_std": 13.083495747467907,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 19.543529617922818,
      "attention_bam_384_peak_intensity_mean": 0.36763232946395874,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12642133235931396,
      "attention_bam_16_std_attention": 0.5165162682533264,
      "attention_bam_16_max_attention": 2.630662441253662,
      "attention_bam_16_min_attention": -1.0149693489074707,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8462459400899145,
      "attention_bam_16_attention_skewness": 0.7711957716377357,
      "attention_bam_16_attention_sparsity": 0.53271484375,
      "attention_bam_16_attention_concentration_10": 0.9286335960533499,
      "attention_bam_16_attention_concentration_20": 1.4449273407805268,
      "attention_bam_16_attention_center_y": 0.4909189027323596,
      "attention_bam_16_attention_center_x": 0.4644093827589843,
      "attention_bam_16_attention_center_distance": 0.051945324393651245,
      "attention_bam_16_attention_spatial_variance": 42.87184173033772,
      "attention_bam_16_attention_spatial_std": 6.547659255820947,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.382360573056802,
      "attention_bam_16_peak_intensity_mean": 0.3291243612766266,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 710,
      "phase": "train",
      "loss": 0.00411467719823122,
      "timestamp": 1759544006.6618466,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00411467719823122,
      "ssim": 0.9286996126174927,
      "attention_bam_384_mean_attention": 0.007463764864951372,
      "attention_bam_384_std_attention": 0.18312501907348633,
      "attention_bam_384_max_attention": 1.721333622932434,
      "attention_bam_384_min_attention": -0.6931272745132446,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.280314509845926,
      "attention_bam_384_attention_skewness": 0.6201265475241005,
      "attention_bam_384_attention_sparsity": 0.7286504109700521,
      "attention_bam_384_attention_concentration_10": 4.915276674967146,
      "attention_bam_384_attention_concentration_20": 7.442492555855963,
      "attention_bam_384_attention_center_y": 0.483637454853399,
      "attention_bam_384_attention_center_x": 0.47701655226556405,
      "attention_bam_384_attention_center_distance": 0.0398991667440839,
      "attention_bam_384_attention_spatial_variance": 172.38166361233115,
      "attention_bam_384_attention_spatial_std": 13.12941977439716,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 20.538056822955664,
      "attention_bam_384_peak_intensity_mean": 0.2973158657550812,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12762276828289032,
      "attention_bam_16_std_attention": 0.511507511138916,
      "attention_bam_16_max_attention": 2.485682964324951,
      "attention_bam_16_min_attention": -0.9354861974716187,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.585684811433242,
      "attention_bam_16_attention_skewness": 0.766188477255225,
      "attention_bam_16_attention_sparsity": 0.539306640625,
      "attention_bam_16_attention_concentration_10": 0.9084322373068974,
      "attention_bam_16_attention_concentration_20": 1.4396778186821997,
      "attention_bam_16_attention_center_y": 0.4634076868358958,
      "attention_bam_16_attention_center_x": 0.44573785562974,
      "attention_bam_16_attention_center_distance": 0.09255676846518372,
      "attention_bam_16_attention_spatial_variance": 43.86296058425507,
      "attention_bam_16_attention_spatial_std": 6.622911790463094,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.622829670965729,
      "attention_bam_16_peak_intensity_mean": 0.3199039399623871,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 711,
      "phase": "train",
      "loss": 0.005749993026256561,
      "timestamp": 1759544006.83403,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005749993026256561,
      "ssim": 0.915510892868042,
      "attention_bam_384_mean_attention": 0.0075583127327263355,
      "attention_bam_384_std_attention": 0.2219405472278595,
      "attention_bam_384_max_attention": 1.9768058061599731,
      "attention_bam_384_min_attention": -0.7577751278877258,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.13267348866271,
      "attention_bam_384_attention_skewness": 0.6504177596226225,
      "attention_bam_384_attention_sparsity": 0.6945749918619791,
      "attention_bam_384_attention_concentration_10": 5.8852569697214765,
      "attention_bam_384_attention_concentration_20": 8.889138100181903,
      "attention_bam_384_attention_center_y": 0.483003999869899,
      "attention_bam_384_attention_center_x": 0.48490810416439617,
      "attention_bam_384_attention_center_distance": 0.032144341347587424,
      "attention_bam_384_attention_spatial_variance": 171.67893622503686,
      "attention_bam_384_attention_spatial_std": 13.102630889444946,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 17.882378520199122,
      "attention_bam_384_peak_intensity_mean": 0.28240710496902466,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12940441071987152,
      "attention_bam_16_std_attention": 0.5841647386550903,
      "attention_bam_16_max_attention": 2.8270516395568848,
      "attention_bam_16_min_attention": -1.0028162002563477,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.741893855844459,
      "attention_bam_16_attention_skewness": 0.8574424164368445,
      "attention_bam_16_attention_sparsity": 0.544677734375,
      "attention_bam_16_attention_concentration_10": 1.0282947745149456,
      "attention_bam_16_attention_concentration_20": 1.605465476687555,
      "attention_bam_16_attention_center_y": 0.4664580735918888,
      "attention_bam_16_attention_center_x": 0.47250502248734993,
      "attention_bam_16_attention_center_distance": 0.06133570926610828,
      "attention_bam_16_attention_spatial_variance": 43.463807766616384,
      "attention_bam_16_attention_spatial_std": 6.592708682068121,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.39235099491062,
      "attention_bam_16_peak_intensity_mean": 0.3067963719367981,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 712,
      "phase": "train",
      "loss": 0.006425616797059774,
      "timestamp": 1759544006.9964263,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006425616797059774,
      "ssim": 0.9098237156867981,
      "attention_bam_384_mean_attention": 0.007016775663942099,
      "attention_bam_384_std_attention": 0.18903714418411255,
      "attention_bam_384_max_attention": 1.3657504320144653,
      "attention_bam_384_min_attention": -0.7571728825569153,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.4601466676124497,
      "attention_bam_384_attention_skewness": 0.35434592317712416,
      "attention_bam_384_attention_sparsity": 0.70953369140625,
      "attention_bam_384_attention_concentration_10": 5.19204856639491,
      "attention_bam_384_attention_concentration_20": 8.016017260981796,
      "attention_bam_384_attention_center_y": 0.4816981577975562,
      "attention_bam_384_attention_center_x": 0.4832438100030264,
      "attention_bam_384_attention_center_distance": 0.03509208831682237,
      "attention_bam_384_attention_spatial_variance": 170.14328573117797,
      "attention_bam_384_attention_spatial_std": 13.0438984100298,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 17.807341842119985,
      "attention_bam_384_peak_intensity_mean": 0.36388683319091797,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12788423895835876,
      "attention_bam_16_std_attention": 0.5134066343307495,
      "attention_bam_16_max_attention": 2.443826913833618,
      "attention_bam_16_min_attention": -1.0110759735107422,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.07494217167134298,
      "attention_bam_16_attention_skewness": 0.5453743433239394,
      "attention_bam_16_attention_sparsity": 0.51953125,
      "attention_bam_16_attention_concentration_10": 0.8835139054470916,
      "attention_bam_16_attention_concentration_20": 1.416776836962589,
      "attention_bam_16_attention_center_y": 0.4607843023221882,
      "attention_bam_16_attention_center_x": 0.46559523831593264,
      "attention_bam_16_attention_center_distance": 0.07377748397573618,
      "attention_bam_16_attention_spatial_variance": 41.935571470288664,
      "attention_bam_16_attention_spatial_std": 6.475768021654934,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.067098320230842,
      "attention_bam_16_peak_intensity_mean": 0.33660081028938293,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 713,
      "phase": "train",
      "loss": 0.005714015103876591,
      "timestamp": 1759544007.15736,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005714015103876591,
      "ssim": 0.9264262318611145,
      "attention_bam_384_mean_attention": 0.007220777217298746,
      "attention_bam_384_std_attention": 0.21871480345726013,
      "attention_bam_384_max_attention": 1.3775889873504639,
      "attention_bam_384_min_attention": -0.8025877475738525,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.86394845933085,
      "attention_bam_384_attention_skewness": 0.49935802590197215,
      "attention_bam_384_attention_sparsity": 0.6967620849609375,
      "attention_bam_384_attention_concentration_10": 5.971498922237469,
      "attention_bam_384_attention_concentration_20": 9.063765082244105,
      "attention_bam_384_attention_center_y": 0.48571901640831855,
      "attention_bam_384_attention_center_x": 0.48130728420139335,
      "attention_bam_384_attention_center_distance": 0.03326752519419963,
      "attention_bam_384_attention_spatial_variance": 173.89235042546937,
      "attention_bam_384_attention_spatial_std": 13.186824880367123,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 19.379254191087384,
      "attention_bam_384_peak_intensity_mean": 0.38000985980033875,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12360755354166031,
      "attention_bam_16_std_attention": 0.5725919604301453,
      "attention_bam_16_max_attention": 2.708876848220825,
      "attention_bam_16_min_attention": -1.1120787858963013,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.4967340752048859,
      "attention_bam_16_attention_skewness": 0.750939182125683,
      "attention_bam_16_attention_sparsity": 0.541015625,
      "attention_bam_16_attention_concentration_10": 1.0429572657351946,
      "attention_bam_16_attention_concentration_20": 1.6285308455058212,
      "attention_bam_16_attention_center_y": 0.4760705764076891,
      "attention_bam_16_attention_center_x": 0.4627532142657346,
      "attention_bam_16_attention_center_distance": 0.06260895081367394,
      "attention_bam_16_attention_spatial_variance": 44.83644045161903,
      "attention_bam_16_attention_spatial_std": 6.6960018258374925,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.404151680733934,
      "attention_bam_16_peak_intensity_mean": 0.33285263180732727,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 714,
      "phase": "train",
      "loss": 0.003853571368381381,
      "timestamp": 1759544007.3128395,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.003853571368381381,
      "ssim": 0.9389258027076721,
      "attention_bam_384_mean_attention": 0.007362591102719307,
      "attention_bam_384_std_attention": 0.19460518658161163,
      "attention_bam_384_max_attention": 1.4306418895721436,
      "attention_bam_384_min_attention": -0.7654795050621033,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8885495824172853,
      "attention_bam_384_attention_skewness": 0.519191272984303,
      "attention_bam_384_attention_sparsity": 0.7108790079752604,
      "attention_bam_384_attention_concentration_10": 5.2043338820457254,
      "attention_bam_384_attention_concentration_20": 7.95217115324995,
      "attention_bam_384_attention_center_y": 0.48540624326164145,
      "attention_bam_384_attention_center_x": 0.4833823689937354,
      "attention_bam_384_attention_center_distance": 0.03127693706227491,
      "attention_bam_384_attention_spatial_variance": 170.58454675496094,
      "attention_bam_384_attention_spatial_std": 13.06080191852556,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 18.090244621499863,
      "attention_bam_384_peak_intensity_mean": 0.35526803135871887,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12990882992744446,
      "attention_bam_16_std_attention": 0.5352949500083923,
      "attention_bam_16_max_attention": 2.6979856491088867,
      "attention_bam_16_min_attention": -1.0073219537734985,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.2510808577176613,
      "attention_bam_16_attention_skewness": 0.6433992279093885,
      "attention_bam_16_attention_sparsity": 0.528564453125,
      "attention_bam_16_attention_concentration_10": 0.9083990725261186,
      "attention_bam_16_attention_concentration_20": 1.4650915561650666,
      "attention_bam_16_attention_center_y": 0.47355047621511537,
      "attention_bam_16_attention_center_x": 0.46743683649605877,
      "attention_bam_16_attention_center_distance": 0.05932852477234855,
      "attention_bam_16_attention_spatial_variance": 42.23308806648215,
      "attention_bam_16_attention_spatial_std": 6.49869895182737,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.743011049198206,
      "attention_bam_16_peak_intensity_mean": 0.3115735650062561,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 715,
      "phase": "train",
      "loss": 0.004992117639631033,
      "timestamp": 1759544007.46466,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004992117639631033,
      "ssim": 0.9221221208572388,
      "attention_bam_384_mean_attention": 0.007727176416665316,
      "attention_bam_384_std_attention": 0.19632655382156372,
      "attention_bam_384_max_attention": 1.3540593385696411,
      "attention_bam_384_min_attention": -0.8503321409225464,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8698555115434066,
      "attention_bam_384_attention_skewness": 0.5333277754926881,
      "attention_bam_384_attention_sparsity": 0.7119242350260416,
      "attention_bam_384_attention_concentration_10": 5.033764121264646,
      "attention_bam_384_attention_concentration_20": 7.680696515796639,
      "attention_bam_384_attention_center_y": 0.4834746938056854,
      "attention_bam_384_attention_center_x": 0.4799571615454033,
      "attention_bam_384_attention_center_distance": 0.03673693286416034,
      "attention_bam_384_attention_spatial_variance": 169.9274513305134,
      "attention_bam_384_attention_spatial_std": 13.035622399046138,
      "attention_bam_384_num_attention_peaks": 5,
      "attention_bam_384_peak_separation_mean": 19.25764531240671,
      "attention_bam_384_peak_intensity_mean": 0.39547646045684814,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13520878553390503,
      "attention_bam_16_std_attention": 0.5429613590240479,
      "attention_bam_16_max_attention": 2.6338775157928467,
      "attention_bam_16_min_attention": -1.0551178455352783,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.2703941855101766,
      "attention_bam_16_attention_skewness": 0.6709726970694434,
      "attention_bam_16_attention_sparsity": 0.5302734375,
      "attention_bam_16_attention_concentration_10": 0.9026545156458758,
      "attention_bam_16_attention_concentration_20": 1.4383275282568433,
      "attention_bam_16_attention_center_y": 0.4660748145742691,
      "attention_bam_16_attention_center_x": 0.45489419680051507,
      "attention_bam_16_attention_center_distance": 0.07981793894157992,
      "attention_bam_16_attention_spatial_variance": 41.839988362997865,
      "attention_bam_16_attention_spatial_std": 6.468383751989199,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.785575034216034,
      "attention_bam_16_peak_intensity_mean": 0.33559322357177734,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 716,
      "phase": "train",
      "loss": 0.004428725689649582,
      "timestamp": 1759544007.6088958,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004428725689649582,
      "ssim": 0.9457226991653442,
      "attention_bam_384_mean_attention": 0.00921224057674408,
      "attention_bam_384_std_attention": 0.20719757676124573,
      "attention_bam_384_max_attention": 1.3574813604354858,
      "attention_bam_384_min_attention": -0.7888223528862,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8721402262828901,
      "attention_bam_384_attention_skewness": 0.46752631938564254,
      "attention_bam_384_attention_sparsity": 0.6988652547200521,
      "attention_bam_384_attention_concentration_10": 4.416553843288149,
      "attention_bam_384_attention_concentration_20": 6.7694607501205555,
      "attention_bam_384_attention_center_y": 0.4823781552254682,
      "attention_bam_384_attention_center_x": 0.48783837958017734,
      "attention_bam_384_attention_center_distance": 0.030279842288015373,
      "attention_bam_384_attention_spatial_variance": 172.73234748771958,
      "attention_bam_384_attention_spatial_std": 13.142767877723458,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 18.359610487631958,
      "attention_bam_384_peak_intensity_mean": 0.377559095621109,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13911083340644836,
      "attention_bam_16_std_attention": 0.5674592852592468,
      "attention_bam_16_max_attention": 2.7722973823547363,
      "attention_bam_16_min_attention": -1.1579554080963135,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.42310051797457504,
      "attention_bam_16_attention_skewness": 0.6866330128567674,
      "attention_bam_16_attention_sparsity": 0.531982421875,
      "attention_bam_16_attention_concentration_10": 0.9112438768977901,
      "attention_bam_16_attention_concentration_20": 1.4489670153790932,
      "attention_bam_16_attention_center_y": 0.46644743719444703,
      "attention_bam_16_attention_center_x": 0.47937387744750104,
      "attention_bam_16_attention_center_distance": 0.05569939680770847,
      "attention_bam_16_attention_spatial_variance": 43.90356287548757,
      "attention_bam_16_attention_spatial_std": 6.625976371485758,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.478831213691148,
      "attention_bam_16_peak_intensity_mean": 0.3345898389816284,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 717,
      "phase": "train",
      "loss": 0.0034676948562264442,
      "timestamp": 1759544007.7520478,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0034676948562264442,
      "ssim": 0.9371873736381531,
      "attention_bam_384_mean_attention": 0.008519123308360577,
      "attention_bam_384_std_attention": 0.19494467973709106,
      "attention_bam_384_max_attention": 1.5659410953521729,
      "attention_bam_384_min_attention": -0.7697008848190308,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1212107368424604,
      "attention_bam_384_attention_skewness": 0.5444347675937569,
      "attention_bam_384_attention_sparsity": 0.7087300618489584,
      "attention_bam_384_attention_concentration_10": 4.511686859167224,
      "attention_bam_384_attention_concentration_20": 6.89273624116985,
      "attention_bam_384_attention_center_y": 0.48280103499940746,
      "attention_bam_384_attention_center_x": 0.4828761084938107,
      "attention_bam_384_attention_center_distance": 0.03432293860983787,
      "attention_bam_384_attention_spatial_variance": 171.75706819691382,
      "attention_bam_384_attention_spatial_std": 13.10561208783908,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 18.24273270297876,
      "attention_bam_384_peak_intensity_mean": 0.33778244256973267,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1412821114063263,
      "attention_bam_16_std_attention": 0.5286124348640442,
      "attention_bam_16_max_attention": 2.5760138034820557,
      "attention_bam_16_min_attention": -0.9599300622940063,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5250337899763631,
      "attention_bam_16_attention_skewness": 0.6712038831297498,
      "attention_bam_16_attention_sparsity": 0.515869140625,
      "attention_bam_16_attention_concentration_10": 0.8340650557449242,
      "attention_bam_16_attention_concentration_20": 1.3359102703390875,
      "attention_bam_16_attention_center_y": 0.46489855552960524,
      "attention_bam_16_attention_center_x": 0.4637314047664514,
      "attention_bam_16_attention_center_distance": 0.07137958257265434,
      "attention_bam_16_attention_spatial_variance": 43.25954978687869,
      "attention_bam_16_attention_spatial_std": 6.577199235759753,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.28018467809368,
      "attention_bam_16_peak_intensity_mean": 0.3164559304714203,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 718,
      "phase": "train",
      "loss": 0.004773233085870743,
      "timestamp": 1759544007.8979282,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004773233085870743,
      "ssim": 0.9153580665588379,
      "attention_bam_384_mean_attention": 0.009298920631408691,
      "attention_bam_384_std_attention": 0.18311646580696106,
      "attention_bam_384_max_attention": 1.3471386432647705,
      "attention_bam_384_min_attention": -0.8956917524337769,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8922464959501526,
      "attention_bam_384_attention_skewness": 0.4329745862178503,
      "attention_bam_384_attention_sparsity": 0.7237726847330729,
      "attention_bam_384_attention_concentration_10": 3.8802186825524716,
      "attention_bam_384_attention_concentration_20": 5.941344037759108,
      "attention_bam_384_attention_center_y": 0.4829862785533486,
      "attention_bam_384_attention_center_x": 0.48304387087323086,
      "attention_bam_384_attention_center_distance": 0.033969899394255355,
      "attention_bam_384_attention_spatial_variance": 170.15838374773332,
      "attention_bam_384_attention_spatial_std": 13.044477135850762,
      "attention_bam_384_num_attention_peaks": 18,
      "attention_bam_384_peak_separation_mean": 16.436797364005688,
      "attention_bam_384_peak_intensity_mean": 0.4055769145488739,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1414925903081894,
      "attention_bam_16_std_attention": 0.5039277076721191,
      "attention_bam_16_max_attention": 2.146576404571533,
      "attention_bam_16_min_attention": -0.9929162263870239,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.14161095324250228,
      "attention_bam_16_attention_skewness": 0.5495680594525821,
      "attention_bam_16_attention_sparsity": 0.5029296875,
      "attention_bam_16_attention_concentration_10": 0.7968742150672888,
      "attention_bam_16_attention_concentration_20": 1.2807217215428646,
      "attention_bam_16_attention_center_y": 0.4650038157481252,
      "attention_bam_16_attention_center_x": 0.4639735565104637,
      "attention_bam_16_attention_center_distance": 0.07103009985486325,
      "attention_bam_16_attention_spatial_variance": 42.21685493017228,
      "attention_bam_16_attention_spatial_std": 6.497449879004245,
      "attention_bam_16_num_attention_peaks": 11,
      "attention_bam_16_peak_separation_mean": 8.639198602614233,
      "attention_bam_16_peak_intensity_mean": 0.36406704783439636,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 719,
      "phase": "train",
      "loss": 0.004085529129952192,
      "timestamp": 1759544008.0479155,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004085529129952192,
      "ssim": 0.9211371541023254,
      "attention_bam_384_mean_attention": 0.009085092693567276,
      "attention_bam_384_std_attention": 0.16531521081924438,
      "attention_bam_384_max_attention": 1.13568913936615,
      "attention_bam_384_min_attention": -0.7695770263671875,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9999425070025083,
      "attention_bam_384_attention_skewness": 0.44515532666221386,
      "attention_bam_384_attention_sparsity": 0.7405598958333334,
      "attention_bam_384_attention_concentration_10": 3.598647017881389,
      "attention_bam_384_attention_concentration_20": 5.50049581186066,
      "attention_bam_384_attention_center_y": 0.4785962566480606,
      "attention_bam_384_attention_center_x": 0.48313981355271274,
      "attention_bam_384_attention_center_distance": 0.03853274235018782,
      "attention_bam_384_attention_spatial_variance": 171.7453431977646,
      "attention_bam_384_attention_spatial_std": 13.105164752789818,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 18.277811440240832,
      "attention_bam_384_peak_intensity_mean": 0.4168229401111603,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13738320767879486,
      "attention_bam_16_std_attention": 0.4737718105316162,
      "attention_bam_16_max_attention": 2.401826858520508,
      "attention_bam_16_min_attention": -0.9559845328330994,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.3226301315715143,
      "attention_bam_16_attention_skewness": 0.5128144293453234,
      "attention_bam_16_attention_sparsity": 0.499267578125,
      "attention_bam_16_attention_concentration_10": 0.7624266090340366,
      "attention_bam_16_attention_concentration_20": 1.224331212366244,
      "attention_bam_16_attention_center_y": 0.45096599995244807,
      "attention_bam_16_attention_center_x": 0.4639597066722504,
      "attention_bam_16_attention_center_distance": 0.0860608610671954,
      "attention_bam_16_attention_spatial_variance": 43.47629483913595,
      "attention_bam_16_attention_spatial_std": 6.5936556506338695,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.91860434455595,
      "attention_bam_16_peak_intensity_mean": 0.3404752016067505,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 720,
      "phase": "train",
      "loss": 0.0028623377438634634,
      "timestamp": 1759544008.2443445,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0028623377438634634,
      "ssim": 0.9525558352470398,
      "attention_bam_384_mean_attention": 0.008368668146431446,
      "attention_bam_384_std_attention": 0.17370477318763733,
      "attention_bam_384_max_attention": 0.9863048791885376,
      "attention_bam_384_min_attention": -0.6219866871833801,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.507819412992546,
      "attention_bam_384_attention_skewness": 0.36809249594192917,
      "attention_bam_384_attention_sparsity": 0.7207387288411459,
      "attention_bam_384_attention_concentration_10": 4.011551276061943,
      "attention_bam_384_attention_concentration_20": 6.227450691754842,
      "attention_bam_384_attention_center_y": 0.4821793508690578,
      "attention_bam_384_attention_center_x": 0.48676470867867166,
      "attention_bam_384_attention_center_distance": 0.03139262562477312,
      "attention_bam_384_attention_spatial_variance": 171.5683928146128,
      "attention_bam_384_attention_spatial_std": 13.09841184322026,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 23.290224459046108,
      "attention_bam_384_peak_intensity_mean": 0.4080559313297272,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1378430873155594,
      "attention_bam_16_std_attention": 0.49067309498786926,
      "attention_bam_16_max_attention": 1.896989345550537,
      "attention_bam_16_min_attention": -0.9498719573020935,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.020483698565247455,
      "attention_bam_16_attention_skewness": 0.4924858487940245,
      "attention_bam_16_attention_sparsity": 0.510009765625,
      "attention_bam_16_attention_concentration_10": 0.7912076685934867,
      "attention_bam_16_attention_concentration_20": 1.2765782320781007,
      "attention_bam_16_attention_center_y": 0.4587478659346239,
      "attention_bam_16_attention_center_x": 0.47617583876833797,
      "attention_bam_16_attention_center_distance": 0.06736956617553642,
      "attention_bam_16_attention_spatial_variance": 43.08851200095826,
      "attention_bam_16_attention_spatial_std": 6.564184031618725,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.328889044274401,
      "attention_bam_16_peak_intensity_mean": 0.39574021100997925,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 721,
      "phase": "train",
      "loss": 0.0064885588362813,
      "timestamp": 1759544008.3982677,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0064885588362813,
      "ssim": 0.9066805839538574,
      "attention_bam_384_mean_attention": 0.007145460229367018,
      "attention_bam_384_std_attention": 0.20497283339500427,
      "attention_bam_384_max_attention": 1.5311543941497803,
      "attention_bam_384_min_attention": -0.7062687873840332,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4006722679690782,
      "attention_bam_384_attention_skewness": 0.64198967285015,
      "attention_bam_384_attention_sparsity": 0.7124786376953125,
      "attention_bam_384_attention_concentration_10": 5.718764861188716,
      "attention_bam_384_attention_concentration_20": 8.610263882472905,
      "attention_bam_384_attention_center_y": 0.48042191820243435,
      "attention_bam_384_attention_center_x": 0.48003383989771337,
      "attention_bam_384_attention_center_distance": 0.039546146110646836,
      "attention_bam_384_attention_spatial_variance": 170.21217982784222,
      "attention_bam_384_attention_spatial_std": 13.04653899805777,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 18.476151404038728,
      "attention_bam_384_peak_intensity_mean": 0.3247702717781067,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12452562153339386,
      "attention_bam_16_std_attention": 0.5644547939300537,
      "attention_bam_16_max_attention": 2.8173177242279053,
      "attention_bam_16_min_attention": -1.0450901985168457,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8129471104543171,
      "attention_bam_16_attention_skewness": 0.8645178234594098,
      "attention_bam_16_attention_sparsity": 0.54833984375,
      "attention_bam_16_attention_concentration_10": 1.0461821805891574,
      "attention_bam_16_attention_concentration_20": 1.6049564825725247,
      "attention_bam_16_attention_center_y": 0.45920152623513466,
      "attention_bam_16_attention_center_x": 0.4620178968696744,
      "attention_bam_16_attention_center_distance": 0.07883090282046873,
      "attention_bam_16_attention_spatial_variance": 42.14917372606693,
      "attention_bam_16_attention_spatial_std": 6.492239500054425,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.153477541033846,
      "attention_bam_16_peak_intensity_mean": 0.31291407346725464,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 722,
      "phase": "train",
      "loss": 0.004215231630951166,
      "timestamp": 1759544008.5497804,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004215231630951166,
      "ssim": 0.9135507941246033,
      "attention_bam_384_mean_attention": 0.006205521058291197,
      "attention_bam_384_std_attention": 0.18189038336277008,
      "attention_bam_384_max_attention": 1.3042190074920654,
      "attention_bam_384_min_attention": -0.7111921906471252,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5080642925100487,
      "attention_bam_384_attention_skewness": 0.3776887384819219,
      "attention_bam_384_attention_sparsity": 0.7154769897460938,
      "attention_bam_384_attention_concentration_10": 5.625747509329661,
      "attention_bam_384_attention_concentration_20": 8.72369941198209,
      "attention_bam_384_attention_center_y": 0.48429555157004156,
      "attention_bam_384_attention_center_x": 0.48137543076548434,
      "attention_bam_384_attention_center_distance": 0.03445299057151618,
      "attention_bam_384_attention_spatial_variance": 172.6525413780167,
      "attention_bam_384_attention_spatial_std": 13.13973140433307,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 19.092992199700543,
      "attention_bam_384_peak_intensity_mean": 0.3590688705444336,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1380080133676529,
      "attention_bam_16_std_attention": 0.5108175873756409,
      "attention_bam_16_max_attention": 2.2592689990997314,
      "attention_bam_16_min_attention": -1.0279148817062378,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.08147591044025582,
      "attention_bam_16_attention_skewness": 0.5463601411790929,
      "attention_bam_16_attention_sparsity": 0.50830078125,
      "attention_bam_16_attention_concentration_10": 0.8206984761926782,
      "attention_bam_16_attention_concentration_20": 1.3175597504334453,
      "attention_bam_16_attention_center_y": 0.475041547502607,
      "attention_bam_16_attention_center_x": 0.46239735612754135,
      "attention_bam_16_attention_center_distance": 0.06382606328551955,
      "attention_bam_16_attention_spatial_variance": 44.15593263396891,
      "attention_bam_16_attention_spatial_std": 6.644993049956404,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 11.176794500141144,
      "attention_bam_16_peak_intensity_mean": 0.3636050522327423,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 723,
      "phase": "train",
      "loss": 0.0037352731451392174,
      "timestamp": 1759544008.6928022,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0037352731451392174,
      "ssim": 0.9317649006843567,
      "attention_bam_384_mean_attention": 0.007142122369259596,
      "attention_bam_384_std_attention": 0.1945648044347763,
      "attention_bam_384_max_attention": 1.3142614364624023,
      "attention_bam_384_min_attention": -0.8019317388534546,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.880839715813404,
      "attention_bam_384_attention_skewness": 0.4304653225129082,
      "attention_bam_384_attention_sparsity": 0.7043202718098959,
      "attention_bam_384_attention_concentration_10": 5.265971282911128,
      "attention_bam_384_attention_concentration_20": 8.047028333756584,
      "attention_bam_384_attention_center_y": 0.4812681433455621,
      "attention_bam_384_attention_center_x": 0.4809837851467244,
      "attention_bam_384_attention_center_distance": 0.03774914253511854,
      "attention_bam_384_attention_spatial_variance": 172.2168832038178,
      "attention_bam_384_attention_spatial_std": 13.123143038305184,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 17.924986895925905,
      "attention_bam_384_peak_intensity_mean": 0.3883460760116577,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13279443979263306,
      "attention_bam_16_std_attention": 0.5478447079658508,
      "attention_bam_16_max_attention": 2.511569023132324,
      "attention_bam_16_min_attention": -1.079542636871338,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.4303286839727867,
      "attention_bam_16_attention_skewness": 0.6511663294540471,
      "attention_bam_16_attention_sparsity": 0.518310546875,
      "attention_bam_16_attention_concentration_10": 0.918443584831949,
      "attention_bam_16_attention_concentration_20": 1.4482210096052242,
      "attention_bam_16_attention_center_y": 0.4581751166957852,
      "attention_bam_16_attention_center_x": 0.460244122879809,
      "attention_bam_16_attention_center_distance": 0.08160699270291626,
      "attention_bam_16_attention_spatial_variance": 43.43177483125075,
      "attention_bam_16_attention_spatial_std": 6.5902788128614676,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.478170804702087,
      "attention_bam_16_peak_intensity_mean": 0.34772390127182007,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 724,
      "phase": "train",
      "loss": 0.004716108553111553,
      "timestamp": 1759544008.8568614,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004716108553111553,
      "ssim": 0.9314906597137451,
      "attention_bam_384_mean_attention": 0.004963966086506844,
      "attention_bam_384_std_attention": 0.19485121965408325,
      "attention_bam_384_max_attention": 1.9294102191925049,
      "attention_bam_384_min_attention": -0.782325029373169,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 3.1858444267948487,
      "attention_bam_384_attention_skewness": 0.8763896567742013,
      "attention_bam_384_attention_sparsity": 0.732879638671875,
      "attention_bam_384_attention_concentration_10": 7.801281971865819,
      "attention_bam_384_attention_concentration_20": 11.498468735568876,
      "attention_bam_384_attention_center_y": 0.4839987296896095,
      "attention_bam_384_attention_center_x": 0.48410140411885616,
      "attention_bam_384_attention_center_distance": 0.031900031427511424,
      "attention_bam_384_attention_spatial_variance": 171.51493955320586,
      "attention_bam_384_attention_spatial_std": 13.096371236079323,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 19.43108430699766,
      "attention_bam_384_peak_intensity_mean": 0.2943565547466278,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12925705313682556,
      "attention_bam_16_std_attention": 0.5496500730514526,
      "attention_bam_16_max_attention": 3.404736280441284,
      "attention_bam_16_min_attention": -1.0511484146118164,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.182599261732727,
      "attention_bam_16_attention_skewness": 1.0384147388355929,
      "attention_bam_16_attention_sparsity": 0.532470703125,
      "attention_bam_16_attention_concentration_10": 0.9685452210682868,
      "attention_bam_16_attention_concentration_20": 1.4816735517331143,
      "attention_bam_16_attention_center_y": 0.47066659154351936,
      "attention_bam_16_attention_center_x": 0.4701155304109618,
      "attention_bam_16_attention_center_distance": 0.059220441982357354,
      "attention_bam_16_attention_spatial_variance": 43.08400071422824,
      "attention_bam_16_attention_spatial_std": 6.5638403937198415,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.661820529901222,
      "attention_bam_16_peak_intensity_mean": 0.26967841386795044,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 725,
      "phase": "train",
      "loss": 0.00491876807063818,
      "timestamp": 1759544009.0336018,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00491876807063818,
      "ssim": 0.9032551050186157,
      "attention_bam_384_mean_attention": 0.004038340877741575,
      "attention_bam_384_std_attention": 0.19355596601963043,
      "attention_bam_384_max_attention": 1.4541429281234741,
      "attention_bam_384_min_attention": -0.909542441368103,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.458917372982964,
      "attention_bam_384_attention_skewness": 0.6309801753158306,
      "attention_bam_384_attention_sparsity": 0.7258809407552084,
      "attention_bam_384_attention_concentration_10": 9.472106574719765,
      "attention_bam_384_attention_concentration_20": 14.248370784155474,
      "attention_bam_384_attention_center_y": 0.478332827673493,
      "attention_bam_384_attention_center_x": 0.48231533036509594,
      "attention_bam_384_attention_center_distance": 0.0395528481078733,
      "attention_bam_384_attention_spatial_variance": 171.38190224381182,
      "attention_bam_384_attention_spatial_std": 13.091291083915742,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 16.745201413392437,
      "attention_bam_384_peak_intensity_mean": 0.39423394203186035,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13183635473251343,
      "attention_bam_16_std_attention": 0.5356624126434326,
      "attention_bam_16_max_attention": 3.0727217197418213,
      "attention_bam_16_min_attention": -1.0695233345031738,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7881098249997445,
      "attention_bam_16_attention_skewness": 0.773938136696763,
      "attention_bam_16_attention_sparsity": 0.52685546875,
      "attention_bam_16_attention_concentration_10": 0.9180610141489878,
      "attention_bam_16_attention_concentration_20": 1.4391229365960003,
      "attention_bam_16_attention_center_y": 0.4520493879566438,
      "attention_bam_16_attention_center_x": 0.4600957263670714,
      "attention_bam_16_attention_center_distance": 0.08822258497124301,
      "attention_bam_16_attention_spatial_variance": 42.84033319874507,
      "attention_bam_16_attention_spatial_std": 6.545252722297671,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 8.954651674006293,
      "attention_bam_16_peak_intensity_mean": 0.30148011445999146,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 726,
      "phase": "train",
      "loss": 0.004079168662428856,
      "timestamp": 1759544009.208905,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004079168662428856,
      "ssim": 0.9284377694129944,
      "attention_bam_384_mean_attention": 0.0010803197510540485,
      "attention_bam_384_std_attention": 0.14924249053001404,
      "attention_bam_384_max_attention": 1.2573977708816528,
      "attention_bam_384_min_attention": -0.6728956699371338,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.015472329521459,
      "attention_bam_384_attention_skewness": 0.4565209302368259,
      "attention_bam_384_attention_sparsity": 0.7652460734049479,
      "attention_bam_384_attention_concentration_10": 26.28280636446634,
      "attention_bam_384_attention_concentration_20": 40.11489923549662,
      "attention_bam_384_attention_center_y": 0.47737933983621994,
      "attention_bam_384_attention_center_x": 0.48894658573873206,
      "attention_bam_384_attention_center_distance": 0.03560539939605867,
      "attention_bam_384_attention_spatial_variance": 171.18283982452684,
      "attention_bam_384_attention_spatial_std": 13.08368601826438,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 19.078227528361356,
      "attention_bam_384_peak_intensity_mean": 0.3592112362384796,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14561787247657776,
      "attention_bam_16_std_attention": 0.45347893238067627,
      "attention_bam_16_max_attention": 2.174515962600708,
      "attention_bam_16_min_attention": -1.098393201828003,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.4364706455971845,
      "attention_bam_16_attention_skewness": 0.5772409514314218,
      "attention_bam_16_attention_sparsity": 0.50390625,
      "attention_bam_16_attention_concentration_10": 0.7073806441591346,
      "attention_bam_16_attention_concentration_20": 1.1332477167299577,
      "attention_bam_16_attention_center_y": 0.44870871384261324,
      "attention_bam_16_attention_center_x": 0.4833825316537173,
      "attention_bam_16_attention_center_distance": 0.07624875461171339,
      "attention_bam_16_attention_spatial_variance": 42.46732334209101,
      "attention_bam_16_attention_spatial_std": 6.516695738032505,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.345317370145803,
      "attention_bam_16_peak_intensity_mean": 0.39433786273002625,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 727,
      "phase": "train",
      "loss": 0.004430423956364393,
      "timestamp": 1759544009.3751037,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004430423956364393,
      "ssim": 0.9241023659706116,
      "attention_bam_384_mean_attention": -0.0029518231749534607,
      "attention_bam_384_std_attention": 0.14219456911087036,
      "attention_bam_384_max_attention": 1.1349691152572632,
      "attention_bam_384_min_attention": -0.6223880052566528,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9120757988421153,
      "attention_bam_384_attention_skewness": 0.32400482334791186,
      "attention_bam_384_attention_sparsity": 0.787017822265625,
      "attention_bam_384_attention_concentration_10": -8.900731220434746,
      "attention_bam_384_attention_concentration_20": -13.58924026628768,
      "attention_bam_384_attention_center_y": 0.48018490843844186,
      "attention_bam_384_attention_center_x": 0.4903586916793335,
      "attention_bam_384_attention_center_distance": 0.03116384699381916,
      "attention_bam_384_attention_spatial_variance": 172.0216748020443,
      "attention_bam_384_attention_spatial_std": 13.115703366653436,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 16.31188559633005,
      "attention_bam_384_peak_intensity_mean": 0.3595867156982422,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14713503420352936,
      "attention_bam_16_std_attention": 0.455740362405777,
      "attention_bam_16_max_attention": 2.2218971252441406,
      "attention_bam_16_min_attention": -0.9605342149734497,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.27099261641071903,
      "attention_bam_16_attention_skewness": 0.5029357317322136,
      "attention_bam_16_attention_sparsity": 0.49267578125,
      "attention_bam_16_attention_concentration_10": 0.6986745580351688,
      "attention_bam_16_attention_concentration_20": 1.1241362093338276,
      "attention_bam_16_attention_center_y": 0.45702414859706975,
      "attention_bam_16_attention_center_x": 0.4865216041927101,
      "attention_bam_16_attention_center_distance": 0.0636960117643909,
      "attention_bam_16_attention_spatial_variance": 44.29236288189885,
      "attention_bam_16_attention_spatial_std": 6.65525077528254,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.020986211725619,
      "attention_bam_16_peak_intensity_mean": 0.3518311083316803,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 728,
      "phase": "train",
      "loss": 0.016564728692173958,
      "timestamp": 1759544009.542726,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.016564728692173958,
      "ssim": 0.8482910394668579,
      "attention_bam_384_mean_attention": 0.0006913500837981701,
      "attention_bam_384_std_attention": 0.18331493437290192,
      "attention_bam_384_max_attention": 1.455594539642334,
      "attention_bam_384_min_attention": -0.8051329851150513,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.7105938093782234,
      "attention_bam_384_attention_skewness": 0.6689280097362176,
      "attention_bam_384_attention_sparsity": 0.7356236775716146,
      "attention_bam_384_attention_concentration_10": 51.543660299016246,
      "attention_bam_384_attention_concentration_20": 76.99026467900704,
      "attention_bam_384_attention_center_y": 0.48436823792543193,
      "attention_bam_384_attention_center_x": 0.48057078648386786,
      "attention_bam_384_attention_center_distance": 0.035266026808001956,
      "attention_bam_384_attention_spatial_variance": 171.46073033652283,
      "attention_bam_384_attention_spatial_std": 13.0943014451525,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 18.0504930856567,
      "attention_bam_384_peak_intensity_mean": 0.360777884721756,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.11692135781049728,
      "attention_bam_16_std_attention": 0.4992809295654297,
      "attention_bam_16_max_attention": 2.9352385997772217,
      "attention_bam_16_min_attention": -0.9797711968421936,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.818080374386632,
      "attention_bam_16_attention_skewness": 0.9182103970632004,
      "attention_bam_16_attention_sparsity": 0.53271484375,
      "attention_bam_16_attention_concentration_10": 0.9545263057616764,
      "attention_bam_16_attention_concentration_20": 1.4763304391946608,
      "attention_bam_16_attention_center_y": 0.4752382609126168,
      "attention_bam_16_attention_center_x": 0.4599434515100886,
      "attention_bam_16_attention_center_distance": 0.06659836033351371,
      "attention_bam_16_attention_spatial_variance": 43.01868165286735,
      "attention_bam_16_attention_spatial_std": 6.5588628322955005,
      "attention_bam_16_num_attention_peaks": 12,
      "attention_bam_16_peak_separation_mean": 8.953680579679737,
      "attention_bam_16_peak_intensity_mean": 0.28590407967567444,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 729,
      "phase": "train",
      "loss": 0.00368168274872005,
      "timestamp": 1759544009.7071717,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00368168274872005,
      "ssim": 0.9467307925224304,
      "attention_bam_384_mean_attention": -0.005955860018730164,
      "attention_bam_384_std_attention": 0.1632673144340515,
      "attention_bam_384_max_attention": 0.9748106002807617,
      "attention_bam_384_min_attention": -0.650646984577179,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.578963099657464,
      "attention_bam_384_attention_skewness": 0.3535599906654036,
      "attention_bam_384_attention_sparsity": 0.7602640787760416,
      "attention_bam_384_attention_concentration_10": -5.062603778106855,
      "attention_bam_384_attention_concentration_20": -7.703450915865374,
      "attention_bam_384_attention_center_y": 0.4796776397099283,
      "attention_bam_384_attention_center_x": 0.48461596554899544,
      "attention_bam_384_attention_center_distance": 0.036046271478453275,
      "attention_bam_384_attention_spatial_variance": 171.7488986945872,
      "attention_bam_384_attention_spatial_std": 13.10530040459154,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 20.26078999511248,
      "attention_bam_384_peak_intensity_mean": 0.40445777773857117,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14303219318389893,
      "attention_bam_16_std_attention": 0.49334314465522766,
      "attention_bam_16_max_attention": 1.9856328964233398,
      "attention_bam_16_min_attention": -0.9571231603622437,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.08807033424479238,
      "attention_bam_16_attention_skewness": 0.49125684974859235,
      "attention_bam_16_attention_sparsity": 0.506591796875,
      "attention_bam_16_attention_concentration_10": 0.7678573660879019,
      "attention_bam_16_attention_concentration_20": 1.2415238768924997,
      "attention_bam_16_attention_center_y": 0.4498836603842622,
      "attention_bam_16_attention_center_x": 0.47089841191453286,
      "attention_bam_16_attention_center_distance": 0.08195791512204507,
      "attention_bam_16_attention_spatial_variance": 43.314088597745496,
      "attention_bam_16_attention_spatial_std": 6.581343981114002,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 10.398638097210327,
      "attention_bam_16_peak_intensity_mean": 0.38588106632232666,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 730,
      "phase": "train",
      "loss": 0.0037052601110190153,
      "timestamp": 1759544009.9089267,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0037052601110190153,
      "ssim": 0.9308886528015137,
      "attention_bam_384_mean_attention": -0.005332041997462511,
      "attention_bam_384_std_attention": 0.18992313742637634,
      "attention_bam_384_max_attention": 1.267246127128601,
      "attention_bam_384_min_attention": -0.7948634028434753,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9252016279217279,
      "attention_bam_384_attention_skewness": 0.4013662269814022,
      "attention_bam_384_attention_sparsity": 0.7332941691080729,
      "attention_bam_384_attention_concentration_10": -6.629326182180711,
      "attention_bam_384_attention_concentration_20": -10.043801624551344,
      "attention_bam_384_attention_center_y": 0.48218461856771694,
      "attention_bam_384_attention_center_x": 0.4801488551606297,
      "attention_bam_384_attention_center_distance": 0.03772149962584715,
      "attention_bam_384_attention_spatial_variance": 172.02037411889918,
      "attention_bam_384_attention_spatial_std": 13.115653781603843,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 21.638109929381976,
      "attention_bam_384_peak_intensity_mean": 0.38947558403015137,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13182130455970764,
      "attention_bam_16_std_attention": 0.5578742027282715,
      "attention_bam_16_max_attention": 2.421940326690674,
      "attention_bam_16_min_attention": -1.0333722829818726,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.2716285742821536,
      "attention_bam_16_attention_skewness": 0.6679697656821201,
      "attention_bam_16_attention_sparsity": 0.525634765625,
      "attention_bam_16_attention_concentration_10": 0.9499630243975962,
      "attention_bam_16_attention_concentration_20": 1.5034899028453983,
      "attention_bam_16_attention_center_y": 0.463021012829333,
      "attention_bam_16_attention_center_x": 0.4548517623986901,
      "attention_bam_16_attention_center_distance": 0.0825325251118938,
      "attention_bam_16_attention_spatial_variance": 43.65293649377077,
      "attention_bam_16_attention_spatial_std": 6.607036892115161,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.93912336616083,
      "attention_bam_16_peak_intensity_mean": 0.33819660544395447,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 731,
      "phase": "train",
      "loss": 0.006955425720661879,
      "timestamp": 1759544010.0694559,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006955425720661879,
      "ssim": 0.9129009246826172,
      "attention_bam_384_mean_attention": -0.006558053195476532,
      "attention_bam_384_std_attention": 0.16945770382881165,
      "attention_bam_384_max_attention": 1.2840077877044678,
      "attention_bam_384_min_attention": -0.6702179908752441,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.4633624916655794,
      "attention_bam_384_attention_skewness": 0.1325826039084778,
      "attention_bam_384_attention_sparsity": 0.7444025675455729,
      "attention_bam_384_attention_concentration_10": -4.517193872216518,
      "attention_bam_384_attention_concentration_20": -7.029535098021254,
      "attention_bam_384_attention_center_y": 0.48472062952687633,
      "attention_bam_384_attention_center_x": 0.4798208040346891,
      "attention_bam_384_attention_center_distance": 0.03579550563580249,
      "attention_bam_384_attention_spatial_variance": 172.8809756590114,
      "attention_bam_384_attention_spatial_std": 13.148421032922979,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 19.558579674952924,
      "attention_bam_384_peak_intensity_mean": 0.3456921875476837,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1494637429714203,
      "attention_bam_16_std_attention": 0.5075071454048157,
      "attention_bam_16_max_attention": 2.5798912048339844,
      "attention_bam_16_min_attention": -1.0430694818496704,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.02225610898300534,
      "attention_bam_16_attention_skewness": 0.3642077881115696,
      "attention_bam_16_attention_sparsity": 0.48046875,
      "attention_bam_16_attention_concentration_10": 0.7280683948643738,
      "attention_bam_16_attention_concentration_20": 1.1913491085154235,
      "attention_bam_16_attention_center_y": 0.4700530549271929,
      "attention_bam_16_attention_center_x": 0.45437327118389265,
      "attention_bam_16_attention_center_distance": 0.07718313159819735,
      "attention_bam_16_attention_spatial_variance": 43.91786579949011,
      "attention_bam_16_attention_spatial_std": 6.627055590493422,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 10.202159020677565,
      "attention_bam_16_peak_intensity_mean": 0.3409819006919861,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 732,
      "phase": "train",
      "loss": 0.0035418528132140636,
      "timestamp": 1759544010.2244616,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0035418528132140636,
      "ssim": 0.9414119720458984,
      "attention_bam_384_mean_attention": -0.007043847814202309,
      "attention_bam_384_std_attention": 0.17254531383514404,
      "attention_bam_384_max_attention": 1.0545003414154053,
      "attention_bam_384_min_attention": -0.7414365410804749,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.4808012160006143,
      "attention_bam_384_attention_skewness": 0.3658647351051037,
      "attention_bam_384_attention_sparsity": 0.7458674112955729,
      "attention_bam_384_attention_concentration_10": -4.485651055366034,
      "attention_bam_384_attention_concentration_20": -6.9073381007821855,
      "attention_bam_384_attention_center_y": 0.48338639547088796,
      "attention_bam_384_attention_center_x": 0.4817218177986218,
      "attention_bam_384_attention_center_distance": 0.034931470053134364,
      "attention_bam_384_attention_spatial_variance": 171.11998893181675,
      "attention_bam_384_attention_spatial_std": 13.081283917560109,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 17.20748807690046,
      "attention_bam_384_peak_intensity_mean": 0.41578415036201477,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1456136405467987,
      "attention_bam_16_std_attention": 0.5185186266899109,
      "attention_bam_16_max_attention": 2.3149490356445312,
      "attention_bam_16_min_attention": -1.1224271059036255,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.19055556502303084,
      "attention_bam_16_attention_skewness": 0.5672829651149366,
      "attention_bam_16_attention_sparsity": 0.514892578125,
      "attention_bam_16_attention_concentration_10": 0.7866889835547022,
      "attention_bam_16_attention_concentration_20": 1.2709638981338827,
      "attention_bam_16_attention_center_y": 0.4677699296949396,
      "attention_bam_16_attention_center_x": 0.4613788072686186,
      "attention_bam_16_attention_center_distance": 0.07113893392318509,
      "attention_bam_16_attention_spatial_variance": 42.510598409501064,
      "attention_bam_16_attention_spatial_std": 6.520015215434782,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 10.697562844308669,
      "attention_bam_16_peak_intensity_mean": 0.3834080100059509,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 733,
      "phase": "train",
      "loss": 0.0030240719206631184,
      "timestamp": 1759544010.3790643,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0030240719206631184,
      "ssim": 0.9475955367088318,
      "attention_bam_384_mean_attention": -0.009621940553188324,
      "attention_bam_384_std_attention": 0.19029651582241058,
      "attention_bam_384_max_attention": 1.2311017513275146,
      "attention_bam_384_min_attention": -0.7249237298965454,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.4716344898798366,
      "attention_bam_384_attention_skewness": 0.34397793688722755,
      "attention_bam_384_attention_sparsity": 0.7328414916992188,
      "attention_bam_384_attention_concentration_10": -3.590947279586086,
      "attention_bam_384_attention_concentration_20": -5.5050978175586,
      "attention_bam_384_attention_center_y": 0.4774460329222966,
      "attention_bam_384_attention_center_x": 0.4780343077395155,
      "attention_bam_384_attention_center_distance": 0.04452354584766218,
      "attention_bam_384_attention_spatial_variance": 170.2563637284015,
      "attention_bam_384_attention_spatial_std": 13.048232207023352,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 18.974328293400543,
      "attention_bam_384_peak_intensity_mean": 0.37487542629241943,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13061706721782684,
      "attention_bam_16_std_attention": 0.5579000115394592,
      "attention_bam_16_max_attention": 2.2164902687072754,
      "attention_bam_16_min_attention": -1.0808167457580566,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.025759598249790905,
      "attention_bam_16_attention_skewness": 0.549225213818866,
      "attention_bam_16_attention_sparsity": 0.513427734375,
      "attention_bam_16_attention_concentration_10": 0.9302933536439794,
      "attention_bam_16_attention_concentration_20": 1.4980560860442802,
      "attention_bam_16_attention_center_y": 0.44872973596935634,
      "attention_bam_16_attention_center_x": 0.45434454119410367,
      "attention_bam_16_attention_center_distance": 0.09708821651002567,
      "attention_bam_16_attention_spatial_variance": 42.48511523932601,
      "attention_bam_16_attention_spatial_std": 6.518060696198372,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.123228324705618,
      "attention_bam_16_peak_intensity_mean": 0.367720365524292,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 734,
      "phase": "train",
      "loss": 0.002735838992521167,
      "timestamp": 1759544010.5399814,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.002735838992521167,
      "ssim": 0.9531092643737793,
      "attention_bam_384_mean_attention": -0.009141591377556324,
      "attention_bam_384_std_attention": 0.1928679347038269,
      "attention_bam_384_max_attention": 1.150294303894043,
      "attention_bam_384_min_attention": -0.6629476547241211,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.017902245969165786,
      "attention_bam_384_attention_skewness": 0.25431635041896067,
      "attention_bam_384_attention_sparsity": 0.7154388427734375,
      "attention_bam_384_attention_concentration_10": -3.736860722047533,
      "attention_bam_384_attention_concentration_20": -5.891706111389968,
      "attention_bam_384_attention_center_y": 0.4848497894830881,
      "attention_bam_384_attention_center_x": 0.48354720499391857,
      "attention_bam_384_attention_center_distance": 0.031629838514253786,
      "attention_bam_384_attention_spatial_variance": 172.30353883092485,
      "attention_bam_384_attention_spatial_std": 13.12644425695416,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 19.669252110440063,
      "attention_bam_384_peak_intensity_mean": 0.37480735778808594,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13377265632152557,
      "attention_bam_16_std_attention": 0.5486071109771729,
      "attention_bam_16_max_attention": 2.116332769393921,
      "attention_bam_16_min_attention": -0.976469874382019,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.3456682670689961,
      "attention_bam_16_attention_skewness": 0.44535623192652607,
      "attention_bam_16_attention_sparsity": 0.52099609375,
      "attention_bam_16_attention_concentration_10": 0.8735947242957701,
      "attention_bam_16_attention_concentration_20": 1.439438737389115,
      "attention_bam_16_attention_center_y": 0.4650538978147794,
      "attention_bam_16_attention_center_x": 0.4678832591320051,
      "attention_bam_16_attention_center_distance": 0.06712250147188811,
      "attention_bam_16_attention_spatial_variance": 43.454479816456704,
      "attention_bam_16_attention_spatial_std": 6.592001199670454,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.559927794608935,
      "attention_bam_16_peak_intensity_mean": 0.3820931911468506,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 735,
      "phase": "train",
      "loss": 0.004593938589096069,
      "timestamp": 1759544010.7106514,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004593938589096069,
      "ssim": 0.920300304889679,
      "attention_bam_384_mean_attention": -0.008372162468731403,
      "attention_bam_384_std_attention": 0.17303377389907837,
      "attention_bam_384_max_attention": 0.958859384059906,
      "attention_bam_384_min_attention": -0.6788896322250366,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.19027589361796382,
      "attention_bam_384_attention_skewness": 0.32542896718618614,
      "attention_bam_384_attention_sparsity": 0.7459259033203125,
      "attention_bam_384_attention_concentration_10": -3.7633157702190623,
      "attention_bam_384_attention_concentration_20": -5.8321409353505675,
      "attention_bam_384_attention_center_y": 0.49073329744311023,
      "attention_bam_384_attention_center_x": 0.4795292370604599,
      "attention_bam_384_attention_center_distance": 0.03177810288877281,
      "attention_bam_384_attention_spatial_variance": 169.18036153900536,
      "attention_bam_384_attention_spatial_std": 13.00693513242091,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 19.674997733947723,
      "attention_bam_384_peak_intensity_mean": 0.4174734652042389,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12058200687170029,
      "attention_bam_16_std_attention": 0.5117862224578857,
      "attention_bam_16_max_attention": 2.0017409324645996,
      "attention_bam_16_min_attention": -0.9474955797195435,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.03883576262436739,
      "attention_bam_16_attention_skewness": 0.5504116693096602,
      "attention_bam_16_attention_sparsity": 0.528076171875,
      "attention_bam_16_attention_concentration_10": 0.9301073890014641,
      "attention_bam_16_attention_concentration_20": 1.4864628515224911,
      "attention_bam_16_attention_center_y": 0.4898110881346563,
      "attention_bam_16_attention_center_x": 0.45178514368591527,
      "attention_bam_16_attention_center_distance": 0.06969198367656897,
      "attention_bam_16_attention_spatial_variance": 40.884785070468624,
      "attention_bam_16_attention_spatial_std": 6.394121133546707,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.154574775243532,
      "attention_bam_16_peak_intensity_mean": 0.36866626143455505,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 736,
      "phase": "train",
      "loss": 0.0031804065220057964,
      "timestamp": 1759544010.8599987,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0031804065220057964,
      "ssim": 0.9410101175308228,
      "attention_bam_384_mean_attention": -0.007650876883417368,
      "attention_bam_384_std_attention": 0.1908082515001297,
      "attention_bam_384_max_attention": 1.5718623399734497,
      "attention_bam_384_min_attention": -0.8701921701431274,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.6090641149471425,
      "attention_bam_384_attention_skewness": 0.46552557514804993,
      "attention_bam_384_attention_sparsity": 0.7422103881835938,
      "attention_bam_384_attention_concentration_10": -4.578846671983798,
      "attention_bam_384_attention_concentration_20": -6.874105140171844,
      "attention_bam_384_attention_center_y": 0.48529040536075346,
      "attention_bam_384_attention_center_x": 0.4825135123352246,
      "attention_bam_384_attention_center_distance": 0.03231561310887641,
      "attention_bam_384_attention_spatial_variance": 171.49485532881386,
      "attention_bam_384_attention_spatial_std": 13.09560442777705,
      "attention_bam_384_num_attention_peaks": 18,
      "attention_bam_384_peak_separation_mean": 19.160019524156194,
      "attention_bam_384_peak_intensity_mean": 0.3606841266155243,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.15227095782756805,
      "attention_bam_16_std_attention": 0.554970383644104,
      "attention_bam_16_max_attention": 3.192051887512207,
      "attention_bam_16_min_attention": -1.084247350692749,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.38096253079678,
      "attention_bam_16_attention_skewness": 0.7428071601372647,
      "attention_bam_16_attention_sparsity": 0.49755859375,
      "attention_bam_16_attention_concentration_10": 0.8074838744524836,
      "attention_bam_16_attention_concentration_20": 1.2817164870853341,
      "attention_bam_16_attention_center_y": 0.4722672134467127,
      "attention_bam_16_attention_center_x": 0.4637132004675355,
      "attention_bam_16_attention_center_distance": 0.064588532578461,
      "attention_bam_16_attention_spatial_variance": 42.99221284970086,
      "attention_bam_16_attention_spatial_std": 6.556844732773597,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.436126200083084,
      "attention_bam_16_peak_intensity_mean": 0.29308897256851196,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 737,
      "phase": "train",
      "loss": 0.0028265926521271467,
      "timestamp": 1759544011.011244,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0028265926521271467,
      "ssim": 0.9426215291023254,
      "attention_bam_384_mean_attention": -0.009977607987821102,
      "attention_bam_384_std_attention": 0.15460868179798126,
      "attention_bam_384_max_attention": 1.2537157535552979,
      "attention_bam_384_min_attention": -0.6202364563941956,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8203860643429528,
      "attention_bam_384_attention_skewness": 0.3060123276005816,
      "attention_bam_384_attention_sparsity": 0.7881724039713541,
      "attention_bam_384_attention_concentration_10": -2.826961910486337,
      "attention_bam_384_attention_concentration_20": -4.255137020942251,
      "attention_bam_384_attention_center_y": 0.4785682270056371,
      "attention_bam_384_attention_center_x": 0.48181143499644974,
      "attention_bam_384_attention_center_distance": 0.039752856263928396,
      "attention_bam_384_attention_spatial_variance": 170.32287309449595,
      "attention_bam_384_attention_spatial_std": 13.05078055498965,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 17.689636530150423,
      "attention_bam_384_peak_intensity_mean": 0.33645883202552795,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13955819606781006,
      "attention_bam_16_std_attention": 0.480998694896698,
      "attention_bam_16_max_attention": 2.3177709579467773,
      "attention_bam_16_min_attention": -0.9649261236190796,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.40139661169527807,
      "attention_bam_16_attention_skewness": 0.5612473777078234,
      "attention_bam_16_attention_sparsity": 0.504150390625,
      "attention_bam_16_attention_concentration_10": 0.7717145910128865,
      "attention_bam_16_attention_concentration_20": 1.2329255854619758,
      "attention_bam_16_attention_center_y": 0.44859686236562896,
      "attention_bam_16_attention_center_x": 0.46548724696458166,
      "attention_bam_16_attention_center_distance": 0.08756040978366729,
      "attention_bam_16_attention_spatial_variance": 41.71903144482311,
      "attention_bam_16_attention_spatial_std": 6.459027128354789,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.706104764563074,
      "attention_bam_16_peak_intensity_mean": 0.36537501215934753,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 738,
      "phase": "train",
      "loss": 0.007358144503086805,
      "timestamp": 1759544011.1622622,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007358144503086805,
      "ssim": 0.9183666706085205,
      "attention_bam_384_mean_attention": -0.01048105675727129,
      "attention_bam_384_std_attention": 0.17136909067630768,
      "attention_bam_384_max_attention": 1.2962770462036133,
      "attention_bam_384_min_attention": -0.672452449798584,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1713832484153182,
      "attention_bam_384_attention_skewness": 0.511962561047085,
      "attention_bam_384_attention_sparsity": 0.7609685262044271,
      "attention_bam_384_attention_concentration_10": -3.015328307865346,
      "attention_bam_384_attention_concentration_20": -4.539665245823389,
      "attention_bam_384_attention_center_y": 0.4863061874491685,
      "attention_bam_384_attention_center_x": 0.4812489780548884,
      "attention_bam_384_attention_center_distance": 0.03283660537154737,
      "attention_bam_384_attention_spatial_variance": 172.27662403749702,
      "attention_bam_384_attention_spatial_std": 13.125419004264092,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 19.872034332996687,
      "attention_bam_384_peak_intensity_mean": 0.3452087938785553,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13119488954544067,
      "attention_bam_16_std_attention": 0.5270481109619141,
      "attention_bam_16_max_attention": 3.017179489135742,
      "attention_bam_16_min_attention": -1.0005669593811035,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8869522275904242,
      "attention_bam_16_attention_skewness": 0.7632660185509996,
      "attention_bam_16_attention_sparsity": 0.52197265625,
      "attention_bam_16_attention_concentration_10": 0.8950942375979741,
      "attention_bam_16_attention_concentration_20": 1.4171567658413706,
      "attention_bam_16_attention_center_y": 0.4799661082139476,
      "attention_bam_16_attention_center_x": 0.4517085168689336,
      "attention_bam_16_attention_center_distance": 0.0739381385090716,
      "attention_bam_16_attention_spatial_variance": 43.12197937512061,
      "attention_bam_16_attention_spatial_std": 6.566732777806678,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.478559203679282,
      "attention_bam_16_peak_intensity_mean": 0.2954232394695282,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 739,
      "phase": "train",
      "loss": 0.004258250817656517,
      "timestamp": 1759544011.3153253,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004258250817656517,
      "ssim": 0.922539472579956,
      "attention_bam_384_mean_attention": -0.008970784954726696,
      "attention_bam_384_std_attention": 0.18770454823970795,
      "attention_bam_384_max_attention": 1.2934402227401733,
      "attention_bam_384_min_attention": -0.7899969816207886,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5657318366291215,
      "attention_bam_384_attention_skewness": 0.3344863674498097,
      "attention_bam_384_attention_sparsity": 0.7321904500325521,
      "attention_bam_384_attention_concentration_10": -3.795673725791916,
      "attention_bam_384_attention_concentration_20": -5.79867695243905,
      "attention_bam_384_attention_center_y": 0.4802296929502922,
      "attention_bam_384_attention_center_x": 0.48533257924355305,
      "attention_bam_384_attention_center_distance": 0.03481374074949073,
      "attention_bam_384_attention_spatial_variance": 170.43134101943042,
      "attention_bam_384_attention_spatial_std": 13.054935504223314,
      "attention_bam_384_num_attention_peaks": 18,
      "attention_bam_384_peak_separation_mean": 16.766047320731868,
      "attention_bam_384_peak_intensity_mean": 0.385729044675827,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13756972551345825,
      "attention_bam_16_std_attention": 0.5462672710418701,
      "attention_bam_16_max_attention": 2.387242078781128,
      "attention_bam_16_min_attention": -1.027768850326538,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.12982167931586464,
      "attention_bam_16_attention_skewness": 0.6316222516158847,
      "attention_bam_16_attention_sparsity": 0.519775390625,
      "attention_bam_16_attention_concentration_10": 0.8891649050528998,
      "attention_bam_16_attention_concentration_20": 1.4185414921606094,
      "attention_bam_16_attention_center_y": 0.46410326971185467,
      "attention_bam_16_attention_center_x": 0.4753546089124766,
      "attention_bam_16_attention_center_distance": 0.061578738980866236,
      "attention_bam_16_attention_spatial_variance": 42.67232894149916,
      "attention_bam_16_attention_spatial_std": 6.532406060671608,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.721247359646501,
      "attention_bam_16_peak_intensity_mean": 0.35957014560699463,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 740,
      "phase": "train",
      "loss": 0.0033448876347392797,
      "timestamp": 1759544011.515622,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0033448876347392797,
      "ssim": 0.9419062733650208,
      "attention_bam_384_mean_attention": -0.010374932549893856,
      "attention_bam_384_std_attention": 0.19054213166236877,
      "attention_bam_384_max_attention": 1.1792888641357422,
      "attention_bam_384_min_attention": -0.7322272062301636,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.3094222046905748,
      "attention_bam_384_attention_skewness": 0.28395900494015924,
      "attention_bam_384_attention_sparsity": 0.726287841796875,
      "attention_bam_384_attention_concentration_10": -3.281875001915585,
      "attention_bam_384_attention_concentration_20": -5.063215144429834,
      "attention_bam_384_attention_center_y": 0.48169299250667313,
      "attention_bam_384_attention_center_x": 0.4870046544631671,
      "attention_bam_384_attention_center_distance": 0.03174981980995825,
      "attention_bam_384_attention_spatial_variance": 169.20621527753912,
      "attention_bam_384_attention_spatial_std": 13.007928938825701,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 19.892680326825886,
      "attention_bam_384_peak_intensity_mean": 0.3829869329929352,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14099469780921936,
      "attention_bam_16_std_attention": 0.5534922480583191,
      "attention_bam_16_max_attention": 2.376608371734619,
      "attention_bam_16_min_attention": -1.0352239608764648,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.05774799931906527,
      "attention_bam_16_attention_skewness": 0.5062932371681377,
      "attention_bam_16_attention_sparsity": 0.50732421875,
      "attention_bam_16_attention_concentration_10": 0.8595937071889037,
      "attention_bam_16_attention_concentration_20": 1.38215475509428,
      "attention_bam_16_attention_center_y": 0.4639443741024227,
      "attention_bam_16_attention_center_x": 0.47605758014700844,
      "attention_bam_16_attention_center_distance": 0.061208620753664636,
      "attention_bam_16_attention_spatial_variance": 41.66006458652037,
      "attention_bam_16_attention_spatial_std": 6.454460828490663,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.344263675332336,
      "attention_bam_16_peak_intensity_mean": 0.3542521297931671,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 741,
      "phase": "train",
      "loss": 0.004358623176813126,
      "timestamp": 1759544011.6753533,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004358623176813126,
      "ssim": 0.9309996962547302,
      "attention_bam_384_mean_attention": -0.011299061588943005,
      "attention_bam_384_std_attention": 0.148980051279068,
      "attention_bam_384_max_attention": 1.08613920211792,
      "attention_bam_384_min_attention": -0.6735671162605286,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0245369480394322,
      "attention_bam_384_attention_skewness": 0.30147824421150154,
      "attention_bam_384_attention_sparsity": 0.7968165079752604,
      "attention_bam_384_attention_concentration_10": -2.3576729661959828,
      "attention_bam_384_attention_concentration_20": -3.53020538276332,
      "attention_bam_384_attention_center_y": 0.4843130080566581,
      "attention_bam_384_attention_center_x": 0.48548415230279357,
      "attention_bam_384_attention_center_distance": 0.03022553723588603,
      "attention_bam_384_attention_spatial_variance": 171.81727378963404,
      "attention_bam_384_attention_spatial_std": 13.107908825958244,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 22.324703897297745,
      "attention_bam_384_peak_intensity_mean": 0.3899438679218292,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14188991487026215,
      "attention_bam_16_std_attention": 0.4640224575996399,
      "attention_bam_16_max_attention": 2.2517099380493164,
      "attention_bam_16_min_attention": -1.0742475986480713,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.47483474038073714,
      "attention_bam_16_attention_skewness": 0.5234849425039653,
      "attention_bam_16_attention_sparsity": 0.486572265625,
      "attention_bam_16_attention_concentration_10": 0.7390937853623342,
      "attention_bam_16_attention_concentration_20": 1.1664561207124886,
      "attention_bam_16_attention_center_y": 0.4688774975862337,
      "attention_bam_16_attention_center_x": 0.46892864933921047,
      "attention_bam_16_attention_center_distance": 0.062193874109603996,
      "attention_bam_16_attention_spatial_variance": 43.09892867447063,
      "attention_bam_16_attention_spatial_std": 6.564977431375574,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 10.623331323801327,
      "attention_bam_16_peak_intensity_mean": 0.3737863600254059,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 742,
      "phase": "train",
      "loss": 0.0030304144602268934,
      "timestamp": 1759544011.8330975,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0030304144602268934,
      "ssim": 0.9393017888069153,
      "attention_bam_384_mean_attention": -0.010924440808594227,
      "attention_bam_384_std_attention": 0.1926376223564148,
      "attention_bam_384_max_attention": 1.1704906225204468,
      "attention_bam_384_min_attention": -0.7117781639099121,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.46393373936714744,
      "attention_bam_384_attention_skewness": 0.42905636967624855,
      "attention_bam_384_attention_sparsity": 0.7280146280924479,
      "attention_bam_384_attention_concentration_10": -3.2223928510853392,
      "attention_bam_384_attention_concentration_20": -4.963017540632651,
      "attention_bam_384_attention_center_y": 0.48703910276106704,
      "attention_bam_384_attention_center_x": 0.4815255888607377,
      "attention_bam_384_attention_center_distance": 0.03191516016505882,
      "attention_bam_384_attention_spatial_variance": 171.65370648099258,
      "attention_bam_384_attention_spatial_std": 13.101668080095472,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 20.600307592590653,
      "attention_bam_384_peak_intensity_mean": 0.3819183111190796,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13398146629333496,
      "attention_bam_16_std_attention": 0.5524304509162903,
      "attention_bam_16_max_attention": 2.3435401916503906,
      "attention_bam_16_min_attention": -0.9678252339363098,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.11804474239753215,
      "attention_bam_16_attention_skewness": 0.6411163831916092,
      "attention_bam_16_attention_sparsity": 0.5390625,
      "attention_bam_16_attention_concentration_10": 0.9153020393669775,
      "attention_bam_16_attention_concentration_20": 1.4679300446918162,
      "attention_bam_16_attention_center_y": 0.4735763712832647,
      "attention_bam_16_attention_center_x": 0.47118673790051735,
      "attention_bam_16_attention_center_distance": 0.05528855627294607,
      "attention_bam_16_attention_spatial_variance": 42.658352687884204,
      "attention_bam_16_attention_spatial_std": 6.531336209986759,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.719755968089519,
      "attention_bam_16_peak_intensity_mean": 0.34562692046165466,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 743,
      "phase": "train",
      "loss": 0.0046529932878911495,
      "timestamp": 1759544011.9777153,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0046529932878911495,
      "ssim": 0.9203007221221924,
      "attention_bam_384_mean_attention": -0.011284139938652515,
      "attention_bam_384_std_attention": 0.19700346887111664,
      "attention_bam_384_max_attention": 1.4314427375793457,
      "attention_bam_384_min_attention": -0.7629328966140747,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.3048492504682905,
      "attention_bam_384_attention_skewness": 0.36192713468444465,
      "attention_bam_384_attention_sparsity": 0.7242279052734375,
      "attention_bam_384_attention_concentration_10": -3.1578710250434594,
      "attention_bam_384_attention_concentration_20": -4.882984949153699,
      "attention_bam_384_attention_center_y": 0.47985096261015386,
      "attention_bam_384_attention_center_x": 0.4779369868002586,
      "attention_bam_384_attention_center_distance": 0.04225541998819515,
      "attention_bam_384_attention_spatial_variance": 172.74902554297066,
      "attention_bam_384_attention_spatial_std": 13.143402357950192,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 21.14980746072256,
      "attention_bam_384_peak_intensity_mean": 0.35653766989707947,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1324673891067505,
      "attention_bam_16_std_attention": 0.5662173628807068,
      "attention_bam_16_max_attention": 2.846987009048462,
      "attention_bam_16_min_attention": -0.9676427841186523,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.1935810255065089,
      "attention_bam_16_attention_skewness": 0.6257516105667376,
      "attention_bam_16_attention_sparsity": 0.525634765625,
      "attention_bam_16_attention_concentration_10": 0.9417756612621229,
      "attention_bam_16_attention_concentration_20": 1.5013967793592533,
      "attention_bam_16_attention_center_y": 0.45387455389098147,
      "attention_bam_16_attention_center_x": 0.4518477343260652,
      "attention_bam_16_attention_center_distance": 0.09429949595081805,
      "attention_bam_16_attention_spatial_variance": 43.80663465281641,
      "attention_bam_16_attention_spatial_std": 6.618658070395872,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.16809155443181,
      "attention_bam_16_peak_intensity_mean": 0.3020212650299072,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 744,
      "phase": "train",
      "loss": 0.00402724277228117,
      "timestamp": 1759544012.1525972,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00402724277228117,
      "ssim": 0.9275617599487305,
      "attention_bam_384_mean_attention": -0.011005870066583157,
      "attention_bam_384_std_attention": 0.19242949783802032,
      "attention_bam_384_max_attention": 1.288867473602295,
      "attention_bam_384_min_attention": -0.8130441904067993,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.4944961926770999,
      "attention_bam_384_attention_skewness": 0.3293902253207693,
      "attention_bam_384_attention_sparsity": 0.7307764689127604,
      "attention_bam_384_attention_concentration_10": -3.1512519833715618,
      "attention_bam_384_attention_concentration_20": -4.810659750209044,
      "attention_bam_384_attention_center_y": 0.4843915688960176,
      "attention_bam_384_attention_center_x": 0.4908077212917396,
      "attention_bam_384_attention_center_distance": 0.025617225040121067,
      "attention_bam_384_attention_spatial_variance": 171.93549032343924,
      "attention_bam_384_attention_spatial_std": 13.112417409594588,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 22.266646000621876,
      "attention_bam_384_peak_intensity_mean": 0.39300423860549927,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14383678138256073,
      "attention_bam_16_std_attention": 0.5472790002822876,
      "attention_bam_16_max_attention": 2.4572935104370117,
      "attention_bam_16_min_attention": -1.0781054496765137,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.10043535317107999,
      "attention_bam_16_attention_skewness": 0.5380142364990346,
      "attention_bam_16_attention_sparsity": 0.5087890625,
      "attention_bam_16_attention_concentration_10": 0.8399223721495361,
      "attention_bam_16_attention_concentration_20": 1.3463909613670058,
      "attention_bam_16_attention_center_y": 0.46761175245822223,
      "attention_bam_16_attention_center_x": 0.48381402629282744,
      "attention_bam_16_attention_center_distance": 0.05120516231156299,
      "attention_bam_16_attention_spatial_variance": 43.15618794505267,
      "attention_bam_16_attention_spatial_std": 6.569336948661765,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.218772980934467,
      "attention_bam_16_peak_intensity_mean": 0.347366064786911,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 745,
      "phase": "train",
      "loss": 0.009786488488316536,
      "timestamp": 1759544012.3397403,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.009786488488316536,
      "ssim": 0.8982571363449097,
      "attention_bam_384_mean_attention": -0.0126185966655612,
      "attention_bam_384_std_attention": 0.16785790026187897,
      "attention_bam_384_max_attention": 1.2198905944824219,
      "attention_bam_384_min_attention": -0.6710184812545776,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.656496092400356,
      "attention_bam_384_attention_skewness": 0.24196573357014967,
      "attention_bam_384_attention_sparsity": 0.7656758626302084,
      "attention_bam_384_attention_concentration_10": -2.3494041824772722,
      "attention_bam_384_attention_concentration_20": -3.5647306254571522,
      "attention_bam_384_attention_center_y": 0.4796302651695312,
      "attention_bam_384_attention_center_x": 0.4873389516649954,
      "attention_bam_384_attention_center_distance": 0.03391837973739121,
      "attention_bam_384_attention_spatial_variance": 169.99750869880958,
      "attention_bam_384_attention_spatial_std": 13.038309273015791,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 18.345822244489646,
      "attention_bam_384_peak_intensity_mean": 0.3590531349182129,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.11981511116027832,
      "attention_bam_16_std_attention": 0.49688389897346497,
      "attention_bam_16_max_attention": 2.615360736846924,
      "attention_bam_16_min_attention": -0.9750210642814636,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.09973853375260733,
      "attention_bam_16_attention_skewness": 0.43799682435874077,
      "attention_bam_16_attention_sparsity": 0.51513671875,
      "attention_bam_16_attention_concentration_10": 0.8785160066362824,
      "attention_bam_16_attention_concentration_20": 1.4245750595183524,
      "attention_bam_16_attention_center_y": 0.45900996768231644,
      "attention_bam_16_attention_center_x": 0.47323639317522576,
      "attention_bam_16_attention_center_distance": 0.0692311114987452,
      "attention_bam_16_attention_spatial_variance": 42.0274853730306,
      "attention_bam_16_attention_spatial_std": 6.482860894160124,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 9.287138022319581,
      "attention_bam_16_peak_intensity_mean": 0.3118847608566284,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 746,
      "phase": "train",
      "loss": 0.013879487290978432,
      "timestamp": 1759544012.5305562,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.013879487290978432,
      "ssim": 0.8580976724624634,
      "attention_bam_384_mean_attention": -0.014395221136510372,
      "attention_bam_384_std_attention": 0.18563112616539001,
      "attention_bam_384_max_attention": 1.5796732902526855,
      "attention_bam_384_min_attention": -0.8034787774085999,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1455362831118094,
      "attention_bam_384_attention_skewness": 0.4874884375867494,
      "attention_bam_384_attention_sparsity": 0.7534027099609375,
      "attention_bam_384_attention_concentration_10": -2.345958180261608,
      "attention_bam_384_attention_concentration_20": -3.5235942215774165,
      "attention_bam_384_attention_center_y": 0.48630035500783414,
      "attention_bam_384_attention_center_x": 0.4779350332961947,
      "attention_bam_384_attention_center_distance": 0.03672990684854542,
      "attention_bam_384_attention_spatial_variance": 174.0037059353318,
      "attention_bam_384_attention_spatial_std": 13.191046430641194,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 19.172198207142262,
      "attention_bam_384_peak_intensity_mean": 0.34330734610557556,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1388135403394699,
      "attention_bam_16_std_attention": 0.560092031955719,
      "attention_bam_16_max_attention": 2.7160592079162598,
      "attention_bam_16_min_attention": -1.1106338500976562,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.9083671976017711,
      "attention_bam_16_attention_skewness": 0.7618101995550594,
      "attention_bam_16_attention_sparsity": 0.51953125,
      "attention_bam_16_attention_concentration_10": 0.9101247055993686,
      "attention_bam_16_attention_concentration_20": 1.4181680250950202,
      "attention_bam_16_attention_center_y": 0.4675538185830204,
      "attention_bam_16_attention_center_x": 0.44506779775038724,
      "attention_bam_16_attention_center_distance": 0.0902252906067463,
      "attention_bam_16_attention_spatial_variance": 44.781798865031384,
      "attention_bam_16_attention_spatial_std": 6.691920416818433,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 11.328747345174857,
      "attention_bam_16_peak_intensity_mean": 0.34694480895996094,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 747,
      "phase": "train",
      "loss": 0.0044872029684484005,
      "timestamp": 1759544012.7144408,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0044872029684484005,
      "ssim": 0.9197015166282654,
      "attention_bam_384_mean_attention": -0.01281779259443283,
      "attention_bam_384_std_attention": 0.18116074800491333,
      "attention_bam_384_max_attention": 1.2809679508209229,
      "attention_bam_384_min_attention": -0.817791223526001,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5589024661930879,
      "attention_bam_384_attention_skewness": 0.2409077248917484,
      "attention_bam_384_attention_sparsity": 0.7408523559570312,
      "attention_bam_384_attention_concentration_10": -2.46477056843716,
      "attention_bam_384_attention_concentration_20": -3.79821763666621,
      "attention_bam_384_attention_center_y": 0.48183309181615563,
      "attention_bam_384_attention_center_x": 0.47828150602384417,
      "attention_bam_384_attention_center_distance": 0.040043214994616716,
      "attention_bam_384_attention_spatial_variance": 174.29519893398052,
      "attention_bam_384_attention_spatial_std": 13.2020907031417,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 22.703175953527946,
      "attention_bam_384_peak_intensity_mean": 0.39636653661727905,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14386050403118134,
      "attention_bam_16_std_attention": 0.5363790392875671,
      "attention_bam_16_max_attention": 2.576834201812744,
      "attention_bam_16_min_attention": -1.075510025024414,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.04535467882215016,
      "attention_bam_16_attention_skewness": 0.47159741976538894,
      "attention_bam_16_attention_sparsity": 0.501953125,
      "attention_bam_16_attention_concentration_10": 0.8072309635502616,
      "attention_bam_16_attention_concentration_20": 1.3185459558533121,
      "attention_bam_16_attention_center_y": 0.45848350244858643,
      "attention_bam_16_attention_center_x": 0.4474006711189041,
      "attention_bam_16_attention_center_distance": 0.09476612229777283,
      "attention_bam_16_attention_spatial_variance": 44.959646738215056,
      "attention_bam_16_attention_spatial_std": 6.7051955033552195,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 11.541749780925532,
      "attention_bam_16_peak_intensity_mean": 0.3543946146965027,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 748,
      "phase": "train",
      "loss": 0.0037010812666267157,
      "timestamp": 1759544012.892911,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0037010812666267157,
      "ssim": 0.9451755881309509,
      "attention_bam_384_mean_attention": -0.012290648184716702,
      "attention_bam_384_std_attention": 0.19163039326667786,
      "attention_bam_384_max_attention": 1.6366010904312134,
      "attention_bam_384_min_attention": -0.7368791103363037,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.078257097264097,
      "attention_bam_384_attention_skewness": 0.42926176049198006,
      "attention_bam_384_attention_sparsity": 0.7457478841145834,
      "attention_bam_384_attention_concentration_10": -2.8388341698772295,
      "attention_bam_384_attention_concentration_20": -4.261791154896041,
      "attention_bam_384_attention_center_y": 0.4861935765093715,
      "attention_bam_384_attention_center_x": 0.48651138805393823,
      "attention_bam_384_attention_center_distance": 0.027296885603820025,
      "attention_bam_384_attention_spatial_variance": 170.56705567873303,
      "attention_bam_384_attention_spatial_std": 13.060132299434528,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 19.053455215319346,
      "attention_bam_384_peak_intensity_mean": 0.3110002875328064,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14496730268001556,
      "attention_bam_16_std_attention": 0.556364119052887,
      "attention_bam_16_max_attention": 2.7023239135742188,
      "attention_bam_16_min_attention": -1.0225164890289307,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.9298005224539376,
      "attention_bam_16_attention_skewness": 0.7568122715024795,
      "attention_bam_16_attention_sparsity": 0.51025390625,
      "attention_bam_16_attention_concentration_10": 0.8706534173198721,
      "attention_bam_16_attention_concentration_20": 1.3587461945699417,
      "attention_bam_16_attention_center_y": 0.4714395762513212,
      "attention_bam_16_attention_center_x": 0.4813519817895737,
      "attention_bam_16_attention_center_distance": 0.04823787698231515,
      "attention_bam_16_attention_spatial_variance": 42.42825612946194,
      "attention_bam_16_attention_spatial_std": 6.513697577372006,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 10.292987974704857,
      "attention_bam_16_peak_intensity_mean": 0.3219972550868988,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 749,
      "phase": "train",
      "loss": 0.005498010199517012,
      "timestamp": 1759544013.0630121,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005498010199517012,
      "ssim": 0.9248635768890381,
      "attention_bam_384_mean_attention": -0.011683125980198383,
      "attention_bam_384_std_attention": 0.16678152978420258,
      "attention_bam_384_max_attention": 1.473949670791626,
      "attention_bam_384_min_attention": -0.7507835626602173,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.167185654291333,
      "attention_bam_384_attention_skewness": 0.42399270990169485,
      "attention_bam_384_attention_sparsity": 0.7765401204427084,
      "attention_bam_384_attention_concentration_10": -2.6105305247569284,
      "attention_bam_384_attention_concentration_20": -3.884333479025718,
      "attention_bam_384_attention_center_y": 0.4794574780219627,
      "attention_bam_384_attention_center_x": 0.4801517866204,
      "attention_bam_384_attention_center_distance": 0.04039670242928941,
      "attention_bam_384_attention_spatial_variance": 170.4721400002323,
      "attention_bam_384_attention_spatial_std": 13.05649799908966,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 18.06872873077955,
      "attention_bam_384_peak_intensity_mean": 0.3451559245586395,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14574593305587769,
      "attention_bam_16_std_attention": 0.490272581577301,
      "attention_bam_16_max_attention": 2.4536194801330566,
      "attention_bam_16_min_attention": -0.923098087310791,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5112912645596035,
      "attention_bam_16_attention_skewness": 0.6536422626275236,
      "attention_bam_16_attention_sparsity": 0.513427734375,
      "attention_bam_16_attention_concentration_10": 0.7684064892430658,
      "attention_bam_16_attention_concentration_20": 1.217950107352745,
      "attention_bam_16_attention_center_y": 0.4543951931786397,
      "attention_bam_16_attention_center_x": 0.4542739885216769,
      "attention_bam_16_attention_center_distance": 0.09133089872468494,
      "attention_bam_16_attention_spatial_variance": 41.66948975145138,
      "attention_bam_16_attention_spatial_std": 6.455190915182245,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 7.795645561935046,
      "attention_bam_16_peak_intensity_mean": 0.3400309383869171,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 750,
      "phase": "train",
      "loss": 0.0033296372275799513,
      "timestamp": 1759544013.2814457,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0033296372275799513,
      "ssim": 0.9306133985519409,
      "attention_bam_384_mean_attention": -0.011714942753314972,
      "attention_bam_384_std_attention": 0.1816592514514923,
      "attention_bam_384_max_attention": 1.2509616613388062,
      "attention_bam_384_min_attention": -0.8037304282188416,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.3533297098149153,
      "attention_bam_384_attention_skewness": 0.32365332711286987,
      "attention_bam_384_attention_sparsity": 0.7394663492838541,
      "attention_bam_384_attention_concentration_10": -2.7798047469892713,
      "attention_bam_384_attention_concentration_20": -4.279843860346844,
      "attention_bam_384_attention_center_y": 0.48296660193331653,
      "attention_bam_384_attention_center_x": 0.487947287049288,
      "attention_bam_384_attention_center_distance": 0.029509474382657386,
      "attention_bam_384_attention_spatial_variance": 171.5300006768448,
      "attention_bam_384_attention_spatial_std": 13.09694623478484,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 17.962541905274733,
      "attention_bam_384_peak_intensity_mean": 0.38892269134521484,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14223510026931763,
      "attention_bam_16_std_attention": 0.524663507938385,
      "attention_bam_16_max_attention": 2.469884157180786,
      "attention_bam_16_min_attention": -1.051771879196167,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.149422762130774,
      "attention_bam_16_attention_skewness": 0.5532719603670844,
      "attention_bam_16_attention_sparsity": 0.510009765625,
      "attention_bam_16_attention_concentration_10": 0.8179533224601242,
      "attention_bam_16_attention_concentration_20": 1.3085233303593133,
      "attention_bam_16_attention_center_y": 0.46365095878241375,
      "attention_bam_16_attention_center_x": 0.478982702176594,
      "attention_bam_16_attention_center_distance": 0.05937978789513366,
      "attention_bam_16_attention_spatial_variance": 42.70173553277361,
      "attention_bam_16_attention_spatial_std": 6.534656496922667,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.178160014354978,
      "attention_bam_16_peak_intensity_mean": 0.34099259972572327,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 751,
      "phase": "train",
      "loss": 0.005009714514017105,
      "timestamp": 1759544013.4466863,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005009714514017105,
      "ssim": 0.9095697999000549,
      "attention_bam_384_mean_attention": -0.012259174138307571,
      "attention_bam_384_std_attention": 0.156028613448143,
      "attention_bam_384_max_attention": 1.4545633792877197,
      "attention_bam_384_min_attention": -0.6752190589904785,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.248550576839568,
      "attention_bam_384_attention_skewness": 0.38298650475125756,
      "attention_bam_384_attention_sparsity": 0.7855504353841146,
      "attention_bam_384_attention_concentration_10": -2.279361099053581,
      "attention_bam_384_attention_concentration_20": -3.436562834684159,
      "attention_bam_384_attention_center_y": 0.4815836479834598,
      "attention_bam_384_attention_center_x": 0.4830343344951155,
      "attention_bam_384_attention_center_distance": 0.035411744594717465,
      "attention_bam_384_attention_spatial_variance": 170.30071384891315,
      "attention_bam_384_attention_spatial_std": 13.049931564913019,
      "attention_bam_384_num_attention_peaks": 18,
      "attention_bam_384_peak_separation_mean": 15.445278028188188,
      "attention_bam_384_peak_intensity_mean": 0.31354251503944397,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1304585039615631,
      "attention_bam_16_std_attention": 0.4812263250350952,
      "attention_bam_16_max_attention": 2.315901279449463,
      "attention_bam_16_min_attention": -0.9380044937133789,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.4837030957658417,
      "attention_bam_16_attention_skewness": 0.6414639194262429,
      "attention_bam_16_attention_sparsity": 0.525634765625,
      "attention_bam_16_attention_concentration_10": 0.830244861103728,
      "attention_bam_16_attention_concentration_20": 1.3142401496877614,
      "attention_bam_16_attention_center_y": 0.45585494152358613,
      "attention_bam_16_attention_center_x": 0.4610920721244582,
      "attention_bam_16_attention_center_distance": 0.08321794325089227,
      "attention_bam_16_attention_spatial_variance": 41.83159495484639,
      "attention_bam_16_attention_spatial_std": 6.467734916865903,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.97111865172847,
      "attention_bam_16_peak_intensity_mean": 0.3367510735988617,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 752,
      "phase": "train",
      "loss": 0.0033529780339449644,
      "timestamp": 1759544013.8277524,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0033529780339449644,
      "ssim": 0.9333221316337585,
      "attention_bam_384_mean_attention": -0.012816031463444233,
      "attention_bam_384_std_attention": 0.1572226583957672,
      "attention_bam_384_max_attention": 1.1075154542922974,
      "attention_bam_384_min_attention": -0.7042298913002014,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9313833897204118,
      "attention_bam_384_attention_skewness": 0.40870837958775924,
      "attention_bam_384_attention_sparsity": 0.7877070109049479,
      "attention_bam_384_attention_concentration_10": -2.230113231185787,
      "attention_bam_384_attention_concentration_20": -3.333004160911471,
      "attention_bam_384_attention_center_y": 0.48765488218797903,
      "attention_bam_384_attention_center_x": 0.4847012736177107,
      "attention_bam_384_attention_center_distance": 0.027801185683809668,
      "attention_bam_384_attention_spatial_variance": 170.62368634663366,
      "attention_bam_384_attention_spatial_std": 13.062300193558318,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 20.330245277732907,
      "attention_bam_384_peak_intensity_mean": 0.39254361391067505,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12896093726158142,
      "attention_bam_16_std_attention": 0.49084874987602234,
      "attention_bam_16_max_attention": 2.3863377571105957,
      "attention_bam_16_min_attention": -1.0309710502624512,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.47939785893719034,
      "attention_bam_16_attention_skewness": 0.7033064914767302,
      "attention_bam_16_attention_sparsity": 0.5341796875,
      "attention_bam_16_attention_concentration_10": 0.8656809200958963,
      "attention_bam_16_attention_concentration_20": 1.37163660378189,
      "attention_bam_16_attention_center_y": 0.487179305648127,
      "attention_bam_16_attention_center_x": 0.4726050530456467,
      "attention_bam_16_attention_center_distance": 0.042775070363378215,
      "attention_bam_16_attention_spatial_variance": 42.05322951371623,
      "attention_bam_16_attention_spatial_std": 6.484846144182314,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 9.986522426714664,
      "attention_bam_16_peak_intensity_mean": 0.3553661108016968,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 753,
      "phase": "train",
      "loss": 0.003714705817401409,
      "timestamp": 1759544013.9634986,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.003714705817401409,
      "ssim": 0.9167090058326721,
      "attention_bam_384_mean_attention": -0.012653226964175701,
      "attention_bam_384_std_attention": 0.18222977221012115,
      "attention_bam_384_max_attention": 1.3509899377822876,
      "attention_bam_384_min_attention": -0.7265808582305908,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1870901598145087,
      "attention_bam_384_attention_skewness": 0.532023812821506,
      "attention_bam_384_attention_sparsity": 0.7554041544596354,
      "attention_bam_384_attention_concentration_10": -2.654594766262007,
      "attention_bam_384_attention_concentration_20": -3.968208363649621,
      "attention_bam_384_attention_center_y": 0.4875938005446141,
      "attention_bam_384_attention_center_x": 0.4851030420096074,
      "attention_bam_384_attention_center_distance": 0.027416533051950204,
      "attention_bam_384_attention_spatial_variance": 171.30549851189767,
      "attention_bam_384_attention_spatial_std": 13.088372645669043,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 19.020571974122262,
      "attention_bam_384_peak_intensity_mean": 0.34947559237480164,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12910275161266327,
      "attention_bam_16_std_attention": 0.5323433876037598,
      "attention_bam_16_max_attention": 2.7498738765716553,
      "attention_bam_16_min_attention": -1.076941967010498,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.312741872446634,
      "attention_bam_16_attention_skewness": 0.8579955482816469,
      "attention_bam_16_attention_sparsity": 0.521728515625,
      "attention_bam_16_attention_concentration_10": 0.931371862134233,
      "attention_bam_16_attention_concentration_20": 1.4457684893399094,
      "attention_bam_16_attention_center_y": 0.476222871503466,
      "attention_bam_16_attention_center_x": 0.47147620999763656,
      "attention_bam_16_attention_center_distance": 0.052515872565151535,
      "attention_bam_16_attention_spatial_variance": 42.64416231074975,
      "attention_bam_16_attention_spatial_std": 6.530249789307431,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.883734167678842,
      "attention_bam_16_peak_intensity_mean": 0.3229531943798065,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 754,
      "phase": "train",
      "loss": 0.00765139888972044,
      "timestamp": 1759544014.1098945,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00765139888972044,
      "ssim": 0.8929311037063599,
      "attention_bam_384_mean_attention": -0.013005689717829227,
      "attention_bam_384_std_attention": 0.15082906186580658,
      "attention_bam_384_max_attention": 1.0688031911849976,
      "attention_bam_384_min_attention": -0.7222313284873962,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8397539253718844,
      "attention_bam_384_attention_skewness": 0.3520146547561685,
      "attention_bam_384_attention_sparsity": 0.7899805704752604,
      "attention_bam_384_attention_concentration_10": -2.063568994897369,
      "attention_bam_384_attention_concentration_20": -3.11767406800491,
      "attention_bam_384_attention_center_y": 0.48572301350475916,
      "attention_bam_384_attention_center_x": 0.4804871347288742,
      "attention_bam_384_attention_center_distance": 0.03419310616116634,
      "attention_bam_384_attention_spatial_variance": 168.1917861812308,
      "attention_bam_384_attention_spatial_std": 12.968877599130574,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 15.345659189556326,
      "attention_bam_384_peak_intensity_mean": 0.406021386384964,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1410437524318695,
      "attention_bam_16_std_attention": 0.4683065116405487,
      "attention_bam_16_max_attention": 1.9490147829055786,
      "attention_bam_16_min_attention": -0.9772006869316101,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.21597593266530124,
      "attention_bam_16_attention_skewness": 0.546086952829029,
      "attention_bam_16_attention_sparsity": 0.504638671875,
      "attention_bam_16_attention_concentration_10": 0.7492657907935629,
      "attention_bam_16_attention_concentration_20": 1.201677265726901,
      "attention_bam_16_attention_center_y": 0.47346287259552633,
      "attention_bam_16_attention_center_x": 0.4621920674585776,
      "attention_bam_16_attention_center_distance": 0.06532471039259208,
      "attention_bam_16_attention_spatial_variance": 40.13482181967621,
      "attention_bam_16_attention_spatial_std": 6.335204954827919,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 6.768699940399687,
      "attention_bam_16_peak_intensity_mean": 0.40670543909072876,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 755,
      "phase": "train",
      "loss": 0.00313621386885643,
      "timestamp": 1759544014.2613997,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00313621386885643,
      "ssim": 0.9365221858024597,
      "attention_bam_384_mean_attention": -0.012854217551648617,
      "attention_bam_384_std_attention": 0.1634681224822998,
      "attention_bam_384_max_attention": 1.060731053352356,
      "attention_bam_384_min_attention": -0.6878286004066467,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1118549405834068,
      "attention_bam_384_attention_skewness": 0.38808068613900665,
      "attention_bam_384_attention_sparsity": 0.7833607991536459,
      "attention_bam_384_attention_concentration_10": -2.308808034485864,
      "attention_bam_384_attention_concentration_20": -3.430966645398126,
      "attention_bam_384_attention_center_y": 0.4810345973641344,
      "attention_bam_384_attention_center_x": 0.48355747737363003,
      "attention_bam_384_attention_center_distance": 0.03549769140265846,
      "attention_bam_384_attention_spatial_variance": 170.81091081374714,
      "attention_bam_384_attention_spatial_std": 13.069464825070197,
      "attention_bam_384_num_attention_peaks": 20,
      "attention_bam_384_peak_separation_mean": 17.83699643390884,
      "attention_bam_384_peak_intensity_mean": 0.39390164613723755,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13313373923301697,
      "attention_bam_16_std_attention": 0.4873771369457245,
      "attention_bam_16_max_attention": 2.518406629562378,
      "attention_bam_16_min_attention": -1.069974422454834,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.9301953773844533,
      "attention_bam_16_attention_skewness": 0.6562490563448168,
      "attention_bam_16_attention_sparsity": 0.51025390625,
      "attention_bam_16_attention_concentration_10": 0.8169432625503642,
      "attention_bam_16_attention_concentration_20": 1.286012441251508,
      "attention_bam_16_attention_center_y": 0.46477420740323233,
      "attention_bam_16_attention_center_x": 0.4686729801513982,
      "attention_bam_16_attention_center_distance": 0.06666691288285642,
      "attention_bam_16_attention_spatial_variance": 41.97408601154356,
      "attention_bam_16_attention_spatial_std": 6.478741082304769,
      "attention_bam_16_num_attention_peaks": 11,
      "attention_bam_16_peak_separation_mean": 7.472017872246787,
      "attention_bam_16_peak_intensity_mean": 0.344573050737381,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 756,
      "phase": "train",
      "loss": 0.004832359962165356,
      "timestamp": 1759544014.4129548,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004832359962165356,
      "ssim": 0.9169367551803589,
      "attention_bam_384_mean_attention": -0.014104031957685947,
      "attention_bam_384_std_attention": 0.16823910176753998,
      "attention_bam_384_max_attention": 1.0902060270309448,
      "attention_bam_384_min_attention": -0.6851885914802551,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.510988232993864,
      "attention_bam_384_attention_skewness": 0.18520195313081733,
      "attention_bam_384_attention_sparsity": 0.7675094604492188,
      "attention_bam_384_attention_concentration_10": -2.0681336005538933,
      "attention_bam_384_attention_concentration_20": -3.1555439847347815,
      "attention_bam_384_attention_center_y": 0.48304858679974444,
      "attention_bam_384_attention_center_x": 0.48686881073787175,
      "attention_bam_384_attention_center_distance": 0.030324199607693874,
      "attention_bam_384_attention_spatial_variance": 171.17941097810092,
      "attention_bam_384_attention_spatial_std": 13.083554982423582,
      "attention_bam_384_num_attention_peaks": 18,
      "attention_bam_384_peak_separation_mean": 19.904862326565997,
      "attention_bam_384_peak_intensity_mean": 0.38772833347320557,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14148461818695068,
      "attention_bam_16_std_attention": 0.5060387253761292,
      "attention_bam_16_max_attention": 2.2256245613098145,
      "attention_bam_16_min_attention": -1.0319784879684448,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.03636399732757978,
      "attention_bam_16_attention_skewness": 0.464384649889019,
      "attention_bam_16_attention_sparsity": 0.498291015625,
      "attention_bam_16_attention_concentration_10": 0.7824587840543613,
      "attention_bam_16_attention_concentration_20": 1.2666897457693442,
      "attention_bam_16_attention_center_y": 0.469861947595058,
      "attention_bam_16_attention_center_x": 0.47863549765495056,
      "attention_bam_16_attention_center_distance": 0.052244505227146194,
      "attention_bam_16_attention_spatial_variance": 42.96987234528766,
      "attention_bam_16_attention_spatial_std": 6.555140909643947,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.363059132587336,
      "attention_bam_16_peak_intensity_mean": 0.366870641708374,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 757,
      "phase": "train",
      "loss": 0.00637789024040103,
      "timestamp": 1759544014.603029,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00637789024040103,
      "ssim": 0.9377083778381348,
      "attention_bam_384_mean_attention": -0.013145223259925842,
      "attention_bam_384_std_attention": 0.15642984211444855,
      "attention_bam_384_max_attention": 1.3120622634887695,
      "attention_bam_384_min_attention": -0.7358946204185486,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.886059595223796,
      "attention_bam_384_attention_skewness": 0.34508234171465774,
      "attention_bam_384_attention_sparsity": 0.7787628173828125,
      "attention_bam_384_attention_concentration_10": -2.0993259733808034,
      "attention_bam_384_attention_concentration_20": -3.1928238345065307,
      "attention_bam_384_attention_center_y": 0.48861069063865,
      "attention_bam_384_attention_center_x": 0.4842575492655545,
      "attention_bam_384_attention_center_distance": 0.02747875990123934,
      "attention_bam_384_attention_spatial_variance": 170.74893700369725,
      "attention_bam_384_attention_spatial_std": 13.067093670885551,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 19.48648840961197,
      "attention_bam_384_peak_intensity_mean": 0.3601398169994354,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.122560515999794,
      "attention_bam_16_std_attention": 0.48069658875465393,
      "attention_bam_16_max_attention": 2.280585765838623,
      "attention_bam_16_min_attention": -0.9681001901626587,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.16892927404917168,
      "attention_bam_16_attention_skewness": 0.5778144212508575,
      "attention_bam_16_attention_sparsity": 0.53369140625,
      "attention_bam_16_attention_concentration_10": 0.8561026356755271,
      "attention_bam_16_attention_concentration_20": 1.3888300363849486,
      "attention_bam_16_attention_center_y": 0.4826820430570134,
      "attention_bam_16_attention_center_x": 0.474212280308213,
      "attention_bam_16_attention_center_distance": 0.04392990142445842,
      "attention_bam_16_attention_spatial_variance": 42.65710583985686,
      "attention_bam_16_attention_spatial_std": 6.531240758068628,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.475648758381496,
      "attention_bam_16_peak_intensity_mean": 0.3330252170562744,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 758,
      "phase": "train",
      "loss": 0.004053744021803141,
      "timestamp": 1759544014.7992308,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004053744021803141,
      "ssim": 0.9318227767944336,
      "attention_bam_384_mean_attention": -0.01430551242083311,
      "attention_bam_384_std_attention": 0.16313710808753967,
      "attention_bam_384_max_attention": 1.1692333221435547,
      "attention_bam_384_min_attention": -0.7462331056594849,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9550287619091216,
      "attention_bam_384_attention_skewness": 0.33847008061977957,
      "attention_bam_384_attention_sparsity": 0.7807464599609375,
      "attention_bam_384_attention_concentration_10": -2.048170016114305,
      "attention_bam_384_attention_concentration_20": -3.071316421771522,
      "attention_bam_384_attention_center_y": 0.4775563548306357,
      "attention_bam_384_attention_center_x": 0.48524032012016094,
      "attention_bam_384_attention_center_distance": 0.0379885603476535,
      "attention_bam_384_attention_spatial_variance": 171.52246899998985,
      "attention_bam_384_attention_spatial_std": 13.096658696018228,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 19.38893367154359,
      "attention_bam_384_peak_intensity_mean": 0.39124202728271484,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12585020065307617,
      "attention_bam_16_std_attention": 0.4963425397872925,
      "attention_bam_16_max_attention": 2.4225172996520996,
      "attention_bam_16_min_attention": -1.0732412338256836,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.1449725254458274,
      "attention_bam_16_attention_skewness": 0.5337450386886046,
      "attention_bam_16_attention_sparsity": 0.52392578125,
      "attention_bam_16_attention_concentration_10": 0.86578983012563,
      "attention_bam_16_attention_concentration_20": 1.390756013946581,
      "attention_bam_16_attention_center_y": 0.44670204932949553,
      "attention_bam_16_attention_center_x": 0.47257455643828716,
      "attention_bam_16_attention_center_distance": 0.08476823108018974,
      "attention_bam_16_attention_spatial_variance": 42.71953748060041,
      "attention_bam_16_attention_spatial_std": 6.5360184730920405,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.530625267816244,
      "attention_bam_16_peak_intensity_mean": 0.35885706543922424,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 759,
      "phase": "train",
      "loss": 0.004870520438998938,
      "timestamp": 1759544014.997647,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004870520438998938,
      "ssim": 0.9223589897155762,
      "attention_bam_384_mean_attention": -0.015092410147190094,
      "attention_bam_384_std_attention": 0.15006230771541595,
      "attention_bam_384_max_attention": 1.1439205408096313,
      "attention_bam_384_min_attention": -0.6176677346229553,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9342008471865229,
      "attention_bam_384_attention_skewness": 0.338885307460764,
      "attention_bam_384_attention_sparsity": 0.79425048828125,
      "attention_bam_384_attention_concentration_10": -1.7377470521290816,
      "attention_bam_384_attention_concentration_20": -2.6206356188213764,
      "attention_bam_384_attention_center_y": 0.48267483250233245,
      "attention_bam_384_attention_center_x": 0.47989495501553414,
      "attention_bam_384_attention_center_distance": 0.03753329888644567,
      "attention_bam_384_attention_spatial_variance": 172.10348204406318,
      "attention_bam_384_attention_spatial_std": 13.1188216713264,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 18.28344093076054,
      "attention_bam_384_peak_intensity_mean": 0.34603533148765564,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1319568157196045,
      "attention_bam_16_std_attention": 0.4770815670490265,
      "attention_bam_16_max_attention": 2.705418348312378,
      "attention_bam_16_min_attention": -0.9628333449363708,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7340358235134801,
      "attention_bam_16_attention_skewness": 0.6200582164831593,
      "attention_bam_16_attention_sparsity": 0.5048828125,
      "attention_bam_16_attention_concentration_10": 0.7976480530760318,
      "attention_bam_16_attention_concentration_20": 1.2747185017118399,
      "attention_bam_16_attention_center_y": 0.46409726176263205,
      "attention_bam_16_attention_center_x": 0.46027396163470125,
      "attention_bam_16_attention_center_distance": 0.07572535555733166,
      "attention_bam_16_attention_spatial_variance": 43.37670682382674,
      "attention_bam_16_attention_spatial_std": 6.586099515177913,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.282869789645286,
      "attention_bam_16_peak_intensity_mean": 0.3029349148273468,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 760,
      "phase": "train",
      "loss": 0.0030902610160410404,
      "timestamp": 1759544015.2453275,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0030902610160410404,
      "ssim": 0.9478441476821899,
      "attention_bam_384_mean_attention": -0.015108250081539154,
      "attention_bam_384_std_attention": 0.17735271155834198,
      "attention_bam_384_max_attention": 1.1325111389160156,
      "attention_bam_384_min_attention": -0.7092467546463013,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.41675310785856245,
      "attention_bam_384_attention_skewness": 0.2583595720360731,
      "attention_bam_384_attention_sparsity": 0.7515309651692709,
      "attention_bam_384_attention_concentration_10": -2.0516564379898705,
      "attention_bam_384_attention_concentration_20": -3.1481098105795104,
      "attention_bam_384_attention_center_y": 0.4839807577942799,
      "attention_bam_384_attention_center_x": 0.4865633659676819,
      "attention_bam_384_attention_center_distance": 0.02956887738700855,
      "attention_bam_384_attention_spatial_variance": 172.21200025039957,
      "attention_bam_384_attention_spatial_std": 13.122956993391375,
      "attention_bam_384_num_attention_peaks": 18,
      "attention_bam_384_peak_separation_mean": 20.583665866974123,
      "attention_bam_384_peak_intensity_mean": 0.383767694234848,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12981107831001282,
      "attention_bam_16_std_attention": 0.5256500244140625,
      "attention_bam_16_max_attention": 1.96457040309906,
      "attention_bam_16_min_attention": -1.129952311515808,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.152624945894404,
      "attention_bam_16_attention_skewness": 0.46304777938567426,
      "attention_bam_16_attention_sparsity": 0.5087890625,
      "attention_bam_16_attention_concentration_10": 0.8750372210095139,
      "attention_bam_16_attention_concentration_20": 1.4094723808817051,
      "attention_bam_16_attention_center_y": 0.4682395019664074,
      "attention_bam_16_attention_center_x": 0.4700815200202821,
      "attention_bam_16_attention_center_distance": 0.06170647744991803,
      "attention_bam_16_attention_spatial_variance": 43.18458797435382,
      "attention_bam_16_attention_spatial_std": 6.571498152959781,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 9.115344516561935,
      "attention_bam_16_peak_intensity_mean": 0.4124423861503601,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 761,
      "phase": "train",
      "loss": 0.0036254606675356627,
      "timestamp": 1759544015.4333591,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0036254606675356627,
      "ssim": 0.9260972738265991,
      "attention_bam_384_mean_attention": -0.015464254654943943,
      "attention_bam_384_std_attention": 0.1675306260585785,
      "attention_bam_384_max_attention": 1.3850653171539307,
      "attention_bam_384_min_attention": -0.6924237608909607,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.4115370530346625,
      "attention_bam_384_attention_skewness": 0.30031768393430597,
      "attention_bam_384_attention_sparsity": 0.7642033894856771,
      "attention_bam_384_attention_concentration_10": -1.8986450596142521,
      "attention_bam_384_attention_concentration_20": -2.9053210340015063,
      "attention_bam_384_attention_center_y": 0.48100543063339635,
      "attention_bam_384_attention_center_x": 0.48923810188593786,
      "attention_bam_384_attention_center_distance": 0.03087432967499609,
      "attention_bam_384_attention_spatial_variance": 173.871141391354,
      "attention_bam_384_attention_spatial_std": 13.186020680681265,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 21.862703223771263,
      "attention_bam_384_peak_intensity_mean": 0.33524090051651,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12938424944877625,
      "attention_bam_16_std_attention": 0.5266279578208923,
      "attention_bam_16_max_attention": 2.315805435180664,
      "attention_bam_16_min_attention": -1.0337275266647339,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.13696458880035722,
      "attention_bam_16_attention_skewness": 0.47353266257003845,
      "attention_bam_16_attention_sparsity": 0.509521484375,
      "attention_bam_16_attention_concentration_10": 0.8723221576210842,
      "attention_bam_16_attention_concentration_20": 1.417258543558701,
      "attention_bam_16_attention_center_y": 0.4523200768486496,
      "attention_bam_16_attention_center_x": 0.48649334840459557,
      "attention_bam_16_attention_center_distance": 0.07008287535537222,
      "attention_bam_16_attention_spatial_variance": 44.783248633730146,
      "attention_bam_16_attention_spatial_std": 6.692028738262422,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 11.432698511645725,
      "attention_bam_16_peak_intensity_mean": 0.36100059747695923,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 762,
      "phase": "train",
      "loss": 0.0118287717923522,
      "timestamp": 1759544015.6052752,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0118287717923522,
      "ssim": 0.9030008912086487,
      "attention_bam_384_mean_attention": -0.017672952264547348,
      "attention_bam_384_std_attention": 0.1634237915277481,
      "attention_bam_384_max_attention": 1.3536938428878784,
      "attention_bam_384_min_attention": -0.6047645807266235,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9464762359914882,
      "attention_bam_384_attention_skewness": 0.5320747008204781,
      "attention_bam_384_attention_sparsity": 0.7845560709635416,
      "attention_bam_384_attention_concentration_10": -1.6780339655175118,
      "attention_bam_384_attention_concentration_20": -2.4999979974939257,
      "attention_bam_384_attention_center_y": 0.49445431826555636,
      "attention_bam_384_attention_center_x": 0.4826563703344599,
      "attention_bam_384_attention_center_distance": 0.025750964093608,
      "attention_bam_384_attention_spatial_variance": 174.80706005354213,
      "attention_bam_384_attention_spatial_std": 13.221462099690115,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 23.733392363990202,
      "attention_bam_384_peak_intensity_mean": 0.3188384175300598,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12042733281850815,
      "attention_bam_16_std_attention": 0.522952139377594,
      "attention_bam_16_max_attention": 2.5099093914031982,
      "attention_bam_16_min_attention": -0.91266930103302,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.4786453625964513,
      "attention_bam_16_attention_skewness": 0.7801883406353836,
      "attention_bam_16_attention_sparsity": 0.544677734375,
      "attention_bam_16_attention_concentration_10": 0.9855174159973482,
      "attention_bam_16_attention_concentration_20": 1.5536106914265269,
      "attention_bam_16_attention_center_y": 0.4988521738904848,
      "attention_bam_16_attention_center_x": 0.45810409480176706,
      "attention_bam_16_attention_center_distance": 0.05927198962675382,
      "attention_bam_16_attention_spatial_variance": 45.327272506310365,
      "attention_bam_16_attention_spatial_std": 6.732553193723044,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 12.40052503940875,
      "attention_bam_16_peak_intensity_mean": 0.3300098776817322,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 763,
      "phase": "train",
      "loss": 0.004697982221841812,
      "timestamp": 1759544015.7661424,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004697982221841812,
      "ssim": 0.9144387245178223,
      "attention_bam_384_mean_attention": -0.01663396693766117,
      "attention_bam_384_std_attention": 0.18722942471504211,
      "attention_bam_384_max_attention": 1.0896131992340088,
      "attention_bam_384_min_attention": -0.6953918933868408,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6757719485924993,
      "attention_bam_384_attention_skewness": 0.4770077279422805,
      "attention_bam_384_attention_sparsity": 0.7628224690755209,
      "attention_bam_384_attention_concentration_10": -2.0871480145514254,
      "attention_bam_384_attention_concentration_20": -3.1094629217154255,
      "attention_bam_384_attention_center_y": 0.48479593648873504,
      "attention_bam_384_attention_center_x": 0.47975420904793264,
      "attention_bam_384_attention_center_distance": 0.035806580359743684,
      "attention_bam_384_attention_spatial_variance": 172.92472048861387,
      "attention_bam_384_attention_spatial_std": 13.150084428953827,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 18.623153383151536,
      "attention_bam_384_peak_intensity_mean": 0.38572102785110474,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.11492275446653366,
      "attention_bam_16_std_attention": 0.5652210116386414,
      "attention_bam_16_max_attention": 2.5734167098999023,
      "attention_bam_16_min_attention": -1.0244872570037842,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6214674005030583,
      "attention_bam_16_attention_skewness": 0.8249701784255827,
      "attention_bam_16_attention_sparsity": 0.54736328125,
      "attention_bam_16_attention_concentration_10": 1.1174424400775769,
      "attention_bam_16_attention_concentration_20": 1.716677652277801,
      "attention_bam_16_attention_center_y": 0.47257600060821175,
      "attention_bam_16_attention_center_x": 0.4524043381542847,
      "attention_bam_16_attention_center_distance": 0.07768426828093936,
      "attention_bam_16_attention_spatial_variance": 43.756196010506514,
      "attention_bam_16_attention_spatial_std": 6.614846635448664,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.148883915739093,
      "attention_bam_16_peak_intensity_mean": 0.32196298241615295,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 764,
      "phase": "train",
      "loss": 0.00476094102486968,
      "timestamp": 1759544015.9213355,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00476094102486968,
      "ssim": 0.9200997352600098,
      "attention_bam_384_mean_attention": -0.01835114322602749,
      "attention_bam_384_std_attention": 0.1837785243988037,
      "attention_bam_384_max_attention": 1.6540499925613403,
      "attention_bam_384_min_attention": -0.6569141745567322,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.2871091208634278,
      "attention_bam_384_attention_skewness": 0.7927870834965763,
      "attention_bam_384_attention_sparsity": 0.7726771036783854,
      "attention_bam_384_attention_concentration_10": -1.8496950899564573,
      "attention_bam_384_attention_concentration_20": -2.696241304733586,
      "attention_bam_384_attention_center_y": 0.4883727453896195,
      "attention_bam_384_attention_center_x": 0.4844651225843487,
      "attention_bam_384_attention_center_distance": 0.027441773488385442,
      "attention_bam_384_attention_spatial_variance": 169.82283985946032,
      "attention_bam_384_attention_spatial_std": 13.03160925824053,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 16.183217589777698,
      "attention_bam_384_peak_intensity_mean": 0.27979776263237,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.10864502936601639,
      "attention_bam_16_std_attention": 0.5768312215805054,
      "attention_bam_16_max_attention": 3.7147204875946045,
      "attention_bam_16_min_attention": -0.9479192495346069,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 3.535342947890026,
      "attention_bam_16_attention_skewness": 1.3569667607130695,
      "attention_bam_16_attention_sparsity": 0.56591796875,
      "attention_bam_16_attention_concentration_10": 1.2067532984886165,
      "attention_bam_16_attention_concentration_20": 1.829710407020588,
      "attention_bam_16_attention_center_y": 0.4816003863952247,
      "attention_bam_16_attention_center_x": 0.47292087852587406,
      "attention_bam_16_attention_center_distance": 0.0462995594064458,
      "attention_bam_16_attention_spatial_variance": 41.59811344184909,
      "attention_bam_16_attention_spatial_std": 6.4496599477684935,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.664425436371232,
      "attention_bam_16_peak_intensity_mean": 0.22573786973953247,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 765,
      "phase": "train",
      "loss": 0.005255550146102905,
      "timestamp": 1759544016.073213,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005255550146102905,
      "ssim": 0.9173837900161743,
      "attention_bam_384_mean_attention": -0.01708243414759636,
      "attention_bam_384_std_attention": 0.16231901943683624,
      "attention_bam_384_max_attention": 1.4012683629989624,
      "attention_bam_384_min_attention": -0.6582392454147339,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8346846560597583,
      "attention_bam_384_attention_skewness": 0.3468086226075431,
      "attention_bam_384_attention_sparsity": 0.7866923014322916,
      "attention_bam_384_attention_concentration_10": -1.686404911451152,
      "attention_bam_384_attention_concentration_20": -2.531917604893294,
      "attention_bam_384_attention_center_y": 0.4893079123929085,
      "attention_bam_384_attention_center_x": 0.48523737503083986,
      "attention_bam_384_attention_center_distance": 0.025778123802084208,
      "attention_bam_384_attention_spatial_variance": 174.8290388060067,
      "attention_bam_384_attention_spatial_std": 13.222293250643276,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 20.6644157811272,
      "attention_bam_384_peak_intensity_mean": 0.31867715716362,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12259514629840851,
      "attention_bam_16_std_attention": 0.49917861819267273,
      "attention_bam_16_max_attention": 2.511866569519043,
      "attention_bam_16_min_attention": -1.0037763118743896,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.15831204396215215,
      "attention_bam_16_attention_skewness": 0.5718120868844718,
      "attention_bam_16_attention_sparsity": 0.52734375,
      "attention_bam_16_attention_concentration_10": 0.8993759861139802,
      "attention_bam_16_attention_concentration_20": 1.4427169271086342,
      "attention_bam_16_attention_center_y": 0.4846771055106459,
      "attention_bam_16_attention_center_x": 0.4779906529458838,
      "attention_bam_16_attention_center_distance": 0.037926308897133984,
      "attention_bam_16_attention_spatial_variance": 45.280371842431606,
      "attention_bam_16_attention_spatial_std": 6.7290691661203486,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 10.3860608988778,
      "attention_bam_16_peak_intensity_mean": 0.3395931124687195,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 766,
      "phase": "train",
      "loss": 0.0045204865746200085,
      "timestamp": 1759544016.2186403,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0045204865746200085,
      "ssim": 0.9362901449203491,
      "attention_bam_384_mean_attention": -0.01582208462059498,
      "attention_bam_384_std_attention": 0.15458254516124725,
      "attention_bam_384_max_attention": 1.229112148284912,
      "attention_bam_384_min_attention": -0.6244730353355408,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.47345740006623016,
      "attention_bam_384_attention_skewness": 0.20094956965951635,
      "attention_bam_384_attention_sparsity": 0.7828013102213541,
      "attention_bam_384_attention_concentration_10": -1.6671759161691093,
      "attention_bam_384_attention_concentration_20": -2.5523736138584097,
      "attention_bam_384_attention_center_y": 0.48813037129503156,
      "attention_bam_384_attention_center_x": 0.48359142755403633,
      "attention_bam_384_attention_center_distance": 0.028640158355297155,
      "attention_bam_384_attention_spatial_variance": 172.75929473613155,
      "attention_bam_384_attention_spatial_std": 13.143793011765347,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 18.548026509901366,
      "attention_bam_384_peak_intensity_mean": 0.3355921804904938,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.11726932227611542,
      "attention_bam_16_std_attention": 0.4758685529232025,
      "attention_bam_16_max_attention": 1.9667539596557617,
      "attention_bam_16_min_attention": -1.023869514465332,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.2416692570626191,
      "attention_bam_16_attention_skewness": 0.3520298294102549,
      "attention_bam_16_attention_sparsity": 0.519775390625,
      "attention_bam_16_attention_concentration_10": 0.853359311914884,
      "attention_bam_16_attention_concentration_20": 1.403097228099902,
      "attention_bam_16_attention_center_y": 0.4841955237343627,
      "attention_bam_16_attention_center_x": 0.474192656891105,
      "attention_bam_16_attention_center_distance": 0.042797206179173014,
      "attention_bam_16_attention_spatial_variance": 43.9524154080606,
      "attention_bam_16_attention_spatial_std": 6.629661786853127,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 10.1061233779928,
      "attention_bam_16_peak_intensity_mean": 0.40492311120033264,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 767,
      "phase": "train",
      "loss": 0.011744072660803795,
      "timestamp": 1759544016.3630302,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.011744072660803795,
      "ssim": 0.9111708402633667,
      "attention_bam_384_mean_attention": -0.015770597383379936,
      "attention_bam_384_std_attention": 0.16961824893951416,
      "attention_bam_384_max_attention": 1.304813027381897,
      "attention_bam_384_min_attention": -0.6892045736312866,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9031034902996646,
      "attention_bam_384_attention_skewness": 0.4814198620842681,
      "attention_bam_384_attention_sparsity": 0.770355224609375,
      "attention_bam_384_attention_concentration_10": -1.9497187555813205,
      "attention_bam_384_attention_concentration_20": -2.9370375797586337,
      "attention_bam_384_attention_center_y": 0.48989258269160374,
      "attention_bam_384_attention_center_x": 0.477981283755815,
      "attention_bam_384_attention_center_distance": 0.034263209122556065,
      "attention_bam_384_attention_spatial_variance": 172.64468161664175,
      "attention_bam_384_attention_spatial_std": 13.139432317137668,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 21.471037451180532,
      "attention_bam_384_peak_intensity_mean": 0.34576770663261414,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12299094349145889,
      "attention_bam_16_std_attention": 0.5161060690879822,
      "attention_bam_16_max_attention": 3.0874791145324707,
      "attention_bam_16_min_attention": -0.9417303800582886,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8175804133180518,
      "attention_bam_16_attention_skewness": 0.7905958598897322,
      "attention_bam_16_attention_sparsity": 0.534423828125,
      "attention_bam_16_attention_concentration_10": 0.9391337850065873,
      "attention_bam_16_attention_concentration_20": 1.4922108741968323,
      "attention_bam_16_attention_center_y": 0.47852591112493337,
      "attention_bam_16_attention_center_x": 0.4477169645398542,
      "attention_bam_16_attention_center_distance": 0.0799331256731666,
      "attention_bam_16_attention_spatial_variance": 43.68849865185563,
      "attention_bam_16_attention_spatial_std": 6.609727577733868,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 8.405378515850842,
      "attention_bam_16_peak_intensity_mean": 0.27054059505462646,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 768,
      "phase": "train",
      "loss": 0.005481026601046324,
      "timestamp": 1759544016.5067856,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005481026601046324,
      "ssim": 0.9192453026771545,
      "attention_bam_384_mean_attention": -0.018790287896990776,
      "attention_bam_384_std_attention": 0.1681278944015503,
      "attention_bam_384_max_attention": 1.600623607635498,
      "attention_bam_384_min_attention": -0.7112661004066467,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9257079749418149,
      "attention_bam_384_attention_skewness": 0.4082567573698608,
      "attention_bam_384_attention_sparsity": 0.7774683634440104,
      "attention_bam_384_attention_concentration_10": -1.581712693927222,
      "attention_bam_384_attention_concentration_20": -2.3807079846177515,
      "attention_bam_384_attention_center_y": 0.4873791305397091,
      "attention_bam_384_attention_center_x": 0.48162414280839544,
      "attention_bam_384_attention_center_distance": 0.0315264483714848,
      "attention_bam_384_attention_spatial_variance": 171.79126274759,
      "attention_bam_384_attention_spatial_std": 13.10691659955117,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 17.373772627750007,
      "attention_bam_384_peak_intensity_mean": 0.3060505986213684,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12913167476654053,
      "attention_bam_16_std_attention": 0.5305578708648682,
      "attention_bam_16_max_attention": 3.0201938152313232,
      "attention_bam_16_min_attention": -1.074966549873352,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.4204942790101147,
      "attention_bam_16_attention_skewness": 0.6651318791369043,
      "attention_bam_16_attention_sparsity": 0.520263671875,
      "attention_bam_16_attention_concentration_10": 0.9052809985658328,
      "attention_bam_16_attention_concentration_20": 1.4504280003603052,
      "attention_bam_16_attention_center_y": 0.4823866113425658,
      "attention_bam_16_attention_center_x": 0.46344935452305064,
      "attention_bam_16_attention_center_distance": 0.05737911021930318,
      "attention_bam_16_attention_spatial_variance": 42.944961282956704,
      "attention_bam_16_attention_spatial_std": 6.5532405177100514,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.033872039279979,
      "attention_bam_16_peak_intensity_mean": 0.3031999468803406,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 769,
      "phase": "train",
      "loss": 0.0037211976014077663,
      "timestamp": 1759544016.6714742,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0037211976014077663,
      "ssim": 0.9364548921585083,
      "attention_bam_384_mean_attention": -0.0188657995313406,
      "attention_bam_384_std_attention": 0.162274569272995,
      "attention_bam_384_max_attention": 1.4434329271316528,
      "attention_bam_384_min_attention": -0.6505119800567627,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4959484010361663,
      "attention_bam_384_attention_skewness": 0.5143672885295961,
      "attention_bam_384_attention_sparsity": 0.7894414265950521,
      "attention_bam_384_attention_concentration_10": -1.5193850698139695,
      "attention_bam_384_attention_concentration_20": -2.253373895668661,
      "attention_bam_384_attention_center_y": 0.48167092073717577,
      "attention_bam_384_attention_center_x": 0.4905041255968728,
      "attention_bam_384_attention_center_distance": 0.029193382034387858,
      "attention_bam_384_attention_spatial_variance": 172.41805237981427,
      "attention_bam_384_attention_spatial_std": 13.130805473382594,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 18.130060632894033,
      "attention_bam_384_peak_intensity_mean": 0.31134575605392456,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13902394473552704,
      "attention_bam_16_std_attention": 0.5053867697715759,
      "attention_bam_16_max_attention": 2.6087124347686768,
      "attention_bam_16_min_attention": -0.9492961168289185,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.2333657849709025,
      "attention_bam_16_attention_skewness": 0.8621476202145927,
      "attention_bam_16_attention_sparsity": 0.517578125,
      "attention_bam_16_attention_concentration_10": 0.8414303443925002,
      "attention_bam_16_attention_concentration_20": 1.2997812693138622,
      "attention_bam_16_attention_center_y": 0.4668881264356066,
      "attention_bam_16_attention_center_x": 0.4937716232437974,
      "attention_bam_16_attention_center_distance": 0.047648480520612144,
      "attention_bam_16_attention_spatial_variance": 43.85237626548995,
      "attention_bam_16_attention_spatial_std": 6.62211267387455,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.52533405655548,
      "attention_bam_16_peak_intensity_mean": 0.31642335653305054,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 770,
      "phase": "train",
      "loss": 0.006636634469032288,
      "timestamp": 1759544016.9347665,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006636634469032288,
      "ssim": 0.8763973712921143,
      "attention_bam_384_mean_attention": -0.0161123126745224,
      "attention_bam_384_std_attention": 0.16522608697414398,
      "attention_bam_384_max_attention": 1.1467366218566895,
      "attention_bam_384_min_attention": -0.7320133447647095,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5952102362787866,
      "attention_bam_384_attention_skewness": 0.276845740083968,
      "attention_bam_384_attention_sparsity": 0.7718760172526041,
      "attention_bam_384_attention_concentration_10": -1.7893704276784441,
      "attention_bam_384_attention_concentration_20": -2.7197824674957234,
      "attention_bam_384_attention_center_y": 0.48384128960458406,
      "attention_bam_384_attention_center_x": 0.4847453730760997,
      "attention_bam_384_attention_center_distance": 0.03142634449726238,
      "attention_bam_384_attention_spatial_variance": 171.7310400728037,
      "attention_bam_384_attention_spatial_std": 13.104619035775276,
      "attention_bam_384_num_attention_peaks": 18,
      "attention_bam_384_peak_separation_mean": 18.666810820440197,
      "attention_bam_384_peak_intensity_mean": 0.38820716738700867,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14333373308181763,
      "attention_bam_16_std_attention": 0.5001968741416931,
      "attention_bam_16_max_attention": 2.156733274459839,
      "attention_bam_16_min_attention": -1.059173583984375,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.08524862460728588,
      "attention_bam_16_attention_skewness": 0.5287831032071127,
      "attention_bam_16_attention_sparsity": 0.502197265625,
      "attention_bam_16_attention_concentration_10": 0.7781852598546477,
      "attention_bam_16_attention_concentration_20": 1.2517086039406031,
      "attention_bam_16_attention_center_y": 0.47119149444437114,
      "attention_bam_16_attention_center_x": 0.47251774381621686,
      "attention_bam_16_attention_center_distance": 0.056306383249144776,
      "attention_bam_16_attention_spatial_variance": 43.36820551762644,
      "attention_bam_16_attention_spatial_std": 6.585454085909827,
      "attention_bam_16_num_attention_peaks": 12,
      "attention_bam_16_peak_separation_mean": 8.848157382312815,
      "attention_bam_16_peak_intensity_mean": 0.3835362195968628,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 771,
      "phase": "train",
      "loss": 0.005051964428275824,
      "timestamp": 1759544017.1354804,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005051964428275824,
      "ssim": 0.8911138772964478,
      "attention_bam_384_mean_attention": -0.01663905195891857,
      "attention_bam_384_std_attention": 0.1677810549736023,
      "attention_bam_384_max_attention": 1.3134753704071045,
      "attention_bam_384_min_attention": -0.7662011384963989,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9446647669698902,
      "attention_bam_384_attention_skewness": 0.3293343140282331,
      "attention_bam_384_attention_sparsity": 0.7778676350911459,
      "attention_bam_384_attention_concentration_10": -1.7807222251189085,
      "attention_bam_384_attention_concentration_20": -2.678904803708462,
      "attention_bam_384_attention_center_y": 0.4848851449462638,
      "attention_bam_384_attention_center_x": 0.48581688603447276,
      "attention_bam_384_attention_center_distance": 0.029312781002647604,
      "attention_bam_384_attention_spatial_variance": 172.7303424028836,
      "attention_bam_384_attention_spatial_std": 13.142691596582626,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 21.762289409248993,
      "attention_bam_384_peak_intensity_mean": 0.36976784467697144,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14388379454612732,
      "attention_bam_16_std_attention": 0.5059360265731812,
      "attention_bam_16_max_attention": 2.3263776302337646,
      "attention_bam_16_min_attention": -1.0789809226989746,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.1966777251527314,
      "attention_bam_16_attention_skewness": 0.5463585986202387,
      "attention_bam_16_attention_sparsity": 0.50390625,
      "attention_bam_16_attention_concentration_10": 0.78465096595788,
      "attention_bam_16_attention_concentration_20": 1.2616847478596234,
      "attention_bam_16_attention_center_y": 0.47148626608087957,
      "attention_bam_16_attention_center_x": 0.4755181612753553,
      "attention_bam_16_attention_center_distance": 0.05314872433746481,
      "attention_bam_16_attention_spatial_variance": 44.03075228765033,
      "attention_bam_16_attention_spatial_std": 6.635567216723099,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 11.73314173851768,
      "attention_bam_16_peak_intensity_mean": 0.367457777261734,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 772,
      "phase": "train",
      "loss": 0.004346105270087719,
      "timestamp": 1759544017.3207912,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004346105270087719,
      "ssim": 0.9212630987167358,
      "attention_bam_384_mean_attention": -0.015197780914604664,
      "attention_bam_384_std_attention": 0.1808084100484848,
      "attention_bam_384_max_attention": 1.209653377532959,
      "attention_bam_384_min_attention": -0.744662880897522,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6067956128404348,
      "attention_bam_384_attention_skewness": 0.283796937534815,
      "attention_bam_384_attention_sparsity": 0.7584025065104166,
      "attention_bam_384_attention_concentration_10": -2.121319533587941,
      "attention_bam_384_attention_concentration_20": -3.2127874550563735,
      "attention_bam_384_attention_center_y": 0.4810133697989577,
      "attention_bam_384_attention_center_x": 0.48527524978964726,
      "attention_bam_384_attention_center_distance": 0.0339797114510531,
      "attention_bam_384_attention_spatial_variance": 170.919323302666,
      "attention_bam_384_attention_spatial_std": 13.073611716073948,
      "attention_bam_384_num_attention_peaks": 26,
      "attention_bam_384_peak_separation_mean": 18.59137533066666,
      "attention_bam_384_peak_intensity_mean": 0.3799959421157837,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14043954014778137,
      "attention_bam_16_std_attention": 0.5379236936569214,
      "attention_bam_16_max_attention": 2.392550468444824,
      "attention_bam_16_min_attention": -1.0078110694885254,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.20506492426718603,
      "attention_bam_16_attention_skewness": 0.5506391191699489,
      "attention_bam_16_attention_sparsity": 0.51318359375,
      "attention_bam_16_attention_concentration_10": 0.8493242464523519,
      "attention_bam_16_attention_concentration_20": 1.359017194937126,
      "attention_bam_16_attention_center_y": 0.4545092748546851,
      "attention_bam_16_attention_center_x": 0.4681644974521147,
      "attention_bam_16_attention_center_distance": 0.07852267566407801,
      "attention_bam_16_attention_spatial_variance": 42.599077940859594,
      "attention_bam_16_attention_spatial_std": 6.526796912794176,
      "attention_bam_16_num_attention_peaks": 12,
      "attention_bam_16_peak_separation_mean": 8.804157344865008,
      "attention_bam_16_peak_intensity_mean": 0.34104928374290466,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 773,
      "phase": "train",
      "loss": 0.0032814317382872105,
      "timestamp": 1759544017.5166497,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0032814317382872105,
      "ssim": 0.935818076133728,
      "attention_bam_384_mean_attention": -0.014634586870670319,
      "attention_bam_384_std_attention": 0.15804482996463776,
      "attention_bam_384_max_attention": 1.0661797523498535,
      "attention_bam_384_min_attention": -0.6664338111877441,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8737128404734995,
      "attention_bam_384_attention_skewness": 0.37687020947500866,
      "attention_bam_384_attention_sparsity": 0.7844289143880209,
      "attention_bam_384_attention_concentration_10": -1.9328641396970763,
      "attention_bam_384_attention_concentration_20": -2.90337696216969,
      "attention_bam_384_attention_center_y": 0.4796378860751367,
      "attention_bam_384_attention_center_x": 0.47898735429017847,
      "attention_bam_384_attention_center_distance": 0.04137987344629254,
      "attention_bam_384_attention_spatial_variance": 172.59367748751765,
      "attention_bam_384_attention_spatial_std": 13.137491293527757,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 16.26880564392002,
      "attention_bam_384_peak_intensity_mean": 0.3833821415901184,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14238880574703217,
      "attention_bam_16_std_attention": 0.49727508425712585,
      "attention_bam_16_max_attention": 2.334887981414795,
      "attention_bam_16_min_attention": -1.0639853477478027,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5462429902811303,
      "attention_bam_16_attention_skewness": 0.6337281857283795,
      "attention_bam_16_attention_sparsity": 0.50634765625,
      "attention_bam_16_attention_concentration_10": 0.7890042133489454,
      "attention_bam_16_attention_concentration_20": 1.2483265485993926,
      "attention_bam_16_attention_center_y": 0.452673339176896,
      "attention_bam_16_attention_center_x": 0.44846888725148387,
      "attention_bam_16_attention_center_distance": 0.09894714150257608,
      "attention_bam_16_attention_spatial_variance": 43.994009122838065,
      "attention_bam_16_attention_spatial_std": 6.632797985981336,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 10.492511627460782,
      "attention_bam_16_peak_intensity_mean": 0.3719911277294159,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 774,
      "phase": "train",
      "loss": 0.005516262259334326,
      "timestamp": 1759544017.696592,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005516262259334326,
      "ssim": 0.9202093482017517,
      "attention_bam_384_mean_attention": -0.01488493662327528,
      "attention_bam_384_std_attention": 0.1659441441297531,
      "attention_bam_384_max_attention": 1.262125849723816,
      "attention_bam_384_min_attention": -0.6971408128738403,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0945670263166232,
      "attention_bam_384_attention_skewness": 0.3519336004477187,
      "attention_bam_384_attention_sparsity": 0.7775446573893229,
      "attention_bam_384_attention_concentration_10": -1.9839692118135155,
      "attention_bam_384_attention_concentration_20": -2.969531324695774,
      "attention_bam_384_attention_center_y": 0.4827739518960279,
      "attention_bam_384_attention_center_x": 0.484449575018967,
      "attention_bam_384_attention_center_distance": 0.03281927635920986,
      "attention_bam_384_attention_spatial_variance": 172.2823562243047,
      "attention_bam_384_attention_spatial_std": 13.12563736449795,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 18.327611070450832,
      "attention_bam_384_peak_intensity_mean": 0.3534356951713562,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14896953105926514,
      "attention_bam_16_std_attention": 0.4859470725059509,
      "attention_bam_16_max_attention": 2.877603054046631,
      "attention_bam_16_min_attention": -1.0492634773254395,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.9188326922367622,
      "attention_bam_16_attention_skewness": 0.6773059863678812,
      "attention_bam_16_attention_sparsity": 0.503662109375,
      "attention_bam_16_attention_concentration_10": 0.7418744553340314,
      "attention_bam_16_attention_concentration_20": 1.1782063254470025,
      "attention_bam_16_attention_center_y": 0.46856696384793195,
      "attention_bam_16_attention_center_x": 0.47148394310178865,
      "attention_bam_16_attention_center_distance": 0.0600200177067492,
      "attention_bam_16_attention_spatial_variance": 43.20576518891545,
      "attention_bam_16_attention_spatial_std": 6.5731092482108835,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.183187174985383,
      "attention_bam_16_peak_intensity_mean": 0.3096112310886383,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 775,
      "phase": "train",
      "loss": 0.00707398122176528,
      "timestamp": 1759544017.857292,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00707398122176528,
      "ssim": 0.9110320806503296,
      "attention_bam_384_mean_attention": -0.015679867938160896,
      "attention_bam_384_std_attention": 0.17118239402770996,
      "attention_bam_384_max_attention": 1.2500866651535034,
      "attention_bam_384_min_attention": -0.8011196255683899,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5205776784549725,
      "attention_bam_384_attention_skewness": 0.26317539382137883,
      "attention_bam_384_attention_sparsity": 0.7666600545247396,
      "attention_bam_384_attention_concentration_10": -1.9260379483930032,
      "attention_bam_384_attention_concentration_20": -2.9305373990601336,
      "attention_bam_384_attention_center_y": 0.48189982485335653,
      "attention_bam_384_attention_center_x": 0.48459304716213064,
      "attention_bam_384_attention_center_distance": 0.03361519109234694,
      "attention_bam_384_attention_spatial_variance": 171.62214758988594,
      "attention_bam_384_attention_spatial_std": 13.10046364026426,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 20.54154135398546,
      "attention_bam_384_peak_intensity_mean": 0.38810479640960693,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14764559268951416,
      "attention_bam_16_std_attention": 0.5174378752708435,
      "attention_bam_16_max_attention": 2.4862022399902344,
      "attention_bam_16_min_attention": -1.0571022033691406,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.05882925491661872,
      "attention_bam_16_attention_skewness": 0.48312056520747737,
      "attention_bam_16_attention_sparsity": 0.498779296875,
      "attention_bam_16_attention_concentration_10": 0.7763847240294021,
      "attention_bam_16_attention_concentration_20": 1.2515290167821402,
      "attention_bam_16_attention_center_y": 0.46070023237399615,
      "attention_bam_16_attention_center_x": 0.46986102978793964,
      "attention_bam_16_attention_center_distance": 0.07004040635092519,
      "attention_bam_16_attention_spatial_variance": 43.074553945785205,
      "attention_bam_16_attention_spatial_std": 6.563120747463451,
      "attention_bam_16_num_attention_peaks": 11,
      "attention_bam_16_peak_separation_mean": 9.635021511599476,
      "attention_bam_16_peak_intensity_mean": 0.34824758768081665,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 776,
      "phase": "train",
      "loss": 0.00905849039554596,
      "timestamp": 1759544018.0091357,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00905849039554596,
      "ssim": 0.8580353260040283,
      "attention_bam_384_mean_attention": -0.01572793908417225,
      "attention_bam_384_std_attention": 0.13012680411338806,
      "attention_bam_384_max_attention": 0.7921732068061829,
      "attention_bam_384_min_attention": -0.6155171990394592,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5773615791647697,
      "attention_bam_384_attention_skewness": 0.06185165585104034,
      "attention_bam_384_attention_sparsity": 0.8263524373372396,
      "attention_bam_384_attention_concentration_10": -1.376084701737424,
      "attention_bam_384_attention_concentration_20": -2.098029111290322,
      "attention_bam_384_attention_center_y": 0.4858576950049813,
      "attention_bam_384_attention_center_x": 0.4857949024921238,
      "attention_bam_384_attention_center_distance": 0.028347472048858263,
      "attention_bam_384_attention_spatial_variance": 170.65733372628432,
      "attention_bam_384_attention_spatial_std": 13.063588087745432,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 19.876866008951435,
      "attention_bam_384_peak_intensity_mean": 0.4305717945098877,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1456097960472107,
      "attention_bam_16_std_attention": 0.40103065967559814,
      "attention_bam_16_max_attention": 1.9472427368164062,
      "attention_bam_16_min_attention": -0.8764994144439697,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.12325937050091396,
      "attention_bam_16_attention_skewness": 0.2893808251477165,
      "attention_bam_16_attention_sparsity": 0.4658203125,
      "attention_bam_16_attention_concentration_10": 0.6083583340701878,
      "attention_bam_16_attention_concentration_20": 0.9991924645963932,
      "attention_bam_16_attention_center_y": 0.4705851169404306,
      "attention_bam_16_attention_center_x": 0.4725044672370332,
      "attention_bam_16_attention_center_distance": 0.05694277245318362,
      "attention_bam_16_attention_spatial_variance": 42.213691440616174,
      "attention_bam_16_attention_spatial_std": 6.497206433584835,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.81065608641348,
      "attention_bam_16_peak_intensity_mean": 0.36436325311660767,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 777,
      "phase": "train",
      "loss": 0.006401551887392998,
      "timestamp": 1759544018.1604247,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006401551887392998,
      "ssim": 0.8936454057693481,
      "attention_bam_384_mean_attention": -0.015767700970172882,
      "attention_bam_384_std_attention": 0.1728595793247223,
      "attention_bam_384_max_attention": 1.2521425485610962,
      "attention_bam_384_min_attention": -0.8165358901023865,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5596801313150692,
      "attention_bam_384_attention_skewness": 0.2927689812980617,
      "attention_bam_384_attention_sparsity": 0.7642822265625,
      "attention_bam_384_attention_concentration_10": -1.9428749636780291,
      "attention_bam_384_attention_concentration_20": -2.947193024324657,
      "attention_bam_384_attention_center_y": 0.4804898238371872,
      "attention_bam_384_attention_center_x": 0.4842241213638569,
      "attention_bam_384_attention_center_distance": 0.03548310360287853,
      "attention_bam_384_attention_spatial_variance": 171.2455587725606,
      "attention_bam_384_attention_spatial_std": 13.086082636624322,
      "attention_bam_384_num_attention_peaks": 19,
      "attention_bam_384_peak_separation_mean": 18.19849568344105,
      "attention_bam_384_peak_intensity_mean": 0.3901137411594391,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14723140001296997,
      "attention_bam_16_std_attention": 0.5140345096588135,
      "attention_bam_16_max_attention": 2.3136868476867676,
      "attention_bam_16_min_attention": -1.0599833726882935,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.006015500526899142,
      "attention_bam_16_attention_skewness": 0.48230547636412924,
      "attention_bam_16_attention_sparsity": 0.49853515625,
      "attention_bam_16_attention_concentration_10": 0.7641266684703623,
      "attention_bam_16_attention_concentration_20": 1.2494634904067197,
      "attention_bam_16_attention_center_y": 0.45177648123297526,
      "attention_bam_16_attention_center_x": 0.4691960041673825,
      "attention_bam_16_attention_center_distance": 0.0809245812041002,
      "attention_bam_16_attention_spatial_variance": 42.94996209543088,
      "attention_bam_16_attention_spatial_std": 6.553622059245626,
      "attention_bam_16_num_attention_peaks": 11,
      "attention_bam_16_peak_separation_mean": 9.241096435374079,
      "attention_bam_16_peak_intensity_mean": 0.3645275831222534,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 778,
      "phase": "train",
      "loss": 0.00530106108635664,
      "timestamp": 1759544018.3099306,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00530106108635664,
      "ssim": 0.8897682428359985,
      "attention_bam_384_mean_attention": -0.016291221603751183,
      "attention_bam_384_std_attention": 0.1619449406862259,
      "attention_bam_384_max_attention": 1.1728851795196533,
      "attention_bam_384_min_attention": -0.6221098899841309,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5683491070725628,
      "attention_bam_384_attention_skewness": 0.3354017477965172,
      "attention_bam_384_attention_sparsity": 0.7792714436848959,
      "attention_bam_384_attention_concentration_10": -1.771618039665327,
      "attention_bam_384_attention_concentration_20": -2.687975730647879,
      "attention_bam_384_attention_center_y": 0.4803415353792799,
      "attention_bam_384_attention_center_x": 0.4816643946323231,
      "attention_bam_384_attention_center_distance": 0.03801709235181684,
      "attention_bam_384_attention_spatial_variance": 172.15429637183993,
      "attention_bam_384_attention_spatial_std": 13.120758223968611,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 20.82250650507503,
      "attention_bam_384_peak_intensity_mean": 0.3415166139602661,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14548464119434357,
      "attention_bam_16_std_attention": 0.508811891078949,
      "attention_bam_16_max_attention": 2.506052017211914,
      "attention_bam_16_min_attention": -1.0224297046661377,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.13289056945673483,
      "attention_bam_16_attention_skewness": 0.5109143723367661,
      "attention_bam_16_attention_sparsity": 0.501708984375,
      "attention_bam_16_attention_concentration_10": 0.7775061200943874,
      "attention_bam_16_attention_concentration_20": 1.2499172155460012,
      "attention_bam_16_attention_center_y": 0.4551242557840952,
      "attention_bam_16_attention_center_x": 0.4637578628525283,
      "attention_bam_16_attention_center_distance": 0.08157603721617593,
      "attention_bam_16_attention_spatial_variance": 43.42674988404513,
      "attention_bam_16_attention_spatial_std": 6.589897562484953,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 11.367477339150563,
      "attention_bam_16_peak_intensity_mean": 0.3346383571624756,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 779,
      "phase": "train",
      "loss": 0.006644878536462784,
      "timestamp": 1759544018.459996,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006644878536462784,
      "ssim": 0.8877710103988647,
      "attention_bam_384_mean_attention": -0.016696974635124207,
      "attention_bam_384_std_attention": 0.17804546654224396,
      "attention_bam_384_max_attention": 1.0878589153289795,
      "attention_bam_384_min_attention": -0.7335017919540405,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.44317726795381507,
      "attention_bam_384_attention_skewness": 0.2576630236135508,
      "attention_bam_384_attention_sparsity": 0.7604726155598959,
      "attention_bam_384_attention_concentration_10": -1.8780081777901576,
      "attention_bam_384_attention_concentration_20": -2.8569503011307678,
      "attention_bam_384_attention_center_y": 0.48532965965781155,
      "attention_bam_384_attention_center_x": 0.48317695299699953,
      "attention_bam_384_attention_center_distance": 0.031566874923590546,
      "attention_bam_384_attention_spatial_variance": 170.49235560780022,
      "attention_bam_384_attention_spatial_std": 13.057272135013509,
      "attention_bam_384_num_attention_peaks": 22,
      "attention_bam_384_peak_separation_mean": 18.717777151656808,
      "attention_bam_384_peak_intensity_mean": 0.3974737226963043,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1419895887374878,
      "attention_bam_16_std_attention": 0.5268672108650208,
      "attention_bam_16_max_attention": 2.650362253189087,
      "attention_bam_16_min_attention": -1.0088642835617065,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.12563790929092145,
      "attention_bam_16_attention_skewness": 0.5413549396473117,
      "attention_bam_16_attention_sparsity": 0.504638671875,
      "attention_bam_16_attention_concentration_10": 0.8261735524732116,
      "attention_bam_16_attention_concentration_20": 1.3220262657243333,
      "attention_bam_16_attention_center_y": 0.4738924108722381,
      "attention_bam_16_attention_center_x": 0.46638070633059464,
      "attention_bam_16_attention_center_distance": 0.0601973939119253,
      "attention_bam_16_attention_spatial_variance": 42.19257695841732,
      "attention_bam_16_attention_spatial_std": 6.495581341066965,
      "attention_bam_16_num_attention_peaks": 11,
      "attention_bam_16_peak_separation_mean": 8.445285914891475,
      "attention_bam_16_peak_intensity_mean": 0.3222980797290802,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 780,
      "phase": "train",
      "loss": 0.0047348178923130035,
      "timestamp": 1759544018.6495242,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0047348178923130035,
      "ssim": 0.9062322974205017,
      "attention_bam_384_mean_attention": -0.017786042764782906,
      "attention_bam_384_std_attention": 0.1685178577899933,
      "attention_bam_384_max_attention": 1.1048266887664795,
      "attention_bam_384_min_attention": -0.7369899153709412,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9760733558658177,
      "attention_bam_384_attention_skewness": 0.2988491970121965,
      "attention_bam_384_attention_sparsity": 0.7832438151041666,
      "attention_bam_384_attention_concentration_10": -1.6669671811788416,
      "attention_bam_384_attention_concentration_20": -2.483439993530143,
      "attention_bam_384_attention_center_y": 0.4829358253429091,
      "attention_bam_384_attention_center_x": 0.48209725925783453,
      "attention_bam_384_attention_center_distance": 0.034976969074203536,
      "attention_bam_384_attention_spatial_variance": 171.7316237043868,
      "attention_bam_384_attention_spatial_std": 13.104641303919264,
      "attention_bam_384_num_attention_peaks": 20,
      "attention_bam_384_peak_separation_mean": 19.623199207203896,
      "attention_bam_384_peak_intensity_mean": 0.3971150815486908,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13980618119239807,
      "attention_bam_16_std_attention": 0.5222060084342957,
      "attention_bam_16_max_attention": 2.6357154846191406,
      "attention_bam_16_min_attention": -1.0834217071533203,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.38719443627839034,
      "attention_bam_16_attention_skewness": 0.5684753477684629,
      "attention_bam_16_attention_sparsity": 0.506591796875,
      "attention_bam_16_attention_concentration_10": 0.8282358444549882,
      "attention_bam_16_attention_concentration_20": 1.3219836554687727,
      "attention_bam_16_attention_center_y": 0.4641944076630471,
      "attention_bam_16_attention_center_x": 0.46101621018310646,
      "attention_bam_16_attention_center_distance": 0.07485688092737758,
      "attention_bam_16_attention_spatial_variance": 43.417995198656264,
      "attention_bam_16_attention_spatial_std": 6.589233278512475,
      "attention_bam_16_num_attention_peaks": 12,
      "attention_bam_16_peak_separation_mean": 9.363342720333677,
      "attention_bam_16_peak_intensity_mean": 0.3346256911754608,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 781,
      "phase": "train",
      "loss": 0.004552383907139301,
      "timestamp": 1759544018.8047926,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004552383907139301,
      "ssim": 0.9060265421867371,
      "attention_bam_384_mean_attention": -0.017328357324004173,
      "attention_bam_384_std_attention": 0.14127463102340698,
      "attention_bam_384_max_attention": 0.931155800819397,
      "attention_bam_384_min_attention": -0.6300022602081299,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.691550582724572,
      "attention_bam_384_attention_skewness": 0.23952406156477368,
      "attention_bam_384_attention_sparsity": 0.8115946451822916,
      "attention_bam_384_attention_concentration_10": -1.3970280989773227,
      "attention_bam_384_attention_concentration_20": -2.1083457778259067,
      "attention_bam_384_attention_center_y": 0.48071962977784066,
      "attention_bam_384_attention_center_x": 0.48199201912374084,
      "attention_bam_384_attention_center_distance": 0.03731005363553486,
      "attention_bam_384_attention_spatial_variance": 169.62103541557937,
      "attention_bam_384_attention_spatial_std": 13.023864073906,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 17.155739826840108,
      "attention_bam_384_peak_intensity_mean": 0.39913690090179443,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13444487750530243,
      "attention_bam_16_std_attention": 0.46218568086624146,
      "attention_bam_16_max_attention": 1.9500458240509033,
      "attention_bam_16_min_attention": -1.1492269039154053,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.20201992271790736,
      "attention_bam_16_attention_skewness": 0.5022345904462944,
      "attention_bam_16_attention_sparsity": 0.49951171875,
      "attention_bam_16_attention_concentration_10": 0.7634628448054384,
      "attention_bam_16_attention_concentration_20": 1.222350753537565,
      "attention_bam_16_attention_center_y": 0.45741287820633525,
      "attention_bam_16_attention_center_x": 0.4635134254229975,
      "attention_bam_16_attention_center_distance": 0.07930867628490088,
      "attention_bam_16_attention_spatial_variance": 41.59129822141835,
      "attention_bam_16_attention_spatial_std": 6.449131586610584,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 6.969390777627841,
      "attention_bam_16_peak_intensity_mean": 0.4267527759075165,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 782,
      "phase": "train",
      "loss": 0.003953102044761181,
      "timestamp": 1759544018.944588,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.003953102044761181,
      "ssim": 0.9390515685081482,
      "attention_bam_384_mean_attention": -0.018661675974726677,
      "attention_bam_384_std_attention": 0.19306212663650513,
      "attention_bam_384_max_attention": 1.1616342067718506,
      "attention_bam_384_min_attention": -0.7226814031600952,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7591448040307531,
      "attention_bam_384_attention_skewness": 0.4321478837125708,
      "attention_bam_384_attention_sparsity": 0.7457936604817709,
      "attention_bam_384_attention_concentration_10": -1.8516288464120398,
      "attention_bam_384_attention_concentration_20": -2.7920275564261066,
      "attention_bam_384_attention_center_y": 0.4812042655778219,
      "attention_bam_384_attention_center_x": 0.48199849579934245,
      "attention_bam_384_attention_center_distance": 0.03680580894248464,
      "attention_bam_384_attention_spatial_variance": 171.67828488752446,
      "attention_bam_384_attention_spatial_std": 13.10260603420268,
      "attention_bam_384_num_attention_peaks": 19,
      "attention_bam_384_peak_separation_mean": 18.82627827805207,
      "attention_bam_384_peak_intensity_mean": 0.37906765937805176,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12464218586683273,
      "attention_bam_16_std_attention": 0.561897337436676,
      "attention_bam_16_max_attention": 2.802826404571533,
      "attention_bam_16_min_attention": -1.0577176809310913,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.686601969814705,
      "attention_bam_16_attention_skewness": 0.7804151649547936,
      "attention_bam_16_attention_sparsity": 0.54150390625,
      "attention_bam_16_attention_concentration_10": 1.007281942065814,
      "attention_bam_16_attention_concentration_20": 1.577131135599038,
      "attention_bam_16_attention_center_y": 0.45847765942724994,
      "attention_bam_16_attention_center_x": 0.4617250736341028,
      "attention_bam_16_attention_center_distance": 0.07986331767406482,
      "attention_bam_16_attention_spatial_variance": 43.35539914746029,
      "attention_bam_16_attention_spatial_std": 6.584481691633768,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 10.198709989669723,
      "attention_bam_16_peak_intensity_mean": 0.3170729875564575,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 783,
      "phase": "train",
      "loss": 0.004617058672010899,
      "timestamp": 1759544019.0950515,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004617058672010899,
      "ssim": 0.9367811679840088,
      "attention_bam_384_mean_attention": -0.01677769608795643,
      "attention_bam_384_std_attention": 0.14278452098369598,
      "attention_bam_384_max_attention": 1.3043255805969238,
      "attention_bam_384_min_attention": -0.6834461092948914,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9006665495226587,
      "attention_bam_384_attention_skewness": 0.28568128198044274,
      "attention_bam_384_attention_sparsity": 0.8113555908203125,
      "attention_bam_384_attention_concentration_10": -1.4740276686317684,
      "attention_bam_384_attention_concentration_20": -2.212697834227529,
      "attention_bam_384_attention_center_y": 0.48473480505132394,
      "attention_bam_384_attention_center_x": 0.47968202263412,
      "attention_bam_384_attention_center_distance": 0.03594012746392245,
      "attention_bam_384_attention_spatial_variance": 169.494592685181,
      "attention_bam_384_attention_spatial_std": 13.019008897960743,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 17.463446347996047,
      "attention_bam_384_peak_intensity_mean": 0.3375830054283142,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1171281486749649,
      "attention_bam_16_std_attention": 0.48576197028160095,
      "attention_bam_16_max_attention": 2.5250086784362793,
      "attention_bam_16_min_attention": -0.9974521398544312,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6737577773179586,
      "attention_bam_16_attention_skewness": 0.6328978479016182,
      "attention_bam_16_attention_sparsity": 0.51708984375,
      "attention_bam_16_attention_concentration_10": 0.9104532668066053,
      "attention_bam_16_attention_concentration_20": 1.4329732936088138,
      "attention_bam_16_attention_center_y": 0.4717471719034338,
      "attention_bam_16_attention_center_x": 0.451679923646133,
      "attention_bam_16_attention_center_distance": 0.07915872755795984,
      "attention_bam_16_attention_spatial_variance": 41.22695721151118,
      "attention_bam_16_attention_spatial_std": 6.420822160090651,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 9.418790298362751,
      "attention_bam_16_peak_intensity_mean": 0.32989802956581116,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 784,
      "phase": "train",
      "loss": 0.007474888116121292,
      "timestamp": 1759544019.276528,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007474888116121292,
      "ssim": 0.9211603403091431,
      "attention_bam_384_mean_attention": -0.01898632012307644,
      "attention_bam_384_std_attention": 0.16437768936157227,
      "attention_bam_384_max_attention": 1.0298740863800049,
      "attention_bam_384_min_attention": -0.6431519985198975,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5047506002889932,
      "attention_bam_384_attention_skewness": 0.32374849011906226,
      "attention_bam_384_attention_sparsity": 0.7813847859700521,
      "attention_bam_384_attention_concentration_10": -1.5260404907761573,
      "attention_bam_384_attention_concentration_20": -2.29615239018414,
      "attention_bam_384_attention_center_y": 0.48324012860793025,
      "attention_bam_384_attention_center_x": 0.47845185373550986,
      "attention_bam_384_attention_center_distance": 0.038606110824960814,
      "attention_bam_384_attention_spatial_variance": 168.4085520609047,
      "attention_bam_384_attention_spatial_std": 12.977232064693329,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 14.4541046461076,
      "attention_bam_384_peak_intensity_mean": 0.3770248591899872,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12367509305477142,
      "attention_bam_16_std_attention": 0.5257635116577148,
      "attention_bam_16_max_attention": 2.4000985622406006,
      "attention_bam_16_min_attention": -0.9555584192276001,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.08768010371016688,
      "attention_bam_16_attention_skewness": 0.587955611997596,
      "attention_bam_16_attention_sparsity": 0.53125,
      "attention_bam_16_attention_concentration_10": 0.9334002032420555,
      "attention_bam_16_attention_concentration_20": 1.4992311162945584,
      "attention_bam_16_attention_center_y": 0.4644443039627796,
      "attention_bam_16_attention_center_x": 0.44934334937441883,
      "attention_bam_16_attention_center_distance": 0.08752489672422817,
      "attention_bam_16_attention_spatial_variance": 40.121534136634665,
      "attention_bam_16_attention_spatial_std": 6.334156150319841,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 7.124741436228496,
      "attention_bam_16_peak_intensity_mean": 0.3378019630908966,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 785,
      "phase": "train",
      "loss": 0.005307921674102545,
      "timestamp": 1759544019.4722207,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005307921674102545,
      "ssim": 0.9047349691390991,
      "attention_bam_384_mean_attention": -0.01795780658721924,
      "attention_bam_384_std_attention": 0.14284168183803558,
      "attention_bam_384_max_attention": 1.2643136978149414,
      "attention_bam_384_min_attention": -0.6485052704811096,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1319153822878345,
      "attention_bam_384_attention_skewness": 0.3839465134031119,
      "attention_bam_384_attention_sparsity": 0.8136825561523438,
      "attention_bam_384_attention_concentration_10": -1.3827255970616343,
      "attention_bam_384_attention_concentration_20": -2.062712978762577,
      "attention_bam_384_attention_center_y": 0.4758798196438152,
      "attention_bam_384_attention_center_x": 0.48323406608134056,
      "attention_bam_384_attention_center_distance": 0.04154225897997695,
      "attention_bam_384_attention_spatial_variance": 170.90671976134695,
      "attention_bam_384_attention_spatial_std": 13.07312968501984,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 16.79837519537596,
      "attention_bam_384_peak_intensity_mean": 0.3338683843612671,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.11715994030237198,
      "attention_bam_16_std_attention": 0.4973088800907135,
      "attention_bam_16_max_attention": 2.7155020236968994,
      "attention_bam_16_min_attention": -0.9029130935668945,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6295705012495492,
      "attention_bam_16_attention_skewness": 0.6376524021091567,
      "attention_bam_16_attention_sparsity": 0.518798828125,
      "attention_bam_16_attention_concentration_10": 0.9257763192686472,
      "attention_bam_16_attention_concentration_20": 1.462462466442372,
      "attention_bam_16_attention_center_y": 0.4341961916681048,
      "attention_bam_16_attention_center_x": 0.46602533111165534,
      "attention_bam_16_attention_center_distance": 0.10473222347542759,
      "attention_bam_16_attention_spatial_variance": 42.293920831602065,
      "attention_bam_16_attention_spatial_std": 6.503377647930502,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 7.247638087674303,
      "attention_bam_16_peak_intensity_mean": 0.3030160665512085,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 786,
      "phase": "train",
      "loss": 0.004486715421080589,
      "timestamp": 1759544019.6694384,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004486715421080589,
      "ssim": 0.92677903175354,
      "attention_bam_384_mean_attention": -0.018819523975253105,
      "attention_bam_384_std_attention": 0.1576204001903534,
      "attention_bam_384_max_attention": 1.478389024734497,
      "attention_bam_384_min_attention": -0.6558573246002197,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8304655888960557,
      "attention_bam_384_attention_skewness": 0.6712320066293562,
      "attention_bam_384_attention_sparsity": 0.8022689819335938,
      "attention_bam_384_attention_concentration_10": -1.5307367987393175,
      "attention_bam_384_attention_concentration_20": -2.2380400702561514,
      "attention_bam_384_attention_center_y": 0.4769751560723344,
      "attention_bam_384_attention_center_x": 0.4843762207328613,
      "attention_bam_384_attention_center_distance": 0.03935088096807062,
      "attention_bam_384_attention_spatial_variance": 171.55741091566162,
      "attention_bam_384_attention_spatial_std": 13.097992629241384,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 17.402100911966052,
      "attention_bam_384_peak_intensity_mean": 0.3005962669849396,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.10744914412498474,
      "attention_bam_16_std_attention": 0.5408739447593689,
      "attention_bam_16_max_attention": 3.1525321006774902,
      "attention_bam_16_min_attention": -1.028803825378418,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.6271974154784115,
      "attention_bam_16_attention_skewness": 0.9761386439455115,
      "attention_bam_16_attention_sparsity": 0.55908203125,
      "attention_bam_16_attention_concentration_10": 1.1309480653041768,
      "attention_bam_16_attention_concentration_20": 1.7488547024269834,
      "attention_bam_16_attention_center_y": 0.44282884039269554,
      "attention_bam_16_attention_center_x": 0.4710545240499041,
      "attention_bam_16_attention_center_distance": 0.09062430213603258,
      "attention_bam_16_attention_spatial_variance": 42.96682494143181,
      "attention_bam_16_attention_spatial_std": 6.554908461712628,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.085217133617181,
      "attention_bam_16_peak_intensity_mean": 0.28069350123405457,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 787,
      "phase": "train",
      "loss": 0.0048337653279304504,
      "timestamp": 1759544019.8641143,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0048337653279304504,
      "ssim": 0.9190151691436768,
      "attention_bam_384_mean_attention": -0.021338505670428276,
      "attention_bam_384_std_attention": 0.1835387498140335,
      "attention_bam_384_max_attention": 1.475357174873352,
      "attention_bam_384_min_attention": -0.6927360892295837,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.590444956824233,
      "attention_bam_384_attention_skewness": 0.662471887981395,
      "attention_bam_384_attention_sparsity": 0.7757771809895834,
      "attention_bam_384_attention_concentration_10": -1.584840323292683,
      "attention_bam_384_attention_concentration_20": -2.314444908573121,
      "attention_bam_384_attention_center_y": 0.4860616582394291,
      "attention_bam_384_attention_center_x": 0.48101383380557355,
      "attention_bam_384_attention_center_distance": 0.03330921427463747,
      "attention_bam_384_attention_spatial_variance": 171.90248550584522,
      "attention_bam_384_attention_spatial_std": 13.111158816284899,
      "attention_bam_384_num_attention_peaks": 21,
      "attention_bam_384_peak_separation_mean": 17.119181584729283,
      "attention_bam_384_peak_intensity_mean": 0.3134683072566986,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12796279788017273,
      "attention_bam_16_std_attention": 0.5748553276062012,
      "attention_bam_16_max_attention": 2.854983329772949,
      "attention_bam_16_min_attention": -1.0862289667129517,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8180510506079726,
      "attention_bam_16_attention_skewness": 0.8739954990713824,
      "attention_bam_16_attention_sparsity": 0.533935546875,
      "attention_bam_16_attention_concentration_10": 1.0345416176315334,
      "attention_bam_16_attention_concentration_20": 1.6032650249978306,
      "attention_bam_16_attention_center_y": 0.47315630647683815,
      "attention_bam_16_attention_center_x": 0.4586141283397829,
      "attention_bam_16_attention_center_distance": 0.06976208504684193,
      "attention_bam_16_attention_spatial_variance": 43.417406954128055,
      "attention_bam_16_attention_spatial_std": 6.589188641564912,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 8.53086887382105,
      "attention_bam_16_peak_intensity_mean": 0.31441032886505127,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 788,
      "phase": "train",
      "loss": 0.007543792482465506,
      "timestamp": 1759544020.0597522,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007543792482465506,
      "ssim": 0.8857868909835815,
      "attention_bam_384_mean_attention": -0.020144954323768616,
      "attention_bam_384_std_attention": 0.17050357162952423,
      "attention_bam_384_max_attention": 0.9593554735183716,
      "attention_bam_384_min_attention": -0.678865909576416,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5240154381468312,
      "attention_bam_384_attention_skewness": 0.29584307338458793,
      "attention_bam_384_attention_sparsity": 0.7746963500976562,
      "attention_bam_384_attention_concentration_10": -1.4742024525903688,
      "attention_bam_384_attention_concentration_20": -2.225809505848265,
      "attention_bam_384_attention_center_y": 0.4916624613139265,
      "attention_bam_384_attention_center_x": 0.4830064621536626,
      "attention_bam_384_attention_center_distance": 0.026769194230558138,
      "attention_bam_384_attention_spatial_variance": 172.55526076099727,
      "attention_bam_384_attention_spatial_std": 13.136029109323612,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 20.866709889930643,
      "attention_bam_384_peak_intensity_mean": 0.40674054622650146,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13044942915439606,
      "attention_bam_16_std_attention": 0.5654999613761902,
      "attention_bam_16_max_attention": 2.3487329483032227,
      "attention_bam_16_min_attention": -1.1643891334533691,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.1196737065073683,
      "attention_bam_16_attention_skewness": 0.49012416926631874,
      "attention_bam_16_attention_sparsity": 0.511474609375,
      "attention_bam_16_attention_concentration_10": 0.9318481644244758,
      "attention_bam_16_attention_concentration_20": 1.506185922270911,
      "attention_bam_16_attention_center_y": 0.49299853097277513,
      "attention_bam_16_attention_center_x": 0.46562128929219404,
      "attention_bam_16_attention_center_distance": 0.04961685839450541,
      "attention_bam_16_attention_spatial_variance": 43.93992538574062,
      "attention_bam_16_attention_spatial_std": 6.628719739568163,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 11.588305534277056,
      "attention_bam_16_peak_intensity_mean": 0.3974508047103882,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 789,
      "phase": "train",
      "loss": 0.004757298622280359,
      "timestamp": 1759544020.2472787,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004757298622280359,
      "ssim": 0.8914992809295654,
      "attention_bam_384_mean_attention": -0.021479284390807152,
      "attention_bam_384_std_attention": 0.16292233765125275,
      "attention_bam_384_max_attention": 1.0277907848358154,
      "attention_bam_384_min_attention": -0.6147639751434326,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.044082559956908,
      "attention_bam_384_attention_skewness": 0.6116926437097474,
      "attention_bam_384_attention_sparsity": 0.7971750895182291,
      "attention_bam_384_attention_concentration_10": -1.3929887976270041,
      "attention_bam_384_attention_concentration_20": -2.0429842535933047,
      "attention_bam_384_attention_center_y": 0.48062532093890525,
      "attention_bam_384_attention_center_x": 0.4852735500975844,
      "attention_bam_384_attention_center_distance": 0.03441646453222004,
      "attention_bam_384_attention_spatial_variance": 170.48616202103696,
      "attention_bam_384_attention_spatial_std": 13.057034962848073,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 20.506331563057035,
      "attention_bam_384_peak_intensity_mean": 0.36716553568840027,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.11377324908971786,
      "attention_bam_16_std_attention": 0.5195814967155457,
      "attention_bam_16_max_attention": 2.5773844718933105,
      "attention_bam_16_min_attention": -0.9241628646850586,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5661592505467166,
      "attention_bam_16_attention_skewness": 0.8410738159434675,
      "attention_bam_16_attention_sparsity": 0.5556640625,
      "attention_bam_16_attention_concentration_10": 1.045933020535581,
      "attention_bam_16_attention_concentration_20": 1.6308398732439202,
      "attention_bam_16_attention_center_y": 0.45569764257977813,
      "attention_bam_16_attention_center_x": 0.47288247554161034,
      "attention_bam_16_attention_center_distance": 0.07345827394841849,
      "attention_bam_16_attention_spatial_variance": 42.1120769572642,
      "attention_bam_16_attention_spatial_std": 6.489381862493854,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.186984579396361,
      "attention_bam_16_peak_intensity_mean": 0.30282482504844666,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 790,
      "phase": "train",
      "loss": 0.004359487444162369,
      "timestamp": 1759544020.4778857,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004359487444162369,
      "ssim": 0.9272679090499878,
      "attention_bam_384_mean_attention": -0.022701321169734,
      "attention_bam_384_std_attention": 0.15913181006908417,
      "attention_bam_384_max_attention": 1.1086878776550293,
      "attention_bam_384_min_attention": -0.6944795250892639,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7598816221439346,
      "attention_bam_384_attention_skewness": 0.39843062040444216,
      "attention_bam_384_attention_sparsity": 0.7976023356119791,
      "attention_bam_384_attention_concentration_10": -1.2304728742998914,
      "attention_bam_384_attention_concentration_20": -1.8339200278684495,
      "attention_bam_384_attention_center_y": 0.49030803246505633,
      "attention_bam_384_attention_center_x": 0.48181370244069044,
      "attention_bam_384_attention_center_distance": 0.029143632361603482,
      "attention_bam_384_attention_spatial_variance": 170.93836838738585,
      "attention_bam_384_attention_spatial_std": 13.07434007464185,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 19.384873275534535,
      "attention_bam_384_peak_intensity_mean": 0.37647977471351624,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12075822800397873,
      "attention_bam_16_std_attention": 0.527449369430542,
      "attention_bam_16_max_attention": 2.3504300117492676,
      "attention_bam_16_min_attention": -1.0191304683685303,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.09327160791203681,
      "attention_bam_16_attention_skewness": 0.5959069930353775,
      "attention_bam_16_attention_sparsity": 0.531494140625,
      "attention_bam_16_attention_concentration_10": 0.9582327007724326,
      "attention_bam_16_attention_concentration_20": 1.5334193613357892,
      "attention_bam_16_attention_center_y": 0.49140534774525607,
      "attention_bam_16_attention_center_x": 0.45932540688830925,
      "attention_bam_16_attention_center_distance": 0.058792696352209864,
      "attention_bam_16_attention_spatial_variance": 42.52807693478443,
      "attention_bam_16_attention_spatial_std": 6.521355452264846,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.316764047486915,
      "attention_bam_16_peak_intensity_mean": 0.3458710312843323,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 791,
      "phase": "train",
      "loss": 0.005610588472336531,
      "timestamp": 1759544020.6548135,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005610588472336531,
      "ssim": 0.9166115522384644,
      "attention_bam_384_mean_attention": -0.023251406848430634,
      "attention_bam_384_std_attention": 0.17873190343379974,
      "attention_bam_384_max_attention": 1.315664291381836,
      "attention_bam_384_min_attention": -0.7034211158752441,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5186809220245179,
      "attention_bam_384_attention_skewness": 0.5892560293233006,
      "attention_bam_384_attention_sparsity": 0.7834142049153646,
      "attention_bam_384_attention_concentration_10": -1.3882570787196433,
      "attention_bam_384_attention_concentration_20": -2.027148807025484,
      "attention_bam_384_attention_center_y": 0.4800151042571969,
      "attention_bam_384_attention_center_x": 0.47728900902316546,
      "attention_bam_384_attention_center_distance": 0.042782827606425676,
      "attention_bam_384_attention_spatial_variance": 169.4870543430868,
      "attention_bam_384_attention_spatial_std": 13.01871938183963,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 16.10835210418729,
      "attention_bam_384_peak_intensity_mean": 0.3423738479614258,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.11540590226650238,
      "attention_bam_16_std_attention": 0.5690146684646606,
      "attention_bam_16_max_attention": 3.1690359115600586,
      "attention_bam_16_min_attention": -1.088426113128662,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.0078054818134792,
      "attention_bam_16_attention_skewness": 0.8862487835809388,
      "attention_bam_16_attention_sparsity": 0.5458984375,
      "attention_bam_16_attention_concentration_10": 1.1190064145077545,
      "attention_bam_16_attention_concentration_20": 1.719529942728789,
      "attention_bam_16_attention_center_y": 0.453955969802757,
      "attention_bam_16_attention_center_x": 0.44511190641315024,
      "attention_bam_16_attention_center_distance": 0.10131885840655137,
      "attention_bam_16_attention_spatial_variance": 40.99391758634665,
      "attention_bam_16_attention_spatial_std": 6.402649263105597,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 6.5125729443520015,
      "attention_bam_16_peak_intensity_mean": 0.29959195852279663,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 792,
      "phase": "train",
      "loss": 0.007313425652682781,
      "timestamp": 1759544020.8163981,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007313425652682781,
      "ssim": 0.8919875621795654,
      "attention_bam_384_mean_attention": -0.022627102211117744,
      "attention_bam_384_std_attention": 0.1752617508172989,
      "attention_bam_384_max_attention": 1.0929332971572876,
      "attention_bam_384_min_attention": -0.6761980056762695,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.4664565223260464,
      "attention_bam_384_attention_skewness": 0.3259652458709367,
      "attention_bam_384_attention_sparsity": 0.7718709309895834,
      "attention_bam_384_attention_concentration_10": -1.3503799580187226,
      "attention_bam_384_attention_concentration_20": -2.042820256015028,
      "attention_bam_384_attention_center_y": 0.47674020899497177,
      "attention_bam_384_attention_center_x": 0.48583221327416864,
      "attention_bam_384_attention_center_distance": 0.03851607608015736,
      "attention_bam_384_attention_spatial_variance": 172.58459138750592,
      "attention_bam_384_attention_spatial_std": 13.137145480944707,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 19.994055839246997,
      "attention_bam_384_peak_intensity_mean": 0.3748053014278412,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12300069630146027,
      "attention_bam_16_std_attention": 0.5578562617301941,
      "attention_bam_16_max_attention": 2.370910406112671,
      "attention_bam_16_min_attention": -1.0543569326400757,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.10859641287314226,
      "attention_bam_16_attention_skewness": 0.668358974432835,
      "attention_bam_16_attention_sparsity": 0.544189453125,
      "attention_bam_16_attention_concentration_10": 1.0059067020361525,
      "attention_bam_16_attention_concentration_20": 1.6069054739574273,
      "attention_bam_16_attention_center_y": 0.44109805335075974,
      "attention_bam_16_attention_center_x": 0.4760246436726914,
      "attention_bam_16_attention_center_distance": 0.08993616658598876,
      "attention_bam_16_attention_spatial_variance": 43.99275622283874,
      "attention_bam_16_attention_spatial_std": 6.632703537988016,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 12.374494875153252,
      "attention_bam_16_peak_intensity_mean": 0.35886839032173157,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 793,
      "phase": "train",
      "loss": 0.005788767244666815,
      "timestamp": 1759544020.9674156,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005788767244666815,
      "ssim": 0.8864030241966248,
      "attention_bam_384_mean_attention": -0.023977765813469887,
      "attention_bam_384_std_attention": 0.17058029770851135,
      "attention_bam_384_max_attention": 1.0780186653137207,
      "attention_bam_384_min_attention": -0.7085933089256287,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7419149641121487,
      "attention_bam_384_attention_skewness": 0.48922062349079365,
      "attention_bam_384_attention_sparsity": 0.7876714070638021,
      "attention_bam_384_attention_concentration_10": -1.2788357285006902,
      "attention_bam_384_attention_concentration_20": -1.899890043466748,
      "attention_bam_384_attention_center_y": 0.4855635332507756,
      "attention_bam_384_attention_center_x": 0.4817711381046129,
      "attention_bam_384_attention_center_distance": 0.032884737438591674,
      "attention_bam_384_attention_spatial_variance": 171.13004835841932,
      "attention_bam_384_attention_spatial_std": 13.081668408823827,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 18.0274773204518,
      "attention_bam_384_peak_intensity_mean": 0.3897964060306549,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12793861329555511,
      "attention_bam_16_std_attention": 0.5426104664802551,
      "attention_bam_16_max_attention": 2.3452136516571045,
      "attention_bam_16_min_attention": -1.0216989517211914,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.38666210381167376,
      "attention_bam_16_attention_skewness": 0.7551257348632889,
      "attention_bam_16_attention_sparsity": 0.53662109375,
      "attention_bam_16_attention_concentration_10": 0.9607651690424949,
      "attention_bam_16_attention_concentration_20": 1.5179194985859006,
      "attention_bam_16_attention_center_y": 0.47361191153505366,
      "attention_bam_16_attention_center_x": 0.4619503395097506,
      "attention_bam_16_attention_center_distance": 0.06548446955205604,
      "attention_bam_16_attention_spatial_variance": 42.84632597236204,
      "attention_bam_16_attention_spatial_std": 6.545710501722638,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 9.646986825408671,
      "attention_bam_16_peak_intensity_mean": 0.35968971252441406,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 794,
      "phase": "train",
      "loss": 0.0029009671416133642,
      "timestamp": 1759544021.118539,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0029009671416133642,
      "ssim": 0.9560632109642029,
      "attention_bam_384_mean_attention": -0.024435050785541534,
      "attention_bam_384_std_attention": 0.16153287887573242,
      "attention_bam_384_max_attention": 1.0236910581588745,
      "attention_bam_384_min_attention": -0.7055045366287231,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.778959095003172,
      "attention_bam_384_attention_skewness": 0.38707557478641014,
      "attention_bam_384_attention_sparsity": 0.7959187825520834,
      "attention_bam_384_attention_concentration_10": -1.1454440157709198,
      "attention_bam_384_attention_concentration_20": -1.7024597689321075,
      "attention_bam_384_attention_center_y": 0.4891721859334982,
      "attention_bam_384_attention_center_x": 0.4870990583089521,
      "attention_bam_384_attention_center_distance": 0.02381914582744526,
      "attention_bam_384_attention_spatial_variance": 169.87243939777494,
      "attention_bam_384_attention_spatial_std": 13.033512166633173,
      "attention_bam_384_num_attention_peaks": 18,
      "attention_bam_384_peak_separation_mean": 17.685278938062137,
      "attention_bam_384_peak_intensity_mean": 0.3983224630355835,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12684759497642517,
      "attention_bam_16_std_attention": 0.5170643925666809,
      "attention_bam_16_max_attention": 2.3143606185913086,
      "attention_bam_16_min_attention": -0.9958614110946655,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7298455494999572,
      "attention_bam_16_attention_skewness": 0.7481566226563825,
      "attention_bam_16_attention_sparsity": 0.52783203125,
      "attention_bam_16_attention_concentration_10": 0.9124270874591409,
      "attention_bam_16_attention_concentration_20": 1.4321685341849049,
      "attention_bam_16_attention_center_y": 0.48969667315055937,
      "attention_bam_16_attention_center_x": 0.4810416695820208,
      "attention_bam_16_attention_center_distance": 0.03051481071229768,
      "attention_bam_16_attention_spatial_variance": 41.419831835948074,
      "attention_bam_16_attention_spatial_std": 6.435824099208125,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 7.004326685314747,
      "attention_bam_16_peak_intensity_mean": 0.3578857183456421,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 795,
      "phase": "train",
      "loss": 0.004977133125066757,
      "timestamp": 1759544021.2700644,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004977133125066757,
      "ssim": 0.9047904014587402,
      "attention_bam_384_mean_attention": -0.027200376614928246,
      "attention_bam_384_std_attention": 0.17187677323818207,
      "attention_bam_384_max_attention": 1.5349392890930176,
      "attention_bam_384_min_attention": -0.8459927439689636,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5719483166408024,
      "attention_bam_384_attention_skewness": 0.5387633554967025,
      "attention_bam_384_attention_sparsity": 0.7968622843424479,
      "attention_bam_384_attention_concentration_10": -1.1102217813627553,
      "attention_bam_384_attention_concentration_20": -1.6223018725366278,
      "attention_bam_384_attention_center_y": 0.48521140568320964,
      "attention_bam_384_attention_center_x": 0.48586600413006475,
      "attention_bam_384_attention_center_distance": 0.028929996927685653,
      "attention_bam_384_attention_spatial_variance": 171.63892231249775,
      "attention_bam_384_attention_spatial_std": 13.101103858549392,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 18.829033666800047,
      "attention_bam_384_peak_intensity_mean": 0.34944379329681396,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12102670967578888,
      "attention_bam_16_std_attention": 0.5450398921966553,
      "attention_bam_16_max_attention": 3.347646713256836,
      "attention_bam_16_min_attention": -1.089804768562317,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.4723232629760377,
      "attention_bam_16_attention_skewness": 0.9295789020021252,
      "attention_bam_16_attention_sparsity": 0.54150390625,
      "attention_bam_16_attention_concentration_10": 1.0250225160822608,
      "attention_bam_16_attention_concentration_20": 1.587755179902876,
      "attention_bam_16_attention_center_y": 0.4722348877834376,
      "attention_bam_16_attention_center_x": 0.4774622000005422,
      "attention_bam_16_attention_center_distance": 0.05057378540734051,
      "attention_bam_16_attention_spatial_variance": 43.2765503380473,
      "attention_bam_16_attention_spatial_std": 6.578491494107696,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.62116726213975,
      "attention_bam_16_peak_intensity_mean": 0.2800027132034302,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 796,
      "phase": "train",
      "loss": 0.003767173271626234,
      "timestamp": 1759544021.4129283,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.003767173271626234,
      "ssim": 0.9300647974014282,
      "attention_bam_384_mean_attention": -0.02565951459109783,
      "attention_bam_384_std_attention": 0.1578403115272522,
      "attention_bam_384_max_attention": 1.184946060180664,
      "attention_bam_384_min_attention": -0.6577240824699402,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0101246298161888,
      "attention_bam_384_attention_skewness": 0.4580434854506334,
      "attention_bam_384_attention_sparsity": 0.8080952962239584,
      "attention_bam_384_attention_concentration_10": -1.0758532445929294,
      "attention_bam_384_attention_concentration_20": -1.5836402553857518,
      "attention_bam_384_attention_center_y": 0.4810866291634364,
      "attention_bam_384_attention_center_x": 0.47800572324265944,
      "attention_bam_384_attention_center_distance": 0.041023500739938434,
      "attention_bam_384_attention_spatial_variance": 170.31914746186033,
      "attention_bam_384_attention_spatial_std": 13.050637818201084,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 17.01084003080466,
      "attention_bam_384_peak_intensity_mean": 0.34915080666542053,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13118630647659302,
      "attention_bam_16_std_attention": 0.504228949546814,
      "attention_bam_16_max_attention": 2.3685247898101807,
      "attention_bam_16_min_attention": -0.9496110677719116,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.4735196325601927,
      "attention_bam_16_attention_skewness": 0.7075365305059668,
      "attention_bam_16_attention_sparsity": 0.525146484375,
      "attention_bam_16_attention_concentration_10": 0.87189950796695,
      "attention_bam_16_attention_concentration_20": 1.3805978896951125,
      "attention_bam_16_attention_center_y": 0.4589309971299026,
      "attention_bam_16_attention_center_x": 0.4470922093782238,
      "attention_bam_16_attention_center_distance": 0.09471955769767695,
      "attention_bam_16_attention_spatial_variance": 41.662609865566104,
      "attention_bam_16_attention_spatial_std": 6.454657997567811,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.959836742407827,
      "attention_bam_16_peak_intensity_mean": 0.3356277346611023,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 797,
      "phase": "train",
      "loss": 0.005183062981814146,
      "timestamp": 1759544021.5633256,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005183062981814146,
      "ssim": 0.903343141078949,
      "attention_bam_384_mean_attention": -0.024855732917785645,
      "attention_bam_384_std_attention": 0.16009287536144257,
      "attention_bam_384_max_attention": 1.1117267608642578,
      "attention_bam_384_min_attention": -0.7563770413398743,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.561547637257017,
      "attention_bam_384_attention_skewness": 0.21786422056937935,
      "attention_bam_384_attention_sparsity": 0.7947565714518229,
      "attention_bam_384_attention_concentration_10": -1.0766051773349785,
      "attention_bam_384_attention_concentration_20": -1.6199285788526843,
      "attention_bam_384_attention_center_y": 0.4852610306193169,
      "attention_bam_384_attention_center_x": 0.4851910286708478,
      "attention_bam_384_attention_center_distance": 0.02954802363043477,
      "attention_bam_384_attention_spatial_variance": 171.92991834440264,
      "attention_bam_384_attention_spatial_std": 13.112204938316157,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 18.7101838213233,
      "attention_bam_384_peak_intensity_mean": 0.3947550654411316,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13133011758327484,
      "attention_bam_16_std_attention": 0.5027395486831665,
      "attention_bam_16_max_attention": 2.0991461277008057,
      "attention_bam_16_min_attention": -1.0222318172454834,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.0380828643701947,
      "attention_bam_16_attention_skewness": 0.4581671094228054,
      "attention_bam_16_attention_sparsity": 0.505615234375,
      "attention_bam_16_attention_concentration_10": 0.8306104387304936,
      "attention_bam_16_attention_concentration_20": 1.3366697244803518,
      "attention_bam_16_attention_center_y": 0.47385227557092574,
      "attention_bam_16_attention_center_x": 0.47295369121041325,
      "attention_bam_16_attention_center_distance": 0.05320162238053431,
      "attention_bam_16_attention_spatial_variance": 43.76658719497161,
      "attention_bam_16_attention_spatial_std": 6.615632032918065,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 10.078838144307527,
      "attention_bam_16_peak_intensity_mean": 0.37899941205978394,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 798,
      "phase": "train",
      "loss": 0.004508994519710541,
      "timestamp": 1759544021.7508328,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004508994519710541,
      "ssim": 0.9066842198371887,
      "attention_bam_384_mean_attention": -0.025937186554074287,
      "attention_bam_384_std_attention": 0.15401430428028107,
      "attention_bam_384_max_attention": 1.4147017002105713,
      "attention_bam_384_min_attention": -0.7673614621162415,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5843810254645474,
      "attention_bam_384_attention_skewness": 0.4347520632959329,
      "attention_bam_384_attention_sparsity": 0.8130060831705729,
      "attention_bam_384_attention_concentration_10": -1.003764856697721,
      "attention_bam_384_attention_concentration_20": -1.4840264806776835,
      "attention_bam_384_attention_center_y": 0.4847502711854501,
      "attention_bam_384_attention_center_x": 0.4831802780033157,
      "attention_bam_384_attention_center_distance": 0.03210785813358028,
      "attention_bam_384_attention_spatial_variance": 170.60088211254018,
      "attention_bam_384_attention_spatial_std": 13.061427261694648,
      "attention_bam_384_num_attention_peaks": 6,
      "attention_bam_384_peak_separation_mean": 22.38680463449456,
      "attention_bam_384_peak_intensity_mean": 0.34680238366127014,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1347440630197525,
      "attention_bam_16_std_attention": 0.5094484090805054,
      "attention_bam_16_max_attention": 2.7998061180114746,
      "attention_bam_16_min_attention": -0.9428408145904541,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.3274011613567174,
      "attention_bam_16_attention_skewness": 0.8076066144174532,
      "attention_bam_16_attention_sparsity": 0.516845703125,
      "attention_bam_16_attention_concentration_10": 0.8460892155916891,
      "attention_bam_16_attention_concentration_20": 1.3397986025999262,
      "attention_bam_16_attention_center_y": 0.47232285611679414,
      "attention_bam_16_attention_center_x": 0.4663423529226109,
      "attention_bam_16_attention_center_distance": 0.061625668358529936,
      "attention_bam_16_attention_spatial_variance": 42.16582585098027,
      "attention_bam_16_attention_spatial_std": 6.493521837260599,
      "attention_bam_16_num_attention_peaks": 2,
      "attention_bam_16_peak_separation_mean": 11.6542910552294,
      "attention_bam_16_peak_intensity_mean": 0.2968920171260834,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 799,
      "phase": "train",
      "loss": 0.006114650517702103,
      "timestamp": 1759544021.9462767,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006114650517702103,
      "ssim": 0.8751120567321777,
      "attention_bam_384_mean_attention": -0.02692553959786892,
      "attention_bam_384_std_attention": 0.1734059900045395,
      "attention_bam_384_max_attention": 1.1440738439559937,
      "attention_bam_384_min_attention": -0.7101900577545166,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.40594051690247746,
      "attention_bam_384_attention_skewness": 0.2698813886272713,
      "attention_bam_384_attention_sparsity": 0.7784016927083334,
      "attention_bam_384_attention_concentration_10": -1.0892787207571055,
      "attention_bam_384_attention_concentration_20": -1.6491133179510145,
      "attention_bam_384_attention_center_y": 0.48797246318373794,
      "attention_bam_384_attention_center_x": 0.4872412450494257,
      "attention_bam_384_attention_center_distance": 0.024797075220894263,
      "attention_bam_384_attention_spatial_variance": 173.12966516521405,
      "attention_bam_384_attention_spatial_std": 13.157874644683845,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 20.6120091133887,
      "attention_bam_384_peak_intensity_mean": 0.37640753388404846,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13814114034175873,
      "attention_bam_16_std_attention": 0.5423274636268616,
      "attention_bam_16_max_attention": 2.301114797592163,
      "attention_bam_16_min_attention": -0.9858913421630859,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.015526875151595565,
      "attention_bam_16_attention_skewness": 0.5212504948251933,
      "attention_bam_16_attention_sparsity": 0.51123046875,
      "attention_bam_16_attention_concentration_10": 0.8644143597357394,
      "attention_bam_16_attention_concentration_20": 1.3846250928103778,
      "attention_bam_16_attention_center_y": 0.48420015860667187,
      "attention_bam_16_attention_center_x": 0.48305629260675703,
      "attention_bam_16_attention_center_distance": 0.032763522651942094,
      "attention_bam_16_attention_spatial_variance": 44.928880379540146,
      "attention_bam_16_attention_spatial_std": 6.7029008928627425,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.870150891272086,
      "attention_bam_16_peak_intensity_mean": 0.353635311126709,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 800,
      "phase": "train",
      "loss": 0.0043501961044967175,
      "timestamp": 1759544022.1972177,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0043501961044967175,
      "ssim": 0.9463894963264465,
      "attention_bam_384_mean_attention": -0.027117999270558357,
      "attention_bam_384_std_attention": 0.17669053375720978,
      "attention_bam_384_max_attention": 1.4624906778335571,
      "attention_bam_384_min_attention": -0.6930020451545715,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.9323899994558094,
      "attention_bam_384_attention_skewness": 0.6891121217428512,
      "attention_bam_384_attention_sparsity": 0.7968393961588541,
      "attention_bam_384_attention_concentration_10": -1.1682435142163519,
      "attention_bam_384_attention_concentration_20": -1.6851888366041399,
      "attention_bam_384_attention_center_y": 0.4774116859422009,
      "attention_bam_384_attention_center_x": 0.48310531148546176,
      "attention_bam_384_attention_center_distance": 0.03989141341133539,
      "attention_bam_384_attention_spatial_variance": 170.3655645951458,
      "attention_bam_384_attention_spatial_std": 13.052416044363044,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 15.830392230630379,
      "attention_bam_384_peak_intensity_mean": 0.3146640658378601,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12668965756893158,
      "attention_bam_16_std_attention": 0.559076726436615,
      "attention_bam_16_max_attention": 3.1393511295318604,
      "attention_bam_16_min_attention": -0.9864044189453125,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.365489747230141,
      "attention_bam_16_attention_skewness": 1.1287736423604884,
      "attention_bam_16_attention_sparsity": 0.53857421875,
      "attention_bam_16_attention_concentration_10": 1.0140015306792987,
      "attention_bam_16_attention_concentration_20": 1.534925256959983,
      "attention_bam_16_attention_center_y": 0.4434334737011435,
      "attention_bam_16_attention_center_x": 0.4641534878540572,
      "attention_bam_16_attention_center_distance": 0.09470738440637508,
      "attention_bam_16_attention_spatial_variance": 41.81687564267631,
      "attention_bam_16_attention_spatial_std": 6.466596913576438,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 7.759729112451355,
      "attention_bam_16_peak_intensity_mean": 0.2873445451259613,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 801,
      "phase": "train",
      "loss": 0.004499531351029873,
      "timestamp": 1759544024.8031805,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004499531351029873,
      "ssim": 0.911963939666748,
      "attention_bam_384_mean_attention": -0.02571638487279415,
      "attention_bam_384_std_attention": 0.15940779447555542,
      "attention_bam_384_max_attention": 1.0241334438323975,
      "attention_bam_384_min_attention": -0.719990074634552,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5308723062387535,
      "attention_bam_384_attention_skewness": 0.20784216123307045,
      "attention_bam_384_attention_sparsity": 0.7948888142903646,
      "attention_bam_384_attention_concentration_10": -1.026403834209435,
      "attention_bam_384_attention_concentration_20": -1.5527207520713036,
      "attention_bam_384_attention_center_y": 0.48135871755136106,
      "attention_bam_384_attention_center_x": 0.4830000137254168,
      "attention_bam_384_attention_center_distance": 0.03567903991606141,
      "attention_bam_384_attention_spatial_variance": 171.74524571909382,
      "attention_bam_384_attention_spatial_std": 13.10516103369561,
      "attention_bam_384_num_attention_peaks": 18,
      "attention_bam_384_peak_separation_mean": 20.515716304429453,
      "attention_bam_384_peak_intensity_mean": 0.40290069580078125,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.145756334066391,
      "attention_bam_16_std_attention": 0.49330589175224304,
      "attention_bam_16_max_attention": 2.1119046211242676,
      "attention_bam_16_min_attention": -0.9959251880645752,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.025429991062774437,
      "attention_bam_16_attention_skewness": 0.4366816270828574,
      "attention_bam_16_attention_sparsity": 0.500732421875,
      "attention_bam_16_attention_concentration_10": 0.7460364122423406,
      "attention_bam_16_attention_concentration_20": 1.208768106276286,
      "attention_bam_16_attention_center_y": 0.45701176825903717,
      "attention_bam_16_attention_center_x": 0.4641334513087715,
      "attention_bam_16_attention_center_distance": 0.0791757208143379,
      "attention_bam_16_attention_spatial_variance": 43.26968634183315,
      "attention_bam_16_attention_spatial_std": 6.5779697735572755,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.430892628936725,
      "attention_bam_16_peak_intensity_mean": 0.37231314182281494,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 802,
      "phase": "train",
      "loss": 0.0076054902747273445,
      "timestamp": 1759544024.9403572,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0076054902747273445,
      "ssim": 0.8987672328948975,
      "attention_bam_384_mean_attention": -0.02623194456100464,
      "attention_bam_384_std_attention": 0.18412116169929504,
      "attention_bam_384_max_attention": 1.0939335823059082,
      "attention_bam_384_min_attention": -0.7587041854858398,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7276855999126179,
      "attention_bam_384_attention_skewness": 0.38056422652039595,
      "attention_bam_384_attention_sparsity": 0.7696990966796875,
      "attention_bam_384_attention_concentration_10": -1.2183819246741905,
      "attention_bam_384_attention_concentration_20": -1.823018229990929,
      "attention_bam_384_attention_center_y": 0.4891527828179102,
      "attention_bam_384_attention_center_x": 0.4833976023236997,
      "attention_bam_384_attention_center_distance": 0.028046451796883164,
      "attention_bam_384_attention_spatial_variance": 171.57247718032892,
      "attention_bam_384_attention_spatial_std": 13.098567753015171,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 19.129791715179028,
      "attention_bam_384_peak_intensity_mean": 0.39888566732406616,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.134454607963562,
      "attention_bam_16_std_attention": 0.5630513429641724,
      "attention_bam_16_max_attention": 2.3921236991882324,
      "attention_bam_16_min_attention": -1.0080796480178833,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.3099322015900885,
      "attention_bam_16_attention_skewness": 0.6669363255768547,
      "attention_bam_16_attention_sparsity": 0.525634765625,
      "attention_bam_16_attention_concentration_10": 0.9406706966041235,
      "attention_bam_16_attention_concentration_20": 1.4852639271217611,
      "attention_bam_16_attention_center_y": 0.4903570836622674,
      "attention_bam_16_attention_center_x": 0.4671461182143423,
      "attention_bam_16_attention_center_distance": 0.04842237879085413,
      "attention_bam_16_attention_spatial_variance": 43.17660442266522,
      "attention_bam_16_attention_spatial_std": 6.570890687164505,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.831621354530975,
      "attention_bam_16_peak_intensity_mean": 0.34940677881240845,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 803,
      "phase": "train",
      "loss": 0.0032545614521950483,
      "timestamp": 1759544025.0768163,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0032545614521950483,
      "ssim": 0.9359079003334045,
      "attention_bam_384_mean_attention": -0.026191428303718567,
      "attention_bam_384_std_attention": 0.14930082857608795,
      "attention_bam_384_max_attention": 1.5119004249572754,
      "attention_bam_384_min_attention": -0.7203671932220459,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1179817469829922,
      "attention_bam_384_attention_skewness": 0.3433210010290567,
      "attention_bam_384_attention_sparsity": 0.8198827107747396,
      "attention_bam_384_attention_concentration_10": -0.958354502373475,
      "attention_bam_384_attention_concentration_20": -1.4159394283870606,
      "attention_bam_384_attention_center_y": 0.489403179846024,
      "attention_bam_384_attention_center_x": 0.48577308581696627,
      "attention_bam_384_attention_center_distance": 0.025087753368809987,
      "attention_bam_384_attention_spatial_variance": 171.067510406343,
      "attention_bam_384_attention_spatial_std": 13.07927790079953,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 18.884972600423445,
      "attention_bam_384_peak_intensity_mean": 0.3156113028526306,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13368865847587585,
      "attention_bam_16_std_attention": 0.4985090494155884,
      "attention_bam_16_max_attention": 2.8241491317749023,
      "attention_bam_16_min_attention": -0.9680650234222412,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5890531941839807,
      "attention_bam_16_attention_skewness": 0.6722344914499697,
      "attention_bam_16_attention_sparsity": 0.517822265625,
      "attention_bam_16_attention_concentration_10": 0.8336345399055538,
      "attention_bam_16_attention_concentration_20": 1.3313437796453906,
      "attention_bam_16_attention_center_y": 0.4904946671685847,
      "attention_bam_16_attention_center_x": 0.4793480228560901,
      "attention_bam_16_attention_center_distance": 0.03215137671044771,
      "attention_bam_16_attention_spatial_variance": 42.72463454700674,
      "attention_bam_16_attention_spatial_std": 6.536408382820548,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.020635206039378,
      "attention_bam_16_peak_intensity_mean": 0.2908039391040802,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 804,
      "phase": "train",
      "loss": 0.003770030802115798,
      "timestamp": 1759544025.2107942,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.003770030802115798,
      "ssim": 0.921608567237854,
      "attention_bam_384_mean_attention": -0.025919705629348755,
      "attention_bam_384_std_attention": 0.1795119047164917,
      "attention_bam_384_max_attention": 1.0319056510925293,
      "attention_bam_384_min_attention": -0.7387752532958984,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5846571671020837,
      "attention_bam_384_attention_skewness": 0.32120167846794256,
      "attention_bam_384_attention_sparsity": 0.7764129638671875,
      "attention_bam_384_attention_concentration_10": -1.1975420853365872,
      "attention_bam_384_attention_concentration_20": -1.7883073997310932,
      "attention_bam_384_attention_center_y": 0.48020669906760804,
      "attention_bam_384_attention_center_x": 0.4803100400749511,
      "attention_bam_384_attention_center_distance": 0.03948339609634055,
      "attention_bam_384_attention_spatial_variance": 171.89599196516957,
      "attention_bam_384_attention_spatial_std": 13.110911179821544,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 18.310892129220534,
      "attention_bam_384_peak_intensity_mean": 0.40782642364501953,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1422145962715149,
      "attention_bam_16_std_attention": 0.5519982576370239,
      "attention_bam_16_max_attention": 2.3366189002990723,
      "attention_bam_16_min_attention": -1.097193717956543,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.07679057888358409,
      "attention_bam_16_attention_skewness": 0.5699844607376301,
      "attention_bam_16_attention_sparsity": 0.511962890625,
      "attention_bam_16_attention_concentration_10": 0.8624787035705356,
      "attention_bam_16_attention_concentration_20": 1.382687822303917,
      "attention_bam_16_attention_center_y": 0.453988102512792,
      "attention_bam_16_attention_center_x": 0.4539026335410059,
      "attention_bam_16_attention_center_distance": 0.09210930359988759,
      "attention_bam_16_attention_spatial_variance": 43.10280207557915,
      "attention_bam_16_attention_spatial_std": 6.565272429654321,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.337663602016,
      "attention_bam_16_peak_intensity_mean": 0.37193360924720764,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 805,
      "phase": "train",
      "loss": 0.0037562400102615356,
      "timestamp": 1759544025.3461554,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0037562400102615356,
      "ssim": 0.9204758405685425,
      "attention_bam_384_mean_attention": -0.025715062394738197,
      "attention_bam_384_std_attention": 0.18167151510715485,
      "attention_bam_384_max_attention": 1.8731480836868286,
      "attention_bam_384_min_attention": -0.9727834463119507,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.4000495647504234,
      "attention_bam_384_attention_skewness": 0.5700391358788012,
      "attention_bam_384_attention_sparsity": 0.7861404418945312,
      "attention_bam_384_attention_concentration_10": -1.2413114921302584,
      "attention_bam_384_attention_concentration_20": -1.8120992226206738,
      "attention_bam_384_attention_center_y": 0.483253507616092,
      "attention_bam_384_attention_center_x": 0.4851029157397441,
      "attention_bam_384_attention_center_distance": 0.03169757487952202,
      "attention_bam_384_attention_spatial_variance": 171.44885913762633,
      "attention_bam_384_attention_spatial_std": 13.093848140925811,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 19.995858374110615,
      "attention_bam_384_peak_intensity_mean": 0.33512166142463684,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12863105535507202,
      "attention_bam_16_std_attention": 0.5546385049819946,
      "attention_bam_16_max_attention": 3.2599446773529053,
      "attention_bam_16_min_attention": -1.2220416069030762,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.0685485314536276,
      "attention_bam_16_attention_skewness": 0.8432148857304694,
      "attention_bam_16_attention_sparsity": 0.537841796875,
      "attention_bam_16_attention_concentration_10": 0.9758945604477458,
      "attention_bam_16_attention_concentration_20": 1.5349110385789577,
      "attention_bam_16_attention_center_y": 0.4627719989003636,
      "attention_bam_16_attention_center_x": 0.4716702553029147,
      "attention_bam_16_attention_center_distance": 0.06615887696260517,
      "attention_bam_16_attention_spatial_variance": 43.403865028983724,
      "attention_bam_16_attention_spatial_std": 6.588160974732154,
      "attention_bam_16_num_attention_peaks": 11,
      "attention_bam_16_peak_separation_mean": 9.364185526526711,
      "attention_bam_16_peak_intensity_mean": 0.30596429109573364,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 806,
      "phase": "train",
      "loss": 0.008471616543829441,
      "timestamp": 1759544025.4825618,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008471616543829441,
      "ssim": 0.9114819765090942,
      "attention_bam_384_mean_attention": -0.026204099878668785,
      "attention_bam_384_std_attention": 0.16272327303886414,
      "attention_bam_384_max_attention": 1.0453979969024658,
      "attention_bam_384_min_attention": -0.7185649275779724,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6420711343029777,
      "attention_bam_384_attention_skewness": 0.31094854063756655,
      "attention_bam_384_attention_sparsity": 0.8008066813151041,
      "attention_bam_384_attention_concentration_10": -1.067564867725583,
      "attention_bam_384_attention_concentration_20": -1.5832367879047482,
      "attention_bam_384_attention_center_y": 0.4822023784491742,
      "attention_bam_384_attention_center_x": 0.484901213524589,
      "attention_bam_384_attention_center_distance": 0.0330069291481796,
      "attention_bam_384_attention_spatial_variance": 171.06341422544125,
      "attention_bam_384_attention_spatial_std": 13.079121309378595,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 18.688525156516693,
      "attention_bam_384_peak_intensity_mean": 0.39838770031929016,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.137777179479599,
      "attention_bam_16_std_attention": 0.5255889296531677,
      "attention_bam_16_max_attention": 2.20290470123291,
      "attention_bam_16_min_attention": -1.0377289056777954,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.0865164369680902,
      "attention_bam_16_attention_skewness": 0.5293639670069544,
      "attention_bam_16_attention_sparsity": 0.50927734375,
      "attention_bam_16_attention_concentration_10": 0.8451060828937632,
      "attention_bam_16_attention_concentration_20": 1.3515775891571833,
      "attention_bam_16_attention_center_y": 0.4608214725361695,
      "attention_bam_16_attention_center_x": 0.4716854315583465,
      "attention_bam_16_attention_center_distance": 0.06836185779030876,
      "attention_bam_16_attention_spatial_variance": 42.77831335778419,
      "attention_bam_16_attention_spatial_std": 6.54051323351495,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 11.259193460723642,
      "attention_bam_16_peak_intensity_mean": 0.36844873428344727,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 807,
      "phase": "train",
      "loss": 0.005040859803557396,
      "timestamp": 1759544025.6930325,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005040859803557396,
      "ssim": 0.8986092209815979,
      "attention_bam_384_mean_attention": -0.025643987581133842,
      "attention_bam_384_std_attention": 0.16655880212783813,
      "attention_bam_384_max_attention": 1.1749658584594727,
      "attention_bam_384_min_attention": -0.6589829325675964,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6830103537961261,
      "attention_bam_384_attention_skewness": 0.38923021145772074,
      "attention_bam_384_attention_sparsity": 0.7928644816080729,
      "attention_bam_384_attention_concentration_10": -1.1278284827682283,
      "attention_bam_384_attention_concentration_20": -1.6740381921396144,
      "attention_bam_384_attention_center_y": 0.4823259069099405,
      "attention_bam_384_attention_center_x": 0.4840914457355667,
      "attention_bam_384_attention_center_distance": 0.03362902512237033,
      "attention_bam_384_attention_spatial_variance": 170.17861829554468,
      "attention_bam_384_attention_spatial_std": 13.045252711064844,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 19.908828770061664,
      "attention_bam_384_peak_intensity_mean": 0.3502306044101715,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13188783824443817,
      "attention_bam_16_std_attention": 0.5215893387794495,
      "attention_bam_16_max_attention": 2.3634440898895264,
      "attention_bam_16_min_attention": -0.8815158009529114,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.4409428670160751,
      "attention_bam_16_attention_skewness": 0.7348503636728452,
      "attention_bam_16_attention_sparsity": 0.53076171875,
      "attention_bam_16_attention_concentration_10": 0.9069512361535963,
      "attention_bam_16_attention_concentration_20": 1.4185678132317545,
      "attention_bam_16_attention_center_y": 0.46053998439123267,
      "attention_bam_16_attention_center_x": 0.4669705056907724,
      "attention_bam_16_attention_center_distance": 0.07277417572418747,
      "attention_bam_16_attention_spatial_variance": 41.77737658014849,
      "attention_bam_16_attention_spatial_std": 6.463542107865353,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.456426327484964,
      "attention_bam_16_peak_intensity_mean": 0.32991546392440796,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 808,
      "phase": "train",
      "loss": 0.005364908836781979,
      "timestamp": 1759544025.9013636,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005364908836781979,
      "ssim": 0.9212245345115662,
      "attention_bam_384_mean_attention": -0.025534510612487793,
      "attention_bam_384_std_attention": 0.1588936448097229,
      "attention_bam_384_max_attention": 1.3085613250732422,
      "attention_bam_384_min_attention": -0.712959349155426,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.3680834591966473,
      "attention_bam_384_attention_skewness": 0.1767758876008083,
      "attention_bam_384_attention_sparsity": 0.7874552408854166,
      "attention_bam_384_attention_concentration_10": -1.0130739016843346,
      "attention_bam_384_attention_concentration_20": -1.5553935826046426,
      "attention_bam_384_attention_center_y": 0.48521486811226483,
      "attention_bam_384_attention_center_x": 0.48400699833640914,
      "attention_bam_384_attention_center_distance": 0.030801825502698478,
      "attention_bam_384_attention_spatial_variance": 171.30798641387136,
      "attention_bam_384_attention_spatial_std": 13.08846768777275,
      "attention_bam_384_num_attention_peaks": 23,
      "attention_bam_384_peak_separation_mean": 19.27630009056593,
      "attention_bam_384_peak_intensity_mean": 0.34236496686935425,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14315596222877502,
      "attention_bam_16_std_attention": 0.502399206161499,
      "attention_bam_16_max_attention": 2.2178306579589844,
      "attention_bam_16_min_attention": -1.002463698387146,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.1806692344231533,
      "attention_bam_16_attention_skewness": 0.3774658360410331,
      "attention_bam_16_attention_sparsity": 0.492919921875,
      "attention_bam_16_attention_concentration_10": 0.7534829167749952,
      "attention_bam_16_attention_concentration_20": 1.2311604184806972,
      "attention_bam_16_attention_center_y": 0.4727800660201816,
      "attention_bam_16_attention_center_x": 0.46588190370715277,
      "attention_bam_16_attention_center_distance": 0.061724700088597755,
      "attention_bam_16_attention_spatial_variance": 43.317969823831675,
      "attention_bam_16_attention_spatial_std": 6.581638840276157,
      "attention_bam_16_num_attention_peaks": 12,
      "attention_bam_16_peak_separation_mean": 8.459439056560441,
      "attention_bam_16_peak_intensity_mean": 0.35937121510505676,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 809,
      "phase": "train",
      "loss": 0.010813640430569649,
      "timestamp": 1759544026.098272,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.010813640430569649,
      "ssim": 0.9017798900604248,
      "attention_bam_384_mean_attention": -0.025846028700470924,
      "attention_bam_384_std_attention": 0.16182173788547516,
      "attention_bam_384_max_attention": 1.3047194480895996,
      "attention_bam_384_min_attention": -0.7729870676994324,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4900561786330178,
      "attention_bam_384_attention_skewness": 0.43463524242430485,
      "attention_bam_384_attention_sparsity": 0.8134104410807291,
      "attention_bam_384_attention_concentration_10": -1.0979634257229944,
      "attention_bam_384_attention_concentration_20": -1.592609714283877,
      "attention_bam_384_attention_center_y": 0.48463427887098814,
      "attention_bam_384_attention_center_x": 0.4843455650900917,
      "attention_bam_384_attention_center_distance": 0.03102149958216454,
      "attention_bam_384_attention_spatial_variance": 170.80362243839986,
      "attention_bam_384_attention_spatial_std": 13.069185989892402,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 17.236411128379668,
      "attention_bam_384_peak_intensity_mean": 0.36029380559921265,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14106790721416473,
      "attention_bam_16_std_attention": 0.5214843153953552,
      "attention_bam_16_max_attention": 2.528496265411377,
      "attention_bam_16_min_attention": -1.1250040531158447,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6741007109886841,
      "attention_bam_16_attention_skewness": 0.7093839985917707,
      "attention_bam_16_attention_sparsity": 0.5146484375,
      "attention_bam_16_attention_concentration_10": 0.844908796490931,
      "attention_bam_16_attention_concentration_20": 1.3215184219918377,
      "attention_bam_16_attention_center_y": 0.4717118425247034,
      "attention_bam_16_attention_center_x": 0.469958884409791,
      "attention_bam_16_attention_center_distance": 0.05835560777254364,
      "attention_bam_16_attention_spatial_variance": 42.516751580101314,
      "attention_bam_16_attention_spatial_std": 6.5204870661708485,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.635818477265246,
      "attention_bam_16_peak_intensity_mean": 0.3554174304008484,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 810,
      "phase": "train",
      "loss": 0.003846141044050455,
      "timestamp": 1759544026.3238726,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.003846141044050455,
      "ssim": 0.9325189590454102,
      "attention_bam_384_mean_attention": -0.026632962748408318,
      "attention_bam_384_std_attention": 0.14980250597000122,
      "attention_bam_384_max_attention": 1.2354631423950195,
      "attention_bam_384_min_attention": -0.7135705947875977,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9126535309877255,
      "attention_bam_384_attention_skewness": 0.29530649522164143,
      "attention_bam_384_attention_sparsity": 0.8185475667317709,
      "attention_bam_384_attention_concentration_10": -0.9384970710613095,
      "attention_bam_384_attention_concentration_20": -1.3918482798210619,
      "attention_bam_384_attention_center_y": 0.48773825069489884,
      "attention_bam_384_attention_center_x": 0.4883181990543216,
      "attention_bam_384_attention_center_distance": 0.02395057282636894,
      "attention_bam_384_attention_spatial_variance": 171.7813504218761,
      "attention_bam_384_attention_spatial_std": 13.106538460702586,
      "attention_bam_384_num_attention_peaks": 18,
      "attention_bam_384_peak_separation_mean": 19.511199042616635,
      "attention_bam_384_peak_intensity_mean": 0.3566422462463379,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14231064915657043,
      "attention_bam_16_std_attention": 0.48740771412849426,
      "attention_bam_16_max_attention": 2.3668336868286133,
      "attention_bam_16_min_attention": -0.9890576601028442,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5032367434197926,
      "attention_bam_16_attention_skewness": 0.6507895343461547,
      "attention_bam_16_attention_sparsity": 0.511474609375,
      "attention_bam_16_attention_concentration_10": 0.7750746415741037,
      "attention_bam_16_attention_concentration_20": 1.2370749167406068,
      "attention_bam_16_attention_center_y": 0.48185466448756564,
      "attention_bam_16_attention_center_x": 0.48557702731955404,
      "attention_bam_16_attention_center_distance": 0.032780339894506946,
      "attention_bam_16_attention_spatial_variance": 43.51747434304772,
      "attention_bam_16_attention_spatial_std": 6.596777572652251,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.858398976035494,
      "attention_bam_16_peak_intensity_mean": 0.34513911604881287,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 811,
      "phase": "train",
      "loss": 0.003000435885041952,
      "timestamp": 1759544026.4862936,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.003000435885041952,
      "ssim": 0.9544847011566162,
      "attention_bam_384_mean_attention": -0.0278133824467659,
      "attention_bam_384_std_attention": 0.16652892529964447,
      "attention_bam_384_max_attention": 1.0497245788574219,
      "attention_bam_384_min_attention": -0.6674615740776062,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7351569106440907,
      "attention_bam_384_attention_skewness": 0.3786585778345073,
      "attention_bam_384_attention_sparsity": 0.79791259765625,
      "attention_bam_384_attention_concentration_10": -1.0303079332747889,
      "attention_bam_384_attention_concentration_20": -1.522824729420517,
      "attention_bam_384_attention_center_y": 0.49346224644056114,
      "attention_bam_384_attention_center_x": 0.4871872439437316,
      "attention_bam_384_attention_center_distance": 0.02034251407085164,
      "attention_bam_384_attention_spatial_variance": 171.52296933595804,
      "attention_bam_384_attention_spatial_std": 13.096677797669074,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 16.802575849756593,
      "attention_bam_384_peak_intensity_mean": 0.3807627260684967,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1351061910390854,
      "attention_bam_16_std_attention": 0.5321640372276306,
      "attention_bam_16_max_attention": 2.1645584106445312,
      "attention_bam_16_min_attention": -1.0797491073608398,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.2872260958805697,
      "attention_bam_16_attention_skewness": 0.6672361408548945,
      "attention_bam_16_attention_sparsity": 0.524658203125,
      "attention_bam_16_attention_concentration_10": 0.8843525455228483,
      "attention_bam_16_attention_concentration_20": 1.4061367471020023,
      "attention_bam_16_attention_center_y": 0.4978924668413675,
      "attention_bam_16_attention_center_x": 0.47825095174768417,
      "attention_bam_16_attention_center_distance": 0.03090187036074993,
      "attention_bam_16_attention_spatial_variance": 42.71638501462489,
      "attention_bam_16_attention_spatial_std": 6.535777307606563,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 6.861357673278514,
      "attention_bam_16_peak_intensity_mean": 0.40625205636024475,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 812,
      "phase": "train",
      "loss": 0.003768270369619131,
      "timestamp": 1759544026.6488364,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.003768270369619131,
      "ssim": 0.9384616613388062,
      "attention_bam_384_mean_attention": -0.0265948548913002,
      "attention_bam_384_std_attention": 0.15190500020980835,
      "attention_bam_384_max_attention": 1.0371379852294922,
      "attention_bam_384_min_attention": -0.659381628036499,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8213487341502574,
      "attention_bam_384_attention_skewness": 0.3510594456631886,
      "attention_bam_384_attention_sparsity": 0.8166071573893229,
      "attention_bam_384_attention_concentration_10": -0.9719418297786304,
      "attention_bam_384_attention_concentration_20": -1.4356818128560735,
      "attention_bam_384_attention_center_y": 0.48647203402225303,
      "attention_bam_384_attention_center_x": 0.48220721080524953,
      "attention_bam_384_attention_center_distance": 0.031609783638105106,
      "attention_bam_384_attention_spatial_variance": 170.6628341684091,
      "attention_bam_384_attention_spatial_std": 13.063798611751832,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 17.973796996315368,
      "attention_bam_384_peak_intensity_mean": 0.3768373131752014,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13689902424812317,
      "attention_bam_16_std_attention": 0.4746035635471344,
      "attention_bam_16_max_attention": 2.383622646331787,
      "attention_bam_16_min_attention": -0.9599078893661499,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.24694375247986278,
      "attention_bam_16_attention_skewness": 0.5770151552833043,
      "attention_bam_16_attention_sparsity": 0.511474609375,
      "attention_bam_16_attention_concentration_10": 0.7805140730303736,
      "attention_bam_16_attention_concentration_20": 1.2434084477446925,
      "attention_bam_16_attention_center_y": 0.48012418670558477,
      "attention_bam_16_attention_center_x": 0.46253609531601686,
      "attention_bam_16_attention_center_distance": 0.05997653054795729,
      "attention_bam_16_attention_spatial_variance": 42.37614404566581,
      "attention_bam_16_attention_spatial_std": 6.509696156170871,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.492666087925425,
      "attention_bam_16_peak_intensity_mean": 0.32938718795776367,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 813,
      "phase": "train",
      "loss": 0.004441457334905863,
      "timestamp": 1759544026.8011026,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004441457334905863,
      "ssim": 0.9196279644966125,
      "attention_bam_384_mean_attention": -0.028171883895993233,
      "attention_bam_384_std_attention": 0.1520419418811798,
      "attention_bam_384_max_attention": 1.0719345808029175,
      "attention_bam_384_min_attention": -0.6881444454193115,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.055676028544597,
      "attention_bam_384_attention_skewness": 0.3356800858785777,
      "attention_bam_384_attention_sparsity": 0.8198903401692709,
      "attention_bam_384_attention_concentration_10": -0.9058411342046467,
      "attention_bam_384_attention_concentration_20": -1.3332177311439488,
      "attention_bam_384_attention_center_y": 0.4828187059210096,
      "attention_bam_384_attention_center_x": 0.47689670802822837,
      "attention_bam_384_attention_center_distance": 0.04071753838732586,
      "attention_bam_384_attention_spatial_variance": 170.88950371424272,
      "attention_bam_384_attention_spatial_std": 13.072471216806818,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 17.550827080228004,
      "attention_bam_384_peak_intensity_mean": 0.37760764360427856,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14811721444129944,
      "attention_bam_16_std_attention": 0.47260338068008423,
      "attention_bam_16_max_attention": 2.700547456741333,
      "attention_bam_16_min_attention": -0.94681316614151,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.2272091712777331,
      "attention_bam_16_attention_skewness": 0.5147958801600142,
      "attention_bam_16_attention_sparsity": 0.498046875,
      "attention_bam_16_attention_concentration_10": 0.7114913131481205,
      "attention_bam_16_attention_concentration_20": 1.1558570853789238,
      "attention_bam_16_attention_center_y": 0.4635876153696623,
      "attention_bam_16_attention_center_x": 0.44122164788770063,
      "attention_bam_16_attention_center_distance": 0.09778298861770486,
      "attention_bam_16_attention_spatial_variance": 42.335847557460994,
      "attention_bam_16_attention_spatial_std": 6.5066003071850815,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 7.518422525411731,
      "attention_bam_16_peak_intensity_mean": 0.30766746401786804,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 814,
      "phase": "train",
      "loss": 0.00828662607818842,
      "timestamp": 1759544026.9510272,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00828662607818842,
      "ssim": 0.8692635297775269,
      "attention_bam_384_mean_attention": -0.02760029025375843,
      "attention_bam_384_std_attention": 0.16462881863117218,
      "attention_bam_384_max_attention": 1.2484667301177979,
      "attention_bam_384_min_attention": -0.7227281332015991,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0360939113994734,
      "attention_bam_384_attention_skewness": 0.3700310236694608,
      "attention_bam_384_attention_sparsity": 0.8053461710611979,
      "attention_bam_384_attention_concentration_10": -1.0266999719715815,
      "attention_bam_384_attention_concentration_20": -1.5049371723828795,
      "attention_bam_384_attention_center_y": 0.4840350159282581,
      "attention_bam_384_attention_center_x": 0.4824941964606748,
      "attention_bam_384_attention_center_distance": 0.03350623446370608,
      "attention_bam_384_attention_spatial_variance": 170.9961678517862,
      "attention_bam_384_attention_spatial_std": 13.076550303951963,
      "attention_bam_384_num_attention_peaks": 21,
      "attention_bam_384_peak_separation_mean": 17.19954445044767,
      "attention_bam_384_peak_intensity_mean": 0.35699501633644104,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14257584512233734,
      "attention_bam_16_std_attention": 0.5015249252319336,
      "attention_bam_16_max_attention": 2.435384511947632,
      "attention_bam_16_min_attention": -1.0724831819534302,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.45563062744015603,
      "attention_bam_16_attention_skewness": 0.5957819306516668,
      "attention_bam_16_attention_sparsity": 0.507080078125,
      "attention_bam_16_attention_concentration_10": 0.7961867153676704,
      "attention_bam_16_attention_concentration_20": 1.2586499120874621,
      "attention_bam_16_attention_center_y": 0.4661332893364814,
      "attention_bam_16_attention_center_x": 0.46722208598270293,
      "attention_bam_16_attention_center_distance": 0.06665351811407712,
      "attention_bam_16_attention_spatial_variance": 42.53965613641994,
      "attention_bam_16_attention_spatial_std": 6.522243182864308,
      "attention_bam_16_num_attention_peaks": 11,
      "attention_bam_16_peak_separation_mean": 9.125672001202732,
      "attention_bam_16_peak_intensity_mean": 0.35216203331947327,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 815,
      "phase": "train",
      "loss": 0.004835569299757481,
      "timestamp": 1759544027.1029868,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004835569299757481,
      "ssim": 0.9185500144958496,
      "attention_bam_384_mean_attention": -0.028550421819090843,
      "attention_bam_384_std_attention": 0.16331183910369873,
      "attention_bam_384_max_attention": 1.0832080841064453,
      "attention_bam_384_min_attention": -0.7818384170532227,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2226863832341301,
      "attention_bam_384_attention_skewness": 0.3692541894949422,
      "attention_bam_384_attention_sparsity": 0.8127314249674479,
      "attention_bam_384_attention_concentration_10": -0.980986903352133,
      "attention_bam_384_attention_concentration_20": -1.4270207912073323,
      "attention_bam_384_attention_center_y": 0.48395708901342366,
      "attention_bam_384_attention_center_x": 0.4855982569704428,
      "attention_bam_384_attention_center_distance": 0.030488856823849973,
      "attention_bam_384_attention_spatial_variance": 171.78295685736046,
      "attention_bam_384_attention_spatial_std": 13.106599744302885,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 19.64063024598113,
      "attention_bam_384_peak_intensity_mean": 0.4098142385482788,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14546260237693787,
      "attention_bam_16_std_attention": 0.511306881904602,
      "attention_bam_16_max_attention": 2.2252087593078613,
      "attention_bam_16_min_attention": -1.0111336708068848,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.29347796321686515,
      "attention_bam_16_attention_skewness": 0.5432068666665231,
      "attention_bam_16_attention_sparsity": 0.498046875,
      "attention_bam_16_attention_concentration_10": 0.7867721523393765,
      "attention_bam_16_attention_concentration_20": 1.2511729870111452,
      "attention_bam_16_attention_center_y": 0.4685517817104193,
      "attention_bam_16_attention_center_x": 0.4772564105472226,
      "attention_bam_16_attention_center_distance": 0.05488645178521937,
      "attention_bam_16_attention_spatial_variance": 43.149228673492594,
      "attention_bam_16_attention_spatial_std": 6.568807248922181,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.367549066615073,
      "attention_bam_16_peak_intensity_mean": 0.36155617237091064,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 816,
      "phase": "train",
      "loss": 0.00464631337672472,
      "timestamp": 1759544027.254353,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00464631337672472,
      "ssim": 0.9170796275138855,
      "attention_bam_384_mean_attention": -0.028318703174591064,
      "attention_bam_384_std_attention": 0.1621074229478836,
      "attention_bam_384_max_attention": 1.4117405414581299,
      "attention_bam_384_min_attention": -0.7603914737701416,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2506570612875514,
      "attention_bam_384_attention_skewness": 0.4528773889527668,
      "attention_bam_384_attention_sparsity": 0.8089625040690104,
      "attention_bam_384_attention_concentration_10": -0.9882265613443547,
      "attention_bam_384_attention_concentration_20": -1.4414971090857363,
      "attention_bam_384_attention_center_y": 0.4792123381138883,
      "attention_bam_384_attention_center_x": 0.4834235859303642,
      "attention_bam_384_attention_center_distance": 0.037600648667258915,
      "attention_bam_384_attention_spatial_variance": 169.26860731497854,
      "attention_bam_384_attention_spatial_std": 13.0103269488118,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 18.280829529163118,
      "attention_bam_384_peak_intensity_mean": 0.340870201587677,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12850543856620789,
      "attention_bam_16_std_attention": 0.532797634601593,
      "attention_bam_16_max_attention": 2.663317918777466,
      "attention_bam_16_min_attention": -1.0384588241577148,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7696728474687284,
      "attention_bam_16_attention_skewness": 0.7862381733179454,
      "attention_bam_16_attention_sparsity": 0.525634765625,
      "attention_bam_16_attention_concentration_10": 0.9490066158175352,
      "attention_bam_16_attention_concentration_20": 1.4699635452732804,
      "attention_bam_16_attention_center_y": 0.4481622125346159,
      "attention_bam_16_attention_center_x": 0.464312647758311,
      "attention_bam_16_attention_center_distance": 0.08900273388305234,
      "attention_bam_16_attention_spatial_variance": 40.70736704786296,
      "attention_bam_16_attention_spatial_std": 6.380232523024765,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.476189125720431,
      "attention_bam_16_peak_intensity_mean": 0.324577659368515,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 817,
      "phase": "train",
      "loss": 0.004507116973400116,
      "timestamp": 1759544027.3999312,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004507116973400116,
      "ssim": 0.9313775897026062,
      "attention_bam_384_mean_attention": -0.028099866583943367,
      "attention_bam_384_std_attention": 0.16199937462806702,
      "attention_bam_384_max_attention": 1.276911973953247,
      "attention_bam_384_min_attention": -0.807994544506073,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.288625607241224,
      "attention_bam_384_attention_skewness": 0.3880626628002953,
      "attention_bam_384_attention_sparsity": 0.8097559611002604,
      "attention_bam_384_attention_concentration_10": -0.9803986052951023,
      "attention_bam_384_attention_concentration_20": -1.4369517489118357,
      "attention_bam_384_attention_center_y": 0.4821517756149782,
      "attention_bam_384_attention_center_x": 0.48243748861161506,
      "attention_bam_384_attention_center_distance": 0.035411888398255126,
      "attention_bam_384_attention_spatial_variance": 172.39377347445804,
      "attention_bam_384_attention_spatial_std": 13.12988093908159,
      "attention_bam_384_num_attention_peaks": 20,
      "attention_bam_384_peak_separation_mean": 18.535260052462675,
      "attention_bam_384_peak_intensity_mean": 0.37854161858558655,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13803038001060486,
      "attention_bam_16_std_attention": 0.5117058157920837,
      "attention_bam_16_max_attention": 2.386307716369629,
      "attention_bam_16_min_attention": -1.0363026857376099,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5106750437712764,
      "attention_bam_16_attention_skewness": 0.6601609409523822,
      "attention_bam_16_attention_sparsity": 0.50927734375,
      "attention_bam_16_attention_concentration_10": 0.8361346388335744,
      "attention_bam_16_attention_concentration_20": 1.317966132557902,
      "attention_bam_16_attention_center_y": 0.4596599416210516,
      "attention_bam_16_attention_center_x": 0.46062362338312407,
      "attention_bam_16_attention_center_distance": 0.07972225969565862,
      "attention_bam_16_attention_spatial_variance": 43.84675285751464,
      "attention_bam_16_attention_spatial_std": 6.621688067065273,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 8.777411503296861,
      "attention_bam_16_peak_intensity_mean": 0.34597158432006836,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 818,
      "phase": "train",
      "loss": 0.006114140152931213,
      "timestamp": 1759544027.5383117,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006114140152931213,
      "ssim": 0.9096027612686157,
      "attention_bam_384_mean_attention": -0.027620777487754822,
      "attention_bam_384_std_attention": 0.17343367636203766,
      "attention_bam_384_max_attention": 1.542424201965332,
      "attention_bam_384_min_attention": -0.7837038040161133,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.322572979738628,
      "attention_bam_384_attention_skewness": 0.4599089170775545,
      "attention_bam_384_attention_sparsity": 0.7916666666666666,
      "attention_bam_384_attention_concentration_10": -1.0872715727629632,
      "attention_bam_384_attention_concentration_20": -1.6016009935281221,
      "attention_bam_384_attention_center_y": 0.4845875638230352,
      "attention_bam_384_attention_center_x": 0.48188327156427607,
      "attention_bam_384_attention_center_distance": 0.03363804507169765,
      "attention_bam_384_attention_spatial_variance": 172.10927748800694,
      "attention_bam_384_attention_spatial_std": 13.119042552259938,
      "attention_bam_384_num_attention_peaks": 22,
      "attention_bam_384_peak_separation_mean": 18.252282612336643,
      "attention_bam_384_peak_intensity_mean": 0.3301316201686859,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13663306832313538,
      "attention_bam_16_std_attention": 0.5331380367279053,
      "attention_bam_16_max_attention": 2.942225456237793,
      "attention_bam_16_min_attention": -1.1165682077407837,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8693796076295857,
      "attention_bam_16_attention_skewness": 0.7430977204296075,
      "attention_bam_16_attention_sparsity": 0.52001953125,
      "attention_bam_16_attention_concentration_10": 0.8744199932444862,
      "attention_bam_16_attention_concentration_20": 1.3790638097141714,
      "attention_bam_16_attention_center_y": 0.4723541166870065,
      "attention_bam_16_attention_center_x": 0.4620128906678031,
      "attention_bam_16_attention_center_distance": 0.06644268717581993,
      "attention_bam_16_attention_spatial_variance": 43.699702780593185,
      "attention_bam_16_attention_spatial_std": 6.61057507185216,
      "attention_bam_16_num_attention_peaks": 13,
      "attention_bam_16_peak_separation_mean": 9.508536294148612,
      "attention_bam_16_peak_intensity_mean": 0.3251636326313019,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 819,
      "phase": "train",
      "loss": 0.00453366432338953,
      "timestamp": 1759544027.6828783,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00453366432338953,
      "ssim": 0.9159919023513794,
      "attention_bam_384_mean_attention": -0.028556257486343384,
      "attention_bam_384_std_attention": 0.1453532874584198,
      "attention_bam_384_max_attention": 1.004480004310608,
      "attention_bam_384_min_attention": -0.6585603952407837,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8811924165750713,
      "attention_bam_384_attention_skewness": 0.34182198897578225,
      "attention_bam_384_attention_sparsity": 0.831085205078125,
      "attention_bam_384_attention_concentration_10": -0.8568899246398479,
      "attention_bam_384_attention_concentration_20": -1.2554810863699521,
      "attention_bam_384_attention_center_y": 0.4826736353053761,
      "attention_bam_384_attention_center_x": 0.481497541266645,
      "attention_bam_384_attention_center_distance": 0.03584812108634464,
      "attention_bam_384_attention_spatial_variance": 172.2578286338152,
      "attention_bam_384_attention_spatial_std": 13.124702992213393,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 19.75415983177424,
      "attention_bam_384_peak_intensity_mean": 0.3844752609729767,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12810590863227844,
      "attention_bam_16_std_attention": 0.4877499043941498,
      "attention_bam_16_max_attention": 2.276621103286743,
      "attention_bam_16_min_attention": -0.993861198425293,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.2127362184379895,
      "attention_bam_16_attention_skewness": 0.6303156182399337,
      "attention_bam_16_attention_sparsity": 0.52392578125,
      "attention_bam_16_attention_concentration_10": 0.8578269130079222,
      "attention_bam_16_attention_concentration_20": 1.3612045863887812,
      "attention_bam_16_attention_center_y": 0.46326559341079043,
      "attention_bam_16_attention_center_x": 0.4585282108938872,
      "attention_bam_16_attention_center_distance": 0.07834954906217725,
      "attention_bam_16_attention_spatial_variance": 43.567217150351105,
      "attention_bam_16_attention_spatial_std": 6.600546731169404,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.063163494179197,
      "attention_bam_16_peak_intensity_mean": 0.3428514897823334,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 820,
      "phase": "train",
      "loss": 0.003997973166406155,
      "timestamp": 1759544027.907479,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.003997973166406155,
      "ssim": 0.9200598001480103,
      "attention_bam_384_mean_attention": -0.028121342882514,
      "attention_bam_384_std_attention": 0.16535556316375732,
      "attention_bam_384_max_attention": 1.0844495296478271,
      "attention_bam_384_min_attention": -0.8109555840492249,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7689169635052133,
      "attention_bam_384_attention_skewness": 0.3343716862709793,
      "attention_bam_384_attention_sparsity": 0.7985738118489584,
      "attention_bam_384_attention_concentration_10": -1.0045349579472322,
      "attention_bam_384_attention_concentration_20": -1.4911445121105253,
      "attention_bam_384_attention_center_y": 0.4826986010141904,
      "attention_bam_384_attention_center_x": 0.48391386664861313,
      "attention_bam_384_attention_center_distance": 0.03340964211316173,
      "attention_bam_384_attention_spatial_variance": 172.39534727592817,
      "attention_bam_384_attention_spatial_std": 13.129940870998931,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 19.40009161129098,
      "attention_bam_384_peak_intensity_mean": 0.414102703332901,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13947272300720215,
      "attention_bam_16_std_attention": 0.5264214873313904,
      "attention_bam_16_max_attention": 2.2866740226745605,
      "attention_bam_16_min_attention": -1.08845853805542,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.2796050289716119,
      "attention_bam_16_attention_skewness": 0.6365754956138865,
      "attention_bam_16_attention_sparsity": 0.525390625,
      "attention_bam_16_attention_concentration_10": 0.8535927261979401,
      "attention_bam_16_attention_concentration_20": 1.355635172141312,
      "attention_bam_16_attention_center_y": 0.4620592679852494,
      "attention_bam_16_attention_center_x": 0.46808176612868846,
      "attention_bam_16_attention_center_distance": 0.07011808324931397,
      "attention_bam_16_attention_spatial_variance": 43.974727581366324,
      "attention_bam_16_attention_spatial_std": 6.631344326859097,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 11.053030465861244,
      "attention_bam_16_peak_intensity_mean": 0.36979183554649353,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 821,
      "phase": "train",
      "loss": 0.005294410046190023,
      "timestamp": 1759544028.1005397,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005294410046190023,
      "ssim": 0.9137463569641113,
      "attention_bam_384_mean_attention": -0.027838045731186867,
      "attention_bam_384_std_attention": 0.1578454226255417,
      "attention_bam_384_max_attention": 1.1113890409469604,
      "attention_bam_384_min_attention": -0.6851789355278015,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0770171679604514,
      "attention_bam_384_attention_skewness": 0.3701384389861963,
      "attention_bam_384_attention_sparsity": 0.8138834635416666,
      "attention_bam_384_attention_concentration_10": -0.9626260072425099,
      "attention_bam_384_attention_concentration_20": -1.4125614970307518,
      "attention_bam_384_attention_center_y": 0.486181739532955,
      "attention_bam_384_attention_center_x": 0.48811565434038157,
      "attention_bam_384_attention_center_distance": 0.02577525922633523,
      "attention_bam_384_attention_spatial_variance": 172.4683623378295,
      "attention_bam_384_attention_spatial_std": 13.13272105611893,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 17.46569935276469,
      "attention_bam_384_peak_intensity_mean": 0.36844074726104736,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13660605251789093,
      "attention_bam_16_std_attention": 0.521725594997406,
      "attention_bam_16_max_attention": 2.450183391571045,
      "attention_bam_16_min_attention": -0.979123592376709,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5731575959834991,
      "attention_bam_16_attention_skewness": 0.7304151960576527,
      "attention_bam_16_attention_sparsity": 0.529541015625,
      "attention_bam_16_attention_concentration_10": 0.8779281911322123,
      "attention_bam_16_attention_concentration_20": 1.3772980286478322,
      "attention_bam_16_attention_center_y": 0.47532058272098654,
      "attention_bam_16_attention_center_x": 0.4852905349673075,
      "attention_bam_16_attention_center_distance": 0.04063107182390519,
      "attention_bam_16_attention_spatial_variance": 43.92320950691906,
      "attention_bam_16_attention_spatial_std": 6.627458751808197,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.349849110495276,
      "attention_bam_16_peak_intensity_mean": 0.33830514550209045,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 822,
      "phase": "train",
      "loss": 0.006562386639416218,
      "timestamp": 1759544028.2847836,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006562386639416218,
      "ssim": 0.9190676808357239,
      "attention_bam_384_mean_attention": -0.028207341209053993,
      "attention_bam_384_std_attention": 0.17021623253822327,
      "attention_bam_384_max_attention": 1.5980912446975708,
      "attention_bam_384_min_attention": -0.8722467422485352,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8785727177294609,
      "attention_bam_384_attention_skewness": 0.5228110326065916,
      "attention_bam_384_attention_sparsity": 0.7988560994466146,
      "attention_bam_384_attention_concentration_10": -1.040173181792866,
      "attention_bam_384_attention_concentration_20": -1.5194069684078608,
      "attention_bam_384_attention_center_y": 0.48553407076806543,
      "attention_bam_384_attention_center_x": 0.4836193648375008,
      "attention_bam_384_attention_center_distance": 0.030905932015399394,
      "attention_bam_384_attention_spatial_variance": 172.64074333390445,
      "attention_bam_384_attention_spatial_std": 13.139282451256783,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 20.79075413760161,
      "attention_bam_384_peak_intensity_mean": 0.34678682684898376,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12395337224006653,
      "attention_bam_16_std_attention": 0.5404205918312073,
      "attention_bam_16_max_attention": 3.017765998840332,
      "attention_bam_16_min_attention": -1.2143687009811401,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.9271924498910571,
      "attention_bam_16_attention_skewness": 0.7704917395203856,
      "attention_bam_16_attention_sparsity": 0.5263671875,
      "attention_bam_16_attention_concentration_10": 0.9758748408450348,
      "attention_bam_16_attention_concentration_20": 1.525371797569726,
      "attention_bam_16_attention_center_y": 0.4756118806143487,
      "attention_bam_16_attention_center_x": 0.4671501408738583,
      "attention_bam_16_attention_center_distance": 0.05786006587925965,
      "attention_bam_16_attention_spatial_variance": 44.35146307099237,
      "attention_bam_16_attention_spatial_std": 6.659689412502085,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 10.811821931847486,
      "attention_bam_16_peak_intensity_mean": 0.33342257142066956,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 823,
      "phase": "train",
      "loss": 0.0037001592572778463,
      "timestamp": 1759544028.4731436,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0037001592572778463,
      "ssim": 0.9158122539520264,
      "attention_bam_384_mean_attention": -0.027520276606082916,
      "attention_bam_384_std_attention": 0.15470238029956818,
      "attention_bam_384_max_attention": 1.4187623262405396,
      "attention_bam_384_min_attention": -0.6903948187828064,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.3339598584987176,
      "attention_bam_384_attention_skewness": 0.40531196618476717,
      "attention_bam_384_attention_sparsity": 0.8192672729492188,
      "attention_bam_384_attention_concentration_10": -0.959785588596704,
      "attention_bam_384_attention_concentration_20": -1.4029693911110637,
      "attention_bam_384_attention_center_y": 0.48533744097774434,
      "attention_bam_384_attention_center_x": 0.48191201613223156,
      "attention_bam_384_attention_center_distance": 0.032929190621142884,
      "attention_bam_384_attention_spatial_variance": 171.93747763590665,
      "attention_bam_384_attention_spatial_std": 13.11249318916531,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 20.711419314038338,
      "attention_bam_384_peak_intensity_mean": 0.3201911747455597,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1440654695034027,
      "attention_bam_16_std_attention": 0.48916587233543396,
      "attention_bam_16_max_attention": 2.863492965698242,
      "attention_bam_16_min_attention": -0.9790422916412354,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.517145959774525,
      "attention_bam_16_attention_skewness": 0.8072909129686974,
      "attention_bam_16_attention_sparsity": 0.504150390625,
      "attention_bam_16_attention_concentration_10": 0.7784823651331086,
      "attention_bam_16_attention_concentration_20": 1.2151865884091555,
      "attention_bam_16_attention_center_y": 0.4760338415437594,
      "attention_bam_16_attention_center_x": 0.46215663544253444,
      "attention_bam_16_attention_center_distance": 0.06334819637809548,
      "attention_bam_16_attention_spatial_variance": 43.461124722998136,
      "attention_bam_16_attention_spatial_std": 6.592505193247718,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 10.572617574120613,
      "attention_bam_16_peak_intensity_mean": 0.3026999831199646,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 824,
      "phase": "train",
      "loss": 0.009715426713228226,
      "timestamp": 1759544028.6490068,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.009715426713228226,
      "ssim": 0.9093261361122131,
      "attention_bam_384_mean_attention": -0.02729690633714199,
      "attention_bam_384_std_attention": 0.17669525742530823,
      "attention_bam_384_max_attention": 1.6492843627929688,
      "attention_bam_384_min_attention": -0.8437715768814087,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.513451474316594,
      "attention_bam_384_attention_skewness": 0.6849568903116765,
      "attention_bam_384_attention_sparsity": 0.8029530843098959,
      "attention_bam_384_attention_concentration_10": -1.1463951206004284,
      "attention_bam_384_attention_concentration_20": -1.6404242453923352,
      "attention_bam_384_attention_center_y": 0.488894915045602,
      "attention_bam_384_attention_center_x": 0.4822515442629589,
      "attention_bam_384_attention_center_distance": 0.02960846476580991,
      "attention_bam_384_attention_spatial_variance": 168.9261013519466,
      "attention_bam_384_attention_spatial_std": 12.997157433529326,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 19.959120406002953,
      "attention_bam_384_peak_intensity_mean": 0.3324485123157501,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13260617852210999,
      "attention_bam_16_std_attention": 0.5651562809944153,
      "attention_bam_16_max_attention": 3.42988920211792,
      "attention_bam_16_min_attention": -1.0661553144454956,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.2695999142483743,
      "attention_bam_16_attention_skewness": 1.0957101144271737,
      "attention_bam_16_attention_sparsity": 0.543701171875,
      "attention_bam_16_attention_concentration_10": 0.9725869615116952,
      "attention_bam_16_attention_concentration_20": 1.492113540181877,
      "attention_bam_16_attention_center_y": 0.49025092482065463,
      "attention_bam_16_attention_center_x": 0.46622113945512533,
      "attention_bam_16_attention_center_distance": 0.049720335609539444,
      "attention_bam_16_attention_spatial_variance": 40.36187620944202,
      "attention_bam_16_attention_spatial_std": 6.353099732370178,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 8.53984503806081,
      "attention_bam_16_peak_intensity_mean": 0.29580923914909363,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 825,
      "phase": "train",
      "loss": 0.0037618556525558233,
      "timestamp": 1759544028.8229566,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0037618556525558233,
      "ssim": 0.9214704036712646,
      "attention_bam_384_mean_attention": -0.030115334317088127,
      "attention_bam_384_std_attention": 0.15525083243846893,
      "attention_bam_384_max_attention": 1.141007661819458,
      "attention_bam_384_min_attention": -0.6911495923995972,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.6753979537146746,
      "attention_bam_384_attention_skewness": 0.5152433303530419,
      "attention_bam_384_attention_sparsity": 0.824462890625,
      "attention_bam_384_attention_concentration_10": -0.8840066847909521,
      "attention_bam_384_attention_concentration_20": -1.277567481869637,
      "attention_bam_384_attention_center_y": 0.4773582540045325,
      "attention_bam_384_attention_center_x": 0.4817302164799141,
      "attention_bam_384_attention_center_distance": 0.04114446868277849,
      "attention_bam_384_attention_spatial_variance": 170.23190444362513,
      "attention_bam_384_attention_spatial_std": 13.047294909046286,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 19.12386968913768,
      "attention_bam_384_peak_intensity_mean": 0.37042149901390076,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13977204263210297,
      "attention_bam_16_std_attention": 0.5194731950759888,
      "attention_bam_16_max_attention": 2.5614161491394043,
      "attention_bam_16_min_attention": -1.0773544311523438,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.9944563531496677,
      "attention_bam_16_attention_skewness": 0.8373562699291222,
      "attention_bam_16_attention_sparsity": 0.530517578125,
      "attention_bam_16_attention_concentration_10": 0.8596410447120154,
      "attention_bam_16_attention_concentration_20": 1.3473645841748982,
      "attention_bam_16_attention_center_y": 0.44241287879534774,
      "attention_bam_16_attention_center_x": 0.4591580796650164,
      "attention_bam_16_attention_center_distance": 0.09984326702676004,
      "attention_bam_16_attention_spatial_variance": 41.457510557514105,
      "attention_bam_16_attention_spatial_std": 6.438750698506202,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 10.207150502287114,
      "attention_bam_16_peak_intensity_mean": 0.3408450186252594,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 826,
      "phase": "train",
      "loss": 0.006692112423479557,
      "timestamp": 1759544028.9996321,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006692112423479557,
      "ssim": 0.918692946434021,
      "attention_bam_384_mean_attention": -0.029501574113965034,
      "attention_bam_384_std_attention": 0.16807135939598083,
      "attention_bam_384_max_attention": 1.1419994831085205,
      "attention_bam_384_min_attention": -0.7510002255439758,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8126516863705664,
      "attention_bam_384_attention_skewness": 0.33266403639998,
      "attention_bam_384_attention_sparsity": 0.79547119140625,
      "attention_bam_384_attention_concentration_10": -0.9551012412518042,
      "attention_bam_384_attention_concentration_20": -1.4204921110993622,
      "attention_bam_384_attention_center_y": 0.48368153907068984,
      "attention_bam_384_attention_center_x": 0.48336080761800154,
      "attention_bam_384_attention_center_distance": 0.03295921389313094,
      "attention_bam_384_attention_spatial_variance": 172.72666934989942,
      "attention_bam_384_attention_spatial_std": 13.142551858368275,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 19.531805660405436,
      "attention_bam_384_peak_intensity_mean": 0.38928669691085815,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13564445078372955,
      "attention_bam_16_std_attention": 0.5355684161186218,
      "attention_bam_16_max_attention": 2.3440332412719727,
      "attention_bam_16_min_attention": -1.1115496158599854,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.14897679825540822,
      "attention_bam_16_attention_skewness": 0.5897295605454227,
      "attention_bam_16_attention_sparsity": 0.525390625,
      "attention_bam_16_attention_concentration_10": 0.86723499920717,
      "attention_bam_16_attention_concentration_20": 1.398004931345949,
      "attention_bam_16_attention_center_y": 0.46178036468280537,
      "attention_bam_16_attention_center_x": 0.4662807837044376,
      "attention_bam_16_attention_center_distance": 0.07207948489502783,
      "attention_bam_16_attention_spatial_variance": 44.06298978102428,
      "attention_bam_16_attention_spatial_std": 6.637995916014432,
      "attention_bam_16_num_attention_peaks": 11,
      "attention_bam_16_peak_separation_mean": 9.744601174996639,
      "attention_bam_16_peak_intensity_mean": 0.37749946117401123,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 827,
      "phase": "train",
      "loss": 0.004280540160834789,
      "timestamp": 1759544029.1816108,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004280540160834789,
      "ssim": 0.9350218772888184,
      "attention_bam_384_mean_attention": -0.029418321326375008,
      "attention_bam_384_std_attention": 0.1536279022693634,
      "attention_bam_384_max_attention": 1.0586824417114258,
      "attention_bam_384_min_attention": -0.7122942209243774,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8904372661131661,
      "attention_bam_384_attention_skewness": 0.3590316637751659,
      "attention_bam_384_attention_sparsity": 0.8163986206054688,
      "attention_bam_384_attention_concentration_10": -0.875806274193204,
      "attention_bam_384_attention_concentration_20": -1.2926545798749096,
      "attention_bam_384_attention_center_y": 0.48661264878103677,
      "attention_bam_384_attention_center_x": 0.48349667770366755,
      "attention_bam_384_attention_center_distance": 0.03005264778606038,
      "attention_bam_384_attention_spatial_variance": 172.2227696199693,
      "attention_bam_384_attention_spatial_std": 13.123367312544799,
      "attention_bam_384_num_attention_peaks": 24,
      "attention_bam_384_peak_separation_mean": 21.10599403048812,
      "attention_bam_384_peak_intensity_mean": 0.3954547941684723,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1307862102985382,
      "attention_bam_16_std_attention": 0.503863513469696,
      "attention_bam_16_max_attention": 2.543829917907715,
      "attention_bam_16_min_attention": -1.0280075073242188,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6323788309576717,
      "attention_bam_16_attention_skewness": 0.6560594079353474,
      "attention_bam_16_attention_sparsity": 0.51025390625,
      "attention_bam_16_attention_concentration_10": 0.8536791519046596,
      "attention_bam_16_attention_concentration_20": 1.3512205998348186,
      "attention_bam_16_attention_center_y": 0.4800042892628155,
      "attention_bam_16_attention_center_x": 0.47091267601188735,
      "attention_bam_16_attention_center_distance": 0.04991794997141986,
      "attention_bam_16_attention_spatial_variance": 43.62621008774715,
      "attention_bam_16_attention_spatial_std": 6.605014011169632,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 9.60292854769777,
      "attention_bam_16_peak_intensity_mean": 0.34024474024772644,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 828,
      "phase": "train",
      "loss": 0.005274487193673849,
      "timestamp": 1759544029.376086,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005274487193673849,
      "ssim": 0.9067103862762451,
      "attention_bam_384_mean_attention": -0.029824726283550262,
      "attention_bam_384_std_attention": 0.191273033618927,
      "attention_bam_384_max_attention": 1.1401751041412354,
      "attention_bam_384_min_attention": -0.8422949314117432,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6482906677963252,
      "attention_bam_384_attention_skewness": 0.3535811938793177,
      "attention_bam_384_attention_sparsity": 0.7744344075520834,
      "attention_bam_384_attention_concentration_10": -1.1143156465469926,
      "attention_bam_384_attention_concentration_20": -1.6611070960752763,
      "attention_bam_384_attention_center_y": 0.4868155306049947,
      "attention_bam_384_attention_center_x": 0.48438893610324574,
      "attention_bam_384_attention_center_distance": 0.028897596758774777,
      "attention_bam_384_attention_spatial_variance": 172.90931921325105,
      "attention_bam_384_attention_spatial_std": 13.149498819850551,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 22.029857312508128,
      "attention_bam_384_peak_intensity_mean": 0.4209630787372589,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13838091492652893,
      "attention_bam_16_std_attention": 0.5732915997505188,
      "attention_bam_16_max_attention": 2.603407382965088,
      "attention_bam_16_min_attention": -1.0793370008468628,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.36084863613210016,
      "attention_bam_16_attention_skewness": 0.684380330378353,
      "attention_bam_16_attention_sparsity": 0.524658203125,
      "attention_bam_16_attention_concentration_10": 0.9400206921947406,
      "attention_bam_16_attention_concentration_20": 1.477419258246027,
      "attention_bam_16_attention_center_y": 0.47966219833967505,
      "attention_bam_16_attention_center_x": 0.4681358072892854,
      "attention_bam_16_attention_center_distance": 0.0534593855834553,
      "attention_bam_16_attention_spatial_variance": 44.671593174738504,
      "attention_bam_16_attention_spatial_std": 6.683681109593612,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.41817871300637,
      "attention_bam_16_peak_intensity_mean": 0.3439953625202179,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 829,
      "phase": "train",
      "loss": 0.004043207503855228,
      "timestamp": 1759544029.5476465,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004043207503855228,
      "ssim": 0.9287906289100647,
      "attention_bam_384_mean_attention": -0.028910493478178978,
      "attention_bam_384_std_attention": 0.15506727993488312,
      "attention_bam_384_max_attention": 1.309731364250183,
      "attention_bam_384_min_attention": -0.7711804509162903,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9696279768238854,
      "attention_bam_384_attention_skewness": 0.2659184649522505,
      "attention_bam_384_attention_sparsity": 0.8123982747395834,
      "attention_bam_384_attention_concentration_10": -0.8796847529520486,
      "attention_bam_384_attention_concentration_20": -1.3069208898084859,
      "attention_bam_384_attention_center_y": 0.487247921979418,
      "attention_bam_384_attention_center_x": 0.479675222848599,
      "attention_bam_384_attention_center_distance": 0.033932640925725864,
      "attention_bam_384_attention_spatial_variance": 172.59211601371172,
      "attention_bam_384_attention_spatial_std": 13.137431865235751,
      "attention_bam_384_num_attention_peaks": 27,
      "attention_bam_384_peak_separation_mean": 18.628475620791136,
      "attention_bam_384_peak_intensity_mean": 0.36041828989982605,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13685160875320435,
      "attention_bam_16_std_attention": 0.48582231998443604,
      "attention_bam_16_max_attention": 2.5405871868133545,
      "attention_bam_16_min_attention": -0.9954683184623718,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.4242137773301864,
      "attention_bam_16_attention_skewness": 0.5080431265998462,
      "attention_bam_16_attention_sparsity": 0.499267578125,
      "attention_bam_16_attention_concentration_10": 0.7779116101898296,
      "attention_bam_16_attention_concentration_20": 1.2479926950646898,
      "attention_bam_16_attention_center_y": 0.4798237377102339,
      "attention_bam_16_attention_center_x": 0.4513139782426467,
      "attention_bam_16_attention_center_distance": 0.07453066851361147,
      "attention_bam_16_attention_spatial_variance": 43.996771933107915,
      "attention_bam_16_attention_spatial_std": 6.633006251550492,
      "attention_bam_16_num_attention_peaks": 12,
      "attention_bam_16_peak_separation_mean": 9.177598788675972,
      "attention_bam_16_peak_intensity_mean": 0.32408395409584045,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 830,
      "phase": "train",
      "loss": 0.007771219592541456,
      "timestamp": 1759544029.7616577,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007771219592541456,
      "ssim": 0.8975216746330261,
      "attention_bam_384_mean_attention": -0.027927741408348083,
      "attention_bam_384_std_attention": 0.1759536862373352,
      "attention_bam_384_max_attention": 1.2525911331176758,
      "attention_bam_384_min_attention": -0.7368601560592651,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6371511434155521,
      "attention_bam_384_attention_skewness": 0.2828526961858544,
      "attention_bam_384_attention_sparsity": 0.7807871500651041,
      "attention_bam_384_attention_concentration_10": -1.0635874312182514,
      "attention_bam_384_attention_concentration_20": -1.592878877858071,
      "attention_bam_384_attention_center_y": 0.4781257825864497,
      "attention_bam_384_attention_center_x": 0.483954194586486,
      "attention_bam_384_attention_center_distance": 0.03836532963037388,
      "attention_bam_384_attention_spatial_variance": 170.86398050027393,
      "attention_bam_384_attention_spatial_std": 13.071494960419558,
      "attention_bam_384_num_attention_peaks": 21,
      "attention_bam_384_peak_separation_mean": 16.577203551477037,
      "attention_bam_384_peak_intensity_mean": 0.36321815848350525,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13618257641792297,
      "attention_bam_16_std_attention": 0.5459191799163818,
      "attention_bam_16_max_attention": 2.3634750843048096,
      "attention_bam_16_min_attention": -1.0228220224380493,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.10660069450849807,
      "attention_bam_16_attention_skewness": 0.5156140880705281,
      "attention_bam_16_attention_sparsity": 0.516845703125,
      "attention_bam_16_attention_concentration_10": 0.8723202106669067,
      "attention_bam_16_attention_concentration_20": 1.4009089339153418,
      "attention_bam_16_attention_center_y": 0.4484782111795556,
      "attention_bam_16_attention_center_x": 0.46656102990328774,
      "attention_bam_16_attention_center_distance": 0.08686379504013493,
      "attention_bam_16_attention_spatial_variance": 42.60690931693034,
      "attention_bam_16_attention_spatial_std": 6.527396825452727,
      "attention_bam_16_num_attention_peaks": 11,
      "attention_bam_16_peak_separation_mean": 8.442694382794334,
      "attention_bam_16_peak_intensity_mean": 0.36664360761642456,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 831,
      "phase": "train",
      "loss": 0.005360998213291168,
      "timestamp": 1759544029.915197,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005360998213291168,
      "ssim": 0.8993221521377563,
      "attention_bam_384_mean_attention": -0.029205121099948883,
      "attention_bam_384_std_attention": 0.15658901631832123,
      "attention_bam_384_max_attention": 1.0631067752838135,
      "attention_bam_384_min_attention": -0.7387418746948242,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8221187747473833,
      "attention_bam_384_attention_skewness": 0.3784231720032495,
      "attention_bam_384_attention_sparsity": 0.8129933675130209,
      "attention_bam_384_attention_concentration_10": -0.9097055283231281,
      "attention_bam_384_attention_concentration_20": -1.3408203640716858,
      "attention_bam_384_attention_center_y": 0.4838226653836476,
      "attention_bam_384_attention_center_x": 0.48457044092639695,
      "attention_bam_384_attention_center_distance": 0.03161573812186708,
      "attention_bam_384_attention_spatial_variance": 171.4930777013288,
      "attention_bam_384_attention_spatial_std": 13.0955365564504,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 19.256209185347167,
      "attention_bam_384_peak_intensity_mean": 0.4004720449447632,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13250738382339478,
      "attention_bam_16_std_attention": 0.5114441514015198,
      "attention_bam_16_max_attention": 2.5283801555633545,
      "attention_bam_16_min_attention": -1.030407428741455,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.4662651405945861,
      "attention_bam_16_attention_skewness": 0.7057158055602275,
      "attention_bam_16_attention_sparsity": 0.535400390625,
      "attention_bam_16_attention_concentration_10": 0.8785494837014062,
      "attention_bam_16_attention_concentration_20": 1.3881962390184626,
      "attention_bam_16_attention_center_y": 0.4683549569338635,
      "attention_bam_16_attention_center_x": 0.4735789425432385,
      "attention_bam_16_attention_center_distance": 0.058300617969128374,
      "attention_bam_16_attention_spatial_variance": 43.1317202525415,
      "attention_bam_16_attention_spatial_std": 6.5674744196335855,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 9.711739339713565,
      "attention_bam_16_peak_intensity_mean": 0.33580446243286133,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 832,
      "phase": "train",
      "loss": 0.0053910259157419205,
      "timestamp": 1759544030.0635157,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0053910259157419205,
      "ssim": 0.9206084609031677,
      "attention_bam_384_mean_attention": -0.027745507657527924,
      "attention_bam_384_std_attention": 0.16534583270549774,
      "attention_bam_384_max_attention": 1.2735636234283447,
      "attention_bam_384_min_attention": -0.7453433871269226,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8447250886782891,
      "attention_bam_384_attention_skewness": 0.45100051772146094,
      "attention_bam_384_attention_sparsity": 0.7953542073567709,
      "attention_bam_384_attention_concentration_10": -1.0311969843410933,
      "attention_bam_384_attention_concentration_20": -1.5265233936445282,
      "attention_bam_384_attention_center_y": 0.48518639034835986,
      "attention_bam_384_attention_center_x": 0.4809798532691488,
      "attention_bam_384_attention_center_distance": 0.03409425208372444,
      "attention_bam_384_attention_spatial_variance": 170.24408409699802,
      "attention_bam_384_attention_spatial_std": 13.047761650834905,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 18.036533460025357,
      "attention_bam_384_peak_intensity_mean": 0.3619626760482788,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13660849630832672,
      "attention_bam_16_std_attention": 0.5370444655418396,
      "attention_bam_16_max_attention": 2.4945337772369385,
      "attention_bam_16_min_attention": -1.0160541534423828,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.4641791499051662,
      "attention_bam_16_attention_skewness": 0.7034204858990538,
      "attention_bam_16_attention_sparsity": 0.525390625,
      "attention_bam_16_attention_concentration_10": 0.8859767741619509,
      "attention_bam_16_attention_concentration_20": 1.404975936532616,
      "attention_bam_16_attention_center_y": 0.47064514454103434,
      "attention_bam_16_attention_center_x": 0.4562760150077987,
      "attention_bam_16_attention_center_distance": 0.07447810957073242,
      "attention_bam_16_attention_spatial_variance": 41.95194017602843,
      "attention_bam_16_attention_spatial_std": 6.477031741162647,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.034538422391332,
      "attention_bam_16_peak_intensity_mean": 0.345601886510849,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 833,
      "phase": "train",
      "loss": 0.0031459087040275335,
      "timestamp": 1759544030.2117543,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0031459087040275335,
      "ssim": 0.9344788193702698,
      "attention_bam_384_mean_attention": -0.028037406504154205,
      "attention_bam_384_std_attention": 0.14350853860378265,
      "attention_bam_384_max_attention": 1.1517244577407837,
      "attention_bam_384_min_attention": -0.6440918445587158,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2342123266359666,
      "attention_bam_384_attention_skewness": 0.39290137726554425,
      "attention_bam_384_attention_sparsity": 0.834075927734375,
      "attention_bam_384_attention_concentration_10": -0.8574699289630362,
      "attention_bam_384_attention_concentration_20": -1.253512358683226,
      "attention_bam_384_attention_center_y": 0.48386820633789407,
      "attention_bam_384_attention_center_x": 0.4824699761774018,
      "attention_bam_384_attention_center_distance": 0.033690844512348515,
      "attention_bam_384_attention_spatial_variance": 170.57354846803196,
      "attention_bam_384_attention_spatial_std": 13.060380869945254,
      "attention_bam_384_num_attention_peaks": 18,
      "attention_bam_384_peak_separation_mean": 20.197994448417198,
      "attention_bam_384_peak_intensity_mean": 0.350378155708313,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13023382425308228,
      "attention_bam_16_std_attention": 0.4782191514968872,
      "attention_bam_16_max_attention": 2.7330892086029053,
      "attention_bam_16_min_attention": -0.9892602562904358,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.1612766376018042,
      "attention_bam_16_attention_skewness": 0.7645629827280057,
      "attention_bam_16_attention_sparsity": 0.518798828125,
      "attention_bam_16_attention_concentration_10": 0.8274157982527418,
      "attention_bam_16_attention_concentration_20": 1.3026248523184827,
      "attention_bam_16_attention_center_y": 0.4699111157297277,
      "attention_bam_16_attention_center_x": 0.46096920196876257,
      "attention_bam_16_attention_center_distance": 0.06969568353327323,
      "attention_bam_16_attention_spatial_variance": 41.96480827325645,
      "attention_bam_16_attention_spatial_std": 6.478025028761193,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 8.758054807754617,
      "attention_bam_16_peak_intensity_mean": 0.3063355088233948,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 834,
      "phase": "train",
      "loss": 0.004030246287584305,
      "timestamp": 1759544030.3558056,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004030246287584305,
      "ssim": 0.9322234988212585,
      "attention_bam_384_mean_attention": -0.02721853367984295,
      "attention_bam_384_std_attention": 0.15371382236480713,
      "attention_bam_384_max_attention": 1.1262130737304688,
      "attention_bam_384_min_attention": -0.6826257705688477,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0967074816572158,
      "attention_bam_384_attention_skewness": 0.3580084382384685,
      "attention_bam_384_attention_sparsity": 0.8187967936197916,
      "attention_bam_384_attention_concentration_10": -0.9551649969182152,
      "attention_bam_384_attention_concentration_20": -1.3987437895949146,
      "attention_bam_384_attention_center_y": 0.48213666524051985,
      "attention_bam_384_attention_center_x": 0.4862071725367358,
      "attention_bam_384_attention_center_distance": 0.03191679238772679,
      "attention_bam_384_attention_spatial_variance": 171.40940329509564,
      "attention_bam_384_attention_spatial_std": 13.092341398508353,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 19.586178223116868,
      "attention_bam_384_peak_intensity_mean": 0.36946624517440796,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13320522010326385,
      "attention_bam_16_std_attention": 0.49850723147392273,
      "attention_bam_16_max_attention": 2.4162817001342773,
      "attention_bam_16_min_attention": -1.0341198444366455,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6862305488268992,
      "attention_bam_16_attention_skewness": 0.7049625019461241,
      "attention_bam_16_attention_sparsity": 0.514404296875,
      "attention_bam_16_attention_concentration_10": 0.8449904807306067,
      "attention_bam_16_attention_concentration_20": 1.3299550487822862,
      "attention_bam_16_attention_center_y": 0.4643037063095628,
      "attention_bam_16_attention_center_x": 0.47718641010700924,
      "attention_bam_16_attention_center_distance": 0.05991135563546391,
      "attention_bam_16_attention_spatial_variance": 43.426728748293996,
      "attention_bam_16_attention_spatial_std": 6.589895958836831,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 9.793583794338508,
      "attention_bam_16_peak_intensity_mean": 0.35282132029533386,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 835,
      "phase": "train",
      "loss": 0.0035949440207332373,
      "timestamp": 1759544030.525206,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0035949440207332373,
      "ssim": 0.9344450235366821,
      "attention_bam_384_mean_attention": -0.02808208577334881,
      "attention_bam_384_std_attention": 0.15477095544338226,
      "attention_bam_384_max_attention": 1.2749598026275635,
      "attention_bam_384_min_attention": -0.8150038719177246,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9573770826497592,
      "attention_bam_384_attention_skewness": 0.30454973423841664,
      "attention_bam_384_attention_sparsity": 0.8131790161132812,
      "attention_bam_384_attention_concentration_10": -0.916618770054727,
      "attention_bam_384_attention_concentration_20": -1.3616622157246292,
      "attention_bam_384_attention_center_y": 0.48381122137626925,
      "attention_bam_384_attention_center_x": 0.48019098294685514,
      "attention_bam_384_attention_center_distance": 0.03617937837884851,
      "attention_bam_384_attention_spatial_variance": 171.7468163636812,
      "attention_bam_384_attention_spatial_std": 13.10522095821666,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 21.49926873311695,
      "attention_bam_384_peak_intensity_mean": 0.38068297505378723,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14075201749801636,
      "attention_bam_16_std_attention": 0.5098623037338257,
      "attention_bam_16_max_attention": 2.6773056983947754,
      "attention_bam_16_min_attention": -1.098809003829956,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.37751303588483065,
      "attention_bam_16_attention_skewness": 0.5790283210472096,
      "attention_bam_16_attention_sparsity": 0.51318359375,
      "attention_bam_16_attention_concentration_10": 0.8048173837120668,
      "attention_bam_16_attention_concentration_20": 1.294193510935121,
      "attention_bam_16_attention_center_y": 0.4673566216277564,
      "attention_bam_16_attention_center_x": 0.4521019848890205,
      "attention_bam_16_attention_center_distance": 0.08197328837035983,
      "attention_bam_16_attention_spatial_variance": 43.51668802151531,
      "attention_bam_16_attention_spatial_std": 6.596717973470998,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.626863966850753,
      "attention_bam_16_peak_intensity_mean": 0.33517205715179443,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 836,
      "phase": "train",
      "loss": 0.005241792649030685,
      "timestamp": 1759544030.7173133,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005241792649030685,
      "ssim": 0.9246314764022827,
      "attention_bam_384_mean_attention": -0.028071017935872078,
      "attention_bam_384_std_attention": 0.1406194567680359,
      "attention_bam_384_max_attention": 1.1597702503204346,
      "attention_bam_384_min_attention": -0.6768684387207031,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1957625766757483,
      "attention_bam_384_attention_skewness": 0.23983382850679755,
      "attention_bam_384_attention_sparsity": 0.8401921590169271,
      "attention_bam_384_attention_concentration_10": -0.8131211633143509,
      "attention_bam_384_attention_concentration_20": -1.1943846195030943,
      "attention_bam_384_attention_center_y": 0.47982812329124896,
      "attention_bam_384_attention_center_x": 0.4826683806843636,
      "attention_bam_384_attention_center_distance": 0.037610893051221055,
      "attention_bam_384_attention_spatial_variance": 171.5949540602656,
      "attention_bam_384_attention_spatial_std": 13.099425714903138,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 19.590403683136678,
      "attention_bam_384_peak_intensity_mean": 0.35856544971466064,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14500820636749268,
      "attention_bam_16_std_attention": 0.4697357714176178,
      "attention_bam_16_max_attention": 2.209409713745117,
      "attention_bam_16_min_attention": -0.9957073926925659,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.467179559940063,
      "attention_bam_16_attention_skewness": 0.5030144542644072,
      "attention_bam_16_attention_sparsity": 0.49560546875,
      "attention_bam_16_attention_concentration_10": 0.722338227750193,
      "attention_bam_16_attention_concentration_20": 1.1599731013100307,
      "attention_bam_16_attention_center_y": 0.4520285830058084,
      "attention_bam_16_attention_center_x": 0.4612747970298543,
      "attention_bam_16_attention_center_distance": 0.08718828124822277,
      "attention_bam_16_attention_spatial_variance": 42.95461525389534,
      "attention_bam_16_attention_spatial_std": 6.553977056253351,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.071243849775161,
      "attention_bam_16_peak_intensity_mean": 0.3555509150028229,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 837,
      "phase": "train",
      "loss": 0.003543765749782324,
      "timestamp": 1759544030.904348,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.003543765749782324,
      "ssim": 0.9383314847946167,
      "attention_bam_384_mean_attention": -0.02714444510638714,
      "attention_bam_384_std_attention": 0.13250106573104858,
      "attention_bam_384_max_attention": 1.0056992769241333,
      "attention_bam_384_min_attention": -0.6981374025344849,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8451877728348474,
      "attention_bam_384_attention_skewness": 0.16195119824262397,
      "attention_bam_384_attention_sparsity": 0.8465932210286459,
      "attention_bam_384_attention_concentration_10": -0.781006454191967,
      "attention_bam_384_attention_concentration_20": -1.1610910980333753,
      "attention_bam_384_attention_center_y": 0.4842452300122195,
      "attention_bam_384_attention_center_x": 0.4842812986118859,
      "attention_bam_384_attention_center_distance": 0.03147349204319629,
      "attention_bam_384_attention_spatial_variance": 170.60567051366476,
      "attention_bam_384_attention_spatial_std": 13.061610563543256,
      "attention_bam_384_num_attention_peaks": 25,
      "attention_bam_384_peak_separation_mean": 19.084653890619336,
      "attention_bam_384_peak_intensity_mean": 0.3985130190849304,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.15312863886356354,
      "attention_bam_16_std_attention": 0.43588289618492126,
      "attention_bam_16_max_attention": 2.6285319328308105,
      "attention_bam_16_min_attention": -0.9313533902168274,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.16904642995024455,
      "attention_bam_16_attention_skewness": 0.3197453484824772,
      "attention_bam_16_attention_sparsity": 0.467529296875,
      "attention_bam_16_attention_concentration_10": 0.6216067395436383,
      "attention_bam_16_attention_concentration_20": 1.0213296842695516,
      "attention_bam_16_attention_center_y": 0.47156036302622684,
      "attention_bam_16_attention_center_x": 0.47299067786215643,
      "attention_bam_16_attention_center_distance": 0.05546740364476802,
      "attention_bam_16_attention_spatial_variance": 42.23092285320303,
      "attention_bam_16_attention_spatial_std": 6.498532361480016,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.30885274500063,
      "attention_bam_16_peak_intensity_mean": 0.30850476026535034,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 838,
      "phase": "train",
      "loss": 0.005115073174238205,
      "timestamp": 1759544031.0948527,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005115073174238205,
      "ssim": 0.9067935943603516,
      "attention_bam_384_mean_attention": -0.02743738330900669,
      "attention_bam_384_std_attention": 0.14766359329223633,
      "attention_bam_384_max_attention": 1.2427011728286743,
      "attention_bam_384_min_attention": -0.7314807176589966,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.3628858327583186,
      "attention_bam_384_attention_skewness": 0.3688079797425838,
      "attention_bam_384_attention_sparsity": 0.8325932820638021,
      "attention_bam_384_attention_concentration_10": -0.9219956099666848,
      "attention_bam_384_attention_concentration_20": -1.3352326039251137,
      "attention_bam_384_attention_center_y": 0.48638248119836497,
      "attention_bam_384_attention_center_x": 0.4848161851632014,
      "attention_bam_384_attention_center_distance": 0.02884389194651334,
      "attention_bam_384_attention_spatial_variance": 170.78624583917647,
      "attention_bam_384_attention_spatial_std": 13.068521180270416,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 20.79834377975097,
      "attention_bam_384_peak_intensity_mean": 0.3652070462703705,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14315266907215118,
      "attention_bam_16_std_attention": 0.47565746307373047,
      "attention_bam_16_max_attention": 2.4086973667144775,
      "attention_bam_16_min_attention": -1.028712272644043,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8127996914352735,
      "attention_bam_16_attention_skewness": 0.7358872234452266,
      "attention_bam_16_attention_sparsity": 0.508544921875,
      "attention_bam_16_attention_concentration_10": 0.7744945175755068,
      "attention_bam_16_attention_concentration_20": 1.2082650094055165,
      "attention_bam_16_attention_center_y": 0.4812107029551356,
      "attention_bam_16_attention_center_x": 0.47228447419334996,
      "attention_bam_16_attention_center_distance": 0.04735373383755991,
      "attention_bam_16_attention_spatial_variance": 42.851837440591545,
      "attention_bam_16_attention_spatial_std": 6.546131486656187,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.037071158892774,
      "attention_bam_16_peak_intensity_mean": 0.34943774342536926,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 839,
      "phase": "train",
      "loss": 0.006088278256356716,
      "timestamp": 1759544031.2793138,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006088278256356716,
      "ssim": 0.8927922248840332,
      "attention_bam_384_mean_attention": -0.02862478606402874,
      "attention_bam_384_std_attention": 0.16133706271648407,
      "attention_bam_384_max_attention": 1.190476655960083,
      "attention_bam_384_min_attention": -0.7055302858352661,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0024706434394597,
      "attention_bam_384_attention_skewness": 0.43175068498867797,
      "attention_bam_384_attention_sparsity": 0.8061599731445312,
      "attention_bam_384_attention_concentration_10": -0.9694496576012783,
      "attention_bam_384_attention_concentration_20": -1.4280637255658926,
      "attention_bam_384_attention_center_y": 0.4842223576639644,
      "attention_bam_384_attention_center_x": 0.47969109155347167,
      "attention_bam_384_attention_center_distance": 0.036369926037134945,
      "attention_bam_384_attention_spatial_variance": 171.6038643944048,
      "attention_bam_384_attention_spatial_std": 13.099765814487098,
      "attention_bam_384_num_attention_peaks": 18,
      "attention_bam_384_peak_separation_mean": 17.108494422191015,
      "attention_bam_384_peak_intensity_mean": 0.363511860370636,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1391228437423706,
      "attention_bam_16_std_attention": 0.5030872821807861,
      "attention_bam_16_max_attention": 2.405972480773926,
      "attention_bam_16_min_attention": -1.0311139822006226,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.4852004824109679,
      "attention_bam_16_attention_skewness": 0.7110523871887628,
      "attention_bam_16_attention_sparsity": 0.5234375,
      "attention_bam_16_attention_concentration_10": 0.8291032837435167,
      "attention_bam_16_attention_concentration_20": 1.308959279251986,
      "attention_bam_16_attention_center_y": 0.47025147931933997,
      "attention_bam_16_attention_center_x": 0.4495408957815294,
      "attention_bam_16_attention_center_distance": 0.08283834475915287,
      "attention_bam_16_attention_spatial_variance": 43.28676420934868,
      "attention_bam_16_attention_spatial_std": 6.579267756319747,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 10.016563416966827,
      "attention_bam_16_peak_intensity_mean": 0.3620387315750122,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 840,
      "phase": "train",
      "loss": 0.004944188520312309,
      "timestamp": 1759544031.515744,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004944188520312309,
      "ssim": 0.9162039756774902,
      "attention_bam_384_mean_attention": -0.028343565762043,
      "attention_bam_384_std_attention": 0.14356675744056702,
      "attention_bam_384_max_attention": 1.0233838558197021,
      "attention_bam_384_min_attention": -0.6699115037918091,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7598906062258255,
      "attention_bam_384_attention_skewness": 0.2048408574880744,
      "attention_bam_384_attention_sparsity": 0.8338775634765625,
      "attention_bam_384_attention_concentration_10": -0.8269772594870987,
      "attention_bam_384_attention_concentration_20": -1.2194843483461335,
      "attention_bam_384_attention_center_y": 0.47702088583113217,
      "attention_bam_384_attention_center_x": 0.4842292558495435,
      "attention_bam_384_attention_center_distance": 0.0394146180761661,
      "attention_bam_384_attention_spatial_variance": 170.2628278540463,
      "attention_bam_384_attention_spatial_std": 13.048479905875867,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 18.057248979636288,
      "attention_bam_384_peak_intensity_mean": 0.3884168267250061,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1494467556476593,
      "attention_bam_16_std_attention": 0.48122647404670715,
      "attention_bam_16_max_attention": 1.8907368183135986,
      "attention_bam_16_min_attention": -0.9457680583000183,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.028549695548399256,
      "attention_bam_16_attention_skewness": 0.3912982865942485,
      "attention_bam_16_attention_sparsity": 0.482666015625,
      "attention_bam_16_attention_concentration_10": 0.7072423608462692,
      "attention_bam_16_attention_concentration_20": 1.1484624599057667,
      "attention_bam_16_attention_center_y": 0.4403075896871638,
      "attention_bam_16_attention_center_x": 0.4722477803972072,
      "attention_bam_16_attention_center_distance": 0.09309532256604115,
      "attention_bam_16_attention_spatial_variance": 41.595807296920604,
      "attention_bam_16_attention_spatial_std": 6.449481164940371,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.015869129829335,
      "attention_bam_16_peak_intensity_mean": 0.393333375453949,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 841,
      "phase": "train",
      "loss": 0.00528685562312603,
      "timestamp": 1759544031.7042155,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00528685562312603,
      "ssim": 0.9105678796768188,
      "attention_bam_384_mean_attention": -0.02824719063937664,
      "attention_bam_384_std_attention": 0.1598069965839386,
      "attention_bam_384_max_attention": 1.1131511926651,
      "attention_bam_384_min_attention": -0.6853395104408264,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5973559156456316,
      "attention_bam_384_attention_skewness": 0.30562648306953877,
      "attention_bam_384_attention_sparsity": 0.7976150512695312,
      "attention_bam_384_attention_concentration_10": -0.9418222776681332,
      "attention_bam_384_attention_concentration_20": -1.4170902636866285,
      "attention_bam_384_attention_center_y": 0.4848836553918471,
      "attention_bam_384_attention_center_x": 0.48250470687148206,
      "attention_bam_384_attention_center_distance": 0.032698292186754976,
      "attention_bam_384_attention_spatial_variance": 172.0733386916317,
      "attention_bam_384_attention_spatial_std": 13.117672762027253,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 19.69388699379971,
      "attention_bam_384_peak_intensity_mean": 0.37434470653533936,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12922629714012146,
      "attention_bam_16_std_attention": 0.5129895806312561,
      "attention_bam_16_max_attention": 2.298393726348877,
      "attention_bam_16_min_attention": -0.9919208288192749,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.0648365147565868,
      "attention_bam_16_attention_skewness": 0.6176896078614149,
      "attention_bam_16_attention_sparsity": 0.530029296875,
      "attention_bam_16_attention_concentration_10": 0.8850798468046844,
      "attention_bam_16_attention_concentration_20": 1.420394062400015,
      "attention_bam_16_attention_center_y": 0.47286813617665596,
      "attention_bam_16_attention_center_x": 0.46169772477922344,
      "attention_bam_16_attention_center_distance": 0.06638075506676011,
      "attention_bam_16_attention_spatial_variance": 44.21703188511437,
      "attention_bam_16_attention_spatial_std": 6.649588850832386,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 10.125216491657337,
      "attention_bam_16_peak_intensity_mean": 0.352354496717453,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 842,
      "phase": "train",
      "loss": 0.003988281823694706,
      "timestamp": 1759544031.874,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.003988281823694706,
      "ssim": 0.9284834861755371,
      "attention_bam_384_mean_attention": -0.029370276257395744,
      "attention_bam_384_std_attention": 0.15092343091964722,
      "attention_bam_384_max_attention": 1.1605768203735352,
      "attention_bam_384_min_attention": -0.733626663684845,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4284109943439143,
      "attention_bam_384_attention_skewness": 0.46856057910980214,
      "attention_bam_384_attention_sparsity": 0.8310724894205729,
      "attention_bam_384_attention_concentration_10": -0.8744971581776103,
      "attention_bam_384_attention_concentration_20": -1.2621521921770844,
      "attention_bam_384_attention_center_y": 0.48387961656247425,
      "attention_bam_384_attention_center_x": 0.4802310003859974,
      "attention_bam_384_attention_center_distance": 0.03607437062268138,
      "attention_bam_384_attention_spatial_variance": 171.7841797419823,
      "attention_bam_384_attention_spatial_std": 13.106646395702537,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 20.34783855129031,
      "attention_bam_384_peak_intensity_mean": 0.3816644847393036,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13515038788318634,
      "attention_bam_16_std_attention": 0.5241270065307617,
      "attention_bam_16_max_attention": 2.863128185272217,
      "attention_bam_16_min_attention": -1.0229191780090332,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.9646561526375814,
      "attention_bam_16_attention_skewness": 0.8224162676981701,
      "attention_bam_16_attention_sparsity": 0.526123046875,
      "attention_bam_16_attention_concentration_10": 0.8890005048468433,
      "attention_bam_16_attention_concentration_20": 1.381034663515737,
      "attention_bam_16_attention_center_y": 0.4686924581357165,
      "attention_bam_16_attention_center_x": 0.45339397324695013,
      "attention_bam_16_attention_center_distance": 0.07940130864525927,
      "attention_bam_16_attention_spatial_variance": 43.36518750854768,
      "attention_bam_16_attention_spatial_std": 6.5852249398595095,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.703163789454617,
      "attention_bam_16_peak_intensity_mean": 0.3117053210735321,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 843,
      "phase": "train",
      "loss": 0.005390696227550507,
      "timestamp": 1759544032.0337126,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005390696227550507,
      "ssim": 0.9116550087928772,
      "attention_bam_384_mean_attention": -0.028298601508140564,
      "attention_bam_384_std_attention": 0.1610899716615677,
      "attention_bam_384_max_attention": 1.446955680847168,
      "attention_bam_384_min_attention": -0.7369017601013184,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9678540648426832,
      "attention_bam_384_attention_skewness": 0.22924945709716515,
      "attention_bam_384_attention_sparsity": 0.8063278198242188,
      "attention_bam_384_attention_concentration_10": -0.9378253866208345,
      "attention_bam_384_attention_concentration_20": -1.3920842840107077,
      "attention_bam_384_attention_center_y": 0.48426121781043163,
      "attention_bam_384_attention_center_x": 0.4828319859078904,
      "attention_bam_384_attention_center_distance": 0.03293781937765609,
      "attention_bam_384_attention_spatial_variance": 170.16795509368973,
      "attention_bam_384_attention_spatial_std": 13.044844004191454,
      "attention_bam_384_num_attention_peaks": 24,
      "attention_bam_384_peak_separation_mean": 18.300094126318456,
      "attention_bam_384_peak_intensity_mean": 0.3283947706222534,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14449623227119446,
      "attention_bam_16_std_attention": 0.5158492922782898,
      "attention_bam_16_max_attention": 2.6841487884521484,
      "attention_bam_16_min_attention": -1.0141273736953735,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.30533390791293913,
      "attention_bam_16_attention_skewness": 0.4781024399278767,
      "attention_bam_16_attention_sparsity": 0.499267578125,
      "attention_bam_16_attention_concentration_10": 0.7849353685108285,
      "attention_bam_16_attention_concentration_20": 1.254256635396564,
      "attention_bam_16_attention_center_y": 0.46472240638350476,
      "attention_bam_16_attention_center_x": 0.465954800033938,
      "attention_bam_16_attention_center_distance": 0.06933374722456204,
      "attention_bam_16_attention_spatial_variance": 41.76868700279909,
      "attention_bam_16_attention_spatial_std": 6.462869873577766,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 8.477722591603294,
      "attention_bam_16_peak_intensity_mean": 0.31319987773895264,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 844,
      "phase": "train",
      "loss": 0.004014268517494202,
      "timestamp": 1759544032.1836293,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004014268517494202,
      "ssim": 0.9294637441635132,
      "attention_bam_384_mean_attention": -0.02834584005177021,
      "attention_bam_384_std_attention": 0.13837109506130219,
      "attention_bam_384_max_attention": 1.1456152200698853,
      "attention_bam_384_min_attention": -0.6505274772644043,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1222325811686709,
      "attention_bam_384_attention_skewness": 0.3446861590097925,
      "attention_bam_384_attention_sparsity": 0.8396123250325521,
      "attention_bam_384_attention_concentration_10": -0.7998543484707764,
      "attention_bam_384_attention_concentration_20": -1.1785612057546082,
      "attention_bam_384_attention_center_y": 0.48076540458865336,
      "attention_bam_384_attention_center_x": 0.4808724140722938,
      "attention_bam_384_attention_center_distance": 0.03836233058769973,
      "attention_bam_384_attention_spatial_variance": 171.89061855127446,
      "attention_bam_384_attention_spatial_std": 13.11070625676872,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 20.00446440619643,
      "attention_bam_384_peak_intensity_mean": 0.3566329777240753,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13743707537651062,
      "attention_bam_16_std_attention": 0.47045961022377014,
      "attention_bam_16_max_attention": 2.3151981830596924,
      "attention_bam_16_min_attention": -0.9702481031417847,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.609029815232089,
      "attention_bam_16_attention_skewness": 0.6677306063145432,
      "attention_bam_16_attention_sparsity": 0.51416015625,
      "attention_bam_16_attention_concentration_10": 0.7783094476578508,
      "attention_bam_16_attention_concentration_20": 1.2387061995090503,
      "attention_bam_16_attention_center_y": 0.4540078916245345,
      "attention_bam_16_attention_center_x": 0.45365346208389906,
      "attention_bam_16_attention_center_distance": 0.09233932650424896,
      "attention_bam_16_attention_spatial_variance": 43.32373235738488,
      "attention_bam_16_attention_spatial_std": 6.582076599173309,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 10.20280661872383,
      "attention_bam_16_peak_intensity_mean": 0.3615672290325165,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 845,
      "phase": "train",
      "loss": 0.005807423498481512,
      "timestamp": 1759544032.3345282,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005807423498481512,
      "ssim": 0.9289448261260986,
      "attention_bam_384_mean_attention": -0.028976136818528175,
      "attention_bam_384_std_attention": 0.16063183546066284,
      "attention_bam_384_max_attention": 0.9408671259880066,
      "attention_bam_384_min_attention": -0.681929349899292,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6062884601740763,
      "attention_bam_384_attention_skewness": 0.3199343748844179,
      "attention_bam_384_attention_sparsity": 0.8032760620117188,
      "attention_bam_384_attention_concentration_10": -0.9330502580974844,
      "attention_bam_384_attention_concentration_20": -1.3930563743194688,
      "attention_bam_384_attention_center_y": 0.487373668635097,
      "attention_bam_384_attention_center_x": 0.48162564312565603,
      "attention_bam_384_attention_center_distance": 0.03152907338575253,
      "attention_bam_384_attention_spatial_variance": 171.93432726938778,
      "attention_bam_384_attention_spatial_std": 13.112373060182042,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 21.945130193066493,
      "attention_bam_384_peak_intensity_mean": 0.4165922999382019,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1266380399465561,
      "attention_bam_16_std_attention": 0.5325536727905273,
      "attention_bam_16_max_attention": 2.272374153137207,
      "attention_bam_16_min_attention": -1.0079275369644165,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.13845395505568314,
      "attention_bam_16_attention_skewness": 0.6218303203475162,
      "attention_bam_16_attention_sparsity": 0.532958984375,
      "attention_bam_16_attention_concentration_10": 0.9272018647741155,
      "attention_bam_16_attention_concentration_20": 1.4883366368151865,
      "attention_bam_16_attention_center_y": 0.4773966658285638,
      "attention_bam_16_attention_center_x": 0.4601006557352665,
      "attention_bam_16_attention_center_distance": 0.0648516520748907,
      "attention_bam_16_attention_spatial_variance": 43.5491698561623,
      "attention_bam_16_attention_spatial_std": 6.599179483554171,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 10.025270653138776,
      "attention_bam_16_peak_intensity_mean": 0.3693329691886902,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 846,
      "phase": "train",
      "loss": 0.004910047631710768,
      "timestamp": 1759544032.4766746,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004910047631710768,
      "ssim": 0.8998356461524963,
      "attention_bam_384_mean_attention": -0.028004273772239685,
      "attention_bam_384_std_attention": 0.15762995183467865,
      "attention_bam_384_max_attention": 1.1721601486206055,
      "attention_bam_384_min_attention": -0.6940507292747498,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8393260070477986,
      "attention_bam_384_attention_skewness": 0.35720881507427527,
      "attention_bam_384_attention_sparsity": 0.8080240885416666,
      "attention_bam_384_attention_concentration_10": -0.9510197312710559,
      "attention_bam_384_attention_concentration_20": -1.4078050658002623,
      "attention_bam_384_attention_center_y": 0.48129047750063825,
      "attention_bam_384_attention_center_x": 0.4849317149918965,
      "attention_bam_384_attention_center_distance": 0.033973502770234316,
      "attention_bam_384_attention_spatial_variance": 170.9989340724976,
      "attention_bam_384_attention_spatial_std": 13.076656073801804,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 22.01616945852983,
      "attention_bam_384_peak_intensity_mean": 0.3646196722984314,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12641966342926025,
      "attention_bam_16_std_attention": 0.5188754200935364,
      "attention_bam_16_max_attention": 2.5999767780303955,
      "attention_bam_16_min_attention": -0.9737186431884766,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6433107687091484,
      "attention_bam_16_attention_skewness": 0.7827612998408864,
      "attention_bam_16_attention_sparsity": 0.54150390625,
      "attention_bam_16_attention_concentration_10": 0.9355665096449639,
      "attention_bam_16_attention_concentration_20": 1.4691058807714514,
      "attention_bam_16_attention_center_y": 0.45285738063942726,
      "attention_bam_16_attention_center_x": 0.4753465858859533,
      "attention_bam_16_attention_center_distance": 0.07523586096609147,
      "attention_bam_16_attention_spatial_variance": 42.47872424778144,
      "attention_bam_16_attention_spatial_std": 6.517570425226063,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 7.5457257571674745,
      "attention_bam_16_peak_intensity_mean": 0.30743104219436646,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 847,
      "phase": "train",
      "loss": 0.006044258829206228,
      "timestamp": 1759544032.6168454,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006044258829206228,
      "ssim": 0.9020607471466064,
      "attention_bam_384_mean_attention": -0.028472190722823143,
      "attention_bam_384_std_attention": 0.1519194096326828,
      "attention_bam_384_max_attention": 1.1275665760040283,
      "attention_bam_384_min_attention": -0.6663734912872314,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7076103524702955,
      "attention_bam_384_attention_skewness": 0.26556526620835724,
      "attention_bam_384_attention_sparsity": 0.8181940714518229,
      "attention_bam_384_attention_concentration_10": -0.8879449440877935,
      "attention_bam_384_attention_concentration_20": -1.3159098874459634,
      "attention_bam_384_attention_center_y": 0.48414460775392476,
      "attention_bam_384_attention_center_x": 0.4857390564834805,
      "attention_bam_384_attention_center_distance": 0.030158513665572543,
      "attention_bam_384_attention_spatial_variance": 171.8052167030903,
      "attention_bam_384_attention_spatial_std": 13.107448901410613,
      "attention_bam_384_num_attention_peaks": 23,
      "attention_bam_384_peak_separation_mean": 19.127896814983174,
      "attention_bam_384_peak_intensity_mean": 0.3589143753051758,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1404118835926056,
      "attention_bam_16_std_attention": 0.5103968977928162,
      "attention_bam_16_max_attention": 2.4046521186828613,
      "attention_bam_16_min_attention": -0.99733567237854,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.3789812867976723,
      "attention_bam_16_attention_skewness": 0.6083072651301518,
      "attention_bam_16_attention_sparsity": 0.50830078125,
      "attention_bam_16_attention_concentration_10": 0.8168500889500863,
      "attention_bam_16_attention_concentration_20": 1.2974644063023844,
      "attention_bam_16_attention_center_y": 0.4724636021766497,
      "attention_bam_16_attention_center_x": 0.4739713398630796,
      "attention_bam_16_attention_center_distance": 0.05358627349628114,
      "attention_bam_16_attention_spatial_variance": 43.50656941395608,
      "attention_bam_16_attention_spatial_std": 6.595950986321538,
      "attention_bam_16_num_attention_peaks": 11,
      "attention_bam_16_peak_separation_mean": 9.748525782195326,
      "attention_bam_16_peak_intensity_mean": 0.341006875038147,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 848,
      "phase": "train",
      "loss": 0.002777072601020336,
      "timestamp": 1759544032.7874742,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.002777072601020336,
      "ssim": 0.9461021423339844,
      "attention_bam_384_mean_attention": -0.027929896488785744,
      "attention_bam_384_std_attention": 0.15880994498729706,
      "attention_bam_384_max_attention": 1.0161631107330322,
      "attention_bam_384_min_attention": -0.7110594511032104,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.17859919884193953,
      "attention_bam_384_attention_skewness": 0.23835675464581862,
      "attention_bam_384_attention_sparsity": 0.7908528645833334,
      "attention_bam_384_attention_concentration_10": -0.937271019847623,
      "attention_bam_384_attention_concentration_20": -1.4287846714711898,
      "attention_bam_384_attention_center_y": 0.48649344322194266,
      "attention_bam_384_attention_center_x": 0.488393093926292,
      "attention_bam_384_attention_center_distance": 0.025185207745927637,
      "attention_bam_384_attention_spatial_variance": 170.50282160687047,
      "attention_bam_384_attention_spatial_std": 13.057672901664771,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 18.078269381800798,
      "attention_bam_384_peak_intensity_mean": 0.3991892635822296,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.11948983371257782,
      "attention_bam_16_std_attention": 0.5145688652992249,
      "attention_bam_16_max_attention": 2.2013206481933594,
      "attention_bam_16_min_attention": -0.953225314617157,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.07749841005472158,
      "attention_bam_16_attention_skewness": 0.5910294520892398,
      "attention_bam_16_attention_sparsity": 0.5419921875,
      "attention_bam_16_attention_concentration_10": 0.939071637266416,
      "attention_bam_16_attention_concentration_20": 1.522316543273796,
      "attention_bam_16_attention_center_y": 0.4842748988882178,
      "attention_bam_16_attention_center_x": 0.4865898793766092,
      "attention_bam_16_attention_center_distance": 0.029227047066361856,
      "attention_bam_16_attention_spatial_variance": 42.36083393950319,
      "attention_bam_16_attention_spatial_std": 6.508520103641318,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 10.631221823296121,
      "attention_bam_16_peak_intensity_mean": 0.35324645042419434,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 849,
      "phase": "train",
      "loss": 0.007939863950014114,
      "timestamp": 1759544032.9775252,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007939863950014114,
      "ssim": 0.8736921548843384,
      "attention_bam_384_mean_attention": -0.02813631109893322,
      "attention_bam_384_std_attention": 0.15816928446292877,
      "attention_bam_384_max_attention": 1.1162950992584229,
      "attention_bam_384_min_attention": -0.7617809772491455,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.4616121718293065,
      "attention_bam_384_attention_skewness": 0.16836729022110686,
      "attention_bam_384_attention_sparsity": 0.7973810831705729,
      "attention_bam_384_attention_concentration_10": -0.9106627799472888,
      "attention_bam_384_attention_concentration_20": -1.3851831223380506,
      "attention_bam_384_attention_center_y": 0.48529887594138477,
      "attention_bam_384_attention_center_x": 0.48178421932278187,
      "attention_bam_384_attention_center_distance": 0.03310400925166947,
      "attention_bam_384_attention_spatial_variance": 170.92549200126606,
      "attention_bam_384_attention_spatial_std": 13.073847635691111,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 17.01838031565677,
      "attention_bam_384_peak_intensity_mean": 0.3931905925273895,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14009582996368408,
      "attention_bam_16_std_attention": 0.5400257110595703,
      "attention_bam_16_max_attention": 2.406010866165161,
      "attention_bam_16_min_attention": -1.0004627704620361,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.1826855691316216,
      "attention_bam_16_attention_skewness": 0.4431259781350299,
      "attention_bam_16_attention_sparsity": 0.50634765625,
      "attention_bam_16_attention_concentration_10": 0.8256387267993105,
      "attention_bam_16_attention_concentration_20": 1.3556969440943996,
      "attention_bam_16_attention_center_y": 0.47174497536445276,
      "attention_bam_16_attention_center_x": 0.45521470434752986,
      "attention_bam_16_attention_center_distance": 0.07488750394871686,
      "attention_bam_16_attention_spatial_variance": 42.60133375819853,
      "attention_bam_16_attention_spatial_std": 6.526969722482136,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.658789309611889,
      "attention_bam_16_peak_intensity_mean": 0.33967676758766174,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 850,
      "phase": "train",
      "loss": 0.005098673980683088,
      "timestamp": 1759544033.2175858,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005098673980683088,
      "ssim": 0.909884512424469,
      "attention_bam_384_mean_attention": -0.02813473530113697,
      "attention_bam_384_std_attention": 0.15384142100811005,
      "attention_bam_384_max_attention": 1.248821496963501,
      "attention_bam_384_min_attention": -0.754128098487854,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0401835621315687,
      "attention_bam_384_attention_skewness": 0.28430984373373713,
      "attention_bam_384_attention_sparsity": 0.8164291381835938,
      "attention_bam_384_attention_concentration_10": -0.9107441990993657,
      "attention_bam_384_attention_concentration_20": -1.347414287507438,
      "attention_bam_384_attention_center_y": 0.48145014912849976,
      "attention_bam_384_attention_center_x": 0.48687612435478783,
      "attention_bam_384_attention_center_distance": 0.03213512344167643,
      "attention_bam_384_attention_spatial_variance": 170.67582528699853,
      "attention_bam_384_attention_spatial_std": 13.06429582055606,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 17.50032890995699,
      "attention_bam_384_peak_intensity_mean": 0.36403241753578186,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13299481570720673,
      "attention_bam_16_std_attention": 0.5187514424324036,
      "attention_bam_16_max_attention": 2.85557222366333,
      "attention_bam_16_min_attention": -1.049450397491455,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.2803058901121429,
      "attention_bam_16_attention_skewness": 0.5698048767343739,
      "attention_bam_16_attention_sparsity": 0.515625,
      "attention_bam_16_attention_concentration_10": 0.8660212942373743,
      "attention_bam_16_attention_concentration_20": 1.3818513139777553,
      "attention_bam_16_attention_center_y": 0.45951339992323653,
      "attention_bam_16_attention_center_x": 0.4806359272705322,
      "attention_bam_16_attention_center_distance": 0.06346860796406205,
      "attention_bam_16_attention_spatial_variance": 42.518856350414666,
      "attention_bam_16_attention_spatial_std": 6.52064846088291,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.49663812940009,
      "attention_bam_16_peak_intensity_mean": 0.3039085566997528,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 851,
      "phase": "train",
      "loss": 0.006921123713254929,
      "timestamp": 1759544033.4025035,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006921123713254929,
      "ssim": 0.9180141687393188,
      "attention_bam_384_mean_attention": -0.027206644415855408,
      "attention_bam_384_std_attention": 0.15787118673324585,
      "attention_bam_384_max_attention": 0.9601377248764038,
      "attention_bam_384_min_attention": -0.726168692111969,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5236467991406766,
      "attention_bam_384_attention_skewness": 0.23883840672844456,
      "attention_bam_384_attention_sparsity": 0.8030624389648438,
      "attention_bam_384_attention_concentration_10": -0.9683017792506653,
      "attention_bam_384_attention_concentration_20": -1.452326468972795,
      "attention_bam_384_attention_center_y": 0.482234597700508,
      "attention_bam_384_attention_center_x": 0.4859135839457891,
      "attention_bam_384_attention_center_distance": 0.03206358171243897,
      "attention_bam_384_attention_spatial_variance": 170.7423622388786,
      "attention_bam_384_attention_spatial_std": 13.066842091296527,
      "attention_bam_384_num_attention_peaks": 22,
      "attention_bam_384_peak_separation_mean": 18.039486045559265,
      "attention_bam_384_peak_intensity_mean": 0.41795358061790466,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12421674281358719,
      "attention_bam_16_std_attention": 0.5182350873947144,
      "attention_bam_16_max_attention": 2.426410675048828,
      "attention_bam_16_min_attention": -0.9426610469818115,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.13543660949537317,
      "attention_bam_16_attention_skewness": 0.5928683065356525,
      "attention_bam_16_attention_sparsity": 0.52197265625,
      "attention_bam_16_attention_concentration_10": 0.9231717752764812,
      "attention_bam_16_attention_concentration_20": 1.4699576039642257,
      "attention_bam_16_attention_center_y": 0.46191376280517465,
      "attention_bam_16_attention_center_x": 0.4805755856642607,
      "attention_bam_16_attention_center_distance": 0.06046270480133969,
      "attention_bam_16_attention_spatial_variance": 42.434435897843464,
      "attention_bam_16_attention_spatial_std": 6.514171927255487,
      "attention_bam_16_num_attention_peaks": 12,
      "attention_bam_16_peak_separation_mean": 8.966773124752562,
      "attention_bam_16_peak_intensity_mean": 0.3240600824356079,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 852,
      "phase": "train",
      "loss": 0.008975639939308167,
      "timestamp": 1759544033.5836737,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008975639939308167,
      "ssim": 0.8629850149154663,
      "attention_bam_384_mean_attention": -0.026170818135142326,
      "attention_bam_384_std_attention": 0.12975920736789703,
      "attention_bam_384_max_attention": 0.8223693370819092,
      "attention_bam_384_min_attention": -0.650729775428772,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8243530759015232,
      "attention_bam_384_attention_skewness": 0.1974581952849787,
      "attention_bam_384_attention_sparsity": 0.8482691446940104,
      "attention_bam_384_attention_concentration_10": -0.8017703567643542,
      "attention_bam_384_attention_concentration_20": -1.1923303835939574,
      "attention_bam_384_attention_center_y": 0.4833907135080076,
      "attention_bam_384_attention_center_x": 0.48214189590855766,
      "attention_bam_384_attention_center_distance": 0.034490006654504156,
      "attention_bam_384_attention_spatial_variance": 171.58451618728594,
      "attention_bam_384_attention_spatial_std": 13.099027299280124,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 19.8864549188536,
      "attention_bam_384_peak_intensity_mean": 0.42809680104255676,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13419462740421295,
      "attention_bam_16_std_attention": 0.4462178945541382,
      "attention_bam_16_max_attention": 2.3449392318725586,
      "attention_bam_16_min_attention": -0.9281753301620483,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5981464849352713,
      "attention_bam_16_attention_skewness": 0.5856604645409771,
      "attention_bam_16_attention_sparsity": 0.5087890625,
      "attention_bam_16_attention_concentration_10": 0.745604231286145,
      "attention_bam_16_attention_concentration_20": 1.1879337069216631,
      "attention_bam_16_attention_center_y": 0.4675804160767014,
      "attention_bam_16_attention_center_x": 0.4601658770493016,
      "attention_bam_16_attention_center_distance": 0.07263314357799963,
      "attention_bam_16_attention_spatial_variance": 43.43031877496129,
      "attention_bam_16_attention_spatial_std": 6.5901683419288535,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.146029668894073,
      "attention_bam_16_peak_intensity_mean": 0.33138251304626465,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 853,
      "phase": "train",
      "loss": 0.006711398717015982,
      "timestamp": 1759544033.7525177,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006711398717015982,
      "ssim": 0.9207128286361694,
      "attention_bam_384_mean_attention": -0.027504652738571167,
      "attention_bam_384_std_attention": 0.16089479625225067,
      "attention_bam_384_max_attention": 0.8577924370765686,
      "attention_bam_384_min_attention": -0.6847525238990784,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.4622640848812045,
      "attention_bam_384_attention_skewness": 0.19451390823486997,
      "attention_bam_384_attention_sparsity": 0.7995783487955729,
      "attention_bam_384_attention_concentration_10": -0.970910991369077,
      "attention_bam_384_attention_concentration_20": -1.4584944643889026,
      "attention_bam_384_attention_center_y": 0.4856883328266816,
      "attention_bam_384_attention_center_x": 0.4860650713611251,
      "attention_bam_384_attention_center_distance": 0.02824910807265869,
      "attention_bam_384_attention_spatial_variance": 171.26803271030266,
      "attention_bam_384_attention_spatial_std": 13.086941304609823,
      "attention_bam_384_num_attention_peaks": 18,
      "attention_bam_384_peak_separation_mean": 20.334407609470418,
      "attention_bam_384_peak_intensity_mean": 0.42951151728630066,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1320408582687378,
      "attention_bam_16_std_attention": 0.5303163528442383,
      "attention_bam_16_max_attention": 2.1488773822784424,
      "attention_bam_16_min_attention": -0.9715796709060669,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.11663895137685909,
      "attention_bam_16_attention_skewness": 0.4685039927409068,
      "attention_bam_16_attention_sparsity": 0.505859375,
      "attention_bam_16_attention_concentration_10": 0.8714079000307443,
      "attention_bam_16_attention_concentration_20": 1.404416511129743,
      "attention_bam_16_attention_center_y": 0.4750228493444998,
      "attention_bam_16_attention_center_x": 0.4754997860549369,
      "attention_bam_16_attention_center_distance": 0.049479663261211025,
      "attention_bam_16_attention_spatial_variance": 43.06847642169636,
      "attention_bam_16_attention_spatial_std": 6.562657725471927,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.928608383457448,
      "attention_bam_16_peak_intensity_mean": 0.35936298966407776,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 854,
      "phase": "train",
      "loss": 0.004179367795586586,
      "timestamp": 1759544033.9105093,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004179367795586586,
      "ssim": 0.9295194745063782,
      "attention_bam_384_mean_attention": -0.027648696675896645,
      "attention_bam_384_std_attention": 0.16081862151622772,
      "attention_bam_384_max_attention": 0.9311394095420837,
      "attention_bam_384_min_attention": -0.7243620157241821,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5954838028914988,
      "attention_bam_384_attention_skewness": 0.20903932379831175,
      "attention_bam_384_attention_sparsity": 0.8022994995117188,
      "attention_bam_384_attention_concentration_10": -0.969157185106286,
      "attention_bam_384_attention_concentration_20": -1.4483451476348732,
      "attention_bam_384_attention_center_y": 0.48372192507725603,
      "attention_bam_384_attention_center_x": 0.4865347519940855,
      "attention_bam_384_attention_center_distance": 0.02987603143160918,
      "attention_bam_384_attention_spatial_variance": 170.78967317601683,
      "attention_bam_384_attention_spatial_std": 13.068652309095105,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 17.136412817743373,
      "attention_bam_384_peak_intensity_mean": 0.42410436272621155,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13529232144355774,
      "attention_bam_16_std_attention": 0.5329173803329468,
      "attention_bam_16_max_attention": 1.9809832572937012,
      "attention_bam_16_min_attention": -1.099374532699585,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.050342322176667675,
      "attention_bam_16_attention_skewness": 0.5034322770321403,
      "attention_bam_16_attention_sparsity": 0.52294921875,
      "attention_bam_16_attention_concentration_10": 0.8686837463554707,
      "attention_bam_16_attention_concentration_20": 1.3958902621686282,
      "attention_bam_16_attention_center_y": 0.4663471153401208,
      "attention_bam_16_attention_center_x": 0.47869898537694705,
      "attention_bam_16_attention_center_distance": 0.05632494775679154,
      "attention_bam_16_attention_spatial_variance": 42.46653833191044,
      "attention_bam_16_attention_spatial_std": 6.516635507062708,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 8.494960201699639,
      "attention_bam_16_peak_intensity_mean": 0.4019660949707031,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 855,
      "phase": "train",
      "loss": 0.006773404311388731,
      "timestamp": 1759544034.0688245,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006773404311388731,
      "ssim": 0.8987467885017395,
      "attention_bam_384_mean_attention": -0.028190458193421364,
      "attention_bam_384_std_attention": 0.1531778872013092,
      "attention_bam_384_max_attention": 1.1226146221160889,
      "attention_bam_384_min_attention": -0.7538142800331116,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0556210400750663,
      "attention_bam_384_attention_skewness": 0.2544050630309135,
      "attention_bam_384_attention_sparsity": 0.8191375732421875,
      "attention_bam_384_attention_concentration_10": -0.9004589736681035,
      "attention_bam_384_attention_concentration_20": -1.332133671654869,
      "attention_bam_384_attention_center_y": 0.48416250722662174,
      "attention_bam_384_attention_center_x": 0.4852824083609777,
      "attention_bam_384_attention_center_distance": 0.03057560076269403,
      "attention_bam_384_attention_spatial_variance": 170.84897613029304,
      "attention_bam_384_attention_spatial_std": 13.070921013084465,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 18.184268042336285,
      "attention_bam_384_peak_intensity_mean": 0.3881981670856476,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1407749503850937,
      "attention_bam_16_std_attention": 0.513563871383667,
      "attention_bam_16_max_attention": 2.487649440765381,
      "attention_bam_16_min_attention": -1.1016168594360352,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5459668454311144,
      "attention_bam_16_attention_skewness": 0.5924937126107489,
      "attention_bam_16_attention_sparsity": 0.508056640625,
      "attention_bam_16_attention_concentration_10": 0.812655686875431,
      "attention_bam_16_attention_concentration_20": 1.2917705020085064,
      "attention_bam_16_attention_center_y": 0.4696174754309088,
      "attention_bam_16_attention_center_x": 0.4712665527468633,
      "attention_bam_16_attention_center_distance": 0.059138968375179124,
      "attention_bam_16_attention_spatial_variance": 42.496427468605766,
      "attention_bam_16_attention_spatial_std": 6.51892839879422,
      "attention_bam_16_num_attention_peaks": 11,
      "attention_bam_16_peak_separation_mean": 9.535500795745177,
      "attention_bam_16_peak_intensity_mean": 0.3480971157550812,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 856,
      "phase": "train",
      "loss": 0.005102721508592367,
      "timestamp": 1759544034.2172961,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005102721508592367,
      "ssim": 0.9108449220657349,
      "attention_bam_384_mean_attention": -0.027297860011458397,
      "attention_bam_384_std_attention": 0.15522725880146027,
      "attention_bam_384_max_attention": 1.1976882219314575,
      "attention_bam_384_min_attention": -0.8468871712684631,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.3271024214893181,
      "attention_bam_384_attention_skewness": 0.23671244011878917,
      "attention_bam_384_attention_sparsity": 0.8191045125325521,
      "attention_bam_384_attention_concentration_10": -0.9404405376128825,
      "attention_bam_384_attention_concentration_20": -1.382795178488074,
      "attention_bam_384_attention_center_y": 0.4844826423906896,
      "attention_bam_384_attention_center_x": 0.4832572271140605,
      "attention_bam_384_attention_center_distance": 0.03228339607554862,
      "attention_bam_384_attention_spatial_variance": 170.3504944725968,
      "attention_bam_384_attention_spatial_std": 13.05183873914311,
      "attention_bam_384_num_attention_peaks": 22,
      "attention_bam_384_peak_separation_mean": 19.15813986500107,
      "attention_bam_384_peak_intensity_mean": 0.4032347500324249,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13544797897338867,
      "attention_bam_16_std_attention": 0.510236382484436,
      "attention_bam_16_max_attention": 2.822279930114746,
      "attention_bam_16_min_attention": -1.0999822616577148,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7737327277513977,
      "attention_bam_16_attention_skewness": 0.6245585547631104,
      "attention_bam_16_attention_sparsity": 0.506591796875,
      "attention_bam_16_attention_concentration_10": 0.8304519591126651,
      "attention_bam_16_attention_concentration_20": 1.3227888304843334,
      "attention_bam_16_attention_center_y": 0.46849714374443346,
      "attention_bam_16_attention_center_x": 0.4610075990745313,
      "attention_bam_16_attention_center_distance": 0.07089199224441894,
      "attention_bam_16_attention_spatial_variance": 42.284979143601994,
      "attention_bam_16_attention_spatial_std": 6.502690146670222,
      "attention_bam_16_num_attention_peaks": 12,
      "attention_bam_16_peak_separation_mean": 8.406713365174465,
      "attention_bam_16_peak_intensity_mean": 0.32159659266471863,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 857,
      "phase": "train",
      "loss": 0.00809604860842228,
      "timestamp": 1759544034.3592868,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00809604860842228,
      "ssim": 0.8950771689414978,
      "attention_bam_384_mean_attention": -0.027013428509235382,
      "attention_bam_384_std_attention": 0.15793178975582123,
      "attention_bam_384_max_attention": 1.0070279836654663,
      "attention_bam_384_min_attention": -0.7651218175888062,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7532491474645155,
      "attention_bam_384_attention_skewness": 0.21750989072100474,
      "attention_bam_384_attention_sparsity": 0.8068135579427084,
      "attention_bam_384_attention_concentration_10": -0.9699497372594678,
      "attention_bam_384_attention_concentration_20": -1.4434265820236973,
      "attention_bam_384_attention_center_y": 0.4840427284913111,
      "attention_bam_384_attention_center_x": 0.4877470478473521,
      "attention_bam_384_attention_center_distance": 0.02845239358848719,
      "attention_bam_384_attention_spatial_variance": 169.60064661433722,
      "attention_bam_384_attention_spatial_std": 13.023081302607967,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 17.145867217062733,
      "attention_bam_384_peak_intensity_mean": 0.41817787289619446,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13919582962989807,
      "attention_bam_16_std_attention": 0.5168118476867676,
      "attention_bam_16_max_attention": 2.521152973175049,
      "attention_bam_16_min_attention": -0.9704236388206482,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.06069193235006676,
      "attention_bam_16_attention_skewness": 0.5363512031670628,
      "attention_bam_16_attention_sparsity": 0.50390625,
      "attention_bam_16_attention_concentration_10": 0.8203773382373314,
      "attention_bam_16_attention_concentration_20": 1.3198687887523428,
      "attention_bam_16_attention_center_y": 0.4639809946288185,
      "attention_bam_16_attention_center_x": 0.4896149488574271,
      "attention_bam_16_attention_center_distance": 0.05301354610216256,
      "attention_bam_16_attention_spatial_variance": 41.15593545853035,
      "attention_bam_16_attention_spatial_std": 6.415289195237449,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.002222124249002,
      "attention_bam_16_peak_intensity_mean": 0.3206031918525696,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 858,
      "phase": "train",
      "loss": 0.003986881580203772,
      "timestamp": 1759544034.495536,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.003986881580203772,
      "ssim": 0.9183352589607239,
      "attention_bam_384_mean_attention": -0.028109950944781303,
      "attention_bam_384_std_attention": 0.14452876150608063,
      "attention_bam_384_max_attention": 0.8926713466644287,
      "attention_bam_384_min_attention": -0.6329951286315918,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6037846421173287,
      "attention_bam_384_attention_skewness": 0.20011131684130817,
      "attention_bam_384_attention_sparsity": 0.8251215616861979,
      "attention_bam_384_attention_concentration_10": -0.8358255082080275,
      "attention_bam_384_attention_concentration_20": -1.2489711368797491,
      "attention_bam_384_attention_center_y": 0.4860469289519264,
      "attention_bam_384_attention_center_x": 0.48174018942079533,
      "attention_bam_384_attention_center_distance": 0.03249950381347457,
      "attention_bam_384_attention_spatial_variance": 170.95390542317892,
      "attention_bam_384_attention_spatial_std": 13.074934241638806,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 18.433759739532377,
      "attention_bam_384_peak_intensity_mean": 0.4014759957790375,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13719728589057922,
      "attention_bam_16_std_attention": 0.48817867040634155,
      "attention_bam_16_max_attention": 2.4349112510681152,
      "attention_bam_16_min_attention": -0.9994415640830994,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.24827021086069134,
      "attention_bam_16_attention_skewness": 0.5451179544373653,
      "attention_bam_16_attention_sparsity": 0.502197265625,
      "attention_bam_16_attention_concentration_10": 0.7903360256459826,
      "attention_bam_16_attention_concentration_20": 1.2678575811583335,
      "attention_bam_16_attention_center_y": 0.476055218655645,
      "attention_bam_16_attention_center_x": 0.4587828739851029,
      "attention_bam_16_attention_center_distance": 0.06741222486399447,
      "attention_bam_16_attention_spatial_variance": 42.57423467992651,
      "attention_bam_16_attention_spatial_std": 6.524893461193563,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.434552763176832,
      "attention_bam_16_peak_intensity_mean": 0.33438509702682495,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 859,
      "phase": "train",
      "loss": 0.003403590526431799,
      "timestamp": 1759544034.6495008,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.003403590526431799,
      "ssim": 0.9464176893234253,
      "attention_bam_384_mean_attention": -0.027313029393553734,
      "attention_bam_384_std_attention": 0.16154362261295319,
      "attention_bam_384_max_attention": 1.035099983215332,
      "attention_bam_384_min_attention": -0.7200515270233154,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.948300880461622,
      "attention_bam_384_attention_skewness": 0.29506494156897867,
      "attention_bam_384_attention_sparsity": 0.8072535196940104,
      "attention_bam_384_attention_concentration_10": -1.0023944145309824,
      "attention_bam_384_attention_concentration_20": -1.479494853369516,
      "attention_bam_384_attention_center_y": 0.4838205572909381,
      "attention_bam_384_attention_center_x": 0.4834817789881214,
      "attention_bam_384_attention_center_distance": 0.03269941870349027,
      "attention_bam_384_attention_spatial_variance": 170.42218149917153,
      "attention_bam_384_attention_spatial_std": 13.054584692711275,
      "attention_bam_384_num_attention_peaks": 19,
      "attention_bam_384_peak_separation_mean": 18.921090621668235,
      "attention_bam_384_peak_intensity_mean": 0.398200124502182,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1359795331954956,
      "attention_bam_16_std_attention": 0.5273469686508179,
      "attention_bam_16_max_attention": 2.275866985321045,
      "attention_bam_16_min_attention": -1.0297750234603882,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.32506341343414835,
      "attention_bam_16_attention_skewness": 0.6336949361693174,
      "attention_bam_16_attention_sparsity": 0.518798828125,
      "attention_bam_16_attention_concentration_10": 0.8739585698361251,
      "attention_bam_16_attention_concentration_20": 1.3888821920729282,
      "attention_bam_16_attention_center_y": 0.46831982149636736,
      "attention_bam_16_attention_center_x": 0.46732877525958866,
      "attention_bam_16_attention_center_distance": 0.06435903411426391,
      "attention_bam_16_attention_spatial_variance": 42.17138703030311,
      "attention_bam_16_attention_spatial_std": 6.4939500329385895,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.702004819525596,
      "attention_bam_16_peak_intensity_mean": 0.3631874918937683,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 860,
      "phase": "train",
      "loss": 0.003080350812524557,
      "timestamp": 1759544034.8844745,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.003080350812524557,
      "ssim": 0.9473751783370972,
      "attention_bam_384_mean_attention": -0.028727645054459572,
      "attention_bam_384_std_attention": 0.1542583853006363,
      "attention_bam_384_max_attention": 1.0403493642807007,
      "attention_bam_384_min_attention": -0.781341552734375,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6236116791875275,
      "attention_bam_384_attention_skewness": 0.17782116350074512,
      "attention_bam_384_attention_sparsity": 0.8064448038736979,
      "attention_bam_384_attention_concentration_10": -0.8643675720432112,
      "attention_bam_384_attention_concentration_20": -1.304525835724996,
      "attention_bam_384_attention_center_y": 0.4797255448877038,
      "attention_bam_384_attention_center_x": 0.48545097584782865,
      "attention_bam_384_attention_center_distance": 0.035291008313194414,
      "attention_bam_384_attention_spatial_variance": 171.46538884465005,
      "attention_bam_384_attention_spatial_std": 13.09447932697784,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 20.137130712401277,
      "attention_bam_384_peak_intensity_mean": 0.4202364683151245,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14184615015983582,
      "attention_bam_16_std_attention": 0.505545437335968,
      "attention_bam_16_max_attention": 2.7141690254211426,
      "attention_bam_16_min_attention": -1.0589720010757446,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.18942319922405115,
      "attention_bam_16_attention_skewness": 0.5040894465495276,
      "attention_bam_16_attention_sparsity": 0.50439453125,
      "attention_bam_16_attention_concentration_10": 0.7894106228434922,
      "attention_bam_16_attention_concentration_20": 1.2678266741273185,
      "attention_bam_16_attention_center_y": 0.44883293493478793,
      "attention_bam_16_attention_center_x": 0.47393121069868266,
      "attention_bam_16_attention_center_distance": 0.08121145637191987,
      "attention_bam_16_attention_spatial_variance": 43.28397180585124,
      "attention_bam_16_attention_spatial_std": 6.579055540565928,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 10.382536126250068,
      "attention_bam_16_peak_intensity_mean": 0.32878750562667847,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 861,
      "phase": "train",
      "loss": 0.0043760123662650585,
      "timestamp": 1759544035.091865,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0043760123662650585,
      "ssim": 0.9376363754272461,
      "attention_bam_384_mean_attention": -0.029658248648047447,
      "attention_bam_384_std_attention": 0.16669508814811707,
      "attention_bam_384_max_attention": 1.2223827838897705,
      "attention_bam_384_min_attention": -0.7873760461807251,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.7338603246636284,
      "attention_bam_384_attention_skewness": 0.5301990542169052,
      "attention_bam_384_attention_sparsity": 0.8170344034830729,
      "attention_bam_384_attention_concentration_10": -0.9824355877773501,
      "attention_bam_384_attention_concentration_20": -1.4018332626037102,
      "attention_bam_384_attention_center_y": 0.4869018959620497,
      "attention_bam_384_attention_center_x": 0.48787755033566016,
      "attention_bam_384_attention_center_distance": 0.025239418188754796,
      "attention_bam_384_attention_spatial_variance": 171.51901601582807,
      "attention_bam_384_attention_spatial_std": 13.096526868442185,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 17.61186741916099,
      "attention_bam_384_peak_intensity_mean": 0.3811459243297577,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12668250501155853,
      "attention_bam_16_std_attention": 0.5672085881233215,
      "attention_bam_16_max_attention": 2.8966634273529053,
      "attention_bam_16_min_attention": -1.1160370111465454,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.764094888013413,
      "attention_bam_16_attention_skewness": 1.0644467855311666,
      "attention_bam_16_attention_sparsity": 0.5478515625,
      "attention_bam_16_attention_concentration_10": 1.051159680973221,
      "attention_bam_16_attention_concentration_20": 1.57977886066492,
      "attention_bam_16_attention_center_y": 0.4791651487483113,
      "attention_bam_16_attention_center_x": 0.4883151129906598,
      "attention_bam_16_attention_center_distance": 0.03378246915490463,
      "attention_bam_16_attention_spatial_variance": 43.28244787592389,
      "attention_bam_16_attention_spatial_std": 6.578939722776299,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 8.42980694344556,
      "attention_bam_16_peak_intensity_mean": 0.3115457594394684,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 862,
      "phase": "train",
      "loss": 0.006579297594726086,
      "timestamp": 1759544035.289247,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006579297594726086,
      "ssim": 0.9181908965110779,
      "attention_bam_384_mean_attention": -0.02763088047504425,
      "attention_bam_384_std_attention": 0.15670046210289001,
      "attention_bam_384_max_attention": 1.2205432653427124,
      "attention_bam_384_min_attention": -0.7547991871833801,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1617859787606513,
      "attention_bam_384_attention_skewness": 0.32602426768859477,
      "attention_bam_384_attention_sparsity": 0.8194122314453125,
      "attention_bam_384_attention_concentration_10": -0.9661442168573784,
      "attention_bam_384_attention_concentration_20": -1.4078257096085085,
      "attention_bam_384_attention_center_y": 0.48368257318868535,
      "attention_bam_384_attention_center_x": 0.48202481958752025,
      "attention_bam_384_attention_center_distance": 0.03433265292993846,
      "attention_bam_384_attention_spatial_variance": 171.58837647580305,
      "attention_bam_384_attention_spatial_std": 13.099174648648786,
      "attention_bam_384_num_attention_peaks": 21,
      "attention_bam_384_peak_separation_mean": 17.58607567101063,
      "attention_bam_384_peak_intensity_mean": 0.37138476967811584,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13551494479179382,
      "attention_bam_16_std_attention": 0.515143871307373,
      "attention_bam_16_max_attention": 2.396792411804199,
      "attention_bam_16_min_attention": -1.0361008644104004,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5604783863856833,
      "attention_bam_16_attention_skewness": 0.6596949530836421,
      "attention_bam_16_attention_sparsity": 0.521728515625,
      "attention_bam_16_attention_concentration_10": 0.8570624374313252,
      "attention_bam_16_attention_concentration_20": 1.3504250045994697,
      "attention_bam_16_attention_center_y": 0.46547007470068463,
      "attention_bam_16_attention_center_x": 0.4586573904955768,
      "attention_bam_16_attention_center_distance": 0.07617778024872505,
      "attention_bam_16_attention_spatial_variance": 43.437744788063945,
      "attention_bam_16_attention_spatial_std": 6.590731733886909,
      "attention_bam_16_num_attention_peaks": 11,
      "attention_bam_16_peak_separation_mean": 8.735502834362608,
      "attention_bam_16_peak_intensity_mean": 0.34688690304756165,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 863,
      "phase": "train",
      "loss": 0.006667142268270254,
      "timestamp": 1759544035.4885902,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006667142268270254,
      "ssim": 0.9184110760688782,
      "attention_bam_384_mean_attention": -0.027885695919394493,
      "attention_bam_384_std_attention": 0.15169531106948853,
      "attention_bam_384_max_attention": 0.9098672866821289,
      "attention_bam_384_min_attention": -0.7068353295326233,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7218141534739004,
      "attention_bam_384_attention_skewness": 0.24978083419486155,
      "attention_bam_384_attention_sparsity": 0.8175582885742188,
      "attention_bam_384_attention_concentration_10": -0.9073680490598807,
      "attention_bam_384_attention_concentration_20": -1.3448919619287338,
      "attention_bam_384_attention_center_y": 0.48476312454590326,
      "attention_bam_384_attention_center_x": 0.4865927041419611,
      "attention_bam_384_attention_center_distance": 0.028702541902369656,
      "attention_bam_384_attention_spatial_variance": 172.4796336440854,
      "attention_bam_384_attention_spatial_std": 13.133150179758298,
      "attention_bam_384_num_attention_peaks": 20,
      "attention_bam_384_peak_separation_mean": 19.743602797068217,
      "attention_bam_384_peak_intensity_mean": 0.42863598465919495,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13275454938411713,
      "attention_bam_16_std_attention": 0.5035411715507507,
      "attention_bam_16_max_attention": 2.3018734455108643,
      "attention_bam_16_min_attention": -1.0582016706466675,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.17514959785856732,
      "attention_bam_16_attention_skewness": 0.5555531346840644,
      "attention_bam_16_attention_sparsity": 0.5205078125,
      "attention_bam_16_attention_concentration_10": 0.8387367413520476,
      "attention_bam_16_attention_concentration_20": 1.3441279145677827,
      "attention_bam_16_attention_center_y": 0.47016637899813374,
      "attention_bam_16_attention_center_x": 0.4797134523559958,
      "attention_bam_16_attention_center_distance": 0.05102134763793385,
      "attention_bam_16_attention_spatial_variance": 44.186783431398226,
      "attention_bam_16_attention_spatial_std": 6.647314001263836,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 9.943082228058357,
      "attention_bam_16_peak_intensity_mean": 0.36397653818130493,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 864,
      "phase": "train",
      "loss": 0.005605315323919058,
      "timestamp": 1759544035.6875393,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005605315323919058,
      "ssim": 0.8779645562171936,
      "attention_bam_384_mean_attention": -0.027873774990439415,
      "attention_bam_384_std_attention": 0.1627577245235443,
      "attention_bam_384_max_attention": 1.2338979244232178,
      "attention_bam_384_min_attention": -0.6997532844543457,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.36769320487363366,
      "attention_bam_384_attention_skewness": 0.20749102578954662,
      "attention_bam_384_attention_sparsity": 0.7873636881510416,
      "attention_bam_384_attention_concentration_10": -0.9551327468961259,
      "attention_bam_384_attention_concentration_20": -1.4570163008510493,
      "attention_bam_384_attention_center_y": 0.4817034586801809,
      "attention_bam_384_attention_center_x": 0.48452488547708866,
      "attention_bam_384_attention_center_distance": 0.033889307864430326,
      "attention_bam_384_attention_spatial_variance": 171.5955508479986,
      "attention_bam_384_attention_spatial_std": 13.099448494039686,
      "attention_bam_384_num_attention_peaks": 19,
      "attention_bam_384_peak_separation_mean": 18.033980254171233,
      "attention_bam_384_peak_intensity_mean": 0.35555803775787354,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13690167665481567,
      "attention_bam_16_std_attention": 0.5340965390205383,
      "attention_bam_16_max_attention": 2.5330862998962402,
      "attention_bam_16_min_attention": -1.0781185626983643,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.28214284851947635,
      "attention_bam_16_attention_skewness": 0.6030380141534274,
      "attention_bam_16_attention_sparsity": 0.521484375,
      "attention_bam_16_attention_concentration_10": 0.8539257820085967,
      "attention_bam_16_attention_concentration_20": 1.3792185878633139,
      "attention_bam_16_attention_center_y": 0.4583684394945834,
      "attention_bam_16_attention_center_x": 0.4709453936450055,
      "attention_bam_16_attention_center_distance": 0.07179633668314633,
      "attention_bam_16_attention_spatial_variance": 43.29705722797801,
      "attention_bam_16_attention_spatial_std": 6.580049941146192,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.254704528673846,
      "attention_bam_16_peak_intensity_mean": 0.35675954818725586,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 865,
      "phase": "train",
      "loss": 0.006044426001608372,
      "timestamp": 1759544035.874645,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006044426001608372,
      "ssim": 0.9194853901863098,
      "attention_bam_384_mean_attention": -0.02748788706958294,
      "attention_bam_384_std_attention": 0.14597804844379425,
      "attention_bam_384_max_attention": 0.9858529567718506,
      "attention_bam_384_min_attention": -0.7755978107452393,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.115942696757208,
      "attention_bam_384_attention_skewness": 0.24069509427569397,
      "attention_bam_384_attention_sparsity": 0.8311513264973959,
      "attention_bam_384_attention_concentration_10": -0.8790366174463786,
      "attention_bam_384_attention_concentration_20": -1.2893312619132582,
      "attention_bam_384_attention_center_y": 0.4864120386761328,
      "attention_bam_384_attention_center_x": 0.4864965300717179,
      "attention_bam_384_attention_center_distance": 0.027091563005590128,
      "attention_bam_384_attention_spatial_variance": 169.84906183812123,
      "attention_bam_384_attention_spatial_std": 13.032615310754831,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 16.08258542883957,
      "attention_bam_384_peak_intensity_mean": 0.4276927411556244,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1394733190536499,
      "attention_bam_16_std_attention": 0.497999370098114,
      "attention_bam_16_max_attention": 2.4725821018218994,
      "attention_bam_16_min_attention": -0.9954967498779297,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.3171179762863585,
      "attention_bam_16_attention_skewness": 0.5495633364729715,
      "attention_bam_16_attention_sparsity": 0.505615234375,
      "attention_bam_16_attention_concentration_10": 0.7938762353630778,
      "attention_bam_16_attention_concentration_20": 1.268877560155808,
      "attention_bam_16_attention_center_y": 0.4794476769197448,
      "attention_bam_16_attention_center_x": 0.4823470904435975,
      "attention_bam_16_attention_center_distance": 0.03831509362644741,
      "attention_bam_16_attention_spatial_variance": 41.13311541777863,
      "attention_bam_16_attention_spatial_std": 6.413510381825123,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 7.352676949291868,
      "attention_bam_16_peak_intensity_mean": 0.33785519003868103,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 866,
      "phase": "train",
      "loss": 0.0034089419059455395,
      "timestamp": 1759544036.050177,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0034089419059455395,
      "ssim": 0.9496456384658813,
      "attention_bam_384_mean_attention": -0.026717133820056915,
      "attention_bam_384_std_attention": 0.15786686539649963,
      "attention_bam_384_max_attention": 1.0614490509033203,
      "attention_bam_384_min_attention": -0.7317648530006409,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.4896416179829375,
      "attention_bam_384_attention_skewness": 0.14224659053115277,
      "attention_bam_384_attention_sparsity": 0.800018310546875,
      "attention_bam_384_attention_concentration_10": -0.9616938094528831,
      "attention_bam_384_attention_concentration_20": -1.450410351098391,
      "attention_bam_384_attention_center_y": 0.48454770235368355,
      "attention_bam_384_attention_center_x": 0.48148106113877825,
      "attention_bam_384_attention_center_distance": 0.03410937111985578,
      "attention_bam_384_attention_spatial_variance": 171.0262224135719,
      "attention_bam_384_attention_spatial_std": 13.077699431229176,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 19.039362208306667,
      "attention_bam_384_peak_intensity_mean": 0.3965132534503937,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1413774937391281,
      "attention_bam_16_std_attention": 0.5236561894416809,
      "attention_bam_16_max_attention": 2.300825595855713,
      "attention_bam_16_min_attention": -0.9896365404129028,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.11568771329883809,
      "attention_bam_16_attention_skewness": 0.45253822326755894,
      "attention_bam_16_attention_sparsity": 0.501953125,
      "attention_bam_16_attention_concentration_10": 0.803120371946282,
      "attention_bam_16_attention_concentration_20": 1.3105581204373373,
      "attention_bam_16_attention_center_y": 0.4696284031166865,
      "attention_bam_16_attention_center_x": 0.4540605987024367,
      "attention_bam_16_attention_center_distance": 0.07788276431690208,
      "attention_bam_16_attention_spatial_variance": 42.866686285010964,
      "attention_bam_16_attention_spatial_std": 6.54726555785016,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 8.465821861596648,
      "attention_bam_16_peak_intensity_mean": 0.35128334164619446,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 867,
      "phase": "train",
      "loss": 0.004273413680493832,
      "timestamp": 1759544036.2172232,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004273413680493832,
      "ssim": 0.9062476754188538,
      "attention_bam_384_mean_attention": -0.027875671163201332,
      "attention_bam_384_std_attention": 0.1463214010000229,
      "attention_bam_384_max_attention": 1.2026822566986084,
      "attention_bam_384_min_attention": -0.7186789512634277,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.244270565809086,
      "attention_bam_384_attention_skewness": 0.32484193333991124,
      "attention_bam_384_attention_sparsity": 0.8291829427083334,
      "attention_bam_384_attention_concentration_10": -0.8715444839510499,
      "attention_bam_384_attention_concentration_20": -1.281516109616904,
      "attention_bam_384_attention_center_y": 0.48201497349749883,
      "attention_bam_384_attention_center_x": 0.4838369222592809,
      "attention_bam_384_attention_center_distance": 0.03419667411746936,
      "attention_bam_384_attention_spatial_variance": 171.45519827158466,
      "attention_bam_384_attention_spatial_std": 13.094090204041848,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 19.246270613612396,
      "attention_bam_384_peak_intensity_mean": 0.3628392815589905,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.140181764960289,
      "attention_bam_16_std_attention": 0.4945553243160248,
      "attention_bam_16_max_attention": 2.8463292121887207,
      "attention_bam_16_min_attention": -1.1105985641479492,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.996726130706675,
      "attention_bam_16_attention_skewness": 0.7313963191471049,
      "attention_bam_16_attention_sparsity": 0.512939453125,
      "attention_bam_16_attention_concentration_10": 0.7984438697789252,
      "attention_bam_16_attention_concentration_20": 1.2670588669022893,
      "attention_bam_16_attention_center_y": 0.4605615997699042,
      "attention_bam_16_attention_center_x": 0.46705211485005865,
      "attention_bam_16_attention_center_distance": 0.0726766888150932,
      "attention_bam_16_attention_spatial_variance": 42.95738343132441,
      "attention_bam_16_attention_spatial_std": 6.554188235878216,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 9.184117325501026,
      "attention_bam_16_peak_intensity_mean": 0.31777113676071167,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 868,
      "phase": "train",
      "loss": 0.003906484693288803,
      "timestamp": 1759544036.388436,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.003906484693288803,
      "ssim": 0.9367849826812744,
      "attention_bam_384_mean_attention": -0.026460574939846992,
      "attention_bam_384_std_attention": 0.13644324243068695,
      "attention_bam_384_max_attention": 0.8413354754447937,
      "attention_bam_384_min_attention": -0.6531692743301392,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7435136062237166,
      "attention_bam_384_attention_skewness": 0.10710062781281869,
      "attention_bam_384_attention_sparsity": 0.8391342163085938,
      "attention_bam_384_attention_concentration_10": -0.8245576607308078,
      "attention_bam_384_attention_concentration_20": -1.2306465805096753,
      "attention_bam_384_attention_center_y": 0.48334947063471284,
      "attention_bam_384_attention_center_x": 0.48453702476529387,
      "attention_bam_384_attention_center_distance": 0.032135454913644064,
      "attention_bam_384_attention_spatial_variance": 169.6411137151773,
      "attention_bam_384_attention_spatial_std": 13.024634878382477,
      "attention_bam_384_num_attention_peaks": 19,
      "attention_bam_384_peak_separation_mean": 17.171550400851952,
      "attention_bam_384_peak_intensity_mean": 0.42349281907081604,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1400688886642456,
      "attention_bam_16_std_attention": 0.46103018522262573,
      "attention_bam_16_max_attention": 1.753505825996399,
      "attention_bam_16_min_attention": -0.9663912057876587,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.09680190322378168,
      "attention_bam_16_attention_skewness": 0.3937693370082062,
      "attention_bam_16_attention_sparsity": 0.495849609375,
      "attention_bam_16_attention_concentration_10": 0.7270778598372142,
      "attention_bam_16_attention_concentration_20": 1.180100903566972,
      "attention_bam_16_attention_center_y": 0.465668190130449,
      "attention_bam_16_attention_center_x": 0.4719114591610337,
      "attention_bam_16_attention_center_distance": 0.06273179888033299,
      "attention_bam_16_attention_spatial_variance": 41.244880715410844,
      "attention_bam_16_attention_spatial_std": 6.422217741202088,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 7.352569446538597,
      "attention_bam_16_peak_intensity_mean": 0.4168003797531128,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 869,
      "phase": "train",
      "loss": 0.004875440616160631,
      "timestamp": 1759544036.5615108,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004875440616160631,
      "ssim": 0.9013392925262451,
      "attention_bam_384_mean_attention": -0.026122422888875008,
      "attention_bam_384_std_attention": 0.16314588487148285,
      "attention_bam_384_max_attention": 0.8940385580062866,
      "attention_bam_384_min_attention": -0.7325430512428284,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5117999440692165,
      "attention_bam_384_attention_skewness": 0.2254499614886939,
      "attention_bam_384_attention_sparsity": 0.7968826293945312,
      "attention_bam_384_attention_concentration_10": -1.0546666531040019,
      "attention_bam_384_attention_concentration_20": -1.5758885224277834,
      "attention_bam_384_attention_center_y": 0.4831675053526161,
      "attention_bam_384_attention_center_x": 0.48586204441597386,
      "attention_bam_384_attention_center_distance": 0.03108744647442448,
      "attention_bam_384_attention_spatial_variance": 170.8384154711806,
      "attention_bam_384_attention_spatial_std": 13.070517031517177,
      "attention_bam_384_num_attention_peaks": 21,
      "attention_bam_384_peak_separation_mean": 17.734952208841204,
      "attention_bam_384_peak_intensity_mean": 0.4392361342906952,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12291672080755234,
      "attention_bam_16_std_attention": 0.5343384742736816,
      "attention_bam_16_max_attention": 2.6350884437561035,
      "attention_bam_16_min_attention": -1.0543426275253296,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.4371550708848013,
      "attention_bam_16_attention_skewness": 0.6416832652550659,
      "attention_bam_16_attention_sparsity": 0.527587890625,
      "attention_bam_16_attention_concentration_10": 0.9612126682697498,
      "attention_bam_16_attention_concentration_20": 1.5176272576993581,
      "attention_bam_16_attention_center_y": 0.46483219484254135,
      "attention_bam_16_attention_center_x": 0.47501335445106807,
      "attention_bam_16_attention_center_distance": 0.061009949604649484,
      "attention_bam_16_attention_spatial_variance": 42.54842359404889,
      "attention_bam_16_attention_spatial_std": 6.522915268041499,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 9.33447911167752,
      "attention_bam_16_peak_intensity_mean": 0.32644596695899963,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 870,
      "phase": "train",
      "loss": 0.0040979692712426186,
      "timestamp": 1759544036.7700765,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0040979692712426186,
      "ssim": 0.9188113808631897,
      "attention_bam_384_mean_attention": -0.02707086317241192,
      "attention_bam_384_std_attention": 0.13171276450157166,
      "attention_bam_384_max_attention": 0.9401916265487671,
      "attention_bam_384_min_attention": -0.7389818429946899,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7809154519589132,
      "attention_bam_384_attention_skewness": 0.18580540551668195,
      "attention_bam_384_attention_sparsity": 0.8466033935546875,
      "attention_bam_384_attention_concentration_10": -0.7837432612290715,
      "attention_bam_384_attention_concentration_20": -1.1643819467397178,
      "attention_bam_384_attention_center_y": 0.4863427810883052,
      "attention_bam_384_attention_center_x": 0.4839513974782628,
      "attention_bam_384_attention_center_distance": 0.02980192179382608,
      "attention_bam_384_attention_spatial_variance": 171.9277325606468,
      "attention_bam_384_attention_spatial_std": 13.112121588844683,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 21.546007733952564,
      "attention_bam_384_peak_intensity_mean": 0.42974168062210083,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14295481145381927,
      "attention_bam_16_std_attention": 0.4607703983783722,
      "attention_bam_16_max_attention": 2.1899847984313965,
      "attention_bam_16_min_attention": -0.9659393429756165,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.14410573135882165,
      "attention_bam_16_attention_skewness": 0.5258937520355026,
      "attention_bam_16_attention_sparsity": 0.503662109375,
      "attention_bam_16_attention_concentration_10": 0.7281258680851953,
      "attention_bam_16_attention_concentration_20": 1.172057640880861,
      "attention_bam_16_attention_center_y": 0.4818904306741038,
      "attention_bam_16_attention_center_x": 0.4674971142675853,
      "attention_bam_16_attention_center_distance": 0.052619275595618915,
      "attention_bam_16_attention_spatial_variance": 43.89746212427094,
      "attention_bam_16_attention_spatial_std": 6.625515989284981,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 10.225631441361774,
      "attention_bam_16_peak_intensity_mean": 0.3690645396709442,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 871,
      "phase": "train",
      "loss": 0.0048356493934988976,
      "timestamp": 1759544036.9420154,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0048356493934988976,
      "ssim": 0.8983359336853027,
      "attention_bam_384_mean_attention": -0.02636115811765194,
      "attention_bam_384_std_attention": 0.14765556156635284,
      "attention_bam_384_max_attention": 0.9734320640563965,
      "attention_bam_384_min_attention": -0.7328991889953613,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1461855651352835,
      "attention_bam_384_attention_skewness": 0.3531655842877652,
      "attention_bam_384_attention_sparsity": 0.8244654337565104,
      "attention_bam_384_attention_concentration_10": -0.9428985367439996,
      "attention_bam_384_attention_concentration_20": -1.3854222997366774,
      "attention_bam_384_attention_center_y": 0.4821845735589172,
      "attention_bam_384_attention_center_x": 0.48143480831554947,
      "attention_bam_384_attention_center_distance": 0.03638834323126084,
      "attention_bam_384_attention_spatial_variance": 171.3767805598665,
      "attention_bam_384_attention_spatial_std": 13.091095468289371,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 17.43166570038418,
      "attention_bam_384_peak_intensity_mean": 0.41959887742996216,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12861493229866028,
      "attention_bam_16_std_attention": 0.5005175471305847,
      "attention_bam_16_max_attention": 2.7126147747039795,
      "attention_bam_16_min_attention": -1.0350611209869385,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.3658635444926781,
      "attention_bam_16_attention_skewness": 0.6476982948429572,
      "attention_bam_16_attention_sparsity": 0.523681640625,
      "attention_bam_16_attention_concentration_10": 0.8758258119618223,
      "attention_bam_16_attention_concentration_20": 1.389364308675937,
      "attention_bam_16_attention_center_y": 0.46260720566625346,
      "attention_bam_16_attention_center_x": 0.4580555834932503,
      "attention_bam_16_attention_center_distance": 0.07946766819502837,
      "attention_bam_16_attention_spatial_variance": 43.10821167573036,
      "attention_bam_16_attention_spatial_std": 6.565684402690276,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 8.639352976354626,
      "attention_bam_16_peak_intensity_mean": 0.31889984011650085,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 872,
      "phase": "train",
      "loss": 0.007949251681566238,
      "timestamp": 1759544037.1011581,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007949251681566238,
      "ssim": 0.9191668033599854,
      "attention_bam_384_mean_attention": -0.026542305946350098,
      "attention_bam_384_std_attention": 0.13771840929985046,
      "attention_bam_384_max_attention": 1.0238535404205322,
      "attention_bam_384_min_attention": -0.6771551370620728,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1580359242961746,
      "attention_bam_384_attention_skewness": 0.385509203875848,
      "attention_bam_384_attention_sparsity": 0.83660888671875,
      "attention_bam_384_attention_concentration_10": -0.8704280502254736,
      "attention_bam_384_attention_concentration_20": -1.2823140155321222,
      "attention_bam_384_attention_center_y": 0.48695180759287177,
      "attention_bam_384_attention_center_x": 0.48297983249080034,
      "attention_bam_384_attention_center_distance": 0.03032957062454576,
      "attention_bam_384_attention_spatial_variance": 171.4905113549004,
      "attention_bam_384_attention_spatial_std": 13.09543857054434,
      "attention_bam_384_num_attention_peaks": 19,
      "attention_bam_384_peak_separation_mean": 17.6739091813961,
      "attention_bam_384_peak_intensity_mean": 0.3866145610809326,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13362683355808258,
      "attention_bam_16_std_attention": 0.4786965847015381,
      "attention_bam_16_max_attention": 2.1579113006591797,
      "attention_bam_16_min_attention": -0.9495446681976318,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.33434979634503126,
      "attention_bam_16_attention_skewness": 0.6240183099286777,
      "attention_bam_16_attention_sparsity": 0.521240234375,
      "attention_bam_16_attention_concentration_10": 0.7982703181159627,
      "attention_bam_16_attention_concentration_20": 1.2852317997611864,
      "attention_bam_16_attention_center_y": 0.48026428379123076,
      "attention_bam_16_attention_center_x": 0.4628416106888322,
      "attention_bam_16_attention_center_distance": 0.0595020065287447,
      "attention_bam_16_attention_spatial_variance": 43.33249223818024,
      "attention_bam_16_attention_spatial_std": 6.5827419999708505,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.749084763923136,
      "attention_bam_16_peak_intensity_mean": 0.36041495203971863,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 873,
      "phase": "train",
      "loss": 0.0065803430043160915,
      "timestamp": 1759544037.2565238,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0065803430043160915,
      "ssim": 0.892234206199646,
      "attention_bam_384_mean_attention": -0.02501978911459446,
      "attention_bam_384_std_attention": 0.1372119039297104,
      "attention_bam_384_max_attention": 0.9493507146835327,
      "attention_bam_384_min_attention": -0.7084940671920776,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.485042846659054,
      "attention_bam_384_attention_skewness": 0.2622875184347143,
      "attention_bam_384_attention_sparsity": 0.8494542439778646,
      "attention_bam_384_attention_concentration_10": -0.925702217664147,
      "attention_bam_384_attention_concentration_20": -1.3339007839567243,
      "attention_bam_384_attention_center_y": 0.4859742173746807,
      "attention_bam_384_attention_center_x": 0.4834919878797761,
      "attention_bam_384_attention_center_distance": 0.030634524393702196,
      "attention_bam_384_attention_spatial_variance": 171.61139695384622,
      "attention_bam_384_attention_spatial_std": 13.100053318740585,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 19.85986225464737,
      "attention_bam_384_peak_intensity_mean": 0.41912150382995605,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1416681855916977,
      "attention_bam_16_std_attention": 0.4737200140953064,
      "attention_bam_16_max_attention": 2.23726224899292,
      "attention_bam_16_min_attention": -1.0370769500732422,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6455020510954648,
      "attention_bam_16_attention_skewness": 0.6237132306407004,
      "attention_bam_16_attention_sparsity": 0.5009765625,
      "attention_bam_16_attention_concentration_10": 0.7593975444351102,
      "attention_bam_16_attention_concentration_20": 1.2009215971156193,
      "attention_bam_16_attention_center_y": 0.4764416966609661,
      "attention_bam_16_attention_center_x": 0.46574648000354885,
      "attention_bam_16_attention_center_distance": 0.05879281058703038,
      "attention_bam_16_attention_spatial_variance": 43.54743953864382,
      "attention_bam_16_attention_spatial_std": 6.599048381292853,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 10.486181192357186,
      "attention_bam_16_peak_intensity_mean": 0.3728734254837036,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 874,
      "phase": "train",
      "loss": 0.002883476670831442,
      "timestamp": 1759544037.4013197,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.002883476670831442,
      "ssim": 0.9410539269447327,
      "attention_bam_384_mean_attention": -0.026606233790516853,
      "attention_bam_384_std_attention": 0.15813882648944855,
      "attention_bam_384_max_attention": 1.0769007205963135,
      "attention_bam_384_min_attention": -0.7518695592880249,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.887994938357402,
      "attention_bam_384_attention_skewness": 0.2903484360900285,
      "attention_bam_384_attention_sparsity": 0.8083902994791666,
      "attention_bam_384_attention_concentration_10": -1.0042809330841942,
      "attention_bam_384_attention_concentration_20": -1.486656271280889,
      "attention_bam_384_attention_center_y": 0.4830686255749017,
      "attention_bam_384_attention_center_x": 0.4826028722448314,
      "attention_bam_384_attention_center_distance": 0.03433166159837097,
      "attention_bam_384_attention_spatial_variance": 171.36449896704434,
      "attention_bam_384_attention_spatial_std": 13.090626377948626,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 19.460758759535445,
      "attention_bam_384_peak_intensity_mean": 0.4027565121650696,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13570065796375275,
      "attention_bam_16_std_attention": 0.5358354449272156,
      "attention_bam_16_max_attention": 2.318955421447754,
      "attention_bam_16_min_attention": -1.1357284784317017,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.30403540556885744,
      "attention_bam_16_attention_skewness": 0.5917430505007584,
      "attention_bam_16_attention_sparsity": 0.5146484375,
      "attention_bam_16_attention_concentration_10": 0.8713262968265338,
      "attention_bam_16_attention_concentration_20": 1.3952248653133072,
      "attention_bam_16_attention_center_y": 0.465703430236273,
      "attention_bam_16_attention_center_x": 0.4616288377851587,
      "attention_bam_16_attention_center_distance": 0.07278187669022916,
      "attention_bam_16_attention_spatial_variance": 43.20185785207528,
      "attention_bam_16_attention_spatial_std": 6.5728120201383575,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.574218311108831,
      "attention_bam_16_peak_intensity_mean": 0.3804199993610382,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 875,
      "phase": "train",
      "loss": 0.005024988204240799,
      "timestamp": 1759544037.5560205,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005024988204240799,
      "ssim": 0.9251367449760437,
      "attention_bam_384_mean_attention": -0.025999389588832855,
      "attention_bam_384_std_attention": 0.16011475026607513,
      "attention_bam_384_max_attention": 1.004136562347412,
      "attention_bam_384_min_attention": -0.7387766242027283,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6705842960541837,
      "attention_bam_384_attention_skewness": 0.14963882764174416,
      "attention_bam_384_attention_sparsity": 0.8013051350911459,
      "attention_bam_384_attention_concentration_10": -1.0207513093518783,
      "attention_bam_384_attention_concentration_20": -1.5320325651523856,
      "attention_bam_384_attention_center_y": 0.485445498111429,
      "attention_bam_384_attention_center_x": 0.48518062302331455,
      "attention_bam_384_attention_center_distance": 0.02937507307911016,
      "attention_bam_384_attention_spatial_variance": 171.15590799342894,
      "attention_bam_384_attention_spatial_std": 13.082656763571723,
      "attention_bam_384_num_attention_peaks": 21,
      "attention_bam_384_peak_separation_mean": 18.55094569289914,
      "attention_bam_384_peak_intensity_mean": 0.4144100546836853,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1430085450410843,
      "attention_bam_16_std_attention": 0.5245171189308167,
      "attention_bam_16_max_attention": 2.771550178527832,
      "attention_bam_16_min_attention": -1.0630340576171875,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.1583322579262072,
      "attention_bam_16_attention_skewness": 0.5020889790421101,
      "attention_bam_16_attention_sparsity": 0.5068359375,
      "attention_bam_16_attention_concentration_10": 0.8069491216048393,
      "attention_bam_16_attention_concentration_20": 1.3034100467823124,
      "attention_bam_16_attention_center_y": 0.4744886323545994,
      "attention_bam_16_attention_center_x": 0.4758495305992023,
      "attention_bam_16_attention_center_distance": 0.04968048009867973,
      "attention_bam_16_attention_spatial_variance": 43.0491667907267,
      "attention_bam_16_attention_spatial_std": 6.561186385915789,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 10.887192167320288,
      "attention_bam_16_peak_intensity_mean": 0.32337090373039246,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 876,
      "phase": "train",
      "loss": 0.0059618474915623665,
      "timestamp": 1759544037.7475417,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0059618474915623665,
      "ssim": 0.889365553855896,
      "attention_bam_384_mean_attention": -0.02664434351027012,
      "attention_bam_384_std_attention": 0.15805739164352417,
      "attention_bam_384_max_attention": 1.29719078540802,
      "attention_bam_384_min_attention": -0.7558573484420776,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2034461955283158,
      "attention_bam_384_attention_skewness": 0.3516365959099247,
      "attention_bam_384_attention_sparsity": 0.8103001912434896,
      "attention_bam_384_attention_concentration_10": -1.008813777972204,
      "attention_bam_384_attention_concentration_20": -1.484311497583076,
      "attention_bam_384_attention_center_y": 0.4859358341408629,
      "attention_bam_384_attention_center_x": 0.48809507944966596,
      "attention_bam_384_attention_center_distance": 0.02605869891698677,
      "attention_bam_384_attention_spatial_variance": 171.9196461975544,
      "attention_bam_384_attention_spatial_std": 13.111813230730311,
      "attention_bam_384_num_attention_peaks": 24,
      "attention_bam_384_peak_separation_mean": 19.86649170081982,
      "attention_bam_384_peak_intensity_mean": 0.36041584610939026,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13571259379386902,
      "attention_bam_16_std_attention": 0.5220216512680054,
      "attention_bam_16_max_attention": 2.649576425552368,
      "attention_bam_16_min_attention": -1.1024421453475952,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8856233905011877,
      "attention_bam_16_attention_skewness": 0.7478421088417068,
      "attention_bam_16_attention_sparsity": 0.5263671875,
      "attention_bam_16_attention_concentration_10": 0.865329555193657,
      "attention_bam_16_attention_concentration_20": 1.368951672648433,
      "attention_bam_16_attention_center_y": 0.4765274478758447,
      "attention_bam_16_attention_center_x": 0.4865564489691522,
      "attention_bam_16_attention_center_distance": 0.038254144024933975,
      "attention_bam_16_attention_spatial_variance": 43.59825081019416,
      "attention_bam_16_attention_spatial_std": 6.602897152780297,
      "attention_bam_16_num_attention_peaks": 11,
      "attention_bam_16_peak_separation_mean": 9.63263373594893,
      "attention_bam_16_peak_intensity_mean": 0.3482416570186615,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 877,
      "phase": "train",
      "loss": 0.0037252758629620075,
      "timestamp": 1759544037.9439352,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0037252758629620075,
      "ssim": 0.9342620372772217,
      "attention_bam_384_mean_attention": -0.027078351005911827,
      "attention_bam_384_std_attention": 0.11429283022880554,
      "attention_bam_384_max_attention": 0.828943133354187,
      "attention_bam_384_min_attention": -0.6131132245063782,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0448960182855105,
      "attention_bam_384_attention_skewness": 0.054166207272009305,
      "attention_bam_384_attention_sparsity": 0.8828811645507812,
      "attention_bam_384_attention_concentration_10": -0.6532968718134712,
      "attention_bam_384_attention_concentration_20": -0.9613114847928683,
      "attention_bam_384_attention_center_y": 0.4801955199075419,
      "attention_bam_384_attention_center_x": 0.4824029237888733,
      "attention_bam_384_attention_center_distance": 0.03746663910501638,
      "attention_bam_384_attention_spatial_variance": 171.70398490441357,
      "attention_bam_384_attention_spatial_std": 13.103586719078619,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 19.588858913094676,
      "attention_bam_384_peak_intensity_mean": 0.41375410556793213,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14582261443138123,
      "attention_bam_16_std_attention": 0.42215263843536377,
      "attention_bam_16_max_attention": 2.052767038345337,
      "attention_bam_16_min_attention": -1.0829411745071411,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.2160103985722066,
      "attention_bam_16_attention_skewness": 0.3205845597606961,
      "attention_bam_16_attention_sparsity": 0.477294921875,
      "attention_bam_16_attention_concentration_10": 0.6383380730917786,
      "attention_bam_16_attention_concentration_20": 1.0350962958096637,
      "attention_bam_16_attention_center_y": 0.4517320914606224,
      "attention_bam_16_attention_center_x": 0.4632239668176397,
      "attention_bam_16_attention_center_distance": 0.08581687026914682,
      "attention_bam_16_attention_spatial_variance": 43.34723532773463,
      "attention_bam_16_attention_spatial_std": 6.583861733643457,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 10.603086525072346,
      "attention_bam_16_peak_intensity_mean": 0.4022133946418762,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 878,
      "phase": "train",
      "loss": 0.006364849861711264,
      "timestamp": 1759544038.1490905,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006364849861711264,
      "ssim": 0.9177390336990356,
      "attention_bam_384_mean_attention": -0.026914766058325768,
      "attention_bam_384_std_attention": 0.1640041172504425,
      "attention_bam_384_max_attention": 1.3461332321166992,
      "attention_bam_384_min_attention": -0.7787777185440063,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.285689008478367,
      "attention_bam_384_attention_skewness": 0.40365514975818667,
      "attention_bam_384_attention_sparsity": 0.7997283935546875,
      "attention_bam_384_attention_concentration_10": -1.0360579132333698,
      "attention_bam_384_attention_concentration_20": -1.5345493293741472,
      "attention_bam_384_attention_center_y": 0.48097878378548636,
      "attention_bam_384_attention_center_x": 0.4843224547334825,
      "attention_bam_384_attention_center_distance": 0.03485949201761212,
      "attention_bam_384_attention_spatial_variance": 170.73550629603758,
      "attention_bam_384_attention_spatial_std": 13.066579747433433,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 17.125331178569535,
      "attention_bam_384_peak_intensity_mean": 0.3606371283531189,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12712585926055908,
      "attention_bam_16_std_attention": 0.5375688672065735,
      "attention_bam_16_max_attention": 2.4665651321411133,
      "attention_bam_16_min_attention": -1.0305778980255127,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.49199457169925687,
      "attention_bam_16_attention_skewness": 0.7330489253827429,
      "attention_bam_16_attention_sparsity": 0.53076171875,
      "attention_bam_16_attention_concentration_10": 0.9529962237570038,
      "attention_bam_16_attention_concentration_20": 1.500374621715751,
      "attention_bam_16_attention_center_y": 0.4519790552022429,
      "attention_bam_16_attention_center_x": 0.4712338704800743,
      "attention_bam_16_attention_center_distance": 0.07916440294509108,
      "attention_bam_16_attention_spatial_variance": 42.47229637076683,
      "attention_bam_16_attention_spatial_std": 6.5170772874630565,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.328508883826931,
      "attention_bam_16_peak_intensity_mean": 0.3458547592163086,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 879,
      "phase": "train",
      "loss": 0.006521002855151892,
      "timestamp": 1759544038.3495014,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006521002855151892,
      "ssim": 0.9154573678970337,
      "attention_bam_384_mean_attention": -0.02726559340953827,
      "attention_bam_384_std_attention": 0.14826689660549164,
      "attention_bam_384_max_attention": 1.082191824913025,
      "attention_bam_384_min_attention": -0.6823639869689941,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6577496151335769,
      "attention_bam_384_attention_skewness": 0.19728923399873793,
      "attention_bam_384_attention_sparsity": 0.8179677327473959,
      "attention_bam_384_attention_concentration_10": -0.8849914806825677,
      "attention_bam_384_attention_concentration_20": -1.3257374497875387,
      "attention_bam_384_attention_center_y": 0.48624387741201464,
      "attention_bam_384_attention_center_x": 0.48595355587727224,
      "attention_bam_384_attention_center_distance": 0.027804082475370213,
      "attention_bam_384_attention_spatial_variance": 170.22534469523575,
      "attention_bam_384_attention_spatial_std": 13.04704352316017,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 19.46191795032696,
      "attention_bam_384_peak_intensity_mean": 0.37391701340675354,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12887105345726013,
      "attention_bam_16_std_attention": 0.4981379508972168,
      "attention_bam_16_max_attention": 2.297804117202759,
      "attention_bam_16_min_attention": -1.0210590362548828,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.05600240134361689,
      "attention_bam_16_attention_skewness": 0.5517518676895291,
      "attention_bam_16_attention_sparsity": 0.519287109375,
      "attention_bam_16_attention_concentration_10": 0.8527537495256672,
      "attention_bam_16_attention_concentration_20": 1.3704973989118734,
      "attention_bam_16_attention_center_y": 0.47593825333634476,
      "attention_bam_16_attention_center_x": 0.47477133217586376,
      "attention_bam_16_attention_center_distance": 0.04930422563404745,
      "attention_bam_16_attention_spatial_variance": 41.777520874804026,
      "attention_bam_16_attention_spatial_std": 6.463553270052319,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.249005548690482,
      "attention_bam_16_peak_intensity_mean": 0.3529083728790283,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 880,
      "phase": "train",
      "loss": 0.0038712150417268276,
      "timestamp": 1759544038.5734665,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0038712150417268276,
      "ssim": 0.9245738387107849,
      "attention_bam_384_mean_attention": -0.027847791090607643,
      "attention_bam_384_std_attention": 0.1660548597574234,
      "attention_bam_384_max_attention": 1.3821388483047485,
      "attention_bam_384_min_attention": -0.8727506995201111,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.2598625458436876,
      "attention_bam_384_attention_skewness": 0.6498953854086825,
      "attention_bam_384_attention_sparsity": 0.8203175862630209,
      "attention_bam_384_attention_concentration_10": -1.0589417535117576,
      "attention_bam_384_attention_concentration_20": -1.5033312220951531,
      "attention_bam_384_attention_center_y": 0.48224013883810796,
      "attention_bam_384_attention_center_x": 0.4811606683953681,
      "attention_bam_384_attention_center_distance": 0.03661510846082432,
      "attention_bam_384_attention_spatial_variance": 170.96073690229483,
      "attention_bam_384_attention_spatial_std": 13.075195482374053,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 18.236421113621837,
      "attention_bam_384_peak_intensity_mean": 0.38015803694725037,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1298467218875885,
      "attention_bam_16_std_attention": 0.5743198394775391,
      "attention_bam_16_max_attention": 3.313563108444214,
      "attention_bam_16_min_attention": -1.115930199623108,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.7857411326410162,
      "attention_bam_16_attention_skewness": 1.0056780502636369,
      "attention_bam_16_attention_sparsity": 0.527587890625,
      "attention_bam_16_attention_concentration_10": 1.0048903666679472,
      "attention_bam_16_attention_concentration_20": 1.5447111534360196,
      "attention_bam_16_attention_center_y": 0.4594196519290026,
      "attention_bam_16_attention_center_x": 0.45289967223853,
      "attention_bam_16_attention_center_distance": 0.08792275615335549,
      "attention_bam_16_attention_spatial_variance": 42.605711323845284,
      "attention_bam_16_attention_spatial_std": 6.527305058279817,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 10.661695186580719,
      "attention_bam_16_peak_intensity_mean": 0.28356266021728516,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 881,
      "phase": "train",
      "loss": 0.0053648874163627625,
      "timestamp": 1759544038.7475061,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0053648874163627625,
      "ssim": 0.9045433402061462,
      "attention_bam_384_mean_attention": -0.027763552963733673,
      "attention_bam_384_std_attention": 0.13237540423870087,
      "attention_bam_384_max_attention": 0.8307896852493286,
      "attention_bam_384_min_attention": -0.6469025015830994,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8361062907823684,
      "attention_bam_384_attention_skewness": 0.2648084321183331,
      "attention_bam_384_attention_sparsity": 0.8485616048177084,
      "attention_bam_384_attention_concentration_10": -0.7840787120024093,
      "attention_bam_384_attention_concentration_20": -1.152413485078499,
      "attention_bam_384_attention_center_y": 0.48598851228458656,
      "attention_bam_384_attention_center_x": 0.48240976626591214,
      "attention_bam_384_attention_center_distance": 0.03180371395981998,
      "attention_bam_384_attention_spatial_variance": 170.9248127132506,
      "attention_bam_384_attention_spatial_std": 13.073821656778502,
      "attention_bam_384_num_attention_peaks": 21,
      "attention_bam_384_peak_separation_mean": 18.750013834052407,
      "attention_bam_384_peak_intensity_mean": 0.42357757687568665,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13672152161598206,
      "attention_bam_16_std_attention": 0.4685017764568329,
      "attention_bam_16_max_attention": 1.9286301136016846,
      "attention_bam_16_min_attention": -1.0898951292037964,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.13163374463868216,
      "attention_bam_16_attention_skewness": 0.5295630709396965,
      "attention_bam_16_attention_sparsity": 0.504150390625,
      "attention_bam_16_attention_concentration_10": 0.7722996686810185,
      "attention_bam_16_attention_concentration_20": 1.2286178018719869,
      "attention_bam_16_attention_center_y": 0.4789244546585738,
      "attention_bam_16_attention_center_x": 0.4610563587066873,
      "attention_bam_16_attention_center_distance": 0.06262245298007289,
      "attention_bam_16_attention_spatial_variance": 42.78177345724123,
      "attention_bam_16_attention_spatial_std": 6.540777741006128,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.564887814075295,
      "attention_bam_16_peak_intensity_mean": 0.41869106888771057,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 882,
      "phase": "train",
      "loss": 0.004726209677755833,
      "timestamp": 1759544038.9077148,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004726209677755833,
      "ssim": 0.9150413274765015,
      "attention_bam_384_mean_attention": -0.028384024277329445,
      "attention_bam_384_std_attention": 0.14804841578006744,
      "attention_bam_384_max_attention": 1.0434911251068115,
      "attention_bam_384_min_attention": -0.6864641904830933,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.3911657850172432,
      "attention_bam_384_attention_skewness": 0.4260645499582543,
      "attention_bam_384_attention_sparsity": 0.8314666748046875,
      "attention_bam_384_attention_concentration_10": -0.8824536145949281,
      "attention_bam_384_attention_concentration_20": -1.2813538429458609,
      "attention_bam_384_attention_center_y": 0.4828630632747856,
      "attention_bam_384_attention_center_x": 0.48586147434774263,
      "attention_bam_384_attention_center_distance": 0.03141886401331344,
      "attention_bam_384_attention_spatial_variance": 170.79404349456325,
      "attention_bam_384_attention_spatial_std": 13.06881951419344,
      "attention_bam_384_num_attention_peaks": 22,
      "attention_bam_384_peak_separation_mean": 17.85459049945816,
      "attention_bam_384_peak_intensity_mean": 0.38823363184928894,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1266939789056778,
      "attention_bam_16_std_attention": 0.5190958380699158,
      "attention_bam_16_max_attention": 3.3444950580596924,
      "attention_bam_16_min_attention": -0.988476574420929,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.3105019845332455,
      "attention_bam_16_attention_skewness": 0.8231105661909673,
      "attention_bam_16_attention_sparsity": 0.52734375,
      "attention_bam_16_attention_concentration_10": 0.9230966507782504,
      "attention_bam_16_attention_concentration_20": 1.4421296429424737,
      "attention_bam_16_attention_center_y": 0.4641618947919175,
      "attention_bam_16_attention_center_x": 0.4812903850716657,
      "attention_bam_16_attention_center_distance": 0.05717376103899653,
      "attention_bam_16_attention_spatial_variance": 42.29068966628104,
      "attention_bam_16_attention_spatial_std": 6.503129221096644,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.98359677481757,
      "attention_bam_16_peak_intensity_mean": 0.2646641135215759,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 883,
      "phase": "train",
      "loss": 0.005186664871871471,
      "timestamp": 1759544039.0658536,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005186664871871471,
      "ssim": 0.9065402150154114,
      "attention_bam_384_mean_attention": -0.02813502959907055,
      "attention_bam_384_std_attention": 0.14911584556102753,
      "attention_bam_384_max_attention": 0.8607936501502991,
      "attention_bam_384_min_attention": -0.6958599090576172,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.38989068153176154,
      "attention_bam_384_attention_skewness": 0.19489875711408775,
      "attention_bam_384_attention_sparsity": 0.8138580322265625,
      "attention_bam_384_attention_concentration_10": -0.8673172173342742,
      "attention_bam_384_attention_concentration_20": -1.304801124300181,
      "attention_bam_384_attention_center_y": 0.4838153827850063,
      "attention_bam_384_attention_center_x": 0.48565008863785286,
      "attention_bam_384_attention_center_distance": 0.030589599229063135,
      "attention_bam_384_attention_spatial_variance": 170.89304704687228,
      "attention_bam_384_attention_spatial_std": 13.0726067426077,
      "attention_bam_384_num_attention_peaks": 18,
      "attention_bam_384_peak_separation_mean": 18.513682346639506,
      "attention_bam_384_peak_intensity_mean": 0.43397006392478943,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12403909862041473,
      "attention_bam_16_std_attention": 0.5182775855064392,
      "attention_bam_16_max_attention": 2.285325527191162,
      "attention_bam_16_min_attention": -1.0074578523635864,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.08909095887220797,
      "attention_bam_16_attention_skewness": 0.5021138398019094,
      "attention_bam_16_attention_sparsity": 0.524658203125,
      "attention_bam_16_attention_concentration_10": 0.9048940650987187,
      "attention_bam_16_attention_concentration_20": 1.4660900613505825,
      "attention_bam_16_attention_center_y": 0.4668663167898592,
      "attention_bam_16_attention_center_x": 0.47701712871223306,
      "attention_bam_16_attention_center_distance": 0.05702724499219701,
      "attention_bam_16_attention_spatial_variance": 42.51634381881577,
      "attention_bam_16_attention_spatial_std": 6.5204557983944476,
      "attention_bam_16_num_attention_peaks": 11,
      "attention_bam_16_peak_separation_mean": 8.758341676641523,
      "attention_bam_16_peak_intensity_mean": 0.35432708263397217,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 884,
      "phase": "train",
      "loss": 0.005009423941373825,
      "timestamp": 1759544039.213046,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005009423941373825,
      "ssim": 0.9296164512634277,
      "attention_bam_384_mean_attention": -0.02746959589421749,
      "attention_bam_384_std_attention": 0.1389663964509964,
      "attention_bam_384_max_attention": 1.5084729194641113,
      "attention_bam_384_min_attention": -0.7223396301269531,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1170196523727052,
      "attention_bam_384_attention_skewness": 0.30602825923932414,
      "attention_bam_384_attention_sparsity": 0.8386764526367188,
      "attention_bam_384_attention_concentration_10": -0.831833280293554,
      "attention_bam_384_attention_concentration_20": -1.2249435841439387,
      "attention_bam_384_attention_center_y": 0.4834010459451928,
      "attention_bam_384_attention_center_x": 0.482769313581104,
      "attention_bam_384_attention_center_distance": 0.03383553842278644,
      "attention_bam_384_attention_spatial_variance": 169.6120444959606,
      "attention_bam_384_attention_spatial_std": 13.023518898360788,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 17.770304923171185,
      "attention_bam_384_peak_intensity_mean": 0.3128485083580017,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13874877989292145,
      "attention_bam_16_std_attention": 0.5015344023704529,
      "attention_bam_16_max_attention": 2.7527222633361816,
      "attention_bam_16_min_attention": -0.9644415378570557,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.3026523946265511,
      "attention_bam_16_attention_skewness": 0.7542387358891423,
      "attention_bam_16_attention_sparsity": 0.5078125,
      "attention_bam_16_attention_concentration_10": 0.8030509362004989,
      "attention_bam_16_attention_concentration_20": 1.2774987909591626,
      "attention_bam_16_attention_center_y": 0.4657969335269817,
      "attention_bam_16_attention_center_x": 0.46290264186265045,
      "attention_bam_16_attention_center_distance": 0.07135914429039186,
      "attention_bam_16_attention_spatial_variance": 40.990349405766665,
      "attention_bam_16_attention_spatial_std": 6.402370608279925,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.04834871472221,
      "attention_bam_16_peak_intensity_mean": 0.30219796299934387,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 885,
      "phase": "train",
      "loss": 0.004603719338774681,
      "timestamp": 1759544039.362103,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004603719338774681,
      "ssim": 0.9268912076950073,
      "attention_bam_384_mean_attention": -0.028753109276294708,
      "attention_bam_384_std_attention": 0.16140462458133698,
      "attention_bam_384_max_attention": 1.3592804670333862,
      "attention_bam_384_min_attention": -0.7535027265548706,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2693742054678259,
      "attention_bam_384_attention_skewness": 0.47548434616107427,
      "attention_bam_384_attention_sparsity": 0.8087005615234375,
      "attention_bam_384_attention_concentration_10": -0.9671974102258853,
      "attention_bam_384_attention_concentration_20": -1.4137465924310182,
      "attention_bam_384_attention_center_y": 0.48202467672030513,
      "attention_bam_384_attention_center_x": 0.48325647178272463,
      "attention_bam_384_attention_center_distance": 0.034740696140757935,
      "attention_bam_384_attention_spatial_variance": 170.63954631820204,
      "attention_bam_384_attention_spatial_std": 13.062907268988862,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 17.676359057021838,
      "attention_bam_384_peak_intensity_mean": 0.3461683690547943,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12315664440393448,
      "attention_bam_16_std_attention": 0.5743995904922485,
      "attention_bam_16_max_attention": 3.545207977294922,
      "attention_bam_16_min_attention": -1.0669379234313965,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.6271991253592768,
      "attention_bam_16_attention_skewness": 1.0055827671277533,
      "attention_bam_16_attention_sparsity": 0.551513671875,
      "attention_bam_16_attention_concentration_10": 1.0685773969898524,
      "attention_bam_16_attention_concentration_20": 1.6359883252986904,
      "attention_bam_16_attention_center_y": 0.4587875647784688,
      "attention_bam_16_attention_center_x": 0.46233847996877364,
      "attention_bam_16_attention_center_distance": 0.07895384611216058,
      "attention_bam_16_attention_spatial_variance": 42.5297582756484,
      "attention_bam_16_attention_spatial_std": 6.521484361374211,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.859936808067015,
      "attention_bam_16_peak_intensity_mean": 0.26394718885421753,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 886,
      "phase": "train",
      "loss": 0.004203861113637686,
      "timestamp": 1759544039.510092,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004203861113637686,
      "ssim": 0.9224156141281128,
      "attention_bam_384_mean_attention": -0.02870054543018341,
      "attention_bam_384_std_attention": 0.1329931616783142,
      "attention_bam_384_max_attention": 1.1929380893707275,
      "attention_bam_384_min_attention": -0.625921905040741,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5625228206876947,
      "attention_bam_384_attention_skewness": 0.19246630058503786,
      "attention_bam_384_attention_sparsity": 0.8447367350260416,
      "attention_bam_384_attention_concentration_10": -0.7483965114991741,
      "attention_bam_384_attention_concentration_20": -1.1124743712696008,
      "attention_bam_384_attention_center_y": 0.48826354671374833,
      "attention_bam_384_attention_center_x": 0.4823769096992699,
      "attention_bam_384_attention_center_distance": 0.0299438690715831,
      "attention_bam_384_attention_spatial_variance": 171.33917721690963,
      "attention_bam_384_attention_spatial_std": 13.089659171151464,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 18.95080055955645,
      "attention_bam_384_peak_intensity_mean": 0.3302777111530304,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13172419369220734,
      "attention_bam_16_std_attention": 0.47311335802078247,
      "attention_bam_16_max_attention": 2.1132378578186035,
      "attention_bam_16_min_attention": -1.0689691305160522,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.09821855013478098,
      "attention_bam_16_attention_skewness": 0.579647579323995,
      "attention_bam_16_attention_sparsity": 0.519287109375,
      "attention_bam_16_attention_concentration_10": 0.8112830620150112,
      "attention_bam_16_attention_concentration_20": 1.2994914738803123,
      "attention_bam_16_attention_center_y": 0.4861912019809213,
      "attention_bam_16_attention_center_x": 0.46122475958975484,
      "attention_bam_16_attention_center_distance": 0.05821000208905718,
      "attention_bam_16_attention_spatial_variance": 43.015408247795435,
      "attention_bam_16_attention_spatial_std": 6.558613286952924,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 5.97173409259926,
      "attention_bam_16_peak_intensity_mean": 0.3804640471935272,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 887,
      "phase": "train",
      "loss": 0.0051157413981854916,
      "timestamp": 1759544039.6572168,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0051157413981854916,
      "ssim": 0.9454746246337891,
      "attention_bam_384_mean_attention": -0.028412654995918274,
      "attention_bam_384_std_attention": 0.15319295227527618,
      "attention_bam_384_max_attention": 1.0886342525482178,
      "attention_bam_384_min_attention": -0.7564080953598022,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9299735490938685,
      "attention_bam_384_attention_skewness": 0.2165382530889129,
      "attention_bam_384_attention_sparsity": 0.8159205118815104,
      "attention_bam_384_attention_concentration_10": -0.8763485269725476,
      "attention_bam_384_attention_concentration_20": -1.3047419654804857,
      "attention_bam_384_attention_center_y": 0.48408679047243575,
      "attention_bam_384_attention_center_x": 0.48404113323415077,
      "attention_bam_384_attention_center_distance": 0.03187210899574387,
      "attention_bam_384_attention_spatial_variance": 169.8849338935368,
      "attention_bam_384_attention_spatial_std": 13.033991479724728,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 17.8899753451827,
      "attention_bam_384_peak_intensity_mean": 0.3956293761730194,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12919336557388306,
      "attention_bam_16_std_attention": 0.5174763202667236,
      "attention_bam_16_max_attention": 2.3556299209594727,
      "attention_bam_16_min_attention": -1.0980746746063232,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.15528028035597785,
      "attention_bam_16_attention_skewness": 0.5674399354978443,
      "attention_bam_16_attention_sparsity": 0.517333984375,
      "attention_bam_16_attention_concentration_10": 0.8791379950514487,
      "attention_bam_16_attention_concentration_20": 1.4096518808225404,
      "attention_bam_16_attention_center_y": 0.46828377575710656,
      "attention_bam_16_attention_center_x": 0.4695241541612019,
      "attention_bam_16_attention_center_distance": 0.06220443810236836,
      "attention_bam_16_attention_spatial_variance": 41.887194473656535,
      "attention_bam_16_attention_spatial_std": 6.472031711422352,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 8.598733213777805,
      "attention_bam_16_peak_intensity_mean": 0.35738512873649597,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 888,
      "phase": "train",
      "loss": 0.0038683374878019094,
      "timestamp": 1759544039.8041413,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0038683374878019094,
      "ssim": 0.9535825848579407,
      "attention_bam_384_mean_attention": -0.028826074674725533,
      "attention_bam_384_std_attention": 0.1460551768541336,
      "attention_bam_384_max_attention": 1.248487114906311,
      "attention_bam_384_min_attention": -0.8216211199760437,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.023353901129357,
      "attention_bam_384_attention_skewness": 0.30878506304764447,
      "attention_bam_384_attention_sparsity": 0.8460133870442709,
      "attention_bam_384_attention_concentration_10": -0.8253479327969735,
      "attention_bam_384_attention_concentration_20": -1.1861733927323255,
      "attention_bam_384_attention_center_y": 0.4823203855216408,
      "attention_bam_384_attention_center_x": 0.48777891907348003,
      "attention_bam_384_attention_center_distance": 0.03039485440386113,
      "attention_bam_384_attention_spatial_variance": 170.60228096867033,
      "attention_bam_384_attention_spatial_std": 13.061480810714777,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 20.352334435190834,
      "attention_bam_384_peak_intensity_mean": 0.3837418556213379,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1332712471485138,
      "attention_bam_16_std_attention": 0.5096591711044312,
      "attention_bam_16_max_attention": 2.862236976623535,
      "attention_bam_16_min_attention": -1.1543139219284058,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.2660254053428073,
      "attention_bam_16_attention_skewness": 0.7350076859772748,
      "attention_bam_16_attention_sparsity": 0.515625,
      "attention_bam_16_attention_concentration_10": 0.8553155735926059,
      "attention_bam_16_attention_concentration_20": 1.3329825456430142,
      "attention_bam_16_attention_center_y": 0.45974595595074275,
      "attention_bam_16_attention_center_x": 0.487071094257437,
      "attention_bam_16_attention_center_distance": 0.059792050742880895,
      "attention_bam_16_attention_spatial_variance": 42.34530107708558,
      "attention_bam_16_attention_spatial_std": 6.507326722786061,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 8.38175433317947,
      "attention_bam_16_peak_intensity_mean": 0.3163577616214752,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 889,
      "phase": "train",
      "loss": 0.00482667051255703,
      "timestamp": 1759544039.994695,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00482667051255703,
      "ssim": 0.9405491948127747,
      "attention_bam_384_mean_attention": -0.029097020626068115,
      "attention_bam_384_std_attention": 0.15223386883735657,
      "attention_bam_384_max_attention": 1.001851201057434,
      "attention_bam_384_min_attention": -0.7042891979217529,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5912308978570451,
      "attention_bam_384_attention_skewness": 0.23964102869017273,
      "attention_bam_384_attention_sparsity": 0.8131510416666666,
      "attention_bam_384_attention_concentration_10": -0.8589499085361495,
      "attention_bam_384_attention_concentration_20": -1.2861527578346799,
      "attention_bam_384_attention_center_y": 0.480730076364664,
      "attention_bam_384_attention_center_x": 0.4859537955723294,
      "attention_bam_384_attention_center_distance": 0.03372316164702217,
      "attention_bam_384_attention_spatial_variance": 172.11002272123284,
      "attention_bam_384_attention_spatial_std": 13.11907095495839,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 20.41234514790642,
      "attention_bam_384_peak_intensity_mean": 0.40106910467147827,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13020603358745575,
      "attention_bam_16_std_attention": 0.5416592955589294,
      "attention_bam_16_max_attention": 2.3647890090942383,
      "attention_bam_16_min_attention": -1.0313129425048828,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.2075500354338149,
      "attention_bam_16_attention_skewness": 0.6391747162199423,
      "attention_bam_16_attention_sparsity": 0.526611328125,
      "attention_bam_16_attention_concentration_10": 0.9206234072946576,
      "attention_bam_16_attention_concentration_20": 1.4698195085796366,
      "attention_bam_16_attention_center_y": 0.45162434243697175,
      "attention_bam_16_attention_center_x": 0.4776299971420995,
      "attention_bam_16_attention_center_distance": 0.07537401770527888,
      "attention_bam_16_attention_spatial_variance": 43.77810260942648,
      "attention_bam_16_attention_spatial_std": 6.616502294220601,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.479870179687643,
      "attention_bam_16_peak_intensity_mean": 0.34983137249946594,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 890,
      "phase": "train",
      "loss": 0.0037051034159958363,
      "timestamp": 1759544040.243292,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0037051034159958363,
      "ssim": 0.9294459819793701,
      "attention_bam_384_mean_attention": -0.029464520514011383,
      "attention_bam_384_std_attention": 0.14826340973377228,
      "attention_bam_384_max_attention": 1.098093867301941,
      "attention_bam_384_min_attention": -0.7167365550994873,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1556982521309687,
      "attention_bam_384_attention_skewness": 0.25435930213688457,
      "attention_bam_384_attention_sparsity": 0.8302052815755209,
      "attention_bam_384_attention_concentration_10": -0.8173502102968598,
      "attention_bam_384_attention_concentration_20": -1.2024102698067178,
      "attention_bam_384_attention_center_y": 0.4860798265047244,
      "attention_bam_384_attention_center_x": 0.4818718453211977,
      "attention_bam_384_attention_center_distance": 0.03232340397288486,
      "attention_bam_384_attention_spatial_variance": 171.80633716977417,
      "attention_bam_384_attention_spatial_std": 13.107491642941229,
      "attention_bam_384_num_attention_peaks": 18,
      "attention_bam_384_peak_separation_mean": 21.109982734404113,
      "attention_bam_384_peak_intensity_mean": 0.38455450534820557,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12826275825500488,
      "attention_bam_16_std_attention": 0.5160914063453674,
      "attention_bam_16_max_attention": 3.0080249309539795,
      "attention_bam_16_min_attention": -1.07309091091156,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7822394582159142,
      "attention_bam_16_attention_skewness": 0.6984291468797035,
      "attention_bam_16_attention_sparsity": 0.523681640625,
      "attention_bam_16_attention_concentration_10": 0.8882026839467869,
      "attention_bam_16_attention_concentration_20": 1.408495640088958,
      "attention_bam_16_attention_center_y": 0.4755884016120741,
      "attention_bam_16_attention_center_x": 0.45946246780900313,
      "attention_bam_16_attention_center_distance": 0.06692111254289626,
      "attention_bam_16_attention_spatial_variance": 43.678681031840036,
      "attention_bam_16_attention_spatial_std": 6.608984871509394,
      "attention_bam_16_num_attention_peaks": 11,
      "attention_bam_16_peak_separation_mean": 9.870518895536287,
      "attention_bam_16_peak_intensity_mean": 0.3052290678024292,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 891,
      "phase": "train",
      "loss": 0.0032302350737154484,
      "timestamp": 1759544040.4382658,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0032302350737154484,
      "ssim": 0.9411572217941284,
      "attention_bam_384_mean_attention": -0.029457630589604378,
      "attention_bam_384_std_attention": 0.147138312458992,
      "attention_bam_384_max_attention": 0.9120209217071533,
      "attention_bam_384_min_attention": -0.6385928392410278,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6172192814588255,
      "attention_bam_384_attention_skewness": 0.2641700622476651,
      "attention_bam_384_attention_sparsity": 0.8266347249348959,
      "attention_bam_384_attention_concentration_10": -0.8275184258205445,
      "attention_bam_384_attention_concentration_20": -1.2220981857762152,
      "attention_bam_384_attention_center_y": 0.48329798728465845,
      "attention_bam_384_attention_center_x": 0.4844563181162895,
      "attention_bam_384_attention_center_distance": 0.0322664926896439,
      "attention_bam_384_attention_spatial_variance": 171.48542510139282,
      "attention_bam_384_attention_spatial_std": 13.095244369670725,
      "attention_bam_384_num_attention_peaks": 8,
      "attention_bam_384_peak_separation_mean": 20.914445552005066,
      "attention_bam_384_peak_intensity_mean": 0.4006219208240509,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13845321536064148,
      "attention_bam_16_std_attention": 0.50751793384552,
      "attention_bam_16_max_attention": 2.354897975921631,
      "attention_bam_16_min_attention": -1.017056941986084,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.16077192211576552,
      "attention_bam_16_attention_skewness": 0.6110102594658956,
      "attention_bam_16_attention_sparsity": 0.514404296875,
      "attention_bam_16_attention_concentration_10": 0.828541556200908,
      "attention_bam_16_attention_concentration_20": 1.322044660878477,
      "attention_bam_16_attention_center_y": 0.4644714157473098,
      "attention_bam_16_attention_center_x": 0.47057308697010986,
      "attention_bam_16_attention_center_distance": 0.06524145169245121,
      "attention_bam_16_attention_spatial_variance": 42.972194253205316,
      "attention_bam_16_attention_spatial_std": 6.555318013125322,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 12.163802759182621,
      "attention_bam_16_peak_intensity_mean": 0.3599661588668823,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 892,
      "phase": "train",
      "loss": 0.004242992959916592,
      "timestamp": 1759544040.6318853,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004242992959916592,
      "ssim": 0.9221855401992798,
      "attention_bam_384_mean_attention": -0.03001249022781849,
      "attention_bam_384_std_attention": 0.15234318375587463,
      "attention_bam_384_max_attention": 1.492400884628296,
      "attention_bam_384_min_attention": -0.8881614804267883,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.599627265117732,
      "attention_bam_384_attention_skewness": 0.6033450677501668,
      "attention_bam_384_attention_sparsity": 0.8304850260416666,
      "attention_bam_384_attention_concentration_10": -0.8559075685020234,
      "attention_bam_384_attention_concentration_20": -1.234635249336462,
      "attention_bam_384_attention_center_y": 0.4867950571380054,
      "attention_bam_384_attention_center_x": 0.4827537535190969,
      "attention_bam_384_attention_center_distance": 0.030718187891495316,
      "attention_bam_384_attention_spatial_variance": 170.46869898824548,
      "attention_bam_384_attention_spatial_std": 13.056366224499277,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 19.682017186617077,
      "attention_bam_384_peak_intensity_mean": 0.3647955358028412,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.11551918089389801,
      "attention_bam_16_std_attention": 0.5458363890647888,
      "attention_bam_16_max_attention": 3.4788851737976074,
      "attention_bam_16_min_attention": -1.078587293624878,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 2.5039490346114865,
      "attention_bam_16_attention_skewness": 1.077555750726494,
      "attention_bam_16_attention_sparsity": 0.547607421875,
      "attention_bam_16_attention_concentration_10": 1.0583131383879834,
      "attention_bam_16_attention_concentration_20": 1.6303913091421924,
      "attention_bam_16_attention_center_y": 0.48414360424698927,
      "attention_bam_16_attention_center_x": 0.46210196587870855,
      "attention_bam_16_attention_center_distance": 0.05809795653092572,
      "attention_bam_16_attention_spatial_variance": 42.13207080326406,
      "attention_bam_16_attention_spatial_std": 6.490922184348235,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.18596122057457,
      "attention_bam_16_peak_intensity_mean": 0.26894065737724304,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 893,
      "phase": "train",
      "loss": 0.004294760525226593,
      "timestamp": 1759544040.829678,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004294760525226593,
      "ssim": 0.9404444098472595,
      "attention_bam_384_mean_attention": -0.029965465888381004,
      "attention_bam_384_std_attention": 0.14146733283996582,
      "attention_bam_384_max_attention": 1.0491750240325928,
      "attention_bam_384_min_attention": -0.6811255216598511,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1121922962294475,
      "attention_bam_384_attention_skewness": 0.2680297623733003,
      "attention_bam_384_attention_sparsity": 0.8437321980794271,
      "attention_bam_384_attention_concentration_10": -0.7798564358945064,
      "attention_bam_384_attention_concentration_20": -1.1321892075804694,
      "attention_bam_384_attention_center_y": 0.4815477247731139,
      "attention_bam_384_attention_center_x": 0.4869133784604071,
      "attention_bam_384_attention_center_distance": 0.03199206540282419,
      "attention_bam_384_attention_spatial_variance": 171.75494287790363,
      "attention_bam_384_attention_spatial_std": 13.105531003278868,
      "attention_bam_384_num_attention_peaks": 19,
      "attention_bam_384_peak_separation_mean": 18.517014274267638,
      "attention_bam_384_peak_intensity_mean": 0.38330167531967163,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13280527293682098,
      "attention_bam_16_std_attention": 0.500938355922699,
      "attention_bam_16_max_attention": 2.2830729484558105,
      "attention_bam_16_min_attention": -1.1147544384002686,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.31943421162802377,
      "attention_bam_16_attention_skewness": 0.5640952503419917,
      "attention_bam_16_attention_sparsity": 0.515380859375,
      "attention_bam_16_attention_concentration_10": 0.8303310966991938,
      "attention_bam_16_attention_concentration_20": 1.3289993021845892,
      "attention_bam_16_attention_center_y": 0.4605303026637126,
      "attention_bam_16_attention_center_x": 0.4807830335292972,
      "attention_bam_16_attention_center_distance": 0.062082989750079684,
      "attention_bam_16_attention_spatial_variance": 43.389498879454436,
      "attention_bam_16_attention_spatial_std": 6.5870705840650015,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 8.800760510728676,
      "attention_bam_16_peak_intensity_mean": 0.3708258271217346,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 894,
      "phase": "train",
      "loss": 0.004755091853439808,
      "timestamp": 1759544041.0387058,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004755091853439808,
      "ssim": 0.9227946996688843,
      "attention_bam_384_mean_attention": -0.02994386851787567,
      "attention_bam_384_std_attention": 0.14888164401054382,
      "attention_bam_384_max_attention": 1.1630102396011353,
      "attention_bam_384_min_attention": -0.7436109185218811,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.65934793095885,
      "attention_bam_384_attention_skewness": 0.4651594075910426,
      "attention_bam_384_attention_sparsity": 0.8386128743489584,
      "attention_bam_384_attention_concentration_10": -0.8466053810766324,
      "attention_bam_384_attention_concentration_20": -1.2101406868090332,
      "attention_bam_384_attention_center_y": 0.4827161067466925,
      "attention_bam_384_attention_center_x": 0.48302959189342237,
      "attention_bam_384_attention_center_distance": 0.034255735791120394,
      "attention_bam_384_attention_spatial_variance": 170.86758446007244,
      "attention_bam_384_attention_spatial_std": 13.071632815378209,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 20.43440020742804,
      "attention_bam_384_peak_intensity_mean": 0.3836481273174286,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12979629635810852,
      "attention_bam_16_std_attention": 0.5330895185470581,
      "attention_bam_16_max_attention": 2.863510847091675,
      "attention_bam_16_min_attention": -0.9479534029960632,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.3046678641688736,
      "attention_bam_16_attention_skewness": 0.8898591030589961,
      "attention_bam_16_attention_sparsity": 0.5322265625,
      "attention_bam_16_attention_concentration_10": 0.9370313261477926,
      "attention_bam_16_attention_concentration_20": 1.4542577551692013,
      "attention_bam_16_attention_center_y": 0.46149946845304046,
      "attention_bam_16_attention_center_x": 0.46221149518961047,
      "attention_bam_16_attention_center_distance": 0.07629235905650393,
      "attention_bam_16_attention_spatial_variance": 42.60193852597957,
      "attention_bam_16_attention_spatial_std": 6.527016050691125,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 10.657898676375044,
      "attention_bam_16_peak_intensity_mean": 0.3009496331214905,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 895,
      "phase": "train",
      "loss": 0.004630229901522398,
      "timestamp": 1759544041.2533805,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004630229901522398,
      "ssim": 0.937920093536377,
      "attention_bam_384_mean_attention": -0.029489576816558838,
      "attention_bam_384_std_attention": 0.15115578472614288,
      "attention_bam_384_max_attention": 1.075003981590271,
      "attention_bam_384_min_attention": -0.7516021728515625,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2038584871397315,
      "attention_bam_384_attention_skewness": 0.2948861168732786,
      "attention_bam_384_attention_sparsity": 0.8340504964192709,
      "attention_bam_384_attention_concentration_10": -0.86647798665941,
      "attention_bam_384_attention_concentration_20": -1.2495889362985837,
      "attention_bam_384_attention_center_y": 0.4843044493433876,
      "attention_bam_384_attention_center_x": 0.4815553954195758,
      "attention_bam_384_attention_center_distance": 0.034250656885452285,
      "attention_bam_384_attention_spatial_variance": 171.13177906112298,
      "attention_bam_384_attention_spatial_std": 13.081734558579111,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 21.361797424037665,
      "attention_bam_384_peak_intensity_mean": 0.400224894285202,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1372830718755722,
      "attention_bam_16_std_attention": 0.5182185769081116,
      "attention_bam_16_max_attention": 2.5463006496429443,
      "attention_bam_16_min_attention": -1.0612235069274902,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.41619822931463357,
      "attention_bam_16_attention_skewness": 0.6354332626471453,
      "attention_bam_16_attention_sparsity": 0.51904296875,
      "attention_bam_16_attention_concentration_10": 0.8518737996991862,
      "attention_bam_16_attention_concentration_20": 1.3455379086783261,
      "attention_bam_16_attention_center_y": 0.46752176536017676,
      "attention_bam_16_attention_center_x": 0.45635437111082383,
      "attention_bam_16_attention_center_distance": 0.07693863329239874,
      "attention_bam_16_attention_spatial_variance": 43.106800348684914,
      "attention_bam_16_attention_spatial_std": 6.565576924283571,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.474034919872144,
      "attention_bam_16_peak_intensity_mean": 0.34554266929626465,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 896,
      "phase": "train",
      "loss": 0.0044952016323804855,
      "timestamp": 1759544041.4380803,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0044952016323804855,
      "ssim": 0.9549353122711182,
      "attention_bam_384_mean_attention": -0.029389047995209694,
      "attention_bam_384_std_attention": 0.15315686166286469,
      "attention_bam_384_max_attention": 1.0365604162216187,
      "attention_bam_384_min_attention": -0.746242344379425,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9893247532569109,
      "attention_bam_384_attention_skewness": 0.17192843247354408,
      "attention_bam_384_attention_sparsity": 0.8261362711588541,
      "attention_bam_384_attention_concentration_10": -0.8564227402096751,
      "attention_bam_384_attention_concentration_20": -1.2547229523011225,
      "attention_bam_384_attention_center_y": 0.4826977844445495,
      "attention_bam_384_attention_center_x": 0.4847424792290699,
      "attention_bam_384_attention_center_distance": 0.03262387479140503,
      "attention_bam_384_attention_spatial_variance": 171.7604986580768,
      "attention_bam_384_attention_spatial_std": 13.10574296474934,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 20.402135551682324,
      "attention_bam_384_peak_intensity_mean": 0.4075821340084076,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1413809359073639,
      "attention_bam_16_std_attention": 0.5165955424308777,
      "attention_bam_16_max_attention": 2.633915901184082,
      "attention_bam_16_min_attention": -1.1272711753845215,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.11714732469949984,
      "attention_bam_16_attention_skewness": 0.5005650095193412,
      "attention_bam_16_attention_sparsity": 0.507568359375,
      "attention_bam_16_attention_concentration_10": 0.8054483314106805,
      "attention_bam_16_attention_concentration_20": 1.3023096541333141,
      "attention_bam_16_attention_center_y": 0.46240642100347534,
      "attention_bam_16_attention_center_x": 0.4704439717104324,
      "attention_bam_16_attention_center_distance": 0.0676289285738235,
      "attention_bam_16_attention_spatial_variance": 43.509785723443535,
      "attention_bam_16_attention_spatial_std": 6.596194791199206,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 10.472981280788058,
      "attention_bam_16_peak_intensity_mean": 0.34136924147605896,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 897,
      "phase": "train",
      "loss": 0.0062690055929124355,
      "timestamp": 1759544041.6159961,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0062690055929124355,
      "ssim": 0.9172120094299316,
      "attention_bam_384_mean_attention": -0.02943313866853714,
      "attention_bam_384_std_attention": 0.16546526551246643,
      "attention_bam_384_max_attention": 1.1418137550354004,
      "attention_bam_384_min_attention": -0.7596480250358582,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1182429692587403,
      "attention_bam_384_attention_skewness": 0.26056081392578245,
      "attention_bam_384_attention_sparsity": 0.8048146565755209,
      "attention_bam_384_attention_concentration_10": -0.9333546642427699,
      "attention_bam_384_attention_concentration_20": -1.3751001468452557,
      "attention_bam_384_attention_center_y": 0.480378092121083,
      "attention_bam_384_attention_center_x": 0.48439999926567573,
      "attention_bam_384_attention_center_distance": 0.03545079101288495,
      "attention_bam_384_attention_spatial_variance": 171.62452838486644,
      "attention_bam_384_attention_spatial_std": 13.10055450677056,
      "attention_bam_384_num_attention_peaks": 9,
      "attention_bam_384_peak_separation_mean": 17.323806408605453,
      "attention_bam_384_peak_intensity_mean": 0.39035850763320923,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1273854374885559,
      "attention_bam_16_std_attention": 0.5558945536613464,
      "attention_bam_16_max_attention": 2.4230833053588867,
      "attention_bam_16_min_attention": -1.130160927772522,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.2778433846572188,
      "attention_bam_16_attention_skewness": 0.6067657129523317,
      "attention_bam_16_attention_sparsity": 0.522216796875,
      "attention_bam_16_attention_concentration_10": 0.9614572615135127,
      "attention_bam_16_attention_concentration_20": 1.5198760231098492,
      "attention_bam_16_attention_center_y": 0.4486008383019027,
      "attention_bam_16_attention_center_x": 0.46837673423181125,
      "attention_bam_16_attention_center_distance": 0.08534523725566234,
      "attention_bam_16_attention_spatial_variance": 43.278693699012045,
      "attention_bam_16_attention_spatial_std": 6.578654398812271,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.858138029392425,
      "attention_bam_16_peak_intensity_mean": 0.3680455982685089,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 898,
      "phase": "train",
      "loss": 0.0042906226590275764,
      "timestamp": 1759544041.7883205,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0042906226590275764,
      "ssim": 0.9282166957855225,
      "attention_bam_384_mean_attention": -0.029355227947235107,
      "attention_bam_384_std_attention": 0.1580181121826172,
      "attention_bam_384_max_attention": 1.119577407836914,
      "attention_bam_384_min_attention": -0.7329317331314087,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9328022712636614,
      "attention_bam_384_attention_skewness": 0.23716651124750054,
      "attention_bam_384_attention_sparsity": 0.8128687540690104,
      "attention_bam_384_attention_concentration_10": -0.8847314072388185,
      "attention_bam_384_attention_concentration_20": -1.3083870897887948,
      "attention_bam_384_attention_center_y": 0.4839923155571396,
      "attention_bam_384_attention_center_x": 0.48348435132924295,
      "attention_bam_384_attention_center_distance": 0.032527299680055625,
      "attention_bam_384_attention_spatial_variance": 172.07101696381048,
      "attention_bam_384_attention_spatial_std": 13.117584265550212,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 19.22863475040016,
      "attention_bam_384_peak_intensity_mean": 0.3849067687988281,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1251981258392334,
      "attention_bam_16_std_attention": 0.5355860590934753,
      "attention_bam_16_max_attention": 2.477269411087036,
      "attention_bam_16_min_attention": -1.013954997062683,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.236587271950794,
      "attention_bam_16_attention_skewness": 0.5982185990452386,
      "attention_bam_16_attention_sparsity": 0.526123046875,
      "attention_bam_16_attention_concentration_10": 0.9365337309074894,
      "attention_bam_16_attention_concentration_20": 1.499009272154788,
      "attention_bam_16_attention_center_y": 0.4634422712583479,
      "attention_bam_16_attention_center_x": 0.46486191354458056,
      "attention_bam_16_attention_center_distance": 0.07170986892327647,
      "attention_bam_16_attention_spatial_variance": 43.58594670282974,
      "attention_bam_16_attention_spatial_std": 6.601965366679057,
      "attention_bam_16_num_attention_peaks": 12,
      "attention_bam_16_peak_separation_mean": 8.448312763257137,
      "attention_bam_16_peak_intensity_mean": 0.33019527792930603,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 899,
      "phase": "train",
      "loss": 0.005992825608700514,
      "timestamp": 1759544041.9563048,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005992825608700514,
      "ssim": 0.9274511933326721,
      "attention_bam_384_mean_attention": -0.028605910018086433,
      "attention_bam_384_std_attention": 0.15193729102611542,
      "attention_bam_384_max_attention": 0.9497464299201965,
      "attention_bam_384_min_attention": -0.6536872386932373,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.4911245732047669,
      "attention_bam_384_attention_skewness": 0.253373750674953,
      "attention_bam_384_attention_sparsity": 0.8090031941731771,
      "attention_bam_384_attention_concentration_10": -0.8608426219903175,
      "attention_bam_384_attention_concentration_20": -1.2943714333277614,
      "attention_bam_384_attention_center_y": 0.4853777946493229,
      "attention_bam_384_attention_center_x": 0.4833715275830793,
      "attention_bam_384_attention_center_distance": 0.03131501187091147,
      "attention_bam_384_attention_spatial_variance": 172.4411219204622,
      "attention_bam_384_attention_spatial_std": 13.131683895086045,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 18.847578916365926,
      "attention_bam_384_peak_intensity_mean": 0.3978178799152374,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.11985243856906891,
      "attention_bam_16_std_attention": 0.5084764957427979,
      "attention_bam_16_max_attention": 2.5435988903045654,
      "attention_bam_16_min_attention": -0.9269485473632812,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.025132331431384713,
      "attention_bam_16_attention_skewness": 0.6005936247176948,
      "attention_bam_16_attention_sparsity": 0.53515625,
      "attention_bam_16_attention_concentration_10": 0.9235881265896181,
      "attention_bam_16_attention_concentration_20": 1.4988181884901264,
      "attention_bam_16_attention_center_y": 0.47278828359421776,
      "attention_bam_16_attention_center_x": 0.468709001998669,
      "attention_bam_16_attention_center_distance": 0.058644762181596734,
      "attention_bam_16_attention_spatial_variance": 44.166228251819504,
      "attention_bam_16_attention_spatial_std": 6.645767694692578,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 10.288231437355904,
      "attention_bam_16_peak_intensity_mean": 0.32175320386886597,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 900,
      "phase": "train",
      "loss": 0.0030785812996327877,
      "timestamp": 1759544042.1575944,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0030785812996327877,
      "ssim": 0.9524078369140625,
      "attention_bam_384_mean_attention": -0.029040558263659477,
      "attention_bam_384_std_attention": 0.1509961038827896,
      "attention_bam_384_max_attention": 1.1443533897399902,
      "attention_bam_384_min_attention": -0.7009286284446716,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2975823436173597,
      "attention_bam_384_attention_skewness": 0.3301267507838403,
      "attention_bam_384_attention_sparsity": 0.8276341756184896,
      "attention_bam_384_attention_concentration_10": -0.8663531587784594,
      "attention_bam_384_attention_concentration_20": -1.265272263806118,
      "attention_bam_384_attention_center_y": 0.48089905989627657,
      "attention_bam_384_attention_center_x": 0.48318389827197417,
      "attention_bam_384_attention_center_distance": 0.03598964268156447,
      "attention_bam_384_attention_spatial_variance": 171.6042756983428,
      "attention_bam_384_attention_spatial_std": 13.099781513381924,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 16.487809327319816,
      "attention_bam_384_peak_intensity_mean": 0.3692066967487335,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.11526135355234146,
      "attention_bam_16_std_attention": 0.5325663089752197,
      "attention_bam_16_max_attention": 2.419400215148926,
      "attention_bam_16_min_attention": -1.060197114944458,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.43939701642811313,
      "attention_bam_16_attention_skewness": 0.6718800310103006,
      "attention_bam_16_attention_sparsity": 0.53076171875,
      "attention_bam_16_attention_concentration_10": 1.02019008645285,
      "attention_bam_16_attention_concentration_20": 1.6029724920292934,
      "attention_bam_16_attention_center_y": 0.45311874674818164,
      "attention_bam_16_attention_center_x": 0.462726524171345,
      "attention_bam_16_attention_center_distance": 0.08470140384681302,
      "attention_bam_16_attention_spatial_variance": 43.08587795594479,
      "attention_bam_16_attention_spatial_std": 6.563983390894951,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.067587461583294,
      "attention_bam_16_peak_intensity_mean": 0.34785372018814087,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 901,
      "phase": "train",
      "loss": 0.008070115931332111,
      "timestamp": 1759544044.6606812,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008070115931332111,
      "ssim": 0.9001492857933044,
      "attention_bam_384_mean_attention": -0.0293597262352705,
      "attention_bam_384_std_attention": 0.12237175554037094,
      "attention_bam_384_max_attention": 1.0249247550964355,
      "attention_bam_384_min_attention": -0.6918323636054993,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.7848120285653337,
      "attention_bam_384_attention_skewness": 0.19206376725270413,
      "attention_bam_384_attention_sparsity": 0.8801472981770834,
      "attention_bam_384_attention_concentration_10": -0.6533520270672015,
      "attention_bam_384_attention_concentration_20": -0.9412905172466429,
      "attention_bam_384_attention_center_y": 0.48016602683630966,
      "attention_bam_384_attention_center_x": 0.4822124512405868,
      "attention_bam_384_attention_center_distance": 0.03767713848812009,
      "attention_bam_384_attention_spatial_variance": 171.78923271702433,
      "attention_bam_384_attention_spatial_std": 13.106839158127498,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 17.74208775328383,
      "attention_bam_384_peak_intensity_mean": 0.3889691233634949,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.11893212050199509,
      "attention_bam_16_std_attention": 0.4484909772872925,
      "attention_bam_16_max_attention": 2.3685550689697266,
      "attention_bam_16_min_attention": -1.0561528205871582,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7290345924983312,
      "attention_bam_16_attention_skewness": 0.5773117914823092,
      "attention_bam_16_attention_sparsity": 0.5244140625,
      "attention_bam_16_attention_concentration_10": 0.8343949579097366,
      "attention_bam_16_attention_concentration_20": 1.3235721379168084,
      "attention_bam_16_attention_center_y": 0.44748863249945475,
      "attention_bam_16_attention_center_x": 0.4600787160724985,
      "attention_bam_16_attention_center_distance": 0.09328614717306646,
      "attention_bam_16_attention_spatial_variance": 43.632675912030145,
      "attention_bam_16_attention_spatial_std": 6.6055034563635,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.738360719700893,
      "attention_bam_16_peak_intensity_mean": 0.36852970719337463,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 902,
      "phase": "train",
      "loss": 0.0033202162012457848,
      "timestamp": 1759544044.8050208,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0033202162012457848,
      "ssim": 0.9383469820022583,
      "attention_bam_384_mean_attention": -0.02916758693754673,
      "attention_bam_384_std_attention": 0.14020077884197235,
      "attention_bam_384_max_attention": 1.1510522365570068,
      "attention_bam_384_min_attention": -0.7075917720794678,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.7076952654215098,
      "attention_bam_384_attention_skewness": 0.42829820779271066,
      "attention_bam_384_attention_sparsity": 0.8519668579101562,
      "attention_bam_384_attention_concentration_10": -0.8149598166694236,
      "attention_bam_384_attention_concentration_20": -1.1599712612516715,
      "attention_bam_384_attention_center_y": 0.4874848839601304,
      "attention_bam_384_attention_center_x": 0.4847504480312534,
      "attention_bam_384_attention_center_distance": 0.02789899513383609,
      "attention_bam_384_attention_spatial_variance": 172.47433029447623,
      "attention_bam_384_attention_spatial_std": 13.132948271217558,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 21.495179729660705,
      "attention_bam_384_peak_intensity_mean": 0.37594085931777954,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.10495760291814804,
      "attention_bam_16_std_attention": 0.49933791160583496,
      "attention_bam_16_max_attention": 2.4342970848083496,
      "attention_bam_16_min_attention": -1.0371025800704956,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.9186848527591294,
      "attention_bam_16_attention_skewness": 0.8085218397476661,
      "attention_bam_16_attention_sparsity": 0.552734375,
      "attention_bam_16_attention_concentration_10": 1.0828213130688327,
      "attention_bam_16_attention_concentration_20": 1.6546232028742898,
      "attention_bam_16_attention_center_y": 0.4849438618645706,
      "attention_bam_16_attention_center_x": 0.4738001697953776,
      "attention_bam_16_attention_center_distance": 0.04273449188428887,
      "attention_bam_16_attention_spatial_variance": 44.2031363440775,
      "attention_bam_16_attention_spatial_std": 6.6485439266111115,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 10.491694635826939,
      "attention_bam_16_peak_intensity_mean": 0.3503188192844391,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 903,
      "phase": "train",
      "loss": 0.003587436629459262,
      "timestamp": 1759544044.9424906,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.003587436629459262,
      "ssim": 0.929633617401123,
      "attention_bam_384_mean_attention": -0.029264060780405998,
      "attention_bam_384_std_attention": 0.14731238782405853,
      "attention_bam_384_max_attention": 1.1277862787246704,
      "attention_bam_384_min_attention": -0.7207241058349609,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.977330845839973,
      "attention_bam_384_attention_skewness": 0.29799396863939237,
      "attention_bam_384_attention_sparsity": 0.825714111328125,
      "attention_bam_384_attention_concentration_10": -0.8277189170039579,
      "attention_bam_384_attention_concentration_20": -1.2240467775204054,
      "attention_bam_384_attention_center_y": 0.4831420287181029,
      "attention_bam_384_attention_center_x": 0.48434714109729765,
      "attention_bam_384_attention_center_distance": 0.032533158087378326,
      "attention_bam_384_attention_spatial_variance": 171.74506507936792,
      "attention_bam_384_attention_spatial_std": 13.105154141763,
      "attention_bam_384_num_attention_peaks": 21,
      "attention_bam_384_peak_separation_mean": 21.581791699466674,
      "attention_bam_384_peak_intensity_mean": 0.3798882067203522,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12466862797737122,
      "attention_bam_16_std_attention": 0.5190830826759338,
      "attention_bam_16_max_attention": 2.243417739868164,
      "attention_bam_16_min_attention": -1.0457682609558105,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.08479856689197351,
      "attention_bam_16_attention_skewness": 0.5238936134350839,
      "attention_bam_16_attention_sparsity": 0.525390625,
      "attention_bam_16_attention_concentration_10": 0.9059987784249992,
      "attention_bam_16_attention_concentration_20": 1.4651025474321548,
      "attention_bam_16_attention_center_y": 0.46392069786771595,
      "attention_bam_16_attention_center_x": 0.4709550562349572,
      "attention_bam_16_attention_center_distance": 0.06550305032083827,
      "attention_bam_16_attention_spatial_variance": 43.36976571465612,
      "attention_bam_16_attention_spatial_std": 6.585572542661429,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 11.639616876323213,
      "attention_bam_16_peak_intensity_mean": 0.3646531105041504,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 904,
      "phase": "train",
      "loss": 0.004167687147855759,
      "timestamp": 1759544045.0786564,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004167687147855759,
      "ssim": 0.9327795505523682,
      "attention_bam_384_mean_attention": -0.02902846783399582,
      "attention_bam_384_std_attention": 0.16352030634880066,
      "attention_bam_384_max_attention": 1.179750919342041,
      "attention_bam_384_min_attention": -0.735368013381958,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8273210922557075,
      "attention_bam_384_attention_skewness": 0.39160064561034613,
      "attention_bam_384_attention_sparsity": 0.8057072957356771,
      "attention_bam_384_attention_concentration_10": -0.9693725533988535,
      "attention_bam_384_attention_concentration_20": -1.4271850607516265,
      "attention_bam_384_attention_center_y": 0.48474846406616434,
      "attention_bam_384_attention_center_x": 0.4804856724396098,
      "attention_bam_384_attention_center_distance": 0.035026228129083035,
      "attention_bam_384_attention_spatial_variance": 171.2697358792544,
      "attention_bam_384_attention_spatial_std": 13.087006375762732,
      "attention_bam_384_num_attention_peaks": 20,
      "attention_bam_384_peak_separation_mean": 19.26488121034976,
      "attention_bam_384_peak_intensity_mean": 0.37285059690475464,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1174800768494606,
      "attention_bam_16_std_attention": 0.5711141228675842,
      "attention_bam_16_max_attention": 2.469334840774536,
      "attention_bam_16_min_attention": -0.9977312088012695,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.28616305563770217,
      "attention_bam_16_attention_skewness": 0.7338536262367704,
      "attention_bam_16_attention_sparsity": 0.540771484375,
      "attention_bam_16_attention_concentration_10": 1.0905428233789687,
      "attention_bam_16_attention_concentration_20": 1.7086696783600224,
      "attention_bam_16_attention_center_y": 0.4720892874468794,
      "attention_bam_16_attention_center_x": 0.45367914130452347,
      "attention_bam_16_attention_center_distance": 0.07648045273805885,
      "attention_bam_16_attention_spatial_variance": 43.00074916950457,
      "attention_bam_16_attention_spatial_std": 6.557495647692385,
      "attention_bam_16_num_attention_peaks": 12,
      "attention_bam_16_peak_separation_mean": 9.405297240685508,
      "attention_bam_16_peak_intensity_mean": 0.33534106612205505,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 905,
      "phase": "train",
      "loss": 0.0035794954746961594,
      "timestamp": 1759544045.223635,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0035794954746961594,
      "ssim": 0.9414157867431641,
      "attention_bam_384_mean_attention": -0.02959117293357849,
      "attention_bam_384_std_attention": 0.14841292798519135,
      "attention_bam_384_max_attention": 1.215964436531067,
      "attention_bam_384_min_attention": -0.753928005695343,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.3764636436399789,
      "attention_bam_384_attention_skewness": 0.3211509187491755,
      "attention_bam_384_attention_sparsity": 0.8326950073242188,
      "attention_bam_384_attention_concentration_10": -0.8312042487699108,
      "attention_bam_384_attention_concentration_20": -1.2116658189952823,
      "attention_bam_384_attention_center_y": 0.4847425740026665,
      "attention_bam_384_attention_center_x": 0.4832996165244081,
      "attention_bam_384_attention_center_distance": 0.03199036905995084,
      "attention_bam_384_attention_spatial_variance": 171.97141613051915,
      "attention_bam_384_attention_spatial_std": 13.113787253517541,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 21.260575778915555,
      "attention_bam_384_peak_intensity_mean": 0.37043601274490356,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.11372049152851105,
      "attention_bam_16_std_attention": 0.5247104167938232,
      "attention_bam_16_max_attention": 2.424400806427002,
      "attention_bam_16_min_attention": -1.0761843919754028,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5941900444902162,
      "attention_bam_16_attention_skewness": 0.665121004378737,
      "attention_bam_16_attention_sparsity": 0.528564453125,
      "attention_bam_16_attention_concentration_10": 1.005410688855386,
      "attention_bam_16_attention_concentration_20": 1.585556366325909,
      "attention_bam_16_attention_center_y": 0.4725021264164851,
      "attention_bam_16_attention_center_x": 0.46404366690401977,
      "attention_bam_16_attention_center_distance": 0.06401548158569222,
      "attention_bam_16_attention_spatial_variance": 44.016467452760914,
      "attention_bam_16_attention_spatial_std": 6.634490745547914,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.81804568630712,
      "attention_bam_16_peak_intensity_mean": 0.34242507815361023,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 906,
      "phase": "train",
      "loss": 0.003546656109392643,
      "timestamp": 1759544045.3667915,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.003546656109392643,
      "ssim": 0.9362784624099731,
      "attention_bam_384_mean_attention": -0.029375605285167694,
      "attention_bam_384_std_attention": 0.14875003695487976,
      "attention_bam_384_max_attention": 1.126379132270813,
      "attention_bam_384_min_attention": -0.709655225276947,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9994408997298647,
      "attention_bam_384_attention_skewness": 0.27712757173881886,
      "attention_bam_384_attention_sparsity": 0.8267415364583334,
      "attention_bam_384_attention_concentration_10": -0.8354121398724416,
      "attention_bam_384_attention_concentration_20": -1.2304559762834708,
      "attention_bam_384_attention_center_y": 0.47963382916214903,
      "attention_bam_384_attention_center_x": 0.4836988302094643,
      "attention_bam_384_attention_center_distance": 0.03689197883379001,
      "attention_bam_384_attention_spatial_variance": 170.66185596675018,
      "attention_bam_384_attention_spatial_std": 13.063761172294532,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 19.133006433676027,
      "attention_bam_384_peak_intensity_mean": 0.3775387406349182,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1256701648235321,
      "attention_bam_16_std_attention": 0.5255572199821472,
      "attention_bam_16_max_attention": 2.5157201290130615,
      "attention_bam_16_min_attention": -1.071495771408081,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.17278937438866615,
      "attention_bam_16_attention_skewness": 0.5977012864460809,
      "attention_bam_16_attention_sparsity": 0.527099609375,
      "attention_bam_16_attention_concentration_10": 0.919694265123564,
      "attention_bam_16_attention_concentration_20": 1.4744505952225788,
      "attention_bam_16_attention_center_y": 0.4491716437956002,
      "attention_bam_16_attention_center_x": 0.4648930969785481,
      "attention_bam_16_attention_center_distance": 0.08736150678873364,
      "attention_bam_16_attention_spatial_variance": 42.27902519991884,
      "attention_bam_16_attention_spatial_std": 6.502232324357447,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.573931907463738,
      "attention_bam_16_peak_intensity_mean": 0.3426651954650879,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 907,
      "phase": "train",
      "loss": 0.005579897668212652,
      "timestamp": 1759544045.5051625,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005579897668212652,
      "ssim": 0.9021968841552734,
      "attention_bam_384_mean_attention": -0.02949296124279499,
      "attention_bam_384_std_attention": 0.14576180279254913,
      "attention_bam_384_max_attention": 1.019964575767517,
      "attention_bam_384_min_attention": -0.7089903354644775,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.008712202291168,
      "attention_bam_384_attention_skewness": 0.5643951695882743,
      "attention_bam_384_attention_sparsity": 0.8515116373697916,
      "attention_bam_384_attention_concentration_10": -0.8606227056111051,
      "attention_bam_384_attention_concentration_20": -1.2034211799409726,
      "attention_bam_384_attention_center_y": 0.485612272693101,
      "attention_bam_384_attention_center_x": 0.48392959436989863,
      "attention_bam_384_attention_center_distance": 0.03050457782607986,
      "attention_bam_384_attention_spatial_variance": 171.64323828542746,
      "attention_bam_384_attention_spatial_std": 13.101268575425337,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 21.781600969655898,
      "attention_bam_384_peak_intensity_mean": 0.40089911222457886,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.11543026566505432,
      "attention_bam_16_std_attention": 0.5230690240859985,
      "attention_bam_16_max_attention": 2.5329065322875977,
      "attention_bam_16_min_attention": -1.1274998188018799,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.2535821143277373,
      "attention_bam_16_attention_skewness": 0.9533154430252615,
      "attention_bam_16_attention_sparsity": 0.551513671875,
      "attention_bam_16_attention_concentration_10": 1.047634680062537,
      "attention_bam_16_attention_concentration_20": 1.5972652565488283,
      "attention_bam_16_attention_center_y": 0.4745825933430315,
      "attention_bam_16_attention_center_x": 0.4709581424797453,
      "attention_bam_16_attention_center_distance": 0.05457974073577997,
      "attention_bam_16_attention_spatial_variance": 43.39651576445829,
      "attention_bam_16_attention_spatial_std": 6.5876031881450094,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 10.258182655962965,
      "attention_bam_16_peak_intensity_mean": 0.35196563601493835,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 908,
      "phase": "train",
      "loss": 0.0032505090348422527,
      "timestamp": 1759544045.6743963,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0032505090348422527,
      "ssim": 0.9485270977020264,
      "attention_bam_384_mean_attention": -0.028891446068882942,
      "attention_bam_384_std_attention": 0.14174288511276245,
      "attention_bam_384_max_attention": 0.9639244079589844,
      "attention_bam_384_min_attention": -0.6323139071464539,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8991252527413729,
      "attention_bam_384_attention_skewness": 0.24489082272811266,
      "attention_bam_384_attention_sparsity": 0.8377507527669271,
      "attention_bam_384_attention_concentration_10": -0.8007822073200288,
      "attention_bam_384_attention_concentration_20": -1.1784702498447395,
      "attention_bam_384_attention_center_y": 0.4816674147291191,
      "attention_bam_384_attention_center_x": 0.4825688428114788,
      "attention_bam_384_attention_center_distance": 0.03577510094032027,
      "attention_bam_384_attention_spatial_variance": 170.70332090003657,
      "attention_bam_384_attention_spatial_std": 13.065348097162838,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 17.863798751121248,
      "attention_bam_384_peak_intensity_mean": 0.3828902840614319,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12116408348083496,
      "attention_bam_16_std_attention": 0.5033983588218689,
      "attention_bam_16_max_attention": 2.3004353046417236,
      "attention_bam_16_min_attention": -1.0037041902542114,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.2684795081114997,
      "attention_bam_16_attention_skewness": 0.5835154384058301,
      "attention_bam_16_attention_sparsity": 0.525390625,
      "attention_bam_16_attention_concentration_10": 0.9151568824232806,
      "attention_bam_16_attention_concentration_20": 1.4567703792905586,
      "attention_bam_16_attention_center_y": 0.4567478378048749,
      "attention_bam_16_attention_center_x": 0.4617108761884698,
      "attention_bam_16_attention_center_distance": 0.08169218489926806,
      "attention_bam_16_attention_spatial_variance": 42.42244571132567,
      "attention_bam_16_attention_spatial_std": 6.5132515467564795,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.195039880980707,
      "attention_bam_16_peak_intensity_mean": 0.3489930331707001,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 909,
      "phase": "train",
      "loss": 0.004137280397117138,
      "timestamp": 1759544045.9056683,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004137280397117138,
      "ssim": 0.942008376121521,
      "attention_bam_384_mean_attention": -0.02933899126946926,
      "attention_bam_384_std_attention": 0.1501956731081009,
      "attention_bam_384_max_attention": 1.0957610607147217,
      "attention_bam_384_min_attention": -0.6883774399757385,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1145749443416726,
      "attention_bam_384_attention_skewness": 0.2757181319116971,
      "attention_bam_384_attention_sparsity": 0.8273366292317709,
      "attention_bam_384_attention_concentration_10": -0.8410334908439535,
      "attention_bam_384_attention_concentration_20": -1.2342516209093948,
      "attention_bam_384_attention_center_y": 0.48292460822255157,
      "attention_bam_384_attention_center_x": 0.4822928517785587,
      "attention_bam_384_attention_center_distance": 0.034788276832560874,
      "attention_bam_384_attention_spatial_variance": 171.32937341292518,
      "attention_bam_384_attention_spatial_std": 13.0892846791918,
      "attention_bam_384_num_attention_peaks": 27,
      "attention_bam_384_peak_separation_mean": 18.984931340261706,
      "attention_bam_384_peak_intensity_mean": 0.3753160834312439,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12455286085605621,
      "attention_bam_16_std_attention": 0.5240115523338318,
      "attention_bam_16_max_attention": 2.633275270462036,
      "attention_bam_16_min_attention": -1.1230717897415161,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.3601120117735186,
      "attention_bam_16_attention_skewness": 0.5823229458573521,
      "attention_bam_16_attention_sparsity": 0.525146484375,
      "attention_bam_16_attention_concentration_10": 0.9180735508070768,
      "attention_bam_16_attention_concentration_20": 1.4658931560149633,
      "attention_bam_16_attention_center_y": 0.46199181499751346,
      "attention_bam_16_attention_center_x": 0.4627828427844416,
      "attention_bam_16_attention_center_distance": 0.07522950110682422,
      "attention_bam_16_attention_spatial_variance": 42.9624880356034,
      "attention_bam_16_attention_spatial_std": 6.554577639757073,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 9.928745143087568,
      "attention_bam_16_peak_intensity_mean": 0.3391020894050598,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 910,
      "phase": "train",
      "loss": 0.0038284864276647568,
      "timestamp": 1759544046.1669767,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0038284864276647568,
      "ssim": 0.9244176149368286,
      "attention_bam_384_mean_attention": -0.029499167576432228,
      "attention_bam_384_std_attention": 0.1510627567768097,
      "attention_bam_384_max_attention": 1.3345741033554077,
      "attention_bam_384_min_attention": -0.753417432308197,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5761323586832479,
      "attention_bam_384_attention_skewness": 0.3553907136751959,
      "attention_bam_384_attention_sparsity": 0.8281097412109375,
      "attention_bam_384_attention_concentration_10": -0.8459136075355077,
      "attention_bam_384_attention_concentration_20": -1.2361635449407835,
      "attention_bam_384_attention_center_y": 0.4818129053116958,
      "attention_bam_384_attention_center_x": 0.4819163268692814,
      "attention_bam_384_attention_center_distance": 0.03627091526554073,
      "attention_bam_384_attention_spatial_variance": 171.43675424097572,
      "attention_bam_384_attention_spatial_std": 13.093385896740985,
      "attention_bam_384_num_attention_peaks": 19,
      "attention_bam_384_peak_separation_mean": 19.80052843665465,
      "attention_bam_384_peak_intensity_mean": 0.35299912095069885,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12238462269306183,
      "attention_bam_16_std_attention": 0.5276494026184082,
      "attention_bam_16_max_attention": 2.599449634552002,
      "attention_bam_16_min_attention": -1.0561838150024414,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8004571592388285,
      "attention_bam_16_attention_skewness": 0.6993349195069647,
      "attention_bam_16_attention_sparsity": 0.53076171875,
      "attention_bam_16_attention_concentration_10": 0.9496113096301741,
      "attention_bam_16_attention_concentration_20": 1.4894936657549063,
      "attention_bam_16_attention_center_y": 0.45665327080209067,
      "attention_bam_16_attention_center_x": 0.45770927636792336,
      "attention_bam_16_attention_center_distance": 0.08564396344730398,
      "attention_bam_16_attention_spatial_variance": 43.03500008295618,
      "attention_bam_16_attention_spatial_std": 6.5601067127719945,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.364473576951632,
      "attention_bam_16_peak_intensity_mean": 0.33287307620048523,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 911,
      "phase": "train",
      "loss": 0.004024840891361237,
      "timestamp": 1759544046.3621757,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004024840891361237,
      "ssim": 0.9346505403518677,
      "attention_bam_384_mean_attention": -0.029070908203721046,
      "attention_bam_384_std_attention": 0.131614550948143,
      "attention_bam_384_max_attention": 1.1596912145614624,
      "attention_bam_384_min_attention": -0.6551132202148438,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.6200578690132454,
      "attention_bam_384_attention_skewness": 0.3422504670517979,
      "attention_bam_384_attention_sparsity": 0.8595504760742188,
      "attention_bam_384_attention_concentration_10": -0.7336542994261936,
      "attention_bam_384_attention_concentration_20": -1.0639012757608433,
      "attention_bam_384_attention_center_y": 0.48243475361574223,
      "attention_bam_384_attention_center_x": 0.485991526350702,
      "attention_bam_384_attention_center_distance": 0.031773423313289924,
      "attention_bam_384_attention_spatial_variance": 171.14321778322378,
      "attention_bam_384_attention_spatial_std": 13.082171753314652,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 17.105371642634918,
      "attention_bam_384_peak_intensity_mean": 0.34938955307006836,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.11339413374662399,
      "attention_bam_16_std_attention": 0.4837932586669922,
      "attention_bam_16_max_attention": 2.838425636291504,
      "attention_bam_16_min_attention": -1.0484960079193115,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.9165127111688776,
      "attention_bam_16_attention_skewness": 0.6912793814433882,
      "attention_bam_16_attention_sparsity": 0.52734375,
      "attention_bam_16_attention_concentration_10": 0.9417944199420567,
      "attention_bam_16_attention_concentration_20": 1.4762426867366343,
      "attention_bam_16_attention_center_y": 0.4641496946939873,
      "attention_bam_16_attention_center_x": 0.4775265801995996,
      "attention_bam_16_attention_center_distance": 0.05983809803226286,
      "attention_bam_16_attention_spatial_variance": 42.70624639812265,
      "attention_bam_16_attention_spatial_std": 6.535001637193571,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.427282274498015,
      "attention_bam_16_peak_intensity_mean": 0.3004757761955261,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 912,
      "phase": "train",
      "loss": 0.006922123488038778,
      "timestamp": 1759544046.5619247,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006922123488038778,
      "ssim": 0.883078932762146,
      "attention_bam_384_mean_attention": -0.02890472114086151,
      "attention_bam_384_std_attention": 0.14338837563991547,
      "attention_bam_384_max_attention": 1.1382697820663452,
      "attention_bam_384_min_attention": -0.7274781465530396,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0648607103185554,
      "attention_bam_384_attention_skewness": 0.20650215951646494,
      "attention_bam_384_attention_sparsity": 0.8351694742838541,
      "attention_bam_384_attention_concentration_10": -0.8057860676801111,
      "attention_bam_384_attention_concentration_20": -1.1877597933366226,
      "attention_bam_384_attention_center_y": 0.48380736556290477,
      "attention_bam_384_attention_center_x": 0.48395887994773484,
      "attention_bam_384_attention_center_distance": 0.03223411058318767,
      "attention_bam_384_attention_spatial_variance": 170.95438493322612,
      "attention_bam_384_attention_spatial_std": 13.07495257862246,
      "attention_bam_384_num_attention_peaks": 21,
      "attention_bam_384_peak_separation_mean": 19.063742774523515,
      "attention_bam_384_peak_intensity_mean": 0.37870627641677856,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12956950068473816,
      "attention_bam_16_std_attention": 0.4955052137374878,
      "attention_bam_16_max_attention": 2.0672500133514404,
      "attention_bam_16_min_attention": -1.079604983329773,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.16532163799618482,
      "attention_bam_16_attention_skewness": 0.5165742012164659,
      "attention_bam_16_attention_sparsity": 0.511962890625,
      "attention_bam_16_attention_concentration_10": 0.8415207040181337,
      "attention_bam_16_attention_concentration_20": 1.3493837218221736,
      "attention_bam_16_attention_center_y": 0.4687329764955001,
      "attention_bam_16_attention_center_x": 0.46996932886757303,
      "attention_bam_16_attention_center_distance": 0.06131016175961259,
      "attention_bam_16_attention_spatial_variance": 42.63282666262897,
      "attention_bam_16_attention_spatial_std": 6.529381797890898,
      "attention_bam_16_num_attention_peaks": 13,
      "attention_bam_16_peak_separation_mean": 9.603420096763003,
      "attention_bam_16_peak_intensity_mean": 0.39189398288726807,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 913,
      "phase": "train",
      "loss": 0.003522934392094612,
      "timestamp": 1759544046.7451174,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.003522934392094612,
      "ssim": 0.9256798624992371,
      "attention_bam_384_mean_attention": -0.029229730367660522,
      "attention_bam_384_std_attention": 0.14998775720596313,
      "attention_bam_384_max_attention": 1.146662712097168,
      "attention_bam_384_min_attention": -0.6894952058792114,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.7008218657219372,
      "attention_bam_384_attention_skewness": 0.44118546645757284,
      "attention_bam_384_attention_sparsity": 0.832763671875,
      "attention_bam_384_attention_concentration_10": -0.8733875618940831,
      "attention_bam_384_attention_concentration_20": -1.2606366961780786,
      "attention_bam_384_attention_center_y": 0.486289940829114,
      "attention_bam_384_attention_center_x": 0.479412768100247,
      "attention_bam_384_attention_center_distance": 0.03497998970163949,
      "attention_bam_384_attention_spatial_variance": 171.99873327746909,
      "attention_bam_384_attention_spatial_std": 13.114828755171342,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 19.85191824713739,
      "attention_bam_384_peak_intensity_mean": 0.3669193983078003,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.11932472884654999,
      "attention_bam_16_std_attention": 0.5400410890579224,
      "attention_bam_16_max_attention": 2.26680064201355,
      "attention_bam_16_min_attention": -0.9953432083129883,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.4705421351284329,
      "attention_bam_16_attention_skewness": 0.7394287741055157,
      "attention_bam_16_attention_sparsity": 0.546142578125,
      "attention_bam_16_attention_concentration_10": 1.0192029668061457,
      "attention_bam_16_attention_concentration_20": 1.5989335077317042,
      "attention_bam_16_attention_center_y": 0.47608903614155296,
      "attention_bam_16_attention_center_x": 0.4500702634049415,
      "attention_bam_16_attention_center_distance": 0.07829064808892419,
      "attention_bam_16_attention_spatial_variance": 44.02316382452715,
      "attention_bam_16_attention_spatial_std": 6.634995389940158,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 10.926948809308136,
      "attention_bam_16_peak_intensity_mean": 0.3504475951194763,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 914,
      "phase": "train",
      "loss": 0.0025238171219825745,
      "timestamp": 1759544046.9242983,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0025238171219825745,
      "ssim": 0.9479503035545349,
      "attention_bam_384_mean_attention": -0.029832152649760246,
      "attention_bam_384_std_attention": 0.1606050729751587,
      "attention_bam_384_max_attention": 1.2083309888839722,
      "attention_bam_384_min_attention": -0.7827619910240173,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1110184076107474,
      "attention_bam_384_attention_skewness": 0.34345855978007644,
      "attention_bam_384_attention_sparsity": 0.8098856608072916,
      "attention_bam_384_attention_concentration_10": -0.8936241400385957,
      "attention_bam_384_attention_concentration_20": -1.3152480463107692,
      "attention_bam_384_attention_center_y": 0.4839941483052368,
      "attention_bam_384_attention_center_x": 0.4845827027558705,
      "attention_bam_384_attention_center_distance": 0.031428660257433724,
      "attention_bam_384_attention_spatial_variance": 170.92129013106793,
      "attention_bam_384_attention_spatial_std": 13.073686937167645,
      "attention_bam_384_num_attention_peaks": 26,
      "attention_bam_384_peak_separation_mean": 19.73479227713718,
      "attention_bam_384_peak_intensity_mean": 0.38245564699172974,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.11848652362823486,
      "attention_bam_16_std_attention": 0.5556920766830444,
      "attention_bam_16_max_attention": 2.583618640899658,
      "attention_bam_16_min_attention": -1.0769374370574951,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.4664360370364409,
      "attention_bam_16_attention_skewness": 0.6962816034044664,
      "attention_bam_16_attention_sparsity": 0.53662109375,
      "attention_bam_16_attention_concentration_10": 1.0377057977303872,
      "attention_bam_16_attention_concentration_20": 1.6302891933458676,
      "attention_bam_16_attention_center_y": 0.46722850274073097,
      "attention_bam_16_attention_center_x": 0.4726225600128221,
      "attention_bam_16_attention_center_distance": 0.0603903179800505,
      "attention_bam_16_attention_spatial_variance": 42.731619994285516,
      "attention_bam_16_attention_spatial_std": 6.536942710035443,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 9.472756669202571,
      "attention_bam_16_peak_intensity_mean": 0.3320062458515167,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 915,
      "phase": "train",
      "loss": 0.0070985532365739346,
      "timestamp": 1759544047.0955427,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0070985532365739346,
      "ssim": 0.9013243317604065,
      "attention_bam_384_mean_attention": -0.029175177216529846,
      "attention_bam_384_std_attention": 0.1467677652835846,
      "attention_bam_384_max_attention": 0.9982027411460876,
      "attention_bam_384_min_attention": -0.7042555809020996,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7941750981753657,
      "attention_bam_384_attention_skewness": 0.14888124685885723,
      "attention_bam_384_attention_sparsity": 0.8277689615885416,
      "attention_bam_384_attention_concentration_10": -0.8092479083602699,
      "attention_bam_384_attention_concentration_20": -1.2021173395695919,
      "attention_bam_384_attention_center_y": 0.48192772314403487,
      "attention_bam_384_attention_center_x": 0.4827421638173279,
      "attention_bam_384_attention_center_distance": 0.03533949916075778,
      "attention_bam_384_attention_spatial_variance": 170.64571605774051,
      "attention_bam_384_attention_spatial_std": 13.063143421770294,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 18.005495384395758,
      "attention_bam_384_peak_intensity_mean": 0.39866241812705994,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12841859459877014,
      "attention_bam_16_std_attention": 0.5260564088821411,
      "attention_bam_16_max_attention": 2.098400831222534,
      "attention_bam_16_min_attention": -1.043835163116455,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.1791502842691033,
      "attention_bam_16_attention_skewness": 0.40647048894008353,
      "attention_bam_16_attention_sparsity": 0.511962890625,
      "attention_bam_16_attention_concentration_10": 0.8769044094153728,
      "attention_bam_16_attention_concentration_20": 1.4243611007632877,
      "attention_bam_16_attention_center_y": 0.4577576478145545,
      "attention_bam_16_attention_center_x": 0.4612766198787376,
      "attention_bam_16_attention_center_distance": 0.08104216786556231,
      "attention_bam_16_attention_spatial_variance": 42.60193863493223,
      "attention_bam_16_attention_spatial_std": 6.527016059037409,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.17602497226368,
      "attention_bam_16_peak_intensity_mean": 0.3783113360404968,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 916,
      "phase": "train",
      "loss": 0.007071693893522024,
      "timestamp": 1759544047.2557259,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007071693893522024,
      "ssim": 0.918044924736023,
      "attention_bam_384_mean_attention": -0.02921709604561329,
      "attention_bam_384_std_attention": 0.1317937970161438,
      "attention_bam_384_max_attention": 0.9769054055213928,
      "attention_bam_384_min_attention": -0.5934345722198486,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9896999363868253,
      "attention_bam_384_attention_skewness": 0.2638331908191608,
      "attention_bam_384_attention_sparsity": 0.8549550374348959,
      "attention_bam_384_attention_concentration_10": -0.7332975359390665,
      "attention_bam_384_attention_concentration_20": -1.0702493982468366,
      "attention_bam_384_attention_center_y": 0.4824708530845804,
      "attention_bam_384_attention_center_x": 0.4826550735902853,
      "attention_bam_384_attention_center_distance": 0.03487455988943182,
      "attention_bam_384_attention_spatial_variance": 171.7075679381419,
      "attention_bam_384_attention_spatial_std": 13.103723437944724,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 19.02671513121679,
      "attention_bam_384_peak_intensity_mean": 0.3643849194049835,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.11572211980819702,
      "attention_bam_16_std_attention": 0.47979333996772766,
      "attention_bam_16_max_attention": 2.417330265045166,
      "attention_bam_16_min_attention": -0.9402467012405396,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.4530650071129414,
      "attention_bam_16_attention_skewness": 0.6107602388206024,
      "attention_bam_16_attention_sparsity": 0.526611328125,
      "attention_bam_16_attention_concentration_10": 0.9056719177555974,
      "attention_bam_16_attention_concentration_20": 1.449086013582649,
      "attention_bam_16_attention_center_y": 0.4621561373300771,
      "attention_bam_16_attention_center_x": 0.4617068318483762,
      "attention_bam_16_attention_center_distance": 0.07613835654738708,
      "attention_bam_16_attention_spatial_variance": 43.503134683635025,
      "attention_bam_16_attention_spatial_std": 6.595690614608528,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 10.847755280557035,
      "attention_bam_16_peak_intensity_mean": 0.3311153054237366,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 917,
      "phase": "train",
      "loss": 0.004142126068472862,
      "timestamp": 1759544047.4143193,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004142126068472862,
      "ssim": 0.9290987253189087,
      "attention_bam_384_mean_attention": -0.029694287106394768,
      "attention_bam_384_std_attention": 0.13992129266262054,
      "attention_bam_384_max_attention": 1.1583610773086548,
      "attention_bam_384_min_attention": -0.7597436904907227,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8047000878322237,
      "attention_bam_384_attention_skewness": 0.32605663943034746,
      "attention_bam_384_attention_sparsity": 0.8514556884765625,
      "attention_bam_384_attention_concentration_10": -0.7673164192969746,
      "attention_bam_384_attention_concentration_20": -1.1065887263496892,
      "attention_bam_384_attention_center_y": 0.4838072175115186,
      "attention_bam_384_attention_center_x": 0.48522777861970945,
      "attention_bam_384_attention_center_distance": 0.030997571815469114,
      "attention_bam_384_attention_spatial_variance": 170.97048342218883,
      "attention_bam_384_attention_spatial_std": 13.075568187355715,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 18.681878486574746,
      "attention_bam_384_peak_intensity_mean": 0.38270729780197144,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12306035310029984,
      "attention_bam_16_std_attention": 0.504349946975708,
      "attention_bam_16_max_attention": 2.786093235015869,
      "attention_bam_16_min_attention": -1.0706162452697754,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.839503278947463,
      "attention_bam_16_attention_skewness": 0.6793278655623318,
      "attention_bam_16_attention_sparsity": 0.5205078125,
      "attention_bam_16_attention_concentration_10": 0.9043097180214398,
      "attention_bam_16_attention_concentration_20": 1.424199520450218,
      "attention_bam_16_attention_center_y": 0.46971619473541765,
      "attention_bam_16_attention_center_x": 0.4745297679438899,
      "attention_bam_16_attention_center_distance": 0.055961443553490364,
      "attention_bam_16_attention_spatial_variance": 42.67762544719948,
      "attention_bam_16_attention_spatial_std": 6.532811450455269,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 10.289237344860496,
      "attention_bam_16_peak_intensity_mean": 0.31358760595321655,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 918,
      "phase": "train",
      "loss": 0.004369507543742657,
      "timestamp": 1759544047.5782359,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004369507543742657,
      "ssim": 0.9250180125236511,
      "attention_bam_384_mean_attention": -0.02970425970852375,
      "attention_bam_384_std_attention": 0.13928167521953583,
      "attention_bam_384_max_attention": 1.0176628828048706,
      "attention_bam_384_min_attention": -0.7144899368286133,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9719443917962369,
      "attention_bam_384_attention_skewness": 0.2396010722244697,
      "attention_bam_384_attention_sparsity": 0.8444697062174479,
      "attention_bam_384_attention_concentration_10": -0.7629316128952485,
      "attention_bam_384_attention_concentration_20": -1.1162617997645947,
      "attention_bam_384_attention_center_y": 0.4819487208942867,
      "attention_bam_384_attention_center_x": 0.48290269589255624,
      "attention_bam_384_attention_center_distance": 0.03516152684667646,
      "attention_bam_384_attention_spatial_variance": 170.27035181104512,
      "attention_bam_384_attention_spatial_std": 13.048768210488111,
      "attention_bam_384_num_attention_peaks": 20,
      "attention_bam_384_peak_separation_mean": 16.70557739955864,
      "attention_bam_384_peak_intensity_mean": 0.4014252722263336,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12774133682250977,
      "attention_bam_16_std_attention": 0.5022013783454895,
      "attention_bam_16_max_attention": 2.3193624019622803,
      "attention_bam_16_min_attention": -1.0400090217590332,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.4605498444802074,
      "attention_bam_16_attention_skewness": 0.6306569949531601,
      "attention_bam_16_attention_sparsity": 0.521240234375,
      "attention_bam_16_attention_concentration_10": 0.8722898461159264,
      "attention_bam_16_attention_concentration_20": 1.3852627261365824,
      "attention_bam_16_attention_center_y": 0.45931782674640564,
      "attention_bam_16_attention_center_x": 0.4619578751744368,
      "attention_bam_16_attention_center_distance": 0.07876855313993267,
      "attention_bam_16_attention_spatial_variance": 42.02577287431179,
      "attention_bam_16_attention_spatial_std": 6.482728813880139,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 8.202018662167704,
      "attention_bam_16_peak_intensity_mean": 0.35593852400779724,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 919,
      "phase": "train",
      "loss": 0.007000477984547615,
      "timestamp": 1759544047.752728,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007000477984547615,
      "ssim": 0.9169827699661255,
      "attention_bam_384_mean_attention": -0.02919657714664936,
      "attention_bam_384_std_attention": 0.13437753915786743,
      "attention_bam_384_max_attention": 0.8019528388977051,
      "attention_bam_384_min_attention": -0.6780624389648438,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.5442583016056521,
      "attention_bam_384_attention_skewness": 0.00010109082774465878,
      "attention_bam_384_attention_sparsity": 0.8454767862955729,
      "attention_bam_384_attention_concentration_10": -0.712295111600178,
      "attention_bam_384_attention_concentration_20": -1.0675544898208915,
      "attention_bam_384_attention_center_y": 0.48319787708973344,
      "attention_bam_384_attention_center_x": 0.4816707839552091,
      "attention_bam_384_attention_center_distance": 0.03516451322308681,
      "attention_bam_384_attention_spatial_variance": 169.51612284386587,
      "attention_bam_384_attention_spatial_std": 13.01983574565616,
      "attention_bam_384_num_attention_peaks": 23,
      "attention_bam_384_peak_separation_mean": 16.280627831044875,
      "attention_bam_384_peak_intensity_mean": 0.4437798261642456,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12656787037849426,
      "attention_bam_16_std_attention": 0.47755470871925354,
      "attention_bam_16_max_attention": 1.9161555767059326,
      "attention_bam_16_min_attention": -0.972201943397522,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.21880347313695747,
      "attention_bam_16_attention_skewness": 0.27108024535248504,
      "attention_bam_16_attention_sparsity": 0.4951171875,
      "attention_bam_16_attention_concentration_10": 0.7854762388435209,
      "attention_bam_16_attention_concentration_20": 1.3004269218355706,
      "attention_bam_16_attention_center_y": 0.4700723964692914,
      "attention_bam_16_attention_center_x": 0.4540251814468491,
      "attention_bam_16_attention_center_distance": 0.07758022163008339,
      "attention_bam_16_attention_spatial_variance": 41.07964952615367,
      "attention_bam_16_attention_spatial_std": 6.409340802777901,
      "attention_bam_16_num_attention_peaks": 12,
      "attention_bam_16_peak_separation_mean": 7.40420494749568,
      "attention_bam_16_peak_intensity_mean": 0.3939497470855713,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 920,
      "phase": "train",
      "loss": 0.0025824818294495344,
      "timestamp": 1759544047.9585342,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0025824818294495344,
      "ssim": 0.9555091857910156,
      "attention_bam_384_mean_attention": -0.029491154477000237,
      "attention_bam_384_std_attention": 0.15230132639408112,
      "attention_bam_384_max_attention": 0.7617729902267456,
      "attention_bam_384_min_attention": -0.6668860912322998,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6969822926548903,
      "attention_bam_384_attention_skewness": 0.13469930232488805,
      "attention_bam_384_attention_sparsity": 0.8256072998046875,
      "attention_bam_384_attention_concentration_10": -0.8461439932798902,
      "attention_bam_384_attention_concentration_20": -1.2456867356822157,
      "attention_bam_384_attention_center_y": 0.48560175464344474,
      "attention_bam_384_attention_center_x": 0.4843479140968828,
      "attention_bam_384_attention_center_distance": 0.03007647793429691,
      "attention_bam_384_attention_spatial_variance": 171.3918119648434,
      "attention_bam_384_attention_spatial_std": 13.091669563689859,
      "attention_bam_384_num_attention_peaks": 18,
      "attention_bam_384_peak_separation_mean": 18.561065243997504,
      "attention_bam_384_peak_intensity_mean": 0.44974151253700256,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12367101013660431,
      "attention_bam_16_std_attention": 0.5319119691848755,
      "attention_bam_16_max_attention": 1.7841687202453613,
      "attention_bam_16_min_attention": -0.9904493093490601,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.237737237125061,
      "attention_bam_16_attention_skewness": 0.3962971826653995,
      "attention_bam_16_attention_sparsity": 0.51611328125,
      "attention_bam_16_attention_concentration_10": 0.922813049229435,
      "attention_bam_16_attention_concentration_20": 1.4893129291496348,
      "attention_bam_16_attention_center_y": 0.4766162190350451,
      "attention_bam_16_attention_center_x": 0.46902710111338075,
      "attention_bam_16_attention_center_distance": 0.05488390798144256,
      "attention_bam_16_attention_spatial_variance": 43.37033411834029,
      "attention_bam_16_attention_spatial_std": 6.585615697741578,
      "attention_bam_16_num_attention_peaks": 12,
      "attention_bam_16_peak_separation_mean": 9.754631436460896,
      "attention_bam_16_peak_intensity_mean": 0.40870001912117004,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 921,
      "phase": "train",
      "loss": 0.0030579199083149433,
      "timestamp": 1759544048.119256,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0030579199083149433,
      "ssim": 0.9393858313560486,
      "attention_bam_384_mean_attention": -0.02933993749320507,
      "attention_bam_384_std_attention": 0.11675550043582916,
      "attention_bam_384_max_attention": 0.7356393933296204,
      "attention_bam_384_min_attention": -0.6429303884506226,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2307469738497128,
      "attention_bam_384_attention_skewness": 0.09587518354878805,
      "attention_bam_384_attention_sparsity": 0.8873748779296875,
      "attention_bam_384_attention_concentration_10": -0.6244633509288059,
      "attention_bam_384_attention_concentration_20": -0.8956258767811808,
      "attention_bam_384_attention_center_y": 0.4830937422123561,
      "attention_bam_384_attention_center_x": 0.484234479047733,
      "attention_bam_384_attention_center_distance": 0.03269168711702226,
      "attention_bam_384_attention_spatial_variance": 171.03984900414804,
      "attention_bam_384_attention_spatial_std": 13.078220406620622,
      "attention_bam_384_num_attention_peaks": 21,
      "attention_bam_384_peak_separation_mean": 18.701794844957156,
      "attention_bam_384_peak_intensity_mean": 0.44863665103912354,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12144884467124939,
      "attention_bam_16_std_attention": 0.43506309390068054,
      "attention_bam_16_max_attention": 1.6966081857681274,
      "attention_bam_16_min_attention": -0.9445371627807617,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.17083562963193888,
      "attention_bam_16_attention_skewness": 0.3923938979732997,
      "attention_bam_16_attention_sparsity": 0.50439453125,
      "attention_bam_16_attention_concentration_10": 0.7864246369359378,
      "attention_bam_16_attention_concentration_20": 1.2562297752442033,
      "attention_bam_16_attention_center_y": 0.46550164347143536,
      "attention_bam_16_attention_center_x": 0.4684238245617431,
      "attention_bam_16_attention_center_distance": 0.06613911790278938,
      "attention_bam_16_attention_spatial_variance": 42.81350772890191,
      "attention_bam_16_attention_spatial_std": 6.5432031703823705,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.124235895505613,
      "attention_bam_16_peak_intensity_mean": 0.40963494777679443,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 922,
      "phase": "train",
      "loss": 0.004316645674407482,
      "timestamp": 1759544048.267216,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004316645674407482,
      "ssim": 0.9126814007759094,
      "attention_bam_384_mean_attention": -0.029645755887031555,
      "attention_bam_384_std_attention": 0.134893536567688,
      "attention_bam_384_max_attention": 1.3673675060272217,
      "attention_bam_384_min_attention": -0.8604466915130615,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.62424836773798,
      "attention_bam_384_attention_skewness": 0.4082767082959097,
      "attention_bam_384_attention_sparsity": 0.8620071411132812,
      "attention_bam_384_attention_concentration_10": -0.7418949618493755,
      "attention_bam_384_attention_concentration_20": -1.059954135719574,
      "attention_bam_384_attention_center_y": 0.4823269783292608,
      "attention_bam_384_attention_center_x": 0.48438144702679464,
      "attention_bam_384_attention_center_distance": 0.033354906444217146,
      "attention_bam_384_attention_spatial_variance": 170.2475827372799,
      "attention_bam_384_attention_spatial_std": 13.04789572066239,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 20.237791411565098,
      "attention_bam_384_peak_intensity_mean": 0.3767402768135071,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1165047287940979,
      "attention_bam_16_std_attention": 0.48934799432754517,
      "attention_bam_16_max_attention": 2.7856712341308594,
      "attention_bam_16_min_attention": -1.2358176708221436,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.0210032167887944,
      "attention_bam_16_attention_skewness": 0.7491161392737171,
      "attention_bam_16_attention_sparsity": 0.53955078125,
      "attention_bam_16_attention_concentration_10": 0.9418746562442518,
      "attention_bam_16_attention_concentration_20": 1.474062416033573,
      "attention_bam_16_attention_center_y": 0.4569627455720655,
      "attention_bam_16_attention_center_x": 0.4712100160184859,
      "attention_bam_16_attention_center_distance": 0.07322661328165608,
      "attention_bam_16_attention_spatial_variance": 42.02719108942615,
      "attention_bam_16_attention_spatial_std": 6.482838197072803,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 10.282361533405052,
      "attention_bam_16_peak_intensity_mean": 0.3499295711517334,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 923,
      "phase": "train",
      "loss": 0.006068381480872631,
      "timestamp": 1759544048.4101605,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006068381480872631,
      "ssim": 0.909406304359436,
      "attention_bam_384_mean_attention": -0.030471282079815865,
      "attention_bam_384_std_attention": 0.148391991853714,
      "attention_bam_384_max_attention": 1.0042051076889038,
      "attention_bam_384_min_attention": -0.7247405052185059,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8570669476556487,
      "attention_bam_384_attention_skewness": 0.240940170181457,
      "attention_bam_384_attention_sparsity": 0.8286107381184896,
      "attention_bam_384_attention_concentration_10": -0.7964383469428318,
      "attention_bam_384_attention_concentration_20": -1.173373686433987,
      "attention_bam_384_attention_center_y": 0.4839235225057827,
      "attention_bam_384_attention_center_x": 0.48395302766072423,
      "attention_bam_384_attention_center_distance": 0.03212346338362528,
      "attention_bam_384_attention_spatial_variance": 171.14485878318618,
      "attention_bam_384_attention_spatial_std": 13.082234472107055,
      "attention_bam_384_num_attention_peaks": 18,
      "attention_bam_384_peak_separation_mean": 19.56360258306086,
      "attention_bam_384_peak_intensity_mean": 0.4058268964290619,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12451258301734924,
      "attention_bam_16_std_attention": 0.5294636487960815,
      "attention_bam_16_max_attention": 2.6641387939453125,
      "attention_bam_16_min_attention": -1.010704755783081,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.1749727232155105,
      "attention_bam_16_attention_skewness": 0.5917727181194835,
      "attention_bam_16_attention_sparsity": 0.52294921875,
      "attention_bam_16_attention_concentration_10": 0.9301073325509253,
      "attention_bam_16_attention_concentration_20": 1.4935665801276288,
      "attention_bam_16_attention_center_y": 0.46770870450249497,
      "attention_bam_16_attention_center_x": 0.46832355106404777,
      "attention_bam_16_attention_center_distance": 0.06397069926300912,
      "attention_bam_16_attention_spatial_variance": 43.01815711378311,
      "attention_bam_16_attention_spatial_std": 6.558822845128774,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.394086649568292,
      "attention_bam_16_peak_intensity_mean": 0.3116375505924225,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 924,
      "phase": "train",
      "loss": 0.004736744798719883,
      "timestamp": 1759544048.6019905,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004736744798719883,
      "ssim": 0.9021687507629395,
      "attention_bam_384_mean_attention": -0.029715783894062042,
      "attention_bam_384_std_attention": 0.12927374243736267,
      "attention_bam_384_max_attention": 0.9516862630844116,
      "attention_bam_384_min_attention": -0.7515468597412109,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.187005524634932,
      "attention_bam_384_attention_skewness": 0.12000798279297614,
      "attention_bam_384_attention_sparsity": 0.8632329305013021,
      "attention_bam_384_attention_concentration_10": -0.6795385851672594,
      "attention_bam_384_attention_concentration_20": -0.9963100352657532,
      "attention_bam_384_attention_center_y": 0.48359483716330337,
      "attention_bam_384_attention_center_x": 0.4841670470442061,
      "attention_bam_384_attention_center_distance": 0.03224319360729998,
      "attention_bam_384_attention_spatial_variance": 170.70629582651446,
      "attention_bam_384_attention_spatial_std": 13.065461944627693,
      "attention_bam_384_num_attention_peaks": 25,
      "attention_bam_384_peak_separation_mean": 19.103933275314976,
      "attention_bam_384_peak_intensity_mean": 0.42699211835861206,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1300036609172821,
      "attention_bam_16_std_attention": 0.4581049382686615,
      "attention_bam_16_max_attention": 2.593900442123413,
      "attention_bam_16_min_attention": -1.1524746417999268,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6281638004348888,
      "attention_bam_16_attention_skewness": 0.49861365580935324,
      "attention_bam_16_attention_sparsity": 0.5029296875,
      "attention_bam_16_attention_concentration_10": 0.7662802636783023,
      "attention_bam_16_attention_concentration_20": 1.235934674208754,
      "attention_bam_16_attention_center_y": 0.4666002802888313,
      "attention_bam_16_attention_center_x": 0.4673250764867665,
      "attention_bam_16_attention_center_distance": 0.06607861837811513,
      "attention_bam_16_attention_spatial_variance": 42.41765074978941,
      "attention_bam_16_attention_spatial_std": 6.512883443590051,
      "attention_bam_16_num_attention_peaks": 11,
      "attention_bam_16_peak_separation_mean": 9.588698080691593,
      "attention_bam_16_peak_intensity_mean": 0.34513211250305176,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 925,
      "phase": "train",
      "loss": 0.003986820112913847,
      "timestamp": 1759544048.7993972,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.003986820112913847,
      "ssim": 0.9052562117576599,
      "attention_bam_384_mean_attention": -0.03059714287519455,
      "attention_bam_384_std_attention": 0.13510173559188843,
      "attention_bam_384_max_attention": 0.8744189739227295,
      "attention_bam_384_min_attention": -0.6327093839645386,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2236332025493821,
      "attention_bam_384_attention_skewness": 0.3146732773980192,
      "attention_bam_384_attention_sparsity": 0.854827880859375,
      "attention_bam_384_attention_concentration_10": -0.7259338588031379,
      "attention_bam_384_attention_concentration_20": -1.047376481094231,
      "attention_bam_384_attention_center_y": 0.47910423024049353,
      "attention_bam_384_attention_center_x": 0.48541873674532493,
      "attention_bam_384_attention_center_distance": 0.036034606476120765,
      "attention_bam_384_attention_spatial_variance": 172.31644979371686,
      "attention_bam_384_attention_spatial_std": 13.126936039827301,
      "attention_bam_384_num_attention_peaks": 19,
      "attention_bam_384_peak_separation_mean": 19.71010458774587,
      "attention_bam_384_peak_intensity_mean": 0.40783315896987915,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12928996980190277,
      "attention_bam_16_std_attention": 0.5004175901412964,
      "attention_bam_16_max_attention": 2.2943413257598877,
      "attention_bam_16_min_attention": -1.1020269393920898,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.49729014028463636,
      "attention_bam_16_attention_skewness": 0.6422773829697821,
      "attention_bam_16_attention_sparsity": 0.51904296875,
      "attention_bam_16_attention_concentration_10": 0.866609335565033,
      "attention_bam_16_attention_concentration_20": 1.3715581035095918,
      "attention_bam_16_attention_center_y": 0.45041376827775065,
      "attention_bam_16_attention_center_x": 0.47359182880260475,
      "attention_bam_16_attention_center_distance": 0.07945043590067387,
      "attention_bam_16_attention_spatial_variance": 44.05081766856296,
      "attention_bam_16_attention_spatial_std": 6.637079001229605,
      "attention_bam_16_num_attention_peaks": 13,
      "attention_bam_16_peak_separation_mean": 10.05604924362879,
      "attention_bam_16_peak_intensity_mean": 0.3741236925125122,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 926,
      "phase": "train",
      "loss": 0.0029393061995506287,
      "timestamp": 1759544048.9930406,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0029393061995506287,
      "ssim": 0.9479357004165649,
      "attention_bam_384_mean_attention": -0.03014553338289261,
      "attention_bam_384_std_attention": 0.14550630748271942,
      "attention_bam_384_max_attention": 0.9321521520614624,
      "attention_bam_384_min_attention": -0.7275425791740417,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8782860283105234,
      "attention_bam_384_attention_skewness": 0.21144480402565896,
      "attention_bam_384_attention_sparsity": 0.83197021484375,
      "attention_bam_384_attention_concentration_10": -0.7798049874802626,
      "attention_bam_384_attention_concentration_20": -1.151483560777512,
      "attention_bam_384_attention_center_y": 0.48389120981746164,
      "attention_bam_384_attention_center_x": 0.48438011411405213,
      "attention_bam_384_attention_center_distance": 0.03173244258594278,
      "attention_bam_384_attention_spatial_variance": 171.59439875151193,
      "attention_bam_384_attention_spatial_std": 13.099404518966194,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 20.735993452453858,
      "attention_bam_384_peak_intensity_mean": 0.42542994022369385,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12495334446430206,
      "attention_bam_16_std_attention": 0.5183597207069397,
      "attention_bam_16_max_attention": 2.4907119274139404,
      "attention_bam_16_min_attention": -0.9742847084999084,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.26172364451185004,
      "attention_bam_16_attention_skewness": 0.5809251766506399,
      "attention_bam_16_attention_sparsity": 0.524169921875,
      "attention_bam_16_attention_concentration_10": 0.9045536109456621,
      "attention_bam_16_attention_concentration_20": 1.44977417501264,
      "attention_bam_16_attention_center_y": 0.4677122235125578,
      "attention_bam_16_attention_center_x": 0.4721233326406906,
      "attention_bam_16_attention_center_distance": 0.06032593295697315,
      "attention_bam_16_attention_spatial_variance": 43.65929420114989,
      "attention_bam_16_attention_spatial_std": 6.607518006116207,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 10.70231293196164,
      "attention_bam_16_peak_intensity_mean": 0.31985023617744446,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 927,
      "phase": "train",
      "loss": 0.0029621697030961514,
      "timestamp": 1759544049.19146,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0029621697030961514,
      "ssim": 0.9484544992446899,
      "attention_bam_384_mean_attention": -0.030182352289557457,
      "attention_bam_384_std_attention": 0.1495160162448883,
      "attention_bam_384_max_attention": 1.034677267074585,
      "attention_bam_384_min_attention": -0.7341045141220093,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9759231943932845,
      "attention_bam_384_attention_skewness": 0.2771004787628888,
      "attention_bam_384_attention_sparsity": 0.8306452433268229,
      "attention_bam_384_attention_concentration_10": -0.8202369452208916,
      "attention_bam_384_attention_concentration_20": -1.197793963970459,
      "attention_bam_384_attention_center_y": 0.4841342326037412,
      "attention_bam_384_attention_center_x": 0.48147810526081913,
      "attention_bam_384_attention_center_distance": 0.03449009016519046,
      "attention_bam_384_attention_spatial_variance": 170.76395085825277,
      "attention_bam_384_attention_spatial_std": 13.067668149224358,
      "attention_bam_384_num_attention_peaks": 11,
      "attention_bam_384_peak_separation_mean": 18.695772988833234,
      "attention_bam_384_peak_intensity_mean": 0.40048930048942566,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12505625188350677,
      "attention_bam_16_std_attention": 0.5381520390510559,
      "attention_bam_16_max_attention": 2.3695573806762695,
      "attention_bam_16_min_attention": -1.052724838256836,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.3563301545501414,
      "attention_bam_16_attention_skewness": 0.6771797445265636,
      "attention_bam_16_attention_sparsity": 0.525634765625,
      "attention_bam_16_attention_concentration_10": 0.9598989941048603,
      "attention_bam_16_attention_concentration_20": 1.5156951249426616,
      "attention_bam_16_attention_center_y": 0.47006042604901577,
      "attention_bam_16_attention_center_x": 0.45553305092914925,
      "attention_bam_16_attention_center_distance": 0.07581144567987194,
      "attention_bam_16_attention_spatial_variance": 42.363055204578565,
      "attention_bam_16_attention_spatial_std": 6.508690744272505,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.460375398578119,
      "attention_bam_16_peak_intensity_mean": 0.3452286720275879,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 928,
      "phase": "train",
      "loss": 0.00755207147449255,
      "timestamp": 1759544049.3796866,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00755207147449255,
      "ssim": 0.8930288553237915,
      "attention_bam_384_mean_attention": -0.029845861718058586,
      "attention_bam_384_std_attention": 0.13666625320911407,
      "attention_bam_384_max_attention": 0.9668951034545898,
      "attention_bam_384_min_attention": -0.7755353450775146,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0493521364112093,
      "attention_bam_384_attention_skewness": 0.1397415279447095,
      "attention_bam_384_attention_sparsity": 0.8494415283203125,
      "attention_bam_384_attention_concentration_10": -0.7258815475497782,
      "attention_bam_384_attention_concentration_20": -1.0666279121735507,
      "attention_bam_384_attention_center_y": 0.48390026911171696,
      "attention_bam_384_attention_center_x": 0.48314338815677427,
      "attention_bam_384_attention_center_distance": 0.03296503291393209,
      "attention_bam_384_attention_spatial_variance": 171.2861498237888,
      "attention_bam_384_attention_spatial_std": 13.087633469187193,
      "attention_bam_384_num_attention_peaks": 18,
      "attention_bam_384_peak_separation_mean": 18.9314529068452,
      "attention_bam_384_peak_intensity_mean": 0.4331826865673065,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13373276591300964,
      "attention_bam_16_std_attention": 0.49876585602760315,
      "attention_bam_16_max_attention": 2.4866394996643066,
      "attention_bam_16_min_attention": -1.0916770696640015,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.2970017965378422,
      "attention_bam_16_attention_skewness": 0.4847264985381644,
      "attention_bam_16_attention_sparsity": 0.50830078125,
      "attention_bam_16_attention_concentration_10": 0.8096620214960203,
      "attention_bam_16_attention_concentration_20": 1.3048659034416492,
      "attention_bam_16_attention_center_y": 0.4675537517667017,
      "attention_bam_16_attention_center_x": 0.46370589478181745,
      "attention_bam_16_attention_center_distance": 0.06884796435633107,
      "attention_bam_16_attention_spatial_variance": 43.06093697170541,
      "attention_bam_16_attention_spatial_std": 6.562083279851408,
      "attention_bam_16_num_attention_peaks": 12,
      "attention_bam_16_peak_separation_mean": 9.161905420760208,
      "attention_bam_16_peak_intensity_mean": 0.3508859872817993,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 929,
      "phase": "train",
      "loss": 0.0061677442863583565,
      "timestamp": 1759544049.5585265,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0061677442863583565,
      "ssim": 0.8773403167724609,
      "attention_bam_384_mean_attention": -0.03029274195432663,
      "attention_bam_384_std_attention": 0.1454877257347107,
      "attention_bam_384_max_attention": 1.126816987991333,
      "attention_bam_384_min_attention": -0.795059084892273,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2808803933129989,
      "attention_bam_384_attention_skewness": 0.23614361470512368,
      "attention_bam_384_attention_sparsity": 0.8402964274088541,
      "attention_bam_384_attention_concentration_10": -0.7831232036751247,
      "attention_bam_384_attention_concentration_20": -1.1386481080633746,
      "attention_bam_384_attention_center_y": 0.4816768859327386,
      "attention_bam_384_attention_center_x": 0.4833889291544698,
      "attention_bam_384_attention_center_distance": 0.03497611138354565,
      "attention_bam_384_attention_spatial_variance": 171.48838315656207,
      "attention_bam_384_attention_spatial_std": 13.095357313054198,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 20.528477798026483,
      "attention_bam_384_peak_intensity_mean": 0.40397727489471436,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13124510645866394,
      "attention_bam_16_std_attention": 0.5144748091697693,
      "attention_bam_16_max_attention": 2.3509063720703125,
      "attention_bam_16_min_attention": -1.0830845832824707,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.34878285161169,
      "attention_bam_16_attention_skewness": 0.5712067688419831,
      "attention_bam_16_attention_sparsity": 0.515869140625,
      "attention_bam_16_attention_concentration_10": 0.8587162837853776,
      "attention_bam_16_attention_concentration_20": 1.3753959882619495,
      "attention_bam_16_attention_center_y": 0.454774872782165,
      "attention_bam_16_attention_center_x": 0.46393514238794226,
      "attention_bam_16_attention_center_distance": 0.0818044752620217,
      "attention_bam_16_attention_spatial_variance": 43.25880642640609,
      "attention_bam_16_attention_spatial_std": 6.57714272510534,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 8.745025174588637,
      "attention_bam_16_peak_intensity_mean": 0.3659939765930176,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 930,
      "phase": "train",
      "loss": 0.004808565601706505,
      "timestamp": 1759544049.994084,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004808565601706505,
      "ssim": 0.9131062030792236,
      "attention_bam_384_mean_attention": -0.029954366385936737,
      "attention_bam_384_std_attention": 0.1391681730747223,
      "attention_bam_384_max_attention": 1.1633480787277222,
      "attention_bam_384_min_attention": -0.7872363328933716,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8581827505861952,
      "attention_bam_384_attention_skewness": 0.333119334182471,
      "attention_bam_384_attention_sparsity": 0.8570963541666666,
      "attention_bam_384_attention_concentration_10": -0.7715864753666235,
      "attention_bam_384_attention_concentration_20": -1.096034472796015,
      "attention_bam_384_attention_center_y": 0.4816193404099662,
      "attention_bam_384_attention_center_x": 0.48233215542593505,
      "attention_bam_384_attention_center_distance": 0.03605555099726028,
      "attention_bam_384_attention_spatial_variance": 171.76030095752458,
      "attention_bam_384_attention_spatial_std": 13.105735422231161,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 19.544368729056313,
      "attention_bam_384_peak_intensity_mean": 0.3913531005382538,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12817558646202087,
      "attention_bam_16_std_attention": 0.5085711479187012,
      "attention_bam_16_max_attention": 2.6040966510772705,
      "attention_bam_16_min_attention": -1.1365771293640137,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.0116906590580346,
      "attention_bam_16_attention_skewness": 0.7133043777853062,
      "attention_bam_16_attention_sparsity": 0.5166015625,
      "attention_bam_16_attention_concentration_10": 0.8884190344131767,
      "attention_bam_16_attention_concentration_20": 1.3919078723310796,
      "attention_bam_16_attention_center_y": 0.45574597478394985,
      "attention_bam_16_attention_center_x": 0.4593385986017392,
      "attention_bam_16_attention_center_distance": 0.08499139146399814,
      "attention_bam_16_attention_spatial_variance": 44.05885121086192,
      "attention_bam_16_attention_spatial_std": 6.637684175287486,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 10.868471730727244,
      "attention_bam_16_peak_intensity_mean": 0.35103750228881836,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 931,
      "phase": "train",
      "loss": 0.0033873110078275204,
      "timestamp": 1759544050.1387417,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0033873110078275204,
      "ssim": 0.9448273777961731,
      "attention_bam_384_mean_attention": -0.030580716207623482,
      "attention_bam_384_std_attention": 0.14727284014225006,
      "attention_bam_384_max_attention": 1.2619324922561646,
      "attention_bam_384_min_attention": -0.741990864276886,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4807344173575192,
      "attention_bam_384_attention_skewness": 0.40405343766259133,
      "attention_bam_384_attention_sparsity": 0.83636474609375,
      "attention_bam_384_attention_concentration_10": -0.8001392464149241,
      "attention_bam_384_attention_concentration_20": -1.1600190296404078,
      "attention_bam_384_attention_center_y": 0.48537830197473986,
      "attention_bam_384_attention_center_x": 0.48361382440313655,
      "attention_bam_384_attention_center_distance": 0.03105803612056434,
      "attention_bam_384_attention_spatial_variance": 171.30675464415683,
      "attention_bam_384_attention_spatial_std": 13.08842063215256,
      "attention_bam_384_num_attention_peaks": 18,
      "attention_bam_384_peak_separation_mean": 19.91795879822298,
      "attention_bam_384_peak_intensity_mean": 0.36121803522109985,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1163681298494339,
      "attention_bam_16_std_attention": 0.5262134671211243,
      "attention_bam_16_max_attention": 2.693166732788086,
      "attention_bam_16_min_attention": -1.0725483894348145,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.0634263641845507,
      "attention_bam_16_attention_skewness": 0.8383426375734249,
      "attention_bam_16_attention_sparsity": 0.547607421875,
      "attention_bam_16_attention_concentration_10": 1.010871607067387,
      "attention_bam_16_attention_concentration_20": 1.5822787938151388,
      "attention_bam_16_attention_center_y": 0.47548468106844344,
      "attention_bam_16_attention_center_x": 0.46440325906692115,
      "attention_bam_16_attention_center_distance": 0.06112493480360804,
      "attention_bam_16_attention_spatial_variance": 43.09492345082687,
      "attention_bam_16_attention_spatial_std": 6.564672379550016,
      "attention_bam_16_num_attention_peaks": 11,
      "attention_bam_16_peak_separation_mean": 9.69766266651647,
      "attention_bam_16_peak_intensity_mean": 0.3287290334701538,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 932,
      "phase": "train",
      "loss": 0.004441344644874334,
      "timestamp": 1759544050.2846704,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004441344644874334,
      "ssim": 0.9184747934341431,
      "attention_bam_384_mean_attention": -0.030394626781344414,
      "attention_bam_384_std_attention": 0.12879937887191772,
      "attention_bam_384_max_attention": 0.849745512008667,
      "attention_bam_384_min_attention": -0.7164309620857239,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0515857770071086,
      "attention_bam_384_attention_skewness": 0.14741319236934694,
      "attention_bam_384_attention_sparsity": 0.8656209309895834,
      "attention_bam_384_attention_concentration_10": -0.6704668622196267,
      "attention_bam_384_attention_concentration_20": -0.9746822586743303,
      "attention_bam_384_attention_center_y": 0.485087288936978,
      "attention_bam_384_attention_center_x": 0.4828378136855351,
      "attention_bam_384_attention_center_distance": 0.03215368067085278,
      "attention_bam_384_attention_spatial_variance": 171.27007432227427,
      "attention_bam_384_attention_spatial_std": 13.087019306254357,
      "attention_bam_384_num_attention_peaks": 10,
      "attention_bam_384_peak_separation_mean": 18.373050033376053,
      "attention_bam_384_peak_intensity_mean": 0.44339579343795776,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13869690895080566,
      "attention_bam_16_std_attention": 0.4699121415615082,
      "attention_bam_16_max_attention": 2.375127077102661,
      "attention_bam_16_min_attention": -0.9412636756896973,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.37435050475131915,
      "attention_bam_16_attention_skewness": 0.562692437996094,
      "attention_bam_16_attention_sparsity": 0.501953125,
      "attention_bam_16_attention_concentration_10": 0.7603550874230347,
      "attention_bam_16_attention_concentration_20": 1.2157117391322043,
      "attention_bam_16_attention_center_y": 0.47655260919695386,
      "attention_bam_16_attention_center_x": 0.4649021784545551,
      "attention_bam_16_attention_center_distance": 0.05969316900126291,
      "attention_bam_16_attention_spatial_variance": 43.1162795959172,
      "attention_bam_16_attention_spatial_std": 6.56629877449368,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.796697262989925,
      "attention_bam_16_peak_intensity_mean": 0.3377379775047302,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 933,
      "phase": "train",
      "loss": 0.003912101965397596,
      "timestamp": 1759544050.4558988,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.003912101965397596,
      "ssim": 0.935668408870697,
      "attention_bam_384_mean_attention": -0.03052409738302231,
      "attention_bam_384_std_attention": 0.14838089048862457,
      "attention_bam_384_max_attention": 0.9242700934410095,
      "attention_bam_384_min_attention": -0.6864088773727417,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.930790492490305,
      "attention_bam_384_attention_skewness": 0.13507510383869836,
      "attention_bam_384_attention_sparsity": 0.8319091796875,
      "attention_bam_384_attention_concentration_10": -0.7783481311982077,
      "attention_bam_384_attention_concentration_20": -1.1471506941275766,
      "attention_bam_384_attention_center_y": 0.48427433187606617,
      "attention_bam_384_attention_center_x": 0.48348156156770505,
      "attention_bam_384_attention_center_distance": 0.03225385081461211,
      "attention_bam_384_attention_spatial_variance": 170.83833784540388,
      "attention_bam_384_attention_spatial_std": 13.070514062017756,
      "attention_bam_384_num_attention_peaks": 24,
      "attention_bam_384_peak_separation_mean": 18.84624242157079,
      "attention_bam_384_peak_intensity_mean": 0.412134051322937,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1319824755191803,
      "attention_bam_16_std_attention": 0.530689537525177,
      "attention_bam_16_max_attention": 2.1703946590423584,
      "attention_bam_16_min_attention": -1.0315687656402588,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.005775419314171248,
      "attention_bam_16_attention_skewness": 0.4769998518440206,
      "attention_bam_16_attention_sparsity": 0.5107421875,
      "attention_bam_16_attention_concentration_10": 0.8782177515651246,
      "attention_bam_16_attention_concentration_20": 1.4107912731468744,
      "attention_bam_16_attention_center_y": 0.4696855535517923,
      "attention_bam_16_attention_center_x": 0.46498924236816097,
      "attention_bam_16_attention_center_distance": 0.06549379838452837,
      "attention_bam_16_attention_spatial_variance": 42.559303543143336,
      "attention_bam_16_attention_spatial_std": 6.523749193764528,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.392940754827572,
      "attention_bam_16_peak_intensity_mean": 0.3713501989841461,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 934,
      "phase": "train",
      "loss": 0.0034826991613954306,
      "timestamp": 1759544050.6542544,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0034826991613954306,
      "ssim": 0.940497875213623,
      "attention_bam_384_mean_attention": -0.030560528859496117,
      "attention_bam_384_std_attention": 0.13819929957389832,
      "attention_bam_384_max_attention": 1.012364387512207,
      "attention_bam_384_min_attention": -0.7190974950790405,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0185145450893884,
      "attention_bam_384_attention_skewness": 0.15790681432265724,
      "attention_bam_384_attention_sparsity": 0.8502909342447916,
      "attention_bam_384_attention_concentration_10": -0.7254675914291385,
      "attention_bam_384_attention_concentration_20": -1.057567092668475,
      "attention_bam_384_attention_center_y": 0.48293216498351293,
      "attention_bam_384_attention_center_x": 0.4844899512926803,
      "attention_bam_384_attention_center_distance": 0.03261510702277248,
      "attention_bam_384_attention_spatial_variance": 171.53622533141248,
      "attention_bam_384_attention_spatial_std": 13.097183870260526,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 20.734686972391,
      "attention_bam_384_peak_intensity_mean": 0.4038546085357666,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13309675455093384,
      "attention_bam_16_std_attention": 0.5081779956817627,
      "attention_bam_16_max_attention": 2.094853639602661,
      "attention_bam_16_min_attention": -1.0253862142562866,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.17952698483370355,
      "attention_bam_16_attention_skewness": 0.5273984187090387,
      "attention_bam_16_attention_sparsity": 0.51123046875,
      "attention_bam_16_attention_concentration_10": 0.8435039317030775,
      "attention_bam_16_attention_concentration_20": 1.3495999539383778,
      "attention_bam_16_attention_center_y": 0.46406427780201004,
      "attention_bam_16_attention_center_x": 0.4723800977885139,
      "attention_bam_16_attention_center_distance": 0.06409734983699657,
      "attention_bam_16_attention_spatial_variance": 43.51288643289814,
      "attention_bam_16_attention_spatial_std": 6.5964298247535496,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 10.807128060882178,
      "attention_bam_16_peak_intensity_mean": 0.38669759035110474,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 935,
      "phase": "train",
      "loss": 0.002974593546241522,
      "timestamp": 1759544050.8520913,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.002974593546241522,
      "ssim": 0.9539556503295898,
      "attention_bam_384_mean_attention": -0.030896492302417755,
      "attention_bam_384_std_attention": 0.1382714807987213,
      "attention_bam_384_max_attention": 0.9230629205703735,
      "attention_bam_384_min_attention": -0.6484227180480957,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7757659664146277,
      "attention_bam_384_attention_skewness": 0.18975147930281258,
      "attention_bam_384_attention_sparsity": 0.8443857828776041,
      "attention_bam_384_attention_concentration_10": -0.717700497831438,
      "attention_bam_384_attention_concentration_20": -1.0571443223957184,
      "attention_bam_384_attention_center_y": 0.4820165168389171,
      "attention_bam_384_attention_center_x": 0.48521094440683893,
      "attention_bam_384_attention_center_distance": 0.03292785544011515,
      "attention_bam_384_attention_spatial_variance": 171.7506154062877,
      "attention_bam_384_attention_spatial_std": 13.105365901274473,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 22.780101380488816,
      "attention_bam_384_peak_intensity_mean": 0.39901426434516907,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13061080873012543,
      "attention_bam_16_std_attention": 0.4883986711502075,
      "attention_bam_16_max_attention": 2.02567458152771,
      "attention_bam_16_min_attention": -0.9875043630599976,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.08425441147197921,
      "attention_bam_16_attention_skewness": 0.5604144283720608,
      "attention_bam_16_attention_sparsity": 0.52001953125,
      "attention_bam_16_attention_concentration_10": 0.8358427808722636,
      "attention_bam_16_attention_concentration_20": 1.3413109175492333,
      "attention_bam_16_attention_center_y": 0.461366669088314,
      "attention_bam_16_attention_center_x": 0.4747908420904527,
      "attention_bam_16_attention_center_distance": 0.06523857600898914,
      "attention_bam_16_attention_spatial_variance": 43.679888400444824,
      "attention_bam_16_attention_spatial_std": 6.609076213847501,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 10.587771917594251,
      "attention_bam_16_peak_intensity_mean": 0.37891989946365356,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 936,
      "phase": "train",
      "loss": 0.005156265571713448,
      "timestamp": 1759544051.0487702,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005156265571713448,
      "ssim": 0.9416850209236145,
      "attention_bam_384_mean_attention": -0.030985742807388306,
      "attention_bam_384_std_attention": 0.12519963085651398,
      "attention_bam_384_max_attention": 0.9352497458457947,
      "attention_bam_384_min_attention": -0.664260745048523,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.6441183727979194,
      "attention_bam_384_attention_skewness": 0.37087248081479324,
      "attention_bam_384_attention_sparsity": 0.8745473225911459,
      "attention_bam_384_attention_concentration_10": -0.6496889995186677,
      "attention_bam_384_attention_concentration_20": -0.9318767719308594,
      "attention_bam_384_attention_center_y": 0.48428573072581343,
      "attention_bam_384_attention_center_x": 0.48377963620948394,
      "attention_bam_384_attention_center_distance": 0.03193864306191884,
      "attention_bam_384_attention_spatial_variance": 172.0206372268544,
      "attention_bam_384_attention_spatial_std": 13.115663811902714,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 19.183332772617312,
      "attention_bam_384_peak_intensity_mean": 0.40246137976646423,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13771174848079681,
      "attention_bam_16_std_attention": 0.4589099884033203,
      "attention_bam_16_max_attention": 2.489112138748169,
      "attention_bam_16_min_attention": -1.0350139141082764,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7276867080935485,
      "attention_bam_16_attention_skewness": 0.6954335184368861,
      "attention_bam_16_attention_sparsity": 0.5146484375,
      "attention_bam_16_attention_concentration_10": 0.7656672559038843,
      "attention_bam_16_attention_concentration_20": 1.211056021292406,
      "attention_bam_16_attention_center_y": 0.46863471812253754,
      "attention_bam_16_attention_center_x": 0.4677760992199179,
      "attention_bam_16_attention_center_distance": 0.06359497918448043,
      "attention_bam_16_attention_spatial_variance": 43.76618788938155,
      "attention_bam_16_attention_spatial_std": 6.615601853904265,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.565466067124834,
      "attention_bam_16_peak_intensity_mean": 0.33923280239105225,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 937,
      "phase": "train",
      "loss": 0.007097368594259024,
      "timestamp": 1759544051.240684,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007097368594259024,
      "ssim": 0.9131734371185303,
      "attention_bam_384_mean_attention": -0.031367938965559006,
      "attention_bam_384_std_attention": 0.11942974478006363,
      "attention_bam_384_max_attention": 1.4104020595550537,
      "attention_bam_384_min_attention": -0.6701405644416809,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.7055689436344652,
      "attention_bam_384_attention_skewness": 0.2204271224183301,
      "attention_bam_384_attention_sparsity": 0.8872146606445312,
      "attention_bam_384_attention_concentration_10": -0.5915964656706089,
      "attention_bam_384_attention_concentration_20": -0.8479121801375002,
      "attention_bam_384_attention_center_y": 0.48312914030368925,
      "attention_bam_384_attention_center_x": 0.48484843700890706,
      "attention_bam_384_attention_center_distance": 0.03206854433757975,
      "attention_bam_384_attention_spatial_variance": 171.10052487929826,
      "attention_bam_384_attention_spatial_std": 13.080539930725271,
      "attention_bam_384_num_attention_peaks": 20,
      "attention_bam_384_peak_separation_mean": 19.56944050101612,
      "attention_bam_384_peak_intensity_mean": 0.31083664298057556,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.14692527055740356,
      "attention_bam_16_std_attention": 0.4321105480194092,
      "attention_bam_16_max_attention": 2.5987260341644287,
      "attention_bam_16_min_attention": -1.0516893863677979,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6919379492502564,
      "attention_bam_16_attention_skewness": 0.5148042555636585,
      "attention_bam_16_attention_sparsity": 0.486328125,
      "attention_bam_16_attention_concentration_10": 0.6652040550040236,
      "attention_bam_16_attention_concentration_20": 1.068382030467477,
      "attention_bam_16_attention_center_y": 0.4644865529123064,
      "attention_bam_16_attention_center_x": 0.4735792241702822,
      "attention_bam_16_attention_center_distance": 0.06259812009149497,
      "attention_bam_16_attention_spatial_variance": 42.87514091822167,
      "attention_bam_16_attention_spatial_std": 6.547911187410964,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.055836155472402,
      "attention_bam_16_peak_intensity_mean": 0.3320983946323395,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 938,
      "phase": "train",
      "loss": 0.0033355229534208775,
      "timestamp": 1759544051.42389,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0033355229534208775,
      "ssim": 0.9406392574310303,
      "attention_bam_384_mean_attention": -0.031574491411447525,
      "attention_bam_384_std_attention": 0.12667705118656158,
      "attention_bam_384_max_attention": 1.0509027242660522,
      "attention_bam_384_min_attention": -0.6871874332427979,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.212756629582504,
      "attention_bam_384_attention_skewness": 0.22732928821142565,
      "attention_bam_384_attention_sparsity": 0.8702901204427084,
      "attention_bam_384_attention_concentration_10": -0.6331708271694977,
      "attention_bam_384_attention_concentration_20": -0.9167554759807721,
      "attention_bam_384_attention_center_y": 0.48294356900371604,
      "attention_bam_384_attention_center_x": 0.4830857516469465,
      "attention_bam_384_attention_center_distance": 0.03397097689733897,
      "attention_bam_384_attention_spatial_variance": 171.8519662710016,
      "attention_bam_384_attention_spatial_std": 13.109232100737312,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 16.904201180561632,
      "attention_bam_384_peak_intensity_mean": 0.3841666877269745,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13364103436470032,
      "attention_bam_16_std_attention": 0.46799901127815247,
      "attention_bam_16_max_attention": 2.4954354763031006,
      "attention_bam_16_min_attention": -0.9687641263008118,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5526112820807918,
      "attention_bam_16_attention_skewness": 0.5897117736358999,
      "attention_bam_16_attention_sparsity": 0.5087890625,
      "attention_bam_16_attention_concentration_10": 0.7826616563745422,
      "attention_bam_16_attention_concentration_20": 1.2549925304989065,
      "attention_bam_16_attention_center_y": 0.4657088652158838,
      "attention_bam_16_attention_center_x": 0.46506550047756673,
      "attention_bam_16_attention_center_distance": 0.06922862387286512,
      "attention_bam_16_attention_spatial_variance": 43.60243361994025,
      "attention_bam_16_attention_spatial_std": 6.603213885672662,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.999523237998753,
      "attention_bam_16_peak_intensity_mean": 0.3230457305908203,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 939,
      "phase": "train",
      "loss": 0.0031849928200244904,
      "timestamp": 1759544051.5982456,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0031849928200244904,
      "ssim": 0.9487942457199097,
      "attention_bam_384_mean_attention": -0.030799701809883118,
      "attention_bam_384_std_attention": 0.1556268185377121,
      "attention_bam_384_max_attention": 1.4123300313949585,
      "attention_bam_384_min_attention": -0.7090833783149719,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2706451631771474,
      "attention_bam_384_attention_skewness": 0.35972468593374457,
      "attention_bam_384_attention_sparsity": 0.8247044881184896,
      "attention_bam_384_attention_concentration_10": -0.8464337418459031,
      "attention_bam_384_attention_concentration_20": -1.2306720472646027,
      "attention_bam_384_attention_center_y": 0.47713997317797574,
      "attention_bam_384_attention_center_x": 0.4788748609179198,
      "attention_bam_384_attention_center_distance": 0.04401936681827444,
      "attention_bam_384_attention_spatial_variance": 171.11754829463626,
      "attention_bam_384_attention_spatial_std": 13.081190629856147,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 19.28020035963776,
      "attention_bam_384_peak_intensity_mean": 0.3310520350933075,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12237844616174698,
      "attention_bam_16_std_attention": 0.5542089939117432,
      "attention_bam_16_max_attention": 2.3390347957611084,
      "attention_bam_16_min_attention": -1.0705335140228271,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.4028697670570289,
      "attention_bam_16_attention_skewness": 0.6857758753728369,
      "attention_bam_16_attention_sparsity": 0.549072265625,
      "attention_bam_16_attention_concentration_10": 1.009023669906801,
      "attention_bam_16_attention_concentration_20": 1.6004951368469829,
      "attention_bam_16_attention_center_y": 0.4378479939292397,
      "attention_bam_16_attention_center_x": 0.4418976279845596,
      "attention_bam_16_attention_center_distance": 0.12032254562167854,
      "attention_bam_16_attention_spatial_variance": 42.275395000212754,
      "attention_bam_16_attention_spatial_std": 6.501953168103624,
      "attention_bam_16_num_attention_peaks": 3,
      "attention_bam_16_peak_separation_mean": 5.428889929254869,
      "attention_bam_16_peak_intensity_mean": 0.38079676032066345,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 940,
      "phase": "train",
      "loss": 0.004825184587389231,
      "timestamp": 1759544051.8022845,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004825184587389231,
      "ssim": 0.9332391619682312,
      "attention_bam_384_mean_attention": -0.031031973659992218,
      "attention_bam_384_std_attention": 0.14117802679538727,
      "attention_bam_384_max_attention": 0.9648364782333374,
      "attention_bam_384_min_attention": -0.6369627714157104,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0689851078254167,
      "attention_bam_384_attention_skewness": 0.27962591277144117,
      "attention_bam_384_attention_sparsity": 0.8452173868815104,
      "attention_bam_384_attention_concentration_10": -0.7427441890734174,
      "attention_bam_384_attention_concentration_20": -1.0795700050340484,
      "attention_bam_384_attention_center_y": 0.48076497162986204,
      "attention_bam_384_attention_center_x": 0.48244144253439974,
      "attention_bam_384_attention_center_distance": 0.03683175957438902,
      "attention_bam_384_attention_spatial_variance": 171.06943364510732,
      "attention_bam_384_attention_spatial_std": 13.079351422953177,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 20.088367174570546,
      "attention_bam_384_peak_intensity_mean": 0.3882019519805908,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12944373488426208,
      "attention_bam_16_std_attention": 0.5132972002029419,
      "attention_bam_16_max_attention": 2.187826156616211,
      "attention_bam_16_min_attention": -0.9606942534446716,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.2712095105764005,
      "attention_bam_16_attention_skewness": 0.5831628793938457,
      "attention_bam_16_attention_sparsity": 0.510986328125,
      "attention_bam_16_attention_concentration_10": 0.8774046480814556,
      "attention_bam_16_attention_concentration_20": 1.3932119248871146,
      "attention_bam_16_attention_center_y": 0.4533456046490347,
      "attention_bam_16_attention_center_x": 0.46255847033035136,
      "attention_bam_16_attention_center_distance": 0.08459906322847026,
      "attention_bam_16_attention_spatial_variance": 43.02944507732422,
      "attention_bam_16_attention_spatial_std": 6.55968330617601,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 9.59820591769232,
      "attention_bam_16_peak_intensity_mean": 0.37211889028549194,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 941,
      "phase": "train",
      "loss": 0.004748997278511524,
      "timestamp": 1759544051.96393,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004748997278511524,
      "ssim": 0.9291159510612488,
      "attention_bam_384_mean_attention": -0.031435441225767136,
      "attention_bam_384_std_attention": 0.1393377035856247,
      "attention_bam_384_max_attention": 1.082364559173584,
      "attention_bam_384_min_attention": -0.6929406523704529,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8965734067912017,
      "attention_bam_384_attention_skewness": 0.4558151065764865,
      "attention_bam_384_attention_sparsity": 0.8588485717773438,
      "attention_bam_384_attention_concentration_10": -0.7428165776705365,
      "attention_bam_384_attention_concentration_20": -1.0483103367073643,
      "attention_bam_384_attention_center_y": 0.4852352431047077,
      "attention_bam_384_attention_center_x": 0.4836960331485698,
      "attention_bam_384_attention_center_distance": 0.031106828230136732,
      "attention_bam_384_attention_spatial_variance": 172.23716575739982,
      "attention_bam_384_attention_spatial_std": 13.12391579359605,
      "attention_bam_384_num_attention_peaks": 19,
      "attention_bam_384_peak_separation_mean": 21.535282886469016,
      "attention_bam_384_peak_intensity_mean": 0.3831964433193207,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1303325891494751,
      "attention_bam_16_std_attention": 0.5124824643135071,
      "attention_bam_16_max_attention": 2.719249725341797,
      "attention_bam_16_min_attention": -1.0616954565048218,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7765372062139462,
      "attention_bam_16_attention_skewness": 0.7025423634801268,
      "attention_bam_16_attention_sparsity": 0.526123046875,
      "attention_bam_16_attention_concentration_10": 0.8852883768283891,
      "attention_bam_16_attention_concentration_20": 1.3901544531066055,
      "attention_bam_16_attention_center_y": 0.4740406913111398,
      "attention_bam_16_attention_center_x": 0.4671236139758535,
      "attention_bam_16_attention_center_distance": 0.05924090589469792,
      "attention_bam_16_attention_spatial_variance": 43.80111166091383,
      "attention_bam_16_attention_spatial_std": 6.618240828265003,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 10.711459405854445,
      "attention_bam_16_peak_intensity_mean": 0.3285432457923889,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 942,
      "phase": "train",
      "loss": 0.003340137889608741,
      "timestamp": 1759544052.1217875,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.003340137889608741,
      "ssim": 0.9291762709617615,
      "attention_bam_384_mean_attention": -0.030878955498337746,
      "attention_bam_384_std_attention": 0.13613881170749664,
      "attention_bam_384_max_attention": 1.0421082973480225,
      "attention_bam_384_min_attention": -0.702234148979187,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.7386468412663536,
      "attention_bam_384_attention_skewness": 0.5066347700798995,
      "attention_bam_384_attention_sparsity": 0.8609898885091146,
      "attention_bam_384_attention_concentration_10": -0.742150044517405,
      "attention_bam_384_attention_concentration_20": -1.048847911813377,
      "attention_bam_384_attention_center_y": 0.4861459221470207,
      "attention_bam_384_attention_center_x": 0.4844500151157407,
      "attention_bam_384_attention_center_distance": 0.02945292865088647,
      "attention_bam_384_attention_spatial_variance": 171.44275865498258,
      "attention_bam_384_attention_spatial_std": 13.093615186608417,
      "attention_bam_384_num_attention_peaks": 21,
      "attention_bam_384_peak_separation_mean": 20.456161362626176,
      "attention_bam_384_peak_intensity_mean": 0.3942317068576813,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.11527838557958603,
      "attention_bam_16_std_attention": 0.52036052942276,
      "attention_bam_16_max_attention": 2.8111443519592285,
      "attention_bam_16_min_attention": -1.0535776615142822,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.3322087655915427,
      "attention_bam_16_attention_skewness": 0.876931955714023,
      "attention_bam_16_attention_sparsity": 0.5458984375,
      "attention_bam_16_attention_concentration_10": 1.0060505145626273,
      "attention_bam_16_attention_concentration_20": 1.5750106818885146,
      "attention_bam_16_attention_center_y": 0.47968916095960823,
      "attention_bam_16_attention_center_x": 0.47185575526046203,
      "attention_bam_16_attention_center_distance": 0.04908418675059643,
      "attention_bam_16_attention_spatial_variance": 43.17204596632372,
      "attention_bam_16_attention_spatial_std": 6.570543810547474,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 10.916850916204917,
      "attention_bam_16_peak_intensity_mean": 0.31549733877182007,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 943,
      "phase": "train",
      "loss": 0.004012828227132559,
      "timestamp": 1759544052.2791047,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004012828227132559,
      "ssim": 0.9264074563980103,
      "attention_bam_384_mean_attention": -0.030459553003311157,
      "attention_bam_384_std_attention": 0.1148872822523117,
      "attention_bam_384_max_attention": 0.913710355758667,
      "attention_bam_384_min_attention": -0.607639729976654,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.979743049755406,
      "attention_bam_384_attention_skewness": 0.37122272925223004,
      "attention_bam_384_attention_sparsity": 0.896148681640625,
      "attention_bam_384_attention_concentration_10": -0.6000890283255161,
      "attention_bam_384_attention_concentration_20": -0.845386524313372,
      "attention_bam_384_attention_center_y": 0.4875013515387624,
      "attention_bam_384_attention_center_x": 0.48575264464956697,
      "attention_bam_384_attention_center_distance": 0.026803109813568645,
      "attention_bam_384_attention_spatial_variance": 172.00971432860487,
      "attention_bam_384_attention_spatial_std": 13.115247398680852,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 21.04231437585182,
      "attention_bam_384_peak_intensity_mean": 0.39125728607177734,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12024956196546555,
      "attention_bam_16_std_attention": 0.4581253230571747,
      "attention_bam_16_max_attention": 2.5986533164978027,
      "attention_bam_16_min_attention": -0.9489819407463074,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7531623193361154,
      "attention_bam_16_attention_skewness": 0.67954670981746,
      "attention_bam_16_attention_sparsity": 0.525146484375,
      "attention_bam_16_attention_concentration_10": 0.8540500605076181,
      "attention_bam_16_attention_concentration_20": 1.3454562104430272,
      "attention_bam_16_attention_center_y": 0.4859397421568341,
      "attention_bam_16_attention_center_x": 0.47928274778727203,
      "attention_bam_16_attention_center_distance": 0.03540890819729097,
      "attention_bam_16_attention_spatial_variance": 43.655477871311305,
      "attention_bam_16_attention_spatial_std": 6.607229212863082,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 10.56708721824362,
      "attention_bam_16_peak_intensity_mean": 0.32227522134780884,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 944,
      "phase": "train",
      "loss": 0.0035679135471582413,
      "timestamp": 1759544052.429127,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0035679135471582413,
      "ssim": 0.9300198554992676,
      "attention_bam_384_mean_attention": -0.03038366138935089,
      "attention_bam_384_std_attention": 0.13753551244735718,
      "attention_bam_384_max_attention": 1.1801751852035522,
      "attention_bam_384_min_attention": -0.7081049084663391,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.7713758063559286,
      "attention_bam_384_attention_skewness": 0.3511349275018988,
      "attention_bam_384_attention_sparsity": 0.8558273315429688,
      "attention_bam_384_attention_concentration_10": -0.7427202932666938,
      "attention_bam_384_attention_concentration_20": -1.0658598874398966,
      "attention_bam_384_attention_center_y": 0.4802074659668783,
      "attention_bam_384_attention_center_x": 0.48108049101815453,
      "attention_bam_384_attention_center_distance": 0.0387218858932881,
      "attention_bam_384_attention_spatial_variance": 171.75499625999376,
      "attention_bam_384_attention_spatial_std": 13.105533039903175,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 19.573225809496208,
      "attention_bam_384_peak_intensity_mean": 0.3687187433242798,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.11981769651174545,
      "attention_bam_16_std_attention": 0.5174654722213745,
      "attention_bam_16_max_attention": 2.137131929397583,
      "attention_bam_16_min_attention": -1.0280219316482544,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.3241130920953088,
      "attention_bam_16_attention_skewness": 0.6462501085195994,
      "attention_bam_16_attention_sparsity": 0.529296875,
      "attention_bam_16_attention_concentration_10": 0.9556604825215389,
      "attention_bam_16_attention_concentration_20": 1.5145934881161016,
      "attention_bam_16_attention_center_y": 0.4477307567392366,
      "attention_bam_16_attention_center_x": 0.45549585173000406,
      "attention_bam_16_attention_center_distance": 0.09708442721972087,
      "attention_bam_16_attention_spatial_variance": 43.285917632767095,
      "attention_bam_16_attention_spatial_std": 6.579203419318109,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.794992691748527,
      "attention_bam_16_peak_intensity_mean": 0.37670329213142395,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 945,
      "phase": "train",
      "loss": 0.00368448905646801,
      "timestamp": 1759544052.573171,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00368448905646801,
      "ssim": 0.950316309928894,
      "attention_bam_384_mean_attention": -0.03085814230144024,
      "attention_bam_384_std_attention": 0.1404486745595932,
      "attention_bam_384_max_attention": 1.0894540548324585,
      "attention_bam_384_min_attention": -0.6897674798965454,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5713198653264984,
      "attention_bam_384_attention_skewness": 0.40216088981611897,
      "attention_bam_384_attention_sparsity": 0.8506902058919271,
      "attention_bam_384_attention_concentration_10": -0.7551424214595868,
      "attention_bam_384_attention_concentration_20": -1.0830698015297138,
      "attention_bam_384_attention_center_y": 0.4856804240366899,
      "attention_bam_384_attention_center_x": 0.484422972935687,
      "attention_bam_384_attention_center_distance": 0.029923035538907124,
      "attention_bam_384_attention_spatial_variance": 171.48630916697928,
      "attention_bam_384_attention_spatial_std": 13.09527812484253,
      "attention_bam_384_num_attention_peaks": 21,
      "attention_bam_384_peak_separation_mean": 20.578694771852334,
      "attention_bam_384_peak_intensity_mean": 0.3795652985572815,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.11303141713142395,
      "attention_bam_16_std_attention": 0.5187952518463135,
      "attention_bam_16_max_attention": 3.0804665088653564,
      "attention_bam_16_min_attention": -1.0379369258880615,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.6410697537040821,
      "attention_bam_16_attention_skewness": 0.940299689469663,
      "attention_bam_16_attention_sparsity": 0.54296875,
      "attention_bam_16_attention_concentration_10": 1.037437989486399,
      "attention_bam_16_attention_concentration_20": 1.596379101424768,
      "attention_bam_16_attention_center_y": 0.4782228612963958,
      "attention_bam_16_attention_center_x": 0.47259550722755794,
      "attention_bam_16_attention_center_distance": 0.04950252507157276,
      "attention_bam_16_attention_spatial_variance": 43.53625015634236,
      "attention_bam_16_attention_spatial_std": 6.598200524108249,
      "attention_bam_16_num_attention_peaks": 12,
      "attention_bam_16_peak_separation_mean": 9.613666725243496,
      "attention_bam_16_peak_intensity_mean": 0.2901945114135742,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 946,
      "phase": "train",
      "loss": 0.0039059296250343323,
      "timestamp": 1759544052.720725,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0039059296250343323,
      "ssim": 0.926383912563324,
      "attention_bam_384_mean_attention": -0.030394762754440308,
      "attention_bam_384_std_attention": 0.12853708863258362,
      "attention_bam_384_max_attention": 0.8773233294487,
      "attention_bam_384_min_attention": -0.689143717288971,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9501316578340684,
      "attention_bam_384_attention_skewness": 0.22428185427890668,
      "attention_bam_384_attention_sparsity": 0.8614832560221354,
      "attention_bam_384_attention_concentration_10": -0.675355851037796,
      "attention_bam_384_attention_concentration_20": -0.9872243831547753,
      "attention_bam_384_attention_center_y": 0.4819757669179278,
      "attention_bam_384_attention_center_x": 0.48243693669079935,
      "attention_bam_384_attention_center_distance": 0.03559028437649397,
      "attention_bam_384_attention_spatial_variance": 171.85113652541406,
      "attention_bam_384_attention_spatial_std": 13.109200453323385,
      "attention_bam_384_num_attention_peaks": 20,
      "attention_bam_384_peak_separation_mean": 19.381142114250373,
      "attention_bam_384_peak_intensity_mean": 0.42872247099876404,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.11027148365974426,
      "attention_bam_16_std_attention": 0.4863296151161194,
      "attention_bam_16_max_attention": 2.244819164276123,
      "attention_bam_16_min_attention": -0.9867717027664185,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.08475403516726265,
      "attention_bam_16_attention_skewness": 0.5480017614905889,
      "attention_bam_16_attention_sparsity": 0.533447265625,
      "attention_bam_16_attention_concentration_10": 0.961060682982438,
      "attention_bam_16_attention_concentration_20": 1.5377064438781014,
      "attention_bam_16_attention_center_y": 0.45928952796656464,
      "attention_bam_16_attention_center_x": 0.46081162896510236,
      "attention_bam_16_attention_center_distance": 0.0799133400322365,
      "attention_bam_16_attention_spatial_variance": 43.79528238095731,
      "attention_bam_16_attention_spatial_std": 6.617800418640419,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 9.481764005077242,
      "attention_bam_16_peak_intensity_mean": 0.3564787805080414,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 947,
      "phase": "train",
      "loss": 0.007739026099443436,
      "timestamp": 1759544052.892832,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007739026099443436,
      "ssim": 0.8710352182388306,
      "attention_bam_384_mean_attention": -0.030289018526673317,
      "attention_bam_384_std_attention": 0.1253066211938858,
      "attention_bam_384_max_attention": 0.9734821915626526,
      "attention_bam_384_min_attention": -0.6597445607185364,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.3822380068363174,
      "attention_bam_384_attention_skewness": 0.1846032452583815,
      "attention_bam_384_attention_sparsity": 0.8757044474283854,
      "attention_bam_384_attention_concentration_10": -0.6507863253194838,
      "attention_bam_384_attention_concentration_20": -0.9375950416415916,
      "attention_bam_384_attention_center_y": 0.4837920795635327,
      "attention_bam_384_attention_center_x": 0.48323264467855337,
      "attention_bam_384_attention_center_distance": 0.032980020902070355,
      "attention_bam_384_attention_spatial_variance": 171.65509223465278,
      "attention_bam_384_attention_spatial_std": 13.101720964615785,
      "attention_bam_384_num_attention_peaks": 25,
      "attention_bam_384_peak_separation_mean": 17.212536816350024,
      "attention_bam_384_peak_intensity_mean": 0.38969185948371887,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1194215938448906,
      "attention_bam_16_std_attention": 0.4633280038833618,
      "attention_bam_16_max_attention": 2.1599791049957275,
      "attention_bam_16_min_attention": -0.9403467178344727,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.1489133340116071,
      "attention_bam_16_attention_skewness": 0.5011265817621193,
      "attention_bam_16_attention_sparsity": 0.5234375,
      "attention_bam_16_attention_concentration_10": 0.8493421247423222,
      "attention_bam_16_attention_concentration_20": 1.3639164500193606,
      "attention_bam_16_attention_center_y": 0.47076066495906754,
      "attention_bam_16_attention_center_x": 0.4656802029334558,
      "attention_bam_16_attention_center_distance": 0.06376185669073128,
      "attention_bam_16_attention_spatial_variance": 43.506718315446626,
      "attention_bam_16_attention_spatial_std": 6.595962273652467,
      "attention_bam_16_num_attention_peaks": 11,
      "attention_bam_16_peak_separation_mean": 9.215068104190657,
      "attention_bam_16_peak_intensity_mean": 0.34934595227241516,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 948,
      "phase": "train",
      "loss": 0.0035217469558119774,
      "timestamp": 1759544053.084381,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0035217469558119774,
      "ssim": 0.9311527609825134,
      "attention_bam_384_mean_attention": -0.030386636033654213,
      "attention_bam_384_std_attention": 0.13837237656116486,
      "attention_bam_384_max_attention": 0.9635544419288635,
      "attention_bam_384_min_attention": -0.6757606267929077,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4164457030437854,
      "attention_bam_384_attention_skewness": 0.338411010051456,
      "attention_bam_384_attention_sparsity": 0.8558756510416666,
      "attention_bam_384_attention_concentration_10": -0.7550773680959655,
      "attention_bam_384_attention_concentration_20": -1.0778066632915382,
      "attention_bam_384_attention_center_y": 0.48314447159980045,
      "attention_bam_384_attention_center_x": 0.4809332208510462,
      "attention_bam_384_attention_center_distance": 0.03599030160376303,
      "attention_bam_384_attention_spatial_variance": 171.14527005171092,
      "attention_bam_384_attention_spatial_std": 13.082250190686269,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 19.68287441101264,
      "attention_bam_384_peak_intensity_mean": 0.39988598227500916,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13039124011993408,
      "attention_bam_16_std_attention": 0.5167856812477112,
      "attention_bam_16_max_attention": 2.4773526191711426,
      "attention_bam_16_min_attention": -0.9674886465072632,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5580251637912554,
      "attention_bam_16_attention_skewness": 0.690756384978784,
      "attention_bam_16_attention_sparsity": 0.517578125,
      "attention_bam_16_attention_concentration_10": 0.886878760379481,
      "attention_bam_16_attention_concentration_20": 1.3954515034923365,
      "attention_bam_16_attention_center_y": 0.4641324196589126,
      "attention_bam_16_attention_center_x": 0.45236982309004187,
      "attention_bam_16_attention_center_distance": 0.08432220433549241,
      "attention_bam_16_attention_spatial_variance": 42.791246737422334,
      "attention_bam_16_attention_spatial_std": 6.541501871697533,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.27998161125783,
      "attention_bam_16_peak_intensity_mean": 0.324196457862854,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 949,
      "phase": "train",
      "loss": 0.007178175263106823,
      "timestamp": 1759544053.2690542,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007178175263106823,
      "ssim": 0.9210162162780762,
      "attention_bam_384_mean_attention": -0.029887722805142403,
      "attention_bam_384_std_attention": 0.14400134980678558,
      "attention_bam_384_max_attention": 0.8762993216514587,
      "attention_bam_384_min_attention": -0.6234251260757446,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.3228311416427956,
      "attention_bam_384_attention_skewness": 0.16431488400674846,
      "attention_bam_384_attention_sparsity": 0.8227691650390625,
      "attention_bam_384_attention_concentration_10": -0.7650715404123064,
      "attention_bam_384_attention_concentration_20": -1.155308783074022,
      "attention_bam_384_attention_center_y": 0.4842625702355382,
      "attention_bam_384_attention_center_x": 0.4866665012357217,
      "attention_bam_384_attention_center_distance": 0.029170152035544114,
      "attention_bam_384_attention_spatial_variance": 172.73921248696024,
      "attention_bam_384_attention_spatial_std": 13.143029045351769,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 22.813796288227852,
      "attention_bam_384_peak_intensity_mean": 0.4048185646533966,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12263265252113342,
      "attention_bam_16_std_attention": 0.5307376384735107,
      "attention_bam_16_max_attention": 1.9295676946640015,
      "attention_bam_16_min_attention": -1.0491619110107422,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.25733044853893894,
      "attention_bam_16_attention_skewness": 0.47752127673576544,
      "attention_bam_16_attention_sparsity": 0.523193359375,
      "attention_bam_16_attention_concentration_10": 0.9292081351615031,
      "attention_bam_16_attention_concentration_20": 1.510587335800059,
      "attention_bam_16_attention_center_y": 0.4696624230830735,
      "attention_bam_16_attention_center_x": 0.4780503478614104,
      "attention_bam_16_attention_center_distance": 0.0529557513816115,
      "attention_bam_16_attention_spatial_variance": 44.56813834859326,
      "attention_bam_16_attention_spatial_std": 6.6759372636801535,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 11.572354811278393,
      "attention_bam_16_peak_intensity_mean": 0.42548221349716187,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 950,
      "phase": "train",
      "loss": 0.007303660735487938,
      "timestamp": 1759544053.5055654,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007303660735487938,
      "ssim": 0.9313552379608154,
      "attention_bam_384_mean_attention": -0.029701871797442436,
      "attention_bam_384_std_attention": 0.13045059144496918,
      "attention_bam_384_max_attention": 0.864708423614502,
      "attention_bam_384_min_attention": -0.6751134395599365,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9307720886684105,
      "attention_bam_384_attention_skewness": 0.08441515607800361,
      "attention_bam_384_attention_sparsity": 0.8582967122395834,
      "attention_bam_384_attention_concentration_10": -0.6936873811259588,
      "attention_bam_384_attention_concentration_20": -1.0189195198190464,
      "attention_bam_384_attention_center_y": 0.4827304302247748,
      "attention_bam_384_attention_center_x": 0.484173292732138,
      "attention_bam_384_attention_center_distance": 0.03312771356927513,
      "attention_bam_384_attention_spatial_variance": 171.41923550417127,
      "attention_bam_384_attention_spatial_std": 13.092716887803359,
      "attention_bam_384_num_attention_peaks": 27,
      "attention_bam_384_peak_separation_mean": 21.02286358000516,
      "attention_bam_384_peak_intensity_mean": 0.4232315123081207,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13477066159248352,
      "attention_bam_16_std_attention": 0.49012207984924316,
      "attention_bam_16_max_attention": 1.9628740549087524,
      "attention_bam_16_min_attention": -1.0665761232376099,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.02418305312776159,
      "attention_bam_16_attention_skewness": 0.42195486864875686,
      "attention_bam_16_attention_sparsity": 0.5068359375,
      "attention_bam_16_attention_concentration_10": 0.7951851695276251,
      "attention_bam_16_attention_concentration_20": 1.2856454657537415,
      "attention_bam_16_attention_center_y": 0.46298931469937044,
      "attention_bam_16_attention_center_x": 0.46745013501227944,
      "attention_bam_16_attention_center_distance": 0.06970343660309833,
      "attention_bam_16_attention_spatial_variance": 43.35999284975984,
      "attention_bam_16_attention_spatial_std": 6.584830510329012,
      "attention_bam_16_num_attention_peaks": 11,
      "attention_bam_16_peak_separation_mean": 10.362109613453532,
      "attention_bam_16_peak_intensity_mean": 0.400847464799881,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 951,
      "phase": "train",
      "loss": 0.005097568966448307,
      "timestamp": 1759544053.675866,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005097568966448307,
      "ssim": 0.9214839935302734,
      "attention_bam_384_mean_attention": -0.02966182492673397,
      "attention_bam_384_std_attention": 0.13356876373291016,
      "attention_bam_384_max_attention": 0.9314823150634766,
      "attention_bam_384_min_attention": -0.6319442987442017,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4685278133119901,
      "attention_bam_384_attention_skewness": 0.3825553008707194,
      "attention_bam_384_attention_sparsity": 0.8603490193684896,
      "attention_bam_384_attention_concentration_10": -0.7406517626269096,
      "attention_bam_384_attention_concentration_20": -1.0624957926661325,
      "attention_bam_384_attention_center_y": 0.48307738539356165,
      "attention_bam_384_attention_center_x": 0.4837281430353803,
      "attention_bam_384_attention_center_distance": 0.033200849814276824,
      "attention_bam_384_attention_spatial_variance": 171.4205064121165,
      "attention_bam_384_attention_spatial_std": 13.09276542263385,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 22.184458602374473,
      "attention_bam_384_peak_intensity_mean": 0.39612844586372375,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.11296942830085754,
      "attention_bam_16_std_attention": 0.4923909306526184,
      "attention_bam_16_max_attention": 2.4211668968200684,
      "attention_bam_16_min_attention": -0.9187602996826172,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8398470577090427,
      "attention_bam_16_attention_skewness": 0.7844552069097425,
      "attention_bam_16_attention_sparsity": 0.540283203125,
      "attention_bam_16_attention_concentration_10": 0.979633173927716,
      "attention_bam_16_attention_concentration_20": 1.5308249958449054,
      "attention_bam_16_attention_center_y": 0.46409305652514304,
      "attention_bam_16_attention_center_x": 0.4691932187881523,
      "attention_bam_16_attention_center_distance": 0.06690839048043563,
      "attention_bam_16_attention_spatial_variance": 43.22629252518866,
      "attention_bam_16_attention_spatial_std": 6.574670525979888,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 9.403134693526718,
      "attention_bam_16_peak_intensity_mean": 0.31184911727905273,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 952,
      "phase": "train",
      "loss": 0.00429533701390028,
      "timestamp": 1759544053.8416002,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00429533701390028,
      "ssim": 0.9329856038093567,
      "attention_bam_384_mean_attention": -0.0297891553491354,
      "attention_bam_384_std_attention": 0.1375018209218979,
      "attention_bam_384_max_attention": 0.9584794044494629,
      "attention_bam_384_min_attention": -0.6209771037101746,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2151921869499454,
      "attention_bam_384_attention_skewness": 0.348836793401874,
      "attention_bam_384_attention_sparsity": 0.8501154581705729,
      "attention_bam_384_attention_concentration_10": -0.7667741196992082,
      "attention_bam_384_attention_concentration_20": -1.1074979961989324,
      "attention_bam_384_attention_center_y": 0.4825224373578178,
      "attention_bam_384_attention_center_x": 0.482692607810451,
      "attention_bam_384_attention_center_distance": 0.03478537107216955,
      "attention_bam_384_attention_spatial_variance": 171.8975107022526,
      "attention_bam_384_attention_spatial_std": 13.110969098516424,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 19.430996325852178,
      "attention_bam_384_peak_intensity_mean": 0.3818431496620178,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1175757572054863,
      "attention_bam_16_std_attention": 0.5198214054107666,
      "attention_bam_16_max_attention": 2.3364503383636475,
      "attention_bam_16_min_attention": -0.9801797866821289,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.42954680530538925,
      "attention_bam_16_attention_skewness": 0.6928486787037283,
      "attention_bam_16_attention_sparsity": 0.53955078125,
      "attention_bam_16_attention_concentration_10": 0.987498503694559,
      "attention_bam_16_attention_concentration_20": 1.5543157609856895,
      "attention_bam_16_attention_center_y": 0.4588644052147834,
      "attention_bam_16_attention_center_x": 0.459903165312006,
      "attention_bam_16_attention_center_distance": 0.08123907077668799,
      "attention_bam_16_attention_spatial_variance": 43.636882437523475,
      "attention_bam_16_attention_spatial_std": 6.605821859354328,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.28143229266491,
      "attention_bam_16_peak_intensity_mean": 0.33642759919166565,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 953,
      "phase": "train",
      "loss": 0.006737751420587301,
      "timestamp": 1759544053.9960582,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006737751420587301,
      "ssim": 0.892267107963562,
      "attention_bam_384_mean_attention": -0.029565105214715004,
      "attention_bam_384_std_attention": 0.12472829967737198,
      "attention_bam_384_max_attention": 0.9763230085372925,
      "attention_bam_384_min_attention": -0.7053366899490356,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9179458835160594,
      "attention_bam_384_attention_skewness": 0.0717382336464492,
      "attention_bam_384_attention_sparsity": 0.8693491617838541,
      "attention_bam_384_attention_concentration_10": -0.6539146089831946,
      "attention_bam_384_attention_concentration_20": -0.9601115008437016,
      "attention_bam_384_attention_center_y": 0.4821738531295367,
      "attention_bam_384_attention_center_x": 0.4830570134646989,
      "attention_bam_384_attention_center_distance": 0.03478034804261516,
      "attention_bam_384_attention_spatial_variance": 171.42309394353424,
      "attention_bam_384_attention_spatial_std": 13.09286423757362,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 16.726797227181287,
      "attention_bam_384_peak_intensity_mean": 0.40560317039489746,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12317726761102676,
      "attention_bam_16_std_attention": 0.4521891176700592,
      "attention_bam_16_max_attention": 1.904476523399353,
      "attention_bam_16_min_attention": -1.0016182661056519,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.13901633320490703,
      "attention_bam_16_attention_skewness": 0.41581960023368403,
      "attention_bam_16_attention_sparsity": 0.5107421875,
      "attention_bam_16_attention_concentration_10": 0.8056104757399841,
      "attention_bam_16_attention_concentration_20": 1.2919140898138883,
      "attention_bam_16_attention_center_y": 0.4585626037839982,
      "attention_bam_16_attention_center_x": 0.46522450789512154,
      "attention_bam_16_attention_center_distance": 0.07650349869513659,
      "attention_bam_16_attention_spatial_variance": 43.134579719930976,
      "attention_bam_16_attention_spatial_std": 6.567692115190158,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 9.147753760349492,
      "attention_bam_16_peak_intensity_mean": 0.40896549820899963,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 954,
      "phase": "train",
      "loss": 0.004985923878848553,
      "timestamp": 1759544054.147358,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004985923878848553,
      "ssim": 0.926273763179779,
      "attention_bam_384_mean_attention": -0.029653003439307213,
      "attention_bam_384_std_attention": 0.14247582852840424,
      "attention_bam_384_max_attention": 0.9827969074249268,
      "attention_bam_384_min_attention": -0.655735194683075,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6615543071300398,
      "attention_bam_384_attention_skewness": 0.26900909057640554,
      "attention_bam_384_attention_sparsity": 0.8323109944661459,
      "attention_bam_384_attention_concentration_10": -0.7825742076390085,
      "attention_bam_384_attention_concentration_20": -1.1594110357604948,
      "attention_bam_384_attention_center_y": 0.48295671901553433,
      "attention_bam_384_attention_center_x": 0.4811294953896127,
      "attention_bam_384_attention_center_distance": 0.03596023834643195,
      "attention_bam_384_attention_spatial_variance": 171.56416743425314,
      "attention_bam_384_attention_spatial_std": 13.098250548613473,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 20.701536405005832,
      "attention_bam_384_peak_intensity_mean": 0.38893184065818787,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.10622557997703552,
      "attention_bam_16_std_attention": 0.517827570438385,
      "attention_bam_16_max_attention": 2.142824172973633,
      "attention_bam_16_min_attention": -0.9646410942077637,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.009022316700551425,
      "attention_bam_16_attention_skewness": 0.6093253891494043,
      "attention_bam_16_attention_sparsity": 0.54345703125,
      "attention_bam_16_attention_concentration_10": 1.0507930081605366,
      "attention_bam_16_attention_concentration_20": 1.6876523248382793,
      "attention_bam_16_attention_center_y": 0.46271709108008724,
      "attention_bam_16_attention_center_x": 0.45136656622939647,
      "attention_bam_16_attention_center_distance": 0.08666286607134789,
      "attention_bam_16_attention_spatial_variance": 43.76198150525521,
      "attention_bam_16_attention_spatial_std": 6.6152839323233295,
      "attention_bam_16_num_attention_peaks": 11,
      "attention_bam_16_peak_separation_mean": 11.271650771471732,
      "attention_bam_16_peak_intensity_mean": 0.3593123257160187,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 955,
      "phase": "train",
      "loss": 0.006015223450958729,
      "timestamp": 1759544054.3002949,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006015223450958729,
      "ssim": 0.8910846710205078,
      "attention_bam_384_mean_attention": -0.029650315642356873,
      "attention_bam_384_std_attention": 0.12023311853408813,
      "attention_bam_384_max_attention": 1.0645222663879395,
      "attention_bam_384_min_attention": -0.668816089630127,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5042142059405794,
      "attention_bam_384_attention_skewness": 0.15424102906461792,
      "attention_bam_384_attention_sparsity": 0.8826751708984375,
      "attention_bam_384_attention_concentration_10": -0.6316956302291897,
      "attention_bam_384_attention_concentration_20": -0.9106805092716506,
      "attention_bam_384_attention_center_y": 0.4819927965380977,
      "attention_bam_384_attention_center_x": 0.4821001542983653,
      "attention_bam_384_attention_center_distance": 0.035907209656576705,
      "attention_bam_384_attention_spatial_variance": 172.18090930551432,
      "attention_bam_384_attention_spatial_std": 13.12177233857966,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 19.352229978851565,
      "attention_bam_384_peak_intensity_mean": 0.37673652172088623,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1256166398525238,
      "attention_bam_16_std_attention": 0.4670865833759308,
      "attention_bam_16_max_attention": 2.818408966064453,
      "attention_bam_16_min_attention": -0.9776538610458374,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.4639382369490366,
      "attention_bam_16_attention_skewness": 0.49030830765855027,
      "attention_bam_16_attention_sparsity": 0.505859375,
      "attention_bam_16_attention_concentration_10": 0.8104978772059288,
      "attention_bam_16_attention_concentration_20": 1.2974595461901406,
      "attention_bam_16_attention_center_y": 0.45643350273486083,
      "attention_bam_16_attention_center_x": 0.4560084006587902,
      "attention_bam_16_attention_center_distance": 0.08755912855380536,
      "attention_bam_16_attention_spatial_variance": 44.081248453394544,
      "attention_bam_16_attention_spatial_std": 6.639371088694662,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 8.505405253646387,
      "attention_bam_16_peak_intensity_mean": 0.3210108280181885,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 956,
      "phase": "train",
      "loss": 0.003640083596110344,
      "timestamp": 1759544054.4526992,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.003640083596110344,
      "ssim": 0.943632960319519,
      "attention_bam_384_mean_attention": -0.029809435829520226,
      "attention_bam_384_std_attention": 0.135393425822258,
      "attention_bam_384_max_attention": 1.0269020795822144,
      "attention_bam_384_min_attention": -0.6444772481918335,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1776819805056657,
      "attention_bam_384_attention_skewness": 0.2907733077853704,
      "attention_bam_384_attention_sparsity": 0.8549016316731771,
      "attention_bam_384_attention_concentration_10": -0.7412395908182906,
      "attention_bam_384_attention_concentration_20": -1.0721319511752345,
      "attention_bam_384_attention_center_y": 0.4827112228787484,
      "attention_bam_384_attention_center_x": 0.4868957528364328,
      "attention_bam_384_attention_center_distance": 0.030679736246329463,
      "attention_bam_384_attention_spatial_variance": 170.8672270388471,
      "attention_bam_384_attention_spatial_std": 13.071619143734532,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 21.80889870804666,
      "attention_bam_384_peak_intensity_mean": 0.3776491582393646,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.10979495942592621,
      "attention_bam_16_std_attention": 0.5206319689750671,
      "attention_bam_16_max_attention": 2.658529758453369,
      "attention_bam_16_min_attention": -1.0064938068389893,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6530058682684214,
      "attention_bam_16_attention_skewness": 0.7569672605658662,
      "attention_bam_16_attention_sparsity": 0.549072265625,
      "attention_bam_16_attention_concentration_10": 1.0651716867416983,
      "attention_bam_16_attention_concentration_20": 1.6643074339887367,
      "attention_bam_16_attention_center_y": 0.4624583021348726,
      "attention_bam_16_attention_center_x": 0.4834055456889132,
      "attention_bam_16_attention_center_distance": 0.058047480435920014,
      "attention_bam_16_attention_spatial_variance": 42.621722317229086,
      "attention_bam_16_attention_spatial_std": 6.528531405854542,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 8.812027408295382,
      "attention_bam_16_peak_intensity_mean": 0.31368494033813477,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 957,
      "phase": "train",
      "loss": 0.0027800179086625576,
      "timestamp": 1759544054.600511,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0027800179086625576,
      "ssim": 0.9480450749397278,
      "attention_bam_384_mean_attention": -0.029708975926041603,
      "attention_bam_384_std_attention": 0.1389043927192688,
      "attention_bam_384_max_attention": 0.9775858521461487,
      "attention_bam_384_min_attention": -0.6323893070220947,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8703783588052247,
      "attention_bam_384_attention_skewness": 0.27293962072083433,
      "attention_bam_384_attention_sparsity": 0.8427378336588541,
      "attention_bam_384_attention_concentration_10": -0.7622198997633592,
      "attention_bam_384_attention_concentration_20": -1.1191162586423995,
      "attention_bam_384_attention_center_y": 0.47990813567094315,
      "attention_bam_384_attention_center_x": 0.48101225625253247,
      "attention_bam_384_attention_center_distance": 0.03909520238690982,
      "attention_bam_384_attention_spatial_variance": 171.3362853958939,
      "attention_bam_384_attention_spatial_std": 13.08954870864133,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 20.833128838489618,
      "attention_bam_384_peak_intensity_mean": 0.3861131966114044,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.11558836698532104,
      "attention_bam_16_std_attention": 0.5164902806282043,
      "attention_bam_16_max_attention": 2.7705981731414795,
      "attention_bam_16_min_attention": -0.9347000122070312,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.36317852652416693,
      "attention_bam_16_attention_skewness": 0.7142573468870087,
      "attention_bam_16_attention_sparsity": 0.549560546875,
      "attention_bam_16_attention_concentration_10": 0.9995583346142701,
      "attention_bam_16_attention_concentration_20": 1.5779641211660411,
      "attention_bam_16_attention_center_y": 0.4475957689447342,
      "attention_bam_16_attention_center_x": 0.45487175835652166,
      "attention_bam_16_attention_center_distance": 0.09780349304933704,
      "attention_bam_16_attention_spatial_variance": 42.94997178660353,
      "attention_bam_16_attention_spatial_std": 6.553622798620892,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 11.197158670694947,
      "attention_bam_16_peak_intensity_mean": 0.29310911893844604,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 958,
      "phase": "train",
      "loss": 0.003952439408749342,
      "timestamp": 1759544054.7596543,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.003952439408749342,
      "ssim": 0.92512047290802,
      "attention_bam_384_mean_attention": -0.03036496974527836,
      "attention_bam_384_std_attention": 0.14050401747226715,
      "attention_bam_384_max_attention": 1.0579895973205566,
      "attention_bam_384_min_attention": -0.73380446434021,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.7781211469293474,
      "attention_bam_384_attention_skewness": 0.45779156953399774,
      "attention_bam_384_attention_sparsity": 0.8549652099609375,
      "attention_bam_384_attention_concentration_10": -0.7829469829276494,
      "attention_bam_384_attention_concentration_20": -1.107724728935136,
      "attention_bam_384_attention_center_y": 0.4842513374910735,
      "attention_bam_384_attention_center_x": 0.48362944440171607,
      "attention_bam_384_attention_center_distance": 0.03212523809768799,
      "attention_bam_384_attention_spatial_variance": 171.2271015580155,
      "attention_bam_384_attention_spatial_std": 13.085377394558229,
      "attention_bam_384_num_attention_peaks": 18,
      "attention_bam_384_peak_separation_mean": 21.090167945884996,
      "attention_bam_384_peak_intensity_mean": 0.4014391601085663,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12224788963794708,
      "attention_bam_16_std_attention": 0.543900191783905,
      "attention_bam_16_max_attention": 2.630706310272217,
      "attention_bam_16_min_attention": -1.093259334564209,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.1320344786445702,
      "attention_bam_16_attention_skewness": 0.9223923891498587,
      "attention_bam_16_attention_sparsity": 0.548583984375,
      "attention_bam_16_attention_concentration_10": 1.0274604191914254,
      "attention_bam_16_attention_concentration_20": 1.5774639114146995,
      "attention_bam_16_attention_center_y": 0.46887626122703324,
      "attention_bam_16_attention_center_x": 0.4683906561769391,
      "attention_bam_16_attention_center_distance": 0.06273496205677266,
      "attention_bam_16_attention_spatial_variance": 43.06062664388774,
      "attention_bam_16_attention_spatial_std": 6.562059634283107,
      "attention_bam_16_num_attention_peaks": 6,
      "attention_bam_16_peak_separation_mean": 11.059946984944881,
      "attention_bam_16_peak_intensity_mean": 0.3341709077358246,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 959,
      "phase": "train",
      "loss": 0.003550444496795535,
      "timestamp": 1759544054.9540014,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.003550444496795535,
      "ssim": 0.928658664226532,
      "attention_bam_384_mean_attention": -0.028926653787493706,
      "attention_bam_384_std_attention": 0.1127350926399231,
      "attention_bam_384_max_attention": 0.9311392307281494,
      "attention_bam_384_min_attention": -0.6875408291816711,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.3668402266636281,
      "attention_bam_384_attention_skewness": 0.23138403758939233,
      "attention_bam_384_attention_sparsity": 0.8911768595377604,
      "attention_bam_384_attention_concentration_10": -0.6236332046042503,
      "attention_bam_384_attention_concentration_20": -0.8910158473879577,
      "attention_bam_384_attention_center_y": 0.47966224296205656,
      "attention_bam_384_attention_center_x": 0.4807519493776089,
      "attention_bam_384_attention_center_distance": 0.03960080337812727,
      "attention_bam_384_attention_spatial_variance": 171.2882704557554,
      "attention_bam_384_attention_spatial_std": 13.087714485568341,
      "attention_bam_384_num_attention_peaks": 7,
      "attention_bam_384_peak_separation_mean": 16.830268159885414,
      "attention_bam_384_peak_intensity_mean": 0.41324448585510254,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.11373445391654968,
      "attention_bam_16_std_attention": 0.45415768027305603,
      "attention_bam_16_max_attention": 2.141187906265259,
      "attention_bam_16_min_attention": -1.049468994140625,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5695540226336844,
      "attention_bam_16_attention_skewness": 0.6950562678620663,
      "attention_bam_16_attention_sparsity": 0.54345703125,
      "attention_bam_16_attention_concentration_10": 0.8990439680177633,
      "attention_bam_16_attention_concentration_20": 1.4189450762804656,
      "attention_bam_16_attention_center_y": 0.4448324570188723,
      "attention_bam_16_attention_center_x": 0.45044267070729455,
      "attention_bam_16_attention_center_distance": 0.10487503692681317,
      "attention_bam_16_attention_spatial_variance": 42.953679587960224,
      "attention_bam_16_attention_spatial_std": 6.553905674325823,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.266687196750329,
      "attention_bam_16_peak_intensity_mean": 0.38560834527015686,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 960,
      "phase": "train",
      "loss": 0.0034544558729976416,
      "timestamp": 1759544055.5412765,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0034544558729976416,
      "ssim": 0.9466874599456787,
      "attention_bam_384_mean_attention": -0.030005721375346184,
      "attention_bam_384_std_attention": 0.1454760879278183,
      "attention_bam_384_max_attention": 1.2335973978042603,
      "attention_bam_384_min_attention": -0.6886082291603088,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9541469332892119,
      "attention_bam_384_attention_skewness": 0.2871835889856881,
      "attention_bam_384_attention_sparsity": 0.8330917358398438,
      "attention_bam_384_attention_concentration_10": -0.7919915569570736,
      "attention_bam_384_attention_concentration_20": -1.1638359168547856,
      "attention_bam_384_attention_center_y": 0.4846858602755803,
      "attention_bam_384_attention_center_x": 0.4803650544942526,
      "attention_bam_384_attention_center_distance": 0.035215166065566676,
      "attention_bam_384_attention_spatial_variance": 172.0366115031941,
      "attention_bam_384_attention_spatial_std": 13.116272774808936,
      "attention_bam_384_num_attention_peaks": 20,
      "attention_bam_384_peak_separation_mean": 18.20921325346201,
      "attention_bam_384_peak_intensity_mean": 0.34721335768699646,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.11661168187856674,
      "attention_bam_16_std_attention": 0.5343961715698242,
      "attention_bam_16_max_attention": 2.3937177658081055,
      "attention_bam_16_min_attention": -0.961546003818512,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.2290220608136324,
      "attention_bam_16_attention_skewness": 0.6773215265742017,
      "attention_bam_16_attention_sparsity": 0.5361328125,
      "attention_bam_16_attention_concentration_10": 1.0223736538890715,
      "attention_bam_16_attention_concentration_20": 1.6134145573639673,
      "attention_bam_16_attention_center_y": 0.4712936471330131,
      "attention_bam_16_attention_center_x": 0.44796675469798847,
      "attention_bam_16_attention_center_distance": 0.08404181473032662,
      "attention_bam_16_attention_spatial_variance": 43.983313248459936,
      "attention_bam_16_attention_spatial_std": 6.63199165021036,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.865738961391848,
      "attention_bam_16_peak_intensity_mean": 0.3258127272129059,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 961,
      "phase": "train",
      "loss": 0.004519975744187832,
      "timestamp": 1759544055.7408688,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004519975744187832,
      "ssim": 0.9244856834411621,
      "attention_bam_384_mean_attention": -0.02962408773601055,
      "attention_bam_384_std_attention": 0.1475166231393814,
      "attention_bam_384_max_attention": 0.9146957993507385,
      "attention_bam_384_min_attention": -0.6886671185493469,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.195590807804047,
      "attention_bam_384_attention_skewness": 0.2786991950738268,
      "attention_bam_384_attention_sparsity": 0.8392588297526041,
      "attention_bam_384_attention_concentration_10": -0.8373280434753895,
      "attention_bam_384_attention_concentration_20": -1.2062289527721628,
      "attention_bam_384_attention_center_y": 0.481893927991455,
      "attention_bam_384_attention_center_x": 0.48272185709451926,
      "attention_bam_384_attention_center_distance": 0.03539389963936814,
      "attention_bam_384_attention_spatial_variance": 171.65819876060422,
      "attention_bam_384_attention_spatial_std": 13.101839518197597,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 18.31601581079557,
      "attention_bam_384_peak_intensity_mean": 0.4184282422065735,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12425112724304199,
      "attention_bam_16_std_attention": 0.5609174370765686,
      "attention_bam_16_max_attention": 2.532480239868164,
      "attention_bam_16_min_attention": -1.046184778213501,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.601417857444047,
      "attention_bam_16_attention_skewness": 0.7412159335350844,
      "attention_bam_16_attention_sparsity": 0.52978515625,
      "attention_bam_16_attention_concentration_10": 1.019937153028907,
      "attention_bam_16_attention_concentration_20": 1.585243582873483,
      "attention_bam_16_attention_center_y": 0.4573365906517568,
      "attention_bam_16_attention_center_x": 0.46000703549244243,
      "attention_bam_16_attention_center_distance": 0.08269950069158247,
      "attention_bam_16_attention_spatial_variance": 43.73942059410476,
      "attention_bam_16_attention_spatial_std": 6.613578501394291,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 11.01057568079016,
      "attention_bam_16_peak_intensity_mean": 0.3446738123893738,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 962,
      "phase": "train",
      "loss": 0.0038256151601672173,
      "timestamp": 1759544055.9222841,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0038256151601672173,
      "ssim": 0.9387527704238892,
      "attention_bam_384_mean_attention": -0.029604898765683174,
      "attention_bam_384_std_attention": 0.14804355800151825,
      "attention_bam_384_max_attention": 1.0636422634124756,
      "attention_bam_384_min_attention": -0.7670592069625854,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2443719537146247,
      "attention_bam_384_attention_skewness": 0.27246088063102075,
      "attention_bam_384_attention_sparsity": 0.8329620361328125,
      "attention_bam_384_attention_concentration_10": -0.8213798288955673,
      "attention_bam_384_attention_concentration_20": -1.198846575905897,
      "attention_bam_384_attention_center_y": 0.48612657009848603,
      "attention_bam_384_attention_center_x": 0.4843473099631115,
      "attention_bam_384_attention_center_distance": 0.02957968095240822,
      "attention_bam_384_attention_spatial_variance": 171.26015770105047,
      "attention_bam_384_attention_spatial_std": 13.086640428354807,
      "attention_bam_384_num_attention_peaks": 18,
      "attention_bam_384_peak_separation_mean": 20.781250856698342,
      "attention_bam_384_peak_intensity_mean": 0.40779441595077515,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1200065016746521,
      "attention_bam_16_std_attention": 0.5530677437782288,
      "attention_bam_16_max_attention": 2.802063465118408,
      "attention_bam_16_min_attention": -1.1867825984954834,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7468972949791381,
      "attention_bam_16_attention_skewness": 0.7238070272437024,
      "attention_bam_16_attention_sparsity": 0.53515625,
      "attention_bam_16_attention_concentration_10": 1.01387291237771,
      "attention_bam_16_attention_concentration_20": 1.6034998447553588,
      "attention_bam_16_attention_center_y": 0.4789651873839176,
      "attention_bam_16_attention_center_x": 0.4697254349410072,
      "attention_bam_16_attention_center_distance": 0.05213468387369174,
      "attention_bam_16_attention_spatial_variance": 43.22271384106695,
      "attention_bam_16_attention_spatial_std": 6.574398363429687,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.28426757003008,
      "attention_bam_16_peak_intensity_mean": 0.342521071434021,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 963,
      "phase": "train",
      "loss": 0.007938854396343231,
      "timestamp": 1759544056.093147,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007938854396343231,
      "ssim": 0.9157277345657349,
      "attention_bam_384_mean_attention": -0.029840955510735512,
      "attention_bam_384_std_attention": 0.13195975124835968,
      "attention_bam_384_max_attention": 0.9341787099838257,
      "attention_bam_384_min_attention": -0.7070481777191162,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9294873323255057,
      "attention_bam_384_attention_skewness": 0.1587134024696005,
      "attention_bam_384_attention_sparsity": 0.8542963663736979,
      "attention_bam_384_attention_concentration_10": -0.6995704568317241,
      "attention_bam_384_attention_concentration_20": -1.031197307890751,
      "attention_bam_384_attention_center_y": 0.4833435849511312,
      "attention_bam_384_attention_center_x": 0.4851835477951567,
      "attention_bam_384_attention_center_distance": 0.031526605215867684,
      "attention_bam_384_attention_spatial_variance": 171.10387396860008,
      "attention_bam_384_attention_spatial_std": 13.080667948105711,
      "attention_bam_384_num_attention_peaks": 22,
      "attention_bam_384_peak_separation_mean": 18.352934893807188,
      "attention_bam_384_peak_intensity_mean": 0.41458645462989807,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12836308777332306,
      "attention_bam_16_std_attention": 0.48959600925445557,
      "attention_bam_16_max_attention": 1.97957444190979,
      "attention_bam_16_min_attention": -1.1083543300628662,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.05192687716043176,
      "attention_bam_16_attention_skewness": 0.5078659385181813,
      "attention_bam_16_attention_sparsity": 0.511962890625,
      "attention_bam_16_attention_concentration_10": 0.8431018372659449,
      "attention_bam_16_attention_concentration_20": 1.351866622698523,
      "attention_bam_16_attention_center_y": 0.4646875672174847,
      "attention_bam_16_attention_center_x": 0.47224158500224783,
      "attention_bam_16_attention_center_distance": 0.06352161068812869,
      "attention_bam_16_attention_spatial_variance": 43.062688044617126,
      "attention_bam_16_attention_spatial_std": 6.56221670204643,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 9.244244244381829,
      "attention_bam_16_peak_intensity_mean": 0.4144832491874695,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 964,
      "phase": "train",
      "loss": 0.0038709682412445545,
      "timestamp": 1759544056.2536204,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0038709682412445545,
      "ssim": 0.9250414967536926,
      "attention_bam_384_mean_attention": -0.02942941151559353,
      "attention_bam_384_std_attention": 0.12850868701934814,
      "attention_bam_384_max_attention": 0.953392744064331,
      "attention_bam_384_min_attention": -0.6855951547622681,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2457485927128529,
      "attention_bam_384_attention_skewness": 0.16198439525092448,
      "attention_bam_384_attention_sparsity": 0.8660558064778646,
      "attention_bam_384_attention_concentration_10": -0.6965826813282749,
      "attention_bam_384_attention_concentration_20": -1.0095510101996548,
      "attention_bam_384_attention_center_y": 0.4845473097122617,
      "attention_bam_384_attention_center_x": 0.48433349330684505,
      "attention_bam_384_attention_center_distance": 0.031119931526127464,
      "attention_bam_384_attention_spatial_variance": 171.15071803827638,
      "attention_bam_384_attention_spatial_std": 13.08245840957564,
      "attention_bam_384_num_attention_peaks": 26,
      "attention_bam_384_peak_separation_mean": 19.63108241610751,
      "attention_bam_384_peak_intensity_mean": 0.40405333042144775,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12057384848594666,
      "attention_bam_16_std_attention": 0.47280701994895935,
      "attention_bam_16_max_attention": 2.1178247928619385,
      "attention_bam_16_min_attention": -1.0328222513198853,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.2833553516843721,
      "attention_bam_16_attention_skewness": 0.5553766219045083,
      "attention_bam_16_attention_sparsity": 0.52392578125,
      "attention_bam_16_attention_concentration_10": 0.8673599227860849,
      "attention_bam_16_attention_concentration_20": 1.3777284864198576,
      "attention_bam_16_attention_center_y": 0.47168013682788407,
      "attention_bam_16_attention_center_x": 0.4686499496966853,
      "attention_bam_16_attention_center_distance": 0.059746804167381734,
      "attention_bam_16_attention_spatial_variance": 43.162035604038124,
      "attention_bam_16_attention_spatial_std": 6.5697820058231855,
      "attention_bam_16_num_attention_peaks": 12,
      "attention_bam_16_peak_separation_mean": 9.5905583781206,
      "attention_bam_16_peak_intensity_mean": 0.3703290522098541,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 965,
      "phase": "train",
      "loss": 0.003209565533325076,
      "timestamp": 1759544056.404687,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.003209565533325076,
      "ssim": 0.9344655275344849,
      "attention_bam_384_mean_attention": -0.029868559911847115,
      "attention_bam_384_std_attention": 0.1266990602016449,
      "attention_bam_384_max_attention": 1.1393537521362305,
      "attention_bam_384_min_attention": -0.665137767791748,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8535724010303296,
      "attention_bam_384_attention_skewness": 0.34123481396841415,
      "attention_bam_384_attention_sparsity": 0.8734792073567709,
      "attention_bam_384_attention_concentration_10": -0.689505765976891,
      "attention_bam_384_attention_concentration_20": -0.9818995630636321,
      "attention_bam_384_attention_center_y": 0.48476628886684847,
      "attention_bam_384_attention_center_x": 0.48394423124233443,
      "attention_bam_384_attention_center_distance": 0.03130027684503555,
      "attention_bam_384_attention_spatial_variance": 171.27018795588083,
      "attention_bam_384_attention_spatial_std": 13.087023647716116,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 20.019122652428702,
      "attention_bam_384_peak_intensity_mean": 0.35622063279151917,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.11821745336055756,
      "attention_bam_16_std_attention": 0.49034714698791504,
      "attention_bam_16_max_attention": 3.232573986053467,
      "attention_bam_16_min_attention": -1.0445505380630493,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.7064828228318962,
      "attention_bam_16_attention_skewness": 0.883082602702668,
      "attention_bam_16_attention_sparsity": 0.532958984375,
      "attention_bam_16_attention_concentration_10": 0.9391202226230181,
      "attention_bam_16_attention_concentration_20": 1.448899020936899,
      "attention_bam_16_attention_center_y": 0.47327397376349567,
      "attention_bam_16_attention_center_x": 0.46849833460505325,
      "attention_bam_16_attention_center_distance": 0.05842320431214816,
      "attention_bam_16_attention_spatial_variance": 43.16527940622851,
      "attention_bam_16_attention_spatial_std": 6.570028874078751,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 10.182971600558881,
      "attention_bam_16_peak_intensity_mean": 0.2767333388328552,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 966,
      "phase": "train",
      "loss": 0.0038961421232670546,
      "timestamp": 1759544056.5529737,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0038961421232670546,
      "ssim": 0.9323114156723022,
      "attention_bam_384_mean_attention": -0.030284887179732323,
      "attention_bam_384_std_attention": 0.13274219632148743,
      "attention_bam_384_max_attention": 0.9374531507492065,
      "attention_bam_384_min_attention": -0.6973785758018494,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2946435507930492,
      "attention_bam_384_attention_skewness": 0.2068988798590108,
      "attention_bam_384_attention_sparsity": 0.8632888793945312,
      "attention_bam_384_attention_concentration_10": -0.7048819342410482,
      "attention_bam_384_attention_concentration_20": -1.013606432380029,
      "attention_bam_384_attention_center_y": 0.4826984986991702,
      "attention_bam_384_attention_center_x": 0.4852584860993033,
      "attention_bam_384_attention_center_distance": 0.0321451140718788,
      "attention_bam_384_attention_spatial_variance": 171.20700254586603,
      "attention_bam_384_attention_spatial_std": 13.08460937689261,
      "attention_bam_384_num_attention_peaks": 22,
      "attention_bam_384_peak_separation_mean": 19.250867147730474,
      "attention_bam_384_peak_intensity_mean": 0.41280296444892883,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12671896815299988,
      "attention_bam_16_std_attention": 0.5030916929244995,
      "attention_bam_16_max_attention": 2.173973798751831,
      "attention_bam_16_min_attention": -1.1030144691467285,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.24278393679621857,
      "attention_bam_16_attention_skewness": 0.5366826811366716,
      "attention_bam_16_attention_sparsity": 0.51953125,
      "attention_bam_16_attention_concentration_10": 0.8721769936353346,
      "attention_bam_16_attention_concentration_20": 1.3921667842712337,
      "attention_bam_16_attention_center_y": 0.4631261338534443,
      "attention_bam_16_attention_center_x": 0.4733903270401279,
      "attention_bam_16_attention_center_distance": 0.06430795751111139,
      "attention_bam_16_attention_spatial_variance": 43.086197348338914,
      "attention_bam_16_attention_spatial_std": 6.564007720009089,
      "attention_bam_16_num_attention_peaks": 13,
      "attention_bam_16_peak_separation_mean": 10.289748015032172,
      "attention_bam_16_peak_intensity_mean": 0.3853159546852112,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 967,
      "phase": "train",
      "loss": 0.003827592357993126,
      "timestamp": 1759544056.701282,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.003827592357993126,
      "ssim": 0.9374508857727051,
      "attention_bam_384_mean_attention": -0.030382946133613586,
      "attention_bam_384_std_attention": 0.11971984803676605,
      "attention_bam_384_max_attention": 0.7915942668914795,
      "attention_bam_384_min_attention": -0.6703744530677795,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8940626388643587,
      "attention_bam_384_attention_skewness": 0.2120310156539663,
      "attention_bam_384_attention_sparsity": 0.87774658203125,
      "attention_bam_384_attention_concentration_10": -0.6162512189604621,
      "attention_bam_384_attention_concentration_20": -0.8996524380432567,
      "attention_bam_384_attention_center_y": 0.4824296854796903,
      "attention_bam_384_attention_center_x": 0.48325451282540455,
      "attention_bam_384_attention_center_distance": 0.034325713191633675,
      "attention_bam_384_attention_spatial_variance": 171.29971490613772,
      "attention_bam_384_attention_spatial_std": 13.088151699385888,
      "attention_bam_384_num_attention_peaks": 20,
      "attention_bam_384_peak_separation_mean": 17.167478988357217,
      "attention_bam_384_peak_intensity_mean": 0.44243311882019043,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.13207854330539703,
      "attention_bam_16_std_attention": 0.4670601189136505,
      "attention_bam_16_max_attention": 2.2285001277923584,
      "attention_bam_16_min_attention": -0.9460687637329102,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.18074169796540795,
      "attention_bam_16_attention_skewness": 0.542099009291628,
      "attention_bam_16_attention_sparsity": 0.513427734375,
      "attention_bam_16_attention_concentration_10": 0.7807941454163221,
      "attention_bam_16_attention_concentration_20": 1.260555566250198,
      "attention_bam_16_attention_center_y": 0.45873358616928533,
      "attention_bam_16_attention_center_x": 0.46411797236828306,
      "attention_bam_16_attention_center_distance": 0.07733610822133598,
      "attention_bam_16_attention_spatial_variance": 43.131481189458945,
      "attention_bam_16_attention_spatial_std": 6.567456219074395,
      "attention_bam_16_num_attention_peaks": 12,
      "attention_bam_16_peak_separation_mean": 9.573767042310127,
      "attention_bam_16_peak_intensity_mean": 0.3505990207195282,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 968,
      "phase": "train",
      "loss": 0.0025499160401523113,
      "timestamp": 1759544056.8477898,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0025499160401523113,
      "ssim": 0.945345401763916,
      "attention_bam_384_mean_attention": -0.03046775609254837,
      "attention_bam_384_std_attention": 0.1310167759656906,
      "attention_bam_384_max_attention": 0.8818851709365845,
      "attention_bam_384_min_attention": -0.6790679693222046,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1128063821940852,
      "attention_bam_384_attention_skewness": 0.2536070081990498,
      "attention_bam_384_attention_sparsity": 0.8598861694335938,
      "attention_bam_384_attention_concentration_10": -0.6931271014639947,
      "attention_bam_384_attention_concentration_20": -1.0072730227962754,
      "attention_bam_384_attention_center_y": 0.48706922106220696,
      "attention_bam_384_attention_center_x": 0.48418140237143226,
      "attention_bam_384_attention_center_distance": 0.028894050421240745,
      "attention_bam_384_attention_spatial_variance": 171.95530469993685,
      "attention_bam_384_attention_spatial_std": 13.113172945551234,
      "attention_bam_384_num_attention_peaks": 18,
      "attention_bam_384_peak_separation_mean": 18.542409614258858,
      "attention_bam_384_peak_intensity_mean": 0.418101042509079,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12243328243494034,
      "attention_bam_16_std_attention": 0.502598226070404,
      "attention_bam_16_max_attention": 2.830381393432617,
      "attention_bam_16_min_attention": -1.0492925643920898,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.9446958667853003,
      "attention_bam_16_attention_skewness": 0.7691125729953603,
      "attention_bam_16_attention_sparsity": 0.534423828125,
      "attention_bam_16_attention_concentration_10": 0.9224098485781593,
      "attention_bam_16_attention_concentration_20": 1.4500383594219295,
      "attention_bam_16_attention_center_y": 0.48674166658837076,
      "attention_bam_16_attention_center_x": 0.4679189306906477,
      "attention_bam_16_attention_center_distance": 0.049091311102584925,
      "attention_bam_16_attention_spatial_variance": 44.020209937560864,
      "attention_bam_16_attention_spatial_std": 6.634772787184265,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 11.386372301722238,
      "attention_bam_16_peak_intensity_mean": 0.3190098702907562,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 969,
      "phase": "train",
      "loss": 0.008414620533585548,
      "timestamp": 1759544056.9981434,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.008414620533585548,
      "ssim": 0.9209883809089661,
      "attention_bam_384_mean_attention": -0.03004308231174946,
      "attention_bam_384_std_attention": 0.14086510241031647,
      "attention_bam_384_max_attention": 0.9138480424880981,
      "attention_bam_384_min_attention": -0.6998676657676697,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.1730648569919708,
      "attention_bam_384_attention_skewness": 0.2549699587063301,
      "attention_bam_384_attention_sparsity": 0.8470026652018229,
      "attention_bam_384_attention_concentration_10": -0.7637379129593171,
      "attention_bam_384_attention_concentration_20": -1.1075267528342774,
      "attention_bam_384_attention_center_y": 0.4835744223200267,
      "attention_bam_384_attention_center_x": 0.4844045059486617,
      "attention_bam_384_attention_center_distance": 0.0320318290712899,
      "attention_bam_384_attention_spatial_variance": 171.40343272218738,
      "attention_bam_384_attention_spatial_std": 13.092113378755448,
      "attention_bam_384_num_attention_peaks": 24,
      "attention_bam_384_peak_separation_mean": 19.45908583395463,
      "attention_bam_384_peak_intensity_mean": 0.41999492049217224,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.11720198392868042,
      "attention_bam_16_std_attention": 0.53631192445755,
      "attention_bam_16_max_attention": 2.682002067565918,
      "attention_bam_16_min_attention": -1.0444064140319824,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.4594623242725251,
      "attention_bam_16_attention_skewness": 0.6737403603485521,
      "attention_bam_16_attention_sparsity": 0.533203125,
      "attention_bam_16_attention_concentration_10": 1.0068244128552433,
      "attention_bam_16_attention_concentration_20": 1.594701633421712,
      "attention_bam_16_attention_center_y": 0.46642917582361143,
      "attention_bam_16_attention_center_x": 0.47072876691226145,
      "attention_bam_16_attention_center_distance": 0.06298897240563169,
      "attention_bam_16_attention_spatial_variance": 43.49457536479088,
      "attention_bam_16_attention_spatial_std": 6.595041725780883,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 10.835698582758594,
      "attention_bam_16_peak_intensity_mean": 0.3260023593902588,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 970,
      "phase": "train",
      "loss": 0.0050935326144099236,
      "timestamp": 1759544057.2411504,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0050935326144099236,
      "ssim": 0.9171646237373352,
      "attention_bam_384_mean_attention": -0.029109902679920197,
      "attention_bam_384_std_attention": 0.1277027577161789,
      "attention_bam_384_max_attention": 0.7708467245101929,
      "attention_bam_384_min_attention": -0.6374574899673462,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8112683812414749,
      "attention_bam_384_attention_skewness": 0.04375345692438255,
      "attention_bam_384_attention_sparsity": 0.8618927001953125,
      "attention_bam_384_attention_concentration_10": -0.6800995120384027,
      "attention_bam_384_attention_concentration_20": -1.0056908020052817,
      "attention_bam_384_attention_center_y": 0.4833909963664883,
      "attention_bam_384_attention_center_x": 0.4815441040544612,
      "attention_bam_384_attention_center_distance": 0.03511350443491964,
      "attention_bam_384_attention_spatial_variance": 169.7339757747651,
      "attention_bam_384_attention_spatial_std": 13.028199252957606,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 17.684237724479935,
      "attention_bam_384_peak_intensity_mean": 0.4354677200317383,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.119038887321949,
      "attention_bam_16_std_attention": 0.47684720158576965,
      "attention_bam_16_max_attention": 2.066818952560425,
      "attention_bam_16_min_attention": -1.0174145698547363,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.15861076121807383,
      "attention_bam_16_attention_skewness": 0.41927597018831275,
      "attention_bam_16_attention_sparsity": 0.51806640625,
      "attention_bam_16_attention_concentration_10": 0.8557493652157148,
      "attention_bam_16_attention_concentration_20": 1.3963782854568199,
      "attention_bam_16_attention_center_y": 0.4620251219888812,
      "attention_bam_16_attention_center_x": 0.45567939829032955,
      "attention_bam_16_attention_center_distance": 0.08253977339279044,
      "attention_bam_16_attention_spatial_variance": 41.14942157391017,
      "attention_bam_16_attention_spatial_std": 6.414781490737636,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 9.528649329150925,
      "attention_bam_16_peak_intensity_mean": 0.38017797470092773,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 971,
      "phase": "train",
      "loss": 0.0042963773012161255,
      "timestamp": 1759544057.4352403,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0042963773012161255,
      "ssim": 0.9259556531906128,
      "attention_bam_384_mean_attention": -0.029514549300074577,
      "attention_bam_384_std_attention": 0.12717589735984802,
      "attention_bam_384_max_attention": 0.9551722407341003,
      "attention_bam_384_min_attention": -0.6838171482086182,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2490633375446327,
      "attention_bam_384_attention_skewness": 0.22166826579612886,
      "attention_bam_384_attention_sparsity": 0.8693822224934896,
      "attention_bam_384_attention_concentration_10": -0.6981418996958842,
      "attention_bam_384_attention_concentration_20": -1.0028350420700038,
      "attention_bam_384_attention_center_y": 0.48355739656692664,
      "attention_bam_384_attention_center_x": 0.48576814780214495,
      "attention_bam_384_attention_center_distance": 0.03075401842487929,
      "attention_bam_384_attention_spatial_variance": 170.91019712671562,
      "attention_bam_384_attention_spatial_std": 13.073262681011027,
      "attention_bam_384_num_attention_peaks": 17,
      "attention_bam_384_peak_separation_mean": 18.9982923050605,
      "attention_bam_384_peak_intensity_mean": 0.4017067551612854,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.11628333479166031,
      "attention_bam_16_std_attention": 0.493251770734787,
      "attention_bam_16_max_attention": 2.4192962646484375,
      "attention_bam_16_min_attention": -1.0241650342941284,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5583028914169756,
      "attention_bam_16_attention_skewness": 0.6454227799866862,
      "attention_bam_16_attention_sparsity": 0.532958984375,
      "attention_bam_16_attention_concentration_10": 0.9341852218174965,
      "attention_bam_16_attention_concentration_20": 1.4846724462014695,
      "attention_bam_16_attention_center_y": 0.4662834357169459,
      "attention_bam_16_attention_center_x": 0.478298468006172,
      "attention_bam_16_attention_center_distance": 0.056705611678782894,
      "attention_bam_16_attention_spatial_variance": 42.88573940639693,
      "attention_bam_16_attention_spatial_std": 6.548720440391156,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 10.10272853204125,
      "attention_bam_16_peak_intensity_mean": 0.33305758237838745,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 972,
      "phase": "train",
      "loss": 0.00403035432100296,
      "timestamp": 1759544057.631209,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00403035432100296,
      "ssim": 0.9391939640045166,
      "attention_bam_384_mean_attention": -0.02897373028099537,
      "attention_bam_384_std_attention": 0.1311994194984436,
      "attention_bam_384_max_attention": 0.8952744007110596,
      "attention_bam_384_min_attention": -0.7151871919631958,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.219795157623646,
      "attention_bam_384_attention_skewness": 0.2666366849532271,
      "attention_bam_384_attention_sparsity": 0.8604151407877604,
      "attention_bam_384_attention_concentration_10": -0.7396111813754819,
      "attention_bam_384_attention_concentration_20": -1.0687548349473845,
      "attention_bam_384_attention_center_y": 0.48473553397129965,
      "attention_bam_384_attention_center_x": 0.4852538472146379,
      "attention_bam_384_attention_center_distance": 0.030015094373018057,
      "attention_bam_384_attention_spatial_variance": 169.87567248880532,
      "attention_bam_384_attention_spatial_std": 13.033636195966393,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 13.983863058601235,
      "attention_bam_384_peak_intensity_mean": 0.42766356468200684,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12197722494602203,
      "attention_bam_16_std_attention": 0.5073527693748474,
      "attention_bam_16_max_attention": 2.5943186283111572,
      "attention_bam_16_min_attention": -1.0895214080810547,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7065623544309472,
      "attention_bam_16_attention_skewness": 0.7595826337105221,
      "attention_bam_16_attention_sparsity": 0.537353515625,
      "attention_bam_16_attention_concentration_10": 0.9483475130320476,
      "attention_bam_16_attention_concentration_20": 1.4813359259383099,
      "attention_bam_16_attention_center_y": 0.47292838067063053,
      "attention_bam_16_attention_center_x": 0.475677027411115,
      "attention_bam_16_attention_center_distance": 0.051468039960230486,
      "attention_bam_16_attention_spatial_variance": 41.292678656930754,
      "attention_bam_16_attention_spatial_std": 6.425937959312302,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 8.370094901317147,
      "attention_bam_16_peak_intensity_mean": 0.32988449931144714,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 973,
      "phase": "train",
      "loss": 0.004659711848944426,
      "timestamp": 1759544057.8265963,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004659711848944426,
      "ssim": 0.9310802221298218,
      "attention_bam_384_mean_attention": -0.029111415147781372,
      "attention_bam_384_std_attention": 0.1248268410563469,
      "attention_bam_384_max_attention": 0.7826741933822632,
      "attention_bam_384_min_attention": -0.6457964181900024,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.8931444096784946,
      "attention_bam_384_attention_skewness": 0.04547061940483175,
      "attention_bam_384_attention_sparsity": 0.8710149129231771,
      "attention_bam_384_attention_concentration_10": -0.6596817349963159,
      "attention_bam_384_attention_concentration_20": -0.9686064534102361,
      "attention_bam_384_attention_center_y": 0.48458480305892854,
      "attention_bam_384_attention_center_x": 0.483763943975247,
      "attention_bam_384_attention_center_distance": 0.03166189545718753,
      "attention_bam_384_attention_spatial_variance": 171.49681936503018,
      "attention_bam_384_attention_spatial_std": 13.095679415938303,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 19.855868201085798,
      "attention_bam_384_peak_intensity_mean": 0.4351412057876587,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12057504057884216,
      "attention_bam_16_std_attention": 0.4836324155330658,
      "attention_bam_16_max_attention": 1.904106855392456,
      "attention_bam_16_min_attention": -0.9552784562110901,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.15180130827865002,
      "attention_bam_16_attention_skewness": 0.3912862905816724,
      "attention_bam_16_attention_sparsity": 0.514404296875,
      "attention_bam_16_attention_concentration_10": 0.8492315662361319,
      "attention_bam_16_attention_concentration_20": 1.3868396992472467,
      "attention_bam_16_attention_center_y": 0.4720816671538674,
      "attention_bam_16_attention_center_x": 0.4662151842322646,
      "attention_bam_16_attention_center_distance": 0.061981401813241827,
      "attention_bam_16_attention_spatial_variance": 43.712832984073565,
      "attention_bam_16_attention_spatial_std": 6.611568118387162,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 10.502327565634092,
      "attention_bam_16_peak_intensity_mean": 0.38900041580200195,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 974,
      "phase": "train",
      "loss": 0.003867020830512047,
      "timestamp": 1759544058.0226674,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.003867020830512047,
      "ssim": 0.9444206953048706,
      "attention_bam_384_mean_attention": -0.029454270377755165,
      "attention_bam_384_std_attention": 0.12938988208770752,
      "attention_bam_384_max_attention": 0.8273583650588989,
      "attention_bam_384_min_attention": -0.6579289436340332,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0172261905771984,
      "attention_bam_384_attention_skewness": 0.25030482120983216,
      "attention_bam_384_attention_sparsity": 0.8598607381184896,
      "attention_bam_384_attention_concentration_10": -0.7142380143576207,
      "attention_bam_384_attention_concentration_20": -1.0387775365915604,
      "attention_bam_384_attention_center_y": 0.48441407928015123,
      "attention_bam_384_attention_center_x": 0.48262658198503267,
      "attention_bam_384_attention_center_distance": 0.03300777418149253,
      "attention_bam_384_attention_spatial_variance": 171.40026622755178,
      "attention_bam_384_attention_spatial_std": 13.091992446818466,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 20.912486819355905,
      "attention_bam_384_peak_intensity_mean": 0.42945778369903564,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12121228873729706,
      "attention_bam_16_std_attention": 0.4998910129070282,
      "attention_bam_16_max_attention": 2.4670650959014893,
      "attention_bam_16_min_attention": -0.9741884469985962,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5915435831455484,
      "attention_bam_16_attention_skewness": 0.720886343774747,
      "attention_bam_16_attention_sparsity": 0.53369140625,
      "attention_bam_16_attention_concentration_10": 0.9240099999580315,
      "attention_bam_16_attention_concentration_20": 1.4572738384586827,
      "attention_bam_16_attention_center_y": 0.4721876294473136,
      "attention_bam_16_attention_center_x": 0.46031746308735294,
      "attention_bam_16_attention_center_distance": 0.06853074772076452,
      "attention_bam_16_attention_spatial_variance": 43.74017249559958,
      "attention_bam_16_attention_spatial_std": 6.613635346433879,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 10.81701195541847,
      "attention_bam_16_peak_intensity_mean": 0.33058181405067444,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 975,
      "phase": "train",
      "loss": 0.005466708447784185,
      "timestamp": 1759544058.2055435,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.005466708447784185,
      "ssim": 0.894517719745636,
      "attention_bam_384_mean_attention": -0.0290722344070673,
      "attention_bam_384_std_attention": 0.1376102715730667,
      "attention_bam_384_max_attention": 1.1563994884490967,
      "attention_bam_384_min_attention": -0.750643253326416,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.8433861495171202,
      "attention_bam_384_attention_skewness": 0.210339073814205,
      "attention_bam_384_attention_sparsity": 0.8546905517578125,
      "attention_bam_384_attention_concentration_10": -0.7546561480980336,
      "attention_bam_384_attention_concentration_20": -1.094520788777475,
      "attention_bam_384_attention_center_y": 0.48406395418335413,
      "attention_bam_384_attention_center_x": 0.4828390362520888,
      "attention_bam_384_attention_center_distance": 0.033119668869943705,
      "attention_bam_384_attention_spatial_variance": 170.96090941040165,
      "attention_bam_384_attention_spatial_std": 13.075202079142091,
      "attention_bam_384_num_attention_peaks": 26,
      "attention_bam_384_peak_separation_mean": 17.526309220025347,
      "attention_bam_384_peak_intensity_mean": 0.38059234619140625,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12463794648647308,
      "attention_bam_16_std_attention": 0.5062856674194336,
      "attention_bam_16_max_attention": 2.7780210971832275,
      "attention_bam_16_min_attention": -1.1568862199783325,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.8144197207462174,
      "attention_bam_16_attention_skewness": 0.6450508309567863,
      "attention_bam_16_attention_sparsity": 0.51953125,
      "attention_bam_16_attention_concentration_10": 0.8923419992219083,
      "attention_bam_16_attention_concentration_20": 1.4128279065386882,
      "attention_bam_16_attention_center_y": 0.4683336134455755,
      "attention_bam_16_attention_center_x": 0.46180332532928453,
      "attention_bam_16_attention_center_distance": 0.07016759926511257,
      "attention_bam_16_attention_spatial_variance": 42.84565097131868,
      "attention_bam_16_attention_spatial_std": 6.545658940956112,
      "attention_bam_16_num_attention_peaks": 12,
      "attention_bam_16_peak_separation_mean": 9.719900461343432,
      "attention_bam_16_peak_intensity_mean": 0.33002564311027527,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 976,
      "phase": "train",
      "loss": 0.00451041990891099,
      "timestamp": 1759544058.3805385,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.00451041990891099,
      "ssim": 0.9124466180801392,
      "attention_bam_384_mean_attention": -0.029520930722355843,
      "attention_bam_384_std_attention": 0.132460817694664,
      "attention_bam_384_max_attention": 0.7919350862503052,
      "attention_bam_384_min_attention": -0.6346131563186646,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.7650561135614788,
      "attention_bam_384_attention_skewness": 0.18997524152456302,
      "attention_bam_384_attention_sparsity": 0.8532638549804688,
      "attention_bam_384_attention_concentration_10": -0.7270937418533884,
      "attention_bam_384_attention_concentration_20": -1.064567810554177,
      "attention_bam_384_attention_center_y": 0.4855973261051002,
      "attention_bam_384_attention_center_x": 0.48476582116588013,
      "attention_bam_384_attention_center_distance": 0.029648514973697214,
      "attention_bam_384_attention_spatial_variance": 171.17269828251642,
      "attention_bam_384_attention_spatial_std": 13.083298448117601,
      "attention_bam_384_num_attention_peaks": 23,
      "attention_bam_384_peak_separation_mean": 21.103783573744778,
      "attention_bam_384_peak_intensity_mean": 0.4295227527618408,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12132445722818375,
      "attention_bam_16_std_attention": 0.5146724581718445,
      "attention_bam_16_max_attention": 2.440143585205078,
      "attention_bam_16_min_attention": -0.9598207473754883,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.05101312468348507,
      "attention_bam_16_attention_skewness": 0.5889207036937685,
      "attention_bam_16_attention_sparsity": 0.5361328125,
      "attention_bam_16_attention_concentration_10": 0.9353529281783848,
      "attention_bam_16_attention_concentration_20": 1.4954288878900137,
      "attention_bam_16_attention_center_y": 0.477073259199253,
      "attention_bam_16_attention_center_x": 0.4727016962465025,
      "attention_bam_16_attention_center_distance": 0.05041493492136739,
      "attention_bam_16_attention_spatial_variance": 43.19926692632092,
      "attention_bam_16_attention_spatial_std": 6.572614923021195,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 9.084664957386185,
      "attention_bam_16_peak_intensity_mean": 0.33681488037109375,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 977,
      "phase": "train",
      "loss": 0.0057517848908901215,
      "timestamp": 1759544058.5511405,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0057517848908901215,
      "ssim": 0.8699005842208862,
      "attention_bam_384_mean_attention": -0.02973521500825882,
      "attention_bam_384_std_attention": 0.1203916147351265,
      "attention_bam_384_max_attention": 1.0004442930221558,
      "attention_bam_384_min_attention": -0.6431978940963745,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.3829026289580293,
      "attention_bam_384_attention_skewness": 0.20398093189145938,
      "attention_bam_384_attention_sparsity": 0.8809483846028646,
      "attention_bam_384_attention_concentration_10": -0.6419870526797529,
      "attention_bam_384_attention_concentration_20": -0.9223468110993468,
      "attention_bam_384_attention_center_y": 0.4841197116733379,
      "attention_bam_384_attention_center_x": 0.4825806450090682,
      "attention_bam_384_attention_center_distance": 0.03333519118403315,
      "attention_bam_384_attention_spatial_variance": 171.2410523993273,
      "attention_bam_384_attention_spatial_std": 13.085910453588138,
      "attention_bam_384_num_attention_peaks": 21,
      "attention_bam_384_peak_separation_mean": 19.017445580605727,
      "attention_bam_384_peak_intensity_mean": 0.3767518401145935,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1297101378440857,
      "attention_bam_16_std_attention": 0.4625850021839142,
      "attention_bam_16_max_attention": 1.97513747215271,
      "attention_bam_16_min_attention": -1.047386646270752,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.3684124675400722,
      "attention_bam_16_attention_skewness": 0.584717054463137,
      "attention_bam_16_attention_sparsity": 0.510986328125,
      "attention_bam_16_attention_concentration_10": 0.8071563637882702,
      "attention_bam_16_attention_concentration_20": 1.2817190712821813,
      "attention_bam_16_attention_center_y": 0.4692362631534433,
      "attention_bam_16_attention_center_x": 0.4601289985191817,
      "attention_bam_16_attention_center_distance": 0.07121943925428793,
      "attention_bam_16_attention_spatial_variance": 43.129888158416406,
      "attention_bam_16_attention_spatial_std": 6.567334935757152,
      "attention_bam_16_num_attention_peaks": 12,
      "attention_bam_16_peak_separation_mean": 9.689127738112841,
      "attention_bam_16_peak_intensity_mean": 0.3965119421482086,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 978,
      "phase": "train",
      "loss": 0.004641546402126551,
      "timestamp": 1759544058.7099001,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004641546402126551,
      "ssim": 0.9295235872268677,
      "attention_bam_384_mean_attention": -0.02949041686952114,
      "attention_bam_384_std_attention": 0.13143181800842285,
      "attention_bam_384_max_attention": 1.1452925205230713,
      "attention_bam_384_min_attention": -0.6508064866065979,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9769372476572205,
      "attention_bam_384_attention_skewness": 0.20780371542550205,
      "attention_bam_384_attention_sparsity": 0.8547795613606771,
      "attention_bam_384_attention_concentration_10": -0.7112179047217743,
      "attention_bam_384_attention_concentration_20": -1.0454994395520036,
      "attention_bam_384_attention_center_y": 0.48200425638668803,
      "attention_bam_384_attention_center_x": 0.4829318678687152,
      "attention_bam_384_attention_center_distance": 0.03507614353508817,
      "attention_bam_384_attention_spatial_variance": 171.61942616906944,
      "attention_bam_384_attention_spatial_std": 13.100359772505083,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 18.06041118087096,
      "attention_bam_384_peak_intensity_mean": 0.34966960549354553,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12244351208209991,
      "attention_bam_16_std_attention": 0.49289771914482117,
      "attention_bam_16_max_attention": 2.398719549179077,
      "attention_bam_16_min_attention": -0.8996408581733704,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.24025267910073111,
      "attention_bam_16_attention_skewness": 0.6125515622886649,
      "attention_bam_16_attention_sparsity": 0.53466796875,
      "attention_bam_16_attention_concentration_10": 0.8929212387000076,
      "attention_bam_16_attention_concentration_20": 1.4266812460886185,
      "attention_bam_16_attention_center_y": 0.4590842040014973,
      "attention_bam_16_attention_center_x": 0.46446315498385904,
      "attention_bam_16_attention_center_distance": 0.07664162988731793,
      "attention_bam_16_attention_spatial_variance": 44.23877839363073,
      "attention_bam_16_attention_spatial_std": 6.651223826757804,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 11.136546265381773,
      "attention_bam_16_peak_intensity_mean": 0.32692867517471313,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 979,
      "phase": "train",
      "loss": 0.004764067009091377,
      "timestamp": 1759544058.8663259,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004764067009091377,
      "ssim": 0.9168443083763123,
      "attention_bam_384_mean_attention": -0.029459616169333458,
      "attention_bam_384_std_attention": 0.11798642575740814,
      "attention_bam_384_max_attention": 0.8963353037834167,
      "attention_bam_384_min_attention": -0.6154049634933472,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.24822505053955,
      "attention_bam_384_attention_skewness": 0.11260447668022011,
      "attention_bam_384_attention_sparsity": 0.88238525390625,
      "attention_bam_384_attention_concentration_10": -0.61914820829714,
      "attention_bam_384_attention_concentration_20": -0.9027213604989345,
      "attention_bam_384_attention_center_y": 0.48334544459713663,
      "attention_bam_384_attention_center_x": 0.4803855112036755,
      "attention_bam_384_attention_center_distance": 0.03638962452150844,
      "attention_bam_384_attention_spatial_variance": 170.8497046771685,
      "attention_bam_384_attention_spatial_std": 13.070948882050166,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 17.08489335364174,
      "attention_bam_384_peak_intensity_mean": 0.3925093710422516,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12922540307044983,
      "attention_bam_16_std_attention": 0.4560302495956421,
      "attention_bam_16_max_attention": 1.8035857677459717,
      "attention_bam_16_min_attention": -1.0287158489227295,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.0783776417443689,
      "attention_bam_16_attention_skewness": 0.45428773188395566,
      "attention_bam_16_attention_sparsity": 0.50244140625,
      "attention_bam_16_attention_concentration_10": 0.780940929418133,
      "attention_bam_16_attention_concentration_20": 1.2519220679247391,
      "attention_bam_16_attention_center_y": 0.46229102184546356,
      "attention_bam_16_attention_center_x": 0.4489212300292994,
      "attention_bam_16_attention_center_distance": 0.08978872730113788,
      "attention_bam_16_attention_spatial_variance": 42.5246326347509,
      "attention_bam_16_attention_spatial_std": 6.521091368379292,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 7.671858855965476,
      "attention_bam_16_peak_intensity_mean": 0.42321908473968506,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 980,
      "phase": "train",
      "loss": 0.004183526616543531,
      "timestamp": 1759544059.0949204,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004183526616543531,
      "ssim": 0.9131169319152832,
      "attention_bam_384_mean_attention": -0.029527835547924042,
      "attention_bam_384_std_attention": 0.12431010603904724,
      "attention_bam_384_max_attention": 1.2245522737503052,
      "attention_bam_384_min_attention": -0.7696133852005005,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.2118711306940106,
      "attention_bam_384_attention_skewness": 0.3277667524390721,
      "attention_bam_384_attention_sparsity": 0.8762257893880209,
      "attention_bam_384_attention_concentration_10": -0.6775737486187945,
      "attention_bam_384_attention_concentration_20": -0.967319840898797,
      "attention_bam_384_attention_center_y": 0.48441481482667287,
      "attention_bam_384_attention_center_x": 0.48300835811339105,
      "attention_bam_384_attention_center_distance": 0.032607173777856296,
      "attention_bam_384_attention_spatial_variance": 170.42965421816785,
      "attention_bam_384_attention_spatial_std": 13.05487090009579,
      "attention_bam_384_num_attention_peaks": 25,
      "attention_bam_384_peak_separation_mean": 19.698081836207912,
      "attention_bam_384_peak_intensity_mean": 0.3743910491466522,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.11489521712064743,
      "attention_bam_16_std_attention": 0.4799305498600006,
      "attention_bam_16_max_attention": 3.2820568084716797,
      "attention_bam_16_min_attention": -1.1137903928756714,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7836209031012173,
      "attention_bam_16_attention_skewness": 0.6898783108672687,
      "attention_bam_16_attention_sparsity": 0.535400390625,
      "attention_bam_16_attention_concentration_10": 0.9324305369598525,
      "attention_bam_16_attention_concentration_20": 1.465690463768972,
      "attention_bam_16_attention_center_y": 0.469245957109492,
      "attention_bam_16_attention_center_x": 0.46207027934368555,
      "attention_bam_16_attention_center_distance": 0.06905758268542639,
      "attention_bam_16_attention_spatial_variance": 42.0596093528878,
      "attention_bam_16_attention_spatial_std": 6.485338029192294,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.123434361385183,
      "attention_bam_16_peak_intensity_mean": 0.28708401322364807,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 981,
      "phase": "train",
      "loss": 0.0037799146957695484,
      "timestamp": 1759544059.2457597,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0037799146957695484,
      "ssim": 0.9430446624755859,
      "attention_bam_384_mean_attention": -0.02956930547952652,
      "attention_bam_384_std_attention": 0.13287238776683807,
      "attention_bam_384_max_attention": 1.2959277629852295,
      "attention_bam_384_min_attention": -0.7359371185302734,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.751674916974915,
      "attention_bam_384_attention_skewness": 0.21382080787355237,
      "attention_bam_384_attention_sparsity": 0.8589401245117188,
      "attention_bam_384_attention_concentration_10": -0.7020328527009883,
      "attention_bam_384_attention_concentration_20": -1.0277001639914183,
      "attention_bam_384_attention_center_y": 0.4851835587848487,
      "attention_bam_384_attention_center_x": 0.48319969246505406,
      "attention_bam_384_attention_center_distance": 0.03167892875558753,
      "attention_bam_384_attention_spatial_variance": 171.39957165690873,
      "attention_bam_384_attention_spatial_std": 13.091965920246995,
      "attention_bam_384_num_attention_peaks": 12,
      "attention_bam_384_peak_separation_mean": 19.996996290307216,
      "attention_bam_384_peak_intensity_mean": 0.3525604009628296,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12584015727043152,
      "attention_bam_16_std_attention": 0.4938547611236572,
      "attention_bam_16_max_attention": 2.686380386352539,
      "attention_bam_16_min_attention": -1.0419734716415405,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.44731300252378636,
      "attention_bam_16_attention_skewness": 0.5534908653820292,
      "attention_bam_16_attention_sparsity": 0.51318359375,
      "attention_bam_16_attention_concentration_10": 0.8589634801058695,
      "attention_bam_16_attention_concentration_20": 1.3688733793380126,
      "attention_bam_16_attention_center_y": 0.4750398728402313,
      "attention_bam_16_attention_center_x": 0.46230478197114966,
      "attention_bam_16_attention_center_distance": 0.06393649052105357,
      "attention_bam_16_attention_spatial_variance": 43.484004575514405,
      "attention_bam_16_attention_spatial_std": 6.594240257642604,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 10.156048437593329,
      "attention_bam_16_peak_intensity_mean": 0.3274993896484375,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 982,
      "phase": "train",
      "loss": 0.004882358945906162,
      "timestamp": 1759544059.4237366,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004882358945906162,
      "ssim": 0.9122804403305054,
      "attention_bam_384_mean_attention": -0.0296099204570055,
      "attention_bam_384_std_attention": 0.12906695902347565,
      "attention_bam_384_max_attention": 1.0178837776184082,
      "attention_bam_384_min_attention": -0.6625329256057739,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.3511016315374773,
      "attention_bam_384_attention_skewness": 0.2150553105697748,
      "attention_bam_384_attention_sparsity": 0.8644816080729166,
      "attention_bam_384_attention_concentration_10": -0.6933786028121299,
      "attention_bam_384_attention_concentration_20": -1.0083031880241453,
      "attention_bam_384_attention_center_y": 0.4848548312169359,
      "attention_bam_384_attention_center_x": 0.4830048491063838,
      "attention_bam_384_attention_center_distance": 0.032193517712865195,
      "attention_bam_384_attention_spatial_variance": 170.93172921644606,
      "attention_bam_384_attention_spatial_std": 13.074086171371444,
      "attention_bam_384_num_attention_peaks": 24,
      "attention_bam_384_peak_separation_mean": 17.166532951337622,
      "attention_bam_384_peak_intensity_mean": 0.37995508313179016,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12684744596481323,
      "attention_bam_16_std_attention": 0.4812784492969513,
      "attention_bam_16_max_attention": 2.290393829345703,
      "attention_bam_16_min_attention": -1.0135533809661865,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.2338495638881004,
      "attention_bam_16_attention_skewness": 0.5735411082320221,
      "attention_bam_16_attention_sparsity": 0.5263671875,
      "attention_bam_16_attention_concentration_10": 0.8450428353705769,
      "attention_bam_16_attention_concentration_20": 1.356980861728263,
      "attention_bam_16_attention_center_y": 0.4723070622152364,
      "attention_bam_16_attention_center_x": 0.4622336430596164,
      "attention_bam_16_attention_center_distance": 0.06622985006323431,
      "attention_bam_16_attention_spatial_variance": 42.775207468237305,
      "attention_bam_16_attention_spatial_std": 6.540275794508768,
      "attention_bam_16_num_attention_peaks": 12,
      "attention_bam_16_peak_separation_mean": 9.4021679696726,
      "attention_bam_16_peak_intensity_mean": 0.352126806974411,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 983,
      "phase": "train",
      "loss": 0.006031528115272522,
      "timestamp": 1759544059.6204116,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006031528115272522,
      "ssim": 0.9045243263244629,
      "attention_bam_384_mean_attention": -0.029438896104693413,
      "attention_bam_384_std_attention": 0.13023707270622253,
      "attention_bam_384_max_attention": 0.881760835647583,
      "attention_bam_384_min_attention": -0.6758472919464111,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0548244439097774,
      "attention_bam_384_attention_skewness": 0.1763787351091001,
      "attention_bam_384_attention_sparsity": 0.8598683675130209,
      "attention_bam_384_attention_concentration_10": -0.7080585624789676,
      "attention_bam_384_attention_concentration_20": -1.0332858234150013,
      "attention_bam_384_attention_center_y": 0.48307615918271096,
      "attention_bam_384_attention_center_x": 0.484432147710043,
      "attention_bam_384_attention_center_distance": 0.03251997579737284,
      "attention_bam_384_attention_spatial_variance": 170.93045241332325,
      "attention_bam_384_attention_spatial_std": 13.074037341744258,
      "attention_bam_384_num_attention_peaks": 20,
      "attention_bam_384_peak_separation_mean": 18.300273161129592,
      "attention_bam_384_peak_intensity_mean": 0.4187082350254059,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.11907333880662918,
      "attention_bam_16_std_attention": 0.49990156292915344,
      "attention_bam_16_max_attention": 2.14794921875,
      "attention_bam_16_min_attention": -1.0327891111373901,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.08051940299372218,
      "attention_bam_16_attention_skewness": 0.48130880710267604,
      "attention_bam_16_attention_sparsity": 0.523681640625,
      "attention_bam_16_attention_concentration_10": 0.9047062609279186,
      "attention_bam_16_attention_concentration_20": 1.4598884114603463,
      "attention_bam_16_attention_center_y": 0.46299153613005445,
      "attention_bam_16_attention_center_x": 0.4709665018268418,
      "attention_bam_16_attention_center_distance": 0.06652173200066043,
      "attention_bam_16_attention_spatial_variance": 42.780604214401464,
      "attention_bam_16_attention_spatial_std": 6.540688359370248,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 9.380731154096296,
      "attention_bam_16_peak_intensity_mean": 0.37180614471435547,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 984,
      "phase": "train",
      "loss": 0.002945310901850462,
      "timestamp": 1759544059.8188617,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.002945310901850462,
      "ssim": 0.9508154392242432,
      "attention_bam_384_mean_attention": -0.02914140187203884,
      "attention_bam_384_std_attention": 0.13556182384490967,
      "attention_bam_384_max_attention": 1.1496000289916992,
      "attention_bam_384_min_attention": -0.7357544898986816,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.965027024836415,
      "attention_bam_384_attention_skewness": 0.49282889876321007,
      "attention_bam_384_attention_sparsity": 0.8760172526041666,
      "attention_bam_384_attention_concentration_10": -0.789604937089689,
      "attention_bam_384_attention_concentration_20": -1.0809576339562308,
      "attention_bam_384_attention_center_y": 0.48607825467347354,
      "attention_bam_384_attention_center_x": 0.4851010374009337,
      "attention_bam_384_attention_center_distance": 0.028837270309966512,
      "attention_bam_384_attention_spatial_variance": 171.1967045901825,
      "attention_bam_384_attention_spatial_std": 13.084215856908754,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 19.99651055585459,
      "attention_bam_384_peak_intensity_mean": 0.37841570377349854,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.11988229304552078,
      "attention_bam_16_std_attention": 0.5109684467315674,
      "attention_bam_16_max_attention": 2.6703410148620605,
      "attention_bam_16_min_attention": -1.0821768045425415,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 1.6575572710751976,
      "attention_bam_16_attention_skewness": 0.963163834476815,
      "attention_bam_16_attention_sparsity": 0.54248046875,
      "attention_bam_16_attention_concentration_10": 0.9921429201152379,
      "attention_bam_16_attention_concentration_20": 1.500048258771369,
      "attention_bam_16_attention_center_y": 0.47972515422962586,
      "attention_bam_16_attention_center_x": 0.475959005303745,
      "attention_bam_16_attention_center_distance": 0.04447558424569188,
      "attention_bam_16_attention_spatial_variance": 43.155730941841405,
      "attention_bam_16_attention_spatial_std": 6.569302165515102,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.918311951761082,
      "attention_bam_16_peak_intensity_mean": 0.3272773325443268,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 985,
      "phase": "train",
      "loss": 0.003686718177050352,
      "timestamp": 1759544060.0178058,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.003686718177050352,
      "ssim": 0.9311606884002686,
      "attention_bam_384_mean_attention": -0.0290357768535614,
      "attention_bam_384_std_attention": 0.1509275585412979,
      "attention_bam_384_max_attention": 0.8427361845970154,
      "attention_bam_384_min_attention": -0.6785078048706055,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.36257979538188767,
      "attention_bam_384_attention_skewness": 0.15087808119694707,
      "attention_bam_384_attention_sparsity": 0.8138605753580729,
      "attention_bam_384_attention_concentration_10": -0.8392979150059168,
      "attention_bam_384_attention_concentration_20": -1.2593356215222484,
      "attention_bam_384_attention_center_y": 0.483752799145337,
      "attention_bam_384_attention_center_x": 0.48364474713627037,
      "attention_bam_384_attention_center_distance": 0.03260263277247097,
      "attention_bam_384_attention_spatial_variance": 171.06238788089087,
      "attention_bam_384_attention_spatial_std": 13.079082073329568,
      "attention_bam_384_num_attention_peaks": 20,
      "attention_bam_384_peak_separation_mean": 17.669171999144417,
      "attention_bam_384_peak_intensity_mean": 0.4299120306968689,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.11147354543209076,
      "attention_bam_16_std_attention": 0.553839921951294,
      "attention_bam_16_max_attention": 2.417433023452759,
      "attention_bam_16_min_attention": -1.0087759494781494,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.036080711364503415,
      "attention_bam_16_attention_skewness": 0.5864538946017135,
      "attention_bam_16_attention_sparsity": 0.539306640625,
      "attention_bam_16_attention_concentration_10": 1.0644638191911278,
      "attention_bam_16_attention_concentration_20": 1.7156624843576076,
      "attention_bam_16_attention_center_y": 0.4690574281106245,
      "attention_bam_16_attention_center_x": 0.47012356742003586,
      "attention_bam_16_attention_center_distance": 0.06082834830626774,
      "attention_bam_16_attention_spatial_variance": 43.11716416967065,
      "attention_bam_16_attention_spatial_std": 6.566366131253317,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 9.208633293196185,
      "attention_bam_16_peak_intensity_mean": 0.33054566383361816,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 986,
      "phase": "train",
      "loss": 0.0038033309392631054,
      "timestamp": 1759544060.2149062,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0038033309392631054,
      "ssim": 0.9317872524261475,
      "attention_bam_384_mean_attention": -0.028917767107486725,
      "attention_bam_384_std_attention": 0.13031600415706635,
      "attention_bam_384_max_attention": 0.9680981040000916,
      "attention_bam_384_min_attention": -0.6487034559249878,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.6377744460751833,
      "attention_bam_384_attention_skewness": 0.10464642682027746,
      "attention_bam_384_attention_sparsity": 0.8520253499348959,
      "attention_bam_384_attention_concentration_10": -0.7070131814870244,
      "attention_bam_384_attention_concentration_20": -1.0534611847261257,
      "attention_bam_384_attention_center_y": 0.4815415844584072,
      "attention_bam_384_attention_center_x": 0.4819049195239755,
      "attention_bam_384_attention_center_distance": 0.036555301715070446,
      "attention_bam_384_attention_spatial_variance": 171.77427358982334,
      "attention_bam_384_attention_spatial_std": 13.106268484577269,
      "attention_bam_384_num_attention_peaks": 18,
      "attention_bam_384_peak_separation_mean": 19.84351150432979,
      "attention_bam_384_peak_intensity_mean": 0.3857015371322632,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12270662933588028,
      "attention_bam_16_std_attention": 0.49928534030914307,
      "attention_bam_16_max_attention": 1.990039348602295,
      "attention_bam_16_min_attention": -0.9757598042488098,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.2163008435705338,
      "attention_bam_16_attention_skewness": 0.43342651942017163,
      "attention_bam_16_attention_sparsity": 0.513671875,
      "attention_bam_16_attention_concentration_10": 0.8716070798984172,
      "attention_bam_16_attention_concentration_20": 1.4228875906284257,
      "attention_bam_16_attention_center_y": 0.45306963067709277,
      "attention_bam_16_attention_center_x": 0.4562795693693973,
      "attention_bam_16_attention_center_distance": 0.09070761400576927,
      "attention_bam_16_attention_spatial_variance": 43.90063467752076,
      "attention_bam_16_attention_spatial_std": 6.6257554042932165,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 10.760863907333013,
      "attention_bam_16_peak_intensity_mean": 0.3799407482147217,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 987,
      "phase": "train",
      "loss": 0.0028688646852970123,
      "timestamp": 1759544060.6861486,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0028688646852970123,
      "ssim": 0.9417723417282104,
      "attention_bam_384_mean_attention": -0.029229722917079926,
      "attention_bam_384_std_attention": 0.12632574141025543,
      "attention_bam_384_max_attention": 1.1239053010940552,
      "attention_bam_384_min_attention": -0.7560674548149109,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.5661367067799556,
      "attention_bam_384_attention_skewness": 0.13891367687582323,
      "attention_bam_384_attention_sparsity": 0.8724441528320312,
      "attention_bam_384_attention_concentration_10": -0.6763935092590146,
      "attention_bam_384_attention_concentration_20": -0.9807293311560034,
      "attention_bam_384_attention_center_y": 0.48342679754687345,
      "attention_bam_384_attention_center_x": 0.4829468403612653,
      "attention_bam_384_attention_center_distance": 0.033629787189825934,
      "attention_bam_384_attention_spatial_variance": 170.9878071672752,
      "attention_bam_384_attention_spatial_std": 13.076230617700011,
      "attention_bam_384_num_attention_peaks": 26,
      "attention_bam_384_peak_separation_mean": 19.49538664609236,
      "attention_bam_384_peak_intensity_mean": 0.3903263509273529,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.11694242060184479,
      "attention_bam_16_std_attention": 0.48865556716918945,
      "attention_bam_16_max_attention": 2.324732542037964,
      "attention_bam_16_min_attention": -1.1858794689178467,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.2560925483833367,
      "attention_bam_16_attention_skewness": 0.5008350047704774,
      "attention_bam_16_attention_sparsity": 0.5224609375,
      "attention_bam_16_attention_concentration_10": 0.90583582326722,
      "attention_bam_16_attention_concentration_20": 1.4430332906462138,
      "attention_bam_16_attention_center_y": 0.46436159611052236,
      "attention_bam_16_attention_center_x": 0.46142260744851477,
      "attention_bam_16_attention_center_distance": 0.07427396647360263,
      "attention_bam_16_attention_spatial_variance": 42.860820282150236,
      "attention_bam_16_attention_spatial_std": 6.546817569029264,
      "attention_bam_16_num_attention_peaks": 11,
      "attention_bam_16_peak_separation_mean": 8.493705021920048,
      "attention_bam_16_peak_intensity_mean": 0.37786629796028137,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 988,
      "phase": "train",
      "loss": 0.007019173353910446,
      "timestamp": 1759544060.8276892,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.007019173353910446,
      "ssim": 0.9232581257820129,
      "attention_bam_384_mean_attention": -0.02922491542994976,
      "attention_bam_384_std_attention": 0.13900087773799896,
      "attention_bam_384_max_attention": 1.0003196001052856,
      "attention_bam_384_min_attention": -0.7378097772598267,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9518083081963149,
      "attention_bam_384_attention_skewness": 0.1635732828501109,
      "attention_bam_384_attention_sparsity": 0.8407007853190104,
      "attention_bam_384_attention_concentration_10": -0.7559104500068401,
      "attention_bam_384_attention_concentration_20": -1.1202939790560082,
      "attention_bam_384_attention_center_y": 0.4843130151690157,
      "attention_bam_384_attention_center_x": 0.48285021998937644,
      "attention_bam_384_attention_center_distance": 0.03286933061382038,
      "attention_bam_384_attention_spatial_variance": 171.49250159930733,
      "attention_bam_384_attention_spatial_std": 13.095514560310615,
      "attention_bam_384_num_attention_peaks": 19,
      "attention_bam_384_peak_separation_mean": 19.207278967166893,
      "attention_bam_384_peak_intensity_mean": 0.4105015993118286,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12193571776151657,
      "attention_bam_16_std_attention": 0.5217231512069702,
      "attention_bam_16_max_attention": 2.511549711227417,
      "attention_bam_16_min_attention": -1.0044547319412231,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.03985525597810069,
      "attention_bam_16_attention_skewness": 0.5349872296782029,
      "attention_bam_16_attention_sparsity": 0.51806640625,
      "attention_bam_16_attention_concentration_10": 0.9340579074580174,
      "attention_bam_16_attention_concentration_20": 1.4967546919567714,
      "attention_bam_16_attention_center_y": 0.4707943551275224,
      "attention_bam_16_attention_center_x": 0.4610381127958902,
      "attention_bam_16_attention_center_distance": 0.06886215719715806,
      "attention_bam_16_attention_spatial_variance": 43.78217635782611,
      "attention_bam_16_attention_spatial_std": 6.616810134636335,
      "attention_bam_16_num_attention_peaks": 11,
      "attention_bam_16_peak_separation_mean": 9.581869787866026,
      "attention_bam_16_peak_intensity_mean": 0.3274540901184082,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 989,
      "phase": "train",
      "loss": 0.0035862093791365623,
      "timestamp": 1759544060.9762745,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0035862093791365623,
      "ssim": 0.9394190311431885,
      "attention_bam_384_mean_attention": -0.028991445899009705,
      "attention_bam_384_std_attention": 0.12244413048028946,
      "attention_bam_384_max_attention": 0.7718648910522461,
      "attention_bam_384_min_attention": -0.6549246311187744,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0124325397837382,
      "attention_bam_384_attention_skewness": 0.040341786590314586,
      "attention_bam_384_attention_sparsity": 0.8755340576171875,
      "attention_bam_384_attention_concentration_10": -0.6495325565658769,
      "attention_bam_384_attention_concentration_20": -0.9511835269950567,
      "attention_bam_384_attention_center_y": 0.48291812300477216,
      "attention_bam_384_attention_center_x": 0.4814031468725827,
      "attention_bam_384_attention_center_distance": 0.03571087979657812,
      "attention_bam_384_attention_spatial_variance": 170.4797202765679,
      "attention_bam_384_attention_spatial_std": 13.0567882833631,
      "attention_bam_384_num_attention_peaks": 14,
      "attention_bam_384_peak_separation_mean": 16.728359415384368,
      "attention_bam_384_peak_intensity_mean": 0.44193556904792786,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12104398012161255,
      "attention_bam_16_std_attention": 0.48494043946266174,
      "attention_bam_16_max_attention": 2.1660473346710205,
      "attention_bam_16_min_attention": -1.0073795318603516,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.038129393809615664,
      "attention_bam_16_attention_skewness": 0.41968005300169514,
      "attention_bam_16_attention_sparsity": 0.50927734375,
      "attention_bam_16_attention_concentration_10": 0.852479292432361,
      "attention_bam_16_attention_concentration_20": 1.3875870908498575,
      "attention_bam_16_attention_center_y": 0.46442636903118983,
      "attention_bam_16_attention_center_x": 0.4536992905784898,
      "attention_bam_16_attention_center_distance": 0.0825740747842834,
      "attention_bam_16_attention_spatial_variance": 42.03319133181118,
      "attention_bam_16_attention_spatial_std": 6.4833009595275755,
      "attention_bam_16_num_attention_peaks": 5,
      "attention_bam_16_peak_separation_mean": 7.850424287664199,
      "attention_bam_16_peak_intensity_mean": 0.3700886368751526,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 990,
      "phase": "train",
      "loss": 0.003706700634211302,
      "timestamp": 1759544061.1702988,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.003706700634211302,
      "ssim": 0.9445710182189941,
      "attention_bam_384_mean_attention": -0.029166189953684807,
      "attention_bam_384_std_attention": 0.12294246256351471,
      "attention_bam_384_max_attention": 0.9575368762016296,
      "attention_bam_384_min_attention": -0.6230702996253967,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.343180972532287,
      "attention_bam_384_attention_skewness": 0.15970499211275255,
      "attention_bam_384_attention_sparsity": 0.8776397705078125,
      "attention_bam_384_attention_concentration_10": -0.6604340617514876,
      "attention_bam_384_attention_concentration_20": -0.9547921173108241,
      "attention_bam_384_attention_center_y": 0.48279582552674494,
      "attention_bam_384_attention_center_x": 0.48477991068389725,
      "attention_bam_384_attention_center_distance": 0.03248491151585135,
      "attention_bam_384_attention_spatial_variance": 170.55499696542947,
      "attention_bam_384_attention_spatial_std": 13.059670630051489,
      "attention_bam_384_num_attention_peaks": 13,
      "attention_bam_384_peak_separation_mean": 18.29596842517473,
      "attention_bam_384_peak_intensity_mean": 0.3796411156654358,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12114345282316208,
      "attention_bam_16_std_attention": 0.48497650027275085,
      "attention_bam_16_max_attention": 2.093120813369751,
      "attention_bam_16_min_attention": -0.9730809926986694,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.20621313473272718,
      "attention_bam_16_attention_skewness": 0.533020587777108,
      "attention_bam_16_attention_sparsity": 0.518798828125,
      "attention_bam_16_attention_concentration_10": 0.8765679891436908,
      "attention_bam_16_attention_concentration_20": 1.4004057541358255,
      "attention_bam_16_attention_center_y": 0.46135432508209384,
      "attention_bam_16_attention_center_x": 0.47480068378603224,
      "attention_bam_16_attention_center_distance": 0.06524559337628894,
      "attention_bam_16_attention_spatial_variance": 42.350587015702715,
      "attention_bam_16_attention_spatial_std": 6.507732862964084,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 8.565995182752532,
      "attention_bam_16_peak_intensity_mean": 0.3601718544960022,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 991,
      "phase": "train",
      "loss": 0.004664821550250053,
      "timestamp": 1759544061.3191292,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004664821550250053,
      "ssim": 0.9438976645469666,
      "attention_bam_384_mean_attention": -0.029469706118106842,
      "attention_bam_384_std_attention": 0.12543684244155884,
      "attention_bam_384_max_attention": 0.8704631328582764,
      "attention_bam_384_min_attention": -0.6187542080879211,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.2082540699657187,
      "attention_bam_384_attention_skewness": 0.18038221774556282,
      "attention_bam_384_attention_sparsity": 0.8723576863606771,
      "attention_bam_384_attention_concentration_10": -0.6803555700961984,
      "attention_bam_384_attention_concentration_20": -0.9799742475845657,
      "attention_bam_384_attention_center_y": 0.48433427975745685,
      "attention_bam_384_attention_center_x": 0.4840519484227867,
      "attention_bam_384_attention_center_distance": 0.03161503249490918,
      "attention_bam_384_attention_spatial_variance": 170.62349135282298,
      "attention_bam_384_attention_spatial_std": 13.062292729564094,
      "attention_bam_384_num_attention_peaks": 20,
      "attention_bam_384_peak_separation_mean": 19.41120127281384,
      "attention_bam_384_peak_intensity_mean": 0.40097981691360474,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.121285580098629,
      "attention_bam_16_std_attention": 0.4871939718723297,
      "attention_bam_16_max_attention": 1.982966661453247,
      "attention_bam_16_min_attention": -1.0055725574493408,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.06603286854136403,
      "attention_bam_16_attention_skewness": 0.5122456267589478,
      "attention_bam_16_attention_sparsity": 0.525146484375,
      "attention_bam_16_attention_concentration_10": 0.8853161574704268,
      "attention_bam_16_attention_concentration_20": 1.4128454557595773,
      "attention_bam_16_attention_center_y": 0.4686988912780471,
      "attention_bam_16_attention_center_x": 0.4691109494022697,
      "attention_bam_16_attention_center_distance": 0.062191524407312244,
      "attention_bam_16_attention_spatial_variance": 42.41675147437892,
      "attention_bam_16_attention_spatial_std": 6.512814405030971,
      "attention_bam_16_num_attention_peaks": 8,
      "attention_bam_16_peak_separation_mean": 8.923415448273415,
      "attention_bam_16_peak_intensity_mean": 0.3843398690223694,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 992,
      "phase": "train",
      "loss": 0.003645323682576418,
      "timestamp": 1759544061.5000856,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.003645323682576418,
      "ssim": 0.9436119794845581,
      "attention_bam_384_mean_attention": -0.029323192313313484,
      "attention_bam_384_std_attention": 0.14188696444034576,
      "attention_bam_384_max_attention": 1.0808331966400146,
      "attention_bam_384_min_attention": -0.7706975340843201,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 2.43432509835597,
      "attention_bam_384_attention_skewness": 0.4135396361767717,
      "attention_bam_384_attention_sparsity": 0.8577804565429688,
      "attention_bam_384_attention_concentration_10": -0.8079687292636674,
      "attention_bam_384_attention_concentration_20": -1.1379808906143032,
      "attention_bam_384_attention_center_y": 0.4843976368448002,
      "attention_bam_384_attention_center_x": 0.48428510332912883,
      "attention_bam_384_attention_center_distance": 0.031317462010925924,
      "attention_bam_384_attention_spatial_variance": 171.5959793025056,
      "attention_bam_384_attention_spatial_std": 13.09946484794343,
      "attention_bam_384_num_attention_peaks": 15,
      "attention_bam_384_peak_separation_mean": 20.39763566148716,
      "attention_bam_384_peak_intensity_mean": 0.4045848250389099,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.11536577343940735,
      "attention_bam_16_std_attention": 0.5395976901054382,
      "attention_bam_16_max_attention": 2.1908528804779053,
      "attention_bam_16_min_attention": -1.1162891387939453,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5374261235970308,
      "attention_bam_16_attention_skewness": 0.6760751308361518,
      "attention_bam_16_attention_sparsity": 0.5341796875,
      "attention_bam_16_attention_concentration_10": 1.0381914207176615,
      "attention_bam_16_attention_concentration_20": 1.6138278851840826,
      "attention_bam_16_attention_center_y": 0.4678328944323491,
      "attention_bam_16_attention_center_x": 0.4735120503626074,
      "attention_bam_16_attention_center_distance": 0.05892935018466509,
      "attention_bam_16_attention_spatial_variance": 43.733440677140784,
      "attention_bam_16_attention_spatial_std": 6.613126392043387,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 7.785301103490342,
      "attention_bam_16_peak_intensity_mean": 0.38234519958496094,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 993,
      "phase": "train",
      "loss": 0.013461632654070854,
      "timestamp": 1759544061.693868,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.013461632654070854,
      "ssim": 0.8475643396377563,
      "attention_bam_384_mean_attention": -0.0288811307400465,
      "attention_bam_384_std_attention": 0.10648597031831741,
      "attention_bam_384_max_attention": 0.6048619151115417,
      "attention_bam_384_min_attention": -0.5810842514038086,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.0737967365883074,
      "attention_bam_384_attention_skewness": -0.014278845522224248,
      "attention_bam_384_attention_sparsity": 0.9064381917317709,
      "attention_bam_384_attention_concentration_10": -0.5564811280416703,
      "attention_bam_384_attention_concentration_20": -0.8001895076994657,
      "attention_bam_384_attention_center_y": 0.48456146512959686,
      "attention_bam_384_attention_center_x": 0.48361983670523107,
      "attention_bam_384_attention_center_distance": 0.03183262818266658,
      "attention_bam_384_attention_spatial_variance": 170.47108857161746,
      "attention_bam_384_attention_spatial_std": 13.056457734455293,
      "attention_bam_384_num_attention_peaks": 24,
      "attention_bam_384_peak_separation_mean": 18.43942885933291,
      "attention_bam_384_peak_intensity_mean": 0.4700510501861572,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.11704343557357788,
      "attention_bam_16_std_attention": 0.4349021315574646,
      "attention_bam_16_max_attention": 1.886490821838379,
      "attention_bam_16_min_attention": -1.0041793584823608,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.21438086896503172,
      "attention_bam_16_attention_skewness": 0.4285764666410056,
      "attention_bam_16_attention_sparsity": 0.503173828125,
      "attention_bam_16_attention_concentration_10": 0.808022303199125,
      "attention_bam_16_attention_concentration_20": 1.2893612600263833,
      "attention_bam_16_attention_center_y": 0.471672523490138,
      "attention_bam_16_attention_center_x": 0.46671730317122817,
      "attention_bam_16_attention_center_distance": 0.06180912284788907,
      "attention_bam_16_attention_spatial_variance": 42.26351817239671,
      "attention_bam_16_attention_spatial_std": 6.501039776250927,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 8.573839375805507,
      "attention_bam_16_peak_intensity_mean": 0.3948161005973816,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 994,
      "phase": "train",
      "loss": 0.004190355539321899,
      "timestamp": 1759544061.888837,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004190355539321899,
      "ssim": 0.9281299114227295,
      "attention_bam_384_mean_attention": -0.029061676934361458,
      "attention_bam_384_std_attention": 0.12743015587329865,
      "attention_bam_384_max_attention": 1.069813847541809,
      "attention_bam_384_min_attention": -0.7381669878959656,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.9640401150114073,
      "attention_bam_384_attention_skewness": 0.30747199615492626,
      "attention_bam_384_attention_sparsity": 0.8686625162760416,
      "attention_bam_384_attention_concentration_10": -0.7021168237958381,
      "attention_bam_384_attention_concentration_20": -1.014193656229339,
      "attention_bam_384_attention_center_y": 0.4812936041330815,
      "attention_bam_384_attention_center_x": 0.48182218524929815,
      "attention_bam_384_attention_center_distance": 0.03688799792454722,
      "attention_bam_384_attention_spatial_variance": 170.91947742678516,
      "attention_bam_384_attention_spatial_std": 13.073617610546254,
      "attention_bam_384_num_attention_peaks": 19,
      "attention_bam_384_peak_separation_mean": 17.018141423669906,
      "attention_bam_384_peak_intensity_mean": 0.39630913734436035,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.11656364798545837,
      "attention_bam_16_std_attention": 0.48190972208976746,
      "attention_bam_16_max_attention": 2.4697844982147217,
      "attention_bam_16_min_attention": -1.0854954719543457,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.33973223507354033,
      "attention_bam_16_attention_skewness": 0.608085576286787,
      "attention_bam_16_attention_sparsity": 0.538818359375,
      "attention_bam_16_attention_concentration_10": 0.9086364713491609,
      "attention_bam_16_attention_concentration_20": 1.454253230477512,
      "attention_bam_16_attention_center_y": 0.4534511021597598,
      "attention_bam_16_attention_center_x": 0.4539943867392192,
      "attention_bam_16_attention_center_distance": 0.09255610559700149,
      "attention_bam_16_attention_spatial_variance": 42.760317314844144,
      "attention_bam_16_attention_spatial_std": 6.5391373524987335,
      "attention_bam_16_num_attention_peaks": 7,
      "attention_bam_16_peak_separation_mean": 7.147859938872547,
      "attention_bam_16_peak_intensity_mean": 0.3519412577152252,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 995,
      "phase": "train",
      "loss": 0.0036550848744809628,
      "timestamp": 1759544062.0806782,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0036550848744809628,
      "ssim": 0.9435613751411438,
      "attention_bam_384_mean_attention": -0.028556669130921364,
      "attention_bam_384_std_attention": 0.13840383291244507,
      "attention_bam_384_max_attention": 0.9748179912567139,
      "attention_bam_384_min_attention": -0.7378908395767212,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.3649948743100584,
      "attention_bam_384_attention_skewness": 0.2965861997250885,
      "attention_bam_384_attention_sparsity": 0.852386474609375,
      "attention_bam_384_attention_concentration_10": -0.8020466091302706,
      "attention_bam_384_attention_concentration_20": -1.1527144478988882,
      "attention_bam_384_attention_center_y": 0.48749622083694294,
      "attention_bam_384_attention_center_x": 0.48335352208174354,
      "attention_bam_384_attention_center_distance": 0.029443156095823014,
      "attention_bam_384_attention_spatial_variance": 170.95332196825063,
      "attention_bam_384_attention_spatial_std": 13.074911929655611,
      "attention_bam_384_num_attention_peaks": 16,
      "attention_bam_384_peak_separation_mean": 17.512126588510895,
      "attention_bam_384_peak_intensity_mean": 0.4179115891456604,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1189187690615654,
      "attention_bam_16_std_attention": 0.5388643145561218,
      "attention_bam_16_max_attention": 2.88497257232666,
      "attention_bam_16_min_attention": -1.106162190437317,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.7158971997492904,
      "attention_bam_16_attention_skewness": 0.7661294171482155,
      "attention_bam_16_attention_sparsity": 0.541748046875,
      "attention_bam_16_attention_concentration_10": 1.0231820586047435,
      "attention_bam_16_attention_concentration_20": 1.588473459066805,
      "attention_bam_16_attention_center_y": 0.4881430036675592,
      "attention_bam_16_attention_center_x": 0.4654626372449341,
      "attention_bam_16_attention_center_distance": 0.05164141338310811,
      "attention_bam_16_attention_spatial_variance": 42.768021296334965,
      "attention_bam_16_attention_spatial_std": 6.539726393079069,
      "attention_bam_16_num_attention_peaks": 4,
      "attention_bam_16_peak_separation_mean": 7.733568451943536,
      "attention_bam_16_peak_intensity_mean": 0.32189762592315674,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 996,
      "phase": "train",
      "loss": 0.004488375969231129,
      "timestamp": 1759544062.2734041,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.004488375969231129,
      "ssim": 0.9114058613777161,
      "attention_bam_384_mean_attention": -0.028317978605628014,
      "attention_bam_384_std_attention": 0.13316610455513,
      "attention_bam_384_max_attention": 1.0383051633834839,
      "attention_bam_384_min_attention": -0.7379603385925293,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.3732086069587064,
      "attention_bam_384_attention_skewness": 0.22163758345179763,
      "attention_bam_384_attention_sparsity": 0.8589579264322916,
      "attention_bam_384_attention_concentration_10": -0.7547273696141005,
      "attention_bam_384_attention_concentration_20": -1.0953233744288635,
      "attention_bam_384_attention_center_y": 0.4845272858162112,
      "attention_bam_384_attention_center_x": 0.48408984593994764,
      "attention_bam_384_attention_center_distance": 0.031385916791701975,
      "attention_bam_384_attention_spatial_variance": 170.652986966051,
      "attention_bam_384_attention_spatial_std": 13.063421717377533,
      "attention_bam_384_num_attention_peaks": 22,
      "attention_bam_384_peak_separation_mean": 19.00112320148656,
      "attention_bam_384_peak_intensity_mean": 0.4025470018386841,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12204001843929291,
      "attention_bam_16_std_attention": 0.5064144730567932,
      "attention_bam_16_max_attention": 3.6616649627685547,
      "attention_bam_16_min_attention": -1.1118110418319702,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5427416353473218,
      "attention_bam_16_attention_skewness": 0.5885220329979698,
      "attention_bam_16_attention_sparsity": 0.527099609375,
      "attention_bam_16_attention_concentration_10": 0.9034939334739653,
      "attention_bam_16_attention_concentration_20": 1.4543929175492052,
      "attention_bam_16_attention_center_y": 0.469408842133214,
      "attention_bam_16_attention_center_x": 0.4697806864489147,
      "attention_bam_16_attention_center_distance": 0.0608116082854159,
      "attention_bam_16_attention_spatial_variance": 42.59173077671653,
      "attention_bam_16_attention_spatial_std": 6.5262340424410565,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 10.307225302781877,
      "attention_bam_16_peak_intensity_mean": 0.2597832977771759,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 997,
      "phase": "train",
      "loss": 0.0049404241144657135,
      "timestamp": 1759544062.4594288,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0049404241144657135,
      "ssim": 0.8926616907119751,
      "attention_bam_384_mean_attention": -0.028124799951910973,
      "attention_bam_384_std_attention": 0.11394936591386795,
      "attention_bam_384_max_attention": 0.711306095123291,
      "attention_bam_384_min_attention": -0.6581912040710449,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 0.9448574543536847,
      "attention_bam_384_attention_skewness": 0.04177351436562314,
      "attention_bam_384_attention_sparsity": 0.8863703409830729,
      "attention_bam_384_attention_concentration_10": -0.6207685256978523,
      "attention_bam_384_attention_concentration_20": -0.9122281346535349,
      "attention_bam_384_attention_center_y": 0.48140428500219057,
      "attention_bam_384_attention_center_x": 0.48570732047489934,
      "attention_bam_384_attention_center_distance": 0.03316869922945385,
      "attention_bam_384_attention_spatial_variance": 170.78097838583741,
      "attention_bam_384_attention_spatial_std": 13.068319646604815,
      "attention_bam_384_num_attention_peaks": 19,
      "attention_bam_384_peak_separation_mean": 17.36292036494979,
      "attention_bam_384_peak_intensity_mean": 0.4632912278175354,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12587851285934448,
      "attention_bam_16_std_attention": 0.4484626054763794,
      "attention_bam_16_max_attention": 1.8565306663513184,
      "attention_bam_16_min_attention": -0.9352536201477051,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": -0.09029571355037946,
      "attention_bam_16_attention_skewness": 0.43021203448146755,
      "attention_bam_16_attention_sparsity": 0.50732421875,
      "attention_bam_16_attention_concentration_10": 0.7785668152229968,
      "attention_bam_16_attention_concentration_20": 1.259736416296296,
      "attention_bam_16_attention_center_y": 0.4522145150671838,
      "attention_bam_16_attention_center_x": 0.4783371188249246,
      "attention_bam_16_attention_center_distance": 0.07419882736364289,
      "attention_bam_16_attention_spatial_variance": 42.816955358981815,
      "attention_bam_16_attention_spatial_std": 6.543466616326686,
      "attention_bam_16_num_attention_peaks": 9,
      "attention_bam_16_peak_separation_mean": 8.583765439793147,
      "attention_bam_16_peak_intensity_mean": 0.38840967416763306,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 998,
      "phase": "train",
      "loss": 0.0037688277661800385,
      "timestamp": 1759544062.6359687,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.0037688277661800385,
      "ssim": 0.9151089191436768,
      "attention_bam_384_mean_attention": -0.028157003223896027,
      "attention_bam_384_std_attention": 0.1344728022813797,
      "attention_bam_384_max_attention": 1.0158326625823975,
      "attention_bam_384_min_attention": -0.7254501581192017,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.6372404758891639,
      "attention_bam_384_attention_skewness": 0.25762199316216183,
      "attention_bam_384_attention_sparsity": 0.8581263224283854,
      "attention_bam_384_attention_concentration_10": -0.7799178426093132,
      "attention_bam_384_attention_concentration_20": -1.123884730568326,
      "attention_bam_384_attention_center_y": 0.48390195132223435,
      "attention_bam_384_attention_center_x": 0.48307391727751064,
      "attention_bam_384_attention_center_distance": 0.03303451066870115,
      "attention_bam_384_attention_spatial_variance": 171.017708163262,
      "attention_bam_384_attention_spatial_std": 13.077373901638738,
      "attention_bam_384_num_attention_peaks": 19,
      "attention_bam_384_peak_separation_mean": 18.302783834553605,
      "attention_bam_384_peak_intensity_mean": 0.40212351083755493,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1206747442483902,
      "attention_bam_16_std_attention": 0.5171420574188232,
      "attention_bam_16_max_attention": 3.0263123512268066,
      "attention_bam_16_min_attention": -1.1005951166152954,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.6757812871697446,
      "attention_bam_16_attention_skewness": 0.6644006439003333,
      "attention_bam_16_attention_sparsity": 0.525390625,
      "attention_bam_16_attention_concentration_10": 0.939807022279987,
      "attention_bam_16_attention_concentration_20": 1.4929065135846153,
      "attention_bam_16_attention_center_y": 0.4681827033391623,
      "attention_bam_16_attention_center_x": 0.46339319481078356,
      "attention_bam_16_attention_center_distance": 0.06859152357201286,
      "attention_bam_16_attention_spatial_variance": 43.040543982699624,
      "attention_bam_16_attention_spatial_std": 6.560529245624901,
      "attention_bam_16_num_attention_peaks": 10,
      "attention_bam_16_peak_separation_mean": 8.88188076372833,
      "attention_bam_16_peak_intensity_mean": 0.30062776803970337,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 999,
      "phase": "train",
      "loss": 0.006034092977643013,
      "timestamp": 1759544062.8097627,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.006034092977643013,
      "ssim": 0.9163742661476135,
      "attention_bam_384_mean_attention": -0.027709076181054115,
      "attention_bam_384_std_attention": 0.12368915230035782,
      "attention_bam_384_max_attention": 0.9005854725837708,
      "attention_bam_384_min_attention": -0.6747735142707825,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.4917386650870794,
      "attention_bam_384_attention_skewness": 0.1658117900437357,
      "attention_bam_384_attention_sparsity": 0.8733851114908854,
      "attention_bam_384_attention_concentration_10": -0.7128795817719098,
      "attention_bam_384_attention_concentration_20": -1.0302657094815406,
      "attention_bam_384_attention_center_y": 0.4850317725997097,
      "attention_bam_384_attention_center_x": 0.4818261755881373,
      "attention_bam_384_attention_center_distance": 0.03329671831457324,
      "attention_bam_384_attention_spatial_variance": 170.87580938170217,
      "attention_bam_384_attention_spatial_std": 13.071947421164996,
      "attention_bam_384_num_attention_peaks": 24,
      "attention_bam_384_peak_separation_mean": 16.124143553007258,
      "attention_bam_384_peak_intensity_mean": 0.4129055440425873,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.1234445720911026,
      "attention_bam_16_std_attention": 0.4837888479232788,
      "attention_bam_16_max_attention": 2.779287338256836,
      "attention_bam_16_min_attention": -1.0053050518035889,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.5100712710609017,
      "attention_bam_16_attention_skewness": 0.5720047073700053,
      "attention_bam_16_attention_sparsity": 0.519775390625,
      "attention_bam_16_attention_concentration_10": 0.8656918420079326,
      "attention_bam_16_attention_concentration_20": 1.3737837878347001,
      "attention_bam_16_attention_center_y": 0.4718587994798237,
      "attention_bam_16_attention_center_x": 0.4565826659215151,
      "attention_bam_16_attention_center_distance": 0.07317092407779936,
      "attention_bam_16_attention_spatial_variance": 42.96813643869428,
      "attention_bam_16_attention_spatial_std": 6.55500850027628,
      "attention_bam_16_num_attention_peaks": 12,
      "attention_bam_16_peak_separation_mean": 8.735999225434794,
      "attention_bam_16_peak_intensity_mean": 0.3008071780204773,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    {
      "batch_idx": 1000,
      "phase": "train",
      "loss": 0.003982855472713709,
      "timestamp": 1759544063.025713,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.003982855472713709,
      "ssim": 0.9285092353820801,
      "attention_bam_384_mean_attention": -0.028206177055835724,
      "attention_bam_384_std_attention": 0.12738369405269623,
      "attention_bam_384_max_attention": 0.9469776749610901,
      "attention_bam_384_min_attention": -0.6859111785888672,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.297716431844015,
      "attention_bam_384_attention_skewness": 0.17745462521114705,
      "attention_bam_384_attention_sparsity": 0.8623606363932291,
      "attention_bam_384_attention_concentration_10": -0.7168746076871341,
      "attention_bam_384_attention_concentration_20": -1.0512559887665947,
      "attention_bam_384_attention_center_y": 0.48554201593079327,
      "attention_bam_384_attention_center_x": 0.4850428253868179,
      "attention_bam_384_attention_center_distance": 0.029419394139059155,
      "attention_bam_384_attention_spatial_variance": 171.13745198582717,
      "attention_bam_384_attention_spatial_std": 13.081951382948462,
      "attention_bam_384_num_attention_peaks": 21,
      "attention_bam_384_peak_separation_mean": 18.949436005377795,
      "attention_bam_384_peak_intensity_mean": 0.4047793447971344,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12401154637336731,
      "attention_bam_16_std_attention": 0.4965234100818634,
      "attention_bam_16_max_attention": 2.2593979835510254,
      "attention_bam_16_min_attention": -1.1299781799316406,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.15844585539115075,
      "attention_bam_16_attention_skewness": 0.5210654730564742,
      "attention_bam_16_attention_sparsity": 0.521484375,
      "attention_bam_16_attention_concentration_10": 0.8668938922051795,
      "attention_bam_16_attention_concentration_20": 1.397508901986528,
      "attention_bam_16_attention_center_y": 0.4753184231996529,
      "attention_bam_16_attention_center_x": 0.47247722970836165,
      "attention_bam_16_attention_center_distance": 0.05228160513751893,
      "attention_bam_16_attention_spatial_variance": 43.11114215740959,
      "attention_bam_16_attention_spatial_std": 6.565907565402485,
      "attention_bam_16_num_attention_peaks": 11,
      "attention_bam_16_peak_separation_mean": 9.379413199440945,
      "attention_bam_16_peak_intensity_mean": 0.37962090969085693,
      "attention_bam_16_peak_coverage": 0.1015625
    }
  ],
  "summary": {
    "total_batches": 1003,
    "latest_batch": 1000,
    "latest_metrics": {
      "batch_idx": 1000,
      "phase": "train",
      "loss": 0.003982855472713709,
      "timestamp": 1759544063.025713,
      "attention_layers": [
        "encoder_kan",
        "bam_384",
        "bam_16",
        "decoder_kan"
      ],
      "mse": 0.003982855472713709,
      "ssim": 0.9285092353820801,
      "attention_bam_384_mean_attention": -0.028206177055835724,
      "attention_bam_384_std_attention": 0.12738369405269623,
      "attention_bam_384_max_attention": 0.9469776749610901,
      "attention_bam_384_min_attention": -0.6859111785888672,
      "attention_bam_384_attention_entropy": NaN,
      "attention_bam_384_attention_kurtosis": 1.297716431844015,
      "attention_bam_384_attention_skewness": 0.17745462521114705,
      "attention_bam_384_attention_sparsity": 0.8623606363932291,
      "attention_bam_384_attention_concentration_10": -0.7168746076871341,
      "attention_bam_384_attention_concentration_20": -1.0512559887665947,
      "attention_bam_384_attention_center_y": 0.48554201593079327,
      "attention_bam_384_attention_center_x": 0.4850428253868179,
      "attention_bam_384_attention_center_distance": 0.029419394139059155,
      "attention_bam_384_attention_spatial_variance": 171.13745198582717,
      "attention_bam_384_attention_spatial_std": 13.081951382948462,
      "attention_bam_384_num_attention_peaks": 21,
      "attention_bam_384_peak_separation_mean": 18.949436005377795,
      "attention_bam_384_peak_intensity_mean": 0.4047793447971344,
      "attention_bam_384_peak_coverage": 0.1005859375,
      "attention_bam_16_mean_attention": 0.12401154637336731,
      "attention_bam_16_std_attention": 0.4965234100818634,
      "attention_bam_16_max_attention": 2.2593979835510254,
      "attention_bam_16_min_attention": -1.1299781799316406,
      "attention_bam_16_attention_entropy": NaN,
      "attention_bam_16_attention_kurtosis": 0.15844585539115075,
      "attention_bam_16_attention_skewness": 0.5210654730564742,
      "attention_bam_16_attention_sparsity": 0.521484375,
      "attention_bam_16_attention_concentration_10": 0.8668938922051795,
      "attention_bam_16_attention_concentration_20": 1.397508901986528,
      "attention_bam_16_attention_center_y": 0.4753184231996529,
      "attention_bam_16_attention_center_x": 0.47247722970836165,
      "attention_bam_16_attention_center_distance": 0.05228160513751893,
      "attention_bam_16_attention_spatial_variance": 43.11114215740959,
      "attention_bam_16_attention_spatial_std": 6.565907565402485,
      "attention_bam_16_num_attention_peaks": 11,
      "attention_bam_16_peak_separation_mean": 9.379413199440945,
      "attention_bam_16_peak_intensity_mean": 0.37962090969085693,
      "attention_bam_16_peak_coverage": 0.1015625
    },
    "loss_mean": 0.0269685227629113,
    "loss_std": 0.06809872139668796,
    "loss_min": 0.0025238171219825745,
    "loss_max": 0.4267430305480957,
    "mse_mean": 0.0269685227629113,
    "mse_std": 0.06809872139668796,
    "mse_min": 0.0025238171219825745,
    "mse_max": 0.4267430305480957,
    "ssim_mean": 0.8254124022934116,
    "ssim_std": 0.1946186324714444,
    "ssim_min": 0.00020899297669529915,
    "ssim_max": 0.9560632109642029,
    "attention_bam_384_mean_attention_mean": 0.06256173327165922,
    "attention_bam_384_mean_attention_std": 0.0798710176183896,
    "attention_bam_384_mean_attention_min": -0.031574491411447525,
    "attention_bam_384_mean_attention_max": 0.24939437210559845,
    "attention_bam_384_std_attention_mean": 0.3166052628148826,
    "attention_bam_384_std_attention_std": 0.14447865523006143,
    "attention_bam_384_std_attention_min": 0.10648597031831741,
    "attention_bam_384_std_attention_max": 0.6589744091033936,
    "attention_bam_384_max_attention_mean": 2.634611808825823,
    "attention_bam_384_max_attention_std": 1.4080871312769225,
    "attention_bam_384_max_attention_min": 0.6048619151115417,
    "attention_bam_384_max_attention_max": 7.411942481994629,
    "attention_bam_384_min_attention_mean": -1.0497611468121157,
    "attention_bam_384_min_attention_std": 0.31734294635325416,
    "attention_bam_384_min_attention_min": -1.7483779191970825,
    "attention_bam_384_min_attention_max": -0.5810842514038086,
    "attention_bam_384_attention_entropy_mean": NaN,
    "attention_bam_384_attention_entropy_std": NaN,
    "attention_bam_384_attention_entropy_min": NaN,
    "attention_bam_384_attention_entropy_max": NaN,
    "attention_bam_384_attention_kurtosis_mean": 1.3842263400958081,
    "attention_bam_384_attention_kurtosis_std": 0.8763375234287609,
    "attention_bam_384_attention_kurtosis_min": -0.04150698504477912,
    "attention_bam_384_attention_kurtosis_max": 8.835262920675946,
    "attention_bam_384_attention_skewness_mean": 0.5987182172974701,
    "attention_bam_384_attention_skewness_std": 0.24917773477936234,
    "attention_bam_384_attention_skewness_min": -0.014278845522224248,
    "attention_bam_384_attention_skewness_max": 1.612352904393224,
    "attention_bam_384_attention_sparsity_mean": 0.6337840117343283,
    "attention_bam_384_attention_sparsity_std": 0.136569184909492,
    "attention_bam_384_attention_sparsity_min": 0.383392333984375,
    "attention_bam_384_attention_sparsity_max": 0.9064381917317709,
    "attention_bam_384_attention_concentration_10_mean": 0.8053886842611209,
    "attention_bam_384_attention_concentration_10_std": 2.540690838774022,
    "attention_bam_384_attention_concentration_10_min": -8.900731220434746,
    "attention_bam_384_attention_concentration_10_max": 51.543660299016246,
    "attention_bam_384_attention_concentration_20_mean": 1.2489193227735045,
    "attention_bam_384_attention_concentration_20_std": 3.8263807528432285,
    "attention_bam_384_attention_concentration_20_min": -13.58924026628768,
    "attention_bam_384_attention_concentration_20_max": 76.99026467900704,
    "attention_bam_384_attention_center_y_mean": 0.48370124553504984,
    "attention_bam_384_attention_center_y_std": 0.0035563448311402117,
    "attention_bam_384_attention_center_y_min": 0.4717375121912036,
    "attention_bam_384_attention_center_y_max": 0.4948224063987425,
    "attention_bam_384_attention_center_x_mean": 0.48348135201536296,
    "attention_bam_384_attention_center_x_std": 0.0034977093803540333,
    "attention_bam_384_attention_center_x_min": 0.47011140629269865,
    "attention_bam_384_attention_center_x_max": 0.4963852482828458,
    "attention_bam_384_attention_center_distance_mean": 0.03319874076545574,
    "attention_bam_384_attention_center_distance_std": 0.004961039330752147,
    "attention_bam_384_attention_center_distance_min": 0.01644010957551244,
    "attention_bam_384_attention_center_distance_max": 0.05429225365447837,
    "attention_bam_384_attention_spatial_variance_mean": 170.97258821391165,
    "attention_bam_384_attention_spatial_variance_std": 1.2201511984816347,
    "attention_bam_384_attention_spatial_variance_min": 165.6335767446653,
    "attention_bam_384_attention_spatial_variance_max": 175.05412062766993,
    "attention_bam_384_attention_spatial_std_mean": 13.075565468645182,
    "attention_bam_384_attention_spatial_std_std": 0.04666969714209183,
    "attention_bam_384_attention_spatial_std_min": 12.869870890753539,
    "attention_bam_384_attention_spatial_std_max": 13.230801964645602,
    "attention_bam_384_num_attention_peaks_mean": 13.00099700897308,
    "attention_bam_384_num_attention_peaks_std": 4.6822166435990376,
    "attention_bam_384_num_attention_peaks_min": 3.0,
    "attention_bam_384_num_attention_peaks_max": 30.0,
    "attention_bam_384_peak_separation_mean_mean": 18.160623087408513,
    "attention_bam_384_peak_separation_mean_std": 1.8375074470598163,
    "attention_bam_384_peak_separation_mean_min": 9.668615369565247,
    "attention_bam_384_peak_separation_mean_max": 24.8699815549216,
    "attention_bam_384_peak_intensity_mean_mean": 0.3242598777545889,
    "attention_bam_384_peak_intensity_mean_std": 0.050058078547278485,
    "attention_bam_384_peak_intensity_mean_min": 0.19719833135604858,
    "attention_bam_384_peak_intensity_mean_max": 0.4700510501861572,
    "attention_bam_384_peak_coverage_mean": 0.1005859375,
    "attention_bam_384_peak_coverage_std": 0.0,
    "attention_bam_384_peak_coverage_min": 0.1005859375,
    "attention_bam_384_peak_coverage_max": 0.1005859375,
    "attention_bam_16_mean_attention_mean": 0.16061254449612122,
    "attention_bam_16_mean_attention_std": 0.03927148344647387,
    "attention_bam_16_mean_attention_min": -0.04029373079538345,
    "attention_bam_16_mean_attention_max": 0.2840683162212372,
    "attention_bam_16_std_attention_mean": 0.5563433014472959,
    "attention_bam_16_std_attention_std": 0.0557861923051202,
    "attention_bam_16_std_attention_min": 0.15093879401683807,
    "attention_bam_16_std_attention_max": 0.7584808468818665,
    "attention_bam_16_max_attention_mean": 2.836844415245123,
    "attention_bam_16_max_attention_std": 0.5922347113440242,
    "attention_bam_16_max_attention_min": 0.3069092631340027,
    "attention_bam_16_max_attention_max": 5.8794450759887695,
    "attention_bam_16_min_attention_mean": -1.0663863867966983,
    "attention_bam_16_min_attention_std": 0.09357281101393697,
    "attention_bam_16_min_attention_min": -1.4626561403274536,
    "attention_bam_16_min_attention_max": -0.4374985098838806,
    "attention_bam_16_attention_entropy_mean": NaN,
    "attention_bam_16_attention_entropy_std": NaN,
    "attention_bam_16_attention_entropy_min": NaN,
    "attention_bam_16_attention_entropy_max": NaN,
    "attention_bam_16_attention_kurtosis_mean": 0.810194803161176,
    "attention_bam_16_attention_kurtosis_std": 0.9599093853532401,
    "attention_bam_16_attention_kurtosis_min": -0.5841703410821704,
    "attention_bam_16_attention_kurtosis_max": 7.870485802815638,
    "attention_bam_16_attention_skewness_mean": 0.734609299321261,
    "attention_bam_16_attention_skewness_std": 0.2551197257584968,
    "attention_bam_16_attention_skewness_min": -0.2805927456680973,
    "attention_bam_16_attention_skewness_max": 2.0136314147787924,
    "attention_bam_16_attention_sparsity_mean": 0.5054506889487786,
    "attention_bam_16_attention_sparsity_std": 0.04103108420354142,
    "attention_bam_16_attention_sparsity_min": 0.2958984375,
    "attention_bam_16_attention_sparsity_max": 0.831298828125,
    "attention_bam_16_attention_concentration_10_mean": 0.8177664546333845,
    "attention_bam_16_attention_concentration_10_std": 0.16027101835077046,
    "attention_bam_16_attention_concentration_10_min": -0.6226609355982947,
    "attention_bam_16_attention_concentration_10_max": 1.3130808211417744,
    "attention_bam_16_attention_concentration_20_mean": 1.2915398138897243,
    "attention_bam_16_attention_concentration_20_std": 0.23847482107777193,
    "attention_bam_16_attention_concentration_20_min": -1.0122358604732702,
    "attention_bam_16_attention_concentration_20_max": 1.9848070329698968,
    "attention_bam_16_attention_center_y_mean": 0.46755764583278764,
    "attention_bam_16_attention_center_y_std": 0.011390698945649353,
    "attention_bam_16_attention_center_y_min": 0.4315571790168308,
    "attention_bam_16_attention_center_y_max": 0.49980089724886084,
    "attention_bam_16_attention_center_x_mean": 0.4674061793913757,
    "attention_bam_16_attention_center_x_std": 0.011063976718812847,
    "attention_bam_16_attention_center_x_min": 0.4336695802177936,
    "attention_bam_16_attention_center_x_max": 0.5046730841662552,
    "attention_bam_16_attention_center_distance_mean": 0.0668865382803891,
    "attention_bam_16_attention_center_distance_std": 0.01612431642550778,
    "attention_bam_16_attention_center_distance_min": 0.01647213666923715,
    "attention_bam_16_attention_center_distance_max": 0.1293868494290582,
    "attention_bam_16_attention_spatial_variance_mean": 42.691978737570174,
    "attention_bam_16_attention_spatial_variance_std": 0.996287556271726,
    "attention_bam_16_attention_spatial_variance_min": 39.47168520702132,
    "attention_bam_16_attention_spatial_variance_max": 45.44775543338126,
    "attention_bam_16_attention_spatial_std_mean": 6.53346475030221,
    "attention_bam_16_attention_spatial_std_std": 0.07630792627130575,
    "attention_bam_16_attention_spatial_std_min": 6.282649537179463,
    "attention_bam_16_attention_spatial_std_max": 6.741495044378603,
    "attention_bam_16_num_attention_peaks_mean": 6.64506480558325,
    "attention_bam_16_num_attention_peaks_std": 2.4420719972000455,
    "attention_bam_16_num_attention_peaks_min": 1.0,
    "attention_bam_16_num_attention_peaks_max": 18.0,
    "attention_bam_16_peak_separation_mean_mean": 9.128293327807508,
    "attention_bam_16_peak_separation_mean_std": 1.2456531610897537,
    "attention_bam_16_peak_separation_mean_min": 0.0,
    "attention_bam_16_peak_separation_mean_max": 14.321605706856886,
    "attention_bam_16_peak_intensity_mean_mean": 0.3294037904363805,
    "attention_bam_16_peak_intensity_mean_std": 0.04443938633078113,
    "attention_bam_16_peak_intensity_mean_min": 0.17640390992164612,
    "attention_bam_16_peak_intensity_mean_max": 0.5501440763473511,
    "attention_bam_16_peak_coverage_mean": 0.1015625,
    "attention_bam_16_peak_coverage_std": 0.0,
    "attention_bam_16_peak_coverage_min": 0.1015625,
    "attention_bam_16_peak_coverage_max": 0.1015625
  },
  "metadata": {
    "created_at": "2025-10-04T09:14:25.336975",
    "total_batches": 1003,
    "device": "cuda:0"
  }
}